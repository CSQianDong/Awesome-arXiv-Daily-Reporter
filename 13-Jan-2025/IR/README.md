# kANNolo: Sweet and Smooth Approximate k-Nearest Neighbors Search 

**Title (ZH)**: kANNolo：甜蜜而平滑的k最近邻搜索近似算法 

**Authors**: Leonardo Delfino, Domenico Erriquez, Silvio Martinico, Franco Maria Nardini, Cosimo Rulli, Rossano Venturini  

**Link**: [PDF](https://arxiv.org/pdf/2501.06121)  

**Abstract**: Approximate Nearest Neighbors (ANN) search is a crucial task in several applications like recommender systems and information retrieval. Current state-of-the-art ANN libraries, although being performance-oriented, often lack modularity and ease of use. This translates into them not being fully suitable for easy prototyping and testing of research ideas, an important feature to enable. We address these limitations by introducing kANNolo, a novel research-oriented ANN library written in Rust and explicitly designed to combine usability with performance effectively. kANNolo is the first ANN library that supports dense and sparse vector representations made available on top of different similarity measures, e.g., euclidean distance and inner product. Moreover, it also supports vector quantization techniques, e.g., Product Quantization, on top of the indexing strategies implemented. These functionalities are managed through Rust traits, allowing shared behaviors to be handled abstractly. This abstraction ensures flexibility and facilitates an easy integration of new components. In this work, we detail the architecture of kANNolo and demonstrate that its flexibility does not compromise performance. The experimental analysis shows that kANNolo achieves state-of-the-art performance in terms of speed-accuracy trade-off while allowing fast and easy prototyping, thus making kANNolo a valuable tool for advancing ANN research. Source code available on GitHub: this https URL. 

**Abstract (ZH)**: 近似最近邻（Approximate Nearest Neighbors, ANN）搜索在推荐系统和信息检索等应用中是一个关键任务。当前最先进的ANN库虽然在性能上有所优化，但在模块化和易用性方面往往有所欠缺。这使得它们不适合用于快速原型设计和研究想法的测试，这是非常重要的功能。我们通过引入kANNolo，一种用Rust编写的面向研究的ANN库，来解决这些局限性，该库旨在有效结合易用性和性能。kANNolo是首个支持不同相似性度量（例如欧几里得距离和内积）下的稠密和稀疏向量表示的ANN库。此外，它还支持在索引策略实施的基础上使用向量量化技术，如产品量化。这些功能通过Rust特质进行管理，允许共享行为以抽象方式处理，从而确保灵活性并简化新组件的集成。在本文中，我们详细介绍了kANNolo的架构，并证明其灵活性不会影响性能。实验分析表明，kANNolo在速度-准确性的权衡方面达到了最先进的性能，同时支持快速原型设计，使其成为推进ANN研究的宝贵工具。代码可在GitHub上获取：this https URL。 

---
# Recommender Systems for Social Good: The Role of Accountability and Sustainability 

**Title (ZH)**: 社会公益中的推荐系统：问责制与可持续性的作用 

**Authors**: Alan Said  

**Link**: [PDF](https://arxiv.org/pdf/2501.05964)  

**Abstract**: This work examines the role of recommender systems in promoting sustainability, social responsibility, and accountability, with a focus on alignment with the United Nations Sustainable Development Goals (SDGs). As recommender systems become increasingly integrated into daily interactions, they must go beyond personalization to support responsible consumption, reduce environmental impact, and foster social good. We explore strategies to mitigate the carbon footprint of recommendation models, ensure fairness, and implement accountability mechanisms. By adopting these approaches, recommender systems can contribute to sustainable and socially beneficial outcomes, aligning technological advancements with the SDGs focused on environmental sustainability and social well-being. 

**Abstract (ZH)**: 本文探讨了推荐系统在促进可持续性、社会责任和可问责性方面的作用，重点关注其与联合国可持续发展目标（SDGs）的一致性。随着推荐系统越来越多地融入日常互动中，它们必须超越个性化功能，支持负责任的消费、减少环境影响，并促进社会福祉。本文探讨了减轻推荐模型碳足迹、确保公平性以及实施问责机制的策略。通过采用这些方法，推荐系统可以为实现可持续和具有社会效益的结果做出贡献，并将技术进步与关注环境可持续性和社会福祉的SDGs目标相一致。 

---
# Text2Playlist: Generating Personalized Playlists from Text on Deezer 

**Title (ZH)**: 文本到播放列表：从 Deezer 上的文本生成个性化播放列表 

**Authors**: Mathieu Delcluze, Antoine Khoury, Clémence Vast, Valerio Arnaudo, Léa Briand, Walid Bendada, Thomas Bouabça  

**Link**: [PDF](https://arxiv.org/pdf/2501.05894)  

**Abstract**: The streaming service Deezer heavily relies on the search to help users navigate through its extensive music catalog. Nonetheless, it is primarily designed to find specific items and does not lead directly to a smooth listening experience. We present Text2Playlist, a stand-alone tool that addresses these limitations. Text2Playlist leverages generative AI, music information retrieval and recommendation systems to generate query-specific and personalized playlists, successfully deployed at scale. 

**Abstract (ZH)**: 以下内容是来自论文标题或摘要的英语翻译，符合学术规范：

流媒体服务Deezer高度依赖搜索功能帮助用户导航其庞大的音乐库。然而，该功能主要是为了找到特定项，而未能直接提供流畅的音乐播放体验。本文介绍了一种名为Text2Playlist的独立工具，旨在解决这些局限性。Text2Playlist利用生成式人工智能、音乐信息检索和推荐系统技术，生成与查询特定和个性化相匹配的播放列表，并成功实现了大规模部署。 

---
# Social web and Wikipedia: an opportunity to rethink the links between sources' credibility, trust and authority 

**Title (ZH)**: 社会网络与维基百科：重新思考来源可信度、信任和权威之间的关系的机会 

**Authors**: Gilles Sahut, André Tricot  

**Link**: [PDF](https://arxiv.org/pdf/2501.05813)  

**Abstract**: The Web and its main tools (Google, Wikipedia, Facebook, Twitter) deeply raise and renew fundamental questions, that everyone asks almost every day: Is this information or content true? Can I trust this author or source? These questions are not new, they have been the same with books, newspapers, broadcasting and television, and, more fundamentally, in every human interpersonal communication. This paper is focused on two scientific problems on this issue. The first one is theoretical: to address this issue, many concepts have been used in library and information sciences, communication and psychology. The links between these concepts are not clear: sometimes two concepts are considered as synonymous, sometimes as very different. The second one is historical: sources like Wikipedia deeply challenge the epistemic evaluation of information sources, compared to previous modes of information production. This paper proposes an integrated and simple model considering the relation between a user, a document and an author as human communication. It reduces the problem to three concepts: credibility as a characteristic granted to information depending on its truth-value; trust as the ability to produce credible information; authority when the power to influence of an author is accepted, i.e., when readers accept that the source can modify their opinion, knowledge and decisions. The model describes also two kinds of relationships between the three concepts: an upward link and a downward link. The model is confronted with findings of empirical research on Wikipedia in particular. 

**Abstract (ZH)**: 互联网及其主要工具（Google、Wikipedia、Facebook、Twitter）深刻地提出了和更新了许多基本问题，几乎每个人都几乎每天都会问这些问题：这些信息或内容是真的吗？我能相信这个作者或信息来源吗？这些问题并不是全新的，它们自书籍、报纸、广播和电视以来一直是同样的问题，更根本地说，在每一种人类的人际交流中也是如此。本文聚焦于该问题上的两个科学问题。第一个问题是理论性的：为了研究这一问题，图书馆和信息科学、通信和心理学中已经使用了许多概念，但这些概念之间的关系并不清晰：有时认为两个概念是同义的，有时则认为它们是极其不同的。第二个问题是历史性的：像Wikipedia这样的来源极大地挑战了对信息来源的认知评估，与以往的信息生产模式相比。本文提出了一种整合而简单的模型，将用户、文档和作者之间的关系视为人类沟通。该模型将问题简化为三个概念：可信赖性作为信息的一种特性，依赖于其真实性的程度；信任作为生产可信信息的能力；权威则当作者的影响被接受时出现，即当读者接受该来源能够改变他们的观点、知识和决策时。该模型还描述了这三种概念之间的两种关系：一种向上联系，一种向下联系。该模型与针对Wikipedia的实证研究发现进行了对比。 

---
# Collaboration of Large Language Models and Small Recommendation Models for Device-Cloud Recommendation 

**Title (ZH)**: 将大型语言模型与小型推荐模型协作应用于设备-云推荐系统

该标题的翻译符合学术规范，其中“Collaboration”被翻译为“协作”，“Large Language Models”被翻译为“大型语言模型”，“Small Recommendation Models”被翻译为“小型推荐模型”，“Device-Cloud Recommendation”被翻译为“设备-云推荐系统”。这样的翻译既准确又专业。 

**Authors**: Zheqi Lv, Tianyu Zhan, Wenjie Wang, Xinyu Lin, Shengyu Zhang, Wenqiao Zhang, Jiwei Li, Kun Kuang, Fei Wu  

**Link**: [PDF](https://arxiv.org/pdf/2501.05647)  

**Abstract**: Large Language Models (LLMs) for Recommendation (LLM4Rec) is a promising research direction that has demonstrated exceptional performance in this field. However, its inability to capture real-time user preferences greatly limits the practical application of LLM4Rec because (i) LLMs are costly to train and infer frequently, and (ii) LLMs struggle to access real-time data (its large number of parameters poses an obstacle to deployment on devices). Fortunately, small recommendation models (SRMs) can effectively supplement these shortcomings of LLM4Rec diagrams by consuming minimal resources for frequent training and inference, and by conveniently accessing real-time data on devices.
In light of this, we designed the Device-Cloud LLM-SRM Collaborative Recommendation Framework (LSC4Rec) under a device-cloud collaboration setting. LSC4Rec aims to integrate the advantages of both LLMs and SRMs, as well as the benefits of cloud and edge computing, achieving a complementary synergy. We enhance the practicability of LSC4Rec by designing three strategies: collaborative training, collaborative inference, and intelligent request. During training, LLM generates candidate lists to enhance the ranking ability of SRM in collaborative scenarios and enables SRM to update adaptively to capture real-time user interests. During inference, LLM and SRM are deployed on the cloud and on the device, respectively. LLM generates candidate lists and initial ranking results based on user behavior, and SRM get reranking results based on the candidate list, with final results integrating both LLM's and SRM's scores. The device determines whether a new candidate list is needed by comparing the consistency of the LLM's and SRM's sorted lists. Our comprehensive and extensive experimental analysis validates the effectiveness of each strategy in LSC4Rec. 

**Abstract (ZH)**: 大规模语言模型（LLMs）在推荐领域的应用（LLM4Rec）是一个前景广阔的研究方向，已在该领域显示出卓越性能。然而，其捕捉实时用户偏好的能力有限，极大地限制了LLM4Rec的实际应用。主要原因在于（i）训练和推断LLMs的成本较高，（ii）LLMs难以访问实时数据（其大量参数阻碍了在设备上的部署）。幸运的是，小型推荐模型（SRMs）可以通过消耗最少的资源进行频繁的训练和推断，并方便地在设备上访问实时数据，有效地补充了LLM4Rec的不足。

基于此，我们提出了一种设备-云LLM-SRM协作推荐框架（LSC4Rec），在设备-云协作环境下设计。LSC4Rec旨在结合LLMs和SRMs的优点，以及云计算和边缘计算的优势，实现互补协同效应。我们通过设计三种策略来增强LSC4Rec的实用性：协作训练、协作推断和智能请求。在训练过程中，LLM生成候选列表，以增强SRM在协作场景下的排名能力，并使SRM能够根据用户行为进行自适应更新，以捕捉实时用户偏好。在推断过程中，LLM和SRM分别部署在云和设备上。LLM根据用户行为生成候选列表和初始排名结果，而SRM基于候选列表获得重新排名结果，最终结果结合了LLM和SRM的评分。设备通过比较LLM和SRM排序列表的一致性来决定是否需要新的候选列表。我们全面而详尽的实验分析验证了LSC4Rec中每种策略的有效性。 

---
# Navigating Tomorrow: Reliably Assessing Large Language Models Performance on Future Event Prediction 

**Title (ZH)**: 导航未来：可靠评估大型语言模型在预测未来事件表现的能力 

**Authors**: Petraq Nako, Adam Jatowt  

**Link**: [PDF](https://arxiv.org/pdf/2501.05925)  

**Abstract**: Predicting future events is an important activity with applications across multiple fields and domains. For example, the capacity to foresee stock market trends, natural disasters, business developments, or political events can facilitate early preventive measures and uncover new opportunities. Multiple diverse computational methods for attempting future predictions, including predictive analysis, time series forecasting, and simulations have been proposed. This study evaluates the performance of several large language models (LLMs) in supporting future prediction tasks, an under-explored domain. We assess the models across three scenarios: Affirmative vs. Likelihood questioning, Reasoning, and Counterfactual analysis. For this, we create a dataset1 by finding and categorizing news articles based on entity type and its popularity. We gather news articles before and after the LLMs training cutoff date in order to thoroughly test and compare model performance. Our research highlights LLMs potential and limitations in predictive modeling, providing a foundation for future improvements. 

**Abstract (ZH)**: 预测未来事件是一项重要的活动，具有跨多个领域和地域的应用价值。例如，预测股票市场趋势、自然灾害、商业发展或政治事件的能力可以促进早期预防措施并发现新的机会。已经提出了多种不同的计算方法来尝试进行未来预测，包括预测分析、时间序列预测和模拟。本研究评估了多个大型语言模型（LLMs）在支持未来预测任务方面的性能，这是尚未充分探索的领域。我们通过根据实体类型及其受欢迎程度来查找和分类新闻文章，创建了一个数据集。我们收集了LLMs训练截止日期前后的新文章，以便全面测试和比较模型的性能。我们的研究突显了LLMs在预测建模中的潜力和局限性，为未来的改进提供了基础。 

---
# VideoRAG: Retrieval-Augmented Generation over Video Corpus 

**Title (ZH)**: VideoRAG：视频语料库中的检索增强生成 

**Authors**: Soyeong Jeong, Kangsan Kim, Jinheon Baek, Sung Ju Hwang  

**Link**: [PDF](https://arxiv.org/pdf/2501.05874)  

**Abstract**: Retrieval-Augmented Generation (RAG) is a powerful strategy to address the issue of generating factually incorrect outputs in foundation models by retrieving external knowledge relevant to queries and incorporating it into their generation process. However, existing RAG approaches have primarily focused on textual information, with some recent advancements beginning to consider images, and they largely overlook videos, a rich source of multimodal knowledge capable of representing events, processes, and contextual details more effectively than any other modality. While a few recent studies explore the integration of videos in the response generation process, they either predefine query-associated videos without retrieving them according to queries, or convert videos into the textual descriptions without harnessing their multimodal richness. To tackle these, we introduce VideoRAG, a novel framework that not only dynamically retrieves relevant videos based on their relevance with queries but also utilizes both visual and textual information of videos in the output generation. Further, to operationalize this, our method revolves around the recent advance of Large Video Language Models (LVLMs), which enable the direct processing of video content to represent it for retrieval and seamless integration of the retrieved videos jointly with queries. We experimentally validate the effectiveness of VideoRAG, showcasing that it is superior to relevant baselines. 

**Abstract (ZH)**: 检索增强生成（RAG）是一种强大的策略，用于通过检索与查询相关的外部知识并在其生成过程中结合这些知识来解决基础模型生成事实不正确输出的问题。然而，现有的RAG方法主要集中在文本信息上，虽然最近有一些进展开始考虑图像，但它们在很大程度上忽略了视频这一富含多模态知识的来源，视频比任何其他模态都能更有效地代表事件、过程和背景细节。虽然有一些最近的研究探索了在响应生成过程中整合视频的方法，但这些方法要么预先定义与查询关联的视频而无需根据查询检索视频，要么将视频转换为文本描述而未能充分利用其多模态丰富性。为了解决这些问题，我们提出了一种名为VideoRAG的新框架，该框架不仅能够根据其与查询的相关性动态检索相关视频，还利用了视频的视觉和文本信息来进行输出生成。此外，为了实现这一目标，我们的方法围绕最近的大型视频语言模型（LVLMs）的发展展开，这些模型使直接处理视频内容成为可能，可以用于检索，并能无缝结合检索到的视频与查询进行集成。我们通过实验证明了VideoRAG的有效性，展示了它优于相关基线方法。 

---
# Harmonizing Metadata of Language Resources for Enhanced Querying and Accessibility 

**Title (ZH)**: 优化语言资源元数据以增强查询和获取便捷性 

**Authors**: Zixuan Liang  

**Link**: [PDF](https://arxiv.org/pdf/2501.05606)  

**Abstract**: This paper addresses the harmonization of metadata from diverse repositories of language resources (LRs). Leveraging linked data and RDF techniques, we integrate data from multiple sources into a unified model based on DCAT and META-SHARE OWL ontology. Our methodology supports text-based search, faceted browsing, and advanced SPARQL queries through Linghub, a newly developed portal. Real user queries from the Corpora Mailing List (CML) were evaluated to assess Linghub capability to satisfy actual user needs. Results indicate that while some limitations persist, many user requests can be successfully addressed. The study highlights significant metadata issues and advocates for adherence to open vocabularies and standards to enhance metadata harmonization. This initial research underscores the importance of API-based access to LRs, promoting machine usability and data subset extraction for specific purposes, paving the way for more efficient and standardized LR utilization. 

**Abstract (ZH)**: 本文探讨了来自多种语言资源（LRs）仓库的元数据的协调统一问题。通过利用链接数据和RDF技术，我们将来自多个数据源的信息整合到基于DCAT和META-SHARE OWL本体的统一模型中。我们的方法通过Linghub新开发的门户支持基于文本的搜索、分类浏览以及先进的SPARQL查询。我们使用来自语料库邮件列表（CML）的实际用户查询来评估Linghub的能力，以满足实际用户需求。结果表明，虽然存在一些限制，但仍有许多用户请求可以成功解决。本研究强调了元数据问题的重大意义，并倡导遵守开放词汇表和标准以提高元数据的协调统一。初步研究强调了基于API访问语言资源的重要性，促进了机器可使用性和特定目的的数据子集提取，为更高效和标准化的语言资源利用铺平了道路。 

---
# Spatial Information Integration in Small Language Models for Document Layout Generation and Classification 

**Title (ZH)**: 小型语言模型中空间信息集成在文档布局生成与分类中的应用 

**Authors**: Pablo Melendez, Clemens Havas  

**Link**: [PDF](https://arxiv.org/pdf/2501.05497)  

**Abstract**: Document layout understanding is a field of study that analyzes the spatial arrangement of information in a document hoping to understand its structure and layout. Models such as LayoutLM (and its subsequent iterations) can understand semi-structured documents with SotA results; however, the lack of open semi-structured data is a limitation in itself. While semi-structured data is common in everyday life (balance sheets, purchase orders, receipts), there is a lack of public datasets for training machine learning models for this type of document. In this investigation we propose a method to generate new, synthetic, layout information that can help overcoming this data shortage. According to our results, the proposed method performs better than LayoutTransformer, another popular layout generation method. We also show that, in some scenarios, text classification can improve when supported by bounding box information. 

**Abstract (ZH)**: 文档布局理解是一个研究领域，旨在分析文档中信息的空间布局，以理解其结构和排版。如LayoutLM（及其后续版本）这样的模型可以理解半结构化文档，并取得当前最先进的结果；然而，公开的半结构化数据不足本身就是一个限制。尽管在日常生活中半结构化数据很常见（如资产负债表、采购订单、收据），但缺乏用于训练机器学习模型的此类文档的公开数据集。在本研究中，我们提出了一种生成新的合成布局信息的方法，以克服数据短缺问题。根据我们的结果，所提出的方法在半结构化文档的布局生成方面优于另一种流行的生成方法LayoutTransformer。此外，我们还展示了在某些情况下，当借助边界框信息支持文本分类时，文本分类性能可以得到改进。 

---
# S2 Chunking: A Hybrid Framework for Document Segmentation Through Integrated Spatial and Semantic Analysis 

**Title (ZH)**: S2分块：一种结合空间和语义综合分析的文档分段混合框架 

**Authors**: Prashant Verma  

**Link**: [PDF](https://arxiv.org/pdf/2501.05485)  

**Abstract**: Document chunking is a critical task in natural language processing (NLP) that involves dividing a document into meaningful segments. Traditional methods often rely solely on semantic analysis, ignoring the spatial layout of elements, which is crucial for understanding relationships in complex documents. This paper introduces a novel hybrid approach that combines layout structure, semantic analysis, and spatial relationships to enhance the cohesion and accuracy of document chunks. By leveraging bounding box information (bbox) and text embeddings, our method constructs a weighted graph representation of document elements, which is then clustered using spectral clustering. Experimental results demonstrate that this approach outperforms traditional methods, particularly in documents with diverse layouts such as reports, articles, and multi-column designs. The proposed method also ensures that no chunk exceeds a specified token length, making it suitable for use cases where token limits are critical (e.g., language models with input size limitations) 

**Abstract (ZH)**: 文档切分是自然语言处理（NLP）中的一个关键任务，涉及将文档划分为有意义的段落。传统方法通常仅依赖于语义分析，而忽略了元素的空间布局，这对于理解复杂文档中的关系至关重要。本文介绍了一种结合布局结构、语义分析和空间关系的新颖混合方法，旨在提高文档切分的一致性和准确性。通过利用边界框信息（bbox）和文本嵌入，我们的方法构建了文档元素的加权图表示，并使用谱聚类对其进行聚类。实验结果表明，该方法在报告、文章和多列设计等具有不同布局的文档中优于传统方法。此外，所提出的方法还确保每个切分段落不超过指定的词元长度，使其适用于词元限制至关重要的应用场景（例如，具有输入大小限制的语言模型）。 

---
# Retrieval-Augmented Generation by Evidence Retroactivity in LLMs 

**Title (ZH)**: 在大规模语言模型中基于证据回溯的检索增强生成 

**Authors**: Liang Xiao, Wen Dai, Shuai Chen, Bin Qin, Chongyang Shi, Haopeng Jing, Tianyu Guo  

**Link**: [PDF](https://arxiv.org/pdf/2501.05475)  

**Abstract**: Retrieval-augmented generation has gained significant attention due to its ability to integrate relevant external knowledge, enhancing the accuracy and reliability of the LLMs' responses. Most of the existing methods apply a dynamic multiple retrieval-generating process, to address multi-hop complex questions by decomposing them into sub-problems. However, these methods rely on an unidirectional forward reasoning paradigm, where errors from insufficient reasoning steps or inherent flaws in current retrieval systems are irreversible, potentially derailing the entire reasoning chain. For the first time, this work introduces Retroactive Retrieval-Augmented Generation (RetroRAG), a novel framework to build a retroactive reasoning paradigm. RetroRAG revises and updates the evidence, redirecting the reasoning chain to the correct direction. RetroRAG constructs an evidence-collation-discovery framework to search, generate, and refine credible evidence. It synthesizes inferential evidence related to the key entities in the question from the existing source knowledge and formulates search queries to uncover additional information. As new evidence is found, RetroRAG continually updates and organizes this information, enhancing its ability to locate further necessary evidence. Paired with an Answerer to generate and evaluate outputs, RetroRAG is capable of refining its reasoning process iteratively until a reliable answer is obtained. Empirical evaluations show that RetroRAG significantly outperforms existing methods. 

**Abstract (ZH)**: 检索增强生成由于其整合相关外部知识的能力，极大地提高了LLM回复的准确性和可靠性，因此引起了广泛关注。现有的大多数方法通过将复杂问题分解为子问题，采用动态多轮检索生成的过程来应对多跳复杂问题。然而，这些方法依赖于单向的前向推理范式，这意味着推理链中的错误，由于推理步骤不足或当前检索系统中存在的缺陷导致的错误，是不可逆的，可能会导致整个推理链偏离正确方向。这是首次提出一种名为Retroactive Retrieval-Augmented Generation（RetroRAG）的新框架，构建了一种后向推理范式。RetroRAG 修正并更新证据，将推理链导向正确的方向。通过构建一个证据集合法，RetroRAG 实现了从现有来源知识中搜索、生成和精炼可信证据的过程。它从问题中的关键实体中综合推断性证据，并制定搜索查询以发现额外信息。随着新证据的发现，RetroRAG 持续更新并组织这些信息，提高其定位进一步所需证据的能力。与一个回答生成器配对，RetroRAG 能够迭代地优化其推理过程，直至获得可靠的答案。实证评估表明，RetroRAG 显著优于现有方法。 

---
# LLM-MedQA: Enhancing Medical Question Answering through Case Studies in Large Language Models 

**Title (ZH)**: LLM-MedQA：通过大型语言模型案例研究增强医学问答能力 

**Authors**: Hang Yang, Hao Chen, Hui Guo, Yineng Chen, Ching-Sheng Lin, Shu Hu, Jinrong Hu, Xi Wu, Xin Wang  

**Link**: [PDF](https://arxiv.org/pdf/2501.05464)  

**Abstract**: Accurate and efficient question-answering systems are essential for delivering high-quality patient care in the medical field. While Large Language Models (LLMs) have made remarkable strides across various domains, they continue to face significant challenges in medical question answering, particularly in understanding domain-specific terminologies and performing complex reasoning. These limitations undermine their effectiveness in critical medical applications. To address these issues, we propose a novel approach incorporating similar case generation within a multi-agent medical question-answering (MedQA) system. Specifically, we leverage the Llama3.1:70B model, a state-of-the-art LLM, in a multi-agent architecture to enhance performance on the MedQA dataset using zero-shot learning. Our method capitalizes on the model's inherent medical knowledge and reasoning capabilities, eliminating the need for additional training data. Experimental results show substantial performance gains over existing benchmark models, with improvements of 7% in both accuracy and F1-score across various medical QA tasks. Furthermore, we examine the model's interpretability and reliability in addressing complex medical queries. This research not only offers a robust solution for medical question answering but also establishes a foundation for broader applications of LLMs in the medical domain. 

**Abstract (ZH)**: 在医疗领域，精准高效的问答系统对于提供高质量的病人护理至关重要。尽管大型语言模型（LLMs）在多个领域取得了显著进展，但在医疗问答方面仍然面临重大挑战，特别是在理解和处理领域特定术语以及执行复杂推理方面。这些局限性削弱了它们在关键医疗应用中的有效性。为了解决这些问题，我们提出了一种创新方法，即将类似病例生成引入多智能体医疗问答（MedQA）系统中。具体而言，我们利用Llama3.1:70B模型（目前最先进的LLM之一）构建多智能体架构，通过零样本学习增强在MedQA数据集上的性能。该方法利用模型固有的医疗知识和推理能力，无需额外的训练数据。实验结果表明，与现有的基准模型相比，我们的方法在多种医疗问答任务中实现了显著的性能提升，准确率和F1分数分别提高了7%。此外，我们还探讨了该模型在处理复杂医疗查询方面的可解释性和可靠性。这项研究不仅提供了一种稳健的医疗问答解决方案，也为大型语言模型在医疗领域的更广泛应用奠定了基础。 

---
