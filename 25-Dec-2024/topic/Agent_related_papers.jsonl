{'arxiv_id': 'arXiv:2412.18454', 'title': 'Multi-Agent Norm Perception and Induction in Distributed Healthcare', 'authors': 'Chao Li, Olga Petruchik, Elizaveta Grishanina, Sergey Kovalchuk', 'link': 'https://arxiv.org/abs/2412.18454', 'abstract': 'This paper presents a Multi-Agent Norm Perception and Induction Learning Model aimed at facilitating the integration of autonomous agent systems into distributed healthcare environments through dynamic interaction processes. The nature of the medical norm system and its sharing channels necessitates distinct approaches for Multi-Agent Systems to learn two types of norms. Building on this foundation, the model enables agents to simultaneously learn descriptive norms, which capture collective tendencies, and prescriptive norms, which dictate ideal behaviors. Through parameterized mixed probability density models and practice-enhanced Markov games, the multi-agent system perceives descriptive norms in dynamic interactions and captures emergent prescriptive norms. We conducted experiments using a dataset from a neurological medical center spanning from 2016 to 2020.', 'abstract_zh': '本文提出了一种多agent规范感知与归纳学习模型，旨在通过动态交互过程促进自主agent系统在分布式医疗环境中的集成。医疗规范系统的性质及其共享渠道要求多agent系统采用不同的方法来学习两种类型的规范。在此基础上，该模型使agents能够同时学习描述性规范，这些规范捕捉了群体倾向，以及规范性规范，这些规范规定了理想行为。通过参数化混合概率密度模型和实践增强的马尔可夫游戏，多agent系统在动态交互中感知描述性规范，并捕捉到新兴的规范性规范。我们使用2016年至2020年间来自一家神经医学中心的数据集进行了实验。', 'title_zh': '多智能体规范感知与诱导在分布式医疗中的应用'}
{'arxiv_id': 'arXiv:2412.18428', 'title': 'Explainable Multi-Modal Data Exploration in Natural Language via LLM Agent', 'authors': 'Farhad Nooralahzadeh, Yi Zhang, Jonathan Furst, Kurt Stockinger', 'link': 'https://arxiv.org/abs/2412.18428', 'abstract': 'International enterprises, organizations, or hospitals collect large amounts of multi-modal data stored in databases, text documents, images, and videos. While there has been recent progress in the separate fields of multi-modal data exploration as well as in database systems that automatically translate natural language questions to database query languages, the research challenge of querying database systems combined with other unstructured modalities such as images in natural language is widely unexplored.\nIn this paper, we propose XMODE - a system that enables explainable, multi-modal data exploration in natural language. Our approach is based on the following research contributions: (1) Our system is inspired by a real-world use case that enables users to explore multi-modal information systems. (2) XMODE leverages a LLM-based agentic AI framework to decompose a natural language question into subtasks such as text-to-SQL generation and image analysis. (3) Experimental results on multi-modal datasets over relational data and images demonstrate that our system outperforms state-of-the-art multi-modal exploration systems, excelling not only in accuracy but also in various performance metrics such as query latency, API costs, planning efficiency, and explanation quality, thanks to the more effective utilization of the reasoning capabilities of LLMs.', 'abstract_zh': '国际企业、组织或医院收集了大量的多模态数据，这些数据存储在数据库、文本文档、图像和视频中。虽然在多模态数据探索和自然语言到数据库查询语言自动生成方面各自取得了一定进展，但将数据库系统与其他未结构化的模态如图像结合查询的研究挑战仍然没有得到广泛探索。\n\n在本文中，我们提出了一种名为XMODE的系统，旨在通过自然语言实现可解释的多模态数据探索。我们的方法主要基于以下研究贡献：（1）我们的系统借鉴了一个实际应用案例，使用户能够探索多模态信息系统。（2）XMODE利用一个基于大语言模型（LLM）的代理AI框架，将自然语言问题分解为子任务，例如文本到SQL生成和图像分析。（3）通过针对关系数据和图像的多模态数据集进行实验，结果显示我们的系统在准确性和多种性能指标（如查询延迟、API成本、计划效率和解释质量）方面均优于现有最先进的多模态探索系统，得益于更有效利用了LLMs的推理能力。', 'title_zh': '通过大语言模型代理进行可解释的多模态数据自然语言探索'}
{'arxiv_id': 'arXiv:2412.18426', 'title': 'GUI Testing Arena: A Unified Benchmark for Advancing Autonomous GUI Testing Agent', 'authors': 'Kangjia Zhao, Jiahui Song, Leigang Sha, Haozhan Shen, Zhi Chen, Tiancheng Zhao, Xiubo Liang, Jianwei Yin', 'link': 'https://arxiv.org/abs/2412.18426', 'abstract': 'Nowadays, research on GUI agents is a hot topic in the AI community. However, current research focuses on GUI task automation, limiting the scope of applications in various GUI scenarios. In this paper, we propose a formalized and comprehensive environment to evaluate the entire process of automated GUI Testing (GTArena), offering a fair, standardized environment for consistent operation of diverse multimodal large language models. We divide the testing process into three key subtasks: test intention generation, test task execution, and GUI defect detection, and construct a benchmark dataset based on these to conduct a comprehensive evaluation. It evaluates the performance of different models using three data types: real mobile applications, mobile applications with artificially injected defects, and synthetic data, thoroughly assessing their capabilities in this relevant task. Additionally, we propose a method that helps researchers explore the correlation between the performance of multimodal language large models in specific scenarios and their general capabilities in standard benchmark tests. Experimental results indicate that even the most advanced models struggle to perform well across all sub-tasks of automated GUI Testing, highlighting a significant gap between the current capabilities of Autonomous GUI Testing and its practical, real-world applicability. This gap provides guidance for the future direction of GUI Agent development. Our code is available at this https URL.', 'abstract_zh': '现今，GUI代理的研究是人工智能领域的一个热点话题。然而，当前的研究主要集中于GUI任务自动化，这限制了其在各种GUI场景中的应用范围。本文提出了一种标准化和全面的环境，用于评估整个自动化GUI测试（GTArena）过程，提供了一个公平且标准化的环境，以便一致地运行不同的多模态大型语言模型。我们将测试过程分为三个关键子任务：测试意图生成、测试任务执行和GUI缺陷检测，并基于这些子任务构建基准数据集，进行全面评估。该基准数据集使用三种不同类型的数据——实际移动应用程序、具有人为注入缺陷的移动应用程序和合成数据，全面评估模型在这项任务中性能的高低。此外，我们提出了一种方法，帮助研究人员探索特定场景下多模态语言大型模型性能与其在标准基准测试中的普遍能力之间的关联。实验结果表明，即使是最先进的模型也无法在自动GUI测试的所有子任务中表现出色，这突显了当前自动GUI测试能力和其实际应用之间的巨大差距。这一差距为GUI代理的未来发展方向提供了指导。我们的代码可以在以下地址获取：[此处提供URL链接]。', 'title_zh': 'GUI测试竞技场：促进自主GUI测试代理发展的统一基准'}
{'arxiv_id': 'arXiv:2412.18354', 'title': 'The Thousand Brains Project: A New Paradigm for Sensorimotor Intelligence', 'authors': 'Viviane Clay, Niels Leadholm, Jeff Hawkins', 'link': 'https://arxiv.org/abs/2412.18354', 'abstract': 'Artificial intelligence has advanced rapidly in the last decade, driven primarily by progress in the scale of deep-learning systems. Despite these advances, the creation of intelligent systems that can operate effectively in diverse, real-world environments remains a significant challenge. In this white paper, we outline the Thousand Brains Project, an ongoing research effort to develop an alternative, complementary form of AI, derived from the operating principles of the neocortex. We present an early version of a thousand-brains system, a sensorimotor agent that is uniquely suited to quickly learn a wide range of tasks and eventually implement any capabilities the human neocortex has. Core to its design is the use of a repeating computational unit, the learning module, modeled on the cortical columns found in mammalian brains. Each learning module operates as a semi-independent unit that can model entire objects, represents information through spatially structured reference frames, and both estimates and is able to effect movement in the world. Learning is a quick, associative process, similar to Hebbian learning in the brain, and leverages inductive biases around the spatial structure of the world to enable rapid and continual learning. Multiple learning modules can interact with one another both hierarchically and non-hierarchically via a "cortical messaging protocol" (CMP), creating more abstract representations and supporting multimodal integration. We outline the key principles motivating the design of thousand-brains systems and provide details about the implementation of Monty, our first instantiation of such a system. Code can be found at this https URL, along with more detailed documentation at this https URL.', 'abstract_zh': '在过去十年中，人工智能技术取得了快速进步，主要是由于深度学习系统的规模扩大所推动。尽管取得了这些进展，但在各种实际环境中的智能系统如何有效运行仍然是一个重大挑战。在这份白皮书中，我们概述了千脑计划，这是一个正在进行的研究项目，旨在开发一种替代且互补的形式的AI，该AI源于新皮层的运作原则。我们介绍了千脑系统的早期版本，这是一种传感器运动代理，特别适合快速学习广泛的任务，并最终实现人类新皮层所具备的所有能力。其核心设计原则是使用重复的计算单元，即学习模块，这一模块模仿哺乳动物大脑中的皮层柱。每个学习模块作为一个半独立的单元运作，能够模拟完整的物体，通过空间结构的参考框架来表示信息，并且能够估计和影响世界中的运动。学习过程是一个快速的关联过程，类似于大脑中的Hebbian学习，并利用世界空间结构的归纳偏见来实现快速且持续的学习。多个学习模块可以通过“皮层消息协议”（CMP）进行逐级和非逐级的交互，从而创建更抽象的表示并支持多模态整合。我们概述了驱动千脑系统设计的关键原则，并提供了关于Monty的首次实现的详细实施细节。代码可以在以下网址找到：这个网址，以及更详细的文档可以在以下网址找到：这个网址。', 'title_zh': '千脑计划：一种新的传感器imotor智能范式'}
{'arxiv_id': 'arXiv:2412.18293', 'title': 'MinsStudio: A Streamlined Package for Minecraft AI Agent Development', 'authors': 'Shaofei Cai, Zhancun Mu, Kaichen He, Bowei Zhang, Xinyue Zheng, Anji Liu, Yitao Liang', 'link': 'https://arxiv.org/abs/2412.18293', 'abstract': 'Minecraft has emerged as a valuable testbed for embodied intelligence and sequential decision-making research, yet the development and validation of novel agents remains hindered by significant engineering challenges. This paper presents MineStudio, an open-source software package designed to streamline embodied policy development in Minecraft. MineStudio represents the first comprehensive integration of seven critical engineering components: simulator, data, model, offline pretraining, online finetuning, inference, and benchmark, thereby allowing users to concentrate their efforts on algorithm innovation. We provide a user-friendly API design accompanied by comprehensive documentation and tutorials. The complete codebase is publicly available at this https URL.', 'abstract_zh': '《我的世界》（Minecraft）已成为开展具身智能和序列决策研究的宝贵实验平台，然而，新型智能体的开发与验证仍受制于重大的工程挑战。本文介绍了MineStudio，一个开源软件包，旨在简化《我的世界》中具身策略的开发过程。MineStudio 是第一个全面整合七个关键工程组件的平台：仿真器、数据、模型、离线预训练、在线微调、推理和基准测试，从而让用户能够将精力集中在算法创新上。我们提供了一个用户友好的 API 设计，并附有全面的文档和教程。完整的代码库可在以下网址公开访问：this https URL。', 'title_zh': 'MinsStudio：一种简化版的Minecraft AI代理开发包'}
{'arxiv_id': 'arXiv:2412.18161', 'title': 'VISION: A Modular AI Assistant for Natural Human-Instrument Interaction at Scientific User Facilities', 'authors': 'Shray Mathur, Noah van der Vleuten, Kevin Yager, Esther Tsai', 'link': 'https://arxiv.org/abs/2412.18161', 'abstract': 'Scientific user facilities, such as synchrotron beamlines, are equipped with a wide array of hardware and software tools that require a codebase for human-computer-interaction. This often necessitates developers to be involved to establish connection between users/researchers and the complex instrumentation. The advent of generative AI presents an opportunity to bridge this knowledge gap, enabling seamless communication and efficient experimental workflows. Here we present a modular architecture for the Virtual Scientific Companion (VISION) by assembling multiple AI-enabled cognitive blocks that each scaffolds large language models (LLMs) for a specialized task. With VISION, we performed LLM-based operation on the beamline workstation with low latency and demonstrated the first voice-controlled experiment at an X-ray scattering beamline. The modular and scalable architecture allows for easy adaptation to new instrument and capabilities. Development on natural language-based scientific experimentation is a building block for an impending future where a science exocortex -- a synthetic extension to the cognition of scientists -- may radically transform scientific practice and discovery.', 'abstract_zh': '科学用户设施，如同步加速器光束线，配备了广泛的硬件和软件工具，需要一套用于人机交互的代码库。这通常需要开发人员参与，以建立用户/研究人员与复杂仪器之间的连接。生成式人工智能的出现为弥合这一知识差距提供了机会，使沟通更加顺畅并提高实验流程的效率。在此，我们通过组装多个AI赋能的认知模块来构建多模块架构的虚拟科学伴侣（VISION），这些模块分别专门配置大型语言模型（LLMs）以执行特定任务。借助VISION，我们在光束线工作站上实现了基于LLM的操作，并首次在X射线散射光束线上展示了语音控制的实验。这种模块化和可扩展的架构允许轻松适应新的仪器和功能。基于自然语言的科学实验开发是构建未来科学外皮（科学认知的合成扩展）的关键组成部分，它可能彻底改变科学研究和发现的方式。', 'title_zh': 'VISION：一种适用于科学用户设施的模块化人工智能助手，实现自然的人机乐器交互'}
{'arxiv_id': 'arXiv:2412.18116', 'title': 'AutoDroid-V2: Boosting SLM-based GUI Agents via Code Generation', 'authors': 'Hao Wen, Shizuo Tian, Borislav Pavlov, Wenjie Du, Yixuan Li, Ge Chang, Shanhui Zhao, Jiacheng Liu, Yunxin Liu, Ya-Qin Zhang, Yuanchun Li', 'link': 'https://arxiv.org/abs/2412.18116', 'abstract': "Large language models (LLMs) have brought exciting new advances to mobile UI agents, a long-standing research field that aims to complete arbitrary natural language tasks through mobile UI interactions. However, existing UI agents usually demand high reasoning capabilities of powerful large models that are difficult to be deployed locally on end-users' devices, which raises huge concerns about user privacy and centralized serving cost. One way to reduce the required model size is to customize a smaller domain-specific model with high-quality training data, e.g. large-scale human demonstrations of diverse types of apps and tasks, while such datasets are extremely difficult to obtain. Inspired by the remarkable coding abilities of recent small language models (SLMs), we propose to convert the UI task automation problem to a code generation problem, which can be effectively solved by an on-device SLM and efficiently executed with an on-device code interpreter. Unlike normal coding tasks that can be extensively pretrained with public datasets, generating UI automation code is challenging due to the diversity, complexity, and variability of target apps. Therefore, we adopt a document-centered approach that automatically builds fine-grained API documentation for each app and generates diverse task samples based on this documentation. By guiding the agent with the synthetic documents and task samples, it learns to generate precise and efficient scripts to complete unseen tasks. Based on detailed comparisons with state-of-the-art mobile UI agents, our approach effectively improves the mobile task automation with significantly higher success rates and lower latency/token consumption. Code will be open-sourced.", 'abstract_zh': '大型语言模型（LLMs）为移动UI代理领域带来了令人兴奋的新进展。移动UI代理是一个长期研究的领域，旨在通过移动UI交互完成任意自然语言任务。然而，现有的UI代理通常需要高性能的大型模型来进行复杂的推理，这使得这些模型难以在终端用户设备上本地部署，引发了用户隐私和集中化服务成本的巨大关注。一种减少所需模型大小的方法是利用高质量的训练数据定制一个较小的领域特定模型，例如大规模的人类示范涵盖多种类型的应用和任务，但获取这样的数据集极其困难。受近期小型语言模型（SLMs）卓越编码能力的启发，我们提出将UI任务自动化问题转化为代码生成问题，该问题可以通过设备上的SLM有效解决，并通过设备上的代码解释器高效执行。与可以广泛使用公开数据集进行预训练的常规编程任务不同，生成UI自动化代码具有挑战性，因为目标应用的多样性、复杂性和多变性使其具有挑战性。因此，我们采用以文档为中心的方法，自动为每个应用构建细粒度的API文档，并基于这些文档生成多样化的任务样本。通过指导代理使用合成文档和任务样本，使其学习生成精确且高效的脚本以完成未见过的任务。基于与最先进的移动UI代理的详细比较，我们的方法在显著提高移动任务自动化的同时，成功率达到更高，延迟和token消耗更低。我们将开源代码。', 'title_zh': 'AutoDroid-V2: 基于生成代码提升SLM方法的GUI代理性能'}
{'arxiv_id': 'arXiv:2412.18096', 'title': 'Real-world Deployment and Evaluation of PErioperative AI CHatbot (PEACH) -- a Large Language Model Chatbot for Perioperative Medicine', 'authors': 'Yu He Ke, Liyuan Jin, Kabilan Elangovan, Bryan Wen Xi Ong, Chin Yang Oh, Jacqueline Sim, Kenny Wei-Tsen Loh, Chai Rick Soh, Jonathan Ming Hua Cheng, Aaron Kwang Yang Lee, Daniel Shu Wei Ting, Nan Liu, Hairil Rizal Abdullah', 'link': 'https://arxiv.org/abs/2412.18096', 'abstract': 'Large Language Models (LLMs) are emerging as powerful tools in healthcare, particularly for complex, domain-specific tasks. This study describes the development and evaluation of the PErioperative AI CHatbot (PEACH), a secure LLM-based system integrated with local perioperative guidelines to support preoperative clinical decision-making. PEACH was embedded with 35 institutional perioperative protocols in the secure Claude 3.5 Sonet LLM framework within Pair Chat (developed by Singapore Government) and tested in a silent deployment with real-world data. Accuracy, safety, and usability were assessed. Deviations and hallucinations were categorized based on potential harm, and user feedback was evaluated using the Technology Acceptance Model (TAM). Updates were made after the initial silent deployment to amend one protocol.\nIn 240 real-world clinical iterations, PEACH achieved a first-generation accuracy of 97.5% (78/80) and an overall accuracy of 96.7% (232/240) across three iterations. The updated PEACH demonstrated improved accuracy of 97.9% (235/240), with a statistically significant difference from the null hypothesis of 95% accuracy (p = 0.018, 95% CI: 0.952-0.991). Minimal hallucinations and deviations were observed (both 1/240 and 2/240, respectively). Clinicians reported that PEACH expedited decisions in 95% of cases, and inter-rater reliability ranged from kappa 0.772-0.893 within PEACH and 0.610-0.784 among attendings.\nPEACH is an accurate, adaptable tool that enhances consistency and efficiency in perioperative decision-making. Future research should explore its scalability across specialties and its impact on clinical outcomes.', 'abstract_zh': '大型语言模型（LLMs）正逐渐成为医疗领域中强有力的工具，尤其是在处理复杂且领域特定的任务时。本研究描述了PErioperative AI CHatbot（PEACH）系统的发展与评价，PEACH是一种集成了本地围手术期指南的安全LLM系统，旨在支持术前临床决策。PEACH系统在安全的Claude 3.5 Sonet LLM框架（由新加坡政府开发的Pair Chat中的一个集成部分）内嵌入了35家机构的围手术期协议，并在真实数据环境下进行了静默部署测试。评估了其准确度、安全性与可用性。根据潜在的危害性，对偏离和幻觉进行了分类，并通过技术接受模型（TAM）评估了用户反馈。在首次静默部署后，对协议进行了更新。\n\n在240次真实临床迭代中，PEACH的一代准确率为97.5%（78/80），整体准确率为96.7%（232/240）。更新后的PEACH准确率为97.9%（235/240），显著优于95%的零假设（p = 0.018，95% CI：0.952-0.991）。观察到的幻觉和偏差最少（分别为1/240和2/240）。临床医生报告，在95%的情况下，PEACH加速了决策过程，PEACH内部的临诊者者一致可靠性范围为κ值0.772-0.893，临诊者间的可靠性范围为0.610-0.784。\n\nPEACH是一种准确且适应性强的工具，能增强围手术期决策的一致性和效率。未来研究应探讨其在不同专科领域的扩展性和对临床结果的影响。', 'title_zh': '在临床 perioperative 医学中大规模语言模型聊天机器人 PErioperative AI CHatbot (PEACH) 的实际部署与评估'}
{'arxiv_id': 'arXiv:2412.17964', 'title': 'Dynamic Multi-Agent Orchestration and Retrieval for Multi-Source Question-Answer Systems using Large Language Models', 'authors': 'Antony Seabra, Claudio Cavalcante, Joao Nepomuceno, Lucas Lago, Nicolaas Ruberg, Sergio Lifschitz', 'link': 'https://arxiv.org/abs/2412.17964', 'abstract': "We propose a methodology that combines several advanced techniques in Large Language Model (LLM) retrieval to support the development of robust, multi-source question-answer systems. This methodology is designed to integrate information from diverse data sources, including unstructured documents (PDFs) and structured databases, through a coordinated multi-agent orchestration and dynamic retrieval approach. Our methodology leverages specialized agents-such as SQL agents, Retrieval-Augmented Generation (RAG) agents, and router agents - that dynamically select the most appropriate retrieval strategy based on the nature of each query. To further improve accuracy and contextual relevance, we employ dynamic prompt engineering, which adapts in real time to query-specific contexts. The methodology's effectiveness is demonstrated within the domain of Contract Management, where complex queries often require seamless interaction between unstructured and structured data. Our results indicate that this approach enhances response accuracy and relevance, offering a versatile and scalable framework for developing question-answer systems that can operate across various domains and data sources.", 'abstract_zh': '我们提出了一种方法论，该方法论结合了大型语言模型（LLM）检索领域的多项先进技术，以支持稳健的多源问答系统的发展。该方法论旨在通过协调多智能体编排和动态检索方式，整合来自多种数据源的信息，包括未结构化的文档（PDF）和结构化数据库。该方法论利用了专门的智能体——如SQL智能体、检索增强生成（RAG）智能体和路由智能体——这些智能体能够根据每个查询的性质动态选择最合适的检索策略。为进一步提高准确性和上下文相关性，我们采用了动态提示工程，这种技术能够实时适应查询特定的上下文。该方法论的有效性在合同管理领域得到验证，该领域中复杂的查询往往需要无缝地交互未结构化和结构化数据。我们的结果表明，这种方法提高了响应的准确性和相关性，提供了一个适用于多种领域和数据源的灵活且可扩展的框架，用于开发问答系统。', 'title_zh': '使用大型语言模型的动态多Agent协同与检索以构建多源问答系统'}
{'arxiv_id': 'arXiv:2412.17942', 'title': 'Contrato360 2.0: A Document and Database-Driven Question-Answer System using Large Language Models and Agents', 'authors': 'Antony Seabra, Claudio Cavalcante, Joao Nepomuceno, Lucas Lago, Nicolaas Ruberg, Sergio Lifschitz', 'link': 'https://arxiv.org/abs/2412.17942', 'abstract': 'We present a question-and-answer (Q\\&A) application designed to support the contract management process by leveraging combined information from contract documents (PDFs) and data retrieved from contract management systems (database). This data is processed by a large language model (LLM) to provide precise and relevant answers. The accuracy of these responses is further enhanced through the use of Retrieval-Augmented Generation (RAG), text-to-SQL techniques, and agents that dynamically orchestrate the workflow. These techniques eliminate the need to retrain the language model. Additionally, we employed Prompt Engineering to fine-tune the focus of responses. Our findings demonstrate that this multi-agent orchestration and combination of techniques significantly improve the relevance and accuracy of the answers, offering a promising direction for future information systems.', 'abstract_zh': '我们提出了一种问答（Q&A）应用，该应用通过结合合同文件（PDF）和从合同管理系统（数据库）中检索的数据来支持合同管理流程。这些数据经过大规模语言模型（LLM）处理，提供精准且相关的答案。通过使用检索增强生成（RAG）、文本到SQL技术以及能够动态协调工作流的代理，这些方法进一步提高了答案的准确性。这些技术消除了重新训练语言模型的需要。此外，我们采用了提示工程（Prompt Engineering）来细化答案的焦点。我们的研究发现，这种多代理协调及技术组合显著提高了答案的相关性和准确性，为未来信息系统的发展提供了有前景的方向。', 'title_zh': 'Contrato360 2.0：一种基于文档和数据库的大语言模型及智能体驱动的问答系统'}
{'arxiv_id': 'arXiv:2412.18601', 'title': 'Decentralized Intelligence in GameFi: Embodied AI Agents and the Convergence of DeFi and Virtual Ecosystems', 'authors': 'Fernando Jia, Jade Zheng, Florence Li', 'link': 'https://arxiv.org/abs/2412.18601', 'abstract': "In the rapidly evolving landscape of GameFi, a fusion of gaming and decentralized finance (DeFi), there exists a critical need to enhance player engagement and economic interaction within gaming ecosystems. Our GameFi ecosystem aims to fundamentally transform this landscape by integrating advanced embodied AI agents into GameFi platforms. These AI agents, developed using cutting-edge large language models (LLMs), such as GPT-4 and Claude AI, are capable of proactive, adaptive, and contextually rich interactions with players. By going beyond traditional scripted responses, these agents become integral participants in the game's narrative and economic systems, directly influencing player strategies and in-game economies. We address the limitations of current GameFi platforms, which often lack immersive AI interactions and mechanisms for community engagement or creator monetization. Through the deep integration of AI agents with blockchain technology, we establish a consensus-driven, decentralized GameFi ecosystem. This ecosystem empowers creators to monetize their contributions and fosters democratic collaboration among players and creators. Furthermore, by embedding DeFi mechanisms into the gaming experience, we enhance economic participation and provide new opportunities for financial interactions within the game. Our approach enhances player immersion and retention and advances the GameFi ecosystem by bridging traditional gaming with Web3 technologies. By integrating sophisticated AI and DeFi elements, we contribute to the development of more engaging, economically robust, and community-centric gaming environments. This project represents a significant advancement in the state-of-the-art in GameFi, offering insights and methodologies that can be applied throughout the gaming industry.", 'abstract_zh': '在快速发展的GameFi（将游戏和去中心化金融DeFi相结合）领域，迫切需要提升玩家参与度和经济互动。我们的GameFi生态系统旨在通过将先进的具身人工智能代理整合到GameFi平台中，从根本上改变这一领域。这些基于前沿大型语言模型（LLMs）如GPT-4和Claude AI开发的人工智能代理，能够在玩家之间实现主动、适应性强且情景丰富的互动。通过超越传统的预编程响应，这些代理将成为游戏叙事和经济系统的积极参与者，直接影响玩家策略和游戏内经济。\n\n我们解决了当前GameFi平台普遍存在的问题，这些平台往往缺乏沉浸式的人工智能互动和社区参与或创作者变现的机制。通过深度整合人工智能代理与区块链技术，我们建立了一个共识驱动的、去中心化的GameFi生态系统。该生态系统赋予创作者变现其贡献的机会，并促进玩家和创作者之间的民主合作。此外，通过将DeFi机制嵌入游戏体验中，我们增强了经济参与并为游戏中的金融互动提供了新的机会。通过整合先进的人工智能和DeFi元素，我们的方法提升了玩家的沉浸感和留存率，并通过传统游戏和Web3技术的结合，推动了GameFi生态系统的进步。该项目在GameFi前沿技术方面实现了重要突破，提供了可用于整个游戏行业的见解和方法论。\n\n总之，我们的研究和创新为更加吸引人、经济上更稳健且更具社区导向的游戏环境做出了贡献。该项目代表了GameFi领域的重大进展，提供了可应用于整个游戏行业的洞见和方法。', 'title_zh': 'GameFi中去中心化智能：具身人工智能代理及DeFi与虚拟生态系统融合'}
{'arxiv_id': 'arXiv:2412.18588', 'title': 'A Paragraph is All It Takes: Rich Robot Behaviors from Interacting, Trusted LLMs', 'authors': 'OpenMind, Shaohong Zhong, Adam Zhou, Boyuan Chen, Homin Luo, Jan Liphardt', 'link': 'https://arxiv.org/abs/2412.18588', 'abstract': "Large Language Models (LLMs) are compact representations of all public knowledge of our physical environment and animal and human behaviors. The application of LLMs to robotics may offer a path to highly capable robots that perform well across most human tasks with limited or even zero tuning. Aside from increasingly sophisticated reasoning and task planning, networks of (suitably designed) LLMs offer ease of upgrading capabilities and allow humans to directly observe the robot's thinking. Here we explore the advantages, limitations, and particularities of using LLMs to control physical robots. The basic system consists of four LLMs communicating via a human language data bus implemented via web sockets and ROS2 message passing. Surprisingly, rich robot behaviors and good performance across different tasks could be achieved despite the robot's data fusion cycle running at only 1Hz and the central data bus running at the extremely limited rates of the human brain, of around 40 bits/s. The use of natural language for inter-LLM communication allowed the robot's reasoning and decision making to be directly observed by humans and made it trivial to bias the system's behavior with sets of rules written in plain English. These rules were immutably written into Ethereum, a global, public, and censorship resistant Turing-complete computer. We suggest that by using natural language as the data bus among interacting AIs, and immutable public ledgers to store behavior constraints, it is possible to build robots that combine unexpectedly rich performance, upgradability, and durable alignment with humans.", 'abstract_zh': '大规模语言模型（LLMs）是所有关于我们物理环境以及动物和人类行为的公开知识的紧凑表示。将LLMs应用于机器人技术可能会提供一条途径，即构建出能够在大多数人类任务上表现优异的机器人，而无需或只需最少的微调。除了不断增强的推理和任务规划能力外，适配设计的LLM网络还提供了升级能力的简便性，并允许人类直接观察机器人的思考过程。本文探讨了使用LLMs控制物理机器人的优势、限制和独特之处。基本系统由四个LLM通过WebSocket和ROS2消息传递实现的人类语言数据总线进行通信。令人惊讶的是，尽管机器人数据融合循环的运行频率仅为1Hz，且中心数据总线的运行速率受限于类似人类大脑的极低速率（约40比特/秒），但仍然能够实现丰富的机器人行为和在不同任务中的良好表现。利用自然语言促进LLM之间的通信，使得人类可以直接观察机器人的推理和决策过程，并且使用简单的英语书写规则即可轻松偏移系统的行为。这些规则被不可变更地写入了以太坊这样一个全球性、公众性和抗审查的图灵完备计算机中。我们认为，通过在交互AI之间使用自然语言作为数据总线，并将行为约束存储在不可变的公共账本中，有可能构建出兼具惊人性能、易于升级以及持久与人类一致性的机器人。', 'title_zh': '仅需一段文本：来自相互信任的大型语言模型丰富机器人行为'}
{'arxiv_id': 'arXiv:2412.18431', 'title': 'GeAR: Graph-enhanced Agent for Retrieval-augmented Generation', 'authors': 'Zhili Shen, Chenxin Diao, Pavlos Vougiouklis, Pascual Merita, Shriram Piramanayagam, Damien Graux, Dandan Tu, Zeren Jiang, Ruofei Lai, Yang Ren, Jeff Z. Pan', 'link': 'https://arxiv.org/abs/2412.18431', 'abstract': "Retrieval-augmented generation systems rely on effective document retrieval capabilities. By design, conventional sparse or dense retrievers face challenges in multi-hop retrieval scenarios. In this paper, we present GeAR, which advances RAG performance through two key innovations: (i) graph expansion, which enhances any conventional base retriever, such as BM25, and (ii) an agent framework that incorporates graph expansion. Our evaluation demonstrates GeAR's superior retrieval performance on three multi-hop question answering datasets. Additionally, our system achieves state-of-the-art results with improvements exceeding 10% on the challenging MuSiQue dataset, while requiring fewer tokens and iterations compared to other multi-step retrieval systems.", 'abstract_zh': '检索增强生成系统依赖于有效的文档检索能力。从设计上看，传统的稀疏或密集检索器在多跳检索场景中面临挑战。本文中，我们提出了一种名为GeAR的新系统，通过两项关键创新来提升RAG（Retrieval-Augmented Generation）的效果：（i）图扩展技术，可以增强任何传统的基线检索器，如BM25；（ii）包含图扩展技术的代理框架。我们的评估结果显示，GeAR在三个多跳问答数据集上表现出优越的检索性能。此外，我们的系统在具有挑战性的MuSiQue数据集上达到了最先进的性能，改进幅度超过10%，所需的token数量和迭代次数也更少，优于其他多步检索系统。', 'title_zh': 'GeAR：图增强代理用于检索增强生成'}
{'arxiv_id': 'arXiv:2412.18351', 'title': 'Multi-Agents Based on Large Language Models for Knowledge-based Visual Question Answering', 'authors': 'Zhongjian Hu, Peng Yang, Bing Li, Zhenqi Wang', 'link': 'https://arxiv.org/abs/2412.18351', 'abstract': 'Large Language Models (LLMs) have achieved impressive results in knowledge-based Visual Question Answering (VQA). However existing methods still have challenges: the inability to use external tools autonomously, and the inability to work in teams. Humans tend to know whether they need to use external tools when they encounter a new question, e.g., they tend to be able to give a direct answer to a familiar question, whereas they tend to use tools such as search engines when they encounter an unfamiliar question. In addition, humans also tend to collaborate and discuss with others to get better answers. Inspired by this, we propose the multi-agent voting framework. We design three LLM-based agents that simulate different levels of staff in a team, and assign the available tools according to the levels. Each agent provides the corresponding answer, and finally all the answers provided by the agents are voted to get the final answer. Experiments on OK-VQA and A-OKVQA show that our approach outperforms other baselines by 2.2 and 1.0, respectively.', 'abstract_zh': '大型语言模型（LLMs）在基于知识的视觉问答（VQA）任务上取得了显著成果。然而，现有方法仍然存在一些挑战：无法自主使用外部工具，以及无法协同工作。人类在遇到新的问题时往往能够判断是否需要使用外部工具，例如，他们通常能够直接回答熟悉的问题，而在面对不熟悉的问题时则倾向于使用搜索引擎等工具。此外，人类还倾向于与他人合作和讨论以获得更好的答案。受此启发，我们提出了多智能体投票框架。我们设计了三种基于LLM的智能体，模拟团队中不同级别的员工，并根据级别分配可用工具。每个智能体提供相应的答案，最终通过投票汇总所有智能体提供的答案以得到最终答案。在OK-VQA和A-OKVQA数据集上的实验表明，我们的方法分别比其他基线方法提高了2.2和1.0的性能。', 'title_zh': '基于大型语言模型的多agents知识驱动视觉问答系统'}
{'arxiv_id': 'arXiv:2412.18194', 'title': 'VLABench: A Large-Scale Benchmark for Language-Conditioned Robotics Manipulation with Long-Horizon Reasoning Tasks', 'authors': 'Shiduo Zhang, Zhe Xu, Peiju Liu, Xiaopeng Yu, Yuan Li, Qinghui Gao, Zhaoye Fei, Zhangyue Yin, Zuxuan Wu, Yu-Gang Jiang, Xipeng Qiu', 'link': 'https://arxiv.org/abs/2412.18194', 'abstract': "General-purposed embodied agents are designed to understand the users' natural instructions or intentions and act precisely to complete universal tasks. Recently, methods based on foundation models especially Vision-Language-Action models (VLAs) have shown a substantial potential to solve language-conditioned manipulation (LCM) tasks well. However, existing benchmarks do not adequately meet the needs of VLAs and relative algorithms. To better define such general-purpose tasks in the context of LLMs and advance the research in VLAs, we present VLABench, an open-source benchmark for evaluating universal LCM task learning. VLABench provides 100 carefully designed categories of tasks, with strong randomization in each category of task and a total of 2000+ objects. VLABench stands out from previous benchmarks in four key aspects: 1) tasks requiring world knowledge and common sense transfer, 2) natural language instructions with implicit human intentions rather than templates, 3) long-horizon tasks demanding multi-step reasoning, and 4) evaluation of both action policies and language model capabilities. The benchmark assesses multiple competencies including understanding of mesh\\&texture, spatial relationship, semantic instruction, physical laws, knowledge transfer and reasoning, etc. To support the downstream finetuning, we provide high-quality training data collected via an automated framework incorporating heuristic skills and prior information. The experimental results indicate that both the current state-of-the-art pretrained VLAs and the workflow based on VLMs face challenges in our tasks.", 'abstract_zh': '通用型具身代理旨在理解用户的自然指令或意图，并精确行动以完成通用任务。最近，基于基础模型的方法，尤其是视觉-语言-行动模型（VLAs），在解决语言条件下的操作任务（LCM）方面显示出巨大的潜力。然而，现有的基准并未充分满足VLAs及其相关算法的需求。为了更好地定义此类通用任务，并推动VLAs的研究，我们提出了VLABench，这是一个开源基准，用于评估通用LCM任务学习。VLABench提供了100个精心设计的任务类别，每个类别中包含强大的随机化因素，并且共有2000多个物体。相比于之前的基准，VLABench在四个关键方面脱颖而出：1）需要世界知识和常识转换的任务；2）具有隐含人类意图的自然语言指令，而非模板；3）长时序任务，需要多步推理；4）同时评估行动策略和语言模型能力。该基准评估了多种能力，包括网格与纹理理解、空间关系、语义指令、物理定律、知识转移与推理等。为了支持下游微调，我们提供了高质量的训练数据，通过包含启发式技能和先验信息的自动化框架进行收集。实验结果表明，当前最先进的预训练VLAs和基于VLM的流程在我们的任务中都面临着挑战。', 'title_zh': 'VLABench：一种用于基于语言条件的机器人Manipulation任务的大型基准测试，包含长期 horizon 原因推理任务'}
{'arxiv_id': 'arXiv:2412.18174', 'title': 'INVESTORBENCH: A Benchmark for Financial Decision-Making Tasks with LLM-based Agent', 'authors': 'Haohang Li, Yupeng Cao, Yangyang Yu, Shashidhar Reddy Javaji, Zhiyang Deng, Yueru He, Yuechen Jiang, Zining Zhu, Koduvayur Subbalakshmi, Guojun Xiong, Jimin Huang, Lingfei Qian, Xueqing Peng, Qianqian Xie, Jordan W. Suchow', 'link': 'https://arxiv.org/abs/2412.18174', 'abstract': "Recent advancements have underscored the potential of large language model (LLM)-based agents in financial decision-making. Despite this progress, the field currently encounters two main challenges: (1) the lack of a comprehensive LLM agent framework adaptable to a variety of financial tasks, and (2) the absence of standardized benchmarks and consistent datasets for assessing agent performance. To tackle these issues, we introduce \\textsc{InvestorBench}, the first benchmark specifically designed for evaluating LLM-based agents in diverse financial decision-making contexts. InvestorBench enhances the versatility of LLM-enabled agents by providing a comprehensive suite of tasks applicable to different financial products, including single equities like stocks, cryptocurrencies and exchange-traded funds (ETFs). Additionally, we assess the reasoning and decision-making capabilities of our agent framework using thirteen different LLMs as backbone models, across various market environments and tasks. Furthermore, we have curated a diverse collection of open-source, multi-modal datasets and developed a comprehensive suite of environments for financial decision-making. This establishes a highly accessible platform for evaluating financial agents' performance across various scenarios.", 'abstract_zh': '近年来，大型语言模型（LLM）代理在财务决策中的潜力得到了强调。尽管取得了这些进展，该领域目前仍面临两个主要挑战：（1）缺乏一个适应各种财务任务的全面LLM代理框架，以及（2）缺乏标准化的基准测试和一致的数据集来评估代理性能。为应对这些问题，我们介绍了InvestorBench，这是第一个专门用于评估在不同财务决策情境下LLM代理的基准测试框架。InvestorBench通过提供适用于不同类型金融产品的综合任务套件，增强了LLM启用代理的灵活性，包括单一股票、加密货币和交易型开放式指数基金（ETFs）等单一证券产品。\n\n此外，我们使用来自不同市场的十三种不同的LLM作为骨干模型，评估我们的代理框架在各种市场环境和任务中的推理和决策能力。我们还精选了多种开源多模态数据集，并开发了一整套用于财务决策的环境，从而建立了一个高度可访问的平台用于评估不同情境下金融代理的性能。', 'title_zh': '投资商衡：基于LLM的代理金融决策任务基准测试'}
{'arxiv_id': 'arXiv:2412.18100', 'title': 'EvoPat: A Multi-LLM-based Patents Summarization and Analysis Agent', 'authors': 'Suyuan Wang, Xueqian Yin, Menghao Wang, Ruofeng Guo, Kai Nan', 'link': 'https://arxiv.org/abs/2412.18100', 'abstract': 'The rapid growth of scientific techniques and knowledge is reflected in the exponential increase in new patents filed annually. While these patents drive innovation, they also present significant burden for researchers and engineers, especially newcomers. To avoid the tedious work of navigating a vast and complex landscape to identify trends and breakthroughs, researchers urgently need efficient tools to summarize, evaluate, and contextualize patents, revealing their innovative contributions and underlying scientific this http URL address this need, we present EvoPat, a multi-LLM-based patent agent designed to assist users in analyzing patents through Retrieval-Augmented Generation (RAG) and advanced search strategies. EvoPat leverages multiple Large Language Models (LLMs), each performing specialized roles such as planning, identifying innovations, and conducting comparative evaluations. The system integrates data from local databases, including patents, literature, product catalogous, and company repositories, and online searches to provide up-to-date insights. The ability to collect information not included in original database automatically is also implemented. Through extensive testing in the natural language processing (NLP) domain, we demonstrate that EvoPat outperforms GPT-4 in tasks such as patent summarization, comparative analysis, and technical evaluation. EvoPat represents a significant step toward creating AI-powered tools that empower researchers and engineers to efficiently navigate the complexities of the patent landscape.', 'abstract_zh': '随着科学技术和知识的迅速发展，每年新提交的专利数量呈指数级增长。虽然这些专利推动了创新，但也给研究人员和工程师，尤其是新入行者带来了巨大负担。为了避免在广阔的复杂领域中寻找趋势和突破时进行繁琐的工作，研究人员迫切需要高效的工具来总结、评估和上下文化专利，揭示其创新贡献和背后的科学原理。为了解决这一需求，我们提出了EvoPat，这是一种基于多大语言模型（LLMs）的专利代理，旨在通过检索增强生成（RAG）和高级搜索策略帮助用户分析专利。EvoPat利用多个大型语言模型，每个模型承担特定的角色，如计划、识别创新和进行比较评估。该系统整合了本地数据库中的数据，包括专利、文献、产品目录和公司仓库，以及在线搜索，以提供最新的洞见。还实现了自动收集未包含在原始数据库中的信息的能力。通过在自然语言处理（NLP）领域的广泛测试，我们证明EvoPat在专利总结、比较分析和技术评估等任务上优于GPT-4。EvoPat代表了朝着创建赋能研究人员和工程师高效导航专利landscape复杂性的AI工具迈出的重要一步。', 'title_zh': 'EvoPat：一种基于多大型语言模型的专利总结与分析代理'}
{'arxiv_id': 'arXiv:2412.18047', 'title': 'Uncertainty-Aware Critic Augmentation for Hierarchical Multi-Agent EV Charging Control', 'authors': 'Lo Pang-Yun Ting, Ali Şenol, Huan-Yang Wang, Hsu-Chao Lai, Kun-Ta Chuang, Huan Liu', 'link': 'https://arxiv.org/abs/2412.18047', 'abstract': 'The advanced bidirectional EV charging and discharging technology, aimed at supporting grid stability and emergency operations, has driven a growing interest in workplace applications. It not only effectively reduces electricity expenses but also enhances the resilience of handling practical issues, such as peak power limitation, fluctuating energy prices, and unpredictable EV departures. However, existing EV charging strategies have yet to fully consider these factors in a way that benefits both office buildings and EV users simultaneously. To address these issues, we propose HUCA, a novel real-time charging control for regulating energy demands for both the building and electric vehicles. HUCA employs hierarchical actor-critic networks to dynamically reduce electricity costs in buildings, accounting for the needs of EV charging in the dynamic pricing scenario. To tackle the uncertain EV departures, a new critic augmentation is introduced to account for departure uncertainties in evaluating the charging decisions, while maintaining the robustness of the charging control. Experiments on real-world electricity datasets under both simulated certain and uncertain departure scenarios demonstrate that HUCA outperforms baselines in terms of total electricity costs while maintaining competitive performance in fulfilling EV charging requirements. A case study also manifests that HUCA effectively balances energy supply between the building and EVs based on real-time information.', 'abstract_zh': '面向支持电网稳定性和应急操作的高级双向电动汽车充放电技术，已在工作场所应用中引发了越来越大的兴趣。它不仅有效降低了电费，还增强了处理尖峰功率限制、波动的能源价格以及不可预测的电动汽车离场等问题的能力。然而，现有的电动汽车充电策略尚未全面考虑这些因素，以同时惠及办公楼和电动汽车用户。为解决这些问题，我们提出了HUCA，这是一种新颖的实时充电控制方法，用于调节建筑和电动汽车的能源需求。HUCA采用分层actor-critic网络，根据动态定价场景的需求动态减少建筑的电力成本。为了应对电动汽车离场的不确定性，引入了一种新的critic增强技术，以在评估充电决策时考虑离场不确定性，同时保持充电控制的稳健性。在具有模拟确定性和不确定性离场场景的实际电力数据集上的实验表明，与基线方法相比，HUCA在总体电力成本方面表现出更优的效果，同时在满足电动汽车充电需求方面维持了竞争力的表现。案例研究还表明，HUCA能够根据实时信息有效地在建筑和电动汽车之间平衡能源供应。', 'title_zh': '面向层次化多代理电动汽车充电控制的不确定性感知评论器增强方法'}
{'arxiv_id': 'arXiv:2412.18023', 'title': 'More than Chit-Chat: Developing Robots for Small-Talk Interactions', 'authors': 'Rebecca Ramnauth, Dražen Brščić, Brian Scassellati', 'link': 'https://arxiv.org/abs/2412.18023', 'abstract': "Beyond mere formality, small talk plays a pivotal role in social dynamics, serving as a verbal handshake for building rapport and understanding. For conversational AI and social robots, the ability to engage in small talk enhances their perceived sociability, leading to more comfortable and natural user interactions. In this study, we evaluate the capacity of current Large Language Models (LLMs) to drive the small talk of a social robot and identify key areas for improvement. We introduce a novel method that autonomously generates feedback and ensures LLM-generated responses align with small talk conventions. Through several evaluations -- involving chatbot interactions and human-robot interactions -- we demonstrate the system's effectiveness in guiding LLM-generated responses toward realistic, human-like, and natural small-talk exchanges.", 'abstract_zh': '超越 mere formality，闲聊在社会动态中扮演着至关重要的角色，它作为一种口头“握手”手段，有助于建立关系和增进理解。对于对话式人工智能和社交机器人而言，具备进行闲聊的能力能够提升其社会性，从而使用户交互更加舒适和自然。在这项研究中，我们评估了当前大型语言模型（LLMs）驱动社交机器人闲聊的能力，并确定了改进的关键领域。我们提出了一种新颖的方法，可以自主生成反馈并确保大型语言模型生成的回应符合闲聊的惯例。通过几次评估——包括聊天机器人交互和人机交互——我们展示了该系统引导大型语言模型生成的回应向现实、人性化的自然闲聊交流方向发展的效果。', 'title_zh': '不仅仅是闲聊：开发用于小型对话的机器人'}
{'arxiv_id': 'arXiv:2412.17993', 'title': 'Multi-Agent Path Finding in Continuous Spaces with Projected Diffusion Models', 'authors': 'Jinhao Liang, Jacob K. Christopher, Sven Koenig, Ferdinando Fioretto', 'link': 'https://arxiv.org/abs/2412.17993', 'abstract': 'Multi-Agent Path Finding (MAPF) is a fundamental problem in robotics, requiring the computation of collision-free paths for multiple agents moving from their respective start to goal positions. Coordinating multiple agents in a shared environment poses significant challenges, especially in continuous spaces where traditional optimization algorithms struggle with scalability. Moreover, these algorithms often depend on discretized representations of the environment, which can be impractical in image-based or high-dimensional settings. Recently, diffusion models have shown promise in single-agent path planning, capturing complex trajectory distributions and generating smooth paths that navigate continuous, high-dimensional spaces. However, directly extending diffusion models to MAPF introduces new challenges since these models struggle to ensure constraint feasibility, such as inter-agent collision avoidance. To overcome this limitation, this work proposes a novel approach that integrates constrained optimization with diffusion models for MAPF in continuous spaces. This unique combination directly produces feasible multi-agent trajectories that respect collision avoidance and kinematic constraints. The effectiveness of our approach is demonstrated across various challenging simulated scenarios of varying dimensionality.', 'abstract_zh': '多智能体路径规划（Multi-Agent Path Finding, MAPF）是机器人技术中的一个基本问题，要求为多个从各自的起点到终点移动的智能体计算无碰撞路径。在共享环境中协调多个智能体特别是在连续空间中提出了重大挑战，传统优化算法在可扩展性方面尤为棘手。此外，这些算法往往依赖于对环境的离散化表示，这在基于图像或高维设置中可能不切实际。最近，扩散模型在单智能体路径规划中显示出潜力，能够捕捉复杂轨迹分布并生成流畅路径，以导航连续的高维空间。然而，直接将扩散模型扩展到MAPF引入了新的挑战，因为这些模型难以确保满足约束条件，例如智能体间的碰撞避免。为克服这一点，本文提出了一种新的方法，将约束优化与扩散模型结合用于连续空间中的MAPF。这种独特的组合直接产生了满足碰撞避免和动力学约束的可行多智能体轨迹。通过在不同维度的多种具有挑战性的仿真场景中进行验证，展示了我们方法的有效性。', 'title_zh': '连续空间中基于投影扩散模型的多代理路径规划'}
{'arxiv_id': 'arXiv:2412.17867', 'title': 'Evaluating and Enhancing LLMs for Multi-turn Text-to-SQL with Multiple Question Types', 'authors': 'Ziming Guo, Chao Ma, Yinggang Sun, Tiancheng Zhao, Guangyao Wang, Hai Huang', 'link': 'https://arxiv.org/abs/2412.17867', 'abstract': "Recent advancements in large language models (LLMs) have significantly advanced text-to-SQL systems. However, most LLM-based methods often narrowly focus on SQL generation, neglecting the complexities of real-world conversational queries. This oversight can lead to unreliable responses, particularly for ambiguous questions that cannot be directly addressed with SQL. To bridge this gap, we propose MMSQL, a comprehensive test suite designed to evaluate the question classification and SQL generation capabilities of LLMs by simulating real-world scenarios with diverse question types and multi-turn Q\\&A interactions. Using MMSQL, we assessed the performance of popular LLMs, including both open-source and closed-source models, and identified key factors impacting their performance in such scenarios. Moreover, we introduce an LLM-based multi-agent framework that employs specialized agents to identify question types and determine appropriate answering strategies. Our experiments demonstrate that this approach significantly enhances the model's ability to navigate the complexities of conversational dynamics, effectively handling the diverse and complex nature of user queries.", 'abstract_zh': '近年来，大型语言模型（LLMs）的最新进展显著提升了文本到SQL系统的能力。然而，大多数基于LLM的方法往往狭隘地集中在SQL生成上，忽视了现实世界对话查询的复杂性。这种忽视可能导致不稳定的响应，尤其是对于那些不能直接用SQL解决的模糊问题。为了弥合这一差距，我们提出了MMSQL，这是一个全面的测试套件，通过模拟各种问题类型和多轮对话交互的现实场景，评估LLMs的问题分类和SQL生成能力。使用MMSQL，我们评估了包括开源和闭源在内的流行LLM模型的性能，并确定了影响它们在这类场景中表现的关键因素。此外，我们介绍了一种基于LLM的多智能体框架，该框架采用专门的智能体来识别问题类型并确定合适的回答策略。我们的实验表明，这种做法显著增强了模型导航对话动态复杂性的能力，有效地应对了用户的多样性和复杂查询。', 'title_zh': '评估和增强多轮文本到SQL转换的LLM模型，支持多种问题类型'}
{'arxiv_id': 'arXiv:2412.17838', 'title': 'Coordinated Power Smoothing Control for Wind Storage Integrated System with Physics-informed Deep Reinforcement Learning', 'authors': 'Shuyi Wang, Huan Zhao, Yuji Cao, Zibin Pan, Guolong Liu, Gaoqi Liang, Junhua Zhao', 'link': 'https://arxiv.org/abs/2412.17838', 'abstract': 'The Wind Storage Integrated System with Power Smoothing Control (PSC) has emerged as a promising solution to ensure both efficient and reliable wind energy generation. However, existing PSC strategies overlook the intricate interplay and distinct control frequencies between batteries and wind turbines, and lack consideration of wake effect and battery degradation cost. In this paper, a novel coordinated control framework with hierarchical levels is devised to address these challenges effectively, which integrates the wake model and battery degradation model. In addition, after reformulating the problem as a Markov decision process, the multi-agent reinforcement learning method is introduced to overcome the bi-level characteristic of the problem. Moreover, a Physics-informed Neural Network-assisted Multi-agent Deep Deterministic Policy Gradient (PAMA-DDPG) algorithm is proposed to incorporate the power fluctuation differential equation and expedite the learning process. The effectiveness of the proposed methodology is evaluated through simulations conducted in four distinct scenarios using WindFarmSimulator (WFSim). The results demonstrate that the proposed algorithm facilitates approximately an 11% increase in total profit and a 19% decrease in power fluctuation compared to the traditional methods, thereby addressing the dual objectives of economic efficiency and grid-connected energy reliability.', 'abstract_zh': '具有功率平滑控制（PSC）的风能存储集成系统已成为确保风能高效可靠生成的有前途的解决方案。然而，现有的PSC策略没有充分考虑电池和风力涡轮机之间复杂交互和不同的控制频率，也没有考虑到来流效应和电池退化成本。在这篇文章中，我们设计了一个具有层次结构的新型协调控制框架来有效解决这些挑战，该框架整合了来流模型和电池退化模型。此外，在将问题重新表述为马尔可夫决策过程后，我们引入了多智能体增强学习方法，以克服该问题的双层特性。同时，我们提出了一个基于物理信息神经网络的多智能体深度确定性策略梯度算法（PAMA-DDPG），以整合功率波动微分方程并加快学习过程。通过在WindFarmSimulator (WFSim)中进行四种不同场景的仿真评估，我们验证了提出方法的有效性。结果表明，所提出的算法相较于传统方法，能够实现总利润提高约11%和功率波动减少约19%，从而同时实现经济效率和并网能源可靠性双重目标。', 'title_zh': '基于物理信息深度强化学习的风储联合系统协同功率平滑控制'}
{'arxiv_id': 'arXiv:2412.16984', 'title': 'LLM-Powered User Simulator for Recommender System', 'authors': 'Zijian Zhang, Shuchang Liu, Ziru Liu, Rui Zhong, Qingpeng Cai, Xiangyu Zhao, Chunxu Zhang, Qidong Liu, Peng Jiang', 'link': 'https://arxiv.org/abs/2412.16984', 'abstract': "User simulators can rapidly generate a large volume of timely user behavior data, providing a testing platform for reinforcement learning-based recommender systems, thus accelerating their iteration and optimization. However, prevalent user simulators generally suffer from significant limitations, including the opacity of user preference modeling and the incapability of evaluating simulation accuracy. In this paper, we introduce an LLM-powered user simulator to simulate user engagement with items in an explicit manner, thereby enhancing the efficiency and effectiveness of reinforcement learning-based recommender systems training. Specifically, we identify the explicit logic of user preferences, leverage LLMs to analyze item characteristics and distill user sentiments, and design a logical model to imitate real human engagement. By integrating a statistical model, we further enhance the reliability of the simulation, proposing an ensemble model that synergizes logical and statistical insights for user interaction simulations. Capitalizing on the extensive knowledge and semantic generation capabilities of LLMs, our user simulator faithfully emulates user behaviors and preferences, yielding high-fidelity training data that enrich the training of recommendation algorithms. We establish quantifying and qualifying experiments on five datasets to validate the simulator's effectiveness and stability across various recommendation scenarios.", 'abstract_zh': '用户模拟器可以快速生成大量及时的用户行为数据，为基于强化学习的推荐系统提供测试平台，从而加速其迭代和优化。然而，目前广泛使用的用户模拟器通常存在显著的局限性，包括用户偏好建模的不透明性和评估模拟准确性的能力不足。在本文中，我们介绍了一个以LLM（大型语言模型）为驱动的用户模拟器，以显式方式模拟用户与项目之间的互动，从而提高基于强化学习的推荐系统训练的效率和有效性。具体来说，我们识别了用户偏好的显式逻辑，利用LLM分析项目特征和萃取用户情感，并设计了一个逻辑模型来模仿真实的人类互动。通过集成统计模型，我们进一步增强了模拟的可靠性，提出了一种结合逻辑和统计洞察的集成模型，用于用户互动模拟。借助LLM广泛的知识和语义生成能力，我们的用户模拟器能够忠实模拟用户行为和偏好，生成高保真度的训练数据，丰富推荐算法的训练。我们在五个数据集上建立了量化和定性的实验，以验证模拟器在各种推荐场景中的有效性和稳定性。', 'title_zh': 'LLM驱动的用户模拟器在推荐系统中的应用'}
