{'arxiv_id': 'arXiv:2502.02464', 'title': 'Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation', 'authors': 'Abdelrahman Abdallah, Jamshid Mozafari, Bhawna Piryani, Mohammed Ali, Adam Jatowt', 'link': 'https://arxiv.org/abs/2502.02464', 'abstract': 'Retrieval, re-ranking, and retrieval-augmented generation (RAG) are critical components of modern natural language processing (NLP) applications in information retrieval, question answering, and knowledge-based text generation. However, existing solutions are often fragmented, lacking a unified framework that easily integrates these essential processes. The absence of a standardized implementation, coupled with the complexity of retrieval and re-ranking workflows, makes it challenging for researchers to compare and evaluate different approaches in a consistent environment. While existing toolkits such as Rerankers and RankLLM provide general-purpose reranking pipelines, they often lack the flexibility required for fine-grained experimentation and benchmarking. In response to these challenges, we introduce \\textbf{Rankify}, a powerful and modular open-source toolkit designed to unify retrieval, re-ranking, and RAG within a cohesive framework. Rankify supports a wide range of retrieval techniques, including dense and sparse retrievers, while incorporating state-of-the-art re-ranking models to enhance retrieval quality. Additionally, Rankify includes a collection of pre-retrieved datasets to facilitate benchmarking, available at Huggingface (this https URL). To encourage adoption and ease of integration, we provide comprehensive documentation (this http URL), an open-source implementation on GitHub(this https URL), and a PyPI package for effortless installation(this https URL). By providing a unified and lightweight framework, Rankify allows researchers and practitioners to advance retrieval and re-ranking methodologies while ensuring consistency, scalability, and ease of use.', 'abstract_zh': '检索、重新排名和检索增强生成（RAG）是现代自然语言处理（NLP）应用中信息检索、问答和知识驱动文本生成的关键组成部分。然而，现有的解决方案往往各自独立，缺乏一个能够轻松整合这些关键过程的统一框架。由于缺乏标准化实施方案，加之检索和重新排名工作流的复杂性，使得研究人员难以在一个一致的环境中比较和评估不同的方法。虽然现有工具包如Rerankers和RankLLM提供了通用的重新排名管道，但它们通常缺乏进行详细实验和基准测试所需的灵活性。为应对这些挑战，我们引入了**Rankify**，这是一个强大且模块化的开源工具包，旨在在一个统一的框架内整合检索、重新排名和RAG。Rankify支持广泛的检索技术，包括密集检索和稀疏检索，并结合了最先进的重新排名模型以提高检索质量。此外，Rankify还提供了一组预检索的数据集以方便基准测试，这些数据集可在Huggingface上获取（https://huggingface.co/datasets）。为了促进采用和集成，我们提供了详尽的文档（https://github.com/alibaba/Rankify/blob/main/docs/en/index.md）、在GitHub上的开源实现（https://github.com/alibaba/Rankify）和PyPI包以实现方便的安装（https://pypi.org/project/rankify/）。通过提供一个统一且轻量级的框架，Rankify使研究人员和从业人员能够推进检索和重新排名方法的发展，同时确保一致、可扩展性和用户友好性。', 'title_zh': 'Rankify：一个全面的Python工具包，用于检索、再排序和检索增强生成'}
{'arxiv_id': 'arXiv:2502.02327', 'title': 'Policy-Guided Causal State Representation for Offline Reinforcement Learning Recommendation', 'authors': 'Siyu Wang, Xiaocong Chen, Lina Yao', 'link': 'https://arxiv.org/abs/2502.02327', 'abstract': 'In offline reinforcement learning-based recommender systems (RLRS), learning effective state representations is crucial for capturing user preferences that directly impact long-term rewards. However, raw state representations often contain high-dimensional, noisy information and components that are not causally relevant to the reward. Additionally, missing transitions in offline data make it challenging to accurately identify features that are most relevant to user satisfaction. To address these challenges, we propose Policy-Guided Causal Representation (PGCR), a novel two-stage framework for causal feature selection and state representation learning in offline RLRS. In the first stage, we learn a causal feature selection policy that generates modified states by isolating and retaining only the causally relevant components (CRCs) while altering irrelevant components. This policy is guided by a reward function based on the Wasserstein distance, which measures the causal effect of state components on the reward and encourages the preservation of CRCs that directly influence user interests. In the second stage, we train an encoder to learn compact state representations by minimizing the mean squared error (MSE) loss between the latent representations of the original and modified states, ensuring that the representations focus on CRCs. We provide a theoretical analysis proving the identifiability of causal effects from interventions, validating the ability of PGCR to isolate critical state components for decision-making. Extensive experiments demonstrate that PGCR significantly improves recommendation performance, confirming its effectiveness for offline RL-based recommender systems.', 'abstract_zh': '基于离线强化学习的推荐系统（RLRS）中，学习有效的状态表示对于捕捉直接影响长期奖励的用户偏好至关重要。然而，原始状态表示通常包含大量高维、噪声信息和与奖励无因果关系的成分。此外，离线数据中的缺失过渡使得准确识别最相关的特征以满足用户满意度变得具有挑战性。为了解决这些挑战，我们提出了一种名为因果表示引导策略（Policy-Guided Causal Representation, PGCR）的新颖两阶段框架，用于离线RLRS中的因果特征选择和状态表示学习。在第一阶段，我们学习一个因果特征选择策略，通过隔离并保留仅因果相关的成分（因果相关成分，Causal-Relevant Components, CRCs）并修改无关成分生成修改后状态。该策略受到基于Wasserstein距离的奖励函数的指导，该奖励函数衡量状态成分对奖励的因果效应，并鼓励保留直接影响用户兴趣的CRCs。在第二阶段，我们训练一个编码器，通过最小化原始状态和修改后状态的潜在表示之间的均方误差（MSE）损失，来学习紧凑的状态表示，确保表示聚焦于CRCs。我们提供了理论分析，证明干预条件下因果效应的可识别性，并验证了PGCR在决策中隔离关键状态成分的能力。广泛的经验实验证明，PGCR显著提高了推荐性能，证实了其在基于离线RL的推荐系统中的有效性。', 'title_zh': '基于策略引导的因果状态表示在 Offline 强化学习推荐中的应用'}
{'arxiv_id': 'arXiv:2502.02232', 'title': 'Combinatorial Optimization Perspective based Framework for Multi-behavior Recommendation', 'authors': 'Chenhao Zhai, Chang Meng, Yu Yang, Kexin Zhang, Xuhao Zhao, Xiu Li', 'link': 'https://arxiv.org/abs/2502.02232', 'abstract': 'In real-world recommendation scenarios, users engage with items through various types of behaviors. Leveraging diversified user behavior information for learning can enhance the recommendation of target behaviors (e.g., buy), as demonstrated by recent multi-behavior methods. The mainstream multi-behavior recommendation framework consists of two steps: fusion and prediction. Recent approaches utilize graph neural networks for multi-behavior fusion and employ multi-task learning paradigms for joint optimization in the prediction step, achieving significant success. However, these methods have limited perspectives on multi-behavior fusion, which leads to inaccurate capture of user behavior patterns in the fusion step. Moreover, when using multi-task learning for prediction, the relationship between the target task and auxiliary tasks is not sufficiently coordinated, resulting in negative information transfer. To address these problems, we propose a novel multi-behavior recommendation framework based on the combinatorial optimization perspective, named COPF. Specifically, we treat multi-behavior fusion as a combinatorial optimization problem, imposing different constraints at various stages of each behavior to restrict the solution space, thus significantly enhancing fusion efficiency (COGCN). In the prediction step, we improve both forward and backward propagation during the generation and aggregation of multiple experts to mitigate negative transfer caused by differences in both feature and label distributions (DFME). Comprehensive experiments on three real-world datasets indicate the superiority of COPF. Further analyses also validate the effectiveness of the COGCN and DFME modules. Our code is available at this https URL.', 'abstract_zh': '在现实世界的推荐场景中，用户通过各种类型的行为与项目互动。利用多样化的用户行为信息进行学习可以增强对目标行为（例如购买）的推荐能力，这一点由最近的多行为方法已经得到了证明。主流的多行为推荐框架包含两个步骤：融合和预测。最近的方法利用图神经网络进行多行为融合，并采用多任务学习范式在预测步骤中进行联合优化，取得了显著的成功。然而，这些方法在多行为融合方面的视角有限，导致在融合步骤中对用户行为模式的捕捉不够准确。此外，在使用多任务学习进行预测时，目标任务与辅助任务之间的关系没有得到充分协调，导致了负信息传递。为了解决这些问题，我们提出了一种基于组合优化视角的新型多行为推荐框架，名为COPF。具体而言，我们将多行为融合视为一个组合优化问题，在每个行为的不同阶段施加不同的约束，以限制解的空间，从而显著提高融合效率（COGCN）。在预测步骤中，我们在专家生成和聚合的过程中改进了前向和反向传播，以减轻由特征分布和标签分布差异引起的负信息传递（DFME）。在三个真实世界数据集上的全面实验表明，COPF在性能上具有优越性，进一步的分析也验证了COGCN和DFME模块的有效性。我们的代码可以在以下链接访问：[此处提供链接]。', 'title_zh': '基于组合优化视角的多行为推荐框架'}
{'arxiv_id': 'arXiv:2502.02061', 'title': 'Large Language Models for Recommendation with Deliberative User Preference Alignment', 'authors': 'Yi Fang, Wenjie Wang, Yang Zhang, Fengbin Zhu, Qifan Wang, Fuli Feng, Xiangnan He', 'link': 'https://arxiv.org/abs/2502.02061', 'abstract': 'While recent advancements in aligning Large Language Models (LLMs) with recommendation tasks have shown great potential and promising performance overall, these aligned recommendation LLMs still face challenges in complex scenarios. This is primarily due to the current alignment approach focusing on optimizing LLMs to generate user feedback directly, without incorporating deliberation. To overcome this limitation and develop more reliable LLMs for recommendations, we propose a new Deliberative Recommendation task, which incorporates explicit reasoning about user preferences as an additional alignment goal. We then introduce the Deliberative User Preference Alignment framework, designed to enhance reasoning capabilities by utilizing verbalized user feedback in a step-wise manner to tackle this task. The framework employs collaborative step-wise experts and tailored training strategies for each expert. Experimental results across three real-world datasets demonstrate the rationality of the deliberative task formulation and the superior performance of the proposed framework in improving both prediction accuracy and reasoning quality.', 'abstract_zh': '虽然近期在将大型语言模型（LLMs）与推荐任务对齐方面取得了显著进展并展现了良好的整体性能，但这些对齐的推荐LLMs在复杂场景下仍面临挑战。这主要是因为当前的对齐方法侧重于优化LLMs以直接生成用户反馈，而忽略了推理过程。为了克服这一局限，开发更为可靠的推荐LLMs，我们提出了一项新的“推理推荐”任务，该任务将用户偏好显式推理作为额外的对齐目标。随后，我们引入了“推理用户偏好对齐”框架，旨在通过逐步利用口头反馈来增强推理能力，从而应对这一任务。该框架采用协作的逐步专家，并为每个专家设计了定制化的训练策略。实验结果表明，通过三个真实数据集的测试，推理任务的表述是合乎逻辑的，所提出的框架在提高预测准确性和推理质量方面具有优越表现。', 'title_zh': '大规模语言模型在迭代用户偏好对齐中的推荐应用'}
{'arxiv_id': 'arXiv:2502.02430', 'title': 'A Scalable Crawling Algorithm Utilizing Noisy Change-Indicating Signals', 'authors': 'Róbert Busa-Fekete, Julian Zimmert, András György, Linhai Qiu, Tzu-Wei Sung, Hao Shen, Hyomin Choi, Sharmila Subramaniam, Li Xiao', 'link': 'https://arxiv.org/abs/2502.02430', 'abstract': 'Web refresh crawling is the problem of keeping a cache of web pages fresh, that is, having the most recent copy available when a page is requested, given a limited bandwidth available to the crawler. Under the assumption that the change and request events, resp., to each web page follow independent Poisson processes, the optimal scheduling policy was derived by Azar et al. 2018. In this paper, we study an extension of this problem where side information indicating content changes, such as various types of web pings, for example, signals from sitemaps, content delivery networks, etc., is available. Incorporating such side information into the crawling policy is challenging, because (i) the signals can be noisy with false positive events and with missing change events; and (ii) the crawler should achieve a fair performance over web pages regardless of the quality of the side information, which might differ from web page to web page. We propose a scalable crawling algorithm which (i) uses the noisy side information in an optimal way under mild assumptions; (ii) can be deployed without heavy centralized computation; (iii) is able to crawl web pages at a constant total rate without spikes in the total bandwidth usage over any time interval, and automatically adapt to the new optimal solution when the total bandwidth changes without centralized computation. Experiments clearly demonstrate the versatility of our approach.', 'abstract_zh': '网络刷新爬取是保持网页缓存最新的一种问题，即在有限的带宽条件下，确保当请求页面时能够获取到最更新的副本。如果假定每个网页的改变事件和请求事件分别遵循独立的泊松过程，Azar等人于2018年推导出了最优调度策略。在本文中，我们研究了一个该问题的扩展，其中可用了一些侧信息来指示内容更改，例如各种类型的网页探测信号，例如来自站点地图、内容分发网络等的信号。将此类侧信息纳入爬取策略中存在挑战，因为（i）这些信号可能是嘈杂的，存在误报事件和丢失更改事件的可能性；（ii）爬取器需要在不考虑侧信息质量的情况下确保对所有网页的公平性能，而不同网页的侧信息质量可能有所不同。本文提出了一种可扩展的爬取算法，该算法（i）在轻度假设下充分利用嘈杂的侧信息；（ii）可以在无需大量集中计算资源的情况下部署；（iii）能够在任何时间间隔内以恒定的总速率爬取网页而不导致带宽使用量波动，并且在无需集中计算的情况下自动适应当总带宽变化时的新最优解。实验结果清楚地证明了我们方法的灵活性。', 'title_zh': '一种利用噪声变化指示信号的可扩展爬取算法'}
{'arxiv_id': 'arXiv:2502.02167', 'title': 'Multilingual Attribute Extraction from News Web Pages', 'authors': 'Pavel Bedrin, Maksim Varlamov, Alexander Yatskov', 'link': 'https://arxiv.org/abs/2502.02167', 'abstract': 'This paper addresses the challenge of automatically extracting attributes from news article web pages across multiple languages. Recent neural network models have shown high efficacy in extracting information from semi-structured web pages. However, these models are predominantly applied to domains like e-commerce and are pre-trained using English data, complicating their application to web pages in other languages. We prepared a multilingual dataset comprising 3,172 marked-up news web pages across six languages (English, German, Russian, Chinese, Korean, and Arabic) from 161 websites. The dataset is publicly available on GitHub. We fine-tuned the pre-trained state-of-the-art model, MarkupLM, to extract news attributes from these pages and evaluated the impact of translating pages into English on extraction quality. Additionally, we pre-trained another state-of-the-art model, DOM-LM, on multilingual data and fine-tuned it on our dataset. We compared both fine-tuned models to existing open-source news data extraction tools, achieving superior extraction metrics.', 'abstract_zh': '本文探讨了跨多种语言自动从新闻文章网页中抽取属性的挑战。近年来，基于神经网络的模型在从半结构化网页中提取信息方面表现出高度的效用。然而，这些模型主要应用于电子商务等领域，并且大多使用英语数据进行预训练，这使得它们在应用于其他语言的网页时变得复杂。我们准备了一个包含6种语言（英语、德语、俄语、中文、韩语和阿拉伯语）共3,172个标记新闻网页的数据集，这些网页来自161个网站。该数据集已在GitHub上公开。我们使用预训练的先进模型MarkupLM对该数据集进行了微调，以从这些网页中抽取新闻属性，并评估了将网页翻译成英语对抽取质量的影响。此外，我们还在多语言数据上预训练了另一个先进模型DOM-LM，并将其微调到我们的数据集上。我们将这两个微调模型与现有的开源新闻数据抽取工具进行了比较，取得了更优异的抽取指标。', 'title_zh': '从新闻网页中提取多语言属性'}
{'arxiv_id': 'arXiv:2502.01792', 'title': 'Policy Design for Two-sided Platforms with Participation Dynamics', 'authors': 'Haruka Kiyohara, Fan Yao, Sarah Dean', 'link': 'https://arxiv.org/abs/2502.01792', 'abstract': 'In two-sided platforms (e.g., video streaming or e-commerce), viewers and providers engage in interactive dynamics, where an increased provider population results in higher viewer utility and the increase of viewer population results in higher provider utility. Despite the importance of such "population effects" on long-term platform health, recommendation policies do not generally take the participation dynamics into account. This paper thus studies the dynamics and policy design on two-sided platforms under the population effects for the first time. Our control- and game-theoretic findings warn against the use of myopic-greedy policy and shed light on the importance of provider-side considerations (i.e., effectively distributing exposure among provider groups) to improve social welfare via population growth. We also present a simple algorithm to optimize long-term objectives by considering the population effects, and demonstrate its effectiveness in synthetic and real-data experiments.', 'abstract_zh': '在双边平台（如视频流媒体或电子商务）中，用户和提供者之间存在着互动动力学，即提供者的群体增加会提高用户的效用，而用户的群体增加会提高提供者的效用。尽管“规模效应”对平台的长期健康至关重要，但推荐策略通常并未将参与动力学纳入考虑。因此，本文首次研究了在考虑规模效应的情况下双边平台的动力学及其政策设计。我们的控制论和博弈论发现提醒人们避免短期逐利策略，并强调了提供者一方考虑的重要性（即在提供者群体中有效分发曝光度），以通过人口增长来提高社会福利。我们还提出了一种简单算法，通过考虑规模效应来优化长期目标，并通过合成数据和实际数据实验展示了其有效性。', 'title_zh': '具有参与动态的双边平台政策设计'}
{'arxiv_id': 'arXiv:2502.01772', 'title': 'On Bob Dylan: A Computational Perspective', 'authors': 'Prashant Garg', 'link': 'https://arxiv.org/abs/2502.01772', 'abstract': "Cass Sunstein's essay 'On Bob Dylan' describes Dylan's 'dishabituating' style -- a constant refusal to conform to expectation and a penchant for reinventing his musical and lyrical identity. In this paper, I extend Sunstein's observations through a large-scale computational analysis of Dylan's lyrics from 1962 to 2012. Using o3-mini-high (a large language model), I extract concept-to-concept relationships from the lyrics and construct directed knowledge graphs that capture Dylan's thematic structure. I then quantify shifts in sentiment, metaphorical expression, thematic diversity, and network complexity over time. The results indicate that Dylan's lyrics increasingly rely on metaphor, display an evolving sentiment profile, and exhibit heightened dishabituation -- measured here as a growing variance in the network centrality of key concepts. I also find that references to movement, protest, and mythic imagery fluctuate in ways that align with well-known phases of Dylan's career, reflecting the dynamic and unpredictable quality of his art. These findings not only deepen our empirical understanding of Sunstein's thesis but also introduce a novel computational method for analyzing an artist's evolution-offering broader applicability to the study of cultural and creative change.", 'abstract_zh': '卡斯·sunstein在《论鲍勃·迪伦》一文中描述了迪伦的“去习惯化”风格——一种不断地拒绝适应预期和不断重塑其音乐和歌词身份的倾向。在此论文中，我通过1962年至2012年迪伦歌词的大规模计算分析，进一步扩展了sunstein的观察。利用o3-mini-high（大型语言模型），我从歌词中提取概念到概念的关系，并构建了能够捕捉迪伦主题结构的有向知识图谱。随后，我量化了情感、隐喻表达、主题多样性和网络复杂性随时间的变化。结果表明，迪伦的歌词越来越多地依赖于隐喻，情感特征呈现出演变的趋势，并表现出更高的去习惯化——在这里，去习惯化被衡量为关键概念在网络中心性上的增长变化。我还发现，关于运动、抗议和神话意象的引用在迪伦职业生涯中著名的不同阶段有所波动，反映了其艺术的动态和不可预测性。这些发现不仅加深了我们对sunstein论点的实证理解，还引入了一种新的计算方法来分析艺术家的演化——这种方法对文化与创造力变迁的研究具有更广泛的应用价值。', 'title_zh': '从计算角度论鲍勃·迪伦'}
{'arxiv_id': 'arXiv:2502.01699', 'title': 'Multimodal Inverse Attention Network with Intrinsic Discriminant Feature Exploitation for Fake News Detection', 'authors': 'Tianlin Zhang, En Yu, Yi Shao, Shuai Li, Sujuan Hou, Jiande Sun', 'link': 'https://arxiv.org/abs/2502.01699', 'abstract': 'Multimodal fake news detection has garnered significant attention due to its profound implications for social security. While existing approaches have contributed to understanding cross-modal consistency, they often fail to leverage modal-specific representations and explicit discrepant features. To address these limitations, we propose a Multimodal Inverse Attention Network (MIAN), a novel framework that explores intrinsic discriminative features based on news content to advance fake news detection. Specifically, MIAN introduces a hierarchical learning module that captures diverse intra-modal relationships through local-to-global and local-to-local interactions, thereby generating enhanced unimodal representations to improve the identification of fake news at the intra-modal level. Additionally, a cross-modal interaction module employs a co-attention mechanism to establish and model dependencies between the refined unimodal representations, facilitating seamless semantic integration across modalities. To explicitly extract inconsistency features, we propose an inverse attention mechanism that effectively highlights the conflicting patterns and semantic deviations introduced by fake news in both intra- and inter-modality. Extensive experiments on benchmark datasets demonstrate that MIAN significantly outperforms state-of-the-art methods, underscoring its pivotal contribution to advancing social security through enhanced multimodal fake news detection.', 'abstract_zh': '多模态假新闻检测因其对社会安全的深远影响而引起了广泛关注。尽管现有方法在理解跨模态一致性方面做出了贡献，但它们往往未能充分利用特定模态的表示和显式的不一致特征。为了解决这些问题，我们提出了一种多模态逆注意力网络（MIAN），这是一种新颖的框架，基于新闻内容探索内在的辨别特征，以促进假新闻检测。具体而言，MIAN 引入了一种分层学习模块，通过局部到全局和局部到局部的交互来捕捉多种内模态关系，从而生成增强的一模态表示，以在内模态级别提高假新闻的识别能力。此外，跨模态交互模块采用共注意力机制来建立并建模细化的一模态表示之间的依赖关系，促进不同模态之间的无缝语义集成。为明确提取不一致特征，我们提出了一种逆注意力机制，该机制有效地突出了假新闻引入的内在和跨模态中的矛盾模式和语义偏差。在基准数据集上的广泛实验表明，MIAN 显著优于现有最先进的方法，突显了其在通过增强多模态假新闻检测来提升社会安全方面的重要贡献。', 'title_zh': '具有内在鉴别特征利用的多模态逆注意力网络用于假新闻检测'}
{'arxiv_id': 'arXiv:2502.01669', 'title': 'Addressing Delayed Feedback in Conversion Rate Prediction via Influence Functions', 'authors': 'Chenlu Ding, Jiancan Wu, Yancheng Yuan, Junfeng Fang, Cunchun Li, Xiang Wang, Xiangnan He', 'link': 'https://arxiv.org/abs/2502.01669', 'abstract': 'In the realm of online digital advertising, conversion rate (CVR) prediction plays a pivotal role in maximizing revenue under cost-per-conversion (CPA) models, where advertisers are charged only when users complete specific actions, such as making a purchase. A major challenge in CVR prediction lies in the delayed feedback problem-conversions may occur hours or even weeks after initial user interactions. This delay complicates model training, as recent data may be incomplete, leading to biases and diminished performance. Although existing methods attempt to address this issue, they often fall short in adapting to evolving user behaviors and depend on auxiliary models, which introduces computational inefficiencies and the risk of model inconsistency. In this work, we propose an Influence Function-empowered framework for Delayed Feedback Modeling (IF-DFM). IF-DFM leverages influence functions to estimate how newly acquired and delayed conversion data impact model parameters, enabling efficient parameter updates without the need for full retraining. Additionally, we present a scalable algorithm that efficiently computes parameter updates by reframing the inverse Hessian-vector product as an optimization problem, striking a balance between computational efficiency and effectiveness. Extensive experiments on benchmark datasets demonstrate that IF-DFM consistently surpasses state-of-the-art methods, significantly enhancing both prediction accuracy and model adaptability.', 'abstract_zh': '在在线数字广告的领域中，点击转换率（CVR）预测在成本每次转换（CPA）模型中发挥着至关重要的作用，这种模型要求广告商在用户完成特定操作（如购买）后才进行收费。CVR预测面临的一个主要挑战是延迟反馈问题——转换可能在最初的用户交互后几小时甚至几周才发生。这种延迟使得模型训练变得复杂，因为近期数据可能是不完整的，从而导致偏差和性能下降。尽管现有的方法试图解决这一问题，但它们往往难以适应用户行为的变化，并且依赖于辅助模型，这引入了计算效率低下和模型不一致的风险。本研究提出了一种基于影响函数的延迟反馈建模框架（IF-DFM）。IF-DFM 利用影响函数来估算新获取的延迟转化数据对模型参数的影响，从而实现高效的参数更新，无需进行全面的重新训练。此外，我们提出了一种可扩展的算法，通过将逆Hessian-向量乘积重新构造成优化问题，有效地计算参数更新，实现了计算效率和效果之间的平衡。在基准数据集上的广泛实验表明，IF-DFM 一致地超越了最先进的方法，显著提高了预测准确性和模型适应性。', 'title_zh': '通过影响函数解决转化率预测中的延迟反馈问题'}
