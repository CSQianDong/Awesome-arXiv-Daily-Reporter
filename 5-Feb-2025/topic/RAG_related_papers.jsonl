{'arxiv_id': 'arXiv:2502.02249', 'title': 'Conversation AI Dialog for Medicare powered by Finetuning and Retrieval Augmented Generation', 'authors': 'Atharva Mangeshkumar Agrawal, Rutika Pandurang Shinde, Vasanth Kumar Bhukya, Ashmita Chakraborty, Sagar Bharat Shah, Tanmay Shukla, Sree Pradeep Kumar Relangi, Nilesh Mutyam', 'link': 'https://arxiv.org/abs/2502.02249', 'abstract': 'Large language models (LLMs) have shown impressive capabilities in natural language processing tasks, including dialogue generation. This research aims to conduct a novel comparative analysis of two prominent techniques, fine-tuning with LoRA (Low-Rank Adaptation) and the Retrieval-Augmented Generation (RAG) framework, in the context of doctor-patient chat conversations with multiple datasets of mixed medical domains. The analysis involves three state-of-the-art models: Llama-2, GPT, and the LSTM model. Employing real-world doctor-patient dialogues, we comprehensively evaluate the performance of models, assessing key metrics such as language quality (perplexity, BLEU score), factual accuracy (fact-checking against medical knowledge bases), adherence to medical guidelines, and overall human judgments (coherence, empathy, safety). The findings provide insights into the strengths and limitations of each approach, shedding light on their suitability for healthcare applications. Furthermore, the research investigates the robustness of the models in handling diverse patient queries, ranging from general health inquiries to specific medical conditions. The impact of domain-specific knowledge integration is also explored, highlighting the potential for enhancing LLM performance through targeted data augmentation and retrieval strategies.', 'abstract_zh': '大型语言模型（LLMs）在自然语言处理任务中展现了令人印象深刻的性能，包括对话生成。本研究旨在在多种医学领域混合的数据集背景下，对比分析两种突出的技术——基于LoRA（低秩适应）的微调和检索增强生成（RAG）框架——在医生与患者对话中的性能。分析将涉及三款最先进的模型：Llama-2、GPT以及LSTM模型。通过使用真实的医生与患者对话数据，我们将全面评估这些模型的表现，评估关键指标，如语言质量（困惑度、BLEU分数）、事实准确性（通过医学知识库进行事实核查）、遵守医学指南情况，以及总体的人类判断（连贯性、同理心、安全性）。研究结果将揭示每种方法的优势和局限性，为其在医疗保健应用中的适用性提供洞察。此外，研究还将探讨模型在处理各种患者查询时的鲁棒性，这些问题范围从一般健康咨询到特定医学状况。研究还将探索领域特定知识整合的影响，突显通过针对性的数据增强和检索策略增强LLM性能的潜力。', 'title_zh': '由微调和检索增强生成驱动的医保对话AI对话'}
{'arxiv_id': 'arXiv:2502.02464', 'title': 'Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation', 'authors': 'Abdelrahman Abdallah, Jamshid Mozafari, Bhawna Piryani, Mohammed Ali, Adam Jatowt', 'link': 'https://arxiv.org/abs/2502.02464', 'abstract': 'Retrieval, re-ranking, and retrieval-augmented generation (RAG) are critical components of modern natural language processing (NLP) applications in information retrieval, question answering, and knowledge-based text generation. However, existing solutions are often fragmented, lacking a unified framework that easily integrates these essential processes. The absence of a standardized implementation, coupled with the complexity of retrieval and re-ranking workflows, makes it challenging for researchers to compare and evaluate different approaches in a consistent environment. While existing toolkits such as Rerankers and RankLLM provide general-purpose reranking pipelines, they often lack the flexibility required for fine-grained experimentation and benchmarking. In response to these challenges, we introduce \\textbf{Rankify}, a powerful and modular open-source toolkit designed to unify retrieval, re-ranking, and RAG within a cohesive framework. Rankify supports a wide range of retrieval techniques, including dense and sparse retrievers, while incorporating state-of-the-art re-ranking models to enhance retrieval quality. Additionally, Rankify includes a collection of pre-retrieved datasets to facilitate benchmarking, available at Huggingface (this https URL). To encourage adoption and ease of integration, we provide comprehensive documentation (this http URL), an open-source implementation on GitHub(this https URL), and a PyPI package for effortless installation(this https URL). By providing a unified and lightweight framework, Rankify allows researchers and practitioners to advance retrieval and re-ranking methodologies while ensuring consistency, scalability, and ease of use.', 'abstract_zh': '检索、重新排名和检索增强生成（RAG）是现代自然语言处理（NLP）应用中信息检索、问答和知识驱动文本生成的关键组成部分。然而，现有的解决方案往往各自独立，缺乏一个能够轻松整合这些关键过程的统一框架。由于缺乏标准化实施方案，加之检索和重新排名工作流的复杂性，使得研究人员难以在一个一致的环境中比较和评估不同的方法。虽然现有工具包如Rerankers和RankLLM提供了通用的重新排名管道，但它们通常缺乏进行详细实验和基准测试所需的灵活性。为应对这些挑战，我们引入了**Rankify**，这是一个强大且模块化的开源工具包，旨在在一个统一的框架内整合检索、重新排名和RAG。Rankify支持广泛的检索技术，包括密集检索和稀疏检索，并结合了最先进的重新排名模型以提高检索质量。此外，Rankify还提供了一组预检索的数据集以方便基准测试，这些数据集可在Huggingface上获取（https://huggingface.co/datasets）。为了促进采用和集成，我们提供了详尽的文档（https://github.com/alibaba/Rankify/blob/main/docs/en/index.md）、在GitHub上的开源实现（https://github.com/alibaba/Rankify）和PyPI包以实现方便的安装（https://pypi.org/project/rankify/）。通过提供一个统一且轻量级的框架，Rankify使研究人员和从业人员能够推进检索和重新排名方法的发展，同时确保一致、可扩展性和用户友好性。', 'title_zh': 'Rankify：一个全面的Python工具包，用于检索、再排序和检索增强生成'}
