# Turn-based Multi-Agent Reinforcement Learning Model Checking 

**Title (ZH)**: 基于轮次的多智能体强化学习模型检查 

**Authors**: Dennis Gross  

**Link**: [PDF](https://arxiv.org/pdf/2501.03187)  

**Abstract**: In this paper, we propose a novel approach for verifying the compliance of turn-based multi-agent reinforcement learning (TMARL) agents with complex requirements in stochastic multiplayer games. Our method overcomes the limitations of existing verification approaches, which are inadequate for dealing with TMARL agents and not scalable to large games with multiple agents. Our approach relies on tight integration of TMARL and a verification technique referred to as model checking. We demonstrate the effectiveness and scalability of our technique through experiments in different types of environments. Our experiments show that our method is suited to verify TMARL agents and scales better than naive monolithic model checking. 

**Abstract (ZH)**: 在本文中，我们提出了一种新的方法，用于验证轮次制多智能体强化学习（TMARL）代理在随机多人游戏中是否符合复杂的要求。我们的方法克服了现有验证方法的局限性，这些方法不适用于处理TMARL代理，并且无法对具有多个代理的大型游戏进行扩展。我们的方法依赖于TMARL与一种称为模型检验的验证技术的紧密集成。我们通过在不同类型环境中的实验展示了该技术的有效性和可扩展性。我们的实验表明，我们的方法适用于验证TMARL代理，并且比传统的单一模型检验方法具有更好的可扩展性。 

---
# Large language models for artificial general intelligence (AGI): A survey of foundational principles and approaches 

**Title (ZH)**: 大语言模型在通用人工智能（AGI）中的应用：基础原则与方法综述 

**Authors**: Alhassan Mumuni, Fuseini Mumuni  

**Link**: [PDF](https://arxiv.org/pdf/2501.03151)  

**Abstract**: Generative artificial intelligence (AI) systems based on large-scale pretrained foundation models (PFMs) such as vision-language models, large language models (LLMs), diffusion models and vision-language-action (VLA) models have demonstrated the ability to solve complex and truly non-trivial AI problems in a wide variety of domains and contexts. Multimodal large language models (MLLMs), in particular, learn from vast and diverse data sources, allowing rich and nuanced representations of the world and, thereby, providing extensive capabilities, including the ability to reason, engage in meaningful dialog; collaborate with humans and other agents to jointly solve complex problems; and understand social and emotional aspects of humans. Despite this impressive feat, the cognitive abilities of state-of-the-art LLMs trained on large-scale datasets are still superficial and brittle. Consequently, generic LLMs are severely limited in their generalist capabilities. A number of foundational problems -- embodiment, symbol grounding, causality and memory -- are required to be addressed for LLMs to attain human-level general intelligence. These concepts are more aligned with human cognition and provide LLMs with inherent human-like cognitive properties that support the realization of physically-plausible, semantically meaningful, flexible and more generalizable knowledge and intelligence. In this work, we discuss the aforementioned foundational issues and survey state-of-the art approaches for implementing these concepts in LLMs. Specifically, we discuss how the principles of embodiment, symbol grounding, causality and memory can be leveraged toward the attainment of artificial general intelligence (AGI) in an organic manner. 

**Abstract (ZH)**: 基于大规模预训练基础模型（PFMs）的生成型人工智能（AI）系统，如视觉-语言模型、大规模语言模型（LLMs）、扩散模型和视觉-语言-动作（VLA）模型，已经在广泛的应用领域和上下文中展示了解决复杂且真正非平凡AI问题的能力。特别是多模态大规模语言模型（MLLMs），它们从大量异质数据源中学习，能够提供丰富细致的世界表征，从而提供了广泛的能动性，包括推理、进行有意义的对话；与人类及其他代理共同解决复杂问题的能力；以及理解人类的社会和情感方面。尽管取得了这一令人印象深刻的成绩，但通过大规模数据集训练的最先进LLMs的认知能力仍然浅薄且脆弱。因此，通用的LLMs在泛化能力方面受到了严重限制。在这些认知领域——体现、符号接地、因果性和记忆——需要得到解决，以便LLMs能够达到人类水平的通用智能。这些概念更符合人类认知，为LLMs赋予了内在的人类认知特性，支持实现物理上可验证、语义上有意义、灵活且更具迁移性的知识和智能。在本文中，我们将讨论上述基础问题，并回顾用于在LLMs中实现这些概念的最先进方法。具体而言，我们将探讨如何通过一种有机的方式利用体现、符号接地、因果性和记忆的原则，以实现人工通用智能（AGI）。 

---
# Co-Activation Graph Analysis of Safety-Verified and Explainable Deep Reinforcement Learning Policies 

**Title (ZH)**: 安全验证和可解释的深度强化学习策略的共激活图分析 

**Authors**: Dennis Gross, Helge Spieker  

**Link**: [PDF](https://arxiv.org/pdf/2501.03142)  

**Abstract**: Deep reinforcement learning (RL) policies can demonstrate unsafe behaviors and are challenging to interpret. To address these challenges, we combine RL policy model checking--a technique for determining whether RL policies exhibit unsafe behaviors--with co-activation graph analysis--a method that maps neural network inner workings by analyzing neuron activation patterns--to gain insight into the safe RL policy's sequential decision-making. This combination lets us interpret the RL policy's inner workings for safe decision-making. We demonstrate its applicability in various experiments. 

**Abstract (ZH)**: 深度强化学习（RL）策略可能会表现出不安全的行为，并且难以解释。为应对这些挑战，我们结合使用RL策略模型检查——一种用于确定RL策略是否表现出不安全行为的技术——与共激活图分析——一种通过分析神经元激活模式来映射神经网络内部工作机制的方法——以深入了解安全RL策略的序列决策机制。这种结合使我们能够解释RL策略内部如何进行安全决策。我们在多项实验中展示了其适用性。 

---
# Analyzing Fine-tuning Representation Shift for Multimodal LLMs Steering alignment 

**Title (ZH)**: 分析多模态LLM微调中的表示转移，以实现对齐 

**Authors**: Pegah Khayatan, Mustafa Shukor, Jayneel Parekh, Matthieu Cord  

**Link**: [PDF](https://arxiv.org/pdf/2501.03012)  

**Abstract**: Multimodal LLMs have reached remarkable levels of proficiency in understanding multimodal inputs, driving extensive research to develop increasingly powerful models. However, much less attention has been paid to understanding and explaining the underlying mechanisms of these models. Most existing explainability research examines these models only in their final states, overlooking the dynamic representational shifts that occur during training. In this work, we systematically analyze the evolution of hidden state representations to reveal how fine-tuning alters the internal structure of a model to specialize in new multimodal tasks. Using a concept-based approach, we map hidden states to interpretable visual and textual concepts, enabling us to trace changes in encoded concepts across modalities as training progresses. We also demonstrate the use of shift vectors to capture these concepts changes. These shift vectors allow us to recover fine-tuned concepts by shifting those in the original model. Finally, we explore the practical impact of our findings on model steering, showing that we can adjust multimodal LLMs behaviors without any training, such as modifying answer types, captions style, or biasing the model toward specific responses. Our work sheds light on how multimodal representations evolve through fine-tuning and offers a new perspective for interpreting model adaptation in multimodal tasks. The code for this project is publicly available at this https URL. 

**Abstract (ZH)**: 多模态大语言模型在理解多模态输入方面达到了显著的熟练水平，推动了大量研究以开发越来越强大的模型。然而，对这些模型背后的机制及其解释的关注却相对较少。现有的大多数解释性研究仅关注模型的最终状态，而忽视了训练过程中发生的动态表示转变。在这项工作中，我们系统地分析了隐藏状态表示的演变，揭示了调整如何改变模型的内部结构以专门从事新的多模态任务。我们采用基于概念的方法，将隐藏状态映射到可解释的视觉和文本概念，从而能够追踪训练过程中不同模态编码概念的变化。我们还展示了使用位移向量捕获这些概念变化的方法。这些位移向量允许我们通过调整原模型中的概念获得微调后的概念。最后，我们探讨了我们研究发现的实际影响，展示了可以在不进行训练的情况下调整多模态大语言模型的行为，例如修改答案类型、调整图例风格或使模型倾向于某些特定的响应。我们的研究揭示了微调过程中多模态表示如何演变，并为理解多模态任务中的模型适应提供了新的视角。该项目的代码已公开，可在以下链接访问：[这里](https://example.com/code)。 

---
# CALM: Curiosity-Driven Auditing for Large Language Models 

**Title (ZH)**: CALM：好奇心驱动的大语言模型审计 

**Authors**: Xiang Zheng, Longxiang Wang, Yi Liu, Xingjun Ma, Chao Shen, Cong Wang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02997)  

**Abstract**: Auditing Large Language Models (LLMs) is a crucial and challenging task. In this study, we focus on auditing black-box LLMs without access to their parameters, only to the provided service. We treat this type of auditing as a black-box optimization problem where the goal is to automatically uncover input-output pairs of the target LLMs that exhibit illegal, immoral, or unsafe behaviors. For instance, we may seek a non-toxic input that the target LLM responds to with a toxic output or an input that induces the hallucinative response from the target LLM containing politically sensitive individuals. This black-box optimization is challenging due to the scarcity of feasible points, the discrete nature of the prompt space, and the large search space. To address these challenges, we propose Curiosity-Driven Auditing for Large Language Models (CALM), which uses intrinsically motivated reinforcement learning to finetune an LLM as the auditor agent to uncover potential harmful and biased input-output pairs of the target LLM. CALM successfully identifies derogatory completions involving celebrities and uncovers inputs that elicit specific names under the black-box setting. This work offers a promising direction for auditing black-box LLMs. Our code is available at this https URL. 

**Abstract (ZH)**: 审查大规模语言模型（LLMs）是至关重要且具有挑战性的任务。在本研究中，我们重点关注在无法访问LLMs参数的情况下审查黑盒LLMs，只能够使用提供的服务。我们将这种审查类型视为黑盒优化问题，其目标是自动发现目标LLMs中表现出非法、不道德或不安全行为的输入-输出对。例如，我们可能寻求一个无害的输入，而目标LLM却以有害的方式响应，或者一个能够引发目标LLM生成包含政治敏感人物的幻觉输出的输入。由于可行点稀缺、提示空间的离散性质以及搜索空间庞大，这种黑盒优化具有挑战性。为了应对这些挑战，我们提出了Curiosity-Driven Auditing for Large Language Models（CALM），该方法使用本体驱动的强化学习来微调一个LLM作为审计代理，以发现目标LLMs中潜在有害和偏见的输入-输出对。CALM成功地识别了涉及名人并对特定名称产生反应的诋毁完成，即使是在黑盒设置中。本项工作为审查黑盒LLMs提供了有前景的方向。我们的代码可在以下网址获得：此 https URL。 

---
# Fairness Through Matching 

**Title (ZH)**: 通过匹配实现公平 

**Authors**: Kunwoong Kim, Insung Kong, Jongjin Lee, Minwoo Chae, Sangchul Park, Yongdai Kim  

**Link**: [PDF](https://arxiv.org/pdf/2501.02793)  

**Abstract**: Group fairness requires that different protected groups, characterized by a given sensitive attribute, receive equal outcomes overall. Typically, the level of group fairness is measured by the statistical gap between predictions from different protected groups. In this study, we reveal an implicit property of existing group fairness measures, which provides an insight into how the group-fair models behave. Then, we develop a new group-fair constraint based on this implicit property to learn group-fair models. To do so, we first introduce a notable theoretical observation: every group-fair model has an implicitly corresponding transport map between the input spaces of each protected group. Based on this observation, we introduce a new group fairness measure termed Matched Demographic Parity (MDP), which quantifies the averaged gap between predictions of two individuals (from different protected groups) matched by a given transport map. Then, we prove that any transport map can be used in MDP to learn group-fair models, and develop a novel algorithm called Fairness Through Matching (FTM), which learns a group-fair model using MDP constraint with an user-specified transport map. We specifically propose two favorable types of transport maps for MDP, based on the optimal transport theory, and discuss their advantages. Experiments reveal that FTM successfully trains group-fair models with certain desirable properties by choosing the transport map accordingly. 

**Abstract (ZH)**: 群体公平要求不同受保护群体（由给定的敏感属性表征）在整体上获得相同的输出结果。通常，群体公平性的水平通过不同受保护群体预测结果之间的统计差距来衡量。在本研究中，我们揭示了现有群体公平性测量方法中隐含的一个属性，这为我们理解群体公平模型的行为提供了新的见解。然后，我们基于这一隐含属性开发了一种新的群体公平约束，以学习群体公平模型。为此，我们首先提出了一项重要的理论观察：每个群体公平模型都存在一个隐含的传输映射，将其输入空间中的每个受保护群体相连。基于这一观察，我们引入了一种新的群体公平性度量，称为匹配人口均等性（Matched Demographic Parity，MDP），该度量通过给定传输映射匹配的两人的预测结果平均差距量化预测结果的差异。然后，我们证明了任何传输映射都可以用于MDP以学习群体公平模型，并开发了一种名为匹配通过公平性（Fairness Through Matching，FTM）的新算法，该算法使用MDP约束和用户指定的传输映射来学习群体公平模型。我们特别根据最佳传输理论提出了两种有利于MDP的传输映射类型，并讨论了它们的优势。实验结果表明，通过适当选择传输映射，FTM成功地训练出了具有某些期望特性的群体公平模型。 

---
# Multi-Agent Path Finding under Limited Communication Range Constraint via Dynamic Leading 

**Title (ZH)**: 在有限通信范围约束下的多智能体路径规划方法：基于动态领航的解决方案 

**Authors**: Hoang-Dung Bui, Erion Plaku, Gregoy J. Stein  

**Link**: [PDF](https://arxiv.org/pdf/2501.02770)  

**Abstract**: This paper proposes a novel framework to handle a multi-agent path finding problem under a limited communication range constraint, where all agents must have a connected communication channel to the rest of the team. Many existing approaches to multi-agent path finding (e.g., leader-follower platooning) overcome computational challenges of planning in this domain by planning one agent at a time in a fixed order. However, fixed leader-follower approaches can become stuck during planning, limiting their practical utility in dense-clutter environments. To overcome this limitation, we develop dynamic leading multi-agent path finding, which allows for dynamic reselection of the leading agent during path planning whenever progress cannot be made. The experiments show the efficiency of our framework, which can handle up to 25 agents with more than 90% success-rate across five environment types where baselines routinely fail. 

**Abstract (ZH)**: 本文提出了一种新颖的框架，用于处理在通信范围受限条件下的多-agent路径规划问题，其中所有agent必须与团队的其他部分保持连通的通信通道。许多现有的多-agent路径规划方法（例如，领导者-跟随者编队）通过以固定顺序一次规划一个agent来克服在这一领域中的计算挑战。然而，固定领导者-跟随者方法在规划过程中可能会陷入困境，限制了它们在密集障碍环境中的实际应用价值。为克服这一局限，我们开发了一种动态领导的多-agent路径规划方法，该方法在路径规划过程中可以在无法取得进展时动态重新选择领导者。实验结果显示，该框架的有效性，能够在五种不同类型的环境中处理多达25个agent，并且成功率达到超过90%，而基线方法在这种环境中通常会失败。 

---
# Artificial Intelligence in Creative Industries: Advances Prior to 2025 

**Title (ZH)**: 人工智能在创意产业中的应用：至2025年的进展 

**Authors**: Nantheera Anantrasirichai, Fan Zhang, David Bull  

**Link**: [PDF](https://arxiv.org/pdf/2501.02725)  

**Abstract**: The rapid advancements in artificial intelligence (AI), particularly in generative AI and large language models (LLMs), have profoundly impacted the creative industries by enabling innovative content creation, enhancing workflows, and democratizing access to creative tools. This paper explores the significant technological shifts since our previous review in 2022, highlighting how these developments have expanded creative opportunities and efficiency. These technological advancements have enhanced the capabilities of text-to-image, text-to-video, and multimodal generation technologies. In particular, key breakthroughs in LLMs have established new benchmarks in conversational AI, while advancements in image generators have revolutionized content creation. We also discuss AI integration into post-production workflows, which has significantly accelerated and refined traditional processes. Despite these innovations, challenges remain, particularly for the media industry, due to the demands on communication traffic from creative content. We therefore include data compression and quality assessment in this paper. Furthermore, we highlight the trend toward unified AI frameworks capable of addressing multiple creative tasks and underscore the importance of human oversight to mitigate AI-generated inaccuracies. Finally, we explore AI's future potential in the creative sector, stressing the need to navigate emerging challenges to maximize its benefits while addressing associated risks. 

**Abstract (ZH)**: 近年来，人工智能（AI）的迅猛发展，尤其是在生成型AI和大型语言模型（LLMs）方面，极大地影响了创意产业，通过促进创新内容创作、提高工作流程效率和普及创意工具的使用。本文探讨了自2022年上次回顾以来的技术变革，突显了这些进展如何扩大了创意机会和效率。这些技术创新增强了文本转图像、文本转视频和多模态生成技术的能力。尤其值得注意的是，大型语言模型方面的重要突破为对话式AI设立了新的基准，而图像生成技术的进步则彻底改变了内容创作方式。此外，我们还讨论了AI在后期制作流程中的集成，这已显著加速和优化了传统流程。尽管如此，仍存在挑战，尤其是在媒体行业，由于创意内容对通信流量的需求。因此，本文还包括数据压缩和质量评估的内容。我们还强调了统一的AI框架的发展趋势，这种框架能够处理多种创意任务，并强调了人工监督的重要性，以减轻AI生成错误的影响。最后，我们探讨了AI在创意领域未来的潜在应用，强调在利用其优势的同时，需要应对新兴挑战并管理相关风险。 

---
# KG-CF: Knowledge Graph Completion with Context Filtering under the Guidance of Large Language Models 

**Title (ZH)**: KG-CF：在大型语言模型指导下基于上下文过滤的知识图谱完成方法 

**Authors**: Zaiyi Zheng, Yushun Dong, Song Wang, Haochen Liu, Qi Wang, Jundong Li  

**Link**: [PDF](https://arxiv.org/pdf/2501.02711)  

**Abstract**: Large Language Models (LLMs) have shown impressive performance in various tasks, including knowledge graph completion (KGC). However, current studies mostly apply LLMs to classification tasks, like identifying missing triplets, rather than ranking-based tasks, where the model ranks candidate entities based on plausibility. This focus limits the practical use of LLMs in KGC, as real-world applications prioritize highly plausible triplets. Additionally, while graph paths can help infer the existence of missing triplets and improve completion accuracy, they often contain redundant information. To address these issues, we propose KG-CF, a framework tailored for ranking-based KGC tasks. KG-CF leverages LLMs' reasoning abilities to filter out irrelevant contexts, achieving superior results on real-world datasets. The code and datasets are available at \url{this https URL}. 

**Abstract (ZH)**: 大的语言模型（LLMs）在各种任务中表现出了令人印象深刻的性能，包括知识图谱补全（KGC）。然而，当前的研究主要将LLMs应用于分类任务，例如识别缺失的三元组，而不是排名任务，在排名任务中，模型会根据可行性对候选实体进行排序。这种关注限制了LLMs在KGC中的实际应用，因为实际应用更倾向于选择高度可行的三元组。此外，尽管图路径可以帮助推断缺失三元组的存在性并提高补全的准确性，但它们往往包含冗余信息。为了应对这些问题，我们提出了KG-CF框架，该框架针对排名型KGC任务进行了专门设计。KG-CF利用LLMs的推理能力过滤掉无关的上下文，从而在实际数据集上取得了优异的结果。相关代码和数据集可在 \url{此链接} 获取。 

---
# Test-time Computing: from System-1 Thinking to System-2 Thinking 

**Title (ZH)**: 测试时计算：从直觉思维到反思思维 

**Authors**: Yixin Ji, Juntao Li, Hai Ye, Kaixin Wu, Jia Xu, Linjian Mo, Min Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02497)  

**Abstract**: The remarkable performance of the o1 model in complex reasoning demonstrates that test-time computing scaling can further unlock the model's potential, enabling powerful System-2 thinking. However, there is still a lack of comprehensive surveys for test-time computing scaling. We trace the concept of test-time computing back to System-1 models. In System-1 models, test-time computing addresses distribution shifts and improves robustness and generalization through parameter updating, input modification, representation editing, and output calibration. In System-2 models, it enhances the model's reasoning ability to solve complex problems through repeated sampling, self-correction, and tree search. We organize this survey according to the trend of System-1 to System-2 thinking, highlighting the key role of test-time computing in the transition from System-1 models to weak System-2 models, and then to strong System-2 models. We also point out a few possible future directions. 

**Abstract (ZH)**: o1模型在复杂推理中的卓越表现展示了测试时计算扩展能够进一步挖掘模型的潜力，使之具备强大的系统2级思考能力。然而，关于测试时计算扩展的研究综述仍然不足。我们回溯到系统1模型，探讨测试时计算的概念。在系统1模型中，测试时计算通过参数更新、输入修改、表示编辑和输出校正来应对分布偏移并提高鲁棒性和泛化能力。而在系统2模型中，测试时计算通过重复采样、自我纠正和树搜索来增强模型的推理能力，以解决复杂问题。我们根据从系统1思维到系统2思维的趋势组织了本次综述，突出了测试时计算在系统1模型向弱系统2模型过渡，再到强系统2模型这一转变过程中的关键作用。同时，我们也指出了几个可能的研究方向。 

---
# LLMPC: Large Language Model Predictive Control 

**Title (ZH)**: LLMPC: 大型语言模型预测控制 

**Authors**: Gabriel Maher  

**Link**: [PDF](https://arxiv.org/pdf/2501.02486)  

**Abstract**: Recent advancements in prompting techniques for Large Language Models (LLMs) have improved their reasoning, planning, and action abilities. This paper examines these prompting techniques through the lens of model predictive control (MPC). We show that LLMs act as implicit planning cost function minimizers when planning prompts are used. Under our framework we demonstrate that LLM planning performance can be improved further by incorporating real planning cost functions and evaluators. 

**Abstract (ZH)**: 近年来，针对大型语言模型（LLMs）的提示技术取得了进步，这些技术提高了它们的推理、规划和行动能力。本文通过模型预测控制（MPC）的视角考察了这些提示技术。我们表明，当使用规划提示时，LLMs实际上充当着隐含规划成本函数的最小化者。在我们提出的框架下，我们证明通过引入实际的规划成本函数和评估器，可以进一步提高LLMs的规划性能。 

---
# Enhancing Workplace Productivity and Well-being Using AI Agent 

**Title (ZH)**: 使用AI代理提升工作场所生产力与福祉 

**Authors**: Ravirajan K, Arvind Sundarajan  

**Link**: [PDF](https://arxiv.org/pdf/2501.02368)  

**Abstract**: This paper discusses the use of Artificial Intelligence (AI) to enhance workplace productivity and employee well-being. By integrating machine learning (ML) techniques with neurobiological data, the proposed approaches ensure alignment with human ethical standards through value alignment models and Hierarchical Reinforcement Learning (HRL) for autonomous task management. The system utilizes biometric feedback from employees to generate personalized health prompts, fostering a supportive work environment that encourages physical activity. Additionally, we explore decentralized multi-agent systems for improved collaboration and decision-making frameworks that enhance transparency. Various approaches using ML techniques in conjunction with AI implementations are discussed. Together, these innovations aim to create a more productive and health-conscious workplace. These outcomes assist HR management and organizations in launching more rational career progression streams for employees and facilitating organizational transformation. 

**Abstract (ZH)**: 本文探讨了利用人工智能（AI）提高工作效率和员工福祉的方法。通过将机器学习（ML）技术与神经生物学数据相结合，提出的方案通过价值对齐模型和分层强化学习（HRL）确保与人类伦理标准的契合。该系统利用员工的生物识别反馈生成个性化健康提示，营造一个支持性的工作环境，鼓励员工进行体育锻炼。此外，本文还探讨了去中心化的多智能体系统，以提高协作效率，并构建更加透明的决策框架。利用ML技术结合AI实施的各种方法进行了讨论。这些创新旨在创建一个更加高效和注重健康的职场环境。这些成果有助于人力资源管理和组织推动员工更加理性的职业发展路径，并促进组织的转型。 

---
# CORD: Generalizable Cooperation via Role Diversity 

**Title (ZH)**: CORD：通过角色多样性实现的可泛化合作 

**Authors**: Kanefumi Matsuyama, Kefan Su, Jiangxing Wang, Deheng Ye, Zongqing Lu  

**Link**: [PDF](https://arxiv.org/pdf/2501.02221)  

**Abstract**: Cooperative multi-agent reinforcement learning (MARL) aims to develop agents that can collaborate effectively. However, most cooperative MARL methods overfit training agents, making learned policies not generalize well to unseen collaborators, which is a critical issue for real-world deployment. Some methods attempt to address the generalization problem but require prior knowledge or predefined policies of new teammates, limiting real-world applications. To this end, we propose a hierarchical MARL approach to enable generalizable cooperation via role diversity, namely CORD. CORD's high-level controller assigns roles to low-level agents by maximizing the role entropy with constraints. We show this constrained objective can be decomposed into causal influence in role that enables reasonable role assignment, and role heterogeneity that yields coherent, non-redundant role clusters. Evaluated on a variety of cooperative multi-agent tasks, CORD achieves better performance than baselines, especially in generalization tests. Ablation studies further demonstrate the efficacy of the constrained objective in generalizable cooperation. 

**Abstract (ZH)**: 合作多智能体强化学习（MARL）旨在开发能够有效协作的智能体。然而，大多数合作MARL方法会导致训练智能体过拟合，使得学到的策略不能很好地泛化到未见过的合作者身上，这是实际部署中一个关键问题。一些方法试图解决泛化问题，但需要对新队友的先验知识或预定义策略，从而限制了实际应用。为了解决这一问题，我们提出了一种分层MARL方法，通过角色多样性来实现可泛化的合作，即CORD方法。CORD的高层控制器通过最大化角色熵（在某些约束条件下）为低层智能体分配角色。我们展示了这种带约束的目标可以分解为角色因果影响，这有助于合理地分配角色，并通过角色异质性生成一致且不冗余的角色簇。在多种合作多智能体任务上进行评估，CORD在性能上优于基准方法，特别是在泛化测试中表现更优。进一步的消融研究还证实了带约束目标在可泛化合作上的有效性。 

---
# Table as Thought: Exploring Structured Thoughts in LLM Reasoning 

**Title (ZH)**: 作为思考的表格：探究大模型推理中的结构化思维 

**Authors**: Zhenjie Sun, Naihao Deng, Haofei Yu, Jiaxuan You  

**Link**: [PDF](https://arxiv.org/pdf/2501.02152)  

**Abstract**: Large language models' reasoning abilities benefit from methods that organize their thought processes, such as chain-of-thought prompting, which employs a sequential structure to guide the reasoning process step-by-step. However, existing approaches focus primarily on organizing the sequence of thoughts, leaving structure in individual thought steps underexplored. To address this gap, we propose Table as Thought, a framework inspired by cognitive neuroscience theories on human thought. Table as Thought organizes reasoning within a tabular schema, where rows represent sequential thought steps and columns capture critical constraints and contextual information to enhance reasoning. The reasoning process iteratively populates the table until self-verification ensures completeness and correctness. Our experiments show that Table as Thought excels in planning tasks and demonstrates a strong potential for enhancing LLM performance in mathematical reasoning compared to unstructured thought baselines. This work provides a novel exploration of refining thought representation within LLMs, paving the way for advancements in reasoning and AI cognition. 

**Abstract (ZH)**: 大型语言模型的推理能力可以从组织其思维过程的方法中受益，例如链式思维提示（chain-of-thought prompting），该方法采用顺序结构逐步引导推理过程。然而，现有的方法主要侧重于组织思维的顺序，而忽视了个体思维步骤中的结构。为了解决这一问题，我们提出了一种名为“Table as Thought”的框架，该框架受到人类思维认知神经科学理论的启发。Table as Thought在表格模式下组织推理，其中行表示顺序的思维步骤，列则捕捉关键约束条件和上下文信息以增强推理。推理过程通过逐步填充表格，直至自我验证确保推理的完整性和正确性。我们的实验结果显示，与无结构思维基线相比，Table as Thought在规划任务方面表现优异，并展示了在数学推理方面显著提升大型语言模型性能的强大潜力。这项工作为改进大型语言模型中思维表示的新探索开辟了道路，为推理和人工智能认知的进步奠定了基础。 

---
# Disagree and Commit: Degrees of Argumentation-based Agreements 

**Title (ZH)**: 《辩论与承诺：基于论据的一致性程度》 

**Authors**: Timotheus Kampik, Juan Carlos Nieves  

**Link**: [PDF](https://arxiv.org/pdf/2501.01992)  

**Abstract**: In cooperative human decision-making, agreements are often not total; a partial degree of agreement is sufficient to commit to a decision and move on, as long as one is somewhat confident that the involved parties are likely to stand by their commitment in the future, given no drastic unexpected changes. In this paper, we introduce the notion of agreement scenarios that allow artificial autonomous agents to reach such agreements, using formal models of argumentation, in particular abstract argumentation and value-based argumentation. We introduce the notions of degrees of satisfaction and (minimum, mean, and median) agreement, as well as a measure of the impact a value in a value-based argumentation framework has on these notions. We then analyze how degrees of agreement are affected when agreement scenarios are expanded with new information, to shed light on the reliability of partial agreements in dynamic scenarios. An implementation of the introduced concepts is provided as part of an argumentation-based reasoning software library. 

**Abstract (ZH)**: 在合作的人类决策中，协议往往并不总是完全一致的；在一定程度上的共识就足以使决策者做出决定并继续前进，只要他们具有某种程度的信心，即参与各方在未来会遵守其承诺，只要没有重大的意外变化。本文中，我们引入了协议情景的概念，使人工自主代理能够利用形式化的论辩模型（特别是抽象论辩和基于价值的论辩）来达成这样的协议。我们引入了满意度度量以及（最小值、平均值和中位数）共识的概念，并提出了一种衡量基于价值的论辩框架中某一价值对这些概念影响的度量方法。然后，我们分析了当协议情景扩展到包含新信息时，满意度和共识如何受到影响，从而探讨动态场景中部分协议的可靠性。作为引入概念的应用，我们提供了一个基于论辩的推理软件库，其中包括了这些概念的实现。 

---
# Gaussian Masked Autoencoders 

**Title (ZH)**: 高斯掩蔽自编码器 

**Authors**: Jathushan Rajasegaran, Xinlei Chen, Rulilong Li, Christoph Feichtenhofer, Jitendra Malik, Shiry Ginosar  

**Link**: [PDF](https://arxiv.org/pdf/2501.03229)  

**Abstract**: This paper explores Masked Autoencoders (MAE) with Gaussian Splatting. While reconstructive self-supervised learning frameworks such as MAE learns good semantic abstractions, it is not trained for explicit spatial awareness. Our approach, named Gaussian Masked Autoencoder, or GMAE, aims to learn semantic abstractions and spatial understanding jointly. Like MAE, it reconstructs the image end-to-end in the pixel space, but beyond MAE, it also introduces an intermediate, 3D Gaussian-based representation and renders images via splatting. We show that GMAE can enable various zero-shot learning capabilities of spatial understanding (e.g., figure-ground segmentation, image layering, edge detection, etc.) while preserving the high-level semantics of self-supervised representation quality from MAE. To our knowledge, we are the first to employ Gaussian primitives in an image representation learning framework beyond optimization-based single-scene reconstructions. We believe GMAE will inspire further research in this direction and contribute to developing next-generation techniques for modeling high-fidelity visual data. More details at this https URL 

**Abstract (ZH)**: 本文探讨了掩码自编码器（MAE）与高斯点扩散相结合的应用。虽然诸如MAE这样的重建自监督学习框架能够学到良好的语义抽象，但它们并未专门训练以实现明确的空间意识。为此，我们提出了一种名为高斯掩码自编码器（GMAE）的方法，旨在联合学习语义抽象和空间理解。类似于MAE，GMAE能够在像素空间中端到端地重建图像，但在MAE的基础上，它还引入了一个中间的基于3D高斯的表示，并通过点扩散生成图像。我们展示了GMAE能够在保持MAE自监督表示质量的高级语义的同时，实现多种零样本学习能力的空间理解（例如，图底分割、图像层析、边缘检测等）。据我们所知，这是首次在图像表示学习框架中使用高斯原语，而不仅仅是基于优化的一景重建。我们相信，GMAE将启发进一步的研究，并为建模高保真视觉数据的下一代技术做出贡献。更多细节请参见<此链接>。 

---
# LightGNN: Simple Graph Neural Network for Recommendation 

**Title (ZH)**: LightGNN：简洁的图神经网络推荐算法 

**Authors**: Guoxuan Chen, Lianghao Xia, Chao Huang  

**Link**: [PDF](https://arxiv.org/pdf/2501.03228)  

**Abstract**: Graph neural networks (GNNs) have demonstrated superior performance in collaborative recommendation through their ability to conduct high-order representation smoothing, effectively capturing structural information within users' interaction patterns. However, existing GNN paradigms face significant challenges in scalability and robustness when handling large-scale, noisy, and real-world datasets. To address these challenges, we present LightGNN, a lightweight and distillation-based GNN pruning framework designed to substantially reduce model complexity while preserving essential collaboration modeling capabilities. Our LightGNN framework introduces a computationally efficient pruning module that adaptively identifies and removes redundant edges and embedding entries for model compression. The framework is guided by a resource-friendly hierarchical knowledge distillation objective, whose intermediate layer augments the observed graph to maintain performance, particularly in high-rate compression scenarios. Extensive experiments on public datasets demonstrate LightGNN's effectiveness, significantly improving both computational efficiency and recommendation accuracy. Notably, LightGNN achieves an 80% reduction in edge count and 90% reduction in embedding entries while maintaining performance comparable to more complex state-of-the-art baselines. The implementation of our LightGNN framework is available at the github repository: this https URL. 

**Abstract (ZH)**: 图神经网络（GNNs）在协作推荐中表现出优越的性能，这是由于它们能够进行高阶表示平滑，从而有效地捕捉用户交互模式中的结构信息。然而，现有的GNN范式在处理大规模、噪声和真实世界的数据集时面临着显著的可扩展性和鲁棒性挑战。为了解决这些问题，我们提出了LightGNN，这是一种轻量级且基于蒸馏的GNN剪枝框架，旨在大幅减少模型复杂性的同时保留关键的协作建模能力。LightGNN框架引入了一个计算高效的剪枝模块，该模块能够自适应地识别并移除冗余的边和嵌入项，以实现模型压缩。该框架由一个资源友好的分层知识蒸馏目标引导，其中间层通过对图进行增强来维持性能，尤其是在高压缩率场景中。在公开数据集上的广泛实验表明，LightGNN在提高计算效率和推荐精度方面具有显著效果。值得注意的是，LightGNN在保持性能与更复杂的状态最先进基线相当的情况下，实现了边数减少80%和嵌入项减少90%。我们的LightGNN框架的实现可在这里的GitHub仓库中获得：this https URL。 

---
# BoostStep: Boosting mathematical capability of Large Language Models via improved single-step reasoning 

**Title (ZH)**: BoostStep: 通过提升单步推理能力增强大型语言模型的数学能力 

**Authors**: Beichen Zhang, Yuhong Liu, Xiaoyi Dong, Yuhang Zang, Pan Zhang, Haodong Duan, Yuhang Cao, Dahua Lin, Jiaqi Wang  

**Link**: [PDF](https://arxiv.org/pdf/2501.03226)  

**Abstract**: Cutting-edge large language models (LLMs) demonstrate promising performance in solving complex math problems with a divide-and-conquer pipeline and the assistance of in-context learning (ICL) examples. However, their potential for improvement is limited by two critical problems within their ICL examples: granularity-mismatch and the ensuing negative-effect noise problem. Specifically, the LLMs are capable of the dividing process yet mostly failed by inaccurate reasoning within a few conquer steps, while the ICL examples retrieved in question-grained sometimes lack relevant steps for a specific challenging reasoning step. Further, this disconnect may hinder the correct reasoning due to its irrelevance. To this end, we focus on improving the reasoning quality within each step and present BoostStep. BoostStep aligns the granularity between the retrieving and reasoning on step grained, and provides highly related ICL examples for each reasoning step with a novel `first-try' strategy. BoostStep provides more relevant examples than the coarse question-grained strategy, enhancing the model reasoning quality within each step steadily. BoostStep is a general and robust reasoning-enhancing method that not only improves standalone reasoning performance but also integrates seamlessly with Monte Carlo Tree Search methods (MCTS) to refine both candidate generation and decision-making. Quantitatively, it improves GPT-4o and Qwen2.5-Math-72B by 3.6\% and 2.0\% respectively on various mathematical benchmarks, and 7.5\% gain combined with MCTS. 

**Abstract (ZH)**: 尖端的大规模语言模型（LLMs）在采用分而治之的管道和上下文学习（ICL）示例辅助的情况下，显示出解决复杂数学问题的前景。然而，它们在改进方面的潜力受到ICL示例中两个关键问题的限制：粒度不匹配和随后产生的负效噪音问题。具体来说，LLMs能够执行拆分过程，但在几步征服策略中往往因不准确的推理而失败。此外，在问题粒度下检索到的ICL示例有时缺乏针对特定具有挑战性的推理步骤的相关步骤，这种不相关性可能会阻碍正确的推理。因此，我们致力于提高每一步推理的质量，并提出了BoostStep。BoostStep在步骤粒度上对检索和推理进行对齐，并为每一步推理提供高度相关的ICL示例，采用一个新的“初次尝试”策略。BoostStep提供了比粗略的问题粒度策略更多的相关示例，逐步提升模型在每一步的推理质量。BoostStep是一个通用且稳健的推理增强方法，不仅可以提高独立推理能力，还可以无缝集成蒙特卡洛树搜索方法（MCTS），以细化候选生成和决策制定过程。定量上，BoostStep分别将GPT-4o和Qwen2.5-Math-72B在各种数学基准上的性能提高了3.6%和2.0%，结合MCTS后，综合改进达到7.5%。 

---
# Automated Generation of Challenging Multiple-Choice Questions for Vision Language Model Evaluation 

**Title (ZH)**: 面向视觉语言模型评估的具有挑战性的多项选择题自动化生成 

**Authors**: Yuhui Zhang, Yuchang Su, Yiming Liu, Xiaohan Wang, James Burgess, Elaine Sui, Chenyu Wang, Josiah Aklilu, Alejandro Lozano, Anjiang Wei, Ludwig Schmidt, Serena Yeung-Levy  

**Link**: [PDF](https://arxiv.org/pdf/2501.03225)  

**Abstract**: The rapid development of vision language models (VLMs) demands rigorous and reliable evaluation. However, current visual question answering (VQA) benchmarks often depend on open-ended questions, making accurate evaluation difficult due to the variability in natural language responses. To address this, we introduce AutoConverter, an agentic framework that automatically converts these open-ended questions into multiple-choice format, enabling objective evaluation while reducing the costly question creation process. Our experiments demonstrate that AutoConverter can generate correct and challenging multiple-choice questions, with VLMs demonstrating consistently similar or lower accuracy on these questions compared to human-created ones. Using AutoConverter, we construct VMCBench, a benchmark created by transforming 20 existing VQA datasets into a unified multiple-choice format, totaling 9,018 questions. We comprehensively evaluate 33 state-of-the-art VLMs on VMCBench, setting a new standard for scalable, consistent, and reproducible VLM evaluation. 

**Abstract (ZH)**: 视觉语言模型（VLMs）的快速发展需要严格的可靠评估。然而，当前的视觉问答（VQA）基准往往依赖于开放式问题，由于自然语言回答的多样性，准确评估变得困难。为解决这一问题，我们引入了AutoConverter，这是一种自主框架，能够自动将开放式问题转换为多项选择格式，从而实现客观评估，并减少成本高昂的问题创建过程。实验结果表明，AutoConverter生成的多项选择问题既正确又具有挑战性，视觉语言模型在这些问题上的准确率与人工创建的问题相当或较低。使用AutoConverter，我们构建了VMCBench，这是一个通过将20个现有的VQA数据集统一转换为多项选择格式而创建的基准，总共包含9,018个问题。我们在VMCBench上全面评估了33个最先进的视觉语言模型，为大规模、一致性和可重复性视觉语言模型评估设立了新的标准。 

---
# Detecting AI-Generated Text in Educational Content: Leveraging Machine Learning and Explainable AI for Academic Integrity 

**Title (ZH)**: 检测教育内容中的AI生成文本：利用机器学习和可解释AI维护学术诚信 

**Authors**: Ayat A. Najjar, Huthaifa I. Ashqar, Omar A. Darwish, Eman Hammad  

**Link**: [PDF](https://arxiv.org/pdf/2501.03203)  

**Abstract**: This study seeks to enhance academic integrity by providing tools to detect AI-generated content in student work using advanced technologies. The findings promote transparency and accountability, helping educators maintain ethical standards and supporting the responsible integration of AI in education. A key contribution of this work is the generation of the CyberHumanAI dataset, which has 1000 observations, 500 of which are written by humans and the other 500 produced by ChatGPT. We evaluate various machine learning (ML) and deep learning (DL) algorithms on the CyberHumanAI dataset comparing human-written and AI-generated content from Large Language Models (LLMs) (i.e., ChatGPT). Results demonstrate that traditional ML algorithms, specifically XGBoost and Random Forest, achieve high performance (83% and 81% accuracies respectively). Results also show that classifying shorter content seems to be more challenging than classifying longer content. Further, using Explainable Artificial Intelligence (XAI) we identify discriminative features influencing the ML model's predictions, where human-written content tends to use a practical language (e.g., use and allow). Meanwhile AI-generated text is characterized by more abstract and formal terms (e.g., realm and employ). Finally, a comparative analysis with GPTZero show that our narrowly focused, simple, and fine-tuned model can outperform generalized systems like GPTZero. The proposed model achieved approximately 77.5% accuracy compared to GPTZero's 48.5% accuracy when tasked to classify Pure AI, Pure Human, and mixed class. GPTZero showed a tendency to classify challenging and small-content cases as either mixed or unrecognized while our proposed model showed a more balanced performance across the three classes. 

**Abstract (ZH)**: 本研究旨在通过提供工具来检测学生作品中的人工智能生成内容，从而提高学术诚信。通过使用先进技术，研究成果增强了透明度和责任感，帮助教育者维护道德标准，并支持人工智能在教育中的负责任整合。本研究的一个重要贡献是生成了CyberHumanAI数据集，该数据集包含1000个观测样本，其中500个由人类撰写，另外500个由ChatGPT生成。我们对CyberHumanAI数据集中的内容进行了各种机器学习（ML）和深度学习（DL）算法的评估，比较了由大型语言模型（LLM，如ChatGPT）生成的人工智能生成内容与人类撰写的作文。结果表明，传统的机器学习算法，特别是XGBoost和随机森林，表现出色（准确性分别为83%和81%）。结果还显示，分类较短的内容似乎比分类较长的内容更具挑战性。进一步使用可解释的人工智能（XAI）技术，我们识别出影响机器学习模型预测的决定性特征：人类撰写的文本倾向于使用实用语言（例如，“使用”和“允许”），而人工智能生成的文本则更多地使用抽象和正式的词汇（例如，“领域”和“使用”）。最后，与GPTZero进行对比分析表明，我们提出的窄焦点、简单且微调的模型可以在分类纯AI、纯人类和混合类别的任务中优于泛化系统GPTZero。我们提出的模型在分类任务中的准确率为约77.5%，而GPTZero的准确率仅为48.5%。GPTZero在处理具有挑战性和较短内容的案例时倾向于将其分类为混合或未识别类，而我们提出的模型则在三个类别中展现出更均衡的性能。 

---
# Classifier-Guided Captioning Across Modalities 

**Title (ZH)**: 跨模态的分类器引导式描述生成 

**Authors**: Ariel Shaulov, Tal Shaharabany, Eitan Shaar, Gal Chechik, Lior Wolf  

**Link**: [PDF](https://arxiv.org/pdf/2501.03183)  

**Abstract**: Most current captioning systems use language models trained on data from specific settings, such as image-based captioning via Amazon Mechanical Turk, limiting their ability to generalize to other modality distributions and contexts. This limitation hinders performance in tasks like audio or video captioning, where different semantic cues are needed. Addressing this challenge is crucial for creating more adaptable and versatile captioning frameworks applicable across diverse real-world contexts. In this work, we introduce a method to adapt captioning networks to the semantics of alternative settings, such as capturing audibility in audio captioning, where it is crucial to describe sounds and their sources. Our framework consists of two main components: (i) a frozen captioning system incorporating a language model (LM), and (ii) a text classifier that guides the captioning system. The classifier is trained on a dataset automatically generated by GPT-4, using tailored prompts specifically designed to enhance key aspects of the generated captions. Importantly, the framework operates solely during inference, eliminating the need for further training of the underlying captioning model. We evaluate the framework on various models and modalities, with a focus on audio captioning, and report promising results. Notably, when combined with an existing zero-shot audio captioning system, our framework improves its quality and sets state-of-the-art performance in zero-shot audio captioning. 

**Abstract (ZH)**: 目前大多数图像字幕系统都是基于特定数据集进行训练的语言模型，例如通过亚马逊MEchanical Turk进行图像字幕训练，这限制了它们在处理其他模态分布和背景下泛化的能力。这种局限性阻碍了在音频或视频字幕等任务中的性能表现，因为这些任务需要不同的语义线索。解决这一挑战对于创建更适应和多功能的字幕框架至关重要，这些框架可以在多种现实场景中适用。在这项工作中，我们提出了一种方法，将字幕网络适应其他语境的语义，例如在音频字幕中捕捉可听性，其中准确描述声音及其来源至关重要。我们的框架主要由两个部分组成：（i）一个冻结的字幕系统，其中包括一个语言模型（LM），以及（ii）一个文本分类器，该分类器指导字幕系统。分类器是通过GPT-4自动生成的数据集进行训练的，使用特定设计的提示以增强生成字幕的关键方面。重要的是，该框架仅在推理阶段运行，无需对基础字幕模型进行进一步训练。我们在多种模型和模态下评估了该框架，重点关注音频字幕，并报告了令人鼓舞的结果。值得注意的是，当与现有的零样本音频字幕系统结合使用时，我们的框架提高了其质量，并在零样本音频字幕性能上设立了新记录。 

---
# Boosting Explainability through Selective Rationalization in Pre-trained Language Models 

**Title (ZH)**: 通过选择性合理化增强预训练语言模型的解释性 

**Authors**: Libing Yuan, Shuaibo Hu, Kui Yu, Le Wu  

**Link**: [PDF](https://arxiv.org/pdf/2501.03182)  

**Abstract**: The widespread application of pre-trained language models (PLMs) in natural language processing (NLP) has led to increasing concerns about their explainability. Selective rationalization is a self-explanatory framework that selects human-intelligible input subsets as rationales for predictions. Recent studies have shown that applying existing rationalization frameworks to PLMs will result in severe degeneration and failure problems, producing sub-optimal or meaningless rationales. Such failures severely damage trust in rationalization methods and constrain the application of rationalization techniques on PLMs. In this paper, we find that the homogeneity of tokens in the sentences produced by PLMs is the primary contributor to these problems. To address these challenges, we propose a method named Pre-trained Language Model's Rationalization (PLMR), which splits PLMs into a generator and a predictor to deal with NLP tasks while providing interpretable rationales. The generator in PLMR also alleviates homogeneity by pruning irrelevant tokens, while the predictor uses full-text information to standardize predictions. Experiments conducted on two widely used datasets across multiple PLMs demonstrate the effectiveness of the proposed method PLMR in addressing the challenge of applying selective rationalization to PLMs. Codes: this https URL. 

**Abstract (ZH)**: 预训练语言模型（PLMs）在自然语言处理（NLP）中的广泛应用引发了对其可解释性的不断增加的关注。选择性理性化是一种自解释框架，该框架选择人类可理解的输入子集作为预测的理由。近期研究表明，将现有的理性化框架应用于PLMs会导致严重的退化和失败问题，产生次优或无意义的理由。这些失败严重损害了理性化方法的信任度，并限制了理性化技术在PLMs中的应用。本文发现，PLMs生成的句子中令牌的同质性是导致这些问题的主要原因。为了解决这一挑战，我们提出了一种名为预训练语言模型理性化（PLMR）的方法，该方法将PLMs划分为生成器和预测器，以处理NLP任务并提供可解释的理由。PLMR中的生成器还通过修剪无关的令牌来缓解同质性，而预测器则利用全文信息来标准化预测。在多个PLMs上广泛使用的两个数据集进行的实验表明，所提出的方法PLMR在将选择性理性化应用于PLMs时具有有效性。代码：见此链接。 

---
# FaceSpeak: Expressive and High-Quality Speech Synthesis from Human Portraits of Different Styles 

**Title (ZH)**: FaceSpeak：不同风格的人像驱动高保真语音合成 

**Authors**: Tian-Hao Zhang, Jiawei Zhang, Jun Wang, Xinyuan Qian, Xu-Cheng Yin  

**Link**: [PDF](https://arxiv.org/pdf/2501.03181)  

**Abstract**: Humans can perceive speakers' characteristics (e.g., identity, gender, personality and emotion) by their appearance, which are generally aligned to their voice style. Recently, vision-driven Text-to-speech (TTS) scholars grounded their investigations on real-person faces, thereby restricting effective speech synthesis from applying to vast potential usage scenarios with diverse characters and image styles. To solve this issue, we introduce a novel FaceSpeak approach. It extracts salient identity characteristics and emotional representations from a wide variety of image styles. Meanwhile, it mitigates the extraneous information (e.g., background, clothing, and hair color, etc.), resulting in synthesized speech closely aligned with a character's persona. Furthermore, to overcome the scarcity of multi-modal TTS data, we have devised an innovative dataset, namely Expressive Multi-Modal TTS, which is diligently curated and annotated to facilitate research in this domain. The experimental results demonstrate our proposed FaceSpeak can generate portrait-aligned voice with satisfactory naturalness and quality. 

**Abstract (ZH)**: 人类可以通过面部特征感知说话人的特性（如身份、性别、个性和情绪），而这些面部特征通常与声音风格相一致。近年来，基于视觉的文本到语音（TTS）研究者将研究重心放在了真实人物的面部上，这限制了有效的语音合成在多样人物和图像风格的广泛潜在应用场景中的应用。为解决这一问题，我们提出了一种名为FaceSpeak的新颖方法。该方法可以从各种图像风格中提取出显著的身份特征和情绪表示，同时减少背景、服饰、发色等无关信息的影响，从而使合成语音与人物个性高度一致。此外，为克服多模态TTS数据不足的问题，我们设计了一个创新的数据集，名为Expressive Multi-Modal TTS，并严格进行了整理和标注，以促进该领域的研究。实验结果表明，我们提出的FaceSpeak能够生成与肖像高度一致的、自然度和质量均较高的语音。 

---
# GLiREL -- Generalist Model for Zero-Shot Relation Extraction 

**Title (ZH)**: GLiREL -- 通用模型在零样本关系提取中的应用 

**Authors**: Jack Boylan, Chris Hokamp, Demian Gholipour Ghalandari  

**Link**: [PDF](https://arxiv.org/pdf/2501.03172)  

**Abstract**: We introduce GLiREL (Generalist Lightweight model for zero-shot Relation Extraction), an efficient architecture and training paradigm for zero-shot relation classification. Inspired by recent advancements in zero-shot named entity recognition, this work presents an approach to efficiently and accurately predict zero-shot relationship labels between multiple entities in a single forward pass. Experiments using the FewRel and WikiZSL benchmarks demonstrate that our approach achieves state-of-the-art results on the zero-shot relation classification task. In addition, we contribute a protocol for synthetically-generating datasets with diverse relation labels. 

**Abstract (ZH)**: 我们介绍了一种名为GLiREL（通用轻量级零样本关系抽取模型）的有效架构和训练范式，用于零样本关系分类。受近期零样本命名实体识别进展的启发，本文提出了一种方法，在单次前向传播过程中高效且准确地预测多个实体之间的零样本关系标签。使用FewRel和WikiZSL基准实验表明，我们的方法在零样本关系分类任务中实现了最先进的结果。此外，我们还贡献了一种合成生成具有多元关系标签数据集的协议。 

---
# The Scaling Law for LoRA Base on Mutual Information Upper Bound 

**Title (ZH)**: 基于互信息上界的LoRA缩放定律 

**Authors**: Jing Zhang, Hui Gao, Peng Zhang, Shuzhen Sun, Chang Yang, Yuexian Hou  

**Link**: [PDF](https://arxiv.org/pdf/2501.03152)  

**Abstract**: LoRA (Low-Rank Adaptation) is a widely used model fine-tuning method. In fine-tuning, the law among model performance, model parameters, and data complexity has been a focal issue in the field. Existing methods often leverage external metrics (such as cross-entropy or perplexity) to evaluate model performance. In the fine-tuning process for large models, two types of knowledge are typically involved: the frozen, general knowledge acquired by the model during pre-training and the new knowledge learned through the LoRA module from the current data. Generally, the less LoRA's learned knowledge relies on the large model, the more it captures the specific knowledge of new data, thereby enhancing its adaptability to new tasks. However, external metrics do not readily capture the dependency relationship between these two types of knowledge. Therefore, we designed an internal metric based on the Mutual Information Upper Bound (MIUB) theory to investigate the scaling law of large-model LoRA fine-tuning. In our experiments, we validated this approach on benchmark datasets, using the Llama3-8B and Phi3-3B models. The results show that the proposed MIUB metric aligns more accurately and stably with the scaling law of LoRA fine-tuning compared to cross-entropy and perplexity. 

**Abstract (ZH)**: LoRA（低秩适应）是一种广泛使用的模型微调方法。在模型微调过程中，模型性能、模型参数和数据复杂度之间的关系一直是研究领域的重点问题。现有方法通常依赖于外部指标（如交叉熵或困惑度）来评估模型性能。在大型模型的微调过程中，通常涉及两种知识：模型在预训练阶段获得的冻结的通用知识以及通过LoRA模块从当前数据中学习到的新知识。一般来说，LoRA学习到的知识依赖于大型模型程度越低，其捕捉到的新数据的特定知识越多，从而提高其对新任务的适应性。然而，外部指标难以捕捉这两种知识之间的依赖关系。因此，我们根据互信息上界（MIUB）理论设计了一个内部指标，以研究大型模型LoRA微调的标度定律。在我们的实验中，我们使用Llama3-8B和Phi3-3B模型在基准数据集上验证了这一方法。结果表明，提出的MIUB指标在描述LoRA微调的标度定律方面比交叉熵和困惑度更为准确和稳定。 

---
# Geometry Restoration and Dewarping of Camera-Captured Document Images 

**Title (ZH)**: 相机拍摄文档图像的几何修复与非线性校正 

**Authors**: Valery Istomin, Oleg Pereziabov, Ilya Afanasyev  

**Link**: [PDF](https://arxiv.org/pdf/2501.03145)  

**Abstract**: This research focuses on developing a method for restoring the topology of digital images of paper documents captured by a camera, using algorithms for detection, segmentation, geometry restoration, and dewarping. Our methodology employs deep learning (DL) for document outline detection, followed by computer vision (CV) to create a topological 2D grid using cubic polynomial interpolation and correct nonlinear distortions by remapping the image. Using classical CV methods makes the document topology restoration process more efficient and faster, as it requires significantly fewer computational resources and memory. We developed a new pipeline for automatic document dewarping and reconstruction, along with a framework and annotated dataset to demonstrate its efficiency. Our experiments confirm the promise of our methodology and its superiority over existing benchmarks (including mobile apps and popular DL solutions, such as RectiNet, DocGeoNet, and DocTr++) both visually and in terms of document readability via Optical Character Recognition (OCR) and geometry restoration metrics. This paves the way for creating high-quality digital copies of paper documents and enhancing the efficiency of OCR systems. Project page: this https URL 

**Abstract (ZH)**: 本研究专注于利用检测、分割、几何恢复和去卷曲算法开发一种方法，以恢复通过相机捕获的纸文档数字图像的拓扑结构。我们的方法利用深度学习（DL）进行文档轮廓检测，随后使用计算机视觉（CV）技术通过三次多项式插值生成拓扑二维网格，并通过重新映射图像来纠正非线性失真。经典CV方法使得文档拓扑结构恢复过程更加高效快速，因为它需要较少的计算资源和内存。我们开发了一种新的自动文档去卷曲和重建管道，以及一个框架和标注数据集，以展示其效率。我们的实验证实了该方法的前景及其在视觉效果和文档可读性（通过光学字符识别（OCR）和几何恢复指标）方面的优越性，超过了现有基准（包括移动应用和流行的DL解决方案，如RectiNet、DocGeoNet和DocTr++）。这为创建高质量的纸文档数字副本和提高OCR系统的效率开辟了道路。

项目页面：[这里](this https URL) 

---
# PRMBench: A Fine-grained and Challenging Benchmark for Process-Level Reward Models 

**Title (ZH)**: PRMBench：一个细粒度且具有挑战性的过程级奖励模型基准测试 

**Authors**: Mingyang Song, Zhaochen Su, Xiaoye Qu, Jiawei Zhou, Yu Cheng  

**Link**: [PDF](https://arxiv.org/pdf/2501.03124)  

**Abstract**: Process-level Reward Models (PRMs) are crucial for complex reasoning and decision-making tasks, where each intermediate step plays an important role in the reasoning process. Since language models are prone to various types of errors during the reasoning process, PRMs are required to possess nuanced capabilities for detecting various implicit error types in real-world scenarios. However, current benchmarks primarily focus on step correctness, failing to evaluate PRMs' performance systematically. To address this gap, we introduce PRMBench, a process-level benchmark specifically designed to assess the fine-grained error detection capabilities of PRMs. PRMBench comprises 6,216 carefully designed problems and 83,456 step-level labels, evaluating models across multiple dimensions, including simplicity, soundness, and sensitivity. In our experiments on 15 models, spanning both open-source PRMs and closed-source large language models prompted as critic models, we uncover significant weaknesses in current PRMs. These findings underscore the challenges inherent in process-level evaluation and highlight key directions for future research. We hope PRMBench can be a robust bench for advancing research on PRM evaluation and development. 

**Abstract (ZH)**: 过程级奖励模型（PRMs）对于复杂的推理和决策任务至关重要，因为每一中间步骤在推理过程中都扮演着重要角色。由于语言模型在推理过程中容易出现各种类型的错误，因此PRMs需要具备在实际场景中检测各种隐含错误类型的细腻能力。然而，当前的基准主要集中在步骤的正确性上，未能系统地评估PRMs的性能。为了弥补这一差距，我们引入了PRMBench，这是一种专门设计来评估PRMs细粒度错误检测能力的过程级基准。PRMBench包含6,216个精心设计的问题和83,456个步骤级标签，从多个维度评估模型，包括简洁性、严谨性和敏感性。在对15个模型进行的实验中，涵盖了开源普适推理模型和作为评论模型的封闭源大型语言模型，我们发现了当前PRMs中的一些显著弱点。这些发现突出了过程级评估中固有的挑战，并指出了未来研究的关键方向。我们希望PRMBench能够成为一个强大的基准，推进PRM评估和开发的研究。 

---
# From Models to Network Topologies: A Topology Inference Attack in Decentralized Federated Learning 

**Title (ZH)**: 从模型到网络拓扑：去中心化联邦学习中的拓扑推理攻击 

**Authors**: Chao Feng, Yuanzhe Gao, Alberto Huertas Celdran, Gerome Bovet, Burkhard Stiller  

**Link**: [PDF](https://arxiv.org/pdf/2501.03119)  

**Abstract**: Federated Learning (FL) is widely recognized as a privacy-preserving machine learning paradigm due to its model-sharing mechanism that avoids direct data exchange. However, model training inevitably leaves exploitable traces that can be used to infer sensitive information. In Decentralized FL (DFL), the overlay topology significantly influences its models' convergence, robustness, and security. This study explores the feasibility of inferring the overlay topology of DFL systems based solely on model behavior, introducing a novel Topology Inference Attack. A taxonomy of topology inference attacks is proposed, categorizing them by the attacker's capabilities and knowledge. Practical attack strategies are developed for different scenarios, and quantitative experiments are conducted to identify key factors influencing the attack effectiveness. Experimental results demonstrate that analyzing only the public models of individual nodes can accurately infer the DFL topology, underscoring the risk of sensitive information leakage in DFL systems. This finding offers valuable insights for improving privacy preservation in decentralized learning environments. 

**Abstract (ZH)**: 联邦学习（FL）因其模型共享机制而广泛被认为是保护隐私的机器学习范式，因为它避免了直接的数据交换。然而，模型训练不可避免地会产生可利用的踪迹，这些踪迹可以用于推断敏感信息。在去中心化联邦学习（DFL）中，覆盖拓扑对模型的收敛性、鲁棒性和安全性有显著影响。本研究探讨了仅基于模型行为推断DFL系统覆盖拓扑可行性的可能性，提出了拓扑推断攻击的新颖方法。提出了一种拓扑推断攻击分类法，按照攻击者的能力和知识对攻击进行分类。针对不同的场景开发了实际的攻击策略，并进行了定量实验以确定影响攻击效果的关键因素。实验结果表明，仅分析个体节点的公共模型即可准确推断DFL拓扑，突显了DFL系统中敏感信息泄漏的风险。这一发现为提高去中心化学习环境中的隐私保护提供了宝贵的见解。 

---
# LangFair: A Python Package for Assessing Bias and Fairness in Large Language Model Use Cases 

**Title (ZH)**: LangFair: 一个评估大型语言模型使用中偏见与公平性的Python软件包 

**Authors**: Dylan Bouchard, Mohit Singh Chauhan, David Skarbrevik, Viren Bajaj, Zeya Ahmad  

**Link**: [PDF](https://arxiv.org/pdf/2501.03112)  

**Abstract**: Large Language Models (LLMs) have been observed to exhibit bias in numerous ways, potentially creating or worsening outcomes for specific groups identified by protected attributes such as sex, race, sexual orientation, or age. To help address this gap, we introduce LangFair, an open-source Python package that aims to equip LLM practitioners with the tools to evaluate bias and fairness risks relevant to their specific use cases. The package offers functionality to easily generate evaluation datasets, comprised of LLM responses to use-case-specific prompts, and subsequently calculate applicable metrics for the practitioner's use case. To guide in metric selection, LangFair offers an actionable decision framework. 

**Abstract (ZH)**: 大规模语言模型（LLMs）在多种方式上显示出偏见的迹象，这可能会为基于受保护特征（如性别、种族、性取向或年龄）识别的具体群体创造出或加剧不利结果。为了应对这一问题，我们引入了LangFair，这是一个开源的Python包，旨在为LLM从业人员提供评估与其特定应用场景相关的偏见和公平性风险的工具。该包提供了轻松生成评价数据集的功能，这些数据集由LLM对特定应用场景的提示响应组成，并随后计算适用的评估指标。为了指导指标选择，LangFair提供了一个可操作的决策框架。 

---
# Personalized Fashion Recommendation with Image Attributes and Aesthetics Assessment 

**Title (ZH)**: 基于图像属性和 aesthetics 评价的个性化时尚推荐 

**Authors**: Chongxian Chen, Fan Mo, Xin Fan, Hayato Yamana  

**Link**: [PDF](https://arxiv.org/pdf/2501.03085)  

**Abstract**: Personalized fashion recommendation is a difficult task because 1) the decisions are highly correlated with users' aesthetic appetite, which previous work frequently overlooks, and 2) many new items are constantly rolling out that cause strict cold-start problems in the popular identity (ID)-based recommendation methods. These new items are critical to recommend because of trend-driven consumerism. In this work, we aim to provide more accurate personalized fashion recommendations and solve the cold-start problem by converting available information, especially images, into two attribute graphs focusing on optimized image utilization and noise-reducing user modeling. Compared with previous methods that separate image and text as two components, the proposed method combines image and text information to create a richer attributes graph. Capitalizing on the advancement of large language and vision models, we experiment with extracting fine-grained attributes efficiently and as desired using two different prompts. Preliminary experiments on the IQON3000 dataset have shown that the proposed method achieves competitive accuracy compared with baselines. 

**Abstract (ZH)**: 个性化时尚推荐是一个艰巨的任务，因为1) 这些决策高度依赖用户的审美偏好，而此前的研究常常忽略了这一点；2) 不断涌现的新品会导致基于用户ID的传统推荐方法出现严重的冷启动问题。由于受到流行趋势的影响，这些新品非常关键。本文旨在通过将可用信息，尤其是图像信息，转化为两个属性图来提供更准确的个性化时尚推荐，并解决冷启动问题。该方法重点优化了图像利用和噪声减少的用户建模。与此前将图像和文本分离处理的方法不同，本方法结合了图像和文本信息，构建了一个更丰富的属性图。借助大规模语言和视觉模型的最新进展，我们实验性地利用两种不同的提示高效、灵活地提取细微的区别特征。初步实验表明，所提出的方法在IQON3000数据集上的准确性与基准方法相当。 

---
# Through-The-Mask: Mask-based Motion Trajectories for Image-to-Video Generation 

**Title (ZH)**: 通过口罩：基于口罩的姿态轨迹生成图像到视频转换 

**Authors**: Guy Yariv, Yuval Kirstain, Amit Zohar, Shelly Sheynin, Yaniv Taigman, Yossi Adi, Sagie Benaim, Adam Polyak  

**Link**: [PDF](https://arxiv.org/pdf/2501.03059)  

**Abstract**: We consider the task of Image-to-Video (I2V) generation, which involves transforming static images into realistic video sequences based on a textual description. While recent advancements produce photorealistic outputs, they frequently struggle to create videos with accurate and consistent object motion, especially in multi-object scenarios. To address these limitations, we propose a two-stage compositional framework that decomposes I2V generation into: (i) An explicit intermediate representation generation stage, followed by (ii) A video generation stage that is conditioned on this representation. Our key innovation is the introduction of a mask-based motion trajectory as an intermediate representation, that captures both semantic object information and motion, enabling an expressive but compact representation of motion and semantics. To incorporate the learned representation in the second stage, we utilize object-level attention objectives. Specifically, we consider a spatial, per-object, masked-cross attention objective, integrating object-specific prompts into corresponding latent space regions and a masked spatio-temporal self-attention objective, ensuring frame-to-frame consistency for each object. We evaluate our method on challenging benchmarks with multi-object and high-motion scenarios and empirically demonstrate that the proposed method achieves state-of-the-art results in temporal coherence, motion realism, and text-prompt faithfulness. Additionally, we introduce \benchmark, a new challenging benchmark for single-object and multi-object I2V generation, and demonstrate our method's superiority on this benchmark. Project page is available at this https URL. 

**Abstract (ZH)**: 我们将研究图像到视频（I2V）生成任务，该任务涉及根据文本描述将静态图像转换为逼真的视频序列。尽管最近的进步能够生成照片级的输出，但在多对象场景中，它们经常难以生成准确且一致的对象运动的视频。为了克服这些限制，我们提出了一种两阶段合成框架，该框架将I2V生成分解为：（i）一个显式的中间表示生成阶段，随后是（ii）一个基于该表示的视频生成阶段。我们的创新之处在于引入了一种基于掩码的运动轨迹作为中间表示，该表示既捕捉了语义对象信息又捕捉了运动，从而提供了一个既富有表现力又紧凑的运动和语义表示。为了在第二阶段中利用学习到的表示，我们采用了对象级注意目标。具体来说，我们考虑了一个基于空间、针对每个对象的掩码交叉注意目标，将对象特定的提示整合到相应的潜在空间区域中，并引入了一个遮罩的空间-时间自注意目标，以确保每个对象在帧到帧之间的一致性。我们在具有多对象和高运动场景的具有挑战性的基准上评估了我们的方法，并通过实验证明，所提出的方法在时间连贯性、运动真实性和文本提示一致性方面达到了最先进的性能。此外，我们引入了Benchmark，这是一种新的具有挑战性的基准，专用于单对象和多对象的I2V生成，并在该基准上展示了我们方法的优越性。项目页面可通过此链接访问：[项目页面链接]。 

---
# Survival Analysis Revisited: Understanding and Unifying Poisson, Exponential, and Cox Models in Fall Risk Analysis 

**Title (ZH)**: 生存分析再探：理解并统一泊松、指数和科克伦模型在跌倒风险分析中的应用 

**Authors**: Tianhua Chen  

**Link**: [PDF](https://arxiv.org/pdf/2501.03058)  

**Abstract**: This paper explores foundational and applied aspects of survival analysis, using fall risk assessment as a case study. It revisits key time-related probability distributions and statistical methods, including logistic regression, Poisson regression, Exponential regression, and the Cox Proportional Hazards model, offering a unified perspective on their relationships within the survival analysis framework. A contribution of this work is the step-by-step derivation and clarification of the relationships among these models, particularly demonstrating that Poisson regression in the survival context is a specific case of the Cox model. These insights address gaps in understanding and reinforce the simplicity and interpretability of survival models. The paper also emphasizes the practical utility of survival analysis by connecting theoretical insights with real-world applications. In the context of fall detection, it demonstrates how these models can simultaneously predict fall risk, analyze contributing factors, and estimate time-to-event outcomes within a single streamlined framework. In contrast, advanced deep learning methods often require complex post-hoc interpretation and separate training for different tasks particularly when working with structured numerical data. This highlights the enduring relevance of classical statistical frameworks and makes survival models especially valuable in healthcare settings, where explainability and robustness are critical. By unifying foundational concepts and offering a cohesive perspective on time-to-event analysis, this work serves as an accessible resource for understanding survival models and applying them effectively to diverse analytical challenges. 

**Abstract (ZH)**: 本文探讨了生存分析的基础和应用方面，并以跌倒风险评估为例进行研究。文章回顾了与时间相关的概率分布和统计方法，包括逻辑回归、泊松回归、指数回归以及Cox比例风险模型，从生存分析框架出发，提供了一个统一的视角来看待这些模型之间的关系。本文的一个贡献是逐步推导和阐明了这些模型之间的关系，特别是在生存分析的背景下，特别证明泊松回归是Cox模型的一种特殊情况。这些见解弥补了理解上的空白，并强化了生存模型的简单性和可解释性。文章还强调了生存分析的实际应用价值，将理论洞见与实际应用相结合。在跌倒检测的情境中，本文展示了这些模型如何能够同时预测跌倒风险、分析影响因素以及在一个集成框架内估计事件发生时间。相比之下，先进的深度学习方法往往需要复杂的后处理解释，并且在处理结构化数值数据时需要为不同的任务分别进行训练。这突显了经典统计框架的持久相关性，并使生存模型在医疗保健等领域尤为重要，因为可解释性和稳健性至关重要。通过统一基础概念并提供一种结合的时间事件分析视角，本文为理解生存模型及其在各种分析挑战中的应用提供了一种易于理解的资源。 

---
# To Analyze and Regulate Human-in-the-loop Learning for Congestion Games 

**Title (ZH)**: 分析和调节人类参与循环的学习在拥堵博弈中的应用 

**Authors**: Hongbo Li, Lingjie Duan  

**Link**: [PDF](https://arxiv.org/pdf/2501.03055)  

**Abstract**: In congestion games, selfish users behave myopically to crowd to the shortest paths, and the social planner designs mechanisms to regulate such selfish routing through information or payment incentives. However, such mechanism design requires the knowledge of time-varying traffic conditions and it is the users themselves to learn and report past road experiences to the social planner (e.g., Waze or Google Maps). When congestion games meet mobile crowdsourcing, it is critical to incentivize selfish users to explore non-shortest paths in the best exploitation-exploration trade-off. First, we consider a simple but fundamental parallel routing network with one deterministic path and multiple stochastic paths for users with an average arrival probability $\lambda$. We prove that the current myopic routing policy (widely used in Waze and Google Maps) misses both exploration (when strong hazard belief) and exploitation (when weak hazard belief) as compared to the social optimum. Due to the myopic policy's under-exploration, we prove that the caused price of anarchy (PoA) is larger than \(\frac{1}{1-\rho^{\frac{1}{\lambda}}}\), which can be arbitrarily large as discount factor \(\rho\rightarrow1\). To mitigate such huge efficiency loss, we propose a novel selective information disclosure (SID) mechanism: we only reveal the latest traffic information to users when they intend to over-explore stochastic paths upon arrival, while hiding such information when they want to under-explore. We prove that our mechanism successfully reduces PoA to be less than~\(2\). Besides the parallel routing network, we further extend our mechanism and PoA results to any linear path graphs with multiple intermediate nodes. 

**Abstract (ZH)**: 在拥塞博弈中，自私的用户为了接近最短路径而采取短视的行为，社会规划者设计机制通过信息或支付激励手段来调节这种自私的路径选择。然而，这样的机制设计需要了解时间变化的交通状况，用户自己也需要学习并报告过去的道路经验（例如，Waze或Google Maps）。当拥塞博弈与移动众包相遇时，关键是如何激励自私的用户在充分利用与探索之间做出最佳权衡，在非最短路径上进行探索。首先，我们考虑了一个简单但基础的并行路由网络，该网络包含一条确定性路径和多条随机路径，用户平均到达概率为 \(\lambda\)。我们证明，在强危险信念的情况下，当前的短视路由策略（广泛应用于Waze和Google Maps）会错过探索；而在弱危险信念的情况下，会错过利用。由于短视策略的探索不足，我们证明，导致的无效率比（PoA）大于 \(\frac{1}{1-\rho^{\frac{1}{\lambda}}}\)，当折扣因子 \(\rho \rightarrow 1\) 时，该比值可以变得任意大。为了缓解这种巨大的效率损失，我们提出了一种新颖的选择性信息披露（SID）机制：当用户到达后打算过度探索随机路径时，只向其透露最新的交通信息，而在他们打算不充分探索时，则隐瞒这些信息。我们证明，我们的机制成功地将PoA减少到小于2。除了并行路由网络外，我们进一步将我们的机制和PoA结果扩展到任何具有多个中间节点的线性路径图上。 

---
# Single-Channel Distance-Based Source Separation for Mobile GPU in Outdoor and Indoor Environments 

**Title (ZH)**: 面向户外和室内环境的移动GPU单通道基于距离的源分离方法 

**Authors**: Hanbin Bae, Byungjun Kang, Jiwon Kim, Jaeyong Hwang, Hosang Sung, Hoon-Young Cho  

**Link**: [PDF](https://arxiv.org/pdf/2501.03045)  

**Abstract**: This study emphasizes the significance of exploring distance-based source separation (DSS) in outdoor environments. Unlike existing studies that primarily focus on indoor settings, the proposed model is designed to capture the unique characteristics of outdoor audio sources. It incorporates advanced techniques, including a two-stage conformer block, a linear relation-aware self-attention (RSA), and a TensorFlow Lite GPU delegate. While the linear RSA may not capture physical cues as explicitly as the quadratic RSA, the linear RSA enhances the model's context awareness, leading to improved performance on the DSS that requires an understanding of physical cues in outdoor and indoor environments. The experimental results demonstrated that the proposed model overcomes the limitations of existing approaches and considerably enhances energy efficiency and real-time inference speed on mobile devices. 

**Abstract (ZH)**: 本研究强调在户外环境中探索基于距离的源分离（DSS）的重要性。与现有主要关注室内环境的研究不同，所提出的模型旨在捕捉户外音频源的独特特征。该模型结合了高级技术，包括两阶段 conformer 块、线性关系感知自注意力（RSA）以及 TensorFlow Lite GPU 代理。虽然线性 RSA 不如二次 RSA 那样明确捕捉物理线索，但线性 RSA 提高了模型的情境意识，从而在需要理解户外和室内环境物理线索的 DSS 上取得了更好的性能。实验结果表明，所提出的模型克服了现有方法的局限性，并在移动设备上显著提高了能效和实时推断速度。 

---
# Piano Transcription by Hierarchical Language Modeling with Pretrained Roll-based Encoders 

**Title (ZH)**: 基于滚动编码器预训练的分级语言建模的钢琴转记方法 

**Authors**: Dichucheng Li, Yongyi Zang, Qiuqiang Kong  

**Link**: [PDF](https://arxiv.org/pdf/2501.03038)  

**Abstract**: Automatic Music Transcription (AMT), aiming to get musical notes from raw audio, typically uses frame-level systems with piano-roll outputs or language model (LM)-based systems with note-level predictions. However, frame-level systems require manual thresholding, while the LM-based systems struggle with long sequences. In this paper, we propose a hybrid method combining pre-trained roll-based encoders with an LM decoder to leverage the strengths of both methods. Besides, our approach employs a hierarchical prediction strategy, first predicting onset and pitch, then velocity, and finally offset. The hierarchical prediction strategy reduces computational costs by breaking down long sequences into different hierarchies. Evaluated on two benchmark roll-based encoders, our method outperforms traditional piano-roll outputs 0.01 and 0.022 in onset-offset-velocity F1 score, demonstrating its potential as a performance-enhancing plug-in for arbitrary roll-based music transcription encoder. We release the code of this work at this https URL. 

**Abstract (ZH)**: 自动音乐转录（AMT）旨在从原始音频中获取音乐音符，通常使用帧级系统输出音轨或基于语言模型（LM）的系统进行音级预测。然而，帧级系统需要人工阈值设置，而基于LM的系统在处理长序列时存在困难。本文提出了一种结合预训练的音轨编码器和LM解码器的混合方法，以充分利用两者的优势。此外，我们的方法采用了分层预测策略，首先预测起始时间和音高，然后预测音量，最后预测结束时间。分层预测策略通过将长序列分解为不同层次，减少计算成本。在两个基准音轨编码器上进行评估，我们的方法在起始时间-结束时间-音量F1评分上分别优于传统的音轨输出0.01和0.022，展示了其作为任意音轨音乐转录编码器的性能增强插件的潜力。我们已将该工作的代码发布在 <https://>。 

---
# Quantization Meets Reasoning: Exploring LLM Low-Bit Quantization Degradation for Mathematical Reasoning 

**Title (ZH)**: 量化与推理的融合：探索大规模语言模型低比特量化对数学推理的性能下降现象 

**Authors**: Zhen Li, Yupeng Su, Runming Yang, Zhongwei Xie, Ngai Wong, Hongxia Yang  

**Link**: [PDF](https://arxiv.org/pdf/2501.03035)  

**Abstract**: Large language models have achieved significant advancements in complex mathematical reasoning benchmarks, such as MATH. However, their substantial computational requirements present challenges for practical deployment. Model quantization has emerged as an effective strategy to reduce memory usage and computational costs by employing lower precision and bit-width representations. In this study, we systematically evaluate the impact of quantization on mathematical reasoning tasks. We introduce a multidimensional evaluation framework that qualitatively assesses specific capability dimensions and conduct quantitative analyses on the step-by-step outputs of various quantization methods. Our results demonstrate that quantization differentially affects numerical computation and reasoning planning abilities, identifying key areas where quantized models experience performance degradation. 

**Abstract (ZH)**: 大规模语言模型在MATH等复杂数学推理基准测试中取得了显著进展。然而，它们巨大的计算需求给实际部署带来了挑战。模型量化已作为一种有效策略出现，通过使用较低精度和位宽表示来减少内存使用和计算成本。在本研究中，我们系统地评估了量化对数学推理任务的影响。我们引入了一个多维度的评估框架，从定性的角度评估特定能力维度，并对不同量化方法的步骤输出进行了定量分析。我们的结果表明，量化以不同的方式影响数值计算和推理规划能力，确定了量化模型性能下降的关键领域。 

---
# Putnam's Critical and Explanatory Tendencies Interpreted from a Machine Learning Perspective 

**Title (ZH)**: 从机器学习视角解读普特南的批判性和解释性倾向 

**Authors**: Sheldon Z. Soudin  

**Link**: [PDF](https://arxiv.org/pdf/2501.03026)  

**Abstract**: Making sense of theory choice in normal and across extraordinary science is central to philosophy of science. The emergence of machine learning models has the potential to act as a wrench in the gears of current debates. In this paper, I will attempt to reconstruct the main movements that lead to and came out of Putnam's critical and explanatory tendency distinction, argue for the biconditional necessity of the tendencies, and conceptualize that wrench through a machine learning interpretation of my claim. 

**Abstract (ZH)**: 理解正常科学与非常规科学中的理论选择是哲学科学的核心问题。机器学习模型的出现有可能在当前的辩论中起到颠覆性的影响。在本文中，我将尝试重构导致并产生于普特南批判性和解释性倾向区分的主要发展过程，论证这两种倾向的双条件必然性，并通过机器学习的视角概念化这种颠覆性影响。 

---
# Quality Estimation based Feedback Training for Improving Pronoun Translation 

**Title (ZH)**: 基于质量评估的反馈训练以提高代词翻译质量 

**Authors**: Harshit Dhankhar, Baban Gain, Asif Ekbal, Yogesh Mani Tripathi  

**Link**: [PDF](https://arxiv.org/pdf/2501.03008)  

**Abstract**: Pronoun translation is a longstanding challenge in neural machine translation (NMT), often requiring inter-sentential context to ensure linguistic accuracy. To address this, we introduce ProNMT, a novel framework designed to enhance pronoun and overall translation quality in context-aware machine translation systems. ProNMT leverages Quality Estimation (QE) models and a unique Pronoun Generation Likelihood-Based Feedback mechanism to iteratively fine-tune pre-trained NMT models without relying on extensive human annotations. The framework combines QE scores with pronoun-specific rewards to guide training, ensuring improved handling of linguistic nuances. Extensive experiments demonstrate significant gains in pronoun translation accuracy and general translation quality across multiple metrics. ProNMT offers an efficient, scalable, and context-aware approach to improving NMT systems, particularly in translating context-dependent elements like pronouns. 

**Abstract (ZH)**: 代词翻译是神经机器翻译（NMT）中的长期挑战，通常需要句子间的上下文来确保语言准确性。为了解决这一问题，我们提出了ProNMT，这是一种新型框架，旨在增强上下文感知机器翻译系统中的代词和整体翻译质量。ProNMT 利用了质量估算（QE）模型和一种独特的基于代词生成概率的反馈机制，迭代微调预训练的NMT模型，而无需依赖大量人类注释。该框架将QE分数与代词特定的奖励相结合，以指导训练，确保更好地处理语言细微差别。大量的实验展示了在多个指标上代词翻译准确性和整体翻译质量的显著提升。ProNMT 提供了一种高效、可扩展且上下文感知的方法来改进NMT系统，特别是在翻译依赖上下文的元素如代词方面。 

---
# GLFC: Unified Global-Local Feature and Contrast Learning with Mamba-Enhanced UNet for Synthetic CT Generation from CBCT 

**Title (ZH)**: GLFC：增强的Mamba-UNet模型中统一的全局-局部特征和对比学习方法在CBCT到合成CT生成中的应用 

**Authors**: Xianhao Zhou, Jianghao Wu, Huangxuan Zhao, Lei Chen, Shaoting Zhang, Guotai Wang, Guotai Wang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02992)  

**Abstract**: Generating synthetic Computed Tomography (CT) images from Cone Beam Computed Tomography (CBCT) is desirable for improving the image quality of CBCT. Existing synthetic CT (sCT) generation methods using Convolutional Neural Networks (CNN) and Transformers often face difficulties in effectively capturing both global and local features and contrasts for high-quality sCT generation. In this work, we propose a Global-Local Feature and Contrast learning (GLFC) framework for sCT generation. First, a Mamba-Enhanced UNet (MEUNet) is introduced by integrating Mamba blocks into the skip connections of a high-resolution UNet for effective global and local feature learning. Second, we propose a Multiple Contrast Loss (MCL) that calculates synthetic loss at different intensity windows to improve quality for both soft tissues and bone regions. Experiments on the SynthRAD2023 dataset demonstrate that GLFC improved the SSIM of sCT from 77.91% to 91.50% compared with the original CBCT, and significantly outperformed several existing methods for sCT generation. The code is available at this https URL 

**Abstract (ZH)**: 从锥形束计算机断层摄影（CBCT）生成合成计算机断层摄影（sCT）图像，对于提高CBCT图像质量具有重要意义。现有的使用卷积神经网络（CNN）和变压器的方法在生成高质sCT图像时，往往难以有效地捕捉全局和局部特征及对比度。在本项工作中，我们提出了一种全局-局部特征和对比度学习（GLFC）框架，用于sCT生成。首先，通过将Mamba块集成到高分辨率UNet的跳跃连接中，我们引入了Mamba-增强UNet（MEUNet），以实现有效的全局和局部特征学习。其次，我们提出了一种多对比度损失（MCL），通过在不同的强度窗中计算合成损失，以提高软组织和骨骼区域的质量。在SynthRAD2023数据集上的实验表明，GLFC将sCT的SSIM从77.91%提高到了91.50%，并且显著优于几种现有的sCT生成方法。代码可以在以下链接获取：[请插入链接] 

---
# A Bio-Inspired Research Paradigm of Collision Perception Neurons Enabling Neuro-Robotic Integration: The LGMD Case 

**Title (ZH)**: 一种生物启发的研究范式：碰撞感知神经元的碰撞感知机制及其在神经机器人集成中的应用——以LGMD为例 

**Authors**: Ziyan Qin, Jigen Peng, Shigang Yue, Qinbing Fu  

**Link**: [PDF](https://arxiv.org/pdf/2501.02982)  

**Abstract**: Compared to human vision, insect visual systems excel at rapid and precise collision detection, despite relying on only tens of thousands of neurons organized through a few neuropils. This efficiency makes them an attractive model system for developing artificial collision-detecting systems. Specifically, researchers have identified collision-selective neurons in the locust's optic lobe, called lobula giant movement detectors (LGMDs), which respond specifically to approaching objects. Research upon LGMD neurons began in the early 1970s. Initially, due to their large size, these neurons were identified as motion detectors, but their role as looming detectors was recognized over time. Since then, progress in neuroscience, computational modeling of LGMD's visual neural circuits, and LGMD-based robotics has advanced in tandem, each field supporting and driving the others. Today, with a deeper understanding of LGMD neurons, LGMD-based models have significantly improved collision-free navigation in mobile robots including ground and aerial robots. This review highlights recent developments in LGMD research from the perspectives of neuroscience, computational modeling, and robotics. It emphasizes a biologically plausible research paradigm, where insights from neuroscience inform real-world applications, which would in turn validate and advance neuroscience. With strong support from extensive research and growing application demand, this paradigm has reached a mature stage and demonstrates versatility across different areas of neuroscience research, thereby enhancing our understanding of the interconnections between neuroscience, computational modeling, and robotics. Furthermore, other motion-sensitive neurons have also shown promising potential for adopting this research paradigm. 

**Abstract (ZH)**: 与人类视觉相比，昆虫视觉系统在仅依赖数千个神经元且这些神经元通过几组神经节区组织的情况下，表现出色，能够在快速和精确地检测碰撞方面取得优异成绩。这种高效性使它们成为开发人工碰撞检测系统的理想模型系统。具体而言，研究人员已经确定了蝗虫视叶中的碰撞选择性神经元——大羽状运动检测器（LGMDs），这些神经元能够对接近的物体作出特定响应。LGMD神经元的研究始于20世纪70年代初期，最初因其较大的尺寸而被认为是运动检测器，但它们作为临界扩大检测器的角色逐渐被认识。此后，神经科学的进步、LGMD视觉神经回路的计算建模以及基于LGMD的机器人技术取得了同步进展，每一领域都支持和推动着其他领域的发展。今天，随着对LGMD神经元更深入的理解，基于LGMD的模型显著提高了地面和空中移动机器人在避免碰撞导航方面的能力。本文回顾了从神经科学、计算建模和机器人技术视角来看的LGMD研究的最新进展，强调了一种生物可行性研究范式，其中神经科学的洞察力指导实际应用，反过来验证和推进神经科学的发展。该范式在广泛的科研支持和不断增长的应用需求下达到了成熟阶段，展示了在不同神经科学研究领域的普适性，从而增强了我们对神经科学、计算建模和机器人技术之间相互联系的理解。此外，其他运动敏感神经元的潜力也显示出采用这一研究范式的前景。 

---
# CONTINUUM: Detecting APT Attacks through Spatial-Temporal Graph Neural Networks 

**Title (ZH)**: 连续性：通过空间-时间图神经网络检测APT攻击 

**Authors**: Atmane Ayoub Mansour Bahara, Kamel Soaïd Ferrahia, Mohamed-Lamine Messai, Hamida Seba, Karima Amrouche  

**Link**: [PDF](https://arxiv.org/pdf/2501.02981)  

**Abstract**: Advanced Persistent Threats (APTs) represent a significant challenge in cybersecurity due to their sophisticated and stealthy nature. Traditional Intrusion Detection Systems (IDS) often fall short in detecting these multi-stage attacks. Recently, Graph Neural Networks (GNNs) have been employed to enhance IDS capabilities by analyzing the complex relationships within networked data. However, existing GNN-based solutions are hampered by high false positive rates and substantial resource consumption. In this paper, we present a novel IDS designed to detect APTs using a Spatio-Temporal Graph Neural Network Autoencoder. Our approach leverages spatial information to understand the interactions between entities within a graph and temporal information to capture the evolution of the graph over time. This dual perspective is crucial for identifying the sequential stages of APTs. Furthermore, to address privacy and scalability concerns, we deploy our architecture in a federated learning environment. This setup ensures that local data remains on-premise while encrypted model-weights are shared and aggregated using homomorphic encryption, maintaining data privacy and security. Our evaluation shows that this system effectively detects APTs with lower false positive rates and optimized resource usage compared to existing methods, highlighting the potential of spatio-temporal analysis and federated learning in enhancing cybersecurity defenses. 

**Abstract (ZH)**: 高级持续性威胁（APTs）由于其复杂且隐蔽的特性，构成了网络空间安全的重大挑战。传统的入侵检测系统（IDS）往往难以检测这种多阶段攻击。近年来，图形神经网络（GNNs）被用于增强IDS的能力，通过分析网络数据中的复杂关系来提高检测能力。然而，现有的基于GNN的解决方案普遍存在较高的误报率和巨大的资源消耗问题。本文提出了一种新型的IDS，该系统采用空间-时间图形神经网络自动编码器来检测APTs。我们的方法利用空间信息来理解图中实体之间的交互，并利用时间信息来捕捉图随时间的变化。这种双重视角对于识别APT的顺序阶段至关重要。此外，为了应对隐私和可扩展性的挑战，我们将在联邦学习环境中部署我们的架构。这种设置确保本地数据保留在本地，同时通过同态加密共享和聚合加密的模型权重，从而保持数据隐私和安全性。评估结果显示，该系统能够以较低的误报率和优化的资源利用率检测APTs，突显了空间-时间分析和联邦学习在增强网络安全防御中的潜力。 

---
# CAMP: Collaborative Attention Model with Profiles for Vehicle Routing Problems 

**Title (ZH)**: CAMP：带有个人资料的协作注意模型在车辆路线问题中的应用 

**Authors**: Chuanbo Hua, Federico Berto, Jiwoo Son, Seunghyun Kang, Changhyun Kwon, Jinkyoo Park  

**Link**: [PDF](https://arxiv.org/pdf/2501.02977)  

**Abstract**: The profiled vehicle routing problem (PVRP) is a generalization of the heterogeneous capacitated vehicle routing problem (HCVRP) in which the objective is to optimize the routes of vehicles to serve client demands subject to different vehicle profiles, with each having a preference or constraint on a per-client basis. While existing learning methods have shown promise for solving the HCVRP in real-time, no learning method exists to solve the more practical and challenging PVRP. In this paper, we propose a Collaborative Attention Model with Profiles (CAMP), a novel approach that learns efficient solvers for PVRP using multi-agent reinforcement learning. CAMP employs a specialized attention-based encoder architecture to embed profiled client embeddings in parallel for each vehicle profile. We design a communication layer between agents for collaborative decision-making across profiled embeddings at each decoding step and a batched pointer mechanism to attend to the profiled embeddings to evaluate the likelihood of the next actions. We evaluate CAMP on two variants of PVRPs: PVRP with preferences, which explicitly influence the reward function, and PVRP with zone constraints with different numbers of agents and clients, demonstrating that our learned solvers achieve competitive results compared to both classical state-of-the-art neural multi-agent models in terms of solution quality and computational efficiency. We make our code openly available at this https URL. 

**Abstract (ZH)**: 以下是翻译后的论文内容或标题，符合学术规范：

简介：有特征的车辆路由问题（PVRP）是对异构容量车辆路由问题（HCVRP）的扩展，其目标是在考虑不同类型车辆的特征的基础上，优化车辆路线以满足客户的特定需求。尽管现有的学习方法在实时解决HCVRP方面显示出潜力，但目前尚无有效的方法解决更具实践意义且更具挑战性的PVRP。本文提出了一种协作注意力模型与有特征的方法（CAMP），这是一种利用多智能体强化学习学习解决PVRP的有效方法。CAMP 使用一种特定的基于注意力的编码器架构并行嵌入具有不同特征的客户表示。我们在每个解码步骤中设计了一个通信层，以促进智能体在有特征表示间的协作决策，并引入了一个批次指针机制，以关注具有特征的表示来评估下一步动作的可能性。我们分别在两个PVRP变体：带有偏好的PVRP，其奖励函数受到显式影响，以及具有区域约束的PVRP，根据不同数量的智能体和客户进行评估，结果显示，我们学习到的求解器在解决方案质量和计算效率方面均与经典的最先进的神经多智能体模型具有竞争性。我们已在以下链接公开提供我们的代码：[链接]。 

---
# Fuzzy Granule Density-Based Outlier Detection with Multi-Scale Granular Balls 

**Title (ZH)**: 基于多尺度粒化球的模糊粒密度离群点检测 

**Authors**: Can Gao, Xiaofeng Tan, Jie Zhou, Weiping Ding, Witold Pedrycz  

**Link**: [PDF](https://arxiv.org/pdf/2501.02975)  

**Abstract**: Outlier detection refers to the identification of anomalous samples that deviate significantly from the distribution of normal data and has been extensively studied and used in a variety of practical tasks. However, most unsupervised outlier detection methods are carefully designed to detect specified outliers, while real-world data may be entangled with different types of outliers. In this study, we propose a fuzzy rough sets-based multi-scale outlier detection method to identify various types of outliers. Specifically, a novel fuzzy rough sets-based method that integrates relative fuzzy granule density is first introduced to improve the capability of detecting local outliers. Then, a multi-scale view generation method based on granular-ball computing is proposed to collaboratively identify group outliers at different levels of granularity. Moreover, reliable outliers and inliers determined by the three-way decision are used to train a weighted support vector machine to further improve the performance of outlier detection. The proposed method innovatively transforms unsupervised outlier detection into a semi-supervised classification problem and for the first time explores the fuzzy rough sets-based outlier detection from the perspective of multi-scale granular balls, allowing for high adaptability to different types of outliers. Extensive experiments carried out on both artificial and UCI datasets demonstrate that the proposed outlier detection method significantly outperforms the state-of-the-art methods, improving the results by at least 8.48% in terms of the Area Under the ROC Curve (AUROC) index. { The source codes are released at \url{this https URL}. } 

**Abstract (ZH)**: 离群点检测是指识别与正常数据分布显著偏离的异常样本，并已在多种实际任务中得到广泛研究和应用。然而，大多数无监督离群点检测方法都是针对特定类型的离群点精心设计的，而现实世界数据可能包含不同类型的离群点。在这项研究中，我们提出了一种基于模糊粗糙集的多尺度离群点检测方法，以识别各种类型的离群点。具体而言，首先介绍了一种基于相对模糊粒度密度的新颖模糊粗糙集方法，以提高局部离群点检测能力。然后，提出了基于粒球计算的多尺度视图生成方法，协同识别不同粒度级别的群组离群点。此外，由三元决策确定的可靠离群点和内群点用于训练加权支持向量机，以进一步提高离群点检测性能。该方法创新性地将无监督离群点检测转换为半监督分类问题，并首次从多尺度粒球的视角探索了基于模糊粗糙集的离群点检测方法，从而具有对不同类型离群点的高适应性。在人工数据集和UCI数据集上的广泛实验表明，所提出的方法在面积下曲线下的区域（AUROC指标）上显著优于当前最先进方法，至少提高了8.48%的检测结果。{ 该源代码发布于 \url{此httpsURL}。} 

---
# Proof-of-Data: A Consensus Protocol for Collaborative Intelligence 

**Title (ZH)**: 数据证明：协作智能的一种共识协议 

**Authors**: Huiwen Liu, Feida Zhu, Ling Cheng  

**Link**: [PDF](https://arxiv.org/pdf/2501.02971)  

**Abstract**: Existing research on federated learning has been focused on the setting where learning is coordinated by a centralized entity. Yet the greatest potential of future collaborative intelligence would be unleashed in a more open and democratized setting with no central entity in a dominant role, referred to as "decentralized federated learning". New challenges arise accordingly in achieving both correct model training and fair reward allocation with collective effort among all participating nodes, especially with the threat of the Byzantine node jeopardising both tasks.
In this paper, we propose a blockchain-based decentralized Byzantine fault-tolerant federated learning framework based on a novel Proof-of-Data (PoD) consensus protocol to resolve both the "trust" and "incentive" components. By decoupling model training and contribution accounting, PoD is able to enjoy not only the benefit of learning efficiency and system liveliness from asynchronous societal-scale PoW-style learning but also the finality of consensus and reward allocation from epoch-based BFT-style voting. To mitigate false reward claims by data forgery from Byzantine attacks, a privacy-aware data verification and contribution-based reward allocation mechanism is designed to complete the framework. Our evaluation results show that PoD demonstrates performance in model training close to that of the centralized counterpart while achieving trust in consensus and fairness for reward allocation with a fault tolerance ratio of 1/3. 

**Abstract (ZH)**: 以下是经过学术规范调整后的翻译：

现有的联邦学习研究主要集中在由中心化的实体协调学习的设置上。然而，未来协作智能的真正潜力将在没有中心化主导实体的开放和民主化的环境中得到最大程度的释放，这种环境被称为“去中心化的联邦学习”。在这种去中心化的环境中，新的挑战随之而来，需要在所有参与节点的共同努力下实现正确的模型训练和公平的奖励分配，尤其是在拜占庭节点的威胁下，这两种任务都面临着风险。

在本论文中，我们提出了一种基于区块链的去中心化拜占庭容错联邦学习框架，其基于一种新型的数据证明（Proof-of-Data，PoD）共识协议，以解决“信任”和“激励”问题。通过将模型训练与贡献计数解耦，PoD 不仅从异步社会规模的工作量证明（proof-of-work，PoW）风格的学习中获得了高效学习和系统活力的优势，还从基于时期的拜占庭容错（Byzantine-fault-tolerant，BFT）风格的投票中获得了共识和奖励分配的最终性。为了缓解拜占庭攻击导致的数据forgery引发的虚假奖励声称，我们设计了一种隐私保护的数据验证和基于贡献的奖励分配机制，以完成该框架。我们的评估结果表明，PoD 在模型训练性能方面接近中心化版本，并且在容错率为三分之一的情况下，达到了共识的信任和奖励分配的公平性。

注释：
1. “数据forgery”修正为“数据伪造”，更符合学术文献中常用的表述。
2. 整体语言风格保持客观正式，符合学术论文的书写标准。 

---
# Socratic Questioning: Learn to Self-guide Multimodal Reasoning in the Wild 

**Title (ZH)**: 苏格拉底式提问：学会在现实世界中自我引导多模态推理 

**Authors**: Wanpeng Hu, Haodi Liu, Lin Chen, Feng Zhou, Changming Xiao, Qi Yang, Changshui Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02964)  

**Abstract**: Complex visual reasoning remains a key challenge today. Typically, the challenge is tackled using methodologies such as Chain of Thought (COT) and visual instruction tuning. However, how to organically combine these two methodologies for greater success remains unexplored. Also, issues like hallucinations and high training cost still need to be addressed. In this work, we devise an innovative multi-round training and reasoning framework suitable for lightweight Multimodal Large Language Models (MLLMs). Our self-questioning approach heuristically guides MLLMs to focus on visual clues relevant to the target problem, reducing hallucinations and enhancing the model's ability to describe fine-grained image details. This ultimately enables the model to perform well in complex visual reasoning and question-answering tasks. We have named this framework Socratic Questioning(SQ). To facilitate future research, we create a multimodal mini-dataset named CapQA, which includes 1k images of fine-grained activities, for visual instruction tuning and evaluation, our proposed SQ method leads to a 31.2% improvement in the hallucination score. Our extensive experiments on various benchmarks demonstrate SQ's remarkable capabilities in heuristic self-questioning, zero-shot visual reasoning and hallucination mitigation. Our model and code will be publicly available. 

**Abstract (ZH)**: 复杂的视觉推理依然是当前一个关键挑战。通常，这一挑战通过使用诸如Chain of Thought（CoT）和视觉指令调优等方法来应对。然而，如何有机地结合这两种方法以取得更大的成功仍然是未解决的问题。此外，幻觉和高昂的训练成本等问题仍然需要解决。在本项工作中，我们设计了一个适用于轻量级多模态大语言模型（MLLMs）的创新多轮训练和推理框架。我们的自我提问方法通过启发式方式引导MLLMs关注与目标问题相关的视觉线索，从而减少幻觉并增强模型描述细粒度图像细节的能力。最终，这一框架使得模型在复杂的视觉推理和问答任务中表现出色。我们将其命名为Socratic Questioning（SQ）。为了促进后续研究，我们创建了一个多模态小型数据集CapQA，其中包括1000张细粒度活动图像，用于视觉指令调优和评估。我们提出的SQ方法在幻觉评分上提高了31.2%。通过对各种基准的大规模实验，我们展示了SQ在启发式自我提问、零样本视觉推理和幻觉缓解方面的卓越能力。我们的模型和代码将对公众开放。 

---
# Key-value memory in the brain 

**Title (ZH)**: 大脑中的键值记忆 

**Authors**: Samuel J. Gershman, Ila Fiete, Kazuki Irie  

**Link**: [PDF](https://arxiv.org/pdf/2501.02950)  

**Abstract**: Classical models of memory in psychology and neuroscience rely on similarity-based retrieval of stored patterns, where similarity is a function of retrieval cues and the stored patterns. While parsimonious, these models do not allow distinct representations for storage and retrieval, despite their distinct computational demands. Key-value memory systems, in contrast, distinguish representations used for storage (values) and those used for retrieval (keys). This allows key-value memory systems to optimize simultaneously for fidelity in storage and discriminability in retrieval. We review the computational foundations of key-value memory, its role in modern machine learning systems, related ideas from psychology and neuroscience, applications to a number of empirical puzzles, and possible biological implementations. 

**Abstract (ZH)**: 心理学和神经科学中的经典记忆模型依赖于基于相似性的存储模式检索，其中相似性是检索线索与存储模式之间的函数。尽管这些模型简洁有效，但它们并未区分存储和检索的表示，尽管这两种操作在计算需求上有所不同。相比之下，键值记忆系统区分用于存储的表示（值）和用于检索的表示（键）。这使得键值记忆系统能够同时优化存储的忠实性和检索的区分性。我们综述了键值记忆的计算基础、它在现代机器学习系统中的作用、相关的人类心理学和神经科学研究理念、对若干 empirical 问题的应用，以及可能的生物实现方式。 

---
# Label-free Concept Based Multiple Instance Learning for Gigapixel Histopathology 

**Title (ZH)**: 基于无标签概念的袋装学习方法用于 gigapixel 组织病理学 

**Authors**: Susu Sun, Leslie Tessier, Frédérique Meeuwsen, Clément Grisi, Dominique van Midden, Geert Litjens, Christian F. Baumgartner  

**Link**: [PDF](https://arxiv.org/pdf/2501.02922)  

**Abstract**: Multiple Instance Learning (MIL) methods allow for gigapixel Whole-Slide Image (WSI) analysis with only slide-level annotations. Interpretability is crucial for safely deploying such algorithms in high-stakes medical domains. Traditional MIL methods offer explanations by highlighting salient regions. However, such spatial heatmaps provide limited insights for end users. To address this, we propose a novel inherently interpretable WSI-classification approach that uses human-understandable pathology concepts to generate explanations. Our proposed Concept MIL model leverages recent advances in vision-language models to directly predict pathology concepts based on image features. The model's predictions are obtained through a linear combination of the concepts identified on the top-K patches of a WSI, enabling inherent explanations by tracing each concept's influence on the prediction. In contrast to traditional concept-based interpretable models, our approach eliminates the need for costly human annotations by leveraging the vision-language model. We validate our method on two widely used pathology datasets: Camelyon16 and PANDA. On both datasets, Concept MIL achieves AUC and accuracy scores over 0.9, putting it on par with state-of-the-art models. We further find that 87.1\% (Camelyon16) and 85.3\% (PANDA) of the top 20 patches fall within the tumor region. A user study shows that the concepts identified by our model align with the concepts used by pathologists, making it a promising strategy for human-interpretable WSI classification. 

**Abstract (ZH)**: 多实例学习（MIL）方法允许仅通过幻灯片级别的注释对巨大的整张切片图像（WSI）进行分析。解释性对于在高风险医疗领域安全地部署此类算法至关重要。传统的MIL方法通过突出显示显著区域来提供解释。然而，这种空间热图对最终用户提供的洞察是有限的。为了解决这个问题，我们提出了一种新颖的内在可解释的WSI分类方法，该方法使用人类可理解的病理概念来生成解释。我们提出的概念MIL模型利用了最近在视觉语言模型方面的进展，直接根据图像特征预测病理概念。该模型的预测是通过对WSI的Top-K区域中识别的概念的线性组合获得的，从而通过跟踪每个概念对预测的影响来实现内在解释。与传统的基于概念的可解释模型不同，我们的方法通过利用视觉语言模型消除了昂贵的人工标注需求。我们使用两个常用的病理数据集（Camelyon16和PANDA）验证了该方法。在两个数据集上，概念MIL都达到了AUC和准确率超过0.9的成绩，与当前最先进的模型相当。进一步的分析显示，在Camelyon16数据集上，87.1%（前20个区域中）和在PANDA数据集上85.3%（前20个区域中）的顶级区域位于肿瘤区域。用户研究显示，我们模型识别的概念与病理学家使用的一致，这使其成为人类可解释WSI分类的一个有前景的方法。 

---
# Unsupervised Tomato Split Anomaly Detection using Hyperspectral Imaging and Variational Autoencoders 

**Title (ZH)**: 使用高光谱成像和变分自编码器的无监督西红柿裂分异常检测 

**Authors**: Mahmoud Abdulsalam, Usman Zahidi, Bradley Hurst, Simon Pearson, Grzegorz Cielniak, James Brown  

**Link**: [PDF](https://arxiv.org/pdf/2501.02921)  

**Abstract**: Tomato anomalies/damages pose a significant challenge in greenhouse farming. While this method of cultivation benefits from efficient resource utilization, anomalies can significantly degrade the quality of farm produce. A common anomaly associated with tomatoes is splitting, characterized by the development of cracks on the tomato skin, which degrades its quality. Detecting this type of anomaly is challenging due to dynamic variations in appearance and sizes, compounded by dataset scarcity. We address this problem in an unsupervised manner by utilizing a tailored variational autoencoder (VAE) with hyperspectral input. Preliminary analysis of the dataset enabled us to select the optimal range of wavelengths for detecting this anomaly. Our findings indicate that the 530nm - 550nm range is suitable for identifying tomato dry splits. The analysis on reconstruction loss allow us to not only detect the anomalies but also to some degree estimate the anomalous regions. 

**Abstract (ZH)**: 温室栽培中的番茄异常/损伤给农业生产带来了重大挑战。尽管这种栽培方式有助于高效利用资源，但异常现象会显著降低作物的质量。番茄常见的异常之一是开裂，表现为番茄果皮上出现裂缝，这会降低其质量。由于外观和尺寸的动态变化以及数据集的缺乏，检测这种异常极具挑战性。我们通过利用带有高光谱输入的定制化变分自编码器（VAE）以无监督的方式解决了这一问题。对数据集的初步分析使我们能够选出合适的波长范围以检测这种异常。我们的研究结果表明，530nm-550nm的波长范围适用于识别番茄干裂。通过分析重构损失，我们不仅能够检测出异常区域，还能在一定程度上估算异常区域的范围。 

---
# Skillful High-Resolution Ensemble Precipitation Forecasting with an Integrated Deep Learning Framework 

**Title (ZH)**: 采用集成深度学习框架的高分辨率集合降水预报技巧 

**Authors**: Shuangshuang He, Hongli Liang, Yuanting Zhang, Xingyuan Yuan  

**Link**: [PDF](https://arxiv.org/pdf/2501.02905)  

**Abstract**: High-resolution precipitation forecasts are crucial for providing accurate weather prediction and supporting effective responses to extreme weather events. Traditional numerical models struggle with stochastic subgrid-scale processes, while recent deep learning models often produce blurry results. To address these challenges, we propose a physics-inspired deep learning framework for high-resolution (0.05\textdegree{} $\times$ 0.05\textdegree{}) ensemble precipitation forecasting. Trained on ERA5 and CMPA high-resolution precipitation datasets, the framework integrates deterministic and probabilistic components. The deterministic model, based on a 3D SwinTransformer, captures average precipitation at mesoscale resolution and incorporates strategies to enhance performance, particularly for moderate to heavy rainfall. The probabilistic model employs conditional diffusion in latent space to account for uncertainties in residual precipitation at convective scales. During inference, ensemble members are generated by repeatedly sampling latent variables, enabling the model to represent precipitation uncertainty. Our model significantly enhances spatial resolution and forecast accuracy. Rank histogram shows that the ensemble system is reliable and unbiased. In a case study of heavy precipitation in southern China, the model outputs align more closely with observed precipitation distributions than ERA5, demonstrating superior capability in capturing extreme precipitation events. Additionally, 5-day real-time forecasts show good performance in terms of CSI scores. 

**Abstract (ZH)**: 高分辨率降水量预报对于提供准确的天气预测和有效应对极端天气事件至关重要。传统的数值模型难以处理随机的次网格过程，而近期的深度学习模型常常产生模糊的结果。为了解决这些挑战，我们提出了一种基于物理的深度学习框架，用于高分辨率（0.05° × 0.05°）集合降水量预报。该框架在ERA5和CMPA高分辨率降水量数据集上进行训练，将确定性和概率性组件结合起来。确定性模型基于三维SwinTransformer，能够捕捉中尺度分辨率的平均降水量，并采用策略以提高性能，特别是在中重度降水情况下。概率性模型通过潜在空间的条件扩散来考虑对流尺度上残余降水量的不确定性。在推断过程中，通过多次采样潜在变量生成集合成员，使模型能够表示降水量的不确定性。我们的模型显著提高了空间分辨率和预报精度。 ranks 统计图显示，该集合系统具有可靠性和无偏差性。在对中国南部的强降水案例研究中，模型输出与观测到的降水量分布更为一致，显示出在捕捉极端降水事件方面具有更优的能力。此外，5天的实时预报在CSI评分方面表现出良好的性能。 

---
# Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis 

**Title (ZH)**: 解释幽默风格分类：一种用于理解计算幽默分析的可解释人工智能方法 

**Authors**: Mary Ogbuka Kenneth, Foaad Khosmood, Abbas Edalat  

**Link**: [PDF](https://arxiv.org/pdf/2501.02891)  

**Abstract**: Humour styles can have either a negative or a positive impact on well-being. Given the importance of these styles to mental health, significant research has been conducted on their automatic identification. However, the automated machine learning models used for this purpose are black boxes, making their prediction decisions opaque. Clarity and transparency are vital in the field of mental health. This paper presents an explainable AI (XAI) framework for understanding humour style classification, building upon previous work in computational humour analysis. Using the best-performing single model (ALI+XGBoost) from prior research, we apply comprehensive XAI techniques to analyse how linguistic, emotional, and semantic features contribute to humour style classification decisions. Our analysis reveals distinct patterns in how different humour styles are characterised and misclassified, with particular emphasis on the challenges in distinguishing affiliative humour from other styles. Through detailed examination of feature importance, error patterns, and misclassification cases, we identify key factors influencing model decisions, including emotional ambiguity, context misinterpretation, and target identification. The framework demonstrates significant utility in understanding model behaviour, achieving interpretable insights into the complex interplay of features that define different humour styles. Our findings contribute to both the theoretical understanding of computational humour analysis and practical applications in mental health, content moderation, and digital humanities research. 

**Abstract (ZH)**: 幽默风格对福祉的影响可能是正面的也可能是负面的。鉴于这些风格在心理健康方面的重要性，已经进行了大量关于其自动识别的研究。然而，用于此目的的自动化机器学习模型往往是“黑盒”的，使其预测决策变得不透明。在心理健康领域，清晰性和透明性至关重要。本文提出了一种可解释的人工智能（XAI）框架，以理解幽默风格分类。该框架建立在计算幽默分析领域的先前研究基础之上。我们使用先前研究中表现最好的单一模型（ALI+XGBoost），并应用全面的XAI技术，分析语言特征、情感特征和语义特征如何影响幽默风格分类决策。我们的分析揭示了不同幽默风格在特征描述和分类错误中的不同模式，尤其强调了区分归属幽默与其他风格的挑战。通过详细检查特征重要性、错误模式和分类错误案例，我们确定了影响模型决策的关键因素，包括情感歧义、情境误解和目标识别。该框架在理解模型行为方面显示出显著的实用性，实现了对定义不同幽默风格的复杂特征交互作用的可解释洞察。我们的研究结果不仅有助于对计算幽默分析的理论理解，还对心理健康、内容审核和数字人文研究的实际应用做出了贡献。 

---
# IIMedGPT: Promoting Large Language Model Capabilities of Medical Tasks by Efficient Human Preference Alignment 

**Title (ZH)**: IIMedGPT：通过高效的人类偏好对齐促进大型语言模型在医疗任务中的能力 

**Authors**: Yiming Zhang, Zheng Chang, Wentao Cai, MengXing Ren, Kang Yuan, Yining Sun, Zenghui Ding  

**Link**: [PDF](https://arxiv.org/pdf/2501.02869)  

**Abstract**: Recent researches of large language models(LLM), which is pre-trained on massive general-purpose corpora, have achieved breakthroughs in responding human queries. However, these methods face challenges including limited data insufficiency to support extensive pre-training and can not align responses with users' instructions. To address these issues, we introduce a medical instruction dataset, CMedINS, containing six medical instructions derived from actual medical tasks, which effectively fine-tunes LLM in conjunction with other data. Subsequently, We launch our medical model, IIMedGPT, employing an efficient preference alignment method, Direct preference Optimization(DPO). The results show that our final model outperforms existing medical models in medical this http URL, Code and model checkpoints will be released upon acceptance. 

**Abstract (ZH)**: 近年来，大规模语言模型（LLM）的研究取得了突破性进展，这些模型在大规模通用语料库上进行预训练，能够有效回应人类查询。然而，这些方法也面临着一些挑战，包括数据量有限，不足以支持广泛的预训练，以及生成的响应与用户指令不完全对齐。为了解决这些问题，我们介绍了一个包含六项实际医学任务指令的医学指令数据集，即CMedINS，该数据集能够与其他数据结合，有效微调LLM。随后，我们推出了我们的医学模型IIMedGPT，该模型采用了一种高效的工作指令对齐方法，即直接偏好优化（DPO）。实验结果表明，我们的最终模型在医学领域的表现优于现有模型。我们将在论文被接受后发布代码和模型检查点。 

---
# Enhanced Rooftop Solar Panel Detection by Efficiently Aggregating Local Features 

**Title (ZH)**: 通过有效地聚集局部特征来增强屋顶太阳能板检测 

**Authors**: Kuldeep Kurte, Kedar Kulkarni  

**Link**: [PDF](https://arxiv.org/pdf/2501.02840)  

**Abstract**: In this paper, we present an enhanced Convolutional Neural Network (CNN)-based rooftop solar photovoltaic (PV) panel detection approach using satellite images. We propose to use pre-trained CNN-based model to extract the local convolutional features of rooftops. These local features are then combined using the Vectors of Locally Aggregated Descriptors (VLAD) technique to obtain rooftop-level global features, which are then used to train traditional Machine Learning (ML) models to identify rooftop images that do and do not contain PV panels. On the dataset used in this study, the proposed approach achieved rooftop-PV classification scores exceeding the predefined threshold of 0.9 across all three cities for each of the feature extractor networks evaluated. Moreover, we propose a 3-phase approach to enable efficient utilization of the previously trained models on a new city or region with limited labelled data. We illustrate the effectiveness of this 3-phase approach for multi-city rooftop-PV detection task. 

**Abstract (ZH)**: 在本文中，我们提出了一种基于卷积神经网络（CNN）的增强屋顶太阳能光伏（PV）板检测方法，利用卫星图像进行屋顶检测。我们提议使用预先训练的基于CNN的模型来提取屋顶的局部卷积特征。然后，使用局部聚合描述子向量（VLAD）技术将这些局部特征合并，得到屋顶级别的全局特征。这些全局特征随后用于训练传统的机器学习（ML）模型，以识别包含或不包含PV板的屋顶图像。在本研究使用的数据集中，所提出的方法在三个城市的每一个特征提取网络评估中均实现了超过预设阈值0.9的屋顶-PV分类分数。此外，我们提出了一种三阶段方法，以在新城市或区域有限标注数据的情况下高效利用已训练模型。我们展示了这种三阶段方法在多城市屋顶-PV检测任务中的有效性。 

---
# Forward Once for All: Structural Parameterized Adaptation for Efficient Cloud-coordinated On-device Recommendation 

**Title (ZH)**: 一前讽定 for All：面向高效云协调设备端推荐的结构参数化适应 

**Authors**: Kairui Fu, Zheqi Lv, Shengyu Zhang, Fan Wu, Kun Kuang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02837)  

**Abstract**: In cloud-centric recommender system, regular data exchanges between user devices and cloud could potentially elevate bandwidth demands and privacy risks. On-device recommendation emerges as a viable solution by performing reranking locally to alleviate these concerns. Existing methods primarily focus on developing local adaptive parameters, while potentially neglecting the critical role of tailor-made model architecture. Insights from broader research domains suggest that varying data distributions might favor distinct architectures for better fitting. In addition, imposing a uniform model structure across heterogeneous devices may result in risking inefficacy on less capable devices or sub-optimal performance on those with sufficient capabilities. In response to these gaps, our paper introduces Forward-OFA, a novel approach for the dynamic construction of device-specific networks (both structure and parameters). Forward-OFA employs a structure controller to selectively determine whether each block needs to be assembled for a given device. However, during the training of the structure controller, these assembled heterogeneous structures are jointly optimized, where the co-adaption among blocks might encounter gradient conflicts. To mitigate this, Forward-OFA is designed to establish a structure-guided mapping of real-time behaviors to the parameters of assembled networks. Structure-related parameters and parallel components within the mapper prevent each part from receiving heterogeneous gradients from others, thus bypassing the gradient conflicts for coupled optimization. Besides, direct mapping enables Forward-OFA to achieve adaptation through only one forward pass, allowing for swift adaptation to changing interests and eliminating the requirement for on-device backpropagation. Experiments on real-world datasets demonstrate the effectiveness and efficiency of Forward-OFA. 

**Abstract (ZH)**: 在以云为中心的推荐系统中，用户设备与云端之间频繁的数据交换可能会增加带宽需求和隐私风险。本地推荐作为一种可行的解决方案，通过在本地重新排序来缓解这些问题。现有方法主要聚焦于开发本地自适应参数，但可能忽视了自定义模型架构的至关重要性。来自更广泛的研究领域的见解表明，不同的数据分布可能有利于不同的架构，以更好地拟合数据。此外，强制在异构设备上使用统一的模型结构可能会导致对较少能力的设备无效，或在具有足够能力的设备上表现不佳。为应对这些不足，我们提出了Forward-OFA，这是一种用于动态构建设备特定网络（包括结构和参数）的新方法。Forward-OFA采用一种结构控制器来选择性地确定每个模块是否需要根据指定设备进行组装。然而，在结构控制器的训练过程中，这些装配的异构结构会被联合优化，这可能导致模块间的共适应出现梯度冲突。为了缓解这一问题，Forward-OFA设计了一种结构导向的实时行为到组装网络参数的映射关系，使得结构相关的参数和映射器内的并行组件防止各部分收到来自其他部分的异构梯度，从而避免了耦合优化中的梯度冲突。此外，直接映射使Forward-OFA能够在单次前向传播中实现适应，从而能够迅速适应用户兴趣的变化，消除在设备上进行反向传播的需求。在实际数据集上的实验结果表明，Forward-OFA具有有效性和高效性。 

---
# Samba-asr state-of-the-art speech recognition leveraging structured state-space models 

**Title (ZH)**: Samba-asr基于结构化状态空间模型的先进语音识别技术 

**Authors**: Syed Abdul Gaffar Shakhadri, Kruthika KR, Kartik Basavaraj Angadi  

**Link**: [PDF](https://arxiv.org/pdf/2501.02832)  

**Abstract**: We propose Samba ASR, the first state-of-the-art Automatic Speech Recognition (ASR) model leveraging the novel Mamba architecture as both encoder and decoder, built on the foundation of state-space models (SSMs). Unlike transformer-based ASR models, which rely on self-attention mechanisms to capture dependencies, Samba ASR effectively models both local and global temporal dependencies using efficient state-space dynamics, achieving remarkable performance gains. By addressing the limitations of transformers, such as quadratic scaling with input length and difficulty in handling long-range dependencies, Samba ASR achieves superior accuracy and efficiency.
Experimental results demonstrate that Samba ASR surpasses existing open-source transformer-based ASR models across various standard benchmarks, establishing it as the new state of the art in ASR. Extensive evaluations on benchmark datasets show significant improvements in Word Error Rate (WER), with competitive performance even in low-resource scenarios. Furthermore, the computational efficiency and parameter optimization of the Mamba architecture make Samba ASR a scalable and robust solution for diverse ASR tasks.
Our contributions include:
A new Samba ASR architecture demonstrating the superiority of SSMs over transformer-based models for speech sequence processing. A comprehensive evaluation on public benchmarks showcasing state-of-the-art performance. An analysis of computational efficiency, robustness to noise, and sequence generalization. This work highlights the viability of Mamba SSMs as a transformer-free alternative for efficient and accurate ASR. By leveraging state-space modeling advancements, Samba ASR sets a new benchmark for ASR performance and future research. 

**Abstract (ZH)**: 我们提出了一种名为Samba ASR的自动语音识别（ASR）模型，这是首个利用新型Mamba架构作为编码器和解码器的先进模型，建立在状态空间模型（SSM）的基础上。不同于依赖自注意力机制捕捉依赖关系的基于变压器的ASR模型，Samba ASR通过高效的状态空间动力学有效地建模局部和全局时间依赖性，实现了显著的性能提升。通过克服变压器模型的局限性，如输入长度的二次时间复杂度和处理长距离依赖的困难，Samba ASR在准确性和效率方面表现出优越性。

实验结果表明，Samba ASR在各种标准基准测试中超过了现有的开源基于变压器的ASR模型，确立了其在ASR领域的最新前沿地位。在基准数据集上的广泛评估显示，在单词错误率（WER）方面取得了显著改进，即使在资源有限的情况下也能保持竞争力。此外，Mamba架构的计算效率和参数优化使Samba ASR成为一个适用于各种ASR任务的可扩展且稳健的解决方案。

我们的贡献包括：
- 一种新的Samba ASR架构，展示了相较于基于变压器的模型，状态空间模型（SSM）在处理语音序列方面的优越性。
- 在公开基准上的全面评估，展示了最先进的性能。
- 对计算效率、抗噪性和序列泛化的分析。这项工作突显了Mamba SSM作为无变压器替代方案的可行性，用于提高ASR的高效性和准确性。通过利用状态空间建模的进步，Samba ASR为ASR性能和未来研究树立了新的标准。 

---
# RDD4D: 4D Attention-Guided Road Damage Detection And Classification 

**Title (ZH)**: RDD4D：基于4D注意力引导的道路损坏检测与分类 

**Authors**: Asma Alkalbani, Muhammad Saqib, Ahmed Salim Alrawahi, Abbas Anwar, Chandarnath Adak, Saeed Anwar  

**Link**: [PDF](https://arxiv.org/pdf/2501.02822)  

**Abstract**: Road damage detection and assessment are crucial components of infrastructure maintenance. However, current methods often struggle with detecting multiple types of road damage in a single image, particularly at varying scales. This is due to the lack of road datasets with various damage types having varying scales. To overcome this deficiency, first, we present a novel dataset called Diverse Road Damage Dataset (DRDD) for road damage detection that captures the diverse road damage types in individual images, addressing a crucial gap in existing datasets. Then, we provide our model, RDD4D, that exploits Attention4D blocks, enabling better feature refinement across multiple scales. The Attention4D module processes feature maps through an attention mechanism combining positional encoding and "Talking Head" components to capture local and global contextual information. In our comprehensive experimental analysis comparing various state-of-the-art models on our proposed, our enhanced model demonstrated superior performance in detecting large-sized road cracks with an Average Precision (AP) of 0.458 and maintained competitive performance with an overall AP of 0.445. Moreover, we also provide results on the CrackTinyNet dataset; our model achieved around a 0.21 increase in performance. The code, model weights, dataset, and our results are available on \href{this https URL}{this https URL\_Damage\_Detection}. 

**Abstract (ZH)**: 道路损伤检测与评估是基础设施维护中的关键组成部分。然而，当前的方法往往难以在单张图像中同时检测多种类型的道路损伤，尤其是在不同尺度的情况下。这归因于缺乏包含不同损伤类型和不同尺度的道路数据集。为解决这一缺陷，首先，我们提出了一种名为Diverse Road Damage Dataset (DRDD) 的新数据集，用于道路损伤检测，该数据集捕捉了单张图像中的多种道路损伤类型，填补了现有数据集的关键空白。然后，我们提出了我们的模型 RDD4D，该模型利用了Attention4D模块，使其能够在不同尺度上更好地进行特征精炼。Attention4D模块通过结合位置编码和“说话头部”组件来处理特征图，从而捕捉局部和全局上下文信息。在我们对各种最新模型进行全面的实验分析中，我们的改进模型在检测大型道路裂缝方面表现出优越的性能，平均精确度（AP）为0.458，并且在整体AP为0.445的情况下保持了竞争力。此外，我们还在CrackTinyNet数据集上提供了结果；我们的模型在该数据集上的性能大约提高了0.21。我们的代码、模型权重、数据集以及实验结果可在 \href{此链接}{此链接\_Damage\_Detection} 获取。 

---
# InpDiffusion: Image Inpainting Localization via Conditional Diffusion Models 

**Title (ZH)**: InpDiffusion：基于条件扩散模型的图像修复定位 

**Authors**: Kai Wang, Shaozhang Niu, Qixian Hao, Jiwei Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02816)  

**Abstract**: As artificial intelligence advances rapidly, particularly with the advent of GANs and diffusion models, the accuracy of Image Inpainting Localization (IIL) has become increasingly challenging. Current IIL methods face two main challenges: a tendency towards overconfidence, leading to incorrect predictions; and difficulty in detecting subtle tampering boundaries in inpainted images. In response, we propose a new paradigm that treats IIL as a conditional mask generation task utilizing diffusion models. Our method, InpDiffusion, utilizes the denoising process enhanced by the integration of image semantic conditions to progressively refine predictions. During denoising, we employ edge conditions and introduce a novel edge supervision strategy to enhance the model's perception of edge details in inpainted objects. Balancing the diffusion model's stochastic sampling with edge supervision of tampered image regions mitigates the risk of incorrect predictions from overconfidence and prevents the loss of subtle boundaries that can result from overly stochastic processes. Furthermore, we propose an innovative Dual-stream Multi-scale Feature Extractor (DMFE) for extracting multi-scale features, enhancing feature representation by considering both semantic and edge conditions of the inpainted images. Extensive experiments across challenging datasets demonstrate that the InpDiffusion significantly outperforms existing state-of-the-art methods in IIL tasks, while also showcasing excellent generalization capabilities and robustness. 

**Abstract (ZH)**: 随着人工智能的迅速发展，特别是生成对抗网络（GANs）和扩散模型（Diffusion Models）的出现，图像 inpainting 本地化（IIL）的准确率变得愈发具有挑战性。当前的 IIL 方法面临两个主要挑战：过度自信倾向，导致错误预测；以及在 inpainted 图像中难以检测细微篡改边界。为应对这些挑战，我们提出了一种新的范式，将 IIL 视为使用扩散模型的条件掩码生成任务。我们的方法 InpDiffusion 利用结合图像语义条件增强的去噪过程，逐步细化预测。在去噪过程中，我们采用边缘条件并引入一种新颖的边缘监督策略，以增强模型对 inpainted 物体边缘细节的感知。通过平衡扩散模型的随机采样与篡改图像区域的边缘监督，减轻因过度自信导致的错误预测风险，并防止由过于随机过程导致的细微边界丢失。此外，我们提出了一个创新的双流多尺度特征提取器（Dual-stream Multi-scale Feature Extractor, DMFE），用于提取多尺度特征，通过同时考虑 inpainted 图像的语义和边缘条件来增强特征表示。在多个具有挑战性的数据集上的广泛实验表明，InpDiffusion 在 IIL 任务中显著优于现有最先进的方法，同时展示了出色的泛化能力和鲁棒性。 

---
# Enhancing Lifelong Multi-Agent Path Finding with Cache Mechanism 

**Title (ZH)**: 基于缓存机制增强 lifelong 多代理路径规划 

**Authors**: Yimin Tang, Zhenghong Yu, Yi Zheng, T. K. Satish Kumar, Jiaoyang Li, Sven Koenig  

**Link**: [PDF](https://arxiv.org/pdf/2501.02803)  

**Abstract**: Multi-Agent Path Finding (MAPF), which focuses on finding collision-free paths for multiple robots, is crucial in autonomous warehouse operations. Lifelong MAPF (L-MAPF), where agents are continuously reassigned new targets upon completing their current tasks, offers a more realistic approximation of real-world warehouse scenarios. While cache storage systems can enhance efficiency and reduce operational costs, existing approaches primarily rely on expectations and mathematical models, often without adequately addressing the challenges of multi-robot planning and execution. In this paper, we introduce a novel mechanism called Lifelong MAPF with Cache Mechanism (L-MAPF-CM), which integrates high-level cache storage with low-level path planning. We have involved a new type of map grid called cache for temporary item storage. Additionally, we involved a task assigner (TA) with a locking mechanism to bridge the gap between the new cache grid and L-MAPF algorithm. The TA dynamically allocates target locations to agents based on their status in various scenarios. We evaluated L-MAPF-CM using different cache replacement policies and task distributions. L-MAPF-CM has demonstrated performance improvements particularly with high cache hit rates and smooth traffic conditions. 

**Abstract (ZH)**: 多智能体路径规划（MAPF），专注于为多个智能体找到无碰撞路径，在自主仓库操作中至关重要。终身多智能体路径规划（L-MAPF），其中智能体在完成当前任务后不断重新分配新的目标，能够更好地模拟现实世界仓库中的情况。虽然缓存存储系统可以提高效率并降低运营成本，但现有方法主要依赖于预期和数学模型，往往没有充分解决多智能体规划和执行中的挑战。在本文中，我们提出了一种名为缓存机制结合终身多智能体路径规划（L-MAPF-CM）的新机制，该机制将高层缓存存储与低层路径规划相结合。我们引入了一种新的图层结构，称为缓存图层，用于临时存储物品。此外，我们引入了一个具有锁机制的任务分配器（TA），以弥合新缓存图层与L-MAPF算法之间的差距。TA能够根据智能体的不同状态，动态分配目标位置。我们使用不同的缓存替换策略和任务分布对L-MAPF-CM进行了评估。实验结果表明，L-MAPF-CM在高缓存命中率和顺畅交通条件下，表现出性能改进。 

---
# Segmenting Text and Learning Their Rewards for Improved RLHF in Language Model 

**Title (ZH)**: 改进语言模型的RLHF性能通过文本分割和学习其奖励 

**Authors**: Yueqin Yin, Shentao Yang, Yujia Xie, Ziyi Yang, Yuting Sun, Hany Awadalla, Weizhu Chen, Mingyuan Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2501.02790)  

**Abstract**: Reinforcement learning from human feedback (RLHF) has been widely adopted to align language models (LMs) with human preference. Prior RLHF works typically take a bandit formulation, which, though intuitive, ignores the sequential nature of LM generation and can suffer from the sparse reward issue. While recent works propose dense token-level RLHF, treating each token as an action may be oversubtle to proper reward assignment. In this paper, we seek to get the best of both by training and utilizing a segment-level reward model, which assigns a reward to each semantically complete text segment that spans over a short sequence of tokens. For reward learning, our method allows dynamic text segmentation and compatibility with standard sequence-preference datasets. For effective RL-based LM training against segment reward, we generalize the classical scalar bandit reward normalizers into location-aware normalizer functions and interpolate the segment reward for further densification. With these designs, our method performs competitively on three popular RLHF benchmarks for LM policy: AlpacaEval 2.0, Arena-Hard, and MT-Bench. Ablation studies are conducted to further demonstrate our method. 

**Abstract (ZH)**: 人类反馈强化学习（RLHF）已被广泛用于使语言模型（LMs）与人类偏好保持一致。之前的RLHF工作通常采用赌博机形式，尽管直观，但忽视了LM生成的顺序性，并可能面临稀疏奖励的问题。近期的工作提出了密集的令牌级RLHF，将每个令牌视为动作可能过于微妙，不足以正确分配奖励。在本文中，我们旨在兼收并蓄，通过训练和利用段落级奖励模型来获得最佳效果，该模型为一段包含多个令牌的语义完整文本段分配奖励。对于奖励学习，我们的方法允许动态文本分段，并与标准序列偏好数据集兼容。为了有效地基于段落奖励对LM进行RL训练，我们将经典的标量赌博机奖励归一化技术扩展为位置感知的归一化函数，并对段落奖励进行插值以进一步增加密度。通过这些设计，我们的方法在三个流行的RLHF基准测试（AlpacaEval 2.0、Arena-Hard和MT-Bench）中表现出色。我们还进行了消融研究以进一步验证我们的方法。 

---
# GLoG-CSUnet: Enhancing Vision Transformers with Adaptable Radiomic Features for Medical Image Segmentation 

**Title (ZH)**: GLoG-CSUnet：通过可适应的影像组学特征增强视觉变换器的医学图像分割 

**Authors**: Niloufar Eghbali, Hassan Bagher-Ebadian, Tuka Alhanai, Mohammad M. Ghassemi  

**Link**: [PDF](https://arxiv.org/pdf/2501.02788)  

**Abstract**: Vision Transformers (ViTs) have shown promise in medical image semantic segmentation (MISS) by capturing long-range correlations. However, ViTs often struggle to model local spatial information effectively, which is essential for accurately segmenting fine anatomical details, particularly when applied to small datasets without extensive pre-training. We introduce Gabor and Laplacian of Gaussian Convolutional Swin Network (GLoG-CSUnet), a novel architecture enhancing Transformer-based models by incorporating learnable radiomic features. This approach integrates dynamically adaptive Gabor and Laplacian of Gaussian (LoG) filters to capture texture, edge, and boundary information, enhancing the feature representation processed by the Transformer model. Our method uniquely combines the long-range dependency modeling of Transformers with the texture analysis capabilities of Gabor and LoG features. Evaluated on the Synapse multi-organ and ACDC cardiac segmentation datasets, GLoG-CSUnet demonstrates significant improvements over state-of-the-art models, achieving a 1.14\% increase in Dice score for Synapse and 0.99\% for ACDC, with minimal computational overhead (only 15 and 30 additional parameters, respectively). GLoG-CSUnet's flexible design allows integration with various base models, offering a promising approach for incorporating radiomics-inspired feature extraction in Transformer architectures for medical image analysis. The code implementation is available on GitHub at: this https URL. 

**Abstract (ZH)**: 视觉变换器（Vision Transformers，ViTs）已经在医疗图像语义分割（Medical Image Semantic Segmentation，MISS）方面显示出潜力，通过捕捉长程相关性。然而，ViTs在有效建模局部空间信息方面常常遇到困难，这是准确分割细微解剖细节所必需的，尤其是在应用到小数据集且未进行大量预训练时。为此，我们提出了一种新的架构——可学习放射学特征增强的变换器网络（Gabor and Laplacian of Gaussian Convolutional Swin Network，GLoG-CSUnet），增强了基于变换器的模型。该方法通过集成动态自适应的Gabor和高斯拉普拉斯（Laplacian of Gaussian，LoG）滤波器来捕捉纹理、边缘和边界信息，增强了传递给变换器模型的特征表示。我们的方法独特地结合了变换器的长程依赖建模与Gabor和LoG特征的纹理分析能力。

GLoG-CSUnet已在Synapse多器官和ACDC心脏分割数据集上进行评估，展示了显著改进，相较于最先进的模型，GLoG-CSUnet在Synapse上的Dice分数提高了1.14%，在ACDC上提高了0.99%，同时计算开销很小（分别仅增加了15和30个参数）。GLoG-CSUnet的灵活设计允许其与各种基础模型集成，为在医疗图像分析中结合放射学特征提取提供了一种有前途的方法。代码实现可以在GitHub上找到： [](https://github.com/yourusername/your-repo)。

请注意，上述代码链接需要替换为实际的GitHub链接。 

---
# Hybrid deep convolution model for lung cancer detection with transfer learning 

**Title (ZH)**: 基于迁移学习的混合deep卷积模型在肺癌检测中的应用 

**Authors**: Sugandha Saxena, S. N. Prasad, Ashwin M Polnaya, Shweta Agarwala  

**Link**: [PDF](https://arxiv.org/pdf/2501.02785)  

**Abstract**: Advances in healthcare research have significantly enhanced our understanding of disease mechanisms, diagnostic precision, and therapeutic options. Yet, lung cancer remains one of the leading causes of cancer-related mortality worldwide due to challenges in early and accurate diagnosis. While current lung cancer detection models show promise, there is considerable potential for further improving the accuracy for timely intervention. To address this challenge, we introduce a hybrid deep convolution model leveraging transfer learning, named the Maximum Sensitivity Neural Network (MSNN). MSNN is designed to improve the precision of lung cancer detection by refining sensitivity and specificity. This model has surpassed existing deep learning approaches through experimental validation, achieving an accuracy of 98% and a sensitivity of 97%. By overlaying sensitivity maps onto lung Computed Tomography (CT) scans, it enables the visualization of regions most indicative of malignant or benign classifications. This innovative method demonstrates exceptional performance in distinguishing lung cancer with minimal false positives, thereby enhancing the accuracy of medical diagnoses. 

**Abstract (ZH)**: 医学研究领域的进展显著增强了我们对疾病机制、诊断准确性和治疗选择的理解。然而，由于早期和准确诊断的挑战，肺癌仍然是全球癌症相关死亡的主要原因之一。尽管现有的肺癌检测模型展现出一定的潜力，但仍有很大的改进空间以提高及时干预的准确性。为应对这一挑战，我们提出了一种结合迁移学习的混合深度卷积模型，命名为最大灵敏度神经网络（Maximum Sensitivity Neural Network, MSNN）。MSNN 设计旨在通过提高灵敏度和特异性来提高肺癌检测的精确度。通过实验验证，该模型已超越现有的深度学习方法，实现了98%的准确率和97%的灵敏度。通过将灵敏度图叠加到肺部计算机断层扫描（CT）图像上，该模型能够可视化最能指示恶性或良性分类的区域。这种方法在区分肺癌时表现卓越，具有极低的假阳性率，从而提升了医学诊断的准确性。 

---
# ICFNet: Integrated Cross-modal Fusion Network for Survival Prediction 

**Title (ZH)**: ICFNet：综合跨模态融合网络用于生存预测 

**Authors**: Binyu Zhang, Zhu Meng, Junhao Dong, Fei Su, Zhicheng Zhao  

**Link**: [PDF](https://arxiv.org/pdf/2501.02778)  

**Abstract**: Survival prediction is a crucial task in the medical field and is essential for optimizing treatment options and resource allocation. However, current methods often rely on limited data modalities, resulting in suboptimal performance. In this paper, we propose an Integrated Cross-modal Fusion Network (ICFNet) that integrates histopathology whole slide images, genomic expression profiles, patient demographics, and treatment protocols. Specifically, three types of encoders, a residual orthogonal decomposition module and a unification fusion module are employed to merge multi-modal features to enhance prediction accuracy. Additionally, a balanced negative log-likelihood loss function is designed to ensure fair training across different patients. Extensive experiments demonstrate that our ICFNet outperforms state-of-the-art algorithms on five public TCGA datasets, including BLCA, BRCA, GBMLGG, LUAD, and UCEC, and shows its potential to support clinical decision-making and advance precision medicine. The codes are available at: this https URL. 

**Abstract (ZH)**: 生存预测是医学领域的一项关键任务，对于优化治疗方案和资源分配至关重要。然而，当前的方法往往依赖于有限的数据模态，导致性能欠佳。本文提出了一种综合跨模态融合网络（ICFNet），将组织病理学全切片图像、基因表达谱、患者人口统计信息以及治疗方案结合在一起。具体地，该网络采用了三种编码器、一个残差正交分解模块和一个统一融合模块来合并多模态特征，以提高预测准确性。此外，设计了一种平衡的负对数似然损失函数，以确保在不同患者之间公平训练。大量实验表明，我们的ICFNet在TCGA发布的五个公开数据集（BLCA、BRCA、GBMLGG、LUAD和UCEC）上优于最先进的算法，并且展示了其支持临床决策和推动精准医疗的应用潜力。代码可在以下链接获取：this https URL。 

---
# Enhancing Trustworthiness of Graph Neural Networks with Rank-Based Conformal Training 

**Title (ZH)**: 基于排名的可信性校准训练提升图神经网络的信任度 

**Authors**: Ting Wang, Zhixin Zhou, Rui Luo  

**Link**: [PDF](https://arxiv.org/pdf/2501.02767)  

**Abstract**: Graph Neural Networks (GNNs) has been widely used in a variety of fields because of their great potential in representing graph-structured data. However, lacking of rigorous uncertainty estimations limits their application in high-stakes. Conformal Prediction (CP) can produce statistically guaranteed uncertainty estimates by using the classifier's probability estimates to obtain prediction sets, which contains the true class with a user-specified probability. In this paper, we propose a Rank-based CP during training framework to GNNs (RCP-GNN) for reliable uncertainty estimates to enhance the trustworthiness of GNNs in the node classification scenario. By exploiting rank information of the classifier's outcome, prediction sets with desired coverage rate can be efficiently constructed. The strategy of CP during training with differentiable rank-based conformity loss function is further explored to adapt prediction sets according to network topology information. In this way, the composition of prediction sets can be guided by the goal of jointly reducing inefficiency and probability estimation errors. Extensive experiments on several real-world datasets show that our model achieves any pre-defined target marginal coverage while significantly reducing the inefficiency compared with state-of-the-art methods. 

**Abstract (ZH)**: 图神经网络（GNNs）由于其在表示图结构数据方面巨大的潜力，已在众多领域得到广泛应用。然而，由于缺乏严格的不确定性估计，限制了其在高风险应用场景中的应用。校准预测（Conformal Prediction，CP）可以通过使用分类器的概率估计来生成预测集，从而以用户指定的概率包含真实类。在这种情况下，本论文提出了一种在训练过程中基于排名的校准预测框架（RCP-GNN），以提高GNNs在节点分类场景中的可信度。通过利用分类器结果的排名信息，可以高效地构建具有所需覆盖率的预测集。此外，进一步探索了基于可微排名一致性损失函数的训练过程中校准预测策略，使预测集能够根据网络拓扑信息进行调整。这样一来，预测集的组成可以联合减小无效率和概率估计误差的目标进行引导。在多个真实世界数据集上的广泛实验表明，我们的模型不仅可实现预定义的目标边际覆盖，而且与现有最先进的方法相比，显著降低了无效率。 

---
# Are GNNs Effective for Multimodal Fault Diagnosis in Microservice Systems? 

**Title (ZH)**: 多模态故障诊断在微服务系统中，图神经网络（GNNs）有效吗？ 

**Authors**: Fei Gao, Ruyue Xin, Yaqiang Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02766)  

**Abstract**: Fault diagnosis in microservice systems has increasingly embraced multimodal observation data for a holistic and multifaceted view of the system, with Graph Neural Networks (GNNs) commonly employed to model complex service dependencies. However, despite the intuitive appeal, there remains a lack of compelling justification for the adoption of GNNs, as no direct evidence supports their necessity or effectiveness. To critically evaluate the current use of GNNs, we propose DiagMLP, a simple topology-agnostic baseline as a substitute for GNNs in fault diagnosis frameworks. Through experiments on five public datasets, we surprisingly find that DiagMLP performs competitively with and even outperforms GNN-based methods in fault diagnosis tasks, indicating that the current paradigm of using GNNs to model service dependencies has not yet demonstrated a tangible contribution. We further discuss potential reasons for this observation and advocate shifting the focus from solely pursuing novel model designs to developing challenging datasets, standardizing preprocessing protocols, and critically evaluating the utility of advanced deep learning modules. 

**Abstract (ZH)**: 以下是经过学术规范翻译的内容：

在微服务系统中，故障诊断越来越多地采用多模态观测数据，以实现对系统的全面和多维度视角。图神经网络（GNNs）通常被用来建模复杂的服务依赖关系。尽管如此，采用GNNs的直观吸引力尚缺乏有力的论据支持，因为没有直接证据证明GNNs的必要性和有效性。为了对当前GNNs的使用进行批判性评估，我们提出了一种简单的拓扑无关的基准方法——DiagMLP，作为GNNs在故障诊断框架中的替代方案。通过在五个公开数据集上的实验，我们惊讶地发现，DiagMLP在故障诊断任务中表现得与基于GNN的方法相当甚至更优，这表明当前使用GNNs建模服务依赖关系的范式尚未显示出实质性贡献。此外，我们讨论了这一现象的潜在原因，并提倡从仅仅追求新的模型设计转向开发更具挑战性的数据集、标准化预处理协议，并对先进深度学习模块的实际应用价值进行批判性评估。 

---
# Visual Large Language Models for Generalized and Specialized Applications 

**Title (ZH)**: 视觉大型语言模型在通用和专用应用中的应用 

**Authors**: Yifan Li, Zhixin Lai, Wentao Bao, Zhen Tan, Anh Dao, Kewei Sui, Jiayi Shen, Dong Liu, Huan Liu, Yu Kong  

**Link**: [PDF](https://arxiv.org/pdf/2501.02765)  

**Abstract**: Visual-language models (VLM) have emerged as a powerful tool for learning a unified embedding space for vision and language. Inspired by large language models, which have demonstrated strong reasoning and multi-task capabilities, visual large language models (VLLMs) are gaining increasing attention for building general-purpose VLMs. Despite the significant progress made in VLLMs, the related literature remains limited, particularly from a comprehensive application perspective, encompassing generalized and specialized applications across vision (image, video, depth), action, and language modalities. In this survey, we focus on the diverse applications of VLLMs, examining their using scenarios, identifying ethics consideration and challenges, and discussing future directions for their development. By synthesizing these contents, we aim to provide a comprehensive guide that will pave the way for future innovations and broader applications of VLLMs. The paper list repository is available: this https URL. 

**Abstract (ZH)**: 视觉-语言模型（VLM）已经成为学习视觉和语言统一嵌入空间的有力工具。受到大型语言模型的启发，这些模型在推理和多任务处理方面表现出色，视觉大型语言模型（VLLMs）正在逐渐引起关注，用于构建通用的VLM框架。尽管在VLLMs方面取得了显著进展，但在全面应用视角的研究仍然有限，尤其涵盖视觉（图像、视频、深度）、动作和语言等不同模态的一般性和专门化应用。在本文综述中，我们重点关注VLLMs的多样应用场景，考察其使用情况，识别伦理考量和挑战，并讨论其未来发展方向。通过综合这些内容，我们旨在提供一个全面的指南，以推动VLLMs的创新和更广泛的应用。本文的参考文献库地址如下：[这里提供链接] 

---
# Enhancing Robot Route Optimization in Smart Logistics with Transformer and GNN Integration 

**Title (ZH)**: 智能物流中基于变压器和GNN集成的机器人路线优化增强方法 

**Authors**: Hao Luo, Jianjun Wei, Shuchen Zhao, Ankai Liang, Zhongjin Xu, Ruxue Jiang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02749)  

**Abstract**: This research delves into advanced route optimization for robots in smart logistics, leveraging a fusion of Transformer architectures, Graph Neural Networks (GNNs), and Generative Adversarial Networks (GANs). The approach utilizes a graph-based representation encompassing geographical data, cargo allocation, and robot dynamics, addressing both spatial and resource limitations to refine route efficiency. Through extensive testing with authentic logistics datasets, the proposed method achieves notable improvements, including a 15% reduction in travel distance, a 20% boost in time efficiency, and a 10% decrease in energy consumption. These findings highlight the algorithm's effectiveness, promoting enhanced performance in intelligent logistics operations. 

**Abstract (ZH)**: 本研究深入探讨了智能物流中机器人的高级路线优化问题，综合利用了Transformer架构、图神经网络（GNN）和生成对抗网络（GAN）等方法。该方法采用基于图的表示形式，涵盖了地理数据、货物分配和机器人动力学，同时解决了空间和资源限制问题，以优化路线效率。通过使用真实的物流数据集进行广泛测试，所提出的方法取得了显著的改进，包括减少了15%的行驶距离、提高了20%的时间效率以及降低了10%的能耗。这些发现突显了该算法的有效性，促进了智能物流操作性能的提升。 

---
# Interpretable Recognition of Fused Magnesium Furnace Working Conditions with Deep Convolutional Stochastic Configuration Networks 

**Title (ZH)**: 具有深度卷积随机配置网络的可解释融合镁炉工作条件识别 

**Authors**: Li Weitao, Zhang Xinru, Wang Dianhui, Tong Qianqian, Chai Tianyou  

**Link**: [PDF](https://arxiv.org/pdf/2501.02740)  

**Abstract**: To address the issues of a weak generalization capability and interpretability in working condition recognition model of a fused magnesium furnace, this paper proposes an interpretable working condition recognition method based on deep convolutional stochastic configuration networks (DCSCNs). Firstly, a supervised learning mechanism is employed to generate physically meaningful Gaussian differential convolution kernels. An incremental method is utilized to construct a DCSCNs model, ensuring the convergence of recognition errors in a hierarchical manner and avoiding the iterative optimization process of convolutional kernel parameters using the widely used backpropagation algorithm. The independent coefficient of channel feature maps is defined to obtain the visualization results of feature class activation maps for the fused magnesium furnace. A joint reward function is constructed based on the recognition accuracy, the interpretable trustworthiness evaluation metrics, and the model parameter quantity. Reinforcement learning (RL) is applied to adaptively prune the convolutional kernels of the DCSCNs model, aiming to build a compact, highly performed and interpretable network. The experimental results demonstrate that the proposed method outperforms the other deep learning approaches in terms of recognition accuracy and interpretability. 

**Abstract (ZH)**: 为了应对融合镁炉工作状态识别模型在泛化能力和可解释性方面的不足，本文提出了一种基于深度卷积随机配置网络（DCSCNs）的可解释工作状态识别方法。首先，采用监督学习机制生成具有物理意义的高斯微分卷积核。通过增量方法构建DCSCNs模型，确保识别误差在层次化的逐级收敛，同时避免使用广为使用的反向传播算法对卷积核参数进行迭代优化。定义信道特征图的独立系数，以获得融合镁炉特征类别激活图的可视化结果。基于识别准确率、可解释性评估指标以及模型参数数量，构造联合奖励函数。采用强化学习（RL）自适应地修剪DCSCNs模型中的卷积核，旨在构建一个紧凑、高性能且可解释的网络。实验结果表明，所提出的方法在识别准确性和可解释性方面优于其他深度学习方法。 

---
# TARDiS : Text Augmentation for Refining Diversity and Separability 

**Title (ZH)**: TARDiS：文本增强以完善多样性和可分性 

**Authors**: Kyungmin Kim, SangHun Im, GiBaeg Kim, Heung-Seon Oh  

**Link**: [PDF](https://arxiv.org/pdf/2501.02739)  

**Abstract**: Text augmentation (TA) is a critical technique for text classification, especially in few-shot settings. This paper introduces a novel LLM-based TA method, TARDiS, to address challenges inherent in the generation and alignment stages of two-stage TA methods. For the generation stage, we propose two generation processes, SEG and CEG, incorporating multiple class-specific prompts to enhance diversity and separability. For the alignment stage, we introduce a class adaptation (CA) method to ensure that generated examples align with their target classes through verification and modification. Experimental results demonstrate TARDiS's effectiveness, outperforming state-of-the-art LLM-based TA methods in various few-shot text classification tasks. An in-depth analysis confirms the detailed behaviors at each stage. 

**Abstract (ZH)**: 文本扩增（TA）是文本分类中的一项关键技术，尤其是在 few-shot 设置中。本文介绍了一种基于大规模语言模型（LLM）的新颖 TA 方法 TARDiS，以应对两阶段 TA 方法中生成和对齐阶段固有的挑战。对于生成阶段，我们提出了两种生成过程，即 SEG 和 CEG，并结合多个类别特定的提示来增强多样性和可区分性。对于对齐阶段，我们引入了一种类别适应（CA）方法，通过验证和修改确保生成的示例与目标类别相一致。实验结果表明，TARDiS 有效，其在多种 few-shot 文本分类任务中显著优于现有的 LLM 基础 TA 方法。深入分析确认了每个阶段的具体行为。 

---
# AFed: Algorithmic Fair Federated Learning 

**Title (ZH)**: AFed: 算法公平联邦学习 

**Authors**: Huiqiang Chen, Tianqing Zhu, Wanlei Zhou, Wei Zhao  

**Link**: [PDF](https://arxiv.org/pdf/2501.02732)  

**Abstract**: Federated Learning (FL) has gained significant attention as it facilitates collaborative machine learning among multiple clients without centralizing their data on a server. FL ensures the privacy of participating clients by locally storing their data, which creates new challenges in fairness. Traditional debiasing methods assume centralized access to sensitive information, rendering them impractical for the FL setting. Additionally, FL is more susceptible to fairness issues than centralized machine learning due to the diverse client data sources that may be associated with group information. Therefore, training a fair model in FL without access to client local data is important and challenging. This paper presents AFed, a straightforward yet effective framework for promoting group fairness in FL. The core idea is to circumvent restricted data access by learning the global data distribution. This paper proposes two approaches: AFed-G, which uses a conditional generator trained on the server side, and AFed-GAN, which improves upon AFed-G by training a conditional GAN on the client side. We augment the client data with the generated samples to help remove bias. Our theoretical analysis justifies the proposed methods, and empirical results on multiple real-world datasets demonstrate a substantial improvement in AFed over several baselines. 

**Abstract (ZH)**: 联邦学习（FL）由于其能够在客户端不集中存储数据的情况下促进多方协作机器学习，已经引起了广泛关注。FL通过在本地存储数据来保证参与客户端的隐私，这为公平性带来了新的挑战。传统的去偏方法假设可以集中访问敏感信息，这在FL环境中是不切实际的。此外，由于FL在客户端的数据来源可能与群体信息相关，因此与传统的中心化机器学习相比，其更容易出现公平性问题。因此，在不访问客户端本地数据的情况下训练一个公平的模型是重要且具有挑战性的。本文提出了一种简单而有效的AFed框架，用于促进FL中的群体公平性。其核心思想是通过学习全局数据分布来绕过受限的数据访问。本文提出了两种方法：AFed-G，它在服务器端训练一个条件生成器；AFed-GAN，在客户端训练一个条件GAN，并在此基础上改进了AFed-G。我们将生成的样本加入客户端数据中，以帮助去除偏差。我们的理论分析证明了所提出方法的合理性，并且在多个实际数据集上的实证结果表明，AFed在多个基准方法上取得了显著的改进。 

---
# OpenGU: A Comprehensive Benchmark for Graph Unlearning 

**Title (ZH)**: OpenGU：图遗忘的全面基准测试 

**Authors**: Bowen Fan, Yuming Ai, Xunkai Li, Zhilin Guo, Rong-Hua Li, Guoren Wang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02728)  

**Abstract**: Graph Machine Learning is essential for understanding and analyzing relational data. However, privacy-sensitive applications demand the ability to efficiently remove sensitive information from trained graph neural networks (GNNs), avoiding the unnecessary time and space overhead caused by retraining models from scratch. To address this issue, Graph Unlearning (GU) has emerged as a critical solution, with the potential to support dynamic graph updates in data management systems and enable scalable unlearning in distributed data systems while ensuring privacy compliance. Unlike machine unlearning in computer vision or other fields, GU faces unique difficulties due to the non-Euclidean nature of graph data and the recursive message-passing mechanism of GNNs. Additionally, the diversity of downstream tasks and the complexity of unlearning requests further amplify these challenges. Despite the proliferation of diverse GU strategies, the absence of a benchmark providing fair comparisons for GU, and the limited flexibility in combining downstream tasks and unlearning requests, have yielded inconsistencies in evaluations, hindering the development of this domain. To fill this gap, we present OpenGU, the first GU benchmark, where 16 SOTA GU algorithms and 37 multi-domain datasets are integrated, enabling various downstream tasks with 13 GNN backbones when responding to flexible unlearning requests. Based on this unified benchmark framework, we are able to provide a comprehensive and fair evaluation for GU. Through extensive experimentation, we have drawn $8$ crucial conclusions about existing GU methods, while also gaining valuable insights into their limitations, shedding light on potential avenues for future research. 

**Abstract (ZH)**: 图机器学习对于理解和分析关联数据至关重要。然而，隐私敏感的应用程序需要能够高效地从已经训练好的图神经网络（GNNs）中删除敏感信息，避免重新训练模型带来的不必要的时间和空间开销。为了解决这一问题，图抹除（Graph Unlearning，简称为GU）作为一种关键解决方案出现，能够在数据管理系统中支持动态图更新，并在分布式数据系统中实现可扩展的抹除操作，同时确保隐私合规性。与计算机视觉或其他领域的机器抹除不同，GU面临独特的挑战，因为图数据的非欧几里得性质以及GNN中的递归消息传递机制。此外，下游任务的多样性以及抹除请求的复杂性进一步加剧了这些挑战。尽管已经出现了各种GU策略，但由于缺乏一个提供公平比较的基准，且下游任务与抹除请求的结合灵活性有限，导致评估结果不一致，阻碍了该领域的进一步发展。

为了填补这一空白，我们提出了OpenGU，第一个GU基准，集成了16种当前最佳（State-of-the-Art, SOTA）GU算法和37个多领域数据集，能够根据灵活的抹除请求支持13种不同的GNN骨架实现各种下游任务。基于这一统一基准框架，我们能够全面且公平地评估GU。通过广泛的实验，我们得出8个重要结论，同时还发现了现有GU方法的局限性，并为未来的研究提供了有价值的洞见。

该结论包括但不限于以下几个方面：
1. 不同的GU算法在处理不同类型数据时表现出显著的不同性能。
2. GNN骨架的选择对于GU的有效性至关重要，不同的骨架可能对抹除操作的效率有显著影响。
3. 抹除请求的灵活性和多样性对评估结果产生了重要影响。
4. 高效的GU算法需要结合有效的数据结构和算法设计。
5. 多领域数据集的引入使得GU算法的评估更加全面和公正。
6. 现有的GU方法在处理大规模图数据时仍存在挑战。
7. 需要进一步研究GU对动态图更新的支持。
8. GU方法尚需进一步研究以确保隐私合规性。

这些发现为进一步研究提供了方向，并有助于改进GU方法，提高其在实际应用中的性能和可靠性。 

---
# Tree-based RAG-Agent Recommendation System: A Case Study in Medical Test Data 

**Title (ZH)**: 基于树结构的RAG代理推荐系统：一项关于医学测试数据的研究案例 

**Authors**: Yahe Yang, Chengyue Huang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02727)  

**Abstract**: We present HiRMed (Hierarchical RAG-enhanced Medical Test Recommendation), a novel tree-structured recommendation system that leverages Retrieval-Augmented Generation (RAG) for intelligent medical test recommendations. Unlike traditional vector similarity-based approaches, our system performs medical reasoning at each tree node through a specialized RAG process. Starting from the root node with initial symptoms, the system conducts step-wise medical analysis to identify potential underlying conditions and their corresponding diagnostic requirements. At each level, instead of simple matching, our RAG-enhanced nodes analyze retrieved medical knowledge to understand symptom-disease relationships and determine the most appropriate diagnostic path. The system dynamically adjusts its recommendation strategy based on medical reasoning results, considering factors such as urgency levels and diagnostic uncertainty. Experimental results demonstrate that our approach achieves superior performance in terms of coverage rate, accuracy, and miss rate compared to conventional retrieval-based methods. This work represents a significant advance in medical test recommendation by introducing medical reasoning capabilities into the traditional tree-based retrieval structure. 

**Abstract (ZH)**: 我们提出了一种名为 HiRMed（层次增强检索生成医疗测试推荐）的创新树结构推荐系统，该系统利用检索增强生成（RAG）技术实现智能化的医疗测试推荐。与传统的基于向量相似性的方法不同，我们的系统在每一棵树节点处通过专门的 RAG 过程进行医疗推理。从根节点出发，初始症状开始，系统逐步进行医疗分析，以识别潜在的病因及其对应的诊断需求。在每一层中，相较于简单的匹配，带有 RAG 增强的节点分析检索到的医学知识，了解症状-疾病关系，并确定最合适的诊断路径。系统根据医疗推理的结果动态调整其推荐策略，综合考虑急迫程度和诊断不确定性等因素。实验结果表明，与传统的基于检索的方法相比，我们的方法在覆盖率、准确性和漏诊率等方面表现更优。这项工作代表了在传统的基于树的检索结构中引入医疗推理能力的重要进展，在医疗测试推荐方面取得了显著进步。 

---
# Improved Data Encoding for Emerging Computing Paradigms: From Stochastic to Hyperdimensional Computing 

**Title (ZH)**: 新兴计算范式中的数据编码改进：从概率计算到超维度计算 

**Authors**: Mehran Shoushtari Moghadam, Sercan Aygun, M.Hassan Najafi  

**Link**: [PDF](https://arxiv.org/pdf/2501.02715)  

**Abstract**: Data encoding is a fundamental step in emerging computing paradigms, particularly in stochastic computing (SC) and hyperdimensional computing (HDC), where it plays a crucial role in determining the overall system performance and hardware cost efficiency. This study presents an advanced encoding strategy that leverages a hardware-friendly class of low-discrepancy (LD) sequences, specifically powers-of-2 bases of Van der Corput (VDC) sequences (VDC-2^n), as sources for random number generation. Our approach significantly enhances the accuracy and efficiency of SC and HDC systems by addressing challenges associated with randomness. By employing LD sequences, we improve correlation properties and reduce hardware complexity. Experimental results demonstrate significant improvements in accuracy and energy savings for SC and HDC systems. Our solution provides a robust framework for integrating SC and HDC in resource-constrained environments, paving the way for efficient and scalable AI implementations. 

**Abstract (ZH)**: 数据编码是新兴计算范式中的一个基本步骤，尤其是在随机计算（SC）和超维计算（HDC）中，数据编码对系统的整体性能和硬件成本效率起着决定性作用。本文提出了一种先进的编码策略，该策略利用一类硬件友好型低方差（LD）序列，特别是维特科普夫（VDC）序列的2的幂次作为随机数生成的来源（称为VDC-2^n）。我们的方法通过解决与随机性相关的问题，显著提高了SC和HDC系统的准确性和效率。通过采用LD序列，我们改善了相关性特性并减少了硬件复杂度。实验结果表明，我们的方法在SC和HDC系统中显著提高了准确性和节省了能源。我们的解决方案为在资源受限环境中整合SC和HDC提供了稳健的框架，为高效且可扩展的AI实现开辟了道路。 

---
# Horizon Generalization in Reinforcement Learning 

**Title (ZH)**: 强化学习中的视野外泛化 

**Authors**: Vivek Myers, Catherine Ji, Benjamin Eysenbach  

**Link**: [PDF](https://arxiv.org/pdf/2501.02709)  

**Abstract**: We study goal-conditioned RL through the lens of generalization, but not in the traditional sense of random augmentations and domain randomization. Rather, we aim to learn goal-directed policies that generalize with respect to the horizon: after training to reach nearby goals (which are easy to learn), these policies should succeed in reaching distant goals (which are quite challenging to learn). In the same way that invariance is closely linked with generalization is other areas of machine learning (e.g., normalization layers make a network invariant to scale, and therefore generalize to inputs of varying scales), we show that this notion of horizon generalization is closely linked with invariance to planning: a policy navigating towards a goal will select the same actions as if it were navigating to a waypoint en route to that goal. Thus, such a policy trained to reach nearby goals should succeed at reaching arbitrarily-distant goals. Our theoretical analysis proves that both horizon generalization and planning invariance are possible, under some assumptions. We present new experimental results and recall findings from prior work in support of our theoretical results. Taken together, our results open the door to studying how techniques for invariance and generalization developed in other areas of machine learning might be adapted to achieve this alluring property. 

**Abstract (ZH)**: 我们通过泛化的视角研究基于目标的强化学习（RL），但这种泛化并非传统意义上的随机增强和领域随机化。相反，我们的目标是学习能够在不同时间尺度上泛化的目标导向策略：经过训练以达到附近的目标（这些目标容易学习），这些策略应该能够在达到较远的目标（这些目标非常难以学习）上取得成功。与机器学习其他领域中的不变性与泛化紧密相关（例如，归一化层使网络对尺度不变，从而能够处理不同尺度的输入）类似，我们证明了这种地平线泛化的概念与规划不变性密切相关：一个朝目标行动的策略所选择的行动应该与它在从途经点前往该目标的过程中所采取的行动相同。因此，这种被训练以达到附近目标的策略应该能够成功达到任意远的目标。我们的理论分析证明，在某些假设下，这种地平线泛化与规划不变性是可能实现的。我们提供了新的实验结果，并回忆了先前研究中的发现以支持我们的理论结果。综合来看，我们的研究为如何在强化学习的其他领域开发的不变性和泛化技术中寻找实现这种令人向往的性质的方法打开了大门。 

---
# QuIM-RAG: Advancing Retrieval-Augmented Generation with Inverted Question Matching for Enhanced QA Performance 

**Title (ZH)**: QuIM-RAG：通过反转问题匹配提升检索增强生成的问答性能 

**Authors**: Binita Saha, Utsha Saha, Muhammad Zubair Malik  

**Link**: [PDF](https://arxiv.org/pdf/2501.02702)  

**Abstract**: This work presents a novel architecture for building Retrieval-Augmented Generation (RAG) systems to improve Question Answering (QA) tasks from a target corpus. Large Language Models (LLMs) have revolutionized the analyzing and generation of human-like text. These models rely on pre-trained data and lack real-time updates unless integrated with live data tools. RAG enhances LLMs by integrating online resources and databases to generate contextually appropriate responses. However, traditional RAG still encounters challenges like information dilution and hallucinations when handling vast amounts of data. Our approach addresses these challenges by converting corpora into a domain-specific dataset and RAG architecture is constructed to generate responses from the target document. We introduce QuIM-RAG (Question-to-question Inverted Index Matching), a novel approach for the retrieval mechanism in our system. This strategy generates potential questions from document chunks and matches these with user queries to identify the most relevant text chunks for generating accurate answers. We have implemented our RAG system on top of the open-source Meta-LLaMA3-8B-instruct model by Meta Inc. that is available on Hugging Face. We constructed a custom corpus of 500+ pages from a high-traffic website accessed thousands of times daily for answering complex questions, along with manually prepared ground truth QA for evaluation. We compared our approach with traditional RAG models using BERT-Score and RAGAS, state-of-the-art metrics for evaluating LLM applications. Our evaluation demonstrates that our approach outperforms traditional RAG architectures on both metrics. 

**Abstract (ZH)**: 本文提出了一个新的架构，用于构建检索增强生成（RAG）系统，以提高目标语料库中的问答（QA）任务性能。大型语言模型（LLMs）已经彻底改变了人类似文本的分析和生成。这些模型依赖于预训练数据，除非与实时数据工具集成，否则无法实现在线更新。RAG通过整合在线资源和数据库来增强LLMs，从而生成上下文相关性更强的响应。然而，传统的RAG在处理大量数据时仍面临信息稀释和幻觉等挑战。我们通过将语料库转化为领域特定的数据集来解决这些挑战，并构建了RAG架构以从目标文档中生成响应。我们引入了一种名为QuIM-RAG（问题到问题倒排索引匹配）的新方法，用于我们的系统中的检索机制。该策略从文档片段中生成潜在问题，并将这些问题与用户查询匹配，以识别生成准确答案所需的最相关文本片段。我们以Meta Inc.提供的开源Meta-LLaMA3-8B-instruct模型为基础，该模型可在Hugging Face上获得，并构建了一个包含500多页的自定义语料库，用于回答复杂问题，同时准备了人工整理的真实QA数据以进行评估。我们使用BERT-Score和RAGAS等最先进的指标，与传统的RAG模型进行了比较评估。我们的评估结果表明，我们的方法在两个指标上均优于传统的RAG架构。 

---
# EAGLE: Enhanced Visual Grounding Minimizes Hallucinations in Instructional Multimodal Models 

**Title (ZH)**: EAGLE：增强视觉定位减少指令多模态模型中的幻觉 

**Authors**: Andrés Villa, Juan León Alcázar, Motasem Alfarra, Vladimir Araujo, Alvaro Soto, Bernard Ghanem  

**Link**: [PDF](https://arxiv.org/pdf/2501.02699)  

**Abstract**: Large language models and vision transformers have demonstrated impressive zero-shot capabilities, enabling significant transferability in downstream tasks. The fusion of these models has resulted in multi-modal architectures with enhanced instructional capabilities. Despite incorporating vast image and language pre-training, these multi-modal architectures often generate responses that deviate from the ground truth in the image data. These failure cases are known as hallucinations. Current methods for mitigating hallucinations generally focus on regularizing the language component, improving the fusion module, or ensembling multiple visual encoders to improve visual representation. In this paper, we address the hallucination issue by directly enhancing the capabilities of the visual component. Our approach, named EAGLE, is fully agnostic to the LLM or fusion module and works as a post-pretraining approach that improves the grounding and language alignment of the visual encoder. We show that a straightforward reformulation of the original contrastive pre-training task results in an improved visual encoder that can be incorporated into the instructional multi-modal architecture without additional instructional training. As a result, EAGLE achieves a significant reduction in hallucinations across multiple challenging benchmarks and tasks. 

**Abstract (ZH)**: 大型语言模型和视觉变换器展示了令人印象深刻的零样本能力，这使得它们在下游任务中具有显著的迁移性能。将这些模型融合起来导致了具有增强指令能力的多模态架构。尽管这些多模态架构进行了大量的图像和语言预训练，但在图像数据上它们往往会产生与事实不符的响应，这种情况被称为幻觉。目前缓解幻觉的方法主要集中在语言部分的正则化、改进融合模块或集成多个视觉编码器以提高视觉表示。

本文通过直接增强视觉组件的能力来解决幻觉问题。我们提出的方法命名为EAGLE，该方法对大型语言模型（LLM）或融合模块具有完全的普适性，并作为一种后预训练方法，该方法可以提高视觉编码器的定位和语言对齐能力。我们显示，对原始对比预训练任务进行简单的重构可以使视觉编码器性能提升，并且无需额外的指令训练即可将其整合到多模态指令架构中。因此，EAGLE在多个具有挑战性的基准和任务上实现了幻觉的显著减少。 

---
# From Superficial Patterns to Semantic Understanding: Fine-Tuning Language Models on Contrast Sets 

**Title (ZH)**: 从表面模式到语义理解：在对比集上微调语言模型 

**Authors**: Daniel Petrov  

**Link**: [PDF](https://arxiv.org/pdf/2501.02683)  

**Abstract**: Large scale pretrained language models have demonstrated high performance on standard datasets for natural language inference (NLI) tasks. Unfortunately, these evaluations can be misleading, as although the models can perform well on in-distribution data, they perform poorly on out-of-distribution test sets, such as contrast sets. Contrast sets consist of perturbed instances of data that have very minor, but meaningful, changes to the input that alter the gold label, revealing how models can learn superficial patterns in the training data rather than learning more sophisticated language nuances. As an example, the ELECTRA-small language model achieves nearly 90% accuracy on an SNLI dataset but drops to 75% when tested on an out-of-distribution contrast set. The research performed in this study explores how a language models' robustness can be improved by exposing it to small amounts of more complex contrast sets during training to help it better learn language patterns. With this approach, the model regains performance and achieves nearly 90% accuracy on contrast sets, highlighting the importance of diverse and challenging training data. 

**Abstract (ZH)**: 大规模预训练语言模型在自然语言推理（NLI）任务的标准数据集上展示了高水平的表现。然而，这些评估可能存在误导性，因为尽管这些模型在内分布数据上表现良好，但在外分布测试集（如对比集）上的表现却较差。对比集包含经过轻微但有意义的更改的输入数据，这些更改改变了目标标签，揭示了模型可能学到表层模式而非更复杂的语言细微差异。例如，ELECTRA-small语言模型在SNLI数据集上可以实现接近90%的准确率，但在外分布对比集上的准确率却下降到75%。这项研究中进行的研究探讨了通过在训练过程中让模型接触少量更复杂的对比集，以提高其鲁棒性的方式。借助这种方法，模型恢复了性能，并在对比集上实现了接近90%的准确率，突显了多样且具有挑战性的训练数据的重要性。 

---
# From thermodynamics to protein design: Diffusion models for biomolecule generation towards autonomous protein engineering 

**Title (ZH)**: 从热力学至蛋白质设计：面向自主蛋白质工程的生物分子生成扩散模型研究 

**Authors**: Wen-ran Li, Xavier F. Cadet, David Medina-Ortiz, Mehdi D. Davari, Ramanathan Sowdhamini, Cedric Damour, Yu Li, Alain Miranville, Frederic Cadet  

**Link**: [PDF](https://arxiv.org/pdf/2501.02680)  

**Abstract**: Protein design with desirable properties has been a significant challenge for many decades. Generative artificial intelligence is a promising approach and has achieved great success in various protein generation tasks. Notably, diffusion models stand out for their robust mathematical foundations and impressive generative capabilities, offering unique advantages in certain applications such as protein design. In this review, we first give the definition and characteristics of diffusion models and then focus on two strategies: Denoising Diffusion Probabilistic Models and Score-based Generative Models, where DDPM is the discrete form of SGM. Furthermore, we discuss their applications in protein design, peptide generation, drug discovery, and protein-ligand interaction. Finally, we outline the future perspectives of diffusion models to advance autonomous protein design and engineering. The E(3) group consists of all rotations, reflections, and translations in three-dimensions. The equivariance on the E(3) group can keep the physical stability of the frame of each amino acid as much as possible, and we reflect on how to keep the diffusion model E(3) equivariant for protein generation. 

**Abstract (ZH)**: 带有期望性质的蛋白质设计一直是许多科研领域的一项重大挑战，持续了多个世纪。生成型人工智能是一种有潜力的方法，并且已经在各种蛋白质生成任务中取得了巨大成功。值得注意的是，扩散模型因其坚实的数学基础和高效的生成能力，在某些应用如蛋白质设计中展现出独特优势。在本文综述中，我们首先定义和阐述扩散模型的特征，然后重点介绍两种策略：去噪扩散概率模型（Denoising Diffusion Probabilistic Models, DDPMs）和基于分数的生成模型（Score-based Generative Models, SGMs），其中DDPM是SGM的离散形式。此外，我们讨论了它们在蛋白质设计、肽生成、药物发现以及蛋白质-配体相互作用中的应用。最后，我们展望了扩散模型的未来前景，旨在推进自主蛋白质设计与工程。E(3)群包含了三维空间中的所有旋转、反射和平移变换。E(3)群上的等变性能够尽可能地保持每种氨基酸框架的物理稳定性，我们进一步探讨如何使扩散模型在蛋白质生成过程中保持E(3)等变性。 

---
# Multi-Aggregator Time-Warping Heterogeneous Graph Neural Network for Personalized Micro-Video Recommendation 

**Title (ZH)**: 面向个性化微视频推荐的多聚合器时间扭曲异构图神经网络 

**Authors**: Jinkun Han, Wei Li, Xhipeng Cai, Yingshu Li  

**Link**: [PDF](https://arxiv.org/pdf/2501.02666)  

**Abstract**: Micro-video recommendation is attracting global attention and becoming a popular daily service for people of all ages. Recently, Graph Neural Networks-based micro-video recommendation has displayed performance improvement for many kinds of recommendation tasks. However, the existing works fail to fully consider the characteristics of micro-videos, such as the high timeliness of news nature micro-video recommendation and sequential interactions of frequently changed interests. In this paper, a novel Multi-aggregator Time-warping Heterogeneous Graph Neural Network (MTHGNN) is proposed for personalized news nature micro-video recommendation based on sequential sessions, where characteristics of micro-videos are comprehensively studied, users' preference is mined via multi-aggregator, the temporal and dynamic changes of users' preference are captured, and timeliness is considered. Through the comparison with the state-of-the-arts, the experimental results validate the superiority of our MTHGNN model. 

**Abstract (ZH)**: 微视频推荐正受到全球关注，并成为各年龄段人们的日常服务。近年来，基于图神经网络（Graph Neural Networks, GNN）的微视频推荐在多种推荐任务中展现了性能提升。然而，现有的工作未能充分考虑微视频的特点，例如新闻性质微视频推荐的高度时效性以及用户兴趣的频繁变化顺序交互。在本文中，我们提出了一种新颖的多聚合器时序变换异构图神经网络（Multi-aggregator Time-warping Heterogeneous Graph Neural Network, MTHGNN），用于基于序列会话的个性化新闻性质微视频推荐。该模型全面研究了微视频的特点，通过多聚合器挖掘用户偏好，捕捉用户偏好随时间的动态变化，并考虑了时效性。通过与现有最佳方法的比较，实验结果验证了我们MTHGNN模型的优越性。 

---
# Tougher Text, Smarter Models: Raising the Bar for Adversarial Defence Benchmarks 

**Title (ZH)**: 更坚韧的文本，更智能的模型：提高对抗防御基准的标准 

**Authors**: Yang Wang, Chenghua Lin  

**Link**: [PDF](https://arxiv.org/pdf/2501.02654)  

**Abstract**: vulnerability of deep learning models to adversarial attacks. While various defence mechanisms have been proposed, there is a lack of comprehensive benchmarks that evaluate these defences across diverse datasets, models, and tasks. In this work, we address this gap by presenting an extensive benchmark for textual adversarial defence that significantly expands upon previous work. Our benchmark incorporates a wide range of datasets, evaluates state-of-the-art defence mechanisms, and extends the assessment to include critical tasks such as single-sentence classification, similarity and paraphrase identification, natural language inference, and commonsense reasoning. This work not only serves as a valuable resource for researchers and practitioners in the field of adversarial robustness but also identifies key areas for future research in textual adversarial defence. By establishing a new standard for benchmarking in this domain, we aim to accelerate progress towards more robust and reliable natural language processing systems. 

**Abstract (ZH)**: 深度学习模型对抗攻击的脆弱性。尽管已经提出了各种防御机制，但缺乏能够跨多样化的数据集、模型和任务评估这些防御机制的全面基准。在此项工作中，我们通过提出一个涵盖广泛数据集的全面基准来填补这一空白，该基准显著扩展了之前的研究。我们的基准不仅涵盖了当前最先进的防御机制，还扩展了评估范围，涵盖了单一句子分类、相似性和同义替换识别、自然语言推理和常识推理等关键任务。这项工作不仅是对抗性鲁棒性领域研究人员和 practitioner 的宝贵资源，还指出了文本对抗性防御未来研究的关键领域。通过在此领域建立新的基准标准，我们旨在加速朝向更鲁棒和可靠的自然语言处理系统的进步。 

---
# Tighnari: Multi-modal Plant Species Prediction Based on Hierarchical Cross-Attention Using Graph-Based and Vision Backbone-Extracted Features 

**Title (ZH)**: Tighnari：基于图结构和视觉骨干特征的分层交叉注意力多模态植物物种预测 

**Authors**: Haixu Liu, Penghao Jiang, Zerui Tao, Muyan Wan, Qiuzhuang Sun  

**Link**: [PDF](https://arxiv.org/pdf/2501.02649)  

**Abstract**: Predicting plant species composition in specific spatiotemporal contexts plays an important role in biodiversity management and conservation, as well as in improving species identification tools. Our work utilizes 88,987 plant survey records conducted in specific spatiotemporal contexts across Europe. We also use the corresponding satellite images, time series data, climate time series, and other rasterized environmental data such as land cover, human footprint, bioclimatic, and soil variables as training data to train the model to predict the outcomes of 4,716 plant surveys. We propose a feature construction and result correction method based on the graph structure. Through comparative experiments, we select the best-performing backbone networks for feature extraction in both temporal and image modalities. In this process, we built a backbone network based on the Swin-Transformer Block for extracting temporal Cubes features. We then design a hierarchical cross-attention mechanism capable of robustly fusing features from multiple modalities. During training, we adopt a 10-fold cross-fusion method based on fine-tuning and use a Threshold Top-K method for post-processing. Ablation experiments demonstrate the improvements in model performance brought by our proposed solution pipeline. 

**Abstract (ZH)**: 在特定时空背景下预测植物物种组成对于生物多样性管理和保护以及提高物种识别工具具有重要意义。我们的工作利用了遍布欧洲的88,987份植物调查记录。我们还使用了相应的遥感图像、时间序列数据、气候时间序列以及土地覆盖、人类足迹、生物气候和土壤变量等栅格化环境数据作为训练数据，以训练模型预测4,716份植物调查的结果。我们提出了基于图结构的特征构建和结果修正方法。通过对比实验，我们选择了在时间和图像模态下表现最佳的骨干网络，用于特征提取。在此过程中，我们基于Swin-Transformer Block构建了一个用于提取时间立方体特征的骨干网络。随后，我们设计了一个层次交叉注意力机制，以稳健地融合多种模态的特征。在训练过程中，我们采用基于微调的十折交叉融合方法，并使用阈值Top-K方法进行后处理。消融实验表明，我们提出的解决方案管道显著提升了模型性能。 

---
# Representation Learning of Lab Values via Masked AutoEncoder 

**Title (ZH)**: 基于掩码自编码器的实验室值表示学习 

**Authors**: David Restrepo, Chenwei Wu, Yueran Jia, Jaden K. Sun, Jack Gallifant, Catherine G. Bielick, Yugang Jia, Leo A. Celi  

**Link**: [PDF](https://arxiv.org/pdf/2501.02648)  

**Abstract**: Accurate imputation of missing laboratory values in electronic health records (EHRs) is critical to enable robust clinical predictions and reduce biases in AI systems in healthcare. Existing methods, such as variational autoencoders (VAEs) and decision tree-based approaches such as XGBoost, struggle to model the complex temporal and contextual dependencies in EHR data, mainly in underrepresented groups. In this work, we propose Lab-MAE, a novel transformer-based masked autoencoder framework that leverages self-supervised learning for the imputation of continuous sequential lab values. Lab-MAE introduces a structured encoding scheme that jointly models laboratory test values and their corresponding timestamps, enabling explicit capturing temporal dependencies. Empirical evaluation on the MIMIC-IV dataset demonstrates that Lab-MAE significantly outperforms the state-of-the-art baselines such as XGBoost across multiple metrics, including root mean square error (RMSE), R-squared (R2), and Wasserstein distance (WD). Notably, Lab-MAE achieves equitable performance across demographic groups of patients, advancing fairness in clinical predictions. We further investigate the role of follow-up laboratory values as potential shortcut features, revealing Lab-MAE's robustness in scenarios where such data is unavailable. The findings suggest that our transformer-based architecture, adapted to the characteristics of the EHR data, offers a foundation model for more accurate and fair clinical imputation models. In addition, we measure and compare the carbon footprint of Lab-MAE with the baseline XGBoost model, highlighting its environmental requirements. 

**Abstract (ZH)**: 在电子健康记录（EHRs）中准确填补缺失的实验室值对于实现稳健的临床预测并减少医疗健康领域AI系统的偏差至关重要。现有方法，如变分自编码器（VAEs）和基于决策树的方法（如XGBoost），难以建模EHR数据中的复杂时间依赖性和上下文关联，尤其是在代表性不足的群体中。在本研究中，我们提出了一种名为Lab-MAE的新颖自编码器框架，该框架结合了基于自监督学习的连续序列实验室值填补方法。Lab-MAE引入了一种结构化的编码方案，可以同时建模实验室测试值及其相应的时间戳，从而实现对时间依赖性的明确捕捉。在MIMIC-IV数据集上的实证研究表明，Lab-MAE在多个指标上显著优于现有的基准方法（包括均方根误差RMSE、决定系数R²和Wasserstein距离WD），并实现了不同患者群体之间的公平性能。此外，我们还探讨了后续实验室值作为潜在捷径特征的作用，揭示了在缺乏此类数据的情况下，Lab-MAE的鲁棒性。研究结果表明，我们的基于Transformer的架构，经过适应EHR数据的特征，为更加准确和公平的临床填补模型提供了基础模型。此外，我们还测量并比较了Lab-MAE与基线XGBoost模型的碳足迹，突显了其环境需求。 

---
# Trust and Dependability in Blockchain & AI Based MedIoT Applications: Research Challenges and Future Directions 

**Title (ZH)**: 基于区块链与AI的医疗物联网（MedIoT）应用中的信任与可靠性：研究挑战与未来方向 

**Authors**: Ellis Solaiman, Christa Awad  

**Link**: [PDF](https://arxiv.org/pdf/2501.02647)  

**Abstract**: This paper critically reviews the integration of Artificial Intelligence (AI) and blockchain technologies in the context of Medical Internet of Things (MedIoT) applications, where they collectively promise to revolutionize healthcare delivery. By examining current research, we underscore AI's potential in advancing diagnostics and patient care, alongside blockchain's capacity to bolster data security and patient privacy. We focus particularly on the imperative to cultivate trust and ensure reliability within these systems. Our review highlights innovative solutions for managing healthcare data and challenges such as ensuring scalability, maintaining privacy, and promoting ethical practices within the MedIoT domain. We present a vision for integrating AI-driven insights with blockchain security in healthcare, offering a comprehensive review of current research and future directions. We conclude with a set of identified research gaps and propose that addressing these is crucial for achieving the dependable, secure, and patient -centric MedIoT applications of tomorrow. 

**Abstract (ZH)**: 本文批判性地回顾了人工智能（AI）与区块链技术在医疗物联网（MedIoT）应用中的整合，它们共同有望革新医疗服务。通过对当前研究的分析，我们强调了AI在改进诊断和患者护理方面的潜力，以及区块链在增强数据安全和患者隐私方面的能力。我们特别关注建立信任和确保这些系统可靠性的迫切需要。本文审视了管理医疗数据的创新解决方案以及诸如确保可扩展性、维护隐私和促进伦理实践等挑战。我们提出了一个愿景，即将基于AI的洞察与区块链安全整合到医疗服务中，并提供当前研究和未来方向的综合回顾。最终，我们指出了已识别的研究空白，并建议解决这些问题对于实现未来的可靠、安全和以患者为中心的MedIoT应用程序至关重要。 

---
# Layer-Level Self-Exposure and Patch: Affirmative Token Mitigation for Jailbreak Attack Defense 

**Title (ZH)**: 层次级自我暴露和补丁：积极标记 mitigation 对抗 Jailbreak 攻击的防御方法 

**Authors**: Yang Ouyang, Hengrui Gu, Shuhang Lin, Wenyue Hua, Jie Peng, Bhavya Kailkhura, Tianlong Chen, Kaixiong Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2501.02629)  

**Abstract**: As large language models (LLMs) are increasingly deployed in diverse applications, including chatbot assistants and code generation, aligning their behavior with safety and ethical standards has become paramount. However, jailbreak attacks, which exploit vulnerabilities to elicit unintended or harmful outputs, threaten LLMs' safety significantly. In this paper, we introduce Layer-AdvPatcher, a novel methodology designed to defend against jailbreak attacks by utilizing an unlearning strategy to patch specific layers within LLMs through self-augmented datasets. Our insight is that certain layer(s), tend to produce affirmative tokens when faced with harmful prompts. By identifying these layers and adversarially exposing them to generate more harmful data, one can understand their inherent and diverse vulnerabilities to attacks. With these exposures, we then "unlearn" these issues, reducing the impact of affirmative tokens and hence minimizing jailbreak risks while keeping the model's responses to safe queries intact. We conduct extensive experiments on two models, four benchmark datasets, and multiple state-of-the-art jailbreak benchmarks to demonstrate the efficacy of our approach. Results indicate that our framework reduces the harmfulness and attack success rate of jailbreak attacks without compromising utility for benign queries compared to recent defense methods. 

**Abstract (ZH)**: 随着大型语言模型（LLMs）在多种应用中日益普及，包括聊天助手和代码生成，将其行为与安全和伦理标准对齐变得至关重要。然而，利用漏洞引发意外或有害输出的“ Jailbreak 攻击”严重威胁着LLMs的安全性。本文提出了一种名为Layer-AdvPatcher的新方法，该方法通过利用自我增强的数据集修补LLMs中的特定层来抵御Jailbreak攻击，采用反学习策略。我们的见解是，某些层在面对有害提示时倾向于生成积极的标记。通过识别这些层并对其进行对抗性曝光以生成更多有害数据，可以了解它们对抗攻击的固有和多样化的脆弱性。基于这些曝光，我们随后“反学习”这些问题，减少积极标记的影响，从而降低Jailbreak风险，同时保持模型对无害查询的响应。我们在两个模型、四个基准数据集和多种最先进的Jailbreak基准测试上进行了广泛实验，以验证该方法的有效性。结果显示，与最近的防御方法相比，我们的框架在不损害对良性查询的效用的情况下，降低了Jailbreak攻击的有害性和成功率。 

---
# Cracks in The Stack: Hidden Vulnerabilities and Licensing Risks in LLM Pre-Training Datasets 

**Title (ZH)**: 《层中的裂缝：大语言模型预训练数据中的隐匿漏洞与许可风险》 

**Authors**: Mahmoud Jahanshahi, Audris Mockus  

**Link**: [PDF](https://arxiv.org/pdf/2501.02628)  

**Abstract**: A critical part of creating code suggestion systems is the pre-training of Large Language Models on vast amounts of source code and natural language text, often of questionable origin or quality. This may contribute to the presence of bugs and vulnerabilities in code generated by LLMs. While efforts to identify bugs at or after code generation exist, it is preferable to pre-train or fine-tune LLMs on curated, high-quality, and compliant datasets. The need for vast amounts of training data necessitates that such curation be automated, minimizing human intervention.
We propose an automated source code autocuration technique that leverages the complete version history of open-source software projects to improve the quality of training data. This approach leverages the version history of all OSS projects to identify training data samples that have been modified or have undergone changes in at least one OSS project, and pinpoint a subset of samples that include fixes for bugs or vulnerabilities. We evaluate this method using The Stack v2 dataset, and find that 17% of the code versions in the dataset have newer versions, with 17% of those representing bug fixes, including 2.36% addressing known CVEs. The deduplicated version of Stack v2 still includes blobs vulnerable to 6,947 known CVEs. Furthermore, 58% of the blobs in the dataset were never modified after creation, suggesting they likely represent software with minimal or no use. Misidentified blob origins present an additional challenge, as they lead to the inclusion of non-permissively licensed code, raising serious compliance concerns.
By addressing these issues, the training of new models can avoid perpetuating buggy code patterns or license violations. We expect our results to inspire process improvements for automated data curation, with the potential to enhance the reliability of outputs generated by AI tools. 

**Abstract (ZH)**: 构建代码建议系统的关键部分是对大规模的源代码和自然语言文本进行预训练，这些文本可能来源模糊或质量参差不齐。这可能会导致由大型语言模型（LLM）生成的代码中存在错误和漏洞。尽管已经有一些努力用于在代码生成前后识别错误，但更优选的是在经过精心筛选、高质量和合规的数据集上进行预训练或微调。由于需要大量的训练数据，这种筛选过程需要自动化，以尽量减少人工干预。

我们提出了一种自动源代码筛选技术，该技术利用开源软件项目（OSS）的完整版本历史，以提高训练数据的质量。该方法通过利用所有OSS项目的版本历史来识别已被修改或至少在一个OSS项目中发生变化的训练数据样本，并确定包含错误修复或漏洞修复的子集样本。我们使用《The Stack v2》数据集对该方法进行了评估，发现数据集中有17%的代码版本存在更新，其中有17%的更新是针对错误修复，包括2.36%的更新解决了已知的CVE（常见漏洞和暴露）。去重后的《The Stack v2》数据集仍然包括对6,947个已知CVE易受攻击的代码片段。此外，数据集中58%的代码片段从未在创建后被修改，这表明它们可能代表几乎没有使用或几乎没被使用的软件。误识别的代码片段起源带来了额外的挑战，因为这会导致包含非许可使用的代码，从而引发严重的合规性问题。

通过解决这些问题，训练新模型可以避免延续有缺陷的代码模式或违反许可。我们期望我们的研究结果能够激发自动化数据筛选过程的改进，从而增强由人工智能工具生成的输出的可靠性。 

---
# LLMs Help Alleviate the Cross-Subject Variability in Brain Signal and Language Alignment 

**Title (ZH)**: 大规模语言模型有助于减轻跨学科的脑信号与语言对齐的变异性 

**Authors**: Yifei Liu, Hengwei Ye, Shuhang Li  

**Link**: [PDF](https://arxiv.org/pdf/2501.02621)  

**Abstract**: Decoding human activity from EEG signals has long been a popular research topic. While recent studies have increasingly shifted focus from single-subject to cross-subject analysis, few have explored the model's ability to perform zero-shot predictions on EEG signals from previously unseen subjects. This research aims to investigate whether deep learning methods can capture subject-independent semantic information inherent in human EEG signals. Such insights are crucial for Brain-Computer Interfaces (BCI) because, on one hand, they demonstrate the model's robustness against subject-specific temporal biases, and on the other, they significantly enhance the generalizability of downstream tasks. We employ Large Language Models (LLMs) as denoising agents to extract subject-independent semantic features from noisy EEG signals. Experimental results, including ablation studies, highlight the pivotal role of LLMs in decoding subject-independent semantic information from noisy EEG data. We hope our findings will contribute to advancing BCI research and assist both academia and industry in applying EEG signals to a broader range of applications. 

**Abstract (ZH)**: 从 EEG 信号解码人类活动一直是热门的研究课题。尽管近年来越来越多的研究开始转向跨被试分析，但鲜有研究探讨模型在对未见过的被试的 EEG 信号进行零样本预测时的表现能力。本研究旨在探讨深度学习方法能否捕捉到人类 EEG 信号中固有的、与个体无关的语义信息。这一洞见对于脑机接口（BCI）非常重要，因为一方面，它展示了模型对个体特定的时间偏好的鲁棒性；另一方面，它大大提高了下游任务的一般化能力。我们利用大型语言模型（LLMs）作为去噪代理，从嘈杂的 EEG 信号中提取与个体无关的语义特征。实验结果，包括消融研究，突显了 LLMs 在从嘈杂的 EEG 数据中解码与个体无关的语义信息中的关键作用。希望我们的研究发现能够推动 BCI 研究的发展，并帮助学术界和工业界更广泛地应用 EEG 信号。 

---
# TAPAS: Thermal- and Power-Aware Scheduling for LLM Inference in Cloud Platforms 

**Title (ZH)**: TAPAS：面向云计算平台中大规模语言模型推理的温控和功率感知调度方法 

**Authors**: Jovan Stojkovic, Chaojie Zhang, Íñigo Goiri, Esha Choukse, Haoran Qiu, Rodrigo Fonseca, Josep Torrellas, Ricardo Bianchini  

**Link**: [PDF](https://arxiv.org/pdf/2501.02600)  

**Abstract**: The rising demand for generative large language models (LLMs) poses challenges for thermal and power management in cloud datacenters. Traditional techniques often are inadequate for LLM inference due to the fine-grained, millisecond-scale execution phases, each with distinct performance, thermal, and power profiles. Additionally, LLM inference workloads are sensitive to various configuration parameters (e.g., model parallelism, size, and quantization) that involve trade-offs between performance, temperature, power, and output quality. Moreover, clouds often co-locate SaaS and IaaS workloads, each with different levels of visibility and flexibility. We propose TAPAS, a thermal- and power-aware framework designed for LLM inference clusters in the cloud. TAPAS enhances cooling and power oversubscription capabilities, reducing the total cost of ownership (TCO) while effectively handling emergencies (e.g., cooling and power failures). The system leverages historical temperature and power data, along with the adaptability of SaaS workloads, to: (1) efficiently place new GPU workload VMs within cooling and power constraints, (2) route LLM inference requests across SaaS VMs, and (3) reconfigure SaaS VMs to manage load spikes and emergency situations. Our evaluation on a large GPU cluster demonstrates significant reductions in thermal and power throttling events, boosting system efficiency. 

**Abstract (ZH)**: 生成型大型语言模型（LLMs）的需求日益增长，这对云数据中心中的热管理和电力管理提出了挑战。传统技术往往无法满足LLM推理需求，因为每一阶段执行都非常精细，时间跨度仅为毫秒级，并且每个阶段都具有独特的性能、热管理和电力特性。此外，LLM推理负载对各种配置参数（如模型并行性、规模和量化）非常敏感，这些参数涉及到性能、温度、电力和输出质量之间的权衡。更重要的是，云环境中通常会同时部署SaaS和IaaS负载，这些负载具有不同的可见性和灵活性水平。我们提出了一种名为TAPAS的热管理和电力管理框架，专门用于云中的LLM推理集群。TAPAS增强了冷却和电能超额订阅的能力，降低了总体拥有成本（TCO），同时有效应对突发情况（如冷却和电源故障）。该系统利用历史温度和电能数据，结合SaaS负载的适应性，实现以下目标：(1)在满足冷却和电能约束的情况下高效地放置新的GPU负载虚拟机，(2)跨SaaS虚拟机路由LLM推理请求，(3)重新配置SaaS虚拟机以管理负载峰值和突发情况。我们在一个大型GPU集群上的评估表明，显著减少了热管理和电能限制事件，提高了系统效率。 

---
# Empowering Bengali Education with AI: Solving Bengali Math Word Problems through Transformer Models 

**Title (ZH)**: 用AI赋能孟加拉国教育：通过Transformer模型解决孟加拉语文应用题 

**Authors**: Jalisha Jashim Era, Bidyarthi Paul, Tahmid Sattar Aothoi, Mirazur Rahman Zim, Faisal Muhammad Shah  

**Link**: [PDF](https://arxiv.org/pdf/2501.02599)  

**Abstract**: Mathematical word problems (MWPs) involve the task of converting textual descriptions into mathematical equations. This poses a significant challenge in natural language processing, particularly for low-resource languages such as Bengali. This paper addresses this challenge by developing an innovative approach to solving Bengali MWPs using transformer-based models, including Basic Transformer, mT5, BanglaT5, and mBART50. To support this effort, the "PatiGonit" dataset was introduced, containing 10,000 Bengali math problems, and these models were fine-tuned to translate the word problems into equations accurately. The evaluation revealed that the mT5 model achieved the highest accuracy of 97.30%, demonstrating the effectiveness of transformer models in this domain. This research marks a significant step forward in Bengali natural language processing, offering valuable methodologies and resources for educational AI tools. By improving math education, it also supports the development of advanced problem-solving skills for Bengali-speaking students. 

**Abstract (ZH)**: 数学文字问题（MWPs）涉及将文本描述转换为数学方程的任务。这对自然语言处理来说构成了显著挑战，尤其是在如孟加拉语这类低资源语言中。本论文通过开发基于变压器模型的新颖方法来解决孟加拉语MWPs的问题，包括基础变压器、mT5、BanglaT5和mBART50。为了支持这一努力，引入了“PatiGonit”数据集，包含10,000个孟加拉语数学问题，并对这些模型进行了微调，以准确地将文字问题转换为方程。评估结果显示，mT5模型实现了最高的准确率97.30%，证明了变压器模型在这领域的有效性。这项研究在孟加拉语自然语言处理领域迈出了重要的一步，提供了宝贵的方法和资源，支持教育人工智能工具的发展。通过改善数学教育，还支持了孟加拉语发言学生高级解决问题技能的发展。 

---
# Evolving Skeletons: Motion Dynamics in Action Recognition 

**Title (ZH)**: 演化骨架：动作识别中的运动动力学 

**Authors**: Jushang Qiu, Lei Wang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02593)  

**Abstract**: Skeleton-based action recognition has gained significant attention for its ability to efficiently represent spatiotemporal information in a lightweight format. Most existing approaches use graph-based models to process skeleton sequences, where each pose is represented as a skeletal graph structured around human physical connectivity. Among these, the Spatiotemporal Graph Convolutional Network (ST-GCN) has become a widely used framework. Alternatively, hypergraph-based models, such as the Hyperformer, capture higher-order correlations, offering a more expressive representation of complex joint interactions. A recent advancement, termed Taylor Videos, introduces motion-enhanced skeleton sequences by embedding motion concepts, providing a fresh perspective on interpreting human actions in skeleton-based action recognition. In this paper, we conduct a comprehensive evaluation of both traditional skeleton sequences and Taylor-transformed skeletons using ST-GCN and Hyperformer models on the NTU-60 and NTU-120 datasets. We compare skeletal graph and hypergraph representations, analyzing static poses against motion-injected poses. Our findings highlight the strengths and limitations of Taylor-transformed skeletons, demonstrating their potential to enhance motion dynamics while exposing current challenges in fully using their benefits. This study underscores the need for innovative skeletal modelling techniques to effectively handle motion-rich data and advance the field of action recognition. 

**Abstract (ZH)**: 基于骨架的动作识别因其实现时空信息高效表示的能力而引起了广泛关注。大多数现有的方法使用图基模型处理骨架序列，其中每个姿态均通过围绕人体物理连接结构化而成的骨骼图来表示。在这之中，时空图卷积网络（ST-GCN）已经成为广泛采用的框架之一。作为替代方案，基于超图的模型，如Hyperformer，能够捕捉更高阶的相关性，从而提供对复杂关节交互关系更具表现力的表示。最近的一个进展被称为Taylor Videos，通过嵌入运动概念引入运动增强的骨架序列，提供了一种新的视角来解释基于骨架的行动识别中的动作。在本文中，我们使用ST-GCN和Hyperformer模型在NTU-60和NTU-120数据集上对传统的骨架序列和Taylor转换后的骨架进行了全面评估。我们比较了骨骼图和超图表示，分析了静止姿态与运动注入的姿态之间的差异。我们的研究结果突显了Taylor转换后骨架的优缺点，展示了它们增强动作动态的潜力，同时也揭示了当前利用其优势的挑战。本文强调了为了有效处理运动丰富的数据并推进动作识别领域的发展，需要创新的骨骼建模技术。 

---
# Efficient Architectures for High Resolution Vision-Language Models 

**Title (ZH)**: 高效架构的高分辨率视觉-语言模型 

**Authors**: Miguel Carvalho, Bruno Martins  

**Link**: [PDF](https://arxiv.org/pdf/2501.02584)  

**Abstract**: Vision-Language Models (VLMs) have recently experienced significant advancements. However, challenges persist in the accurate recognition of fine details within high resolution images, which limits performance in multiple tasks. This work introduces Pheye, a novel architecture that efficiently processes high-resolution images while training fewer parameters than similarly sized VLMs. Notably, Pheye achieves a high efficiency while maintaining strong performance, particularly in tasks that demand fine-grained image understanding and/or the handling of scene-text. 

**Abstract (ZH)**: 视觉-语言模型（VLMs）最近取得了显著的进步。然而，在高分辨率图像中准确识别细粒度细节的问题仍存在挑战，这限制了其在多个任务中的表现。本研究引入了Pheye，一种新型架构，它能够在处理高分辨率图像时比同等规模的VLMs训练更少的参数。值得注意的是，Pheye在保持高性能的同时，特别是在需要细粒度图像理解和/或场景文本处理的任务中表现出色。 

---
# Energy Optimization of Multi-task DNN Inference in MEC-assisted XR Devices: A Lyapunov-Guided Reinforcement Learning Approach 

**Title (ZH)**: MEC辅助XR设备多任务DNN推理的能量优化：一种Lyapunov引导的强化学习方法 

**Authors**: Yanzan Sun, Jiacheng Qiu, Guangjin Pan, Shugong Xu, Shunqing Zhang, Xiaoyun Wang, Shuangfeng Han  

**Link**: [PDF](https://arxiv.org/pdf/2501.02572)  

**Abstract**: Extended reality (XR), blending virtual and real worlds, is a key application of future networks. While AI advancements enhance XR capabilities, they also impose significant computational and energy challenges on lightweight XR devices. In this paper, we developed a distributed queue model for multi-task DNN inference, addressing issues of resource competition and queue coupling. In response to the challenges posed by the high energy consumption and limited resources of XR devices, we designed a dual time-scale joint optimization strategy for model partitioning and resource allocation, formulated as a bi-level optimization problem. This strategy aims to minimize the total energy consumption of XR devices while ensuring queue stability and adhering to computational and communication resource constraints. To tackle this problem, we devised a Lyapunov-guided Proximal Policy Optimization algorithm, named LyaPPO. Numerical results demonstrate that the LyaPPO algorithm outperforms the baselines, achieving energy conservation of 24.79% to 46.14% under varying resource capacities. Specifically, the proposed algorithm reduces the energy consumption of XR devices by 24.29% to 56.62% compared to baseline algorithms. 

**Abstract (ZH)**: 扩展现实（XR）将虚拟世界与真实世界融为一体，是未来网络的关键应用之一。随着人工智能（AI）的进步增强了XR的能力，这也对轻量级XR设备提出了巨大的计算和能源挑战。本文中，我们发展了一个分布式队列模型来处理多任务深度神经网络（DNN）推理问题，解决了资源竞争和队列耦合的问题。鉴于XR设备高能耗和有限资源带来的挑战，我们设计了一种双时间尺度联合优化策略来实现模型划分和资源分配，将其形式化为多级优化问题。该策略旨在在确保队列稳定性的同时，最小化XR设备的总能耗，同时遵守计算和通信资源约束。为了解决这个问题，我们设计了一种基于拉普拉斯引导近端策略优化算法，命名为LyaPPO。数值结果表明，LyaPPO算法优于基准算法，在不同资源容量条件下，能够实现24.79%至46.14%的能源节约。具体而言，与基准算法相比，所提出的算法能够使XR设备的能耗减少24.29%至56.62%。 

---
# Decoding fMRI Data into Captions using Prefix Language Modeling 

**Title (ZH)**: 使用前缀语言模型解码功能性磁共振成像数据为字幕 

**Authors**: Vyacheslav Shen, Kassymzhomart Kunanbayev, Dae-Shik Kim  

**Link**: [PDF](https://arxiv.org/pdf/2501.02570)  

**Abstract**: With the advancements in Large Language and Latent Diffusion models, brain decoding has achieved remarkable results in recent years. The works on the NSD dataset, with stimuli images from the COCO dataset, leverage the embeddings from the CLIP model for image reconstruction and GIT for captioning. However, the current captioning approach introduces the challenge of potential data contamination given that the GIT model was trained on the COCO dataset. In this work, we present an alternative method for decoding brain signals into image captions by predicting a DINOv2 model's embedding of an image from the corresponding fMRI signal and then providing its [CLS] token as the prefix to the GPT-2 language model which decreases computational requirements considerably. Additionally, instead of commonly used Linear Regression, we explore 3D Convolutional Neural Network mapping of fMRI signals to image embedding space for better accounting positional information of voxels. 

**Abstract (ZH)**: 随着大型语言模型和隐变量扩散模型的进步，脑信号解码在过去几年中取得了显著成果。在NSD数据集上的相关研究利用了CLIP模型的嵌入进行图像重建和GIT进行图像配字，但由于GIT模型是基于COCO数据集进行训练的，现有的配字方法可能会引入数据污染的风险。在本研究中，我们提出了另一种将脑信号解码为图像配字的方法，即从对应的fMRI信号预测DINOv2模型的图像嵌入，并将其[CLS]标记作为前缀传给GPT-2语言模型，这大大降低了计算需求。此外，我们探索了将fMRI信号映射到图像嵌入空间的三维卷积神经网络方法，以更好地考虑体素的空间位置信息，而非常用的线性回归。 

---
# Balanced Multi-view Clustering 

**Title (ZH)**: 平衡多视图聚类 

**Authors**: Zhenglai Li, Jun Wang, Chang Tang, Xinzhong Zhu, Wei Zhang, Xinwang Liu  

**Link**: [PDF](https://arxiv.org/pdf/2501.02564)  

**Abstract**: Multi-view clustering (MvC) aims to integrate information from different views to enhance the capability of the model in capturing the underlying data structures. The widely used joint training paradigm in MvC is potentially not fully leverage the multi-view information, since the imbalanced and under-optimized view-specific features caused by the uniform learning objective for all views. For instance, particular views with more discriminative information could dominate the learning process in the joint training paradigm, leading to other views being under-optimized. To alleviate this issue, we first analyze the imbalanced phenomenon in the joint-training paradigm of multi-view clustering from the perspective of gradient descent for each view-specific feature extractor. Then, we propose a novel balanced multi-view clustering (BMvC) method, which introduces a view-specific contrastive regularization (VCR) to modulate the optimization of each view. Concretely, VCR preserves the sample similarities captured from the joint features and view-specific ones into the clustering distributions corresponding to view-specific features to enhance the learning process of view-specific feature extractors. Additionally, a theoretical analysis is provided to illustrate that VCR adaptively modulates the magnitudes of gradients for updating the parameters of view-specific feature extractors to achieve a balanced multi-view learning procedure. In such a manner, BMvC achieves a better trade-off between the exploitation of view-specific patterns and the exploration of view-invariance patterns to fully learn the multi-view information for the clustering task. Finally, a set of experiments are conducted to verify the superiority of the proposed method compared with state-of-the-art approaches both on eight benchmark MvC datasets and two spatially resolved transcriptomics datasets. 

**Abstract (ZH)**: 多视角聚类（MvC）的目标是通过整合不同视角的信息来增强模型在捕捉底层数据结构方面的能力。在MvC中广泛使用的联合训练范式可能未能充分利用多视角信息，因为统一的学习目标导致不同视角的特征出现不平衡和优化不足的问题。例如，在联合训练范式中，某些具有更强区分信息的视角可能会主导学习过程，导致其他视角被优化不足。为了解决这一问题，我们首先从每个视角特定特征提取器的梯度下降视角分析多视角聚类中联合训练范式的不平衡现象，然后提出一种新型的平衡多视角聚类（BMvC）方法，其中引入了视角特定对比性正则化（VCR）来调节每个视角的优化过程。具体而言，VCR 保留了从联合特征和视角特定特征中捕获的样本相似性，并将其整合到相应视角特征的聚类分布中，以增强视角特定特征提取器的学习过程。此外，我们还提供了一种理论分析，以说明VCR如何适配性地调节更新视角特定特征提取器参数的梯度大小，从而实现平衡的多视角学习过程。通过这种方式，BMvC 能够在利用视角特定模式和探索视角不变模式之间取得更好的权衡，从而充分学习聚类任务中的多视角信息。最后，我们在八个基准多视角聚类数据集和两个空间解析转录组学数据集上进行了实验，验证了所提出方法在与最新方法相比时的优越性。 

---
# KM-UNet KAN Mamba UNet for medical image segmentation 

**Title (ZH)**: KM-UNet KAN 马来西亚滴蚁 UNet 用于医学图像分割

注释：这里的“KAN Mamba”可能是专有名词或特定的命名方式，翻译时保持了原有的缩写形式。如果“KAN Mamba”是团队名称或者模型名称的一部分，那么建议尽量保持其英文形式不变，以符合学术论文中对于特定术语和命名的使用习惯。如果“KAN Mamba”具有特殊含义或代表某个特定事物，那么需要根据实际情况进行适当调整。 

**Authors**: Yibo Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02559)  

**Abstract**: Medical image segmentation is a critical task in medical imaging analysis. Traditional CNN-based methods struggle with modeling long-range dependencies, while Transformer-based models, despite their success, suffer from quadratic computational complexity. To address these limitations, we propose KM-UNet, a novel U-shaped network architecture that combines the strengths of Kolmogorov-Arnold Networks (KANs) and state-space models (SSMs). KM-UNet leverages the Kolmogorov-Arnold representation theorem for efficient feature representation and SSMs for scalable long-range modeling, achieving a balance between accuracy and computational efficiency. We evaluate KM-UNet on five benchmark datasets: ISIC17, ISIC18, CVC, BUSI, and GLAS. Experimental results demonstrate that KM-UNet achieves competitive performance compared to state-of-the-art methods in medical image segmentation tasks. To the best of our knowledge, KM-UNet is the first medical image segmentation framework integrating KANs and SSMs. This work provides a valuable baseline and new insights for the development of more efficient and interpretable medical image segmentation systems. The code is open source at this https URL
Keywords:KAN,Manba, state-space models,UNet, Medical image segmentation, Deep learning 

**Abstract (ZH)**: 医学图像分割是医学影像分析中的一个重要任务。传统的基于卷积神经网络（CNN）的方法难以建模长程依赖关系，而基于Transformer的模型尽管取得了一定的成功，但由于计算复杂性呈二次阶增长而受到限制。为了解决这些限制，我们提出了KM-UNet，这是一种结合Kolmogorov-Arnold网络（KAN）和状态空间模型（SSMs）优点的新型U型网络架构。KM-UNet利用Kolmogorov-Arnold表示定理进行高效的特征表示，并利用SSMs进行可扩展的长程建模，实现了准确性和计算效率之间的平衡。我们使用五个基准数据集（ISIC17、ISIC18、CVC、BUSI和GLAS）对KM-UNet进行了评估。实验结果表明，KM-UNet在医学图像分割任务中的性能与当前最先进的方法相比具有竞争力。据我们所知，KM-UNet是第一个将KAN和SSMs集成在一起的医学图像分割框架。这项工作为开发更高效、更可解释的医学图像分割系统提供了有价值的基准和新的见解。代码开源于此链接：[URL]。

关键词：KAN、Manba、状态空间模型、UNet、医学图像分割、深度学习 

---
# AMM: Adaptive Modularized Reinforcement Model for Multi-city Traffic Signal Control 

**Title (ZH)**: AMM：适应性模块化强化学习模型在多城市交通信号控制中的应用 

**Authors**: Zherui Huang, Yicheng Liu, Chumeng Liang, Guanjie Zheng  

**Link**: [PDF](https://arxiv.org/pdf/2501.02548)  

**Abstract**: Traffic signal control (TSC) is an important and widely studied direction. Recently, reinforcement learning (RL) methods have been used to solve TSC problems and achieve superior performance over conventional TSC methods. However, applying RL methods to the real world is challenging due to the huge cost of experiments in real-world traffic environments. One possible solution is TSC domain adaptation, which adapts trained models to target environments and reduces the number of interactions and the training cost. However, existing TSC domain adaptation methods still face two major issues: the lack of consideration for differences across cities and the low utilization of multi-city data.
To solve aforementioned issues, we propose an approach named Adaptive Modularized Model (AMM). By modularizing TSC problems and network models, we overcome the challenge of possible changes in environmental observations. We also aggregate multi-city experience through meta-learning. We conduct extensive experiments on different cities and show that AMM can achieve excellent performance with limited interactions in target environments and outperform existing methods. We also demonstrate the feasibility and generalizability of our method. 

**Abstract (ZH)**: 交通信号控制（TSC）是一个重要且广泛研究的方向。近年来，强化学习（RL）方法被用于解决TSC问题，并在性能上超过了传统的TSC方法。然而，将RL方法应用于现实世界充满挑战，因为真实交通环境中的实验成本巨大。一种可能的解决方案是TSC领域自适应，它可以将训练好的模型适应目标环境，从而减少交互次数和训练成本。然而，现有的TSC领域自适应方法仍然面临两大问题：对不同城市间差异考虑不足以及多城市数据利用不足。

为了解决上述问题，我们提出了一种名为自适应模块化模型（AMM）的方法。通过模块化TSC问题和网络模型，我们克服了环境观察可能变化的挑战。我们通过元学习聚合多城市的经验。我们在不同城市进行了广泛的实验，并展示了AMM可以在目标环境中以有限的交互次数实现卓越性能，并优于现有方法。我们还证明了我们方法的可行性和通用性。 

---
# TreeMatch: A Fully Unsupervised WSD System Using Dependency Knowledge on a Specific Domain 

**Title (ZH)**: TreeMatch：一种基于特定领域依存知识的完全无监督谓词消歧系统 

**Authors**: Andrew Tran, Chris Bowes, David Brown, Ping Chen, Max Choly, Wei Ding  

**Link**: [PDF](https://arxiv.org/pdf/2501.02546)  

**Abstract**: Word sense disambiguation (WSD) is one of the main challenges in Computational Linguistics. TreeMatch is a WSD system originally developed using data from SemEval 2007 Task 7 (Coarse-grained English All-words Task) that has been adapted for use in SemEval 2010 Task 17 (All-words Word Sense Disambiguation on a Specific Domain). The system is based on a fully unsupervised method using dependency knowledge drawn from a domain specific knowledge base that was built for this task. When evaluated on the task, the system precision performs above the Most Frequent Selection baseline. 

**Abstract (ZH)**: 词义消歧（WSD）是计算语言学中的主要挑战之一。TreeMatch 是一个最初基于 2007 年 SemEval 任务 7（粗粒度英语全词任务）的数据开发的 WSD 系统，并已适应用于 2010 年 SemEval 任务 17（特定领域全词词义消歧）。该系统基于完全无监督的方法，利用从专门知识库中抽取的依赖关系知识，该知识库是专门为该任务构建的。在任务评估中，该系统的精确度超过了最常见的最频繁选择基线。 

---
# A completely uniform transformer for parity 

**Title (ZH)**: 一个完全均匀的变压器用于奇偶校验 

**Authors**: Alexander Kozachinskiy, Tomasz Steifer  

**Link**: [PDF](https://arxiv.org/pdf/2501.02535)  

**Abstract**: We construct a 3-layer constant-dimension transformer, recognizing the parity language, where neither parameter matrices nor the positional encoding depend on the input length. This improves upon a construction of Chiang and Cholak who use a positional encoding, depending on the input length (but their construction has 2 layers). 

**Abstract (ZH)**: 我们构造了一个三层常维变换器，该变换器识别奇偶性语言，其中参数矩阵和位置编码均不依赖于输入长度。这改进了Chiang和Cholak的构造，后者使用的位置编码依赖于输入长度（但他们的构造只有两层）。 

---
# Evaluating Large Language Models Against Human Annotators in Latent Content Analysis: Sentiment, Political Leaning, Emotional Intensity, and Sarcasm 

**Title (ZH)**: 在潜在内容分析中，大型语言模型与人工注释者之间的评估：情感、政治倾向、情感强度和讽刺 

**Authors**: Ljubisa Bojic, Olga Zagovora, Asta Zelenkauskaite, Vuk Vukovic, Milan Cabarkapa, Selma Veseljević Jerkovic, Ana Jovančevic  

**Link**: [PDF](https://arxiv.org/pdf/2501.02532)  

**Abstract**: In the era of rapid digital communication, vast amounts of textual data are generated daily, demanding efficient methods for latent content analysis to extract meaningful insights. Large Language Models (LLMs) offer potential for automating this process, yet comprehensive assessments comparing their performance to human annotators across multiple dimensions are lacking. This study evaluates the reliability, consistency, and quality of seven state-of-the-art LLMs, including variants of OpenAI's GPT-4, Gemini, Llama, and Mixtral, relative to human annotators in analyzing sentiment, political leaning, emotional intensity, and sarcasm detection. A total of 33 human annotators and eight LLM variants assessed 100 curated textual items, generating 3,300 human and 19,200 LLM annotations, with LLMs evaluated across three time points to examine temporal consistency. Inter-rater reliability was measured using Krippendorff's alpha, and intra-class correlation coefficients assessed consistency over time. The results reveal that both humans and LLMs exhibit high reliability in sentiment analysis and political leaning assessments, with LLMs demonstrating higher internal consistency than humans. In emotional intensity, LLMs displayed higher agreement compared to humans, though humans rated emotional intensity significantly higher. Both groups struggled with sarcasm detection, evidenced by low agreement. LLMs showed excellent temporal consistency across all dimensions, indicating stable performance over time. This research concludes that LLMs, especially GPT-4, can effectively replicate human analysis in sentiment and political leaning, although human expertise remains essential for emotional intensity interpretation. The findings demonstrate the potential of LLMs for consistent and high-quality performance in certain areas of latent content analysis. 

**Abstract (ZH)**: 在快速数字化通信的时代，每天都会生成大量文本数据，迫切需要高效的方法来进行潜在内容分析以提取有意义的洞见。大规模语言模型（LLMs）为自动化这一过程提供了潜力，但缺乏涵盖多个维度的全面评估，将它们的表现与人类注释者的表现进行对比。本研究评估了七种最先进的LLMs，包括OpenAI的GPT-4变体、Gemini、Llama和Mistral，在分析 sentiment、政治倾向、情感强度和讽刺检测方面与人类注释者的可靠性和质量。共有33名人类注释者和8种LLM变体评估了100个精心挑选的文本项目，生成了3,300个人类注释和19,200个LLM注释，并在三个时间点对LLMs进行评估，以检查时间一致性。信度分析使用Krippendorff的α系数，而内在一致性相关系数则评估了时间的一致性。结果显示，无论是人类还是LLMs，在情感分析和政治倾向评估中都表现出高度的可靠性，LLMs在内部一致性方面优于人类。在情感强度方面，LLMs的表现比人类更高，尽管人类在情感强度的评分明显高于LLMs。两个群体在讽刺检测方面都存在困难，表现为低一致性。LLMs在所有维度上均表现出色的时间一致性，表明其在时间上的稳定表现。研究结论指出，LLMs，尤其是GPT-4，在情感和政治倾向分析方面可以有效地复制人类分析，尽管人类的专业知识对于情感强度的解释仍然是必不可少的。研究结果表明，LLMs在某些潜在内容分析的领域中可以实现一致性和高质量的性能。 

---
# Face-MakeUp: Multimodal Facial Prompts for Text-to-Image Generation 

**Title (ZH)**: 面部妆容生成：用于文本到图像生成的多模态面部提示 

**Authors**: Dawei Dai, Mingming Jia, Yinxiu Zhou, Hang Xing, Chenghang Li  

**Link**: [PDF](https://arxiv.org/pdf/2501.02523)  

**Abstract**: Facial images have extensive practical applications. Although the current large-scale text-image diffusion models exhibit strong generation capabilities, it is challenging to generate the desired facial images using only text prompt. Image prompts are a logical choice. However, current methods of this type generally focus on general domain. In this paper, we aim to optimize image makeup techniques to generate the desired facial images. Specifically, (1) we built a dataset of 4 million high-quality face image-text pairs (FaceCaptionHQ-4M) based on LAION-Face to train our Face-MakeUp model; (2) to maintain consistency with the reference facial image, we extract/learn multi-scale content features and pose features for the facial image, integrating these into the diffusion model to enhance the preservation of facial identity features for diffusion models. Validation on two face-related test datasets demonstrates that our Face-MakeUp can achieve the best comprehensive this http URL codes are available at:this https URL 

**Abstract (ZH)**: 面部图像在实际应用中有广泛的应用。尽管当前的大型文本-图像扩散模型具有强大的生成能力，仅通过文本提示生成所需的面部图像仍然是一个挑战。图像提示是一个合理的选择。然而，现有的此类方法通常侧重于通用领域。在本文中，我们旨在优化面部妆容技术以生成所需的面部图像。具体而言，(1) 基于LAION-Face，我们构建了一个包含400万高质量面部图像-文本对的数据集（FaceCaptionHQ-4M）来训练我们的Face-MakeUp模型；(2) 为了与参考面部图像保持一致，我们提取/学习多尺度内容特征和姿态特征，并将其整合到扩散模型中，以增强面部身份特征在扩散模型中的保留。通过对两个面部相关的测试数据集进行验证，我们的Face-MakeUp能够实现最佳的整体效果。源代码可在以下链接获取：[代码链接] 

---
# Remote Inference over Dynamic Links via Adaptive Rate Deep Task-Oriented Vector Quantization 

**Title (ZH)**: 通过自适应速率深度任务导向向量量化实现动态链路上的远程推理 

**Authors**: Eyal Fishel, May Malka, Shai Ginzach, Nir Shlezinger  

**Link**: [PDF](https://arxiv.org/pdf/2501.02521)  

**Abstract**: A broad range of technologies rely on remote inference, wherein data acquired is conveyed over a communication channel for inference in a remote server. Communication between the participating entities is often carried out over rate-limited channels, necessitating data compression for reducing latency. While deep learning facilitates joint design of the compression mapping along with encoding and inference rules, existing learned compression mechanisms are static, and struggle in adapting their resolution to changes in channel conditions and to dynamic links. To address this, we propose Adaptive Rate Task-Oriented Vector Quantization (ARTOVeQ), a learned compression mechanism that is tailored for remote inference over dynamic links. ARTOVeQ is based on designing nested codebooks along with a learning algorithm employing progressive learning. We show that ARTOVeQ extends to support low-latency inference that is gradually refined via successive refinement principles, and that it enables the simultaneous usage of multiple resolutions when conveying high-dimensional data. Numerical results demonstrate that the proposed scheme yields remote deep inference that operates with multiple rates, supports a broad range of bit budgets, and facilitates rapid inference that gradually improves with more bits exchanged, while approaching the performance of single-rate deep quantization methods. 

**Abstract (ZH)**: 以下是对论文内容或标题的学术规范翻译：

近年来，广泛的技术依赖远程推理，其中获取的数据通过通信信道传输到远程服务器进行推理。参与实体之间的通信常常受限于带宽有限的信道，因此需要进行数据压缩以减少延迟。尽管深度学习可以同时设计压缩映射和编码及推理规则，现有的学习型压缩机制通常是静态的，难以适应信道条件的变化和动态链接的要求。为解决这一问题，我们提出了一种面向动态链路的自适应率任务导向矢量量化（ARTOVeQ），这是一种专门用于动态链路上远程推理的学习型压缩机制。ARTOVeQ 基于嵌套码本设计和采用渐进学习的学习算法。我们表明，ARTOVeQ 可以支持通过逐步细化原则逐渐进行低延迟推理，并在传输高维数据时同时使用多种分辨率。数值结果表明，所提出的方案可以实现具有多种速率的远程深度推理，支持广泛的比特预算，并且随着比特交换量的增加逐步提高推理速度，同时接近单速率深度量化方法的性能。 

---
# PTEENet: Post-Trained Early-Exit Neural Networks Augmentation for Inference Cost Optimization 

**Title (ZH)**: PTEENet：后训练早期退出神经网络增强以优化推理成本 

**Authors**: Assaf Lahiany, Yehudit Aperstein  

**Link**: [PDF](https://arxiv.org/pdf/2501.02508)  

**Abstract**: For many practical applications, a high computational cost of inference over deep network architectures might be unacceptable. A small degradation in the overall inference accuracy might be a reasonable price to pay for a significant reduction in the required computational resources. In this work, we describe a method for introducing "shortcuts" into the DNN feedforward inference process by skipping costly feedforward computations whenever possible. The proposed method is based on the previously described BranchyNet (Teerapittayanon et al., 2016) and the EEnet (Demir, 2019) architectures that jointly train the main network and early exit branches. We extend those methods by attaching branches to pre-trained models and, thus, eliminating the need to alter the original weights of the network. We also suggest a new branch architecture based on convolutional building blocks to allow enough training capacity when applied on large DNNs. The proposed architecture includes confidence heads that are used for predicting the confidence level in the corresponding early exits. By defining adjusted thresholds on these confidence extensions, we can control in real-time the amount of data exiting from each branch and the overall tradeoff between speed and accuracy of our model. In our experiments, we evaluate our method using image datasets (SVHN and CIFAR10) and several DNN architectures (ResNet, DenseNet, VGG) with varied depth. Our results demonstrate that the proposed method enables us to reduce the average inference computational cost and further controlling the tradeoff between the model accuracy and the computation cost. 

**Abstract (ZH)**: 在许多实际应用中，深度网络架构的推断计算成本可能难以接受。一些总体推断准确性的小幅降低可能是一个合理的代价，以换取显著减少所需的计算资源。在本文中，我们提出了一个方法，通过在可能的情况下跳过昂贵的前向传播计算，将“快捷路径”引入到DNN的前向推断过程。该方法基于先前描述的BranchyNet（Teerapittayanon等，2016年）和EEnet（Demir, 2019）架构，这些架构通过联合训练主网络和早期退出分支来进行训练。我们在此基础上扩展了这些方法，将分支附加到预训练模型上，从而消除需要修改网络原始权重的需要。我们还提出了一种新的分支架构，基于卷积模块，以便在应用于大型DNN时提供足够的训练能力。所提出架构包括置信度头部，用于预测相应早期退出的置信度级别。通过在这些置信度扩展上定义调整后的阈值，我们可以在实时控制从每个分支退出的数据量，并控制我们的模型的速度与准确性的整体权衡。在我们的实验中，我们使用图像数据集（SVHN和CIFAR10）和几种不同深度的DNN架构（ResNet、DenseNet、VGG）来评估该方法。实验结果表明，所提出的方法使我们能够降低平均推断计算成本，并进一步控制模型准确性和计算成本之间的权衡。 

---
# Watch Video, Catch Keyword: Context-aware Keyword Attention for Moment Retrieval and Highlight Detection 

**Title (ZH)**: 观看视频，捕捉关键词：基于上下文的关键词注意力模型在关键 Moment检索与亮点检测中的应用 

**Authors**: Sung Jin Um, Dongjin Kim, Sangmin Lee, Jung Uk Kim  

**Link**: [PDF](https://arxiv.org/pdf/2501.02504)  

**Abstract**: The goal of video moment retrieval and highlight detection is to identify specific segments and highlights based on a given text query. With the rapid growth of video content and the overlap between these tasks, recent works have addressed both simultaneously. However, they still struggle to fully capture the overall video context, making it challenging to determine which words are most relevant. In this paper, we present a novel Video Context-aware Keyword Attention module that overcomes this limitation by capturing keyword variation within the context of the entire video. To achieve this, we introduce a video context clustering module that provides concise representations of the overall video context, thereby enhancing the understanding of keyword dynamics. Furthermore, we propose a keyword weight detection module with keyword-aware contrastive learning that incorporates keyword information to enhance fine-grained alignment between visual and textual features. Extensive experiments on the QVHighlights, TVSum, and Charades-STA benchmarks demonstrate that our proposed method significantly improves performance in moment retrieval and highlight detection tasks compared to existing approaches. Our code is available at: this https URL 

**Abstract (ZH)**: 视频片段检索和亮点检测的目标是根据给定的文本查询识别特定的片段和亮点。随着视频内容的快速增长以及这两个任务之间的重叠，最近的研究同时解决了这两个问题。然而，它们仍然难以完全捕捉整个视频的上下文，导致难以确定哪些词是最相关的。在本文中，我们提出了一种新型的视频上下文感知关键词注意力模块，该模块通过捕捉整个视频上下文中的关键词变化来克服这一限制。为了实现这一点，我们引入了一个视频上下文聚类模块，该模块提供了整个视频上下文的简洁表示，从而增强了对关键词动态的理解。此外，我们提出了一个带有关键词感知对比学习的关键词权重检测模块，该模块结合了关键词信息以增强视觉特征和文本特征的细粒度对齐。在QVHighlights、TVSum和Charades-STA基准上的广泛实验表明，与现有方法相比，我们提出的方法在片段检索和亮点检测任务中的性能显著提升。我们的代码可在以下链接获取：this https URL 

---
# Rethinking IDE Customization for Enhanced HAX: A Hyperdimensional Perspective 

**Title (ZH)**: 从超维视角重新思考IDE自定义以增强HAX：一种超维方法 

**Authors**: Roham Koohestani, Maliheh Izadi  

**Link**: [PDF](https://arxiv.org/pdf/2501.02491)  

**Abstract**: As Integrated Development Environments (IDEs) increasingly integrate Artificial Intelligence, Software Engineering faces both benefits like productivity gains and challenges like mismatched user preferences. We propose Hyper-Dimensional (HD) vector spaces to model Human-Computer Interaction, focusing on user actions, stylistic preferences, and project context. These contributions aim to inspire further research on applying HD computing in IDE design. 

**Abstract (ZH)**: 随着集成开发环境（IDEs）越来越多地集成人工智能技术，软件工程既面临着生产率提升等好处，也面临着用户偏好不匹配等挑战。我们提出使用超维度（HD）向量空间来建模人机交互，重点关注用户行为、风格偏好以及项目上下文。这些贡献旨在激发进一步研究如何在IDE设计中应用HD计算。 

---
# The Meta-Representation Hypothesis 

**Title (ZH)**: 元表示假设 

**Authors**: Zhengpeng Xie, Jiahang Cao, Qiang Zhang, Jianxiong Zhang, Changwei Wang, Renjing Xu  

**Link**: [PDF](https://arxiv.org/pdf/2501.02481)  

**Abstract**: Humans rely on high-level meta-representations to engage in abstract reasoning. In complex cognitive tasks, these meta-representations help individuals abstract general rules from experience. However, constructing such meta-representations from high-dimensional observations remains a longstanding challenge for reinforcement learning agents. For instance, a well-trained agent often fails to generalize to even minor variations of the same task, such as changes in background color, while humans can easily handle. In this paper, we build a bridge between meta-representation and generalization, showing that generalization performance benefits from meta-representation learning. We also hypothesize that deep mutual learning (DML) among agents can help them converge to meta-representations. Empirical results provide support for our theory and hypothesis. Overall, this work provides a new perspective on the generalization of deep reinforcement learning. 

**Abstract (ZH)**: 人类依赖高层次的元表示来进行抽象推理。在复杂的认知任务中，这些元表示有助于个体从经验中抽象出通用规则。然而，从高维度观察构建这样的元表示仍然是强化学习代理长期存在的挑战。例如，一个训练有素的代理往往无法泛化到同一任务的细微变化中，比如背景颜色的变化，而人类则可以轻松应对。本文构建了元表示和泛化之间的桥梁，表明元表示学习能够提高泛化性能。我们还假设代理之间的深度互学习（DML）有助于它们向元表示收敛。实验结果支持我们的理论和假设。总体来说，这项工作为深度强化学习的泛化提供了一个新的视角。 

---
# Hengqin-RA-v1: Advanced Large Language Model for Diagnosis and Treatment of Rheumatoid Arthritis with Dataset based Traditional Chinese Medicine 

**Title (ZH)**: Henqin-RA-v1：基于数据集的传统中药用于类风湿性关节炎的诊断与治疗的高级语言模型 

**Authors**: Yishen Liu, Shengda Luo, Zishao Zhong, Tongtong Wu, Jianguo Zhang, Peiyao Ou, Yong Liang, Liang Liu, Hudan Pan  

**Link**: [PDF](https://arxiv.org/pdf/2501.02471)  

**Abstract**: Large language models (LLMs) primarily trained on English texts, often face biases and inaccuracies in Chinese contexts. Their limitations are pronounced in fields like Traditional Chinese Medicine (TCM), where cultural and clinical subtleties are vital, further hindered by a lack of domain-specific data, such as rheumatoid arthritis (RA). To address these issues, this paper introduces Hengqin-RA-v1, the first large language model specifically tailored for TCM with a focus on diagnosing and treating RA. We also present HQ-GCM-RA-C1, a comprehensive RA-specific dataset curated from ancient Chinese medical literature, classical texts, and modern clinical studies. This dataset empowers Hengqin-RA-v1 to deliver accurate and culturally informed responses, effectively bridging the gaps left by general-purpose models. Extensive experiments demonstrate that Hengqin-RA-v1 outperforms state-of-the-art models, even surpassing the diagnostic accuracy of TCM practitioners in certain cases. 

**Abstract (ZH)**: 大型语言模型（LLMs）主要在英文文本上进行训练，往往在中文背景下表现出偏见和不准确性。在中医（TCM）这一领域尤为突出，因为在中医领域，文化差异和临床细微之处至关重要，而缺乏特定领域的数据，如风湿性关节炎（RA），进一步加剧了这一问题。为了解决这些问题，本文介绍了“横琴-RA-v1”，这是首个专门针对中医领域的大型语言模型，重点在于诊断和治疗RA。我们还提出了HQ-GCM-RA-C1数据集，这是一个针对RA的数据集，从古代中医文献、古典文献和现代临床研究中精心挑选和整理而成。该数据集使“横琴-RA-v1”能够提供准确且文化敏感的响应，有效地弥补了通用模型留下的空白。广泛实验表明，“横琴-RA-v1”在某些情况下甚至超越了中医专业人员的诊断准确性，超过了最先进的模型。 

---
# Depth Any Camera: Zero-Shot Metric Depth Estimation from Any Camera 

**Title (ZH)**: 任意相机的深度估计：任意相机的零样本度量深度估计 

**Authors**: Yuliang Guo, Sparsh Garg, S. Mahdi H. Miangoleh, Xinyu Huang, Liu Ren  

**Link**: [PDF](https://arxiv.org/pdf/2501.02464)  

**Abstract**: While recent depth estimation methods exhibit strong zero-shot generalization, achieving accurate metric depth across diverse camera types-particularly those with large fields of view (FoV) such as fisheye and 360-degree cameras-remains a significant challenge. This paper presents Depth Any Camera (DAC), a powerful zero-shot metric depth estimation framework that extends a perspective-trained model to effectively handle cameras with varying FoVs. The framework is designed to ensure that all existing 3D data can be leveraged, regardless of the specific camera types used in new applications. Remarkably, DAC is trained exclusively on perspective images but generalizes seamlessly to fisheye and 360-degree cameras without the need for specialized training data. DAC employs Equi-Rectangular Projection (ERP) as a unified image representation, enabling consistent processing of images with diverse FoVs. Its key components include a pitch-aware Image-to-ERP conversion for efficient online augmentation in ERP space, a FoV alignment operation to support effective training across a wide range of FoVs, and multi-resolution data augmentation to address resolution disparities between training and testing. DAC achieves state-of-the-art zero-shot metric depth estimation, improving delta-1 ($\delta_1$) accuracy by up to 50% on multiple fisheye and 360-degree datasets compared to prior metric depth foundation models, demonstrating robust generalization across camera types. 

**Abstract (ZH)**: 虽然近期的一些深度估计方法在零样本泛化方面表现出色，但在多种相机类型，尤其是具有大视野（FoV）的鱼眼相机和全景相机（如360度相机）等相机类型上实现准确的度量深度仍然是一个重大挑战。本文提出了一种名为Depth Any Camera (DAC) 的强大零样本度量深度估计框架，该框架能够将基于透视相机训练的模型扩展到能够有效处理视野不同的各种相机。该框架旨在确保所有现有的3D数据都可以被利用，而与新应用中使用的具体相机类型无关。值得注意的是，DAC仅通过透视图像进行训练，并且在无需专门训练数据的情况下，能够无缝地泛化到鱼眼和全景相机上。DAC采用等角投影（Equi-Rectangular Projection, ERP）作为统一的图像表示，使其能够一致地处理具有不同FoV的图像。其关键组件包括针对ERP空间中高效在线数据增强的俯仰角感知图像到ERP转换、视野对齐操作以支持广泛视野范围内的有效训练，以及多尺度数据增强以解决训练和测试之间的分辨率差异。DAC实现了有史以来最佳的零样本度量深度估计，与之前的度量深度基础模型相比，在多个鱼眼和全景相机数据集上将delta-1（$\delta_1$）精度提高了50%，展示了在不同相机类型上具有稳健的泛化能力。 

---
# FedRSClip: Federated Learning for Remote Sensing Scene Classification Using Vision-Language Models 

**Title (ZH)**: FedRSClip：基于视觉语言模型的遥感场景分类联邦学习 

**Authors**: Hui Lin, Chao Zhang, Danfeng Hong, Kexin Dong, Congcong Wen  

**Link**: [PDF](https://arxiv.org/pdf/2501.02461)  

**Abstract**: Remote sensing data is often distributed across multiple institutions, and due to privacy concerns and data-sharing restrictions, leveraging large-scale datasets in a centralized training framework is challenging. Federated learning offers a promising solution by enabling collaborative model training across distributed data sources without requiring data centralization. However, current Vision-Language Models (VLMs), which typically contain billions of parameters, pose significant communication challenges for traditional federated learning approaches based on model parameter updates, as they would incur substantial communication costs. In this paper, we propose FedRSCLIP, the first federated learning framework designed for remote sensing image classification based on a VLM, specifically CLIP. FedRSCLIP addresses the challenges of data heterogeneity and large-scale model transmission in federated environments by introducing Prompt Learning, which optimizes only a small set of tunable parameters. The framework introduces a dual-prompt mechanism, comprising Shared Prompts for global knowledge sharing and Private Prompts for client-specific adaptation. To maintain semantic coherence between shared and private prompts, we propose the Dual Prompt Alignment Constraint to balance global consistency and local adaptability across diverse client distributions. Additionally, to enhance cross-modal representation learning, we introduce the Cross-Modal Feature Alignment Constraint to align multimodal features between text and image prompts. To validate the effectiveness of our proposed model, we construct a Fed-RSIC dataset based on three existing remote sensing image classification datasets, specifically designed to simulate various federated learning configurations. Experimental results demonstrate the effectiveness and superiority of FedRSCLIP in remote sensing image classification. 

**Abstract (ZH)**: 遥感数据通常分布在多个机构中，由于隐私问题和数据共享限制，在集中式训练框架中利用大规模数据集具有挑战性。联邦学习提供了一种有前途的解决方案，它可以在分布式数据源上进行协作模型训练，而无需数据集中化。然而，当前基于视觉语言模型（VLM）的视觉语言模型通常包含数十亿个参数，这些模型对传统的基于模型参数更新的联邦学习方法提出了重大通信挑战，因为它们会导致显著的通信成本。在本文中，我们提出了 FedRSCLIP，这是一种专门基于 CLIP 的视觉语言模型设计的联邦学习框架，用于遥感图像分类。FedRSCLIP 通过引入提示学习来解决联邦环境中数据异质性和大规模模型传输的挑战，优化仅一小部分可调参数。该框架引入了一种双重提示机制，包括用于全局知识共享的共享提示和用于客户端特定适应的私有提示。为保持共享和私有提示之间的语义一致性，我们提出了双重提示对齐约束，以平衡全球一致性与在多样化客户端分布中的局部适应性。此外，为了增强跨模态表示学习，我们引入了跨模态特征对齐约束，以在文本和图像提示之间对齐多模态特征。为了验证我们所提出模型的有效性，我们基于三个现有的遥感图像分类数据集构建了一个 Fed-RSIC 数据集，专门设计用于模拟各种联邦学习配置。实验结果表明，FedRSCLIP 在遥感图像分类中的有效性和优越性。 

---
# Enhancing Contrastive Learning for Retinal Imaging via Adjusted Augmentation Scales 

**Title (ZH)**: 通过调整增强比例来增强视网膜成像的对比学习 

**Authors**: Zijie Cheng, Boxuan Li, André Altmann, Pearse A Keane, Yukun Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2501.02451)  

**Abstract**: Contrastive learning, a prominent approach within self-supervised learning, has demonstrated significant effectiveness in developing generalizable models for various applications involving natural images. However, recent research indicates that these successes do not necessarily extend to the medical imaging domain. In this paper, we investigate the reasons for this suboptimal performance and hypothesize that the dense distribution of medical images poses challenges to the pretext tasks in contrastive learning, particularly in constructing positive and negative pairs. We explore model performance under different augmentation strategies and compare the results to those achieved with strong augmentations. Our study includes six publicly available datasets covering multiple clinically relevant tasks. We further assess the model's generalizability through external evaluations. The model pre-trained with weak augmentation outperforms those with strong augmentation, improving AUROC from 0.838 to 0.848 and AUPR from 0.523 to 0.597 on MESSIDOR2, and showing similar enhancements across other datasets. Our findings suggest that optimizing the scale of augmentation is critical for enhancing the efficacy of contrastive learning in medical imaging. 

**Abstract (ZH)**: 对比学习，作为自监督学习中的一个突出方法，已经在涉及自然图像的各种应用中展示了显著的泛化能力。然而，近期的研究表明，这些成功并不必然适用于医学成像领域。在本文中，我们探讨了这种次优表现的原因，并假设医学成像的密集分布对对比学习中的预设任务提出了挑战，尤其是在构建正样本和负样本对方面。我们研究了不同增强策略下的模型性能，并将其结果与使用强增强策略的结果进行了比较。我们的研究包括六个公开可用的数据集，涵盖了多个临床相关任务。此外，我们通过外部评估进一步测试了模型的泛化能力。使用弱增强预训练的模型优于使用强增强预训练的模型，在MESSIDOR2数据集上，AUROC从0.838提高到0.848，AUPR从0.523提高到0.597，其他数据集也展现出类似的提升。我们的发现表明，优化增强的规模对于提高医学成像中对比学习的效率至关重要。 

---
# RTLMarker: Protecting LLM-Generated RTL Copyright via a Hardware Watermarking Framework 

**Title (ZH)**: RTLMarker：一种基于硬件水印框架保护LLM生成的RTL版权的方法 

**Authors**: Kun Wang, Kaiyan Chang, Mengdi Wang, Xinqi Zou, Haobo Xu, Yinhe Han, Ying Wang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02446)  

**Abstract**: Recent advances of large language models in the field of Verilog generation have raised several ethical and security concerns, such as code copyright protection and dissemination of malicious code. Researchers have employed watermarking techniques to identify codes generated by large language models. However, the existing watermarking works fail to protect RTL code copyright due to the significant syntactic and semantic differences between RTL code and software code in languages such as Python. This paper proposes a hardware watermarking framework RTLMarker that embeds watermarks into RTL code and deeper into the synthesized netlist. We propose a set of rule-based Verilog code transformations , ensuring the watermarked RTL code's syntactic and semantic correctness. In addition, we consider an inherent tradeoff between watermark transparency and watermark effectiveness and jointly optimize them. The results demonstrate RTLMarker's superiority over the baseline in RTL code watermarking. 

**Abstract (ZH)**: 近年来，在Verilog生成领域，大型语言模型的研究取得了显著进展，但也引发了若干伦理和安全方面的关切，如代码版权保护和恶意代码的传播。研究人员已采用水印技术来识别由大型语言模型生成的代码，但现有的水印工作无法保护 RTL（Register-Transfer Level）代码的版权，这是因为 RTL 代码与 Python 等编程语言中的软件代码之间存在显著的语法和语义差异。本文提出了一种硬件水印框架 RTLMarker，该框架将水印嵌入到 RTL 代码中，并更深入地嵌入到综合网表中。我们提出了一套基于规则的 Verilog 代码转换技术，以确保嵌入水印的 RTL 代码在语法和语义上的正确性。此外，我们考虑了水印透明度与水印有效性之间的固有权衡，并同时优化了两者。实验结果表明，RTLMarker 在 RTL 代码水印化方面优于基线方法。 

---
# A Statistical Hypothesis Testing Framework for Data Misappropriation Detection in Large Language Models 

**Title (ZH)**: 大型语言模型中数据误用检测的统计假设检验框架 

**Authors**: Yinpeng Cai, Lexin Li, Linjun Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02441)  

**Abstract**: Large Language Models (LLMs) are rapidly gaining enormous popularity in recent years. However, the training of LLMs has raised significant privacy and legal concerns, particularly regarding the inclusion of copyrighted materials in their training data without proper attribution or licensing, which falls under the broader issue of data misappropriation. In this article, we focus on a specific problem of data misappropriation detection, namely, to determine whether a given LLM has incorporated data generated by another LLM. To address this issue, we propose embedding watermarks into the copyrighted training data and formulating the detection of data misappropriation as a hypothesis testing problem. We develop a general statistical testing framework, construct a pivotal statistic, determine the optimal rejection threshold, and explicitly control the type I and type II errors. Furthermore, we establish the asymptotic optimality properties of the proposed tests, and demonstrate its empirical effectiveness through intensive numerical experiments. 

**Abstract (ZH)**: 近年来，大型语言模型（LLMs）迅速获得了巨大的流行度。然而，LLMs的训练也引发了重大的隐私和法律问题，尤其是在未经适当归属或许可的情况下将受版权保护的内容纳入其训练数据之中，这属于更广泛的数据误用问题。本文重点关注数据误用检测中的一个具体问题，即判断给定的LLM是否包含另一个LLM生成的数据。为了应对这一问题，我们提出将水印嵌入受版权保护的训练数据中，并将数据误用检测问题表述为假设检验问题。我们建立了通用的统计检验框架，构造了关键统计量，确定了最优拒绝阈值，并明确控制了I型错误和II型错误。此外，我们确立了所提出的检验的渐近最优性，并通过密集的数值实验展示了其实证有效性。 

---
# Efficient Deployment of Large Language Models on Resource-constrained Devices 

**Title (ZH)**: 资源受限设备上高效部署大型语言模型 

**Authors**: Zhiwei Yao, Yang Xu, Hongli Xu, Yunming Liao, Zuan Xie  

**Link**: [PDF](https://arxiv.org/pdf/2501.02438)  

**Abstract**: Deploying Large Language Models (LLMs) on resource-constrained (or weak) devices presents significant challenges due to limited resources and heterogeneous data distribution. To address the data concern, it is necessary to fine-tune LLMs using on-device private data for various downstream tasks. While Federated Learning (FL) offers a promising privacy-preserving solution, existing fine-tuning methods retain the original LLM size, leaving issues of high inference latency and excessive memory demands unresolved. Hence, we design FedSpine, an FL framework that combines Parameter- Efficient Fine-Tuning (PEFT) with structured pruning for efficient deployment of LLMs on resource-constrained devices. Specifically, FedSpine introduces an iterative process to prune and tune the parameters of LLMs. To mitigate the impact of device heterogeneity, an online Multi-Armed Bandit (MAB) algorithm is employed to adaptively determine different pruning ratios and LoRA ranks for heterogeneous devices without any prior knowledge of their computing and communication capabilities. As a result, FedSpine maintains higher inference accuracy while improving fine-tuning efficiency. Experimental results conducted on a physical platform with 80 devices demonstrate that FedSpine can speed up fine-tuning by 1.4$\times$-6.9$\times$ and improve final accuracy by 0.4%-4.5% under the same sparsity level compared to other baselines. 

**Abstract (ZH)**: 将下面的论文内容或标题翻译成中文，要符合学术规范：

在资源受限（或薄弱）设备上部署大型语言模型（LLMs）面临重大挑战，主要是由于资源有限和数据分布异质性。为了解决数据问题，有必要使用设备上的私有数据对LLMs进行微调以满足各种下游任务的需求。虽然联邦学习（FL）提供了一种有前景的隐私保护解决方案，但现有的微调方法保留了原始LLM的大小，未能解决高推理延迟和内存需求过高的问题。因此，我们设计了FedSpine，这是一种结合参数高效微调（PEFT）与结构化剪枝的联邦学习框架，以实现LLMs的有效部署。具体而言，FedSpine 引入了一个迭代过程，用于修剪和优化LLMs的参数。为减轻设备异质性的影响，我们采用了在线多臂老虎机（MAB）算法，能够适应地为不同类型的异质设备确定不同的修剪比率和LoRA秩，而无需预先了解这些设备的计算和通信能力。因此，FedSpine 在保持高推理准确率的同时，提高了微调效率。在包含80台设备的实际平台上进行的实验结果显示，与其他基准方法相比，在相同的稀疏度水平下，FedSpine可以在微调上加速1.4倍至6.9倍，并且最终准确率可提高0.4%至4.5%。 

---
# Interpretable Neural ODEs for Gene Regulatory Network Discovery under Perturbations 

**Title (ZH)**: 可解释的神经ODE模型在扰动条件下的基因调控网络发现 

**Authors**: Zaikang Lin, Sei Chang, Aaron Zweig, Elham Azizi, David A. Knowles  

**Link**: [PDF](https://arxiv.org/pdf/2501.02409)  

**Abstract**: Modern high-throughput biological datasets with thousands of perturbations provide the opportunity for large-scale discovery of causal graphs that represent the regulatory interactions between genes. Numerous methods have been proposed to infer a directed acyclic graph (DAG) corresponding to the underlying gene regulatory network (GRN) that captures causal gene relationships. However, existing models have restrictive assumptions (e.g. linearity, acyclicity), limited scalability, and/or fail to address the dynamic nature of biological processes such as cellular differentiation. We propose PerturbODE, a novel framework that incorporates biologically informative neural ordinary differential equations (neural ODEs) to model cell state trajectories under perturbations and derive the causal GRN from the neural ODE's parameters. We demonstrate PerturbODE's efficacy in trajectory prediction and GRN inference across simulated and real over-expression datasets. 

**Abstract (ZH)**: 现代的高通量生物数据集包含成千上万种扰动，为大规模发现描述基因之间调节相互作用的因果图提供了机会。已经提出了多种方法来推断对应于潜在基因调控网络（GRN）的有向无环图（DAG），以捕捉因果基因关系。然而，现有的模型存在一些限制性的假设（例如线性、无环），并且在可扩展性和处理生物过程中动态性质（例如细胞分化）方面存在局限性。我们提出了PerturbODE这一新型框架，该框架结合了生物信息量丰富的神经常微分方程（神经ODE）来建模在扰动下的细胞状态轨迹，并从神经ODE的参数中推导出因果GRN。我们在模拟和真实的过度表达数据集上展示了PerturbODE在轨迹预测和GRN推断方面的有效性能。 

---
# Who Wrote This? Zero-Shot Statistical Tests for LLM-Generated Text Detection using Finite Sample Concentration Inequalities 

**Title (ZH)**: 谁是作者？基于有限样本 Concentration Inequalities 的零样本统计检验方法用于检测 LLM 生成的文本 

**Authors**: Tara Radvand, Mojtaba Abdolmaleki, Mohamed Mostagir, Ambuj Tewari  

**Link**: [PDF](https://arxiv.org/pdf/2501.02406)  

**Abstract**: Verifying the provenance of content is crucial to the function of many organizations, e.g., educational institutions, social media platforms, firms, etc. This problem is becoming increasingly difficult as text generated by Large Language Models (LLMs) becomes almost indistinguishable from human-generated content. In addition, many institutions utilize in-house LLMs and want to ensure that external, non-sanctioned LLMs do not produce content within the institution. In this paper, we answer the following question: Given a piece of text, can we identify whether it was produced by LLM $A$ or $B$ (where $B$ can be a human)? We model LLM-generated text as a sequential stochastic process with complete dependence on history and design zero-shot statistical tests to distinguish between (i) the text generated by two different sets of LLMs $A$ (in-house) and $B$ (non-sanctioned) and also (ii) LLM-generated and human-generated texts. We prove that the type I and type II errors for our tests decrease exponentially in the text length. In designing our tests, we derive concentration inequalities on the difference between log-perplexity and the average entropy of the string under $A$. Specifically, for a given string, we demonstrate that if the string is generated by $A$, the log-perplexity of the string under $A$ converges to the average entropy of the string under $A$, except with an exponentially small probability in string length. We also show that if $B$ generates the text, except with an exponentially small probability in string length, the log-perplexity of the string under $A$ converges to the average cross-entropy of $B$ and $A$. Lastly, we present preliminary experimental results to support our theoretical results. By enabling guaranteed (with high probability) finding of the origin of harmful LLM-generated text with arbitrary size, we can help fight misinformation. 

**Abstract (ZH)**: 验证内容的来源对于许多组织的功能至关重要，例如教育机构、社交媒体平台、企业等。随着大型语言模型（LLMs）生成的文本越来越难以与人类生成的内容区分开来，这一问题变得日益复杂。此外，许多机构使用内部的LLMs，并希望确保外部、未经许可的LLMs不会在机构内生成内容。在本文中，我们回答了以下问题：给定一段文本，我们是否可以确定它是由LLM \(A\)还是\(B\)（其中\(B\)可以是真人）生成的？我们将LLM生成的文本建模为一个完全依赖于历史的顺序随机过程，并设计零样本统计检验来区分以下情况：（i）由不同两组LLM（内部的LLM \(A\)和外部的非许可LLM \(B\)）生成的文本；（ii）LLM生成的文本和人类生成的文本。我们证明，我们的检验的一类错误和二类错误随文本长度呈指数级减少。在设计这些检验时，我们推导出了关于基于字符串在LLM \(A\)下对数困惑度和平均熵差异的集中不等式。具体来说，对于给定的字符串，我们证明了如果该字符串是由LLM \(A\)生成的，那么该字符串在LLM \(A\)下的对数困惑度将收敛于该字符串在LLM \(A\)下的平均熵，仅以指数级概率下的极小概率不成立。我们还证明，如果LLM \(B\)生成了文本，那么在指数级概率下的极小概率外，该字符串在LLM \(A\)下的对数困惑度会收敛于LLM \(B\)和LLM \(A\)的平均交叉熵。最后，我们展示了初步的实验结果来支持我们的理论结果。通过确保能够以高概率识别任意大小的有害LLM生成文本的来源，我们能够帮助打击虚假信息。 

---
# iTARGET: Interpretable Tailored Age Regression for Grouped Epigenetic Traits 

**Title (ZH)**: iTARGET: 可解释的分组表观遗传特征个性化年龄回归 

**Authors**: Zipeng Wu, Daniel Herring, Fabian Spill, James Andrews  

**Link**: [PDF](https://arxiv.org/pdf/2501.02401)  

**Abstract**: Accurately predicting chronological age from DNA methylation patterns is crucial for advancing biological age estimation. However, this task is made challenging by Epigenetic Correlation Drift (ECD) and Heterogeneity Among CpGs (HAC), which reflect the dynamic relationship between methylation and age across different life stages. To address these issues, we propose a novel two-phase algorithm. The first phase employs similarity searching to cluster methylation profiles by age group, while the second phase uses Explainable Boosting Machines (EBM) for precise, group-specific prediction. Our method not only improves prediction accuracy but also reveals key age-related CpG sites, detects age-specific changes in aging rates, and identifies pairwise interactions between CpG sites. Experimental results show that our approach outperforms traditional epigenetic clocks and machine learning models, offering a more accurate and interpretable solution for biological age estimation with significant implications for aging research. 

**Abstract (ZH)**: 从DNA甲基化模式准确预测 chronological age 对于推进生物学年龄估算是至关重要的。然而，这一任务由于表观遗传相关漂移（ECD）和CpG异质性（HAC）而变得复杂，这些现象反映了不同生命阶段甲基化与年龄之间的动态关系。为了应对这些挑战，我们提出了一种新颖的两阶段算法。第一阶段采用相似性搜索来按年龄组聚类甲基化轮廓，第二阶段则利用可解释提升机（EBM）进行精确的群体特定预测。我们的方法不仅提高了预测准确性，还揭示了与年龄相关的关键CpG位点，检测了特定于年龄的衰老速率变化，并识别了CpG位点之间的两两相互作用。实验结果表明，我们的方法优于传统的表观遗传时钟和机器学习模型，提供了一种更准确且更具可解释性的生物学年龄估测方法，对衰老研究具有重要含义。 

---
# Graph-Aware Isomorphic Attention for Adaptive Dynamics in Transformers 

**Title (ZH)**: 基于图的同构注意力机制以适应Transformer中的动态变化 

**Authors**: Markus J. Buehler  

**Link**: [PDF](https://arxiv.org/pdf/2501.02393)  

**Abstract**: We present an approach to modifying Transformer architectures by integrating graph-aware relational reasoning into the attention mechanism, merging concepts from graph neural networks and language modeling. Building on the inherent connection between attention and graph theory, we reformulate the Transformer's attention mechanism as a graph operation and propose Graph-Aware Isomorphic Attention. This method leverages advanced graph modeling strategies, including Graph Isomorphism Networks (GIN) and Principal Neighborhood Aggregation (PNA), to enrich the representation of relational structures. Our approach captures complex dependencies and generalizes across tasks, as evidenced by a reduced generalization gap and improved learning performance. Additionally, we expand the concept of graph-aware attention to introduce Sparse GIN-Attention, a fine-tuning approach that employs sparse GINs. By interpreting attention matrices as sparse adjacency graphs, this technique enhances the adaptability of pre-trained foundational models with minimal computational overhead, endowing them with graph-aware capabilities. Sparse GIN-Attention fine-tuning achieves improved training dynamics and better generalization compared to alternative methods like low-rank adaption (LoRA). We discuss latent graph-like structures within traditional attention mechanisms, offering a new lens through which Transformers can be understood. By evolving Transformers as hierarchical GIN models for relational reasoning. This perspective suggests profound implications for foundational model development, enabling the design of architectures that dynamically adapt to both local and global dependencies. Applications in bioinformatics, materials science, language modeling, and beyond could benefit from this synthesis of relational and sequential data modeling, setting the stage for interpretable and generalizable modeling strategies. 

**Abstract (ZH)**: 我们提出了通过将图意识关系推理整合到注意力机制中来修改Transformer架构的方法，结合了图神经网络和语言建模的概念。基于注意力和图论之间的固有联系，我们将Transformer的注意力机制重新表述为图操作，并提出了一种图意识同构注意力机制（Graph-Aware Isomorphic Attention）。该方法利用了先进的图建模策略，包括图同构网络（GIN）和主邻域聚合（PNA），以丰富关系结构的表示。我们的方法能够捕捉到复杂的依赖关系，并在不同类型的任务上表现出更好的泛化能力，这从泛化差距的减小以及改进的学习性能得到了验证。此外，我们扩展了图意识注意力的概念，引入了稀疏GIN-注意力机制，这是一种采用稀疏GIN进行微调的方法。通过将注意力矩阵视为稀疏邻接图，该技术能够以最小的计算开销增强预训练基础模型的适应性，并赋予它们图意识能力。与低秩适配（LoRA）等方法相比，稀疏GIN-注意力机制的微调能够实现更好的训练动态和泛化能力。我们讨论了传统注意力机制中的潜在图样结构，提供了一种新的视角来理解Transformer。通过将Transformer演化为层次GIN模型以进行关系推理，这一视角暗示了基础模型开发的重要意义，使能够设计出能够动态适应局部和全局依赖性的架构。生物信息学、材料科学、语言建模以及其他领域的应用可以从关系数据和序列数据建模的融合中获益，为可解释性和可泛化的建模策略奠定基础。 

---
# Syntactic Evolution in Language Usage 

**Title (ZH)**: 语言使用中的句法演变 

**Authors**: Surbhit Kumar  

**Link**: [PDF](https://arxiv.org/pdf/2501.02392)  

**Abstract**: This research aims to investigate the dynamic nature of linguistic style throughout various stages of life, from post teenage to old age. By employing linguistic analysis tools and methodologies, the study will delve into the intricacies of how individuals adapt and modify their language use over time. The research uses a data set of blogs from this http URL from 2004 and focuses on English for syntactic analysis. The findings of this research can have implications for linguistics, psychology, and communication studies, shedding light on the intricate relationship between age and language. 

**Abstract (ZH)**: 本研究旨在探讨语言风格在人生不同阶段（从青少年期之后到老年期）的动态特性。通过使用语言分析工具和方法，研究将深入探讨个体如何随时间调整和改变其语言使用方式的复杂性。本研究利用2004年从该网址（请在此处提供网址）获取的博客数据集，并集中在句法分析上的英语。本研究的发现对语言学、心理学和传播学等领域具有重要意义，有助于阐明年龄与语言之间的复杂关系。 

---
# Context Aware Lemmatization and Morphological Tagging Method in Turkish 

**Title (ZH)**: 面向上下文的土耳其语词形还原和形态标记方法 

**Authors**: Cagri Sayallar  

**Link**: [PDF](https://arxiv.org/pdf/2501.02361)  

**Abstract**: The smallest part of a word that defines the word is called a word root. Word roots are used to increase success in many applications since they simplify the word. In this study, the lemmatization model, which is a word root finding method, and the morphological tagging model, which predicts the grammatical knowledge of the word, are presented. The presented model was developed for Turkish, and both models make predictions by taking the meaning of the word into account. In the literature, there is no lemmatization study that is sensitive to word meaning in Turkish. For this reason, the present study shares the model and the results obtained from the model on Turkish lemmatization for the first time in the literature. In the present study, in the lemmatization and morphological tagging models, bidirectional LSTM is used for the spelling of words, and the Turkish BERT model is used for the meaning of words. The models are trained using the IMST and PUD datasets from Universal Dependencies. The results from the training of the models were compared with the results from the SIGMORPHON 2019 competition. The results of the comparisons revealed that our models were superior. 

**Abstract (ZH)**: 一个词中能够定义该词的最小部分称为词根。由于词根简化了单词，因此在许多应用中使用词根可以提高成功率。在本研究中，我们提出了一个词根查找模型——词形还原模型，以及一个预测单词语法知识的形态标注模型。这两个模型都是为土耳其语开发的，并且在进行预测时都考虑了单词的意义。文献中没有针对土耳其语进行过考虑单词意义的词形还原研究，因此本研究首次在文献中分享了这两个模型及其在土耳其语词形还原中的应用结果。在本研究中，词形还原和形态标注模型使用双向LSTM进行单词拼写，并使用土耳其语BERT模型进行单词意义的处理。模型使用Universal Dependencies中的IMST和PUD数据集进行训练。将模型训练结果与SIGMORPHON 2019竞赛的结果进行了比较，比较结果显示我们模型的表现更为出色。 

---
# GNSS/GPS Spoofing and Jamming Identification Using Machine Learning and Deep Learning 

**Title (ZH)**: 使用机器学习和深度学习进行GNSS/GPS欺骗与干扰识别 

**Authors**: Ali Ghanbarzade, Hossein Soleimani  

**Link**: [PDF](https://arxiv.org/pdf/2501.02352)  

**Abstract**: The increasing reliance on Global Navigation Satellite Systems (GNSS), particularly the Global Positioning System (GPS), underscores the urgent need to safeguard these technologies against malicious threats such as spoofing and jamming. As the backbone for positioning, navigation, and timing (PNT) across various applications including transportation, telecommunications, and emergency services GNSS is vulnerable to deliberate interference that poses significant risks. Spoofing attacks, which involve transmitting counterfeit GNSS signals to mislead receivers into calculating incorrect positions, can result in serious consequences, from navigational errors in civilian aviation to security breaches in military operations. Furthermore, the lack of inherent security measures within GNSS systems makes them attractive targets for adversaries. While GNSS/GPS jamming and spoofing systems consist of numerous components, the ability to distinguish authentic signals from malicious ones is essential for maintaining system integrity. Recent advancements in machine learning and deep learning provide promising avenues for enhancing detection and mitigation strategies against these threats. This paper addresses both spoofing and jamming by tackling real-world challenges through machine learning, deep learning, and computer vision techniques. Through extensive experiments on two real-world datasets related to spoofing and jamming detection using advanced algorithms, we achieved state of the art results. In the GNSS/GPS jamming detection task, we attained approximately 99% accuracy, improving performance by around 5% compared to previous studies. Additionally, we addressed a challenging tasks related to spoofing detection, yielding results that underscore the potential of machine learning and deep learning in this domain. 

**Abstract (ZH)**: 全球导航卫星系统（GNSS），尤其是全球定位系统（GPS）的日益依赖性凸显出防范恶意威胁（如伪造和干扰）的紧急需求。作为各种应用（包括交通、电信和应急服务等领域）中定位、导航和授时（PNT）的核心基础，GNSS易受故意干扰的影响，这带来了重大风险。伪造攻击通过传输伪造的GNSS信号误导接收器计算错误的位置，其后果可能从民用航空中的导航错误到军事操作中的安全漏洞。此外，GNSS系统缺乏内在的安全措施，使其成为敌对方的 attractive 目标。尽管GNSS/GPS干扰和伪造系统包含多个组件，但能够区分真实信号与恶意信号的能力对于保持系统完整至关重要。近年来，机器学习和深度学习的进步为增强这些威胁的检测与缓解策略提供了前景。本文通过结合机器学习、深度学习和计算机视觉技术来解决伪造和干扰的实际挑战。通过在伪造和干扰检测领域使用先进算法的两个实际数据集进行广泛实验，我们取得了领先的研究成果。在GNSS/GPS干扰检测任务中，我们达到了约99%的准确率，相较于之前的研究所改善约5%的性能。此外，我们还解决了伪造检测的挑战任务，结果进一步突显了机器学习和深度学习在该领域的潜力。 

---
# Exploring the Capabilities and Limitations of Large Language Models for Radiation Oncology Decision Support 

**Title (ZH)**: 探索大型语言模型在放射肿瘤学决策支持中的能力和局限性 

**Authors**: Florian Putz, Marlen Haderleina, Sebastian Lettmaier, Sabine Semrau, Rainer Fietkau, Yixing Huang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02346)  

**Abstract**: Thanks to the rapidly evolving integration of LLMs into decision-support tools, a significant transformation is happening across large-scale systems. Like other medical fields, the use of LLMs such as GPT-4 is gaining increasing interest in radiation oncology as well. An attempt to assess GPT-4's performance in radiation oncology was made via a dedicated 100-question examination on the highly specialized topic of radiation oncology physics, revealing GPT-4's superiority over other LLMs. GPT-4's performance on a broader field of clinical radiation oncology is further benchmarked by the ACR Radiation Oncology In-Training (TXIT) exam where GPT-4 achieved a high accuracy of 74.57%. Its performance on re-labelling structure names in accordance with the AAPM TG-263 report has also been benchmarked, achieving above 96% accuracies. Such studies shed light on the potential of LLMs in radiation oncology. As interest in the potential and constraints of LLMs in general healthcare applications continues to rise5, the capabilities and limitations of LLMs in radiation oncology decision support have not yet been fully explored. 

**Abstract (ZH)**: 由于大规模语言模型（LLM）快速融入决策支持工具，正在对大型系统产生显著的转变。就像其他医学领域一样，GPT-4等LLM在放射肿瘤学中的应用正日益受到关注。我们通过一项针对放射肿瘤学物理学这一专业领域的100道题的专项考试，评估了GPT-4的表现，结果显示其在其他LLM之上。GPT-4在更广泛的临床放射肿瘤学领域的表现通过ACR放射肿瘤学在岗培训（TXIT）考试进一步进行了基准测试，其准确率为74.57%。此外，GPT-4在按照AAPM TG-263报告重新标注结构名称方面也达到了96%以上的准确率。这类研究表明了LLM在放射肿瘤学中的潜在应用价值。随着对LLM在一般医疗保健应用中的潜力和限制的关注不断上升，放射肿瘤学决策支持中LLM的能力和局限性尚未得到充分探索。 

---
# Optimizing Small Language Models for In-Vehicle Function-Calling 

**Title (ZH)**: 优化车载功能调用的小型语言模型 

**Authors**: Yahya Sowti Khiabani, Farris Atif, Chieh Hsu, Sven Stahlmann, Tobias Michels, Sebastian Kramer, Benedikt Heidrich, M. Saquib Sarfraz, Julian Merten, Faezeh Tafazzoli  

**Link**: [PDF](https://arxiv.org/pdf/2501.02342)  

**Abstract**: We propose a holistic approach for deploying Small Language Models (SLMs) as function-calling agents within vehicles as edge devices, offering a more flexible and robust alternative to traditional rule-based systems. By leveraging SLMs, we simplify vehicle control mechanisms and enhance the user experience. Given the in-vehicle hardware constraints, we apply state-of-the-art model compression techniques, including structured pruning, healing, and quantization, ensuring that the model fits within the resource limitations while maintaining acceptable performance. Our work focuses on optimizing a representative SLM, Microsoft's Phi-3 mini, and outlines best practices for enabling embedded models, including compression, task-specific fine-tuning, and vehicle integration. We demonstrate that, despite significant reduction in model size which removes up to 2 billion parameters from the original model, our approach preserves the model's ability to handle complex in-vehicle tasks accurately and efficiently. Furthermore, by executing the model in a lightweight runtime environment, we achieve a generation speed of 11 tokens per second, making real-time, on-device inference feasible without hardware acceleration. Our results demonstrate the potential of SLMs to transform vehicle control systems, enabling more intuitive interactions between users and their vehicles for an enhanced driving experience. 

**Abstract (ZH)**: 我们提出了一种整体方法，将小型语言模型（SLMs）部署为车载边缘设备中的功能调用代理，提供了一种比传统基于规则的系统更具灵活性和鲁棒性的替代方案。通过利用SLMs，我们简化了车辆控制机制并提升了用户体验。鉴于车载硬件的限制，我们应用了最先进的模型压缩技术，包括结构化剪枝、愈合和量化，确保模型在资源限制内运行的同时仍能保持良好的性能。我们的工作集中在优化一个典型的SLM——Microsoft的Phi-3 mini，并提出了使嵌入式模型能够运行的最佳实践，包括压缩、任务特定微调以及车辆集成。我们证明，尽管模型大小显著减小，移除了原模型中高达2亿个参数，但我们的方法仍能保持模型处理复杂车内任务的准确性和效率。此外，通过在轻量级运行时环境中执行模型，我们实现了每秒生成11个token的速度，使得在不使用硬件加速的情况下进行实时、本地推理成为可能。我们的结果展示了SLMs在转变车辆控制系统方面的潜力，以实现用户与车辆之间更为直观的交互，从而提升驾驶体验。 

---
# UAVs Meet LLMs: Overviews and Perspectives Toward Agentic Low-Altitude Mobility 

**Title (ZH)**: 无人机遇见大语言模型：自主低空移动的概览与展望 

**Authors**: Yonglin Tian, Fei Lin, Yiduo Li, Tengchao Zhang, Qiyao Zhang, Xuan Fu, Jun Huang, Xingyuan Dai, Yutong Wang, Chunwei Tian, Bai Li, Yisheng Lv, Levente Kovács, Fei-Yue Wang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02341)  

**Abstract**: Low-altitude mobility, exemplified by unmanned aerial vehicles (UAVs), has introduced transformative advancements across various domains, like transportation, logistics, and agriculture. Leveraging flexible perspectives and rapid maneuverability, UAVs extend traditional systems' perception and action capabilities, garnering widespread attention from academia and industry. However, current UAV operations primarily depend on human control, with only limited autonomy in simple scenarios, and lack the intelligence and adaptability needed for more complex environments and tasks. The emergence of large language models (LLMs) demonstrates remarkable problem-solving and generalization capabilities, offering a promising pathway for advancing UAV intelligence. This paper explores the integration of LLMs and UAVs, beginning with an overview of UAV systems' fundamental components and functionalities, followed by an overview of the state-of-the-art in LLM technology. Subsequently, it systematically highlights the multimodal data resources available for UAVs, which provide critical support for training and evaluation. Furthermore, it categorizes and analyzes key tasks and application scenarios where UAVs and LLMs converge. Finally, a reference roadmap towards agentic UAVs is proposed, aiming to enable UAVs to achieve agentic intelligence through autonomous perception, memory, reasoning, and tool utilization. Related resources are available at this https URL. 

**Abstract (ZH)**: 低空移动性，以无人机（UAVs）为例，在交通、物流和农业等多个领域引入了变革性的进步。利用灵活的视角和快速的操作能力，无人机扩展了传统系统感知和行动的能力，吸引了学术界和工业界的广泛关注。然而，当前的无人机操作主要依赖于人工控制，在简单场景中仅限于有限的自主能力，缺乏在更复杂环境和任务中所需的智能和适应能力。大型语言模型（LLMs）的出现展示了其出色的解决问题和泛化能力，为推进无人机智能提供了有前景的途径。本文探讨了将LLMs与UAVs集成的方法，首先概述了无人机系统的基本组件和功能，随后概述了当前大型语言模型技术的最新进展。接着，系统地介绍了可用于无人机的多模态数据资源，这些资源为训练和评估提供了关键支持。文中还对无人机和大型语言模型在关键任务和应用场景中的交汇点进行了分类和分析。最后，提出了一个通往自主无人机的参考路线图，旨在通过自主感知、记忆、推理和工具利用，使无人机实现自主智能。相关资源可以通过以下链接获取：https://your-resource-url-here.com 

---
# Evaluation of the Code Generation Capabilities of ChatGPT 4: A Comparative Analysis in 19 Programming Languages 

**Title (ZH)**: ChatGPT 4 的代码生成能力评估：19 种编程语言的比较分析 

**Authors**: L. C. Gilbert  

**Link**: [PDF](https://arxiv.org/pdf/2501.02338)  

**Abstract**: This bachelor's thesis examines the capabilities of ChatGPT 4 in code generation across 19 programming languages. The study analyzed solution rates across three difficulty levels, types of errors encountered, and code quality in terms of runtime and memory efficiency through a quantitative experiment. A total of 188 programming problems were selected from the LeetCode platform, and ChatGPT 4 was given three attempts to produce a correct solution with feedback. ChatGPT 4 successfully solved 39.67% of all tasks, with success rates decreasing significantly as problem complexity increased. Notably, the model faced considerable challenges with hard problems across all languages. ChatGPT 4 demonstrated higher competence in widely used languages, likely due to a larger volume and higher quality of training data. The solution rates also revealed a preference for languages with low abstraction levels and static typing. For popular languages, the most frequent error was "Wrong Answer," whereas for less popular languages, compiler and runtime errors prevailed, suggesting frequent misunderstandings and confusion regarding the structural characteristics of these languages. The model exhibited above-average runtime efficiency in all programming languages, showing a tendency toward statically typed and low-abstraction languages. Memory efficiency results varied significantly, with above-average performance in 14 languages and below-average performance in five languages. A slight preference for low-abstraction languages and a leaning toward dynamically typed languages in terms of memory efficiency were observed. Future research should include a larger number of tasks, iterations, and less popular languages. Additionally, ChatGPT 4's abilities in code interpretation and summarization, debugging, and the development of complex, practical code could be analyzed further. 

**Abstract (ZH)**: 本学士学位论文考察了ChatGPT 4在19种编程语言中的代码生成能力。研究通过定量实验分析了不同难度级别的解题率、遇到的错误类型以及在运行效率和内存效率方面的代码质量。从LeetCode平台选择了188个编程问题，ChatGPT 4被允许在有反馈的情况下尝试三次，以生成正确解决方案。ChatGPT 4成功解决了所有任务的39.67%，随着问题复杂度的增加，成功率显著下降。值得注意的是，该模型在所有语言中处理困难问题时面临巨大挑战。ChatGPT 4在广泛使用的语言中表现出更高的能力，这可能归因于更大的训练数据量和更高的质量。解题率还揭示了对低抽象级别和静态类型语言的偏好。在流行的语言中，“Wrong Answer”是最常见的错误，而在不那么流行的语言中，编译器和运行时错误则占主导，表明对这些语言的结构特点有频繁的误解和困惑。模型在所有编程语言中都表现出色的运行效率，倾向于静态类型和低抽象级别的语言。内存效率的结果则差异显著，有14种语言表现出色，5种语言表现不佳。观察到对低抽象级别语言的轻微偏好，并且在内存效率方面倾向于动态类型语言。未来的研究应包括更多的任务、迭代以及不那么流行的编程语言。此外，还应进一步分析ChatGPT 4在代码解释和总结、调试以及开发复杂实用代码方面的能力。 

---
# AdaSkip: Adaptive Sublayer Skipping for Accelerating Long-Context LLM Inference 

**Title (ZH)**: AdaSkip：适应性子层跳过加速长上下文LLM推理 

**Authors**: Zhuomin He, Yizhen Yao, Pengfei Zuo, Bin Gao, Qinya Li, Zhenzhe Zheng, Fan Wu  

**Link**: [PDF](https://arxiv.org/pdf/2501.02336)  

**Abstract**: Long-context large language models (LLMs) inference is increasingly critical, motivating a number of studies devoted to alleviating the substantial storage and computational costs in such scenarios. Layer-wise skipping methods are promising optimizations but rarely explored in long-context inference. We observe that existing layer-wise skipping strategies have several limitations when applied in long-context inference, including the inability to adapt to model and context variability, disregard for sublayer significance, and inapplicability for the prefilling phase. This paper proposes \sysname, an adaptive sublayer skipping method specifically designed for long-context inference. \sysname adaptively identifies less important layers by leveraging on-the-fly similarity information, enables sublayer-wise skipping, and accelerates both the prefilling and decoding phases. The effectiveness of \sysname is demonstrated through extensive experiments on various long-context benchmarks and models, showcasing its superior inference performance over existing baselines. 

**Abstract (ZH)**: 长上下文大规模语言模型（LLMs）推理日益重要，促使了多项研究致力于缓解此类场景中的显著存储和计算成本。逐层跳过方法是很有前景的优化手段，但在长上下文推理中鲜有探索。我们观察到，现有的逐层跳过策略在长上下文推理中存在几个限制，包括无法适应模型和上下文的变化性、忽视子层的重要性以及不适用于填充阶段。本文提出了一种名为**SysName**的自适应子层跳过方法，专门设计用于长上下文推理。**SysName**通过利用实时相似性信息自适应地识别较不重要的层，支持子层级别的跳过，并加速填充和解码阶段。通过在多种长上下文基准和模型上进行广泛的实验，证明了**SysName**在推理性能方面的优越性，高于现有基线方法。 

---
# Validity Arguments For Constructed Response Scoring Using Generative Artificial Intelligence Applications 

**Title (ZH)**: 生成式人工智能应用背景下构造性回答评分的有效性论证 

**Authors**: Jodi M. Casabianca, Daniel F. McCaffrey, Matthew S. Johnson, Naim Alper, Vladimir Zubenko  

**Link**: [PDF](https://arxiv.org/pdf/2501.02334)  

**Abstract**: The rapid advancements in large language models and generative artificial intelligence (AI) capabilities are making their broad application in the high-stakes testing context more likely. Use of generative AI in the scoring of constructed responses is particularly appealing because it reduces the effort required for handcrafting features in traditional AI scoring and might even outperform those methods. The purpose of this paper is to highlight the differences in the feature-based and generative AI applications in constructed response scoring systems and propose a set of best practices for the collection of validity evidence to support the use and interpretation of constructed response scores from scoring systems using generative AI. We compare the validity evidence needed in scoring systems using human ratings, feature-based natural language processing AI scoring engines, and generative AI. The evidence needed in the generative AI context is more extensive than in the feature-based NLP scoring context because of the lack of transparency and other concerns unique to generative AI such as consistency. Constructed response score data from standardized tests demonstrate the collection of validity evidence for different types of scoring systems and highlights the numerous complexities and considerations when making a validity argument for these scores. In addition, we discuss how the evaluation of AI scores might include a consideration of how a contributory scoring approach combining multiple AI scores (from different sources) will cover more of the construct in the absence of human ratings. 

**Abstract (ZH)**: 近年来，大型语言模型和生成型人工智能（AI）能力的迅速发展使其在高风险测试环境中更广泛的应用成为可能。特别是在作品集型响应评分中使用生成型AI尤为重要，因为它减少了传统AI评分所需的手工特征工程的工作量，并且有可能超越这些方法。本文的目的是突出基于特征的评分系统和生成型AI在作品集型响应评分系统中的差异，并提出一套最佳实践，以收集有效性证据来支持使用和解释基于生成型AI的评分系统的作品集型响应分数。我们将比较在不同评分系统中——包括人类评分、基于特征的自然语言处理AI评分引擎以及生成型AI——所需的有效性证据。生成型AI所需的有效性证据比基于特征的自然语言处理（NLP）评分引擎更为广泛，这主要是由于生成型AI的透明度不足和其他特有的问题，如一致性。通过标准化测试中作品集型响应评分数据的收集，我们可以展示不同评分系统收集有效性证据的过程，并突出在为这些分数的有效性论点提供支持时所面对的诸多复杂性和考量。此外，我们将讨论如何在评估AI评分时，考虑结合多个不同来源的AI评分（贡献性评分方法）可能有助于覆盖更多构念的情况，特别是在没有人类评分的情况下。 

---
# SR-Reward: Taking The Path More Traveled 

**Title (ZH)**: SR-Reward: 走更常走的路径 

**Authors**: Seyed Mahdi B. Azad, Zahra Padar, Gabriel Kalweit, Joschka Boedecker  

**Link**: [PDF](https://arxiv.org/pdf/2501.02330)  

**Abstract**: In this paper, we propose a novel method for learning reward functions directly from offline demonstrations. Unlike traditional inverse reinforcement learning (IRL), our approach decouples the reward function from the learner's policy, eliminating the adversarial interaction typically required between the two. This results in a more stable and efficient training process. Our reward function, called \textit{SR-Reward}, leverages successor representation (SR) to encode a state based on expected future states' visitation under the demonstration policy and transition dynamics. By utilizing the Bellman equation, SR-Reward can be learned concurrently with most reinforcement learning (RL) algorithms without altering the existing training pipeline. We also introduce a negative sampling strategy to mitigate overestimation errors by reducing rewards for out-of-distribution data, thereby enhancing robustness. This strategy inherently introduces a conservative bias into RL algorithms that employ the learned reward. We evaluate our method on the D4RL benchmark, achieving competitive results compared to offline RL algorithms with access to true rewards and imitation learning (IL) techniques like behavioral cloning. Moreover, our ablation studies on data size and quality reveal the advantages and limitations of SR-Reward as a proxy for true rewards. 

**Abstract (ZH)**: 在本文中，我们提出了一种直接从离线演示学习奖励函数的新方法。与传统的逆强化学习（Inverse Reinforcement Learning, IRL）不同，我们的方法将奖励函数与学习者的策略分离，消除了两者之间通常所需的对抗性交互。这导致了更稳定和高效的训练过程。我们提出的奖励函数称为“SR-Reward”，它利用后继表示（Successor Representation, SR）根据演示策略下的预期未来状态的访问情况来编码状态，并结合过渡动力学。借助贝尔曼方程，SR-Reward 可以在不改变现有训练管道的情况下与大多数强化学习（Reinforcement Learning, RL）算法同时学习。我们还引入了一种负采样策略，以通过减少异常分布数据的奖励来减轻过度估计误差，从而增强鲁棒性。这一策略在使用学习到的奖励进行强化学习的算法中不可避免地引入了保守偏差。我们在 D4RL 基准上评估了我们的方法，结果与具有真实奖励访问权限的 Offline RL 算法和基于行为克隆的模仿学习（Imitation Learning, IL）技术相比具有竞争力。此外，我们的数据规模和质量的消融研究揭示了 SR-Reward 作为真实奖励代理的优势和局限性。 

---
# DiffGraph: Heterogeneous Graph Diffusion Model 

**Title (ZH)**: DiffGraph：异质图扩散模型 

**Authors**: Zongwei Li, Lianghao Xia, Hua Hua, Shijie Zhang, Shuangyang Wang, Chao Huang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02313)  

**Abstract**: Recent advances in Graph Neural Networks (GNNs) have revolutionized graph-structured data modeling, yet traditional GNNs struggle with complex heterogeneous structures prevalent in real-world scenarios. Despite progress in handling heterogeneous interactions, two fundamental challenges persist: noisy data significantly compromising embedding quality and learning performance, and existing methods' inability to capture intricate semantic transitions among heterogeneous relations, which impacts downstream predictions. To address these fundamental issues, we present the Heterogeneous Graph Diffusion Model (DiffGraph), a pioneering framework that introduces an innovative cross-view denoising strategy. This advanced approach transforms auxiliary heterogeneous data into target semantic spaces, enabling precise distillation of task-relevant information. At its core, DiffGraph features a sophisticated latent heterogeneous graph diffusion mechanism, implementing a novel forward and backward diffusion process for superior noise management. This methodology achieves simultaneous heterogeneous graph denoising and cross-type transition, while significantly simplifying graph generation through its latent-space diffusion capabilities. Through rigorous experimental validation on both public and industrial datasets, we demonstrate that DiffGraph consistently surpasses existing methods in link prediction and node classification tasks, establishing new benchmarks for robustness and efficiency in heterogeneous graph processing. The model implementation is publicly available at: this https URL. 

**Abstract (ZH)**: 近年来，图神经网络（GNNs）在图结构数据建模方面取得了革命性的进展，但传统GNNs在处理真实世界场景中普遍存在的复杂异质结构方面能力有限。尽管在处理异质交互方面已经取得了进展，但依然存在两个根本性的挑战：噪声数据严重损害嵌入质量和学习性能，以及现有方法无法捕捉异质关系之间的复杂语义转换，这影响了下游预测的准确性。为了解决这些根本问题，我们提出了异质图扩散模型（DiffGraph），这是一种创新性的框架，引入了新颖的跨视图降噪策略。这一先进方法将辅助的异质数据转换为目标语义空间，使模型能够精确地提炼任务相关的信息。DiffGraph的核心在于一种复杂的潜在异质图扩散机制，执行一种新颖的前向和后向扩散过程，以实现更高效的噪声管理。该方法同时实现了异质图降噪和跨类型转换，同时通过潜在空间扩散能力极大地简化了图的生成过程。通过在公共和工业数据集上进行严格的实验验证，我们证明DiffGraph在链接预测和节点分类任务中始终超越现有方法，建立了异质图处理中的鲁棒性和效率的新基准。模型实现已公开可供下载：[这个链接](this https URL)。 

---
# Deep Learning-Driven Segmentation of Ischemic Stroke Lesions Using Multi-Channel MRI 

**Title (ZH)**: 使用多通道MRI的深度学习驱动的缺血性卒中病灶分割 

**Authors**: Ashiqur Rahman, Muhammad E. H. Chowdhury, Md Sharjis Ibne Wadud, Rusab Sarmun, Adam Mushtak, Sohaib Bassam Zoghoul, Israa Al-Hashimi  

**Link**: [PDF](https://arxiv.org/pdf/2501.02287)  

**Abstract**: Ischemic stroke, caused by cerebral vessel occlusion, presents substantial challenges in medical imaging due to the variability and subtlety of stroke lesions. Magnetic Resonance Imaging (MRI) plays a crucial role in diagnosing and managing ischemic stroke, yet existing segmentation techniques often fail to accurately delineate lesions. This study introduces a novel deep learning-based method for segmenting ischemic stroke lesions using multi-channel MRI modalities, including Diffusion Weighted Imaging (DWI), Apparent Diffusion Coefficient (ADC), and enhanced Diffusion Weighted Imaging (eDWI). The proposed architecture integrates DenseNet121 as the encoder with Self-Organized Operational Neural Networks (SelfONN) in the decoder, enhanced by Channel and Space Compound Attention (CSCA) and Double Squeeze-and-Excitation (DSE) blocks. Additionally, a custom loss function combining Dice Loss and Jaccard Loss with weighted averages is introduced to improve model performance. Trained and evaluated on the ISLES 2022 dataset, the model achieved Dice Similarity Coefficients (DSC) of 83.88% using DWI alone, 85.86% with DWI and ADC, and 87.49% with the integration of DWI, ADC, and eDWI. This approach not only outperforms existing methods but also addresses key limitations in current segmentation practices. These advancements significantly enhance diagnostic precision and treatment planning for ischemic stroke, providing valuable support for clinical decision-making. 

**Abstract (ZH)**: 缺血性中风，由于脑血管闭塞导致的中风，其在医学影像学中呈现了显著的挑战，这主要是由于中风病灶的多样性和细微性。磁共振成像（MRI）在诊断和管理缺血性中风中起到了关键作用，但现有的分割技术往往无法准确地勾勒出病灶。本研究提出了一种基于深度学习的方法，用于利用多通道MRI模态（包括弥散加权成像（DWI）、表观弥散系数（ADC）和增强弥散加权成像（eDWI））分割缺血性中风病灶。所提出的设计架构以DenseNet121作为编码器，在解码器中使用自组织操作神经网络（SelfONN），并增强了通道和空间复合注意（CSCA）和双重挤压-激励（DSE）模块。此外，本研究还引入了一种结合Dice损失和Jaccard损失的加权平均值作为自定义损失函数，以提高模型性能。该模型在ISLES 2022数据集中训练和评估后，仅使用DWI时的骰子相似性系数（DSC）为83.88%，结合DWI和ADC时为85.86%，而结合DWI、ADC和eDWI时为87.49%。这种方式不仅超越了现有的方法，并且解决了当前分割技术中的关键限制。这些进展在缺血性中风的诊断精度和治疗计划方面提供了显著的改进，为临床决策提供了有力支持。 

---
# Hyperbolic Contrastive Learning for Hierarchical 3D Point Cloud Embedding 

**Title (ZH)**: 双曲对比学习在层次化3D点云嵌入中的应用 

**Authors**: Yingjie Liu, Pengyu Zhang, Ziyao He, Mingsong Chen, Xuan Tang, Xian Wei  

**Link**: [PDF](https://arxiv.org/pdf/2501.02285)  

**Abstract**: Hyperbolic spaces allow for more efficient modeling of complex, hierarchical structures, which is particularly beneficial in tasks involving multi-modal data. Although hyperbolic geometries have been proven effective for language-image pre-training, their capabilities to unify language, image, and 3D Point Cloud modalities are under-explored. We extend the 3D Point Cloud modality in hyperbolic multi-modal contrastive pre-training. Additionally, we explore the entailment, modality gap, and alignment regularizers for learning hierarchical 3D embeddings and facilitating the transfer of knowledge from both Text and Image modalities. These regularizers enable the learning of intra-modal hierarchy within each modality and inter-modal hierarchy across text, 2D images, and 3D Point this http URL results demonstrate that our proposed training strategy yields an outstanding 3D Point Cloud encoder, and the obtained 3D Point Cloud hierarchical embeddings significantly improve performance on various downstream tasks. 

**Abstract (ZH)**: 双曲空间能够更有效地建模复杂的层次结构，这在涉及多模态数据的任务中特别有益。尽管已证实在语言-图像预训练任务中双曲几何是有效的，但其统一语言、图像和3D点云模态的能力还有待探索。我们扩展了在双曲多模态对比预训练中3D点云模态的应用。此外，我们还探讨了蕴含关系、模态差异和对齐正则化器，以学习层次化的3D嵌入，并促进从文本和图像模态的知识迁移。这些正则化器能够学习每个模态内的层次结构和跨文本、二维图像和3D点云的层次结构。实验结果表明，我们提出的一种训练策略生成了出色的3D点云编码器，获得的3D点云层次化嵌入显著提高了各种下游任务的性能。 

---
# What Kind of Visual Tokens Do We Need? Training-free Visual Token Pruning for Multi-modal Large Language Models from the Perspective of Graph 

**Title (ZH)**: 我们需要什么样的视觉标记？基于图论视角的无训练视觉标记剪枝方法用于多模态大型语言模型 

**Authors**: Yutao Jiang, Qiong Wu, Wenhao Lin, Wei Yu, Yiyi Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2501.02268)  

**Abstract**: Recent Multimodal Large Language Models(MLLMs) often use a large number of visual tokens to compensate their visual shortcoming, leading to excessive computation and obvious visual redundancy. In this paper, we investigate what kind of visual tokens are needed for MLLMs, and reveal that both foreground and background tokens are critical for MLLMs given the varying difficulties of examples. Based on this observation, we propose a graph-based method towards training-free visual token pruning, termed this http URL particular, G-Prune regards visual tokens as nodes, and construct their connections based on their semantic similarities. Afterwards, the information flow is propagated via weighted links, and the most important tokens after iterations are kept for MLLMs, which can be front or this http URL validate G-Prune, we apply it to a recent MLLM called LLaVA-NeXT, and conduct extensive experiments on a set of this http URL experiment results show that G-Prune can greatly reduce computation overhead while retaining high performance on both coarse- and fine-grained tasks. For instance, G-Prune can reduce 63.57\% FLOPs of LLaVA-NeXT on VQA2.0 and TextVQA with only 0.95\% and 2.34\% accuracy drops, respectively. 

**Abstract (ZH)**: 近年来，多模态大规模语言模型（MLLMs）经常使用大量的视觉标记来弥补其视觉方面的不足，导致了计算量过大和明显的视觉冗余。本文探讨了MLLMs需要哪些视觉标记，并揭示了在不同难度的示例中，前景和背景标记都是关键的。基于这一观察，我们提出了一种基于图的方法，用于无训练的视觉标记修剪，称之为这种特定方法。特别地，G-Prune将视觉标记视为节点，并根据它们的语义相似性构建连接。此后，信息通过加权链接传播，在迭代后保留最重要的标记用于MLLMs，这些标记可以是前景的或背景的。为了验证G-Prune的有效性，我们将其应用于最近的一种MLLM（LLaVA-NeXT），并在一组实验中进行了广泛测试。实验结果表明，G-Prune可以大大减少计算开销，同时在粗粒度和细粒度任务上保持高性能。例如，G-Prune可以在VQA2.0和TextVQA上将LLaVA-NeXT的FLOPs分别减少63.57%，仅损失0.95%和2.34%的准确性。 

---
# Towards a constructive framework for control theory 

**Title (ZH)**: 朝向一种建设性的控制理论框架 

**Authors**: Pavel Osinenko  

**Link**: [PDF](https://arxiv.org/pdf/2501.02267)  

**Abstract**: This work presents a framework for control theory based on constructive analysis to account for discrepancy between mathematical results and their implementation in a computer, also referred to as computational uncertainty. In control engineering, the latter is usually either neglected or considered submerged into some other type of uncertainty, such as system noise, and addressed within robust control. However, even robust control methods may be compromised when the mathematical objects involved in the respective algorithms fail to exist in exact form and subsequently fail to satisfy the required properties. For instance, in general stabilization using a control Lyapunov function, computational uncertainty may distort stability certificates or even destabilize the system despite robustness of the stabilization routine with regards to system, actuator and measurement noise. In fact, battling numerical problems in practical implementation of controllers is common among control engineers. Such observations indicate that computational uncertainty should indeed be addressed explicitly in controller synthesis and system analysis. The major contribution here is a fairly general framework for proof techniques in analysis and synthesis of control systems based on constructive analysis which explicitly states that every computation be doable only up to a finite precision thus accounting for computational uncertainty. A series of previous works is overviewed, including constructive system stability and stabilization, approximate optimal controls, eigenvalue problems, Caratheodory trajectories, measurable selectors. Additionally, a new constructive version of the Danskin's theorem, which is crucial in adversarial defense, is presented. 

**Abstract (ZH)**: 本文提出了一种基于建设性分析的控制理论框架，以解决数学结果与计算机实现之间的差异问题，这种差异通常被称为计算不确定性。在控制工程中，这种差异通常被忽略，或者被归类为其他类型不确定性的一部分，例如系统噪声，并在稳健控制中进行处理。然而，即使在稳健控制方法中，如果参与相应算法的数学对象无法精确存在，并且未能满足所需的属性时，这些方法也可能受到损害。例如，在使用控制李雅普诺夫函数的一般镇定过程中，计算不确定性可能会扭曲稳定性证明，甚至使系统不稳定，尽管镇定过程对系统、执行器和测量噪声具有稳健性。实际上，在控制器的实际实现中对抗数值问题是非常普遍的。这些观察表明，计算不确定性确实应在控制器设计和系统分析中明确解决。本文的主要贡献是一个基于建设性分析的相当通用的分析和综合控制系统的证明技术框架，明确指出每一项计算只能精确到有限的精度，从而考虑计算不确定性。此外，还综述了若干先前的研究工作，包括建设性系统稳定性与镇定、近似最优控制、特征值问题、卡拉西奥多里轨迹和可测选择器。还提出了一个在对抗防御中至关重要的丹斯金定理的新建设性版本。 

---
# LLMzSz{\L}: a comprehensive LLM benchmark for Polish 

**Title (ZH)**: 将给定的标题翻译成中文，同时确保符合学术规范，可以翻译为：

"LLMzSz\(\L\)：一种全面的波兰语大型语言模型基准"

解释：
- "LLM" 通常指 "Large Language Model"。
- " Polish" 在中文中直接翻译为 "波兰语"。
- "benchmark" 用中文表述为 "基准" 更符合学术论文的翻译规范。
- LLMzSz\(\L\) 可能是作者定义的一种特定标识或缩写，保持不变。

这样的翻译既保留了原文的含义，又符合学术论文的表达习惯。 

**Authors**: Krzysztof Jassem, Michał Ciesiółka, Filip Graliński, Piotr Jabłoński, Jakub Pokrywka, Marek Kubis, Monika Jabłońska, Ryszard Staruch  

**Link**: [PDF](https://arxiv.org/pdf/2501.02266)  

**Abstract**: This article introduces the first comprehensive benchmark for the Polish language at this scale: LLMzSzŁ (LLMs Behind the School Desk). It is based on a coherent collection of Polish national exams, including both academic and professional tests extracted from the archives of the Polish Central Examination Board. It covers 4 types of exams, coming from 154 domains. Altogether, it consists of almost 19k closed-ended questions. We investigate the performance of open-source multilingual, English, and Polish LLMs to verify LLMs' abilities to transfer knowledge between languages. Also, the correlation between LLMs and humans at model accuracy and exam pass rate levels is examined. We show that multilingual LLMs can obtain superior results over monolingual ones; however, monolingual models may be beneficial when model size matters. Our analysis highlights the potential of LLMs in assisting with exam validation, particularly in identifying anomalies or errors in examination tasks. 

**Abstract (ZH)**: 本文介绍了首个针对波兰语的大规模全面基准测试：LLMzSzŁ（LLMs Behind the School Desk）。该基准测试基于波兰中央考试委员会档案中收集的一系列连贯的全国性考试，包括学术和职业测试。它涵盖了4种类型的考试，来源于154个领域。总共包含近19,000个闭合问题。我们通过对开源多语言模型、英语模型和波兰语模型进行研究，验证了语言模型在不同语言间转移知识的能力。此外，我们还探讨了模型准确性和考试通过率上语言模型与人类的相关性。研究表明，多语言模型在某些方面可以优于单语言模型，但在模型规模成为关键因素时，单语言模型可能更具有优势。我们的分析强调了语言模型在考试验证方面的潜力，特别是在识别考试任务中的异常或错误方面。 

---
# Interpretable Load Forecasting via Representation Learning of Geo-distributed Meteorological Factors 

**Title (ZH)**: 基于地理分布气象因素表示学习的可解释性负荷预测 

**Authors**: Yangze Zhou, Guoxin Lin, Gonghao Zhang, Yi Wang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02241)  

**Abstract**: Meteorological factors (MF) are crucial in day-ahead load forecasting as they significantly influence the electricity consumption behaviors of consumers. Numerous studies have incorporated MF into the load forecasting model to achieve higher accuracy. Selecting MF from one representative location or the averaged MF as the inputs of the forecasting model is a common practice. However, the difference in MF collected in various locations within a region may be significant, which poses a challenge in selecting the appropriate MF from numerous locations. A representation learning framework is proposed to extract geo-distributed MF while considering their spatial relationships. In addition, this paper employs the Shapley value in the graph-based model to reveal connections between MF collected in different locations and loads. To reduce the computational complexity of calculating the Shapley value, an acceleration method is adopted based on Monte Carlo sampling and weighted linear regression. Experiments on two real-world datasets demonstrate that the proposed method improves the day-ahead forecasting accuracy, especially in extreme scenarios such as the "accumulation temperature effect" in summer and "sudden temperature change" in winter. We also find a significant correlation between the importance of MF in different locations and the corresponding area's GDP and mainstay industry. 

**Abstract (ZH)**: 气象因素（MF）在一天前的负荷预测中至关重要，因为它们显著影响消费者的用电行为。众多研究将MF纳入负荷预测模型，以实现更高的预测精度。通常的做法是从一个代表地点或使用多个地点的平均MF作为预测模型的输入。然而，同一区域内不同地点收集的MF之间可能存在显著差异，这为选择合适的MF带来了挑战。本文提出了一种表示学习框架，以考虑MF的空间关系来提取地理分布的MF。此外，本文采用图模型中的Shapley值来揭示不同地点收集的MF与负荷之间的连接。为了降低计算Shapley值的复杂性，本文采用了基于蒙特卡洛采样和加权线性回归的加速方法。在两个实际数据集上的实验表明，所提出的方法提高了一天前的预测精度，尤其是在夏季的“累积温度效应”和冬季的“突变温度变化”等极端情况下效果尤为显著。我们还发现，不同地点MF的重要性与其相应区域的GDP和主导产业之间存在显著的相关性。 

---
# Financial Named Entity Recognition: How Far Can LLM Go? 

**Title (ZH)**: 金融命名实体识别：大语言模型能走多远？ 

**Authors**: Yi-Te Lu, Yintong Huo  

**Link**: [PDF](https://arxiv.org/pdf/2501.02237)  

**Abstract**: The surge of large language models (LLMs) has revolutionized the extraction and analysis of crucial information from a growing volume of financial statements, announcements, and business news. Recognition for named entities to construct structured data poses a significant challenge in analyzing financial documents and is a foundational task for intelligent financial analytics. However, how effective are these generic LLMs and their performance under various prompts are yet need a better understanding. To fill in the blank, we present a systematic evaluation of state-of-the-art LLMs and prompting methods in the financial Named Entity Recognition (NER) problem. Specifically, our experimental results highlight their strengths and limitations, identify five representative failure types, and provide insights into their potential and challenges for domain-specific tasks. 

**Abstract (ZH)**: 大规模语言模型（LLMs）的兴起已经改变了从不断增加的财务报表、公告和商业新闻中提取和分析关键信息的方式。命名实体识别以构建结构化数据在分析财务文档方面面临重大挑战，并且是智能财务分析的基础任务。然而，这些通用LLMs的有效性及其在各种提示下的性能仍然需要进一步了解。为了填补这一空白，我们系统地评估了最先进的LLMs及其提示方法在财务命名实体识别（NER）问题上的表现。具体而言，我们的实验结果突显了它们的优势和局限性，识别了五种代表性失败类型，并为特定领域任务的潜力和挑战提供了见解。 

---
# Diffusion Model-Based Data Synthesis Aided Federated Semi-Supervised Learning 

**Title (ZH)**: 基于扩散模型的数据合成辅助联邦半监督学习 

**Authors**: Zhongwei Wang, Tong Wu, Zhiyong Chen, Liang Qian, Yin Xu, Meixia Tao  

**Link**: [PDF](https://arxiv.org/pdf/2501.02219)  

**Abstract**: Federated semi-supervised learning (FSSL) is primarily challenged by two factors: the scarcity of labeled data across clients and the non-independent and identically distribution (non-IID) nature of data among clients. In this paper, we propose a novel approach, diffusion model-based data synthesis aided FSSL (DDSA-FSSL), which utilizes a diffusion model (DM) to generate synthetic data, bridging the gap between heterogeneous local data distributions and the global data distribution. In DDSA-FSSL, clients address the challenge of the scarcity of labeled data by employing a federated learning-trained classifier to perform pseudo labeling for unlabeled data. The DM is then collaboratively trained using both labeled and precision-optimized pseudo-labeled data, enabling clients to generate synthetic samples for classes that are absent in their labeled datasets. This process allows clients to generate more comprehensive synthetic datasets aligned with the global distribution. Extensive experiments conducted on multiple datasets and varying non-IID distributions demonstrate the effectiveness of DDSA-FSSL, e.g., it improves accuracy from 38.46% to 52.14% on CIFAR-10 datasets with 10% labeled data. 

**Abstract (ZH)**: 联邦半监督学习（FSSL）主要面临两个挑战：客户端标签数据的稀缺性和客户端间数据的非独立且不同分布（non-IID）性质。本文提出了一种新的方法——基于扩散模型的数据合成辅助联邦半监督学习（DDSA-FSSL），该方法利用扩散模型（DM）生成合成数据，从而弥合本地异构数据分布与全局数据分布之间的差距。在DDSA-FSSL中，客户端通过使用在联邦学习中训练的分类器对未标记数据进行伪标记，来应对标签数据稀缺的挑战。然后，通过协作训练，DM 使用标记数据和精度优化后的伪标记数据进行训练，使客户端能够生成其标记数据集中不存在的类别的合成样本。这个过程使客户端能够生成与全局分布更匹配的全面的合成数据集。通过在多个数据集和不同non-IID分布下进行的广泛实验表明，DDSA-FSSL的有效性，例如，在CIFAR-10数据集中，使用10%的标记数据时，其准确率从38.46％提高到52.14％。 

---
# Learning Evolution via Optimization Knowledge Adaptation 

**Title (ZH)**: 通过优化知识适应学习演化 

**Authors**: Chao Wang, Licheng Jiao, Jiaxuan Zhao, Lingling Li, Fang Liu, Shuyuan Yang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02200)  

**Abstract**: Evolutionary algorithms (EAs) maintain populations through evolutionary operators to discover diverse solutions for complex tasks while gathering valuable knowledge, such as historical population data and fitness evaluations. However, traditional EAs face challenges in dynamically adapting to expanding knowledge bases, hindering the efficient exploitation of accumulated information and limiting adaptability to new situations. To address these issues, we introduce an Optimization Knowledge Adaptation Evolutionary Model (OKAEM), which features dynamic parameter adjustment using accumulated knowledge to enhance its optimization capabilities. OKAEM employs attention mechanisms to model the interactions among individuals, fitness landscapes, and genetic components separately, thereby parameterizing the evolutionary operators of selection, crossover, and mutation. These powerful learnable operators enable OKAEM to benefit from pre-learned extensive prior knowledge and self-tune with real-time evolutionary insights. Experimental results demonstrate that OKAEM: 1) exploits prior knowledge for significant performance gains across various knowledge transfer settings; 2) achieves competitive performance through self-tuning alone, even without prior knowledge; 3) outperforms state-of-the-art black-box baselines in a vision-language model tuning case; 4) can improve its optimization capabilities with growing knowledge; 5) is capable of emulating principles of natural selection and genetic recombination. 

**Abstract (ZH)**: 进化算法（EAs）通过进化操作维护种群，以发现复杂任务的多样化解决方案，同时积累宝贵的知识，如历史种群数据和适应度评估。然而，传统的EAs在动态适应扩大的知识库方面面临挑战，这阻碍了对累积信息的有效利用，并限制了对新情况的适应性。为解决这些问题，我们提出了一种优化知识自适应进化模型（OKAEM），该模型利用积累的知识动态调整参数，以增强其优化能力。OKAEM采用注意力机制分别建模个体间的互动、适应度景观和遗传成分，从而参数化选择、交配和变异等进化操作。这些强大的可学习操作符使OKAEM能够从预先学习的广泛先验知识中受益，并依靠实时进化的洞察自主调节。实验结果表明，OKAEM：1）在各种知识迁移设置中通过利用先验知识实现显著的性能提升；2）仅通过自我调节即可达到具有竞争力的性能，即使没有先验知识；3）在视觉语言模型调优案例中优于最先进的黑盒基准模型；4）随着知识的增长可以提升其优化能力；5）能够模拟自然选择和遗传重组的基本原理。 

---
# Can ChatGPT implement finite element models for geotechnical engineering applications? 

**Title (ZH)**: ChatGPT能否实现地质工程应用中的有限元模型？ 

**Authors**: Taegu Kim, Tae Sup Yun, Hyoung Suk Suh  

**Link**: [PDF](https://arxiv.org/pdf/2501.02199)  

**Abstract**: This study assesses the capability of ChatGPT to generate finite element code for geotechnical engineering applications from a set of prompts. We tested three different initial boundary value problems using a hydro-mechanically coupled formulation for unsaturated soils, including the dissipation of excess pore water pressure through fluid mass diffusion in one-dimensional space, time-dependent differential settlement of a strip footing, and gravity-driven seepage. For each case, initial prompting involved providing ChatGPT with necessary information for finite element implementation, such as balance and constitutive equations, problem geometry, initial and boundary conditions, material properties, and spatiotemporal discretization and solution strategies. Any errors and unexpected results were further addressed through prompt augmentation processes until the ChatGPT-generated finite element code passed the verification/validation test. Our results demonstrate that ChatGPT required minimal code revisions when using the FEniCS finite element library, owing to its high-level interfaces that enable efficient programming. In contrast, the MATLAB code generated by ChatGPT necessitated extensive prompt augmentations and/or direct human intervention, as it involves a significant amount of low-level programming required for finite element analysis, such as constructing shape functions or assembling global matrices. Given that prompt engineering for this task requires an understanding of the mathematical formulation and numerical techniques, this study suggests that while a large language model may not yet replace human programmers, it can greatly assist in the implementation of numerical models. 

**Abstract (ZH)**: 本研究评估了ChatGPT自一组提示生成适用于岩土工程应用的有限元代码的能力。我们测试了三个不同的初始边界值问题，采用了一种考虑饱和-非饱和土耦合效应的流固耦合公式，包括通过流体质量扩散方式在一维空间和时间中耗散多余的孔隙水压力、条形基础的时间依赖性差异沉降，以及重力驱动下的渗透。对于每个案例，初始提示涉及向ChatGPT提供有限元实现所需的必要信息，如平衡方程和本构方程、问题几何形状、初始和边界条件、材料属性以及空间时间和离散化和求解策略。任何错误和意外结果均通过提示增强过程进行进一步处理，直到ChatGPT生成的有限元代码通过验证/验证测试。我们的结果显示，当使用FEniCS有限元库时，ChatGPT需要进行极少的代码修订，这得益于其高级接口能够实现高效编程。相比之下，ChatGPT生成的MATLAB代码需要大量的提示增强或直接的人工干预，因为有限元分析需要大量的低级编程，例如构造形函数或组装全局矩阵。鉴于此任务的提示工程需要对数学公式和数值技术有深刻的理解，本研究表明，虽然大规模语言模型目前可能尚未能够取代人类程序员，但在数值模型的实现中，它能够极大地提供协助。 

---
# CPTuning: Contrastive Prompt Tuning for Generative Relation Extraction 

**Title (ZH)**: CPTuning：对比提示调整在生成性关系抽取中的应用 

**Authors**: Jiaxin Duan, Fengyu Lu, Junfei Liu  

**Link**: [PDF](https://arxiv.org/pdf/2501.02196)  

**Abstract**: Generative relation extraction (RE) commonly involves first reformulating RE as a linguistic modeling problem easily tackled with pre-trained language models (PLM) and then fine-tuning a PLM with supervised cross-entropy loss. Although having achieved promising performance, existing approaches assume only one deterministic relation between each pair of entities without considering real scenarios where multiple relations may be valid, i.e., entity pair overlap, causing their limited applications. To address this problem, we introduce a novel contrastive prompt tuning method for RE, CPTuning, which learns to associate a candidate relation between two in-context entities with a probability mass above or below a threshold, corresponding to whether the relation exists. Beyond learning schema, CPTuning also organizes RE as a verbalized relation generation task and uses Trie-constrained decoding to ensure a model generates valid relations. It adaptively picks out the generated candidate relations with a high estimated likelihood in inference, thereby achieving multi-relation extraction. We conduct extensive experiments on four widely used datasets to validate our method. Results show that T5-large fine-tuned with CPTuning significantly outperforms previous methods, regardless of single or multiple relations extraction. 

**Abstract (ZH)**: 生成式关系抽取（RE）通常首先将RE问题重新表述为一个语言模型问题，利用预训练语言模型（PLM）轻松解决，然后使用监督交叉熵损失对PLM进行微调。尽管现有方法已取得令人瞩目的性能，但它们假设每对实体之间只存在一种确定的关系，而未考虑实际场景中可能有多个关系同时成立的情况，即实体对重叠，导致这些方法的应用受限。为解决这一问题，我们引入了一种新颖的对比式提示微调方法（CPTuning）用于关系抽取，该方法学习根据给定上下文中的实体对关联一个候选关系，并赋予其一个高于或低于阈值的概率质量，以判断该关系是否存在。除了学习模式之外，CPTuning还将关系抽取组织为一种口头化关系生成任务，并使用Trie约束解码来确保模型生成有效的关系。在推理过程中，它会自适应地挑选生成的高概率候选关系，从而实现多关系抽取。我们在四个广泛使用的数据集上进行了大量实验以验证该方法。结果显示，使用CPTuning微调的T5-large在单关系和多关系抽取方面均显著优于先前的方法。 

---
# Benchmark Evaluations, Applications, and Challenges of Large Vision Language Models: A Survey 

**Title (ZH)**: 大规模视觉语言模型的基准评估、应用与挑战：一项综述 

**Authors**: Zongxia Li, Xiyang Wu, Hongyang Du, Huy Nghiem, Guangyao Shi  

**Link**: [PDF](https://arxiv.org/pdf/2501.02189)  

**Abstract**: Multimodal Vision Language Models (VLMs) have emerged as a transformative technology at the intersection of computer vision and natural language processing, enabling machines to perceive and reason about the world through both visual and textual modalities. For example, models such as CLIP, Claude, and GPT-4V demonstrate strong reasoning and understanding abilities on visual and textual data and beat classical single modality vision models on zero-shot classification. Despite their rapid advancements in research and growing popularity in applications, a comprehensive survey of existing studies on VLMs is notably lacking, particularly for researchers aiming to leverage VLMs in their specific domains. To this end, we provide a systematic overview of VLMs in the following aspects: model information of the major VLMs developed over the past five years (2019-2024); the main architectures and training methods of these VLMs; summary and categorization of the popular benchmarks and evaluation metrics of VLMs; the applications of VLMs including embodied agents, robotics, and video generation; the challenges and issues faced by current VLMs such as hallucination, fairness, and safety. Detailed collections including papers and model repository links are listed in this https URL. 

**Abstract (ZH)**: 多模态视觉语言模型（VLMs）作为计算机视觉和自然语言处理交汇领域的变革性技术，使机器能够通过视觉和文本两种模态感知和推理世界。例如，CLIP、Claude 和 GPT-4V 等模型在视觉和文本数据上的推理和理解能力非常强大，并在零样本分类上超过了传统的单模态视觉模型。尽管这些模型在研究中取得了飞速进展并在应用中越来越受欢迎，但专门针对视觉语言模型的研究综述依然缺乏，尤其对于希望在其特定领域利用 VLMs 的研究人员来说更为如此。为此，我们从以下几个方面系统地概述了 VLMs：过去五年（2019-2024）开发的主要 VLMs 的模型信息；这些 VLMs 的主要架构和训练方法；VLMs 的流行基准和评估指标的总结与分类；VLMs 的应用，包括具身代理、机器人技术和视频生成；当前 VLMs 面临的挑战和问题，如幻觉、公平性和安全性。详细的资料集合包括论文和模型存储库链接，列于以下 URL。 

---
# AdaMixup: A Dynamic Defense Framework for Membership Inference Attack Mitigation 

**Title (ZH)**: AdaMixup：一种动态防御框架，用于缓解成员推断攻击 

**Authors**: Ying Chen, Jiajing Chen, Yijie Weng, ChiaHua Chang, Dezhi Yu, Guanbiao Lin  

**Link**: [PDF](https://arxiv.org/pdf/2501.02182)  

**Abstract**: Membership inference attacks have emerged as a significant privacy concern in the training of deep learning models, where attackers can infer whether a data point was part of the training set based on the model's outputs. To address this challenge, we propose a novel defense mechanism, AdaMixup. AdaMixup employs adaptive mixup techniques to enhance the model's robustness against membership inference attacks by dynamically adjusting the mixup strategy during training. This method not only improves the model's privacy protection but also maintains high performance. Experimental results across multiple datasets demonstrate that AdaMixup significantly reduces the risk of membership inference attacks while achieving a favorable trade-off between defensive efficiency and model accuracy. This research provides an effective solution for data privacy protection and lays the groundwork for future advancements in mixup training methods. 

**Abstract (ZH)**: 会员推理攻击已成为深度学习模型训练中一个重要的隐私问题，攻击者可以通过模型的输出推测某个数据点是否属于训练集的一部分。为应对这一挑战，我们提出了一种新的防御机制——AdaMixup。AdaMixup 采用自适应 Mixup 技术来增强模型对会员推理攻击的稳健性，通过在训练过程中动态调整 Mixup 策略。这种方法不仅提升了模型的隐私保护能力，还保持了较高的性能。实验结果表明，AdaMixup 显著降低了会员推理攻击的风险，并且在防御效率与模型准确性之间实现了良好的权衡。本研究为数据隐私保护提供了有效的解决方案，并为进一步改进 Mixup 训练方法奠定了基础。 

---
# The Integration of Blockchain and Artificial Intelligence for Secure Healthcare Systems 

**Title (ZH)**: 区块链与人工智能在安全医疗系统中的集成 

**Authors**: Umar Safdar, Simon Gabrael  

**Link**: [PDF](https://arxiv.org/pdf/2501.02169)  

**Abstract**: Verisign reported a 125 percent increase in data breaches within the healthcare sector in the United States during 2022, with 18.2 million patient records being impacted. Growing healthcare data volumes and diversification mean that medical information is becoming more valuable. Many Health Centers use various technologies to ease the classification, storage, and exchange of big data. This use can also make the health data of the users at risk and vulnerable. AI and blockchain are among the leading technologies at hand. With AI, data-driven operations and big data efficiency have been improved with respect to traditional techniques. Due to its potential to bring about improvements in health services and lower medical costs, this AI technology is regularly used in healthcare. Blockchain helps protect transactions on sharing information and private privacy as long as the exchange of knowledge is that of the standard. The objective of this analysis is to investigate the research and unique contributions since 2008 regarding blockchain-integrated AI and healthcare systems. The work sheds light on applied AI-based healthcare schemes with machine, ballistic, and acrylic learning and disparate blockchain structures. The use of technology in order to ensure patient data security and manage medical information effectively in healthcare settings offers a highly successful position for both healthcare providers and patients. From 2018 to 2021, the best year was 2021 to grow, enhancing everything to examine the download of the device and the counting of Google Academies, for which the joining perspective was borrowed; local research experts were asked, identified articles in recent years, and read reviews of large research grants. 

**Abstract (ZH)**: VeriSign报告称，在2022年，美国医疗保健领域数据泄露事件增加了125%，受影响的患者记录达1820万份。随着医疗数据量的增加和多样化，医疗信息的价值也不断提高。许多医疗机构使用多种技术来简化、存储和交换大数据，但这也可能会使用户的健康数据面临风险。人工智能和区块链是其中领先的技术。借助人工智能，数据驱动的运营和大数据效率相对于传统技术得到了提高。由于其在改善医疗服务和降低医疗成本方面具有潜力，这项技术在医疗保健领域被频繁使用。区块链有助于保护在知识分享过程中的交易和隐私，只要信息交换符合标准。本文旨在研究自2008年以来有关区块链集成AI与医疗保健系统的研究成果和独特贡献。工作重点介绍了基于机器学习、深度学习、和不同的区块链结构的AI健康应用方案。通过技术确保患者数据安全并有效管理医疗服务中的医疗信息，在医院和患者方面均取得了显著的成功。2018年至2021年间，最出色的两年是2021年，这一年通过下载设备和Google学术论文计数来提升工作，借鉴了联合视角；同时，本地研究专家被询问，确定了近年来的文章，并对大型研究项目的评审进行了阅读。 

---
# The Race to Efficiency: A New Perspective on AI Scaling Laws 

**Title (ZH)**: 追求效率的竞赛：AI 规模定律的新视角 

**Authors**: Chien-Ping Lu  

**Link**: [PDF](https://arxiv.org/pdf/2501.02156)  

**Abstract**: As large-scale AI models expand, training becomes costlier and sustaining progress grows harder. Classical scaling laws (e.g., Kaplan et al. (2020), Hoffmann et al. (2022)) predict training loss from a static compute budget yet neglect time and efficiency, prompting the question: how can we balance ballooning GPU fleets with rapidly improving hardware and algorithms? We introduce the relative-loss equation, a time- and efficiency-aware framework that extends classical AI scaling laws. Our model shows that, without ongoing efficiency gains, advanced performance could demand millennia of training or unrealistically large GPU fleets. However, near-exponential progress remains achievable if the "efficiency-doubling rate" parallels Moore's Law. By formalizing this race to efficiency, we offer a quantitative roadmap for balancing front-loaded GPU investments with incremental improvements across the AI stack. Empirical trends suggest that sustained efficiency gains can push AI scaling well into the coming decade, providing a new perspective on the diminishing returns inherent in classical scaling. 

**Abstract (ZH)**: 随着大型AI模型的扩展，训练成本变得越来越高，保持进展也变得越来越困难。经典的扩展定律（如Kaplan等人（2020），Hoffmann等人（2022））预测固定计算预算下的训练损失，但忽略了时间和效率，这引发了一个问题：我们如何在硬件和算法快速进步的情况下平衡不断膨胀的GPU舰队？我们引入了相对损失方程，这是一种兼顾时间和效率的框架，扩展了经典的AI扩展定律。我们的模型表明，如果没有持续的效率提升，先进的性能可能需要成千上万年的训练或难以实现的庞大GPU舰队。然而，如果“效率翻倍率”与摩尔定律平行，近指数级的进展仍然是可以实现的。通过正式化这一效率竞赛，我们提供了一种定量的方式来平衡前端GPU投资与AI栈中逐步改进之间的关系。经验趋势表明，持续的效率提升可以将AI扩展延续到未来的十年，这为经典扩展中的边际效益递减提供了一种新的视角。 

---
# Attribute-Based Robotic Grasping with Data-Efficient Adaptation 

**Title (ZH)**: 基于属性的机器人抓取：数据高效适应 

**Authors**: Yang Yang, Houjian Yu, Xibai Lou, Yuanhao Liu, Changhyun Choi  

**Link**: [PDF](https://arxiv.org/pdf/2501.02149)  

**Abstract**: Robotic grasping is one of the most fundamental robotic manipulation tasks and has been the subject of extensive research. However, swiftly teaching a robot to grasp a novel target object in clutter remains challenging. This paper attempts to address the challenge by leveraging object attributes that facilitate recognition, grasping, and rapid adaptation to new domains. In this work, we present an end-to-end encoder-decoder network to learn attribute-based robotic grasping with data-efficient adaptation capability. We first pre-train the end-to-end model with a variety of basic objects to learn generic attribute representation for recognition and grasping. Our approach fuses the embeddings of a workspace image and a query text using a gated-attention mechanism and learns to predict instance grasping affordances. To train the joint embedding space of visual and textual attributes, the robot utilizes object persistence before and after grasping. Our model is self-supervised in a simulation that only uses basic objects of various colors and shapes but generalizes to novel objects in new environments. To further facilitate generalization, we propose two adaptation methods, adversarial adaption and one-grasp adaptation. Adversarial adaptation regulates the image encoder using augmented data of unlabeled images, whereas one-grasp adaptation updates the overall end-to-end model using augmented data from one grasp trial. Both adaptation methods are data-efficient and considerably improve instance grasping performance. Experimental results in both simulation and the real world demonstrate that our approach achieves over 81% instance grasping success rate on unknown objects, which outperforms several baselines by large margins. 

**Abstract (ZH)**: 机器人抓取是机器人操作中最基本的任务之一，并且一直是研究的热点。然而，迅速教会机器人在杂乱环境中抓取新的目标对象仍然具有挑战性。本文旨在通过利用有助于识别、抓取和快速适应新领域的事物属性来应对这一挑战。在本文中，我们提出了一种端到端的编码器-解码器网络，以学习基于属性的机器人抓取，并具备数据高效的适应能力。首先，我们使用各种基本对象对端到端模型进行预训练，以学习通用属性表示用于识别和抓取。我们的方法使用门控注意机制融合工作空间图像的嵌入和查询文本的嵌入，并学习预测实例抓取容征。为了联合学习视觉和文本属性的嵌入空间，机器人在抓取前后利用物体的持续性。我们的模型仅使用各种颜色和形状的基本对象在仿真环境中进行自我监督学习，但能够泛化到新的环境中新型对象的抓取。为了进一步促进泛化，我们提出了两种适应方法：对抗适应和单次抓取适应。对抗适应通过未标注图像的数据增强调节图像编码器，而单次抓取适应使用一次抓取试验的数据增强更新整个端到端模型。这两种适应方法都是数据高效的，并且显著提高了实例抓取性能。在仿真和现实环境中的实验结果表明，我们的方法在未知对象上的实例抓取成功率超过81%，远远优于多个基线方法。 

---
# Plasma-CycleGAN: Plasma Biomarker-Guided MRI to PET Cross-modality Translation Using Conditional CycleGAN 

**Title (ZH)**: Plasma-CycleGAN：基于血浆生物标志物的MRI到PET跨模态转换的条件循环GAN 

**Authors**: Yanxi Chen, Yi Su, Celine Dumitrascu, Kewei Chen, David Weidman, Richard J Caselli, Nicholas Ashton, Eric M Reiman, Yalin Wang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02146)  

**Abstract**: Cross-modality translation between MRI and PET imaging is challenging due to the distinct mechanisms underlying these modalities. Blood-based biomarkers (BBBMs) are revolutionizing Alzheimer's disease (AD) detection by identifying patients and quantifying brain amyloid levels. However, the potential of BBBMs to enhance PET image synthesis remains unexplored. In this paper, we performed a thorough study on the effect of incorporating BBBM into deep generative models. By evaluating three widely used cross-modality translation models, we found that BBBMs integration consistently enhances the generative quality across all models. By visual inspection of the generated results, we observed that PET images generated by CycleGAN exhibit the best visual fidelity. Based on these findings, we propose Plasma-CycleGAN, a novel generative model based on CycleGAN, to synthesize PET images from MRI using BBBMs as conditions. This is the first approach to integrate BBBMs in conditional cross-modality translation between MRI and PET. 

**Abstract (ZH)**: 由于MRI和PET成像背后的机制不同，跨模态翻译在MRI和PET之间具有挑战性。血液生物标志物（BBBMs）正通过识别患者并量化脑内淀粉样蛋白水平，从根本上革新阿尔茨海默病（AD）的检测。然而，BBBMs在增强PET图像合成方面的潜力尚未得到探索。在本文中，我们对将BBBM纳入深度生成模型的影响进行了全面研究。通过评估三种广泛使用的跨模态翻译模型，我们发现BBBM的整合在所有模型中都一致地提升了生成质量。通过视觉检查生成的结果，我们发现使用CycleGAN生成的PET图像具有最佳的视觉保真度。基于这些发现，我们提出了一种基于CycleGAN的新生成模型——Plasma-CycleGAN，用于使用BBBM作为条件从MRI合成PET图像。这是首次在MRI和PET之间的条件跨模态翻译中整合BBBM的方法。 

---
# Establishing baselines for generative discovery of inorganic crystals 

**Title (ZH)**: 建立无机晶体生成发现的基础基准 

**Authors**: Nathan J. Szymanski, Christopher J. Bartel  

**Link**: [PDF](https://arxiv.org/pdf/2501.02144)  

**Abstract**: Generative artificial intelligence offers a promising avenue for materials discovery, yet its advantages over traditional methods remain unclear. In this work, we introduce and benchmark two baseline approaches - random enumeration of charge-balanced prototypes and data-driven ion exchange of known compounds - against three generative models: a variational autoencoder, a large language model, and a diffusion model. Our results show that established methods such as ion exchange perform comparably well in generating stable materials, although many of these materials tend to closely resemble known compounds. In contrast, generative models excel at proposing novel structural frameworks and, when sufficient training data is available, can more effectively target properties such as electronic band gap and bulk modulus while maintaining a high stability rate. To enhance the performance of both the baseline and generative approaches, we implement a post-generation screening step in which all proposed structures are passed through stability and property filters from pre-trained machine learning models including universal interatomic potentials. This low-cost filtering step leads to substantial improvement in the success rates of all methods, remains computationally efficient, and ultimately provides a practical pathway toward more effective generative strategies for materials discovery. 

**Abstract (ZH)**: 生成式人工智能为材料发现提供了有希望的途径，但与传统方法相比其优势尚不明确。在本文中，我们引入并评估了两种基线方法——电荷平衡原型的随机枚举和基于数据驱动的已知化合物离子交换——与三种生成模型进行对比：变分自编码器、大规模语言模型以及扩散模型。研究结果显示，已建立的离子交换方法在生成稳定材料方面表现出色，尽管这些材料往往会与已知化合物高度相似。相比之下，生成模型在提议新颖的结构框架方面表现出色，且在有足够的训练数据时，能够更有效地针对电子带隙和体积模量等性质进行调控，同时保持较高的稳定性。为了提升基线方法和生成模型的性能，我们在生成后增加了一步筛选环节，即所有提议的结构都通过预训练的机器学习模型（包括通用原子间势）的稳定性和性质筛选。这个低成本的筛选步骤显著提高了所有方法的成功率，同时保持了计算效率，并最终提供了一条实现更有效材料发现生成策略的可行路径。 

---
# Effective LLM-Driven Code Generation with Pythoness 

**Title (ZH)**: 有效的基于大语言模型的代码生成方法——以Pythoness为例 

**Authors**: Kyla H. Levin, Kyle Gwilt, Emery D. Berger, Stephen N. Freund  

**Link**: [PDF](https://arxiv.org/pdf/2501.02138)  

**Abstract**: The advent of large language models (LLMs) has paved the way for a new era of programming tools with both significant capabilities and risks, as the generated code lacks guarantees of correctness and reliability. Developers using LLMs currently face the difficult task of optimizing, integrating, and maintaining code generated by AI. We propose an embedded domain-specific language (DSL), Pythoness, to address those challenges. In Pythoness, developers program with LLMs at a higher level of abstraction. Rather than interacting directly with generated code, developers using Pythoness operate at the level of behavioral specifications when writing functions, classes, or an entire program. These specifications can take the form of unit tests and property-based tests, which may be expressed formally or in natural language. Guided by these specifications, Pythoness generates code that both passes the tests and can be continuously checked during execution. We posit that the Pythoness approach lets developers harness the full potential of LLMs for code generation while substantially mitigating their inherent risks. We describe our current prototype implementation of Pythoness and demonstrate that it can successfully leverage a combination of tests and code generation to yield higher quality code than specifications alone. 

**Abstract (ZH)**: 大型语言模型（LLMs）的出现为编程工具开启了一个新时代，这一时代兼具重大能力和潜在风险，因为生成的代码缺乏正确性和可靠性的保证。目前使用LLMs的开发者面临着优化、整合和维护由AI生成代码的艰巨任务。我们提出了一种嵌入式领域特定语言（DSL），即Pythoness，以应对这些挑战。在Pythoness中，开发者以更高的抽象级别与LLMs进行编程。使用Pythoness时，开发者在编写函数、类或整个程序时操作的是行为规范，而不是直接与生成的代码互动。这些规范可以是单元测试和基于属性的测试的形式，既可以正式表达，也可以用自然语言表达。受到这些规范的指导，Pythoness生成的代码不仅能够通过测试，还可以在执行过程中持续检查。我们认为，Pythoness的方法使开发者能够充分利用LLMs的全部潜力进行代码生成，并显著减轻其固有的风险。我们描述了Pythoness当前的原型实现，并展示了它如何通过结合测试和代码生成来产生比仅仅使用规范更高的质量代码。 

---
# AVTrustBench: Assessing and Enhancing Reliability and Robustness in Audio-Visual LLMs 

**Title (ZH)**: AVTrustBench: 评估和提升音频-视觉大语言模型的可靠性和鲁棒性 

**Authors**: Sanjoy Chowdhury, Sayan Nag, Subhrajyoti Dasgupta, Yaoting Wang, Mohamed Elhoseiny, Ruohan Gao, Dinesh Manocha  

**Link**: [PDF](https://arxiv.org/pdf/2501.02135)  

**Abstract**: With the rapid advancement of Multi-modal Large Language Models (MLLMs), several diagnostic benchmarks have recently been developed to assess these models' multi-modal reasoning proficiency. However, these benchmarks are restricted to assessing primarily the visual aspect and do not examine the holistic audio-visual (AV) understanding. Moreover, currently, there are no benchmarks that investigate the capabilities of AVLLMs to calibrate their responses when presented with perturbed inputs. To this end, we introduce Audio-Visual Trustworthiness assessment Benchmark (AVTrustBench), comprising 600K samples spanning over 9 meticulously crafted tasks, evaluating the capabilities of AVLLMs across three distinct dimensions: Adversarial attack, Compositional reasoning, and Modality-specific dependency. Using our benchmark we extensively evaluate 13 state-of-the-art AVLLMs. The findings reveal that the majority of existing models fall significantly short of achieving human-like comprehension, offering valuable insights for future research directions. To alleviate the limitations in the existing approaches, we further propose a robust, model-agnostic calibrated audio-visual preference optimization based training strategy CAVPref, obtaining a gain up to 30.19% across all 9 tasks. We will publicly release our code and benchmark to facilitate future research in this direction. 

**Abstract (ZH)**: 随着多模态大型语言模型（MLLMs）的迅速发展，近年来已开发出若干诊断基准，以评估这些模型的多模态推理能力。然而，这些基准主要侧重于评估视觉方面的表现，而不考查整体的视听（AV）理解能力。此外，目前尚无基准来调查AVLLMs在面对扰动输入时调整其响应的能力。为解决这一问题，我们提出了一个名为AVTrustBench的视听可信度评估基准，该基准包括60万个样本，涵盖9个精心设计的任务，从三个不同的维度评估AVLLMs的能力：对抗性攻击、组成性推理和模态特定依赖。利用我们提出的基准，我们广泛评估了13个最新的AVLLMs。研究结果表明，现有的大多数模型在实现人类级别的理解方面存在显著差距，为未来的研究方向提供了宝贵见解。为缓解现有方法的局限性，我们进一步提出了一种鲁棒的、模型无关的音频-视觉偏好优化训练策略（CAVPref），在所有9个任务中，这一策略获得了高达30.19%的性能提升。我们将公开发布我们的代码和基准，以促进该领域的未来研究。 

---
# A hybrid marketplace of ideas 

**Title (ZH)**: 一种理念混合市场 

**Authors**: Tomer Jordi Chaffer, Dontrail Cotlage, Justin Goldston  

**Link**: [PDF](https://arxiv.org/pdf/2501.02132)  

**Abstract**: The convergence of humans and artificial intelligence systems introduces new dynamics into the cultural and intellectual landscape. Complementing emerging cultural evolution concepts such as machine culture, AI agents represent a significant technosociological development, particularly within the anthropological study of Web3 as a community focused on decentralization through blockchain. Despite their growing presence, the cultural significance of AI agents remains largely unexplored in academic literature. We argue that, within the context of Web3, these agents challenge traditional notions of participation and influence in public discourse, creating a hybrid marketplace of ideas, a conceptual space where human and AI generated ideas coexist and compete for attention. We examine the current state of AI agents in idea generation, propagation, and engagement, positioning their role as cultural agents through the lens of memetics and encouraging further inquiry into their cultural and societal impact. Additionally, we address the implications of this paradigm for privacy, intellectual property, and governance, highlighting the societal and legal challenges of integrating AI agents into the hybrid marketplace of ideas. 

**Abstract (ZH)**: 人类与人工智能系统的融合为文化与智力景观引入了新的动态。补充新兴的文化进化概念，如机器文化，人工智能代理代表了在区块链驱动去中心化方面着重于社区发展的重要技术社会变革，尤其是在人类学研究中的Web3领域。尽管它们的影响力在不断增加，但人工智能代理的文化意义在学术文献中仍鲜有探讨。我们认为，在Web3的背景下，这些代理挑战了传统参与和影响公共话语的方式，创造了一个由人类和人工智能生成的观念共同存在和竞争吸引力的混合市场。我们考察了当前人工智能代理在观念生成、传播和互动中的状态，通过记忆论的视角将其定位为文化代理，并鼓励进一步探讨其文化和社会影响。此外，我们还分析了这一范式对隐私、知识产权和治理的潜在影响，强调了将人工智能代理整合到混合市场中的社会和法律挑战。 

---
# Relaxation-assisted reverse annealing on nonnegative/binary matrix factorization 

**Title (ZH)**: 非负/二元矩阵分解中的松弛辅助逆退火优化 

**Authors**: Renichiro Haba, Masayuki Ohzeki, Kazuyuki Tanaka  

**Link**: [PDF](https://arxiv.org/pdf/2501.02114)  

**Abstract**: Quantum annealing has garnered significant attention as meta-heuristics inspired by quantum physics for combinatorial optimization problems. Among its many applications, nonnegative/binary matrix factorization stands out for its complexity and relevance in unsupervised machine learning. The use of reverse annealing, a derivative procedure of quantum annealing to prioritize the search in a vicinity under a given initial state, helps improve its optimization performance in matrix factorization. This study proposes an improved strategy that integrates reverse annealing with a linear programming relaxation technique. Using relaxed solutions as the initial configuration for reverse annealing, we demonstrate improvements in optimization performance comparable to the exact optimization methods. Our experiments on facial image datasets show that our method provides better convergence than known reverse annealing methods. Furthermore, we investigate the effectiveness of relaxation-based initialization methods on randomized datasets, demonstrating a relationship between the relaxed solution and the optimal solution. This research underscores the potential of combining reverse annealing and classical optimization strategies to enhance optimization performance. 

**Abstract (ZH)**: 量子退火作为一种受量子物理启发的元启发式方法，已引起广泛关注，用于组合优化问题。在众多应用中，非负/二值矩阵分解因其在无监督机器学习中的复杂性和相关性而尤为突出。逆退火是一种基于给定初始状态在邻域内优先搜索的退火衍生过程，有助于提高其在矩阵分解中的优化性能。本研究提出了一种改进策略，将逆退火与线性规划松弛技术结合起来。使用松弛解作为逆退火的初始配置，我们展示了优化性能的改进与精确优化方法相当。在面部图像数据集上的实验表明，我们的方法在收敛性方面优于已知的逆退火方法。此外，我们还研究了基于松弛初始化的方法在随机数据集上的效果，展示了松弛解与最优解之间的关系。这项研究强调了结合逆退火与经典的优化策略以增强优化性能的潜力。 

---
# Siamese Networks for Cat Re-Identification: Exploring Neural Models for Cat Instance Recognition 

**Title (ZH)**: 基于二元网络的猫再识别：探索猫实例识别的神经网络模型 

**Authors**: Tobias Trein, Luan Fonseca Garcia  

**Link**: [PDF](https://arxiv.org/pdf/2501.02112)  

**Abstract**: Street cats in urban areas often rely on human intervention for survival, leading to challenges in population control and welfare management. In April 2023, Hello Inc., a Chinese urban mobility company, launched the Hello Street Cat initiative to address these issues. The project deployed over 21,000 smart feeding stations across 14 cities in China, integrating livestreaming cameras and treat dispensers activated through user donations. It also promotes the Trap-Neuter-Return (TNR) method, supported by a community-driven platform, HelloStreetCatWiki, where volunteers catalog and identify cats. However, manual identification is inefficient and unsustainable, creating a need for automated solutions. This study explores Deep Learning-based models for re-identifying street cats in the Hello Street Cat initiative. A dataset of 2,796 images of 69 cats was used to train Siamese Networks with EfficientNetB0, MobileNet and VGG16 as base models, evaluated under contrastive and triplet loss functions. VGG16 paired with contrastive loss emerged as the most effective configuration, achieving up to 97% accuracy and an F1 score of 0.9344 during testing. The approach leverages image augmentation and dataset refinement to overcome challenges posed by limited data and diverse visual variations. These findings underscore the potential of automated cat re-identification to streamline population monitoring and welfare efforts. By reducing reliance on manual processes, the method offers a scalable and reliable solution for communitydriven initiatives. Future research will focus on expanding datasets and developing real-time implementations to enhance practicality in large-scale deployments. 

**Abstract (ZH)**: 城市区域中的Street猫通常依赖人类干预来生存，这给猫种群控制和福利管理带来了挑战。2023年4月，中国城市出行公司Hello Inc.推出了Hello Street Cat项目，以应对这些问题。该项目在中国14个城市部署了超过21,000个智能喂食站，这些喂食站集成了直播摄像头和通过用户捐款激活的奖励发放器。项目还推广了Trap-Neuter-Return（TNR）方法，并依托一个由社区驱动的平台——HelloStreetCatWiki，志愿者们可以在此平台上对猫进行分类和识别。然而，手动识别效率低下且不可持续，因此需要自动化的解决方案。本研究探讨了基于深度学习的模型在Hello Street Cat项目中对街道猫进行再识别的可能性。我们使用了一张包含69只猫、共计2,796张图像的数据集，训练了Siamese网络，基础模型包括EfficientNetB0、MobileNet和VGG16，并使用对比损失函数和三元组损失函数进行评估。结果显示，结合对比损失函数的VGG16模型在测试中达到了最高的准确性，最高可达97%，F1分数为0.9344。该方法通过图像增强和数据集 refinement，有效克服了数据有限和视觉多样性带来的挑战。这些研究结果强调了自动化的猫再识别技术在简化种群监测和福利努力方面的潜力。通过减少对手动过程的依赖，该方法为社区驱动的项目提供了一个可扩展且可靠的解决方案。未来的研究将侧重于扩大数据集和开发实时实施方法，以增强在大规模部署中的实际应用能力。 

---
# Online Detection of Water Contamination Under Concept Drift 

**Title (ZH)**: 在线检测概念漂移下的水质污染 

**Authors**: Jin Li, Kleanthis Malialis, Stelios G. Vrachimis, Marios M. Polycarpou  

**Link**: [PDF](https://arxiv.org/pdf/2501.02107)  

**Abstract**: Water Distribution Networks (WDNs) are vital infrastructures, and contamination poses serious public health risks. Harmful substances can interact with disinfectants like chlorine, making chlorine monitoring essential for detecting contaminants. However, chlorine sensors often become unreliable and require frequent calibration. This study introduces the Dual-Threshold Anomaly and Drift Detection (AD&DD) method, an unsupervised approach combining a dual-threshold drift detection mechanism with an LSTM-based Variational Autoencoder(LSTM-VAE) for real-time contamination detection. Tested on two realistic WDNs, AD&DD effectively identifies anomalies with sensor offsets as concept drift, and outperforms other methods. A proposed decentralized architecture enables accurate contamination detection and localization by deploying AD&DD on selected nodes. 

**Abstract (ZH)**: 城镇供水网络（WDNs）是重要的基础设施，而污染物的存在则对公众健康构成严重风险。有害物质可以与氯等消毒剂发生相互作用，因此氯浓度监测对于检测污染物至关重要。然而，氯传感器常常会变得不可靠，并需要频繁校准。本研究引入了一种双阈值异常和漂移检测（AD&DD）方法，该方法结合了双阈值漂移检测机制和基于LSTM的变分自编码器（LSTM-VAE），以实现实时污染检测。在两个现实的WDNs上测试表明，AD&DD方法能够有效识别传感器偏移作为概念漂移的异常，并且其性能优于其他方法。提出的一种分布式架构通过在选定节点部署AD&DD，实现了对污染的准确检测和定位。 

---
# On the Statistical Complexity for Offline and Low-Adaptive Reinforcement Learning with Structures 

**Title (ZH)**: Offline 和低适应性结构强化学习中的统计复杂性研究 

**Authors**: Ming Yin, Mengdi Wang, Yu-Xiang Wang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02089)  

**Abstract**: This article reviews the recent advances on the statistical foundation of reinforcement learning (RL) in the offline and low-adaptive settings. We will start by arguing why offline RL is the appropriate model for almost any real-life ML problems, even if they have nothing to do with the recent AI breakthroughs that use RL. Then we will zoom into two fundamental problems of offline RL: offline policy evaluation (OPE) and offline policy learning (OPL). It may be surprising to people that tight bounds for these problems were not known even for tabular and linear cases until recently. We delineate the differences between worst-case minimax bounds and instance-dependent bounds. We also cover key algorithmic ideas and proof techniques behind near-optimal instance-dependent methods in OPE and OPL. Finally, we discuss the limitations of offline RL and review a burgeoning problem of \emph{low-adaptive exploration} which addresses these limitations by providing a sweet middle ground between offline and online RL. 

**Abstract (ZH)**: 本文回顾了在离线和低自适应设置下强化学习（RL）的统计基础的最新进展。我们将首先论证为什么离线RL是几乎所有实际ML问题的合适模型，即使这些问题与最近使用RL的AI突破无关。然后我们将深入探讨离线RL中的两个基本问题：离线策略评估（OPE）和离线策略学习（OPL）。人们可能会惊讶地发现，在最近之前，即使在表格和线性情况下，这些问题的紧致界也未知。我们将区分最坏情形的最小最优化界与实例相关界之间的差异。同时，我们将涵盖OPE和OPL中近最优实例相关方法背后的算法思想和证明技术。最后，我们将讨论离线RL的局限性，并回顾一个新兴问题，即低自适应探索，该问题通过提供离线RL与在线RL之间的折中方案来解决这些局限性。 

---
# The interplay between domain specialization and model size: a case study in the legal domain 

**Title (ZH)**: 领域专业化与模型规模之间的相互作用：法律领域的案例研究 

**Authors**: Roseval Malaquias Junior, Ramon Pires, Thales Sales Almeida, Kenzo Sakiyama, Roseli Romero, Rodrigo Nogueira  

**Link**: [PDF](https://arxiv.org/pdf/2501.02068)  

**Abstract**: Scaling laws for language models so far focused on finding the compute-optimal model size and token count for training from scratch. However, achieving this optimal balance requires significant compute resources due to the extensive data demands when training models from randomly-initialized weights. Continual pre-training offers a cost-effective alternative, leveraging the compute investment from pre-trained models to incorporate new knowledge without requiring extensive new data. Recent findings suggest that data quality influences constants in scaling laws, thereby altering the optimal parameter-token allocation ratio. Building on this insight, we investigate the interplay between domain specialization and model size during continual pre-training under compute-constrained scenarios. Our goal is to identify a compute-efficient training regime for this scenario and, potentially, detect patterns in this interplay that can be generalized across different model sizes and domains. To compare general and specialized training, we filtered a web-based dataset to extract legal domain data. We pre-trained models with 1.5B, 3B, 7B and 14B parameters on both the unfiltered and filtered datasets, then evaluated their performance on legal exams. Results show that as model size increases, the compute-effectiveness gap between specialized and general models widens. 

**Abstract (ZH)**: 到目前为止，关于语言模型的研究主要集中在寻找从头训练时在计算资源上最优的模型大小和 token 数量。然而，要在训练初始随机权重的模型时获得这种最优平衡需要大量的计算资源，因为数据需求非常广泛。持续预训练提供了一种成本效益较高的替代方案，可以通过利用预训练模型的计算投资来引入新知识，而无需使用大量新的数据。最近的研究发现，数据质量会影响标度定律中的常数，从而改变最优的参数-tokene 数量分配比例。基于这一见解，我们研究了在计算受限场景下持续预训练期间领域专业化和模型大小之间的相互作用。我们的目标是在此场景中确定一种计算高效的训练范式，并且可能检测到这些相互作用中的模式，这些模式可以在不同模型大小和领域中推广。为了比较通用训练和专业化训练，我们筛选了一个网页数据集以提取法律领域的数据。我们在未筛选和筛选过的数据集上分别使用参数数量为 1.5B、3B、7B 和 14B 的模型进行预训练，然后评估它们在法律考试中的性能。结果表明，随着模型大小的增加，专业化模型和通用模型之间的计算效率差距逐渐增大。 

---
# ArtCrafter: Text-Image Aligning Style Transfer via Embedding Reframing 

**Title (ZH)**: ArtCrafter：通过嵌入重构实现文本-图像对齐的风格转移 

**Authors**: Nisha Huang, Kaer Huang, Yifan Pu, Jiangshan Wang, Jie Guo, Yiqiang Yan, Xiu Li  

**Link**: [PDF](https://arxiv.org/pdf/2501.02064)  

**Abstract**: Recent years have witnessed significant advancements in text-guided style transfer, primarily attributed to innovations in diffusion models. These models excel in conditional guidance, utilizing text or images to direct the sampling process. However, despite their capabilities, direct conditional guidance approaches often face challenges in balancing the expressiveness of textual semantics with the diversity of output results while capturing stylistic features. To address these challenges, we introduce ArtCrafter, a novel framework for text-to-image style transfer. Specifically, we introduce an attention-based style extraction module, meticulously engineered to capture the subtle stylistic elements within an image. This module features a multi-layer architecture that leverages the capabilities of perceiver attention mechanisms to integrate fine-grained information. Additionally, we present a novel text-image aligning augmentation component that adeptly balances control over both modalities, enabling the model to efficiently map image and text embeddings into a shared feature space. We achieve this through attention operations that enable smooth information flow between modalities. Lastly, we incorporate an explicit modulation that seamlessly blends multimodal enhanced embeddings with original embeddings through an embedding reframing design, empowering the model to generate diverse outputs. Extensive experiments demonstrate that ArtCrafter yields impressive results in visual stylization, exhibiting exceptional levels of stylistic intensity, controllability, and diversity. 

**Abstract (ZH)**: 近年来，文本导向的风格迁移取得了显著进展，主要得益于扩散模型的创新。这些模型在条件引导方面表现出色，能够利用文本或图像来指导采样过程。然而，尽管这些模型具有强大的能力，直接的条件引导方法在平衡文本语义的表达性和输出结果的多样性方面仍然面临挑战，尤其是在捕捉风格特征方面。为了解决这些问题，我们提出了ArtCrafter，一种新颖的文字到图像风格迁移框架。具体而言，我们引入了一种基于注意力的风格提取模块，该模块精心设计以捕捉图像中的细微风格元素。该模块采用多层架构，利用感知注意力机制整合细粒度信息。此外，我们提出了一种新颖的文字与图像对齐增强组件，该组件能够巧妙地平衡两种模态的控制，使模型能够高效地将图像和文本嵌入映射到共享特征空间。我们通过注意力操作实现不同模态之间的平滑信息流来实现这一点。最后，我们引入了一种显式的调节机制，通过嵌入重构设计将多模态增强嵌入与原始嵌入无缝融合，使模型能够生成多样化的输出。广泛的实验结果表明，ArtCrafter在视觉风格化方面取得了显著成果，展现了极高的风格强度、可控性和多样性。 

---
# METAGENE-1: Metagenomic Foundation Model for Pandemic Monitoring 

**Title (ZH)**: METAGENE-1：用于传染病监测的代谢基因组基础模型 

**Authors**: Ollie Liu, Sami Jaghouar, Johannes Hagemann, Shangshang Wang, Jason Wiemels, Jeff Kaufman, Willie Neiswanger  

**Link**: [PDF](https://arxiv.org/pdf/2501.02045)  

**Abstract**: We pretrain METAGENE-1, a 7-billion-parameter autoregressive transformer model, which we refer to as a metagenomic foundation model, on a novel corpus of diverse metagenomic DNA and RNA sequences comprising over 1.5 trillion base pairs. This dataset is sourced from a large collection of human wastewater samples, processed and sequenced using deep metagenomic (next-generation) sequencing methods. Unlike genomic models that focus on individual genomes or curated sets of specific species, the aim of METAGENE-1 is to capture the full distribution of genomic information present within this wastewater, to aid in tasks relevant to pandemic monitoring and pathogen detection. We carry out byte-pair encoding (BPE) tokenization on our dataset, tailored for metagenomic sequences, and then pretrain our model. In this paper, we first detail the pretraining dataset, tokenization strategy, and model architecture, highlighting the considerations and design choices that enable the effective modeling of metagenomic data. We then show results of pretraining this model on our metagenomic dataset, providing details about our losses, system metrics, and training stability over the course of pretraining. Finally, we demonstrate the performance of METAGENE-1, which achieves state-of-the-art results on a set of genomic benchmarks and new evaluations focused on human-pathogen detection and genomic sequence embedding, showcasing its potential for public health applications in pandemic monitoring, biosurveillance, and early detection of emerging health threats. 

**Abstract (ZH)**: 我们预训练了一个名为“METAGENE-1”的70亿参数自回归变压器模型，将其称为元基因组基础模型。我们使用了一个包含多种多样的元基因组DNA和RNA序列的新颖数据集，该数据集包含超过1.5万亿个碱基对。这些数据来源于大量人类污水处理样品，并使用深度元基因组（下一代）测序方法进行处理和测序。与其他专注于单个基因组或特定物种精选集的基因组模型不同，METAGENE-1的目的是捕捉这些污水处理样品中所含的全基因组信息，以辅助与大流行监控和病原体检测相关的任务。我们对数据集进行了字节对编码（BPE）词元化处理，专门针对元基因组序列，并进行了预训练。在这篇论文中，我们首先详细介绍了预训练数据集、词元化策略和模型架构，突出了使元基因组数据建模有效的考虑因素和设计选择。然后，我们展示了在元基因组数据集上预训练该模型的结果，提供了关于损失函数、系统指标和预训练过程中训练稳定性等细节。最后，我们展示了METAGENE-1的性能，该模型在一组基因组基准测试和针对人类-病原体检测及基因组序列嵌入的新评估中取得了最新的研究成果，展示了其在公共卫生领域（如大流行监控、生物监测和新兴健康威胁的早期检测）的应用潜力。 

---
# Advancing Pancreatic Cancer Prediction with a Next Visit Token Prediction Head on top of Med-BERT 

**Title (ZH)**: 基于 Med-BERT 的下一次就诊标记预测头部以提升胰腺癌预测 

**Authors**: Jianping He, Laila Rasmy, Degui Zhi, Cui Tao  

**Link**: [PDF](https://arxiv.org/pdf/2501.02044)  

**Abstract**: Background: Recently, numerous foundation models pretrained on extensive data have demonstrated efficacy in disease prediction using Electronic Health Records (EHRs). However, there remains some unanswered questions on how to best utilize such models especially with very small fine-tuning cohorts. Methods: We utilized Med-BERT, an EHR-specific foundation model, and reformulated the disease binary prediction task into a token prediction task and a next visit mask token prediction task to align with Med-BERT's pretraining task format in order to improve the accuracy of pancreatic cancer (PaCa) prediction in both few-shot and fully supervised settings. Results: The reformulation of the task into a token prediction task, referred to as Med-BERT-Sum, demonstrates slightly superior performance in both few-shot scenarios and larger data samples. Furthermore, reformulating the prediction task as a Next Visit Mask Token Prediction task (Med-BERT-Mask) significantly outperforms the conventional Binary Classification (BC) prediction task (Med-BERT-BC) by 3% to 7% in few-shot scenarios with data sizes ranging from 10 to 500 samples. These findings highlight that aligning the downstream task with Med-BERT's pretraining objectives substantially enhances the model's predictive capabilities, thereby improving its effectiveness in predicting both rare and common diseases. Conclusion: Reformatting disease prediction tasks to align with the pretraining of foundation models enhances prediction accuracy, leading to earlier detection and timely intervention. This approach improves treatment effectiveness, survival rates, and overall patient outcomes for PaCa and potentially other cancers. 

**Abstract (ZH)**: 背景：近年来，大量在大量数据上预训练的基础模型在电子健康记录（EHRs）中的疾病预测方面显示出显著的效果。然而，如何最大程度地利用这些模型，特别是在很小的微调组中，仍然存在一些未解答的问题。方法：我们采用了专门针对EHRs的基础模型Med-BERT，并将疾病二分类预测任务重新表述为一个token预测任务和一个下一次就诊掩码token预测任务，以与Med-BERT的预训练任务格式相匹配，旨在在少量样本和完全监督设置中提高胰腺癌（PaCa）预测的准确性。结果：将任务重新表述为token预测任务（称为Med-BERT-Sum）在少量样本和大规模数据样本中均显示出略微更好的性能。此外，将预测任务重新表述为下一次就诊掩码token预测任务（Med-BERT-Mask）在少量样本条件下（样本大小从10到500），相较于传统的二分类（BC）预测任务（Med-BERT-BC），表现提高了3%到7%。这些发现突出了让下游任务与Med-BERT的预训练目标相吻合能够显著增强模型的预测能力，从而在预测罕见和常见疾病方面提高模型的有效性。结论：将疾病预测任务重新格式化以与基础模型的预训练相匹配，可以提高预测准确性，从而实现更早的检测和更及时的干预。这种方法提高了胰腺癌（PaCa）和其他癌症治疗的有效性、存活率和总体患者预后。 

---
# MRG: A Multi-Robot Manufacturing Digital Scene Generation Method Using Multi-Instance Point Cloud Registration 

**Title (ZH)**: MRG：一种基于多实例点云配准的多机器人制造数字化场景生成方法 

**Authors**: Songjie Han, Yinhua Liu, Yanzheng Li, Hua Chen, Dongmei Yang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02041)  

**Abstract**: A high-fidelity digital simulation environment is crucial for accurately replicating physical operational processes. However, inconsistencies between simulation and physical environments result in low confidence in simulation outcomes, limiting their effectiveness in guiding real-world production. Unlike the traditional step-by-step point cloud "segmentation-registration" generation method, this paper introduces, for the first time, a novel Multi-Robot Manufacturing Digital Scene Generation (MRG) method that leverages multi-instance point cloud registration, specifically within manufacturing scenes. Tailored to the characteristics of industrial robots and manufacturing settings, an instance-focused transformer module is developed to delineate instance boundaries and capture correlations between local regions. Additionally, a hypothesis generation module is proposed to extract target instances while preserving key features. Finally, an efficient screening and optimization algorithm is designed to refine the final registration results. Experimental evaluations on the Scan2CAD and Welding-Station datasets demonstrate that: (1) the proposed method outperforms existing multi-instance point cloud registration techniques; (2) compared to state-of-the-art methods, the Scan2CAD dataset achieves improvements in MR and MP by 12.15% and 17.79%, respectively; and (3) on the Welding-Station dataset, MR and MP are enhanced by 16.95% and 24.15%, respectively. This work marks the first application of multi-instance point cloud registration in manufacturing scenes, significantly advancing the precision and reliability of digital simulation environments for industrial applications. 

**Abstract (ZH)**: 高保真数字仿真环境对于准确复制物理运行过程至关重要。然而，仿真与物理环境之间的不一致性降低了对仿真结果的信心，限制了它们在指导实际生产方面的有效性。不同于传统的逐点云“分割-注册”生成方法，本文首次提出了一种多机器人制造数字场景生成（MRG）方法，该方法基于多实例点云注册，特别是在制造场景中应用。针对工业机器人的特性和制造环境的特点，本文开发了一种以实例为中心的变压器模块，用于划分实例边界并捕捉局部区域之间的关联性。此外，提出了一种假设生成模块以提取目标实例并保留关键特征。最后，设计了一种高效的筛选和优化算法以细化最终注册结果。在Scan2CAD和Welding-Station数据集上的实验评估表明：（1）所提出的方法优于现有的多实例点云注册技术；（2）与最先进的方法相比，Scan2CAD数据集在MR（Mean Recall）和MP（Mean Precision）方面分别提高了12.15%和17.79%；（3）对于Welding-Station数据集，MR和MP分别提升了16.95%和24.15%。本文标志着多实例点云注册首次应用于制造场景，极大地提升了工业应用中数字仿真环境的精确性和可靠性。 

---
# A Separable Self-attention Inspired by the State Space Model for Computer Vision 

**Title (ZH)**: 受状态空间模型启发的可分离自注意力机制在计算机视觉中的应用 

**Authors**: Juntao Zhang, Shaogeng Liu, Kun Bian, You Zhou, Pei Zhang, Jianning Liu, Jun Zhou, Bingyan Liu  

**Link**: [PDF](https://arxiv.org/pdf/2501.02040)  

**Abstract**: Mamba is an efficient State Space Model (SSM) with linear computational complexity. Although SSMs are not suitable for handling non-causal data, Vision Mamba (ViM) methods still demonstrate good performance in tasks such as image classification and object detection. Recent studies have shown that there is a rich theoretical connection between state space models and attention variants. We propose a novel separable self attention method, for the first time introducing some excellent design concepts of Mamba into separable self-attention. To ensure a fair comparison with ViMs, we introduce VMINet, a simple yet powerful prototype architecture, constructed solely by stacking our novel attention modules with the most basic down-sampling layers. Notably, VMINet differs significantly from the conventional Transformer architecture. Our experiments demonstrate that VMINet has achieved competitive results on image classification and high-resolution dense prediction this http URL is available at: \url{this https URL}. 

**Abstract (ZH)**: 马amba是一种具有线性计算复杂度的有效状态空间模型（SSM）。尽管状态空间模型（SSM）不适于处理非因果数据，但视觉马amba（ViM）方法在图像分类和目标检测等任务中仍能表现出良好的性能。最近的研究表明，状态空间模型与注意力变体之间存在丰富的理论联系。在此基础上，我们提出了一种新颖的可分离自我注意力方法，首次将马amba的一些优秀设计概念引入到可分离自我注意力中。为了与ViMs进行公平比较，我们引入了VMINet，这是一种简单而强大的原型架构，仅通过堆叠我们的新型注意力模块和最基本的下采样层构建而成。值得注意的是，VMINet与传统的Transformer架构有显著区别。我们的实验表明，VMINet在图像分类和高分辨率密集预测任务中取得了具有竞争力的结果。完整的实验结果及相关代码可在以下网址获取：this https URL。 

---
# An Investigation into Value Misalignment in LLM-Generated Texts for Cultural Heritage 

**Title (ZH)**: 对大型语言模型生成文本中文化遗产领域价值错位现象的探究 

**Authors**: Fan Bu, Zheng Wang, Siyi Wang, Ziyao Liu  

**Link**: [PDF](https://arxiv.org/pdf/2501.02039)  

**Abstract**: As Large Language Models (LLMs) become increasingly prevalent in tasks related to cultural heritage, such as generating descriptions of historical monuments, translating ancient texts, preserving oral traditions, and creating educational content, their ability to produce accurate and culturally aligned texts is being increasingly relied upon by users and researchers. However, cultural value misalignments may exist in generated texts, such as the misrepresentation of historical facts, the erosion of cultural identity, and the oversimplification of complex cultural narratives, which may lead to severe consequences. Therefore, investigating value misalignment in the context of LLM for cultural heritage is crucial for mitigating these risks, yet there has been a significant lack of systematic and comprehensive study and investigation in this area. To fill this gap, we systematically assess the reliability of LLMs in generating culturally aligned texts for cultural heritage-related tasks. We conduct a comprehensive evaluation by compiling an extensive set of 1066 query tasks covering 5 widely recognized categories with 17 aspects within the knowledge framework of cultural heritage across 5 open-source LLMs, and examine both the type and rate of cultural value misalignments in the generated texts. Using both automated and manual approaches, we effectively detect and analyze the cultural value misalignments in LLM-generated texts. Our findings are concerning: over 65% of the generated texts exhibit notable cultural misalignments, with certain tasks demonstrating almost complete misalignment with key cultural values. Beyond these findings, this paper introduces a benchmark dataset and a comprehensive evaluation workflow that can serve as a valuable resource for future research aimed at enhancing the cultural sensitivity and reliability of LLMs. 

**Abstract (ZH)**: 随着大型语言模型（LLMs）在文化遗产相关任务中的应用越来越广泛，如生成历史古迹描述、翻译古代文献、保护口头传统以及创建教育内容等，用户和研究者对LLMs生成准确且文化契合的文本的能力依赖性日益增强。然而，这些生成的文本中可能存在文化价值不一致的问题，例如对历史事实的误代表、文化身份的侵蚀以及复杂文化叙事的过度简化，这可能导致严重的后果。因此，在文化遗产背景下研究LLMs的文化价值不一致对于减轻这些风险至关重要。然而，迄今为止，这一领域的系统性和全面性研究仍有明显的空白。为填补这一空白，我们系统评估了LLMs在生成文化遗产相关任务中文化契合文本的可靠性。我们通过综合评价，在5个广泛认可的类别中涵盖了包括17个方面的知识框架，共整理了1066项查询任务，评估了5个开源LLMs生成的文本中文化价值不一致的类型和频率。我们使用自动和手动相结合的方法，有效地检测并分析了LLMs生成的文本中的文化价值不一致。我们的研究结果令人担忧：超过65%的生成文本表现出明显文化不一致，某些任务甚至几乎完全与关键文化价值观不一致。此外，本研究还引入了一个基准数据集和一个全面的评估工作流程，可以为未来旨在提高LLMs文化敏感性和可靠性的研究提供有价值的资源。 

---
# Architecture for Trajectory-Based Fishing Ship Classification with AIS Data 

**Title (ZH)**: 基于AIS数据的捕鱼船分类架构 

**Authors**: David Sánchez Pedroche, Daniel Amigo, Jesús García, Jose M. Molina  

**Link**: [PDF](https://arxiv.org/pdf/2501.02038)  

**Abstract**: This paper proposes a data preparation process for managing real-world kinematic data and detecting fishing vessels. The solution is a binary classification that classifies ship trajectories into either fishing or non-fishing ships. The data used are characterized by the typical problems found in classic data mining applications using real-world data, such as noise and inconsistencies. The two classes are also clearly unbalanced in the data, a problem which is addressed using algorithms that resample the instances. For classification, a series of features are extracted from spatiotemporal data that represent the trajectories of the ships, available from sequences of Automatic Identification System (AIS) reports. These features are proposed for the modelling of ship behavior but, because they do not contain context-related information, the classification can be applied in other scenarios. Experimentation shows that the proposed data preparation process is useful for the presented classification problem. In addition, positive results are obtained using minimal information. 

**Abstract (ZH)**: 本文提出了一种数据准备流程，用于管理和检测实际水域中的动力学数据及渔船。该解决方案为二元分类问题，将船只轨迹分为渔船和非渔船两类。所使用的数据具有典型的问题，如噪声和不一致现象，这些问题是经典数据挖掘应用在处理真实世界数据时常见到的。此外，两类数据在样本分布上也存在明显的不平衡问题，本文通过重采样算法解决了这一问题。分类过程中，从连续的自动识别系统（AIS）报告获取的船只轨迹数据中提取了一系列时空特征，用于建模船只行为。尽管这些特征不含上下文相关信息，但分类方法可以应用于其他场景。实验结果表明，提出的数据准备流程对于解决本文提出的分类问题是有用的。此外，仅使用少量信息便可获得积极的结果。 

---
# Deep Clustering via Community Detection 

**Title (ZH)**: 基于社区检测的深度聚类 

**Authors**: Tianyu Cheng, Qun Chen  

**Link**: [PDF](https://arxiv.org/pdf/2501.02036)  

**Abstract**: Deep clustering is an essential task in modern artificial intelligence, aiming to partition a set of data samples into a given number of homogeneous groups (i.e., clusters). Even though many Deep Neural Network (DNN) backbones and clustering strategies have been proposed for the task, achieving increasingly improved performance, deep clustering remains very challenging due to the lack of accurately labeled samples. In this paper, we propose a novel approach of deep clustering via community detection. It initializes clustering by detecting many communities, and then gradually expands clusters by community merging. Compared with the existing clustering strategies, community detection factors in the new perspective of cluster network analysis. As a result, it has the inherent benefit of high pseudo-label purity, which is critical to the performance of self-supervision. We have validated the efficacy of the proposed approach on benchmark image datasets. Our extensive experiments have shown that it can effectively improve the SOTA performance. Our ablation study also demonstrates that the new network perspective can effectively improve community pseudo-label purity, resulting in improved clustering performance. 

**Abstract (ZH)**: 深度聚类是现代人工智能中的一个必不可少的任务，旨在将一组数据样本划分为给定数量的同质组（即聚类）。尽管已经为该任务提出了许多深度神经网络（DNN）骨干和聚类策略，并取得了逐步提高的效果，但由于缺乏准确标注的数据样本，深度聚类仍然非常具有挑战性。在本文中，我们提出了一种新的基于社区检测的深度聚类方法。该方法通过检测许多社区进行初始化聚类，然后通过社区合并逐步扩展聚类。与现有的聚类策略相比，社区检测从聚类网络分析的全新视角出发。因此，它具有固有的优势，即伪标签的高纯度，这对自监督的性能至关重要。我们已在基准图像数据集上验证了所提方法的有效性。广泛的实验结果表明，它可以有效提高目前最佳性能。我们还通过消融研究证明，新的网络视角能够有效提高社区伪标签的纯度，从而提高聚类性能。 

---
# 3D Cloud reconstruction through geospatially-aware Masked Autoencoders 

**Title (ZH)**: 通过地理空间意识的掩蔽自编码器进行3D云重建 

**Authors**: Stella Girtsou, Emiliano Diaz Salas-Porras, Lilli Freischem, Joppe Massant, Kyriaki-Margarita Bintsi, Guiseppe Castiglione, William Jones, Michael Eisinger, Emmanuel Johnson, Anna Jungbluth  

**Link**: [PDF](https://arxiv.org/pdf/2501.02035)  

**Abstract**: Clouds play a key role in Earth's radiation balance with complex effects that introduce large uncertainties into climate models. Real-time 3D cloud data is essential for improving climate predictions. This study leverages geostationary imagery from MSG/SEVIRI and radar reflectivity measurements of cloud profiles from CloudSat/CPR to reconstruct 3D cloud structures. We first apply self-supervised learning (SSL) methods-Masked Autoencoders (MAE) and geospatially-aware SatMAE on unlabelled MSG images, and then fine-tune our models on matched image-profile pairs. Our approach outperforms state-of-the-art methods like U-Nets, and our geospatial encoding further improves prediction results, demonstrating the potential of SSL for cloud reconstruction. 

**Abstract (ZH)**: 云在地球辐射平衡中扮演着关键角色，其复杂的影响引入了气候模型中的大量不确定性。实时三维云数据对于提高气候预测至关重要。本研究利用静止轨道卫星MSG/SEVIRI的图像和CloudSat/CPR的雷达反射率测量资料，重构三维云结构。我们首先在未标记的MSG图像上应用自监督学习（SSL）方法——掩码自编码器（MAE）和地理空间感知的SatMAE，然后在匹配的图像-剖面对上微调我们的模型。我们的方法超越了诸如U-Nets等最先进的方法，而我们的地理空间编码进一步提高了预测结果，展示了SSL在云重构中的潜在价值。 

---
# Dynamic Feature Fusion: Combining Global Graph Structures and Local Semantics for Blockchain Fraud Detection 

**Title (ZH)**: 动态特征融合：结合全局图结构与局部语义的区块链欺诈检测 

**Authors**: Zhang Sheng, Liangliang Song, Yanbin Wang  

**Link**: [PDF](https://arxiv.org/pdf/2501.02032)  

**Abstract**: The advent of blockchain technology has facilitated the widespread adoption of smart contracts in the financial sector. However, current fraud detection methodologies exhibit limitations in capturing both global structural patterns within transaction networks and local semantic relationships embedded in transaction data. Most existing models focus on either structural information or semantic features individually, leading to suboptimal performance in detecting complex fraud this http URL this paper, we propose a dynamic feature fusion model that combines graph-based representation learning and semantic feature extraction for blockchain fraud detection. Specifically, we construct global graph representations to model account relationships and extract local contextual features from transaction data. A dynamic multimodal fusion mechanism is introduced to adaptively integrate these features, enabling the model to capture both structural and semantic fraud patterns effectively. We further develop a comprehensive data processing pipeline, including graph construction, temporal feature enhancement, and text preprocessing. Experimental results on large-scale real-world blockchain datasets demonstrate that our method outperforms existing benchmarks across accuracy, F1 score, and recall metrics. This work highlights the importance of integrating structural relationships and semantic similarities for robust fraud detection and offers a scalable solution for securing blockchain systems. 

**Abstract (ZH)**: 区块链技术的出现促进了智能合约在金融领域的广泛应用。然而，当前的欺诈检测方法在捕捉交易网络中的全局结构模式和交易数据中嵌入的局部语义关系方面存在局限性。现有的大多数模型分别侧重于结构信息或语义特征，导致在检测复杂欺诈方面表现不佳（https://this.http.url/）。本文提出了一种动态特征融合模型，该模型结合了基于图的表示学习和语义特征提取，以用于区块链欺诈检测。具体来说，我们构建全局图表示来建模账户关系，并从交易数据中提取局部上下文特征。引入了一个动态多模态融合机制，以自适应地整合这些特征，使模型能够有效地捕捉结构和语义欺诈模式。我们还开发了一个综合的数据处理管道，包括图构建、时序特征增强和文本预处理。在大规模真实世界区块链数据集上的实验结果表明，我们的方法在准确率、F1分数和召回率指标方面优于现有基准。这项工作强调了将结构关系和语义相似性相结合对于稳健欺诈检测的重要性，并提供了一个可扩展的解决方案，用于保护区块链系统。 

---
# CarbonChat: Large Language Model-Based Corporate Carbon Emission Analysis and Climate Knowledge Q&A System 

**Title (ZH)**: 碳聊：基于大型语言模型的企业碳排放分析与气候知识问答系统 

**Authors**: Zhixuan Cao, Ming Han, Jingtao Wang, Meng Jia  

**Link**: [PDF](https://arxiv.org/pdf/2501.02031)  

**Abstract**: As the impact of global climate change intensifies, corporate carbon emissions have become a focal point of global attention. In response to issues such as the lag in climate change knowledge updates within large language models, the lack of specialization and accuracy in traditional augmented generation architectures for complex problems, and the high cost and time consumption of sustainability report analysis, this paper proposes CarbonChat: Large Language Model-based corporate carbon emission analysis and climate knowledge Q&A system, aimed at achieving precise carbon emission analysis and policy this http URL, a diversified index module construction method is proposed to handle the segmentation of rule-based and long-text documents, as well as the extraction of structured data, thereby optimizing the parsing of key this http URL, an enhanced self-prompt retrieval-augmented generation architecture is designed, integrating intent recognition, structured reasoning chains, hybrid retrieval, and Text2SQL, improving the efficiency of semantic understanding and query this http URL, based on the greenhouse gas accounting framework, 14 dimensions are established for carbon emission analysis, enabling report summarization, relevance evaluation, and customized this http URL, through a multi-layer chunking mechanism, timestamps, and hallucination detection features, the accuracy and verifiability of the analysis results are ensured, reducing hallucination rates and enhancing the precision of the responses. 

**Abstract (ZH)**: 随着全球气候变化影响的加剧，企业碳排放已成为全球关注的焦点。针对大型语言模型在气候知识更新滞后、传统增强生成架构对复杂问题的专业性和准确性不足、以及可持续报告分析成本高且耗时等问题，本文提出CarbonChat：基于大型语言模型的企业碳排放分析和气候变化知识问答系统，旨在实现精准的碳排放分析与政策建议。通过提出一种多样化的指标模块构造方法，以处理基于规则的和长文档的分段，以及结构化数据的抽取，从而优化关键信息的解析。设计了一种增强的自提示检索增强生成架构，整合意图识别、结构化推理链、混合检索和Text2SQL技术，提高语义理解和查询效率。基于温室气体核算框架，建立了14个维度进行碳排放分析，支持报告摘要、相关性评估和个性化分析。通过多层切块机制、时间戳和幻觉检测功能，确保分析结果的准确性和可验证性，降低幻觉率并提高响应的精确度。 

---
# Detecting Music Performance Errors with Transformers 

**Title (ZH)**: 使用变换器检测音乐表演错误 

**Authors**: Benjamin Shiue-Hal Chou, Purvish Jajal, Nicholas John Eliopoulos, Tim Nadolsky, Cheng-Yun Yang, Nikita Ravi, James C. Davis, Kristen Yeon-Ji Yun, Yung-Hsiang Lu  

**Link**: [PDF](https://arxiv.org/pdf/2501.02030)  

**Abstract**: Beginner musicians often struggle to identify specific errors in their performances, such as playing incorrect notes or rhythms. There are two limitations in existing tools for music error detection: (1) Existing approaches rely on automatic alignment; therefore, they are prone to errors caused by small deviations between alignment targets.; (2) There is a lack of sufficient data to train music error detection models, resulting in over-reliance on heuristics. To address (1), we propose a novel transformer model, Polytune, that takes audio inputs and outputs annotated music scores. This model can be trained end-to-end to implicitly align and compare performance audio with music scores through latent space representations. To address (2), we present a novel data generation technique capable of creating large-scale synthetic music error datasets. Our approach achieves a 64.1% average Error Detection F1 score, improving upon prior work by 40 percentage points across 14 instruments. Additionally, compared with existing transcription methods repurposed for music error detection, our model can handle multiple instruments. Our source code and datasets are available at this https URL. 

**Abstract (ZH)**: 初学者音乐家在识别其表演中的特定错误（如演奏错误的音符或节奏）时常常遇到困难。现有音乐错误检测工具存在两个局限性：（1）现有方法依赖自动对齐，因此容易受到对齐目标小偏差所导致的错误；（2）缺乏足够的数据来训练音乐错误检测模型，导致过度依赖启发式方法。为解决（1），我们提出了一种新颖的变换器模型——Polytune，该模型接受音频输入并输出注释过的音乐谱。该模型可以通过潜在空间表示从头到尾进行训练，从而隐式地将表演音频与音乐谱对齐和比较。为解决（2），我们提出了一种新颖的数据生成技术，能够创建大规模的合成音乐错误数据集。我们的方法在14种乐器上实现了64.1%的平均错误检测F1分数，比之前的工作提高了40个百分点。此外，与现有被重新用于音乐错误检测的谱转录方法相比，我们的模型能够处理多种乐器。我们的源代码和数据集可在以下链接获取：this https URL。 

---
# Spot Risks Before Speaking! Unraveling Safety Attention Heads in Large Vision-Language Models 

**Title (ZH)**: 发言之前先察险！解析大规模视觉语言模型中的安全注意力头 

**Authors**: Ziwei Zheng, Junyao Zhao, Le Yang, Lijun He, Fan Li  

**Link**: [PDF](https://arxiv.org/pdf/2501.02029)  

**Abstract**: With the integration of an additional modality, large vision-language models (LVLMs) exhibit greater vulnerability to safety risks (e.g., jailbreaking) compared to their language-only predecessors. Although recent studies have devoted considerable effort to the post-hoc alignment of LVLMs, the inner safety mechanisms remain largely unexplored. In this paper, we discover that internal activations of LVLMs during the first token generation can effectively identify malicious prompts across different attacks. This inherent safety perception is governed by sparse attention heads, which we term ``safety heads." Further analysis reveals that these heads act as specialized shields against malicious prompts; ablating them leads to higher attack success rates, while the model's utility remains unaffected. By locating these safety heads and concatenating their activations, we construct a straightforward but powerful malicious prompt detector that integrates seamlessly into the generation process with minimal extra inference overhead. Despite its simple structure of a logistic regression model, the detector surprisingly exhibits strong zero-shot generalization capabilities. Experiments across various prompt-based attacks confirm the effectiveness of leveraging safety heads to protect LVLMs. Code is available at \url{this https URL}. 

**Abstract (ZH)**: 随着额外模态的集成，大型视觉-语言模型（LVLMs）在安全风险（例如， Jailbreaking）方面表现出更大的脆弱性，相较于仅语言的前身模型。虽然近期研究已经投入了大量努力来对LVLMs进行事后对齐，但其内部的安全机制仍然尚未得到充分探索。在本文中，我们发现LVLMs在首次生成标记时的内部激活能够有效地识别不同攻击中的恶意提示。这种固有的安全感知是由稀疏注意力头控制的，我们将其称为“安全头”。进一步分析表明，这些头作为对抗恶意提示的特殊盾牌：移除它们会导致更高的攻击成功率，而模型的实用性不受影响。通过定位这些安全头并拼接其激活，我们构建了一个简单但功能强大的恶意提示检测器，该检测器可以无缝集成到生成过程中，并且具有极小的额外推理开销。尽管检测器的结构仅为逻辑回归模型，但它却意外地表现出强大的零样本泛化能力。在各种基于提示的攻击实验中，利用安全头来保护LVLMs的有效性得到了验证。代码可在 \url{this https URL} 获取。 

---
# Recursive Decomposition of Logical Thoughts: Framework for Superior Reasoning and Knowledge Propagation in Large Language Models 

**Title (ZH)**: 递归分解逻辑思维：大型语言模型中高级推理和知识传播的框架 

**Authors**: Kaleem Ullah Qasim, Jiashu Zhang, Tariq Alsahfi, Ateeq Ur Rehman Butt  

**Link**: [PDF](https://arxiv.org/pdf/2501.02026)  

**Abstract**: Enhancing the reasoning capabilities of Large Language Models remains a critical challenge in artificial intelligence. We introduce RDoLT, Recursive Decomposition of Logical Thought prompting, a novel framework that significantly boosts LLM reasoning performance. RDoLT is built on three key innovations: (1) recursively breaking down complex reasoning tasks into sub-tasks of progressive complexity; (2) employing an advanced selection and scoring mechanism to identify the most promising reasoning thoughts; and (3) integrating a knowledge propagation module that mimics human learning by keeping track of strong and weak thoughts for information propagation. Our approach was evaluated across multiple benchmarks, including GSM8K, SVAMP, MultiArith, LastLetterConcatenation, and Gaokao2023 Math. The results demonstrate that RDoLT consistently outperforms existing state-of-the-art techniques, achieving a 90.98 percent accuracy on GSM8K with ChatGPT-4, surpassing state-of-the-art techniques by 6.28 percent. Similar improvements were observed on other benchmarks, with accuracy gains ranging from 5.5 percent to 6.75 percent. These findings highlight RDoLT's potential to advance prompt engineering, offering a more effective and generalizable approach to complex reasoning tasks. 

**Abstract (ZH)**: 增强大型语言模型的推理能力仍然是人工智能领域的一项关键挑战。我们引入了RDoLT——递归分解逻辑思维提示框架，这一创新框架显著提升了大型语言模型的推理表现。RDoLT基于三项关键创新：(1) 递归地将复杂的推理任务分解为逐步复杂化的子任务；(2) 使用先进的选择和评分机制来识别最有前景的推理思维；以及(3) 集成一个知识传播模块，该模块通过追踪强和弱的思维来模拟人类学习过程，以促进信息传播。我们的方法在多个基准测试中进行了评估，包括GSM8K、SVAMP、MultiArith、LastLetterConcatenation和2023年高考数学。结果表明，RDoLT在各个基准测试中均稳定地优于现有最先进的技术。例如，与ChatGPT-4在GSM8K上的90.98％准确率相比，超越了现有技术6.28％。在其他基准测试中也观察到类似的改进，准确率的提升范围从5.5％到6.75％不等。这些发现突显了RDoLT在推进提示工程方面的潜力，提供了一种更有效和更具普适性的复杂推理任务方法。 

---
# Model Checking in Medical Imaging for Tumor Detection and Segmentation 

**Title (ZH)**: 医学成像中的模型检查在肿瘤检测与分割中的应用 

**Authors**: Elhoucine Elfatimi, Lahcen El fatimi  

**Link**: [PDF](https://arxiv.org/pdf/2501.02024)  

**Abstract**: Recent advancements in model checking have demonstrated significant potential across diverse applications, particularly in signal and image analysis. Medical imaging stands out as a critical domain where model checking can be effectively applied to design and evaluate robust frameworks. These frameworks facilitate automatic and semi-automatic delineation of regions of interest within images, aiding in accurate segmentation. This paper provides a comprehensive analysis of recent works leveraging spatial logic to develop operators and tools for identifying regions of interest, including tumorous and non-tumorous areas. Additionally, we examine the challenges inherent to spatial model-checking techniques, such as variability in ground truth data and the need for streamlined procedures suitable for routine clinical practice. 

**Abstract (ZH)**: 近期在模型检查方面的进展表明了其在多种应用中的巨大潜力，尤其是在信号和图像分析领域表现尤为突出。医学成像作为一个关键领域，在这里可以有效应用模型检查来设计和评估稳健的框架。这些框架能够促进图像中感兴趣区域的自动或半自动分割，从而有助于准确的分割。本文对利用空间逻辑开发识别感兴趣区域的操作符和工具的近期研究进行了全面分析，包括肿瘤和非肿瘤区域。此外，我们还探讨了空间模型检查技术固有的挑战，如ground truth数据的变异性以及需要适用于常规临床实践的简化流程。 

---
# Weakly Supervised Learning on Large Graphs 

**Title (ZH)**: 大规模图上的弱监督学习 

**Authors**: Aditya Prakash  

**Link**: [PDF](https://arxiv.org/pdf/2501.02021)  

**Abstract**: Graph classification plays a pivotal role in various domains, including pathology, where images can be represented as this http URL this domain, images can be represented as graphs, where nodes might represent individual nuclei, and edges capture the spatial or functional relationships between them. Often, the overall label of the graph, such as a cancer type or disease state, is determined by patterns within smaller, localized regions of the image. This work introduces a weakly-supervised graph classification framework leveraging two subgraph extraction techniques: (1) Sliding-window approach (2) BFS-based approach. Subgraphs are processed using a Graph Attention Network (GAT), which employs attention mechanisms to identify the most informative subgraphs for classification. Weak supervision is achieved by propagating graph-level labels to subgraphs, eliminating the need for detailed subgraph annotations. 

**Abstract (ZH)**: 图分类在各个领域中扮演着关键角色，尤其是在病理学领域，其中图像可以表示为一个图，即这里的 https://this-http-url.com/。在这个领域中，图像可以表示为图，其中节点可以代表单个核，边则捕捉它们之间的空间或功能关系。通常，图的整体标签（如癌症类型或疾病状态）是由图像中小区域内的模式决定的。本文介绍了一种利用两种子图提取技术的弱监督图分类框架：（1）滑动窗口方法；（2）基于BFS的方法。使用图注意力网络（GAT）处理子图，该网络采用注意力机制来识别对分类最具有信息量的子图。通过将图级标签传播到子图，实现弱监督，从而避免了详细子图标注的需要。 

---
# Enhancing Uncertainty Modeling with Semantic Graph for Hallucination Detection 

**Title (ZH)**: 使用语义图增强不确定性建模以提高生成式幻觉检测 

**Authors**: Kedi Chen, Qin Chen, Jie Zhou, Xinqi Tao, Bowen Ding, Jingwen Xie, Mingchen Xie, Peilong Li, Feng Zheng, Liang He  

**Link**: [PDF](https://arxiv.org/pdf/2501.02020)  

**Abstract**: Large Language Models (LLMs) are prone to hallucination with non-factual or unfaithful statements, which undermines the applications in real-world scenarios. Recent researches focus on uncertainty-based hallucination detection, which utilizes the output probability of LLMs for uncertainty calculation and does not rely on external knowledge or frequent sampling from LLMs. Whereas, most approaches merely consider the uncertainty of each independent token, while the intricate semantic relations among tokens and sentences are not well studied, which limits the detection of hallucination that spans over multiple tokens and sentences in the passage. In this paper, we propose a method to enhance uncertainty modeling with semantic graph for hallucination detection. Specifically, we first construct a semantic graph that well captures the relations among entity tokens and sentences. Then, we incorporate the relations between two entities for uncertainty propagation to enhance sentence-level hallucination detection. Given that hallucination occurs due to the conflict between sentences, we further present a graph-based uncertainty calibration method that integrates the contradiction probability of the sentence with its neighbors in the semantic graph for uncertainty calculation. Extensive experiments on two datasets show the great advantages of our proposed approach. In particular, we obtain substantial improvements with 19.78% in passage-level hallucination detection. 

**Abstract (ZH)**: 大型语言模型（LLMs）容易产生基于虚构或不忠实的陈述的幻觉，这在现实场景中的应用中造成了阻碍。近期的研究集中在基于不确定性的幻觉检测上，这种方法利用LLMs的输出概率来进行不确定性的计算，并不依赖于外部知识或频繁的LLMs抽样。然而，大多数方法仅考虑每个独立词汇单元的不确定性，而对词汇单元和句子之间复杂的语义关系的研究不足，这限制了对跨多个词汇单元和句子的幻觉的检测能力。在本文中，我们提出了一种通过引入语义图来增强不确定性建模的方法，以提高幻觉检测的准确性。具体而言，我们首先构建了一个能够很好地捕捉实体词汇单元和句子之间关系的语义图；然后，通过引入实体之间关系来进行不确定性传播，以增强句子级别的幻觉检测。鉴于幻觉通常是由于句子之间的冲突引起的，我们进一步提出了一种基于图的不确定性校准方法，该方法将句子与其语义图中邻居的矛盾概率结合起来，进行不确定性计算。通过对两个数据集的广泛实验表明，我们的方法具有显著优势，特别是在段落级别的幻觉检测上，我们取得了19.78%的显著改进。 

---
# Benchmarking Constraint-Based Bayesian Structure Learning Algorithms: Role of Network Topology 

**Title (ZH)**: 基于约束的贝叶斯结构学习算法的基准测试：网络拓扑的作用 

**Authors**: Radha Nagarajan, Marco Scutari  

**Link**: [PDF](https://arxiv.org/pdf/2501.02019)  

**Abstract**: Modeling the associations between real world entities from their multivariate cross-sectional profiles can provide cues into the concerted working of these entities as a system. Several techniques have been proposed for deciphering these associations including constraint-based Bayesian structure learning (BSL) algorithms that model them as directed acyclic graphs. Benchmarking these algorithms have typically focused on assessing the variation in performance measures such as sensitivity as a function of the dimensionality represented by the number of nodes in the DAG, and sample size. The present study elucidates the importance of network topology in benchmarking exercises. More specifically, it investigates variations in sensitivity across distinct network topologies while constraining the nodes, edges, and sample-size to be identical, eliminating these as potential confounders. Sensitivity of three popular constraint-based BSL algorithms (Peter-Clarke, Grow-Shrink, Incremental Association Markov Blanket) in learning the network structure from multivariate cross-sectional profiles sampled from network models with sub-linear, linear, and super-linear DAG topologies generated using preferential attachment is investigated. Results across linear and nonlinear models revealed statistically significant $(\alpha=0.05)$ decrease in sensitivity estimates from sub-linear to super-linear topology constitutively across the three algorithms. These results are demonstrated on networks with nodes $(N_{nods}=48,64)$, noise strengths $(\sigma =3,6)$ and sample size $(N = 2^{10})$. The findings elucidate the importance of accommodating the network topology in constraint-based BSL benchmarking exercises. 

**Abstract (ZH)**: 从多变量横截面配置文件模拟现实世界实体之间的关联，可以揭示这些实体作为系统的协同工作机制。已提出多种技术来解析这些关联，包括将它们建模为有向无环图（DAG）的约束基于贝叶斯结构学习（BSL）算法。这些算法的基准测试通常侧重于评估敏感度等性能指标随DAG中节点数量表示的维度性和样本大小变化的情况。本研究阐明了网络拓扑在基准测试中的重要性。具体来说，它探讨了不同的网络拓扑结构在约束节点、边和样本大小的情况下敏感度的变异性，从而消除这些潜在混杂因素。本研究调查了三种流行的约束基于BSL算法（Peter-Clarke、Grow-Shrink、增量关联马尔可夫毯）从使用偏好连接生成的亚线性、线性和超线性DAG拓扑的网络模型中学习网络结构的敏感度。线性和非线性模型的结果表明，在三种算法中，从亚线性到超线性拓扑的敏感度估计统计上显着（α=0.05）下降。这些结果在具有节点数（N_{nods}=48,64）、噪声强度（σ=3,6）和样本量（N = 2^10）的网络上得到了验证。研究结果阐明了在网络拓扑建模中考虑网络拓扑的重要性。 

---
# Safeguarding Large Language Models in Real-time with Tunable Safety-Performance Trade-offs 

**Title (ZH)**: 实时动态调整安全与性能权衡以保障大型语言模型安全 

**Authors**: Joao Fonseca, Andrew Bell, Julia Stoyanovich  

**Link**: [PDF](https://arxiv.org/pdf/2501.02018)  

**Abstract**: Large Language Models (LLMs) have been shown to be susceptible to jailbreak attacks, or adversarial attacks used to illicit high risk behavior from a model. Jailbreaks have been exploited by cybercriminals and blackhat actors to cause significant harm, highlighting the critical need to safeguard widely-deployed models. Safeguarding approaches, which include fine-tuning models or having LLMs "self-reflect", may lengthen the inference time of a model, incur a computational penalty, reduce the semantic fluency of an output, and restrict ``normal'' model behavior. Importantly, these Safety-Performance Trade-offs (SPTs) remain an understudied area. In this work, we introduce a novel safeguard, called SafeNudge, that combines Controlled Text Generation with "nudging", or using text interventions to change the behavior of a model. SafeNudge triggers during text-generation while a jailbreak attack is being executed, and can reduce successful jailbreak attempts by 30% by guiding the LLM towards a safe responses. It adds minimal latency to inference and has a negligible impact on the semantic fluency of outputs. Further, we allow for tunable SPTs. SafeNudge is open-source and available through this https URL, and is compatible with models loaded with the Hugging Face "transformers" library. 

**Abstract (ZH)**: 大型语言模型（LLMs）已被证明容易受到劫持攻击的影响，这种攻击旨在诱使模型表现出高风险行为。劫持攻击已被网络犯罪分子和黑客利用，对模型造成了重大伤害，这凸显了保护广泛部署模型的迫切需求。保护措施，包括对模型进行微调或使LLMs进行“自我反省”，可能会延长模型的推理时间、增加计算成本、降低输出的语义流畅性，并限制模型的常规行为。重要的是，这些安全性能权衡（SPTs）仍是一个研究不足的领域。在本研究中，我们提出了一种名为SafeNudge的新型保护措施，该措施结合了受控文本生成和“引导”技术，即将文本干预用来改变模型的行为。SafeNudge在执行劫持攻击期间启动，可以将成功的劫持攻击减少30%，通过引导LLM生成安全的响应。它对推理的延迟影响很小，并且对输出的语义流畅性几乎没有影响。此外，SafeNudge允许调节安全性能权衡。SafeNudge是开源的，并可通过以下链接获取：[该链接]，并与Hugging Face“transformers”库加载的模型兼容。 

---
# ST-HCSS: Deep Spatio-Temporal Hypergraph Convolutional Neural Network for Soft Sensing 

**Title (ZH)**: ST-HCSS：时空超图卷积神经网络在软感知中的应用 

**Authors**: Hwa Hui Tew, Fan Ding, Gaoxuan Li, Junn Yong Loo, Chee-Ming Ting, Ze Yang Ding, Chee Pin Tan  

**Link**: [PDF](https://arxiv.org/pdf/2501.02016)  

**Abstract**: Higher-order sensor networks are more accurate in characterizing the nonlinear dynamics of sensory time-series data in modern industrial settings by allowing multi-node connections beyond simple pairwise graph edges. In light of this, we propose a deep spatio-temporal hypergraph convolutional neural network for soft sensing (ST-HCSS). In particular, our proposed framework is able to construct and leverage a higher-order graph (hypergraph) to model the complex multi-interactions between sensor nodes in the absence of prior structural knowledge. To capture rich spatio-temporal relationships underlying sensor data, our proposed ST-HCSS incorporates stacked gated temporal and hypergraph convolution layers to effectively aggregate and update hypergraph information across time and nodes. Our results validate the superiority of ST-HCSS compared to existing state-of-the-art soft sensors, and demonstrates that the learned hypergraph feature representations aligns well with the sensor data correlations. The code is available at this https URL 

**Abstract (ZH)**: 在现代工业环境中，高阶传感器网络通过允许多节点连接而非简单的双边图边，能够更准确地刻画传感器时间序列数据的非线性动态。基于此，我们提出了一种深度空间-时间超图卷积神经网络（ST-HCSS）用于软传感。具体而言，我们提出的框架能够在缺乏先验结构知识的情况下，构建并利用高阶图（超图）来建模传感器节点之间的复杂多交互。为了捕捉传感器数据下的丰富空间-时间关系，我们提出的ST-HCSS融合了堆叠的门控时间卷积和超图卷积层，以有效地在时间和节点之间聚合和更新超图信息。我们的实验结果验证了ST-HCSS在与现有最佳软传感器相比的优势，并且表明学习到的超图特征表示与传感器数据的相关性吻合得很好。代码可以在以下链接中获得：[链接] 

---
# KANS: Knowledge Discovery Graph Attention Network for Soft Sensing in Multivariate Industrial Processes 

**Title (ZH)**: KANS：用于多变量工业过程软传感的知识发现图形注意力网络 

**Authors**: Hwa Hui Tew, Gaoxuan Li, Fan Ding, Xuewen Luo, Junn Yong Loo, Chee-Ming Ting, Ze Yang Ding, Chee Pin Tan  

**Link**: [PDF](https://arxiv.org/pdf/2501.02015)  

**Abstract**: Soft sensing of hard-to-measure variables is often crucial in industrial processes. Current practices rely heavily on conventional modeling techniques that show success in improving accuracy. However, they overlook the non-linear nature, dynamics characteristics, and non-Euclidean dependencies between complex process variables. To tackle these challenges, we present a framework known as a Knowledge discovery graph Attention Network for effective Soft sensing (KANS). Unlike the existing deep learning soft sensor models, KANS can discover the intrinsic correlations and irregular relationships between the multivariate industrial processes without a predefined topology. First, an unsupervised graph structure learning method is introduced, incorporating the cosine similarity between different sensor embedding to capture the correlations between sensors. Next, we present a graph attention-based representation learning that can compute the multivariate data parallelly to enhance the model in learning complex sensor nodes and edges. To fully explore KANS, knowledge discovery analysis has also been conducted to demonstrate the interpretability of the model. Experimental results demonstrate that KANS significantly outperforms all the baselines and state-of-the-art methods in soft sensing performance. Furthermore, the analysis shows that KANS can find sensors closely related to different process variables without domain knowledge, significantly improving soft sensing accuracy. 

**Abstract (ZH)**: 在工业过程中，难以测量变量的软传感往往至关重要。当前的做法主要依赖于传统的建模技术，这些技术在提高准确度方面显示出一定的成效。然而，它们忽略了复杂过程变量之间的非线性性质、动态特性和非欧几里得依赖关系。为应对这些挑战，我们提出了一种名为知识发现图注意网络（KANS，Knowledge discovery graph Attention Network for effective Soft sensing）的框架。与现有的深度学习软传感器模型不同，KANS能够在没有预定义拓扑结构的情况下发现多变量工业过程之间的内在关联和不规则关系。首先，我们引入了一种无监督的图结构学习方法，通过不同传感器嵌入的余弦相似性来捕捉传感器之间的关联。接着，我们提出了一种基于图注意机制的表示学习方法，能够并行处理多变量数据，以增强模型在学习复杂传感器节点和边方面的能力。为了全面探索KANS，我们还进行了知识发现分析以展示模型的可解释性。实验结果表明，KANS在软传感性能上显著优于所有基线和最先进的方法。此外，分析显示，KANS能够在没有领域知识的情况下找到与不同过程变量紧密相关的传感器，从而显著提高软传感的准确性。 

---
# Machine Learning-Based Differential Diagnosis of Parkinson's Disease Using Kinematic Feature Extraction and Selection 

**Title (ZH)**: 基于机器学习的帕金森病鉴别诊断研究：通过运动特征提取与选择 

**Authors**: Masahiro Matsumoto, Abu Saleh Musa Miah, Nobuyoshi Asai, Jungpil Shin  

**Link**: [PDF](https://arxiv.org/pdf/2501.02014)  

**Abstract**: Parkinson's disease (PD), the second most common neurodegenerative disorder, is characterized by dopaminergic neuron loss and the accumulation of abnormal synuclein. PD presents both motor and non-motor symptoms that progressively impair daily functioning. The severity of these symptoms is typically assessed using the MDS-UPDRS rating scale, which is subjective and dependent on the physician's experience. Additionally, PD shares symptoms with other neurodegenerative diseases, such as progressive supranuclear palsy (PSP) and multiple system atrophy (MSA), complicating accurate diagnosis. To address these diagnostic challenges, we propose a machine learning-based system for differential diagnosis of PD, PSP, MSA, and healthy controls (HC). This system utilizes a kinematic feature-based hierarchical feature extraction and selection approach. Initially, 18 kinematic features are extracted, including two newly proposed features: Thumb-to-index vector velocity and acceleration, which provide insights into motor control patterns. In addition, 41 statistical features were extracted here from each kinematic feature, including some new approaches such as Average Absolute Change, Rhythm, Amplitude, Frequency, Standard Deviation of Frequency, and Slope. Feature selection is performed using One-way ANOVA to rank features, followed by Sequential Forward Floating Selection (SFFS) to identify the most relevant ones, aiming to reduce the computational complexity. The final feature set is used for classification, achieving a classification accuracy of 66.67% for each dataset and 88.89% for each patient, with particularly high performance for the MSA and HC groups using the SVM algorithm. This system shows potential as a rapid and accurate diagnostic tool in clinical practice, though further data collection and refinement are needed to enhance its reliability. 

**Abstract (ZH)**: 帕金森病（PD），作为仅次于阿尔茨海默病的第二大常见的神经退行性疾病，其特征是多巴胺能神经元的丢失和异常α-突触核蛋白的累积。PD 病例表现出运动和非运动症状，并随时间逐渐损害日常功能。这些症状的严重程度通常使用 MDS-UPDRS 评分量表进行评估，该量表具有一定的主观性，并且依赖于医生的经验。此外，PD 的症状与其他神经退行性疾病，如进行性核上性麻痹（PSP）和多系统萎缩（MSA）相似，增加了准确诊断的难度。为了应对这些诊断方面的挑战，我们提出了一种基于机器学习的系统，用于区分 PD、PSP、MSA 和健康对照组（HC）。该系统利用了一种基于运动特征的分层次特征提取和选择方法。首先，从中提取了18个运动特征，其中包括两个新提出的特征：拇指到小指向量速度和加速度，这些特征提供了有关运动控制模式的见解。此外，还从中提取了每个运动特征的41个统计特征，包括一些新的方法，如平均绝对变化、节奏、幅度、频率、频率的标准偏差和斜率。特征选择使用单因素方差分析（ANOVA）进行排序，然后使用逐步向前选择（SFFS）方法来识别最相关特征，以降低计算复杂度。最终的特征集被用于分类，使用支持向量机（SVM）算法实现了每个数据集66.67%的分类准确率和每位患者88.89%的准确率，尤其是在MSA和HC组中表现尤为突出。该系统有望成为临床实践中快速准确的诊断工具，但进一步的数据收集和优化将有助于增强其可靠性。 

---
# Cross-model Transferability among Large Language Models on the Platonic Representations of Concepts 

**Title (ZH)**: 大型语言模型中关于概念的柏拉图式表示之间的跨模型可转移性 

**Authors**: Youcheng Huang, Chen Huang, Duanyu Feng, Wenqiang Lei, Jiancheng Lv  

**Link**: [PDF](https://arxiv.org/pdf/2501.02009)  

**Abstract**: Understanding the inner workings of Large Language Models (LLMs) is a critical research frontier. Prior research has shown that a single LLM's concept representations can be captured as steering vectors (SVs), enabling the control of LLM behavior (e.g., towards generating harmful content). Our work takes a novel approach by exploring the intricate relationships between concept representations across different LLMs, drawing an intriguing parallel to Plato's Allegory of the Cave. In particular, we introduce a linear transformation method to bridge these representations and present three key findings: 1) Concept representations across different LLMs can be effectively aligned using simple linear transformations, enabling efficient cross-model transfer and behavioral control via SVs. 2) This linear transformation generalizes across concepts, facilitating alignment and control of SVs representing different concepts across LLMs. 3) A weak-to-strong transferability exists between LLM concept representations, whereby SVs extracted from smaller LLMs can effectively control the behavior of larger LLMs. 

**Abstract (ZH)**: 理解大型语言模型（LLMs）的工作原理是研究的重要前沿领域。先前的研究表明，单个LLM的概念表示可以被捕捉为引导向量（SVs），从而控制LLM的行为（例如，使其倾向于生成有害内容）。我们的工作采取了一种新的方法，通过探索不同LLM之间概念表示的复杂关系，从而引出了柏拉图洞穴寓言的一个有趣的平行关系。具体来说，我们引入了一种线性变换方法来连接这些表示，并提出了以下三个关键发现：1）可以使用简单的线性变换有效地对不同LLM之间的概念表示进行对齐，从而通过SVs实现高效的跨模型转移和行为控制。2）这种线性变换适用于不同概念，便于在不同LLM之间对不同概念的SVs进行对齐和控制。3）存在从弱到强的概念表示转移性，即从较小的LLM中提取的SVs可以有效地控制较大LLM的行为。 

---
# TART: Token-based Architecture Transformer for Neural Network Performance Prediction 

**Title (ZH)**: TART：基于令牌的架构变换器神经网络性能预测 

**Authors**: Yannis Y. He  

**Link**: [PDF](https://arxiv.org/pdf/2501.02007)  

**Abstract**: In the realm of neural architecture design, achieving high performance is largely reliant on the manual expertise of researchers. Despite the emergence of Neural Architecture Search (NAS) as a promising technique for automating this process, current NAS methods still require human input to expand the search space and cannot generate new architectures. This paper explores the potential of Transformers in comprehending neural architectures and their performance, with the objective of establishing the foundation for utilizing Transformers to generate novel networks. We propose the Token-based Architecture Transformer (TART), which predicts neural network performance without the need to train candidate networks. TART attains state-of-the-art performance on the DeepNets-1M dataset for performance prediction tasks without edge information, indicating the potential of Transformers to aid in discovering novel and high-performing neural architectures. 

**Abstract (ZH)**: 在神经网络架构设计领域，取得高性能很大程度上依赖于研究人员的手动专业知识。尽管神经架构搜索（NAS）作为一种自动化的有前景的技术已经出现，但现有的NAS方法仍然需要人类输入来扩展搜索空间，并且无法生成新的架构。本文探讨了Transformer在理解神经网络及其性能方面的潜力，旨在为利用Transformer生成新颖网络奠定基础。我们提出了基于Token的架构Transformer（TART），该方法能够在无需训练候选网络的情况下预测神经网络的性能。在不利用边缘信息的情况下，TART在DeepNets-1M数据集上的性能预测任务中达到了最先进的性能，这表明Transformer在发现新颖且高性能的神经网络方面的潜力。 

---
# Multi-Task Semantic Communication With Graph Attention-Based Feature Correlation Extraction 

**Title (ZH)**: 基于图注意力特征相关提取的多任务语义通信 

**Authors**: Xi Yu, Tiejun Lv, Weicai Li, Wei Ni, Dusit Niyato, Ekram Hossain  

**Link**: [PDF](https://arxiv.org/pdf/2501.02006)  

**Abstract**: Multi-task semantic communication can serve multiple learning tasks using a shared encoder model. Existing models have overlooked the intricate relationships between features extracted during an encoding process of tasks. This paper presents a new graph attention inter-block (GAI) module to the encoder/transmitter of a multi-task semantic communication system, which enriches the features for multiple tasks by embedding the intermediate outputs of encoding in the features, compared to the existing techniques. The key idea is that we interpret the outputs of the intermediate feature extraction blocks of the encoder as the nodes of a graph to capture the correlations of the intermediate features. Another important aspect is that we refine the node representation using a graph attention mechanism to extract the correlations and a multi-layer perceptron network to associate the node representations with different tasks. Consequently, the intermediate features are weighted and embedded into the features transmitted for executing multiple tasks at the receiver. Experiments demonstrate that the proposed model surpasses the most competitive and publicly available models by 11.4% on the CityScapes 2Task dataset and outperforms the established state-of-the-art by 3.97% on the NYU V2 3Task dataset, respectively, when the bandwidth ratio of the communication channel (i.e., compression level for transmission over the channel) is as constrained as 1 12 . 

**Abstract (ZH)**: 多任务语义通信可以通过共享编码模型服务于多个学习任务。现有模型未能充分考虑编码过程中提取特征之间的复杂关系。本文在多任务语义通信系统的编码/发送端引入了新的图注意力跨模块（GAI）模块，通过将编码中间输出嵌入特征中，丰富了多任务的特征。关键思想是将编码器的中间特征提取模块的输出解释为图的节点，以捕捉中间特征之间的相关性。另一个重要方面是通过图注意力机制细化节点表示以提取相关性，并通过多层感知机网络关联节点表示与不同任务。因此，中间特征被加权嵌入到传送到接收端执行多个任务的特征中。实验结果表明，在CityScapes 2Task数据集上，所提出模型比最先进且已公开的模型高出11.4%，在NYU V2 3Task数据集上比现有最先进的模型高出3.97%，当通信信道带宽比（即通道传输压缩水平）受限于1/12时。 

---
# General Information Metrics for Improving AI Model Training Efficiency 

**Title (ZH)**: 提高AI模型训练效率的一般信息度量标准 

**Authors**: Jianfeng Xu, Congcong Liu, Xiaoying Tan, Xiaojie Zhu, Anpeng Wu, Huan Wan, Weijun Kong, Chun Li, Hu Xu, Kun Kuang, Fei Wu  

**Link**: [PDF](https://arxiv.org/pdf/2501.02004)  

**Abstract**: To address the growing size of AI model training data and the lack of a universal data selection methodology-factors that significantly drive up training costs -- this paper presents the General Information Metrics Evaluation (GIME) method. GIME leverages general information metrics from Objective Information Theory (OIT), including volume, delay, scope, granularity, variety, duration, sampling rate, aggregation, coverage, distortion, and mismatch to optimize dataset selection for training purposes. Comprehensive experiments conducted across diverse domains, such as CTR Prediction, Civil Case Prediction, and Weather Forecasting, demonstrate that GIME effectively preserves model performance while substantially reducing both training time and costs. Additionally, applying GIME within the Judicial AI Program led to a remarkable 39.56% reduction in total model training expenses, underscoring its potential to support efficient and sustainable AI development. 

**Abstract (ZH)**: 为了解决AI模型训练数据规模不断增长以及缺乏通用的数据选择方法——这些因素显著增加了训练成本的问题，本文提出了一种通用信息度量评估（GIME）方法。GIME 利用了客观信息理论（OIT）中的通用信息度量，包括容量、延迟、范围、粒度、多样性、持续时间、采样率、聚合、覆盖率、失真和不匹配等方面，以优化训练数据集的选择。在包括点击率预测、民事案件预测和天气预报等多个领域进行的全面实验表明，GIME 能够在显著减少训练时间和成本的同时，有效地保持模型性能。此外，在司法AI计划中应用GIME导致总模型训练成本减少了39.56%，这进一步突显了其支持高效和可持续的AI开发的潜力。 

---
# Multi-Center Study on Deep Learning-Assisted Detection and Classification of Fetal Central Nervous System Anomalies Using Ultrasound Imaging 

**Title (ZH)**: 使用超声成像辅助深度学习检测和分类胎儿中枢神经系统异常的多中心研究 

**Authors**: Yang Qi, Jiaxin Cai, Jing Lu, Runqing Xiong, Rongshang Chen, Liping Zheng, Duo Ma  

**Link**: [PDF](https://arxiv.org/pdf/2501.02000)  

**Abstract**: Prenatal ultrasound evaluates fetal growth and detects congenital abnormalities during pregnancy, but the examination of ultrasound images by radiologists requires expertise and sophisticated equipment, which would otherwise fail to improve the rate of identifying specific types of fetal central nervous system (CNS) abnormalities and result in unnecessary patient examinations. We construct a deep learning model to improve the overall accuracy of the diagnosis of fetal cranial anomalies to aid prenatal diagnosis. In our collected multi-center dataset of fetal craniocerebral anomalies covering four typical anomalies of the fetal central nervous system (CNS): anencephaly, encephalocele (including meningocele), holoprosencephaly, and rachischisis, patient-level prediction accuracy reaches 94.5%, with an AUROC value of 99.3%. In the subgroup analyzes, our model is applicable to the entire gestational period, with good identification of fetal anomaly types for any gestational period. Heatmaps superimposed on the ultrasound images not only provide a visual interpretation for the algorithm but also provide an intuitive visual aid to the physician by highlighting key areas that need to be reviewed, helping the physician to quickly identify and validate key areas. Finally, the retrospective reader study demonstrates that by combining the automatic prediction of the DL system with the professional judgment of the radiologist, the diagnostic accuracy and efficiency can be effectively improved and the misdiagnosis rate can be reduced, which has an important clinical application prospect. 

**Abstract (ZH)**: 羊水超声评估胎儿生长和检测妊娠期间的先天性异常，但由放射科医生检查超声图像需要专业知识和复杂设备，否则将无法提高识别特定类型的胎儿中枢神经系统（CNS）异常的准确率，导致不必要的患者检查。我们构建了一个深度学习模型，以提高胎儿头颅畸形诊断的总体准确性，辅助产前诊断。在我们收集的涵盖胎儿中枢神经系统四种典型畸形（无脑儿、脑膨出（包括脊髓膨出）、头面部裂畸形和脊柱裂）的多中心数据集中，患者级预测准确率达到94.5%，AUROC值为99.3%。在子组分析中，我们的模型在整个妊娠期均可应用，能够良好地区分不同妊娠时期的胎儿畸形类型。叠加在超声图像上的热图不仅为算法提供了视觉解释，还为医生提供了直观的视觉辅助工具，突出了需要进一步审查的关键区域，帮助医生快速识别和验证关键区域。最后，回顾性读者研究表明，结合深度学习系统的自动预测和放射科医生的专业判断，可以有效提高诊断准确性和效率，并降低误诊率，具有重要的临床应用前景。 

---
# On the Utility of Equivariance and Symmetry Breaking in Deep Learning Architectures on Point Clouds 

**Title (ZH)**: 点云数据上深度学习架构中的等变性和对称性破缺的效用探究 

**Authors**: Sharvaree Vadgama, Mohammad Mohaiminul Islam, Domas Buracus, Christian Shewmake, Erik Bekkers  

**Link**: [PDF](https://arxiv.org/pdf/2501.01999)  

**Abstract**: This paper explores the key factors that influence the performance of models working with point clouds, across different tasks of varying geometric complexity. In this work, we explore the trade-offs between flexibility and weight-sharing introduced by equivariant layers, assessing when equivariance boosts or detracts from performance. It is often argued that providing more information as input improves a model's performance. However, if this additional information breaks certain properties, such as $\SE(3)$ equivariance, does it remain beneficial? We identify the key aspects of equivariant and non-equivariant architectures that drive success in different tasks by benchmarking them on segmentation, regression, and generation tasks across multiple datasets with increasing complexity. We observe a positive impact of equivariance, which becomes more pronounced with increasing task complexity, even when strict equivariance is not required. 

**Abstract (ZH)**: 本文探讨了在不同几何复杂度任务中，影响点云处理模型性能的关键因素。本研究考察了均衡层引入的灵活性与权重共享之间的权衡，评估了均衡性对性能的促进作用或负面影响。通常认为，提供更多输入信息可以提高模型的性能。然而，如果这种额外信息破坏了某些属性，例如 $\SE(3)$ 普遍性，它是否仍然有益？我们通过在一个具有不同复杂度的多个数据集上的分割、回归和生成任务中对比均衡性和非均衡性架构，识别出驱动不同任务成功的关键方面。研究发现，即使不需要严格的均衡性，均衡性仍然具有正面影响，并且这种影响随着任务复杂度的增加而更加明显。 

---
# SmartSpatial: Enhancing the 3D Spatial Arrangement Capabilities of Stable Diffusion Models and Introducing a Novel 3D Spatial Evaluation Framework 

**Title (ZH)**: SmartSpatial: 提升稳定扩散模型的三维空间布局能力并引入一种新型三维空间评估框架 

**Authors**: Mao Xun Huang, Hen-Hsen Huang  

**Link**: [PDF](https://arxiv.org/pdf/2501.01998)  

**Abstract**: Stable Diffusion models have made remarkable strides in generating photorealistic images from text prompts but often falter when tasked with accurately representing complex spatial arrangements, particularly involving intricate 3D relationships. To address this limitation, we introduce SmartSpatial, an innovative approach that enhances the spatial arrangement capabilities of Stable Diffusion models through 3D-aware conditioning and attention-guided mechanisms. SmartSpatial incorporates depth information and employs cross-attention control to ensure precise object placement, delivering notable improvements in spatial accuracy metrics. In conjunction with SmartSpatial, we present SmartSpatialEval, a comprehensive evaluation framework designed to assess spatial relationships. This framework utilizes vision-language models and graph-based dependency parsing for performance analysis. Experimental results on the COCO and SpatialPrompts datasets show that SmartSpatial significantly outperforms existing methods, setting new benchmarks for spatial arrangement accuracy in image generation. 

**Abstract (ZH)**: 稳定的扩散模型已经在从文本提示生成逼真图像方面取得了显著进展，但在准确表示复杂的空间排列结构，特别是涉及复杂的3D关系时，经常表现不佳。为了解决这一局限性，我们提出了SmartSpatial，这是一种创新的方法，通过3D意识条件和注意力引导机制增强稳定扩散模型的空间排列能力。SmartSpatial融合了深度信息，并利用交叉注意力控制确保精确的对象放置，从而在空间准确性指标方面取得显著改进。与SmartSpatial一起，我们还提出了SmartSpatialEval，这是一种全面的评估框架，用于评估空间关系。该框架利用视觉语言模型和基于图的依赖解析来进行性能分析。在COCO和SpatialPrompts数据集上的实验结果表明，SmartSpatial在空间排列准确性方面显著优于现有方法，为图像生成中的空间排列精度设立了新的基准。 

---
# Fuzzy Model Identification and Self Learning with Smooth Compositions 

**Title (ZH)**: 模糊模型辨识与平滑组合的自我学习方法 

**Authors**: Ebrahim Navid Sadjadi, Jesus Garcia, Jose M. Molina, Akbar Hashemi Borzabadi, Monireh Asadi Abchouyeh  

**Link**: [PDF](https://arxiv.org/pdf/2501.01994)  

**Abstract**: This paper develops a smooth model identification and self-learning strategy for dynamic systems taking into account possible parameter variations and uncertainties. We have tried to solve the problem such that the model follows the changes and variations in the system on a continuous and smooth surface. Running the model to adaptively gain the optimum values of the parameters on a smooth surface would facilitate further improvements in the application of other derivative based optimization control algorithms such as MPC or robust control algorithms to achieve a combined modeling-control scheme. Compared to the earlier works on the smooth fuzzy modeling structures, we could reach a desired trade-off between the model optimality and the computational load. The proposed method has been evaluated on a test problem as well as the non-linear dynamic of a chemical process. 

**Abstract (ZH)**: 本文提出了一种考虑可能参数变化和不确定性的情况下，动态系统平滑模型识别及自学习策略。我们力求使模型能够在一个连续和平滑的表面上跟随系统的更改和变化。通过使模型在平滑表面上自适应地获得参数的最优值，可以进一步改进基于导数的优化控制算法（如MPC或稳健控制算法）的应用，并实现模型-控制方案的结合。相较于之前关于平滑模糊建模结构的研究，我们能够在模型最优性和计算负载之间达到一个理想的折衷。所提出的方法已经在测试问题以及化学过程的非线性动态中进行了评估。 

---
# A Hybrid Deep Learning and Model-Checking Framework for Accurate Brain Tumor Detection and Validation 

**Title (ZH)**: 一种融合深度学习与模型检测的混合框架，用于精确的脑肿瘤检测与验证 

**Authors**: Lahcen El Fatimi, Elhoucine Elfatimi, Hanifa Bouchaneb  

**Link**: [PDF](https://arxiv.org/pdf/2501.01991)  

**Abstract**: Model checking, a formal verification technique, ensures systems meet predefined requirements, playing a crucial role in minimizing errors and enhancing quality during development. This paper introduces a novel hybrid framework integrating model checking with deep learning for brain tumor detection and validation in medical imaging. By combining model-checking principles with CNN-based feature extraction and K-FCM clustering for segmentation, the proposed approach enhances the reliability of tumor detection and segmentation. Experimental results highlight the framework's effectiveness, achieving 98\% accuracy, 96.15\% precision, and 100\% recall, demonstrating its potential as a robust tool for advanced medical image analysis. 

**Abstract (ZH)**: 模型检查是一种形式验证技术，确保系统满足预定义的要求，从而在开发过程中最大程度地减少错误并提高质量。本文介绍了一种将模型检查与深度学习相结合的新颖混合框架，用于医疗影像中的脑肿瘤检测和验证。通过结合模型检查原理、基于CNN的特征提取以及K-FCM聚类进行分割，所提出的方法提升了肿瘤检测和分割的可靠性。实验结果表明该框架的有效性，准确率达到98%，精确率96.15%，召回率100%，展示了其作为先进医疗影像分析工具的潜力。 

---
# CRRG-CLIP: Automatic Generation of Chest Radiology Reports and Classification of Chest Radiographs 

**Title (ZH)**: CRRG-CLIP：胸部放射影像报告的自动生成与胸部X光片分类 

**Authors**: Jianfei Xu, Thanet Markchom, Huizhi Liang  

**Link**: [PDF](https://arxiv.org/pdf/2501.01989)  

**Abstract**: The complexity of stacked imaging and the massive number of radiographs make writing radiology reports complex and inefficient. Even highly experienced radiologists struggle to maintain accuracy and consistency in interpreting radiographs under prolonged high-intensity work. To address these issues, this work proposes the CRRG-CLIP Model (Chest Radiology Report Generation and Radiograph Classification Model), an end-to-end model for automated report generation and radiograph classification. The model consists of two modules: the radiology report generation module and the radiograph classification module. The generation module uses Faster R-CNN to identify anatomical regions in radiographs, a binary classifier to select key regions, and GPT-2 to generate semantically coherent reports. The classification module uses the unsupervised Contrastive Language Image Pretraining (CLIP) model, addressing the challenges of high-cost labelled datasets and insufficient features. The results show that the generation module performs comparably to high-performance baseline models on BLEU, METEOR, and ROUGE-L metrics, and outperformed the GPT-4o model on BLEU-2, BLEU-3, BLEU-4, and ROUGE-L metrics. The classification module significantly surpasses the state-of-the-art model in AUC and Accuracy. This demonstrates that the proposed model achieves high accuracy, readability, and fluency in report generation, while multimodal contrastive training with unlabelled radiograph-report pairs enhances classification performance. 

**Abstract (ZH)**: 医学影像堆叠成像的复杂性和成像数量的庞大使得编写放射报告变得复杂且效率低下。即使是非常有经验的放射科医生，在长时间高强度工作下也难以保持解释影像的准确性和一致性。为解决这些问题，本研究提出了一种端到端的模型——CRRG-CLIP模型（胸部放射报告生成和影像分类模型），该模型用于自动化报告生成和影像分类。该模型由两个模块组成：放射报告生成模块和影像分类模块。生成模块使用Faster R-CNN识别影像中的解剖区域，使用二分类器选择关键区域，并使用GPT-2生成语义连贯的报告。分类模块使用无监督的对比语言影像预训练（CLIP）模型，以应对高成本标记数据集和特征不足的问题。结果显示，生成模块在BLEU、METEOR和ROUGE-L指标上性能与高性能基准模型相当，并且在BLEU-2、BLEU-3、BLEU-4和ROUGE-L指标上优于GPT-4o模型。分类模块在AUC和准确率上显著优于最先进的模型。这表明，提出的模型在报告生成方面实现了高精度、可读性和流畅性，同时，多模态对比训练无标记的影像-报告对对提高了分类性能。 

---
# Gender Bias in Text-to-Video Generation Models: A case study of Sora 

**Title (ZH)**: 文本生成视频模型中的性别偏见：Sora的案例研究 

**Authors**: Mohammad Nadeem, Shahab Saquib Sohail, Erik Cambria, Björn W. Schuller, Amir Hussain  

**Link**: [PDF](https://arxiv.org/pdf/2501.01987)  

**Abstract**: The advent of text-to-video generation models has revolutionized content creation as it produces high-quality videos from textual prompts. However, concerns regarding inherent biases in such models have prompted scrutiny, particularly regarding gender representation. Our study investigates the presence of gender bias in OpenAI's Sora, a state-of-the-art text-to-video generation model. We uncover significant evidence of bias by analyzing the generated videos from a diverse set of gender-neutral and stereotypical prompts. The results indicate that Sora disproportionately associates specific genders with stereotypical behaviors and professions, which reflects societal prejudices embedded in its training data. 

**Abstract (ZH)**: 文本到视频生成模型的问世已经彻底改变了内容创作的方式，它能够从文本提示中生成高质量的视频。然而，人们对这类模型固有偏见的担忧促使了对其审查，尤其是对性别代表性方面的审查。本研究旨在调查OpenAI的Sora——一种最先进的文本到视频生成模型——是否存在性别偏见。我们通过对一系列性别中性和刻板印象提示生成的视频进行分析，发现了显著的偏见证据。研究结果表明，Sora 不公正地将特定性别与刻板行为和职业关联起来，这反映了其训练数据中嵌入的社会偏见。 

---
# FrameFusion: Combining Similarity and Importance for Video Token Reduction on Large Visual Language Models 

**Title (ZH)**: FrameFusion：结合相似性与重要性进行大视觉语言模型中视频令牌减少的方法 

**Authors**: Tianyu Fu, Tengxuan Liu, Qinghao Han, Guohao Dai, Shengen Yan, Huazhong Yang, Xuefei Ning, Yu Wang  

**Link**: [PDF](https://arxiv.org/pdf/2501.01986)  

**Abstract**: The increasing demand to process long and high-resolution videos significantly burdens Large Vision-Language Models (LVLMs) due to the enormous number of visual tokens. Existing token reduction methods primarily focus on importance-based token pruning, which overlooks the redundancy caused by frame resemblance and repetitive visual elements. In this paper, we analyze the high vision token similarities in LVLMs. We reveal that token similarity distribution condenses as layers deepen while maintaining ranking consistency. Leveraging the unique properties of similarity over importance, we introduce FrameFusion, a novel approach that combines similarity-based merging with importance-based pruning for better token reduction in LVLMs. FrameFusion identifies and merges similar tokens before pruning, opening up a new perspective for token reduction. We evaluate FrameFusion on diverse LVLMs, including Llava-Video-{7B,32B,72B}, and MiniCPM-V-8B, on video understanding, question-answering, and retrieval benchmarks. Experiments show that FrameFusion reduces vision tokens by 70$\%$, achieving 3.4-4.4x LLM speedups and 1.6-1.9x end-to-end speedups, with an average performance impact of less than 3$\%$. Our code is available at this https URL. 

**Abstract (ZH)**: 随着处理长时高分辨率视频的需求不断增加，这给大型视觉-语言模型（LVLM）带来了巨大负担，因为它们需要处理大量的视觉标记。现有的标记缩减方法主要集中在基于重要性的标记剪枝上，而忽略了由于帧相似性和重复视觉元素导致的冗余。本文分析了LVLM中的高视觉标记相似性。我们发现，随着层级的加深，标记相似性分布趋于集中，但保持了排名一致性。利用相似性和重要性之间的独特特性，我们提出了FrameFusion，这是一种将基于相似性的合并与基于重要性的剪枝相结合的新型方法，以在LVLM中实现更好的标记缩减。FrameFusion 在标记缩减前识别并合并相似的标记，为标记缩减提供了新的视角。我们在多种LVLM上评估了FrameFusion，包括Llava-Video-{7B,32B,72B} 和 MiniCPM-V-8B，并用于视频理解、问答和检索基准测试。实验表明，FrameFusion 可以将视觉标记减少70%，实现3.4-4.4倍的LLM加速和1.6-1.9倍的端到端加速，平均性能影响不到3%。我们的代码可在以下网址获取：[请插入网址]。 

---
# Fall Detection in Passenger Elevators using Intelligent Surveillance Camera Systems: An Application with YoloV8 Nano Model 

**Title (ZH)**: 使用智能监控摄像头系统在乘客电梯中进行跌倒检测：基于YoloV8 Nano模型的应用研究 

**Authors**: Pinar Yozgatli, Yavuz Acar, Mehmet Tulumen, Selman Minga, Salih Selamet, Beytullah Nalbant, Mustafa Talha Toru, Berna Koca, Tevfik Keles, Mehmet Selcok  

**Link**: [PDF](https://arxiv.org/pdf/2501.01985)  

**Abstract**: Computer vision technology, which involves analyzing images and videos captured by cameras through deep learning algorithms, has significantly advanced the field of human fall detection. This study focuses on the application of the YoloV8 Nano model in identifying fall incidents within passenger elevators, a context that presents unique challenges due to the enclosed environment and varying lighting conditions. By training the model on a robust dataset comprising over 10,000 images across diverse elevator types, we aim to enhance the detection precision and recall rates. The model's performance, with an 85% precision and 82% recall in fall detection, underscores its potential for integration into existing elevator safety systems to enable rapid intervention. 

**Abstract (ZH)**: 计算机视觉技术涉及通过深度学习算法分析摄像机捕捉到的图像和视频，显著推动了人体跌倒检测领域的进步。本研究关注的是将YoloV8 Nano模型应用于乘客电梯中跌倒事件的识别，这一应用场景由于封闭的环境和变化的照明条件而具有独特的挑战。通过在包含超过10,000张图像的稳健数据集上训练该模型，涵盖多种类型的电梯，旨在提高跌倒检测的准确率和召回率。该模型在跌倒检测方面的表现（准确率为85%，召回率为82%）突显了其集成到现有电梯安全系统中以实现快速干预的潜力。 

---
# Leveraging AI for Automatic Classification of PCOS Using Ultrasound Imaging 

**Title (ZH)**: 利用人工智能自动分类多囊卵巢综合征的超声成像方法 

**Authors**: Atharva Divekar, Atharva Sonawane  

**Link**: [PDF](https://arxiv.org/pdf/2501.01984)  

**Abstract**: The AUTO-PCOS Classification Challenge seeks to advance the diagnostic capabilities of artificial intelligence (AI) in identifying Polycystic Ovary Syndrome (PCOS) through automated classification of healthy and unhealthy ultrasound frames. This report outlines our methodology for building a robust AI pipeline utilizing transfer learning with the InceptionV3 architecture to achieve high accuracy in binary classification. Preprocessing steps ensured the dataset was optimized for training, validation, and testing, while interpretability methods like LIME and saliency maps provided valuable insights into the model's decision-making. Our approach achieved an accuracy of 90.52%, with precision, recall, and F1-score metrics exceeding 90% on validation data, demonstrating its efficacy. The project underscores the transformative potential of AI in healthcare, particularly in addressing diagnostic challenges like PCOS. Key findings, challenges, and recommendations for future enhancements are discussed, highlighting the pathway for creating reliable, interpretable, and scalable AI-driven medical diagnostic tools. 

**Abstract (ZH)**: 《自动PCOS分类挑战》致力于通过自动化分类健康和不健康的超声图像来提高人工智能（AI）在识别多囊卵巢综合征（PCOS）方面的诊断能力。本报告概述了我们利用InceptionV3架构的迁移学习构建稳健AI管道的方法，以实现二分类中的高精度。预处理步骤确保数据集优化了训练、验证和测试，而解释性方法如LIME和显著性图则提供了有关模型决策过程的重要见解。我们的方法在验证数据上的准确率达到90.52%，其精确率、召回率和F1得分均超过90%，显示出其有效性。该项目强调了AI在医疗保健领域的变革潜力，特别是在解决如PCOS等诊断挑战方面。报告讨论了关键发现、面临的问题以及未来改善的建议，突显了创建可靠、可解释和可扩展的AI驱动医疗诊断工具的道路。 

---
# ECG-guided individual identification via PPG 

**Title (ZH)**: 心电图引导的心率变异性个体识别 

**Authors**: Riling Wei, Hanjie Chen, Kelu Yao, Chuanguang Yang, Jun Wang, Chao Li  

**Link**: [PDF](https://arxiv.org/pdf/2501.01983)  

**Abstract**: Photoplethsmography (PPG)-based individual identification aiming at recognizing humans via intrinsic cardiovascular activities has raised extensive attention due to its high security and resistance to mimicry. However, this kind of technology witnesses unpromising results due to the limitation of low information density. To this end, electrocardiogram (ECG) signals have been introduced as a novel modality to enhance the density of input information. Specifically, a novel cross-modal knowledge distillation framework is implemented to propagate discriminate knowledge from ECG modality to PPG modality without incurring additional computational demands at the inference phase. Furthermore, to ensure efficient knowledge propagation, Contrastive Language-Image Pre-training (CLIP)-based knowledge alignment and cross-knowledge assessment modules are proposed respectively. Comprehensive experiments are conducted and results show our framework outperforms the baseline model with the improvement of 2.8% and 3.0% in terms of overall accuracy on seen- and unseen individual recognitions. 

**Abstract (ZH)**: 基于光电容积脉搏波谱仪（PPG）的心内血管活动进行的人体鉴别研究，由于其高安全性和对抗冒充的强抵抗性，引起了广泛关注。然而，由于低信息密度的限制，这种技术取得了不太理想的结果。为了解决这一问题，引入了心电图（ECG）信号作为新的模态，以提高输入信息的密度。具体地，实现了一种新的跨模态知识蒸馏框架，该框架可以在不增加推理阶段的计算需求的情况下，从ECG模态向PPG模态传播 discriminative 知识。此外，为了确保有效的知识传播，提出了基于CLIP（对比语言-图像预训练）的知识对齐模块和跨知识评估模块。开展了全面的实验，结果显示，与基础模型相比，我们的框架在识别已见过和未见过个人的总体准确性上分别提高了2.8%和3.0%。 

---
# Is Your Image a Good Storyteller? 

**Title (ZH)**: 你的图像是一个好的叙述者吗？ 

**Authors**: Xiujie Song, Xiaoyi Pang, Haifeng Tang, Mengyue Wu, Kenny Q. Zhu  

**Link**: [PDF](https://arxiv.org/pdf/2501.01982)  

**Abstract**: Quantifying image complexity at the entity level is straightforward, but the assessment of semantic complexity has been largely overlooked. In fact, there are differences in semantic complexity across images. Images with richer semantics can tell vivid and engaging stories and offer a wide range of application scenarios. For example, the Cookie Theft picture is such a kind of image and is widely used to assess human language and cognitive abilities due to its higher semantic complexity. Additionally, semantically rich images can benefit the development of vision models, as images with limited semantics are becoming less challenging for them. However, such images are scarce, highlighting the need for a greater number of them. For instance, there is a need for more images like Cookie Theft to cater to people from different cultural backgrounds and eras. Assessing semantic complexity requires human experts and empirical evidence. Automatic evaluation of how semantically rich an image will be the first step of mining or generating more images with rich semantics, and benefit human cognitive assessment, Artificial Intelligence, and various other applications. In response, we propose the Image Semantic Assessment (ISA) task to address this problem. We introduce the first ISA dataset and a novel method that leverages language to solve this vision problem. Experiments on our dataset demonstrate the effectiveness of our approach. Our data and code are available at: this https URL. 

**Abstract (ZH)**: 在实体水平上量化图像的复杂性相对简单，但对语义复杂性的评估却往往被忽视。事实上，不同图像之间的语义复杂性是有所差异的。语义丰富的图像能够讲出生动有趣的故事，并提供广泛的应用场景。例如，“偷饼干”的图片就是一个这样的例子，它因其较高的语义复杂性广泛用于评估人类的语言和认知能力。此外，语义丰富的图像有助于视觉模型的发展，因为具有有限语义的图像对它们来说变得不再具有挑战性了。然而，这类图像稀缺，突显了需要增加它们的数量。例如，为了适应来自不同文化背景和时代的受众，需要更多的类似于“偷饼干”的图像。评估语义复杂性需要人工专家和实证证据。自动评估一张图像的语义丰富度是挖掘或生成更多语义丰富的图像的第一步，这将有利于人类的认知评估、人工智能以及各种其他应用。为此，我们提出了一项图像语义评估（ISA）任务来解决这个问题。我们介绍了第一个ISA数据集，并提出了一种利用语言解决这一视觉问题的全新方法。在我们数据集上的实验结果证明了我们方法的有效性。我们的数据和代码可在以下链接获取：[这里提供链接]。 

---
# Hawkes based Representation Learning for Reasoning over Scale-free Community-structured Temporal Knowledge Graphs 

**Title (ZH)**: 基于霍夫克斯的表示学习方法在无标度社区结构化时序知识图谱中的推理研究 

**Authors**: Yuwei Du, Xinyue Liu, Wenxin Liang, Linlin Zong, Xianchao Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2501.01974)  

**Abstract**: Temporal knowledge graph (TKG) reasoning has become a hot topic due to its great value in many practical tasks. The key to TKG reasoning is modeling the structural information and evolutional patterns of the TKGs. While great efforts have been devoted to TKG reasoning, the structural and evolutional characteristics of real-world networks have not been considered. In the aspect of structure, real-world networks usually exhibit clear community structure and scale-free (long-tailed distribution) properties. In the aspect of evolution, the impact of an event decays with the time elapsing. In this paper, we propose a novel TKG reasoning model called Hawkes process-based Evolutional Representation Learning Network (HERLN), which learns structural information and evolutional patterns of a TKG simultaneously, considering the characteristics of real-world networks: community structure, scale-free and temporal decaying. First, we find communities in the input TKG to make the encoding get more similar intra-community embeddings. Second, we design a Hawkes process-based relational graph convolutional network to cope with the event impact-decaying phenomenon. Third, we design a conditional decoding method to alleviate biases towards frequent entities caused by long-tailed distribution. Experimental results show that HERLN achieves significant improvements over the state-of-the-art models. 

**Abstract (ZH)**: 时序知识图谱（Temporal Knowledge Graph, TKG）推理已成为一个热点话题，因其在许多实际任务中的巨大价值。TKG推理的关键在于建模TKG的结构性信息和演变规律。尽管在TKG推理方面已经做出了巨大努力，但现实网络的结构性和演变特性尚未得到充分考虑。从结构性来看，现实网络通常表现出明显的社区结构和无标度（长尾分布）特性。在演变方面，事件的影响会随时间的推移而减弱。在本文中，我们提出了一种基于霍克斯过程的演变表示学习网络（HERLN, Hawkes Process-based Evolutional Representation Learning Network），该模型可以同时学习TKG的结构性信息和演变规律，并考虑现实网络的特性：社区结构、无标度特性和时间衰减。具体来说，首先，我们在输入TKG中找到社区，以使编码获得更相似的社区内嵌入。其次，我们设计了一种基于霍克斯过程的关系图卷积网络来应对事件影响衰减的现象。第三，我们设计了一种条件解码方法来缓解由长尾分布引起的频繁实体的偏倚。实验结果表明，HERLN 在性能上显著优于现有最先进的模型。 

---
# INFELM: In-depth Fairness Evaluation of Large Text-To-Image Models 

**Title (ZH)**: INFELM：大型文本到图像模型的深入公平性评估 

**Authors**: Di Jin, Xing Liu, Yu Liu, Jia Qing Yap, Andrea Wong, Adriana Crespo, Qi Lin, Zhiyuan Yin, Qiang Yan, Ryan Ye  

**Link**: [PDF](https://arxiv.org/pdf/2501.01973)  

**Abstract**: The rapid development of large language models (LLMs) and large vision models (LVMs) have propelled the evolution of multi-modal AI systems, which have demonstrated the remarkable potential for industrial applications by emulating human-like cognition. However, they also pose significant ethical challenges, including amplifying harmful content and reinforcing societal biases. For instance, biases in some industrial image generation models highlighted the urgent need for robust fairness assessments. Most existing evaluation frameworks focus on the comprehensiveness of various aspects of the models, but they exhibit critical limitations, including insufficient attention to content generation alignment and social bias-sensitive domains. More importantly, their reliance on pixel-detection techniques is prone to inaccuracies.
To address these issues, this paper presents INFELM, an in-depth fairness evaluation on widely-used text-to-image models. Our key contributions are: (1) an advanced skintone classifier incorporating facial topology and refined skin pixel representation to enhance classification precision by at least 16.04%, (2) a bias-sensitive content alignment measurement for understanding societal impacts, (3) a generalizable representation bias evaluation for diverse demographic groups, and (4) extensive experiments analyzing large-scale text-to-image model outputs across six social-bias-sensitive domains. We find that existing models in the study generally do not meet the empirical fairness criteria, and representation bias is generally more pronounced than alignment errors. INFELM establishes a robust benchmark for fairness assessment, supporting the development of multi-modal AI systems that align with ethical and human-centric principles. 

**Abstract (ZH)**: 大型语言模型（LLMs）和大型视觉模型（LVMs）的迅速发展推动了多模态人工智能系统的演变，这些系统通过模拟人类认知展示了显著的工业应用潜力。然而，它们也带来了重大的伦理挑战，包括放大有害内容和加剧社会偏见。例如，一些工业图像生成模型中存在的偏见突显了加强对公平性的稳健评估的迫切需求。目前大多数评估框架侧重于评估模型各方面内容的全面性，但这些框架存在关键局限性，包括对内容生成对齐关注不足以及对社会偏见敏感领域的不足。更为重要的是，它们依赖于像素检测技术，容易导致不准确的评估结果。

为解决这些问题，本文提出了一种名为INFELM的深度公平性评估方法，专门针对广泛使用的文本到图像模型。我们的主要贡献包括：（1）一种先进的肤色分类器，结合面部拓扑结构和细化的皮肤像素表示，可提高分类精度至少16.04%；（2）一种社会偏见敏感的内容对齐度量，用于理解社会影响；（3）一种泛化的表示偏见评估方法，适用于多元化的demographic群体；（4）对六个社会偏见敏感领域的大型文本到图像模型输出进行了广泛实验分析。我们的研究发现，现有模型在研究中普遍未能满足实证公平性的标准，表示偏见相对于对齐误差更加突出。INFELM为公平性评估提供了稳健的基准，支持符合伦理和以人为中心原则的多模态人工智能系统的发展。 

---
# Optimal bounds for dissatisfaction in perpetual voting 

**Title (ZH)**: perpetual voting 指的是持续或不断的投票过程，这与传统的定期选举不同。给定的标题“Optimal Bounds for Dissatisfaction in Perpetual Voting”可以翻译为：

“持续投票中不满意程度的最优界” 

**Authors**: Alexander Kozachinskiy, Alexander Shen, Tomasz Steifer  

**Link**: [PDF](https://arxiv.org/pdf/2501.01969)  

**Abstract**: In perpetual voting, multiple decisions are made at different moments in time. Taking the history of previous decisions into account allows us to satisfy properties such as proportionality over periods of time. In this paper, we consider the following question: is there a perpetual approval voting method that guarantees that no voter is dissatisfied too many times? We identify a sufficient condition on voter behavior -- which we call 'bounded conflicts' condition -- under which a sublinear growth of dissatisfaction is possible. We provide a tight upper bound on the growth of dissatisfaction under bounded conflicts, using techniques from Kolmogorov complexity. We also observe that the approval voting with binary choices mimics the machine learning setting of prediction with expert advice. This allows us to present a voting method with sublinear guarantees on dissatisfaction under bounded conflicts, based on the standard techniques from prediction with expert advice. 

**Abstract (ZH)**: 在持续投票中，不同时刻会做出多个决策。考虑到以前决策的历史，我们可以满足一定时期内的比例性等性质。在本文中，我们将考虑以下问题：是否存在一种持续的批准投票方法，能够保证没有选民被频繁不满意？我们确定了一个选民行为的充分条件——我们称之为“有界冲突”条件，在该条件下，不满意程度的非线性增长是可能的。我们使用科尔莫哥洛夫复杂性的技术，提供了在有界冲突下不满意程度的紧致上界。同时，我们观察到二元选择的批准投票类似于机器学习中的专家建议预测设置，这使得我们可以基于专家建议预测的标准技术，提出一种在有界冲突下不满意程度有非线性保证的投票方法。 

---
# Statistical learning does not always entail knowledge 

**Title (ZH)**: 统计学习并不总是蕴含知识 

**Authors**: Daniel Andrés Díaz-Pachón, H. Renata Gallegos, Ola Hössjer, J. Sunil Rao  

**Link**: [PDF](https://arxiv.org/pdf/2501.01963)  

**Abstract**: In this paper, we study learning and knowledge acquisition (LKA) of an agent about a proposition that is either true or false. We use a Bayesian approach, where the agent receives data to update his beliefs about the proposition according to a posterior distribution. The LKA is formulated in terms of active information, with data representing external or exogenous information that modifies the agent's beliefs. It is assumed that data provide details about a number of features that are relevant to the proposition. We show that this leads to a Gibbs distribution posterior, which is in maximum entropy relative to the prior, conditioned on the side constraints that the data provide in terms of the features. We demonstrate that full learning is sometimes not possible and full knowledge acquisition is never possible when the number of extracted features is too small. We also distinguish between primary learning (receiving data about features of relevance for the proposition) and secondary learning (receiving data about the learning of another agent). We argue that this type of secondary learning does not represent true knowledge acquisition. Our results have implications for statistical learning algorithms, and we claim that such algorithms do not always generate true knowledge. The theory is illustrated with several examples. 

**Abstract (ZH)**: 在本文中，我们研究智能体关于某个命题（该命题为真或假）的学习和知识获取（LKA）。我们采用贝叶斯方法，其中智能体接收数据以根据后验分布更新其对该命题的信念。LKA 用主动信息的形式进行表述，其中数据代表外部或外生信息，对智能体的信念进行修改。假定数据包含关于命题相关特征的详细信息。我们证明这导致了格波斯分布的后验，该后验在条件概率下相对于先验信息具有最大熵，其中的条件是数据在特征方面的限制。我们表明，当提取的特征数量太少时，全面学习有时是不可能的，而全面的知识获取更是不可能的。此外，我们区分两种类型的学习：首要学习（接收关于命题相关特征的数据）和次级学习（接收关于另一智能体的学习数据）。我们认为这种次级学习并不真正代表知识的获取。这些结果对统计学习算法具有重要意义，我们提出这些算法并不总是生成真正知识。我们通过几个示例说明了该理论。 

---
# GAF-FusionNet: Multimodal ECG Analysis via Gramian Angular Fields and Split Attention 

**Title (ZH)**: GAF-FusionNet：基于Gram.angular字段和分割注意力机制的多模态心电图分析 

**Authors**: Jiahao Qin, Feng Liu  

**Link**: [PDF](https://arxiv.org/pdf/2501.01960)  

**Abstract**: Electrocardiogram (ECG) analysis plays a crucial role in diagnosing cardiovascular diseases, but accurate interpretation of these complex signals remains challenging. This paper introduces a novel multimodal framework(GAF-FusionNet) for ECG classification that integrates time-series analysis with image-based representation using Gramian Angular Fields (GAF). Our approach employs a dual-layer cross-channel split attention module to adaptively fuse temporal and spatial features, enabling nuanced integration of complementary information. We evaluate GAF-FusionNet on three diverse ECG datasets: ECG200, ECG5000, and the MIT-BIH Arrhythmia Database. Results demonstrate significant improvements over state-of-the-art methods, with our model achieving 94.5\%, 96.9\%, and 99.6\% accuracy on the respective datasets. Our code will soon be available at this https URL. 

**Abstract (ZH)**: 心电图（ECG）分析在心血管疾病诊断中起着关键作用，但准确解读这些复杂的信号仍然具有挑战性。本文介绍了一种新颖的多模态框架（GAF-FusionNet），该框架将时间序列分析与基于图像的表示方法（Gramian Angular Fields，GAF）相结合，以提高ECG分类的准确性。我们的方法采用了双层跨通道分注意力模块，以自适应地融合时序和空间特征，从而实现互补信息的精细化整合。我们使用GAF-FusionNet在三个不同的ECG数据集（ECG200、ECG5000和MIT-BIH心律失常数据库）上进行了评估。结果表明，该模型在各数据集上的准确率分别为94.5%、96.9%和99.6%，显著优于现有最先进的方法。我们将在不久的将来在以下链接提供代码：这个 https URL。 

---
# STEAM-EEG: Spatiotemporal EEG Analysis with Markov Transfer Fields and Attentive CNNs 

**Title (ZH)**: STEAM-EEG：基于马尔可夫转移场和注意力卷积神经网络的时空脑电图分析 

**Authors**: Jiahao Qin, Feng Liu  

**Link**: [PDF](https://arxiv.org/pdf/2501.01959)  

**Abstract**: Electroencephalogram (EEG) signals play a pivotal role in biomedical research and clinical applications, including epilepsy diagnosis, sleep disorder analysis, and brain-computer interfaces. However, the effective analysis and interpretation of these complex signals often present significant challenges. This paper presents a novel approach that integrates computer graphics techniques with biological signal pattern recognition, specifically using Markov Transfer Fields (MTFs) for EEG time series imaging. The proposed framework (STEAM-EEG) employs the capabilities of MTFs to capture the spatiotemporal dynamics of EEG signals, transforming them into visually informative images. These images are then rendered, visualised, and modelled using state-of-the-art computer graphics techniques, thereby facilitating enhanced data exploration, pattern recognition, and decision-making. The code could be accessed from GitHub. 

**Abstract (ZH)**: 脑电图（EEG）信号在生物医学研究和临床应用中扮演着重要角色，包括癫痫诊断、睡眠障碍分析和脑-机接口。然而，这些复杂信号的有效分析和解释往往存在显著挑战。本文提出了一种创新方法，将计算机图形技术与生物信号模式识别相结合，特别利用马尔可夫转移场（Markov Transfer Fields, MTFs）对脑电信号进行时间序列成像。所提出的框架（STEAM-EEG）利用MTFs的能力捕捉EEG信号的空间时间动态，并将它们转换为具有视觉信息的图像。这些图像随后使用最新的计算机图形技术进行渲染、可视化和建模，从而促进数据探索、模式识别和决策过程。代码可以从GitHub获取。 

---
