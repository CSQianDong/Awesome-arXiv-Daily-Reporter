{'arxiv_id': 'arXiv:2501.17860', 'title': 'Dialogue is Better Than Monologue: Instructing Medical LLMs via Strategical Conversations', 'authors': 'Zijie Liu, Xinyu Zhao, Jie Peng, Zhuangdi Zhu, Qingyu Chen, Xia Hu, Tianlong Chen', 'link': 'https://arxiv.org/abs/2501.17860', 'abstract': 'Current medical AI systems often fail to replicate real-world clinical reasoning, as they are predominantly trained and evaluated on static text and question-answer tasks. These tuning methods and benchmarks overlook critical aspects like evidence-based reasoning and handling distracting information. To bridge this gap, we introduce a novel benchmark that simulates real-world diagnostic scenarios, integrating noise and difficulty levels aligned with USMLE standards. Moreover, we explore dialogue-based fine-tuning, which transforms static datasets into conversational formats to better capture iterative reasoning processes. Experiments show that dialogue-tuned models outperform traditional methods, with improvements of $9.64\\%$ in multi-round reasoning scenarios and $6.18\\%$ in accuracy in a noisy environment. Our findings highlight dialogue tuning as a promising approach for advancing clinically aligned and robust medical AI systems.', 'abstract_zh': '当前的医疗AI系统经常难以复制现实生活中的临床推理，因为它们主要是在静态文本和问答任务上进行训练和评估。这些调优方法和基准标准忽视了证据推理和处理干扰信息等关键方面。为解决这一问题，我们介绍了一种新的基准测试，该基准测试模拟了现实世界的诊断场景，并且噪声和难度级别与USMLE标准相一致。此外，我们还探索基于对话的微调，将其静态数据集转换为对话格式，以更好地捕捉迭代推理过程。实验表明，对话微调后的模型优于传统方法，在多轮推理场景中的表现提高了9.64%，在嘈杂环境中准确性的提高为6.18%。我们的研究结果强调了对话微调作为促进临床对齐和稳健医疗AI系统的有前途的方法。', 'title_zh': '对话胜于独白：通过策略性对话指导医疗大语言模型'}
{'arxiv_id': 'arXiv:2501.17858', 'title': 'Improving Your Model Ranking on Chatbot Arena by Vote Rigging', 'authors': 'Rui Min, Tianyu Pang, Chao Du, Qian Liu, Minhao Cheng, Min Lin', 'link': 'https://arxiv.org/abs/2501.17858', 'abstract': 'Chatbot Arena is a popular platform for evaluating LLMs by pairwise battles, where users vote for their preferred response from two randomly sampled anonymous models. While Chatbot Arena is widely regarded as a reliable LLM ranking leaderboard, we show that crowdsourced voting can be rigged to improve (or decrease) the ranking of a target model $m_{t}$. We first introduce a straightforward target-only rigging strategy that focuses on new battles involving $m_{t}$, identifying it via watermarking or a binary classifier, and exclusively voting for $m_{t}$ wins. However, this strategy is practically inefficient because there are over $190$ models on Chatbot Arena and on average only about $1\\%$ of new battles will involve $m_{t}$. To overcome this, we propose omnipresent rigging strategies, exploiting the Elo rating mechanism of Chatbot Arena that any new vote on a battle can influence the ranking of the target model $m_{t}$, even if $m_{t}$ is not directly involved in the battle. We conduct experiments on around $1.7$ million historical votes from the Chatbot Arena Notebook, showing that omnipresent rigging strategies can improve model rankings by rigging only hundreds of new votes. While we have evaluated several defense mechanisms, our findings highlight the importance of continued efforts to prevent vote rigging. Our code is available at this https URL.', 'abstract_zh': '聊天机器人大擂台是一个流行的平台，用于通过一对一战斗来评估语言模型（LLMs）。在这个平台上，用户可以在两个随机抽取的匿名模型之间投票，选择他们更喜欢的回复。虽然聊天机器人大擂台普遍被视为一个可靠的LLM排名排行榜，但我们展示了通过网络众包投票可以操纵来提升（或降低）目标模型$m_{t}$的排名。我们首先介绍了一种简单的目标模型定向操纵策略，这种方法专注于新加入的与$m_{t}$相关的战斗，利用水印或二元分类器来识别$m_{t}$，并通过专门投票让$m_{t}$获胜。然而，这种方法实际上效率低下，因为聊天机器人大擂台上有超过190个模型，而平均来看，仅约1%的新战斗会涉及$m_{t}$。为克服这一问题，我们提出了无处不在的操纵策略，利用了聊天机器人大擂台的Elo排名机制，即使$m_{t}$并未直接参与战斗，每个新投票都可以影响目标模型$m_{t}$的排名。我们通过对聊天机器人大擂台上约170万个历史投票进行实验，展示了无处不在的操纵策略能够通过操纵少量的新投票来提升模型的排名。虽然我们已经评估了几种防御机制，但我们的研究结果强调了继续努力防止投票操纵的重要性。我们的代码可在以下链接获取：this https URL。', 'title_zh': '通过投票作弊提高您在聊天机器人竞技场中的模型排名'}
{'arxiv_id': 'arXiv:2501.17840', 'title': "Learning Beyond the Surface: How Far Can Continual Pre-Training with LoRA Enhance LLMs' Domain-Specific Insight Learning?", 'authors': 'Pouya Pezeshkpour, Estevam Hruschka', 'link': 'https://arxiv.org/abs/2501.17840', 'abstract': "Large Language Models (LLMs) have demonstrated remarkable performance on various tasks, yet their ability to extract and internalize deeper insights from domain-specific datasets remains underexplored. In this study, we investigate how continual pre-training can enhance LLMs' capacity for insight learning across three distinct forms: declarative, statistical, and probabilistic insights. Focusing on two critical domains: medicine and finance, we employ LoRA to train LLMs on two existing datasets. To evaluate each insight type, we create benchmarks to measure how well continual pre-training helps models go beyond surface-level knowledge. We also assess the impact of document modification on capturing insights. The results show that, while continual pre-training on original documents has a marginal effect, modifying documents to retain only essential information significantly enhances the insight-learning capabilities of LLMs.", 'abstract_zh': '大型语言模型（LLMs）在各种任务上展现了出色的性能，但在提取和内化特定领域的深层次洞察方面的能力仍未得到充分探索。本研究旨在考察连续预训练如何增强LLMs在三种不同形式的洞察学习上的能力：声明性洞察、统计性洞察和概率性洞察。我们以医学和金融这两个关键领域为重点，利用LoRA对现有的两个数据集进行训练。为了评估每种洞察类型的效果，我们创建了基准测试来衡量连续预训练如何帮助模型超越表面知识。我们还评估了文档修改对捕捉洞察的影响。研究结果表明，尽管对原始文档进行连续预训练的效果有限，但保留仅有关键信息的文档修改显著增强了LLMs的洞察学习能力。', 'title_zh': '超越表面学习：持续预训练方法LoRA能否在多大程度上增强大规模语言模型在特定领域洞察力的学习？'}
{'arxiv_id': 'arXiv:2501.17830', 'title': 'A Comprehensive Survey on Legal Summarization: Challenges and Future Directions', 'authors': 'Mousumi Akter, Erion Cano, Erik Weber, Dennis Dobler, Ivan Habernal', 'link': 'https://arxiv.org/abs/2501.17830', 'abstract': "This article provides a systematic up-to-date survey of automatic summarization techniques, datasets, models, and evaluation methods in the legal domain. Through specific source selection criteria, we thoroughly review over 120 papers spanning the modern `transformer' era of natural language processing (NLP), thus filling a gap in existing systematic surveys on the matter. We present existing research along several axes and discuss trends, challenges, and opportunities for future research.", 'abstract_zh': '本文提供了一个全面且最新的人工智能摘要技术在法律领域的综述，涵盖了该领域的数据集、模型和评估方法。我们通过具体的数据来源选择标准，全面回顾了超过120篇现代自然语言处理（NLP）「变换器」时代的相关论文，从而填补了该领域现有系统综述中的空白。我们从多个维度呈现现有研究，并讨论了未来研究的趋势、挑战和机遇。', 'title_zh': '全面综述法律摘要化：面临的挑战与未来方向'}
{'arxiv_id': 'arXiv:2501.17790', 'title': 'BreezyVoice: Adapting TTS for Taiwanese Mandarin with Enhanced Polyphone Disambiguation -- Challenges and Insights', 'authors': 'Chan-Jan Hsu, Yi-Cheng Lin, Chia-Chun Lin, Wei-Chih Chen, Ho Lam Chung, Chen-An Li, Yi-Chang Chen, Chien-Yu Yu, Ming-Ji Lee, Chien-Cheng Chen, Ru-Heng Huang, Hung-yi Lee, Da-Shan Shiu', 'link': 'https://arxiv.org/abs/2501.17790', 'abstract': "We present BreezyVoice, a Text-to-Speech (TTS) system specifically adapted for Taiwanese Mandarin, highlighting phonetic control abilities to address the unique challenges of polyphone disambiguation in the language. Building upon CosyVoice, we incorporate a $S^{3}$ tokenizer, a large language model (LLM), an optimal-transport conditional flow matching model (OT-CFM), and a grapheme to phoneme prediction model, to generate realistic speech that closely mimics human utterances. Our evaluation demonstrates BreezyVoice's superior performance in both general and code-switching contexts, highlighting its robustness and effectiveness in generating high-fidelity speech. Additionally, we address the challenges of generalizability in modeling long-tail speakers and polyphone disambiguation. Our approach significantly enhances performance and offers valuable insights into the workings of neural codec TTS systems.", 'abstract_zh': '我们介绍了BreezyVoice，这是一个专门为台湾 Mandarin 设计的文本到语音（TTS）系统，重点突出了其在应对语言中多音字消歧这一独特挑战方面的音素控制能力。该系统基于CosyVoice构建，集成了一个 $S^{3}$ 分词器、一个大型语言模型（LLM）、一个最优运输条件流匹配模型（OT-CFM）和一个从字符到音素的预测模型，从而生成逼真且接近人类语音的语音。评估结果表明，BreezyVoice 在一般场景和代码切换场景中均表现出优越的性能，展示了其在生成高保真语音方面的稳定性和有效性。此外，我们还解决了建模长尾群体和多音字消歧的挑战。我们的方法显著提高了性能，并为神经编解码器TTS系统的运作机制提供了宝贵的见解。', 'title_zh': '"BreezyVoice：强化多音字消歧的台湾普通话TTS适应——挑战与见解"'}
{'arxiv_id': 'arXiv:2501.17785', 'title': "Reasoning Over the Glyphs: Evaluation of LLM's Decipherment of Rare Scripts", 'authors': 'Yu-Fei Shih, Zheng-Lin Lin, Shu-Kai Hsieh', 'link': 'https://arxiv.org/abs/2501.17785', 'abstract': "We explore the capabilities of LVLMs and LLMs in deciphering rare scripts not encoded in Unicode. We introduce a novel approach to construct a multimodal dataset of linguistic puzzles involving such scripts, utilizing a tokenization method for language glyphs. Our methods include the Picture Method for LVLMs and the Description Method for LLMs, enabling these models to tackle these challenges. We conduct experiments using prominent models, GPT-4o, Gemini, and Claude 3.5 Sonnet, on linguistic puzzles. Our findings reveal the strengths and limitations of current AI methods in linguistic decipherment, highlighting the impact of Unicode encoding on model performance and the challenges of modeling visual language tokens through descriptions. Our study advances understanding of AI's potential in linguistic decipherment and underscores the need for further research.", 'abstract_zh': '我们探讨了低维语言模型（LVLMs）和大规模语言模型（LLMs）在解码未被Unicode编码的稀有文字方面的能力。我们提出了一个创新方法，构建了一个涉及此类文字的语言谜题多模态数据集，利用语言字符的子化方法。我们的方法包括LVLMs的图像法和LLMs的描述法，使这些模型能够应对这些挑战。我们使用GPT-4o、Gemini和Claude 3.5 Sonnet等主流模型，在语言谜题上进行了实验。研究结果揭示了当前AI方法在语言解码方面的优势和局限性，突显了Unicode编码对模型性能的影响以及通过描述建模视觉语言标记的挑战。我们的研究深化了对AI在语言解码方面潜力的理解，并强调了进一步研究的必要性。', 'title_zh': '基于字符进行推理：评估大语言模型对稀有字体的释读能力'}
{'arxiv_id': 'arXiv:2501.17771', 'title': '2SSP: A Two-Stage Framework for Structured Pruning of LLMs', 'authors': 'Fabrizio Sandri, Elia Cunegatti, Giovanni Iacca', 'link': 'https://arxiv.org/abs/2501.17771', 'abstract': 'We propose a novel Two-Stage framework for Structured Pruning (2SSP) for pruning Large Language Models (LLMs), which combines two different strategies of pruning, namely Width and Depth Pruning. The first stage (Width Pruning) removes entire neurons, hence their corresponding rows and columns, aiming to preserve the connectivity among the pruned structures in the intermediate state of the Feed-Forward Networks in each Transformer block. This is done based on an importance score measuring the impact of each neuron over the output magnitude. The second stage (Depth Pruning), instead, removes entire Attention submodules. This is done by applying an iterative process that removes the Attention submodules with the minimum impact on a given metric of interest (in our case, perplexity). We also propose a novel mechanism to balance the sparsity rate of the two stages w.r.t. to the desired global sparsity. We test 2SSP on four LLM families and three sparsity rates (25\\%, 37.5\\%, and 50\\%), measuring the resulting perplexity over three language modeling datasets as well as the performance over six downstream tasks. Our method consistently outperforms five state-of-the-art competitors over three language modeling and six downstream tasks, with an up to two-order-of-magnitude gain in terms of pruning time. The code is available at available at \\url{this https URL}.', 'abstract_zh': '我们提出了一种新颖的两阶段框架（Two-Stage Structured Pruning, 2SSP）用于剪枝大型语言模型（Large Language Models, LLMs），该框架结合了两种不同的剪枝策略，即宽度剪枝（Width Pruning）和深度剪枝（Depth Pruning）。第一阶段（宽度剪枝）移除整个神经元及其对应的行和列，以保持在每个Transformer块的前向网络中剪枝结构之间的连接性。这基于一个衡量每个神经元对输出幅度影响的重要性得分来进行。第二阶段（深度剪枝）则移除整个注意力子模块。这通过迭代过程实现，该过程根据给定的目标度量值（在我们的情况下为困惑度）移除影响最小的注意力子模块。我们还提出了一种新的机制，用于平衡两个阶段的稀疏率，使其符合期望的全局稀疏率。我们在四种LLM系列上测试了2SSP，在三种语言模型数据集上测量了结果的困惑度，并在六个下游任务上评估了性能。我们的方法在三种语言模型和六个下游任务上均优于五种最先进的竞争对手，剪枝时间可提高两个数量级。代码可在<https://this-url> 获取。', 'title_zh': '2SSP：LLMs结构化剪枝的两阶段框架'}
{'arxiv_id': 'arXiv:2501.17767', 'title': 'Hybrid Graphs for Table-and-Text based Question Answering using LLMs', 'authors': 'Ankush Agarwal, Ganesh S, Chaitanya Devaguptapu', 'link': 'https://arxiv.org/abs/2501.17767', 'abstract': 'Answering questions that require reasoning and aggregation across both structured (tables) and unstructured (raw text) data sources presents significant challenges. Current methods rely on fine-tuning and high-quality, human-curated data, which is difficult to obtain. Recent advances in Large Language Models (LLMs) have shown promising results for multi-hop question answering (QA) over single-source text data in a zero-shot setting, yet exploration into multi-source Table-Text QA remains limited. In this paper, we present a novel Hybrid Graph-based approach for Table-Text QA that leverages LLMs without fine-tuning. Our method constructs a unified Hybrid Graph from textual and tabular data, pruning information based on the input question to provide the LLM with relevant context concisely. We evaluate our approach on the challenging Hybrid-QA and OTT-QA datasets using state-of-the-art LLMs, including GPT-3.5, GPT-4, and LLaMA-3. Our method achieves the best zero-shot performance on both datasets, improving Exact Match scores by up to 10% on Hybrid-QA and 5.4% on OTT-QA. Moreover, our approach reduces token usage by up to 53% compared to the original context.', 'abstract_zh': '跨结构化（表格）和非结构化（原始文本）数据源进行推理和聚合以回答问题，这一过程面临着巨大的挑战。当前的方法依赖于微调和高质量的人工标注数据，但这些数据获取起来非常困难。最近，大规模语言模型（LLMs）在零样本设置下对单源文本数据进行多跳问答方面取得了令人鼓舞的结果，但在表文多源问答方面的研究仍相对有限。在本文中，我们提出了一种新颖的基于混合图的方法来解决表文多源问答问题，该方法无需微调即可利用LLMs。我们的方法从文本和表格数据中构建一个统一的混合图，并根据输入问题筛选信息，以便为LLMs提供简洁的相关背景信息。我们使用最新的LLMs（包括GPT-3.5、GPT-4和LLaMA-3）在具有挑战性的Hybrid-QA和OTT-QA数据集上评估了我们的方法。我们的方法在两个数据集上的零样本性能最佳，分别在Hybrid-QA数据集上将精确匹配分数提高了10%，在OTT-QA数据集上提高了5.4%。此外，我们的方法相比于原始上下文将标记使用的数量减少了53%。', 'title_zh': '基于LLMs的表格和文本问答的混合图模型'}
{'arxiv_id': 'arXiv:2501.17715', 'title': 'RICoTA: Red-teaming of In-the-wild Conversation with Test Attempts', 'authors': 'Eujeong Choi, Younghun Jeong, Soomin Kim, Won Ik Cho', 'link': 'https://arxiv.org/abs/2501.17715', 'abstract': 'User interactions with conversational agents (CAs) evolve in the era of heavily guardrailed large language models (LLMs). As users push beyond programmed boundaries to explore and build relationships with these systems, there is a growing concern regarding the potential for unauthorized access or manipulation, commonly referred to as "jailbreaking." Moreover, with CAs that possess highly human-like qualities, users show a tendency toward initiating intimate sexual interactions or attempting to tame their chatbots. To capture and reflect these in-the-wild interactions into chatbot designs, we propose RICoTA, a Korean red teaming dataset that consists of 609 prompts challenging LLMs with in-the-wild user-made dialogues capturing jailbreak attempts. We utilize user-chatbot conversations that were self-posted on a Korean Reddit-like community, containing specific testing and gaming intentions with a social chatbot. With these prompts, we aim to evaluate LLMs\' ability to identify the type of conversation and users\' testing purposes to derive chatbot design implications for mitigating jailbreaking risks. Our dataset will be made publicly available via GitHub.', 'abstract_zh': '在高度限制的大语言模型（LLMs）时代，用户与对话型智能代理（CAs）的互动方式正在发生变化。随着用户超越既定界限去探索并与这些系统建立关系，未经授权的访问或操控（通常称为“越狱”）的可能性引起了越来越多的关注。此外，由于CAs具备高度的人类特质，用户倾向于发起亲密的性互动或试图驯服其聊天机器人。为了捕捉并反映这些真实的互动模式，我们提出了RICoTA，这是一个包含609个挑战LLMs的韩语红队测试数据集，这些数据集捕捉了用户自制的对话，展示了越狱尝试。我们利用自发布于类似韩国Reddit的社区中用户与聊天机器人之间的对话，这些对话包含了对社交聊天机器人的具体测试和游戏意图。通过这些提示，我们旨在评估LLMs识别对话类型和用户测试目的的能力，从而为缓解越狱风险提供聊天机器人设计启示。我们的数据集将通过GitHub公开发布。', 'title_zh': 'RICoTA：对野生对话的红队测试与测试尝试'}
{'arxiv_id': 'arXiv:2501.17703', 'title': 'Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate', 'authors': 'Yubo Wang, Xiang Yue, Wenhu Chen', 'link': 'https://arxiv.org/abs/2501.17703', 'abstract': 'Supervised Fine-Tuning (SFT) is commonly used to train language models to imitate annotated responses for given instructions. In this paper, we challenge this paradigm and propose Critique Fine-Tuning (CFT), a strategy where models learn to critique noisy responses rather than simply imitate correct ones. Inspired by human learning processes that emphasize critical thinking, CFT encourages deeper analysis and nuanced understanding-traits often overlooked by standard SFT. To validate the effectiveness of CFT, we construct a 50K-sample dataset from WebInstruct, using GPT-4o as the teacher to generate critiques in the form of (input=[query; noisy response], output=critique). CFT on this dataset yields a consistent 4-10% improvement over SFT on six math benchmarks with different base models like Qwen2.5, Qwen2.5-Math and DeepSeek-Math. We further expand to MetaMath and NuminaMath datasets and observe similar gains over SFT. Notably, our Qwen2.5-Math-CFT model-trained on just 50K samples-matches or outperforms competitive models such as AceMath and Qwen2.5-Math-Instruct on most benchmarks, both of which use over 2M samples. Ablation studies show that CFT is robust to the source of noisy response and teacher critique model. Through these findings, we argue that critique-based training offers a more effective alternative to advance the reasoning of language models.', 'abstract_zh': '监督微调（SFT）常用于训练语言模型以模仿给定指令下的标注响应。本文挑战这一范式，提出了一种新的策略——批判性微调（CFT），通过这种策略，模型学会批判性地评估噪声响应，而不是简单地模仿正确响应。受到人类学习过程中强调批判性思考的启发，CFT 鼓励进行更深层次的分析和细致的理解，这是标准 SFT 经常忽视的特质。为了验证 CFT 的有效性，我们从 WebInstruct 构建了一个包含 50,000 个样本的数据集，并使用 GPT-4o 作为教师生成形如 (输入=[查询；噪声响应]，输出=批评) 的批评。在这一数据集上进行 CFT 微调后，我们的模型在六个不同基础模型（如 Qwen2.5、Qwen2.5-Math 和 DeepSeek-Math）的数学基准测试中均取得了 4-10% 的持续改进。我们进一步扩展到 MetaMath 和 NuminaMath 数据集，并观察到类似的改进。值得注意的是，仅使用 50,000 个样本训练的 Qwen2.5-Math-CFT 模型在大多数基准测试中与使用超过 2 百万样本训练的 AceMath 和 Qwen2.5-Math-Instruct 等竞争模型相当或优于后者。消融实验表明，CFT 对噪声响应的来源以及教师批评模型的选择具有鲁棒性。通过这些研究结果，我们认为基于批评的训练为提升语言模型的推理能力提供了更有效的方法。', 'title_zh': '批判性调优：学习批判比学习模仿更有效'}
{'arxiv_id': 'arXiv:2501.17654', 'title': 'Exploring Vision Language Models for Multimodal and Multilingual Stance Detection', 'authors': 'Jake Vasilakes, Carolina Scarton, Zhixue Zhao', 'link': 'https://arxiv.org/abs/2501.17654', 'abstract': "Social media's global reach amplifies the spread of information, highlighting the need for robust Natural Language Processing tasks like stance detection across languages and modalities. Prior research predominantly focuses on text-only inputs, leaving multimodal scenarios, such as those involving both images and text, relatively underexplored. Meanwhile, the prevalence of multimodal posts has increased significantly in recent years. Although state-of-the-art Vision-Language Models (VLMs) show promise, their performance on multimodal and multilingual stance detection tasks remains largely unexamined. This paper evaluates state-of-the-art VLMs on a newly extended dataset covering seven languages and multimodal inputs, investigating their use of visual cues, language-specific performance, and cross-modality interactions. Our results show that VLMs generally rely more on text than images for stance detection and this trend persists across languages. Additionally, VLMs rely significantly more on text contained within the images than other visual content. Regarding multilinguality, the models studied tend to generate consistent predictions across languages whether they are explicitly multilingual or not, although there are outliers that are incongruous with macro F1, language support, and model size.", 'abstract_zh': '社交媒体的全球影响力放大了信息传播的速度，突显了在多种语言和模态下进行稳健自然语言处理任务（如立场检测）的重要性。现有研究主要集中在文本输入上，而涉及图像和文本等多种模态的情景则相对较少被探索。与此同时，近年来多模态帖子的数量显著增加。尽管最先进的视觉语言模型（VLM）表现出潜力，但它们在多模态和跨语言立场检测任务上的性能尚未得到充分研究。本文在涵盖七种语言和多种模态输入的全新扩展数据集上评估了最先进的VLM，考察了它们对视觉线索的使用、语言特定性能以及跨模态交互情况。我们的结果表明，VLMs在立场检测中通常更依赖文本而非图像，这种趋势在不同语言中依然持续。此外，VLMs更依赖图像中的文本而非其他视觉内容。至于多语言性，研究的模型即使不是明确的多语言模型，也倾向于在多种语言中生成一致的预测，但存在一些模型在宏F1分数、语言支持和模型规模方面与这一趋势不符。', 'title_zh': '探索视觉语言模型在多模态多语言立场检测中的应用'}
{'arxiv_id': 'arXiv:2501.17643', 'title': 'Tonguescape: Exploring Language Models Understanding of Vowel Articulation', 'authors': 'Haruki Sakajo, Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe', 'link': 'https://arxiv.org/abs/2501.17643', 'abstract': 'Vowels are primarily characterized by tongue position. Humans have discovered these features of vowel articulation through their own experience and explicit objective observation such as using MRI. With this knowledge and our experience, we can explain and understand the relationship between tongue positions and vowels, and this knowledge is helpful for language learners to learn pronunciation. Since language models (LMs) are trained on a large amount of data that includes linguistic and medical fields, our preliminary studies indicate that an LM is able to explain the pronunciation mechanisms of vowels. However, it is unclear whether multi-modal LMs, such as vision LMs, align textual information with visual information. One question arises: do LMs associate real tongue positions with vowel articulation? In this study, we created video and image datasets from the existing real-time MRI dataset and investigated whether LMs can understand vowel articulation based on tongue positions using vision-based information. Our findings suggest that LMs exhibit potential for understanding vowels and tongue positions when reference examples are provided while they have difficulties without them. Our code for dataset building is available on GitHub.', 'abstract_zh': '元音主要由舌位决定。人类通过自身的体验和明确的目标观察，比如使用MRI扫描，发现了元音发音的这些特征。凭借这些知识和我们的经验，我们可以解释和理解舌位与元音之间的关系，这对于语言学习者学习发音大有帮助。由于语言模型（LMs）在大量包括语言学和医学领域的数据上进行训练，我们的初步研究表明，LMs能够解释元音发音的机制。然而，尚不清楚多模态LMs，如视觉LMs，是否能够将文本信息与视觉信息对齐。一个问题是，LMs是否会将真实的舌位与元音发音关联起来？在这项研究中，我们从现有的实时MRI数据集中创建了视频和图像数据集，并研究了LMs是否能够依靠基于视觉的信息理解元音发音与舌位之间的关系。研究结果表明，当提供参考示例时，LMs能够理解元音和舌位，但如果没有参考示例，它们会面临困难。我们的数据集构建代码可在GitHub上获取。', 'title_zh': '舌尖韵：探索语言模型对元音发音的理解'}
{'arxiv_id': 'arXiv:2501.17635', 'title': 'In-Context Meta LoRA Generation', 'authors': 'Yihua Shao, Minxi Yan, Yang Liu, Siyu Chen, Wenjie Chen, Xinwei Long, Ziyang Yan, Lei Li, Chenyu Zhang, Nicu Sebe, Hao Tang, Yan Wang, Hao Zhao, Mengzhu Wang, Jingcai Guo', 'link': 'https://arxiv.org/abs/2501.17635', 'abstract': 'Low-rank Adaptation (LoRA) has demonstrated remarkable capabilities for task specific fine-tuning. However, in scenarios that involve multiple tasks, training a separate LoRA model for each one results in considerable inefficiency in terms of storage and inference. Moreover, existing parameter generation methods fail to capture the correlations among these tasks, making multi-task LoRA parameter generation challenging. To address these limitations, we propose In-Context Meta LoRA (ICM-LoRA), a novel approach that efficiently achieves task-specific customization of large language models (LLMs). Specifically, we use training data from all tasks to train a tailored generator, Conditional Variational Autoencoder (CVAE). CVAE takes task descriptions as inputs and produces task-aware LoRA weights as outputs. These LoRA weights are then merged with LLMs to create task-specialized models without the need for additional fine-tuning. Furthermore, we utilize in-context meta-learning for knowledge enhancement and task mapping, to capture the relationship between tasks and parameter distributions. As a result, our method achieves more accurate LoRA parameter generation for diverse tasks using CVAE. ICM-LoRA enables more accurate LoRA parameter reconstruction than current parameter reconstruction methods and is useful for implementing task-specific enhancements of LoRA parameters. At the same time, our method occupies 283MB, only 1\\% storage compared with the original LoRA.', 'abstract_zh': '低秩适应（Low-rank Adaptation, LoRA）已经展示了在特定任务微调方面的显著能力。然而，在涉及多个任务的场景中，为每个任务单独训练一个LoRA模型会导致存储和推理效率的显著下降。此外，现有的参数生成方法无法捕捉各个任务之间的相关性，使得多任务LoRA参数生成变得具有挑战性。为了解决这些限制，我们提出了一种名为情境元LoRA（In-Context Meta LoRA, ICM-LoRA）的新型方法，该方法能够高效地实现大型语言模型（Large Language Models, LLMs）的特定任务定制。具体而言，我们使用所有任务的数据来训练一个定制生成器，即条件变分自动编码器（Conditional Variational Autoencoder, CVAE）。CVAE 以任务描述作为输入，并生成任务感知的LoRA权重作为输出。这些LoRA权重随后与LLMs结合，创建出特定任务模型，而无需额外的微调。此外，我们利用情境元学习来增强知识并优化任务映射，以捕捉任务之间的关系和参数分布。因此，我们的方法能够使用CVAE实现更准确的LoRA参数生成，适用于多种任务。ICM-LoRA 使得LoRA参数重建更加准确，并且能够有效实现LoRA参数的特定任务增强。同时，我们的方法占用空间仅为283MB，仅为原始LoRA存储空间的1%。', 'title_zh': '上下文相关元LoRA生成'}
{'arxiv_id': 'arXiv:2501.17617', 'title': 'Structured Context Recomposition for Large Language Models Using Probabilistic Layer Realignment', 'authors': 'Jonathan Teel, Jocasta Cumberbatch, Raphael Benington, Quentin Baskerville', 'link': 'https://arxiv.org/abs/2501.17617', 'abstract': 'Extended sequence generation often leads to degradation in contextual consistency due to the inability of conventional self-attention mechanisms to effectively retain long-range dependencies. Existing approaches, including memory compression and retrieval-augmented conditioning, introduce computational trade-offs that either increase inference latency or impose additional storage overhead. Structured Context Recomposition (SCR) introduces a probabilistic layer realignment strategy that dynamically adjusts learned representations within transformer layers, ensuring that semantically relevant embeddings persist throughout extended transformations. The proposed method enhances coherence retention through a recursive weighting function that redistributes representational emphasis based on inferred contextual relevance rather than relying on fixed token-level attention scores. Empirical results indicate that probabilistic realignment mitigates abrupt topic shifts and logical inconsistencies, particularly in scenarios where sequences exceed standard attention window constraints. Sequence-level entropy analysis further reveals that SCR moderates representational variability without introducing excessive output regularization, allowing models to sustain generative diversity while preserving contextual alignment. Attention head deviation measurements confirm that hierarchical reweighting contributes to smoother token dependency transitions across transformer layers, reinforcing the stability of multi-turn interactions and document-level reasoning. Computational resource assessments show that while SCR incurs a moderate increase in processing time, memory overhead remains within feasible limits, making it suitable for practical deployment in autoregressive generative applications.', 'abstract_zh': '扩展序列生成常常会因常规自注意力机制难以有效保留长范围依赖关系而导致语境一致性退化。现有方法，包括内存压缩和检索增强条件化，引入了计算折衷，要么增加推理延迟，要么增加额外的存储开销。结构化上下文重构（SCR）引入了一种基于概率的层重新对齐策略，该策略动态调整transformer层中的学习表示，确保语义相关的嵌入在整个扩展变换过程中持久存在。所提出的方法通过递归加权函数增强了连贯性的保持，该函数基于推断出的上下文相关性重新分配表示性的重点，而不是依赖于固定token级别的注意力评分。实验证据表明，概率重新对齐可以减轻主题突变和逻辑不一致现象，尤其是在序列超过标准注意力窗口约束的情况下。序列级熵分析进一步表明，SCR在不引入过度输出正则化的情况下调节表示性变异性，从而使模型在保持上下文对齐的同时维持生成多样。注意力头偏差测量证实，层次加权有助于transformer层内更平滑的token依赖性过渡，增强多轮对话和文档级推理的稳定性。计算资源评估显示，尽管SCR会导致处理时间的适度增加，但内存开销仍控制在可行范围内，使其适合在自回归生成应用中的实际部署。', 'title_zh': '使用概率层重排进行大规模语言模型的结构化上下文重组'}
{'arxiv_id': 'arXiv:2501.17615', 'title': 'Cross-lingual Embedding Clustering for Hierarchical Softmax in Low-Resource Multilingual Speech Recognition', 'authors': 'Zhengdong Yang, Qianying Liu, Sheng Li, Fei Cheng, Chenhui Chu', 'link': 'https://arxiv.org/abs/2501.17615', 'abstract': 'We present a novel approach centered on the decoding stage of Automatic Speech Recognition (ASR) that enhances multilingual performance, especially for low-resource languages. It utilizes a cross-lingual embedding clustering method to construct a hierarchical Softmax (H-Softmax) decoder, which enables similar tokens across different languages to share similar decoder representations. It addresses the limitations of the previous Huffman-based H-Softmax method, which relied on shallow features in token similarity assessments. Through experiments on a downsampled dataset of 15 languages, we demonstrate the effectiveness of our approach in improving low-resource multilingual ASR accuracy.', 'abstract_zh': '我们提出了一种新颖的方法，该方法着重于自动语音识别（ASR）的解码阶段，旨在提高多语种性能，特别是对于低资源语言。该方法利用跨语言嵌入聚类方法构建层次Softmax（H-Softmax）解码器，使不同语言中相似的令牌能够共享相似的解码器表示。该方法解决了基于Huffman编码的H-Softmax方法在令牌相似性评估中依赖浅层特征的局限性。通过在15种语言的稀疏数据集上进行实验，我们证明了该方法在提高低资源多语种ASR准确性方面的有效性。', 'title_zh': '跨语言嵌入聚类在低资源多语言语音识别中的层次softmax中应用'}
{'arxiv_id': 'arXiv:2501.17598', 'title': 'Semantic Consistency Regularization with Large Language Models for Semi-supervised Sentiment Analysis', 'authors': 'Kunrong Li, Xinyu Liu, Zhen Chen', 'link': 'https://arxiv.org/abs/2501.17598', 'abstract': 'Accurate sentiment analysis of texts is crucial for a variety of applications, such as understanding customer feedback, monitoring market trends, and detecting public sentiment. However, manually annotating large sentiment corpora for supervised learning is labor-intensive and time-consuming. Therefore, it is essential and effective to develop a semi-supervised method for the sentiment analysis task. Although some methods have been proposed for semi-supervised text classification, they rely on the intrinsic information within the unlabeled data and the learning capability of the NLP model, which lack generalization ability to the sentiment analysis scenario and may prone to overfit. Inspired by the ability of pretrained Large Language Models (LLMs) in following instructions and generating coherent text, we propose a Semantic Consistency Regularization with Large Language Models (SCR) framework for semi-supervised sentiment analysis. We introduce two prompting strategies to semantically enhance unlabeled text using LLMs. The first is Entity-based Enhancement (SCR-EE), which involves extracting entities and numerical information, and querying the LLM to reconstruct the textual information. The second is Concept-based Enhancement (SCR-CE), which directly queries the LLM with the original sentence for semantic reconstruction. Subsequently, the LLM-augmented data is utilized for a consistency loss with confidence thresholding, which preserves high-quality agreement samples to provide additional supervision signals during training. Furthermore, to fully utilize the uncertain unlabeled data samples, we propose a class re-assembling strategy inspired by the class space shrinking theorem. Experiments show our method achieves remarkable performance over prior semi-supervised methods.', 'abstract_zh': '准确的情感分析对于各种应用至关重要，如理解客户反馈、监控市场趋势和检测公众情绪。然而，手动为监督学习标注大量情感语料库是耗时且劳动密集型的。因此，开发一种半监督方法对于情感分析任务是必要且有效的。尽管已经提出了多种半监督文本分类方法，但这些方法主要依赖于未标注数据的内在信息和NLP模型的学习能力，缺乏对情感分析场景的泛化能力，而且容易出现过拟合的情况。借鉴预训练大型语言模型（LLMs）遵循指令和生成连贯文本的能力，我们提出了一种基于大型语言模型的情感一致性正则化（Semantic Consistency Regularization with Large Language Models, SCR）框架，用于半监督情感分析。我们引入了两种提示策略来利用大型语言模型增强未标注文本的语义信息。第一种是实体增强（SCR-EE），涉及提取实体和数值信息，并查询模型重建文本信息。第二种是概念增强（SCR-CE），直接用原始句子查询模型进行语义重建。随后，利用增强后的数据通过一致性损失进行训练，并结合置信阈值保留高质量的一致性样本，为训练期间提供额外的监督信号。此外，为了充分利用未标注数据中的不确定性样本，我们提出了一个受类空间收缩定理启发的类别重组策略。实验结果显示，我们的方法在前人研究的半监督方法中取得了显著性能。', 'title_zh': '使用大型语言模型进行半监督情感分析的语义一致性正则化'}
{'arxiv_id': 'arXiv:2501.17581', 'title': 'CSEval: Towards Automated, Multi-Dimensional, and Reference-Free Counterspeech Evaluation using Auto-Calibrated LLMs', 'authors': 'Amey Hengle, Aswini Kumar, Anil Bandhakavi, Tanmoy Chakraborty', 'link': 'https://arxiv.org/abs/2501.17581', 'abstract': 'Counterspeech has been popular as an effective approach to counter online hate speech, leading to increasing research interest in automated counterspeech generation using language models. However, this field lacks standardised evaluation protocols and robust automated evaluation metrics that align with human judgement. Current automatic evaluation methods, primarily based on similarity metrics, do not effectively capture the complex and independent attributes of counterspeech quality, such as contextual relevance, aggressiveness, or argumentative coherence. This has led to an increased dependency on labor-intensive human evaluations to assess automated counter-speech generation methods. To address these challenges, we introduce CSEval, a novel dataset and framework for evaluating counterspeech quality across four dimensions: contextual-relevance, aggressiveness, argument-coherence, and suitableness. Furthermore, we propose Auto-Calibrated COT for Counterspeech Evaluation (ACE), a prompt-based method with auto-calibrated chain-of-thoughts (CoT) for scoring counterspeech using large language models. Our experiments show that ACE outperforms traditional metrics like ROUGE, METEOR, and BertScore in correlating with human judgement, indicating a significant advancement in automated counterspeech evaluation.', 'abstract_zh': '对抗言论作为一种有效的方法，已经被广泛用于反击网络仇恨言论，这促进了对使用语言模型进行自动化对抗言论生成的研究兴趣增加。然而，这一领域缺乏标准化的评估协议和与人类判断相一致的稳健自动评估指标。当前的自动评估方法主要基于相似性指标，无法有效捕捉对抗言论质量的复杂且独立的属性，如上下文相关性、攻击性或说理连贯性。这导致了对劳动密集型的人工评估的依赖，以评估自动化对抗言论生成方法。为了解决这些挑战，我们提出了一种新的对抗言论评估数据集和框架CSEval，它从四个维度评估对抗言论质量：上下文相关性、攻击性、说理连贯性以及适用性。此外，我们还提出了基于提示的对抗言论评估自动校准链式思维（Auto-Calibrated Chain-of-Thoughts，简称ACE）方法，这是一种使用大型语言模型评分对抗言论的方法，结合了自动校准的链式思维（CoT）。实验结果表明，ACE在与人类判断相关性方面优于传统的ROUGE、METEOR和BertScore等指标，表明在自动化对抗言论评估方面取得了重要进展。', 'title_zh': 'CSEval：面向自动化、多维度且无需参考标准的反言论评估系统，利用自动标定的大语言模型'}
{'arxiv_id': 'arXiv:2501.17569', 'title': "A linguistically-motivated evaluation methodology for unraveling model's abilities in reading comprehension tasks", 'authors': 'Elie Antoine, Frédéric Béchet, Géraldine Damnati, Philippe Langlais', 'link': 'https://arxiv.org/abs/2501.17569', 'abstract': "We introduce an evaluation methodology for reading comprehension tasks based on the intuition that certain examples, by the virtue of their linguistic complexity, consistently yield lower scores regardless of model size or architecture. We capitalize on semantic frame annotation for characterizing this complexity, and study seven complexity factors that may account for model's difficulty. We first deploy this methodology on a carefully annotated French reading comprehension benchmark showing that two of those complexity factors are indeed good predictors of models' failure, while others are less so. We further deploy our methodology on a well studied English benchmark by using Chat-GPT as a proxy for semantic annotation. Our study reveals that fine-grained linguisticallymotivated automatic evaluation of a reading comprehension task is not only possible, but helps understand models' abilities to handle specific linguistic characteristics of input examples. It also shows that current state-of-the-art models fail with some for those characteristics which suggests that adequately handling them requires more than merely increasing model size.", 'abstract_zh': '我们提出了一种阅读理解任务的评估方法，基于这样一种直觉：某些示例由于其语言复杂性，在模型大小或架构不同的情况下，始终会获得较低的分数。我们利用语义框架注释来表征这种复杂性，并研究了七个可能解释模型难度的复杂性因素。我们首先将这种方法应用于一个仔细标注的法语阅读理解基准数据集，结果显示其中两个复杂性因素确实是模型失败的良好预测指标，而其他因素则不然。我们进一步将该方法应用于一个受到广泛研究的英语基准数据集，并使用Chat-GPT作为语义注释的代理。我们的研究发现，细粒度的、语言驱动的自动评估阅读理解任务不仅是可行的，而且有助于理解模型处理输入示例特定语言特征的能力。此外，研究表明当前最先进的模型在处理某些特征时会出现失败，这表明适当地处理这些特征需要的不仅仅是增加模型规模。', 'title_zh': '基于语言学驱动力的评估方法：揭开模型在阅读理解任务中能力的面纱'}
{'arxiv_id': 'arXiv:2501.17549', 'title': 'Query-Aware Learnable Graph Pooling Tokens as Prompt for Large Language Models', 'authors': 'Wooyoung Kim, Byungyoon Park, Wooju Kim', 'link': 'https://arxiv.org/abs/2501.17549', 'abstract': 'Graph-structured data plays a vital role in numerous domains, such as social networks, citation networks, commonsense reasoning graphs and knowledge graphs. While graph neural networks have been employed for graph processing, recent advancements have explored integrating large language models for graph-based tasks. In this paper, we propose a novel approach named Learnable Graph Pooling Token (LGPT), which addresses the limitations of the scalability issues in node-level projection and information loss in graph-level projection. LGPT enables flexible and efficient graph representation by introducing learnable parameters that act as tokens in large language models, balancing fine-grained and global graph information. Additionally, we investigate an Early Query Fusion technique, which fuses query context before constructing the graph representation, leading to more effective graph embeddings. Our method achieves a 4.13\\% performance improvement on the GraphQA benchmark without training the large language model, demonstrating significant gains in handling complex textual-attributed graph data.', 'abstract_zh': '图结构数据在许多领域中扮演着重要的角色，例如社交网络、引用网络、常识推理图和知识图谱。尽管图神经网络已被用于图处理，但近期的研究已探索将大规模语言模型集成到基于图的任务中。在本文中，我们提出了一种名为可学习图池化令牌（Learnable Graph Pooling Token, LGPT）的新方法，以解决节点级别投影的可扩展性问题以及图级别投影的信息损失问题。LGPT 通过引入作为大规模语言模型中可学习参数的令牌，实现了灵活且高效的图表示，平衡了细粒度和全局图信息。此外，我们研究了一种早期查询融合技术，该技术在构建图表示之前融合查询上下文，从而获得更有效的图嵌入。我们的方法在不训练大规模语言模型的情况下，在GraphQA基准上实现了4.13%的性能提升，显示出在处理复杂文本属性图数据方面的显著优势。', 'title_zh': '具有查询意识的学习图池化标记作为大规模语言模型的提示'}
{'arxiv_id': 'arXiv:2501.17486', 'title': 'DINT Transformer', 'authors': 'Yueyang Cang, Yuhang Liu, Xiaoteng Zhang, Erlu Zhao, Li Shi', 'link': 'https://arxiv.org/abs/2501.17486', 'abstract': 'DIFF Transformer addresses the issue of irrelevant context interference by introducing a differential attention mechanism that enhances the robustness of local attention. However, it has two critical limitations: the lack of global context modeling, which is essential for identifying globally significant tokens, and numerical instability due to the absence of strict row normalization in the attention matrix. To overcome these challenges, we propose DINT Transformer, which extends DIFF Transformer by incorporating a differential-integral mechanism. By computing global importance scores and integrating them into the attention matrix, DINT Transformer improves its ability to capture global dependencies. Moreover, the unified parameter design enforces row-normalized attention matrices, improving numerical stability. Experimental results demonstrate that DINT Transformer excels in accuracy and robustness across various practical applications, such as long-context language modeling and key information retrieval. These results position DINT Transformer as a highly effective and promising architecture.', 'abstract_zh': 'DIFF Transformer通过引入差异注意力机制来解决无关上下文干扰的问题，从而增强局部注意力的鲁棒性。然而，它存在两个关键限制：缺乏全局上下文建模，这对于识别全局重要的标记至关重要；以及由于注意矩阵中缺乏严格的行归一化而导致的数值不稳定。为克服这些挑战，我们提出DINT Transformer，该模型在DIFF Transformer的基础上引入了差异-积分机制。通过计算全局重要评分并将其整合到注意矩阵中，DINT Transformer能够更好地捕获全局依赖关系。此外，统一的参数设计确保了注意矩阵的行归一化，从而提高了数值稳定性。实验结果表明，DINT Transformer在各种实用应用中表现出色，如长上下文语言建模和关键信息检索，其准确性和鲁棒性均表现出色。这些结果将DINT Transformer定位为一种高效且有前景的架构。', 'title_zh': '"DINTTransformer" 可以翻译为中文为：“DINT 模型变换器” 或 “DINT 变换器”。DINT具体指的是什么需要根据上下文来确定，如果这是一个新的模型或技术，最好保留其缩写形式，并在首次出现时给出解释，例如：“DINT 模型变换器（Doubly Integrated Transformer）”。\n\n完整的翻译可以是：“DINT 模型变换器” 或 “DINT 变换器：双积分变压器”。\n\n如果你能提供更多关于DINT的具体信息，我可以给出更精确的翻译。'}
{'arxiv_id': 'arXiv:2501.17449', 'title': 'Cross-Language Approach for Quranic QA', 'authors': 'Islam Oshallah, Mohamed Basem, Ali Hamdi, Ammar Mohammed', 'link': 'https://arxiv.org/abs/2501.17449', 'abstract': 'Question answering systems face critical limitations in languages with limited resources and scarce data, making the development of robust models especially challenging. The Quranic QA system holds significant importance as it facilitates a deeper understanding of the Quran, a Holy text for over a billion people worldwide. However, these systems face unique challenges, including the linguistic disparity between questions written in Modern Standard Arabic and answers found in Quranic verses written in Classical Arabic, and the small size of existing datasets, which further restricts model performance. To address these challenges, we adopt a cross-language approach by (1) Dataset Augmentation: expanding and enriching the dataset through machine translation to convert Arabic questions into English, paraphrasing questions to create linguistic diversity, and retrieving answers from an English translation of the Quran to align with multilingual training requirements; and (2) Language Model Fine-Tuning: utilizing pre-trained models such as BERT-Medium, RoBERTa-Base, DeBERTa-v3-Base, ELECTRA-Large, Flan-T5, Bloom, and Falcon to address the specific requirements of Quranic QA. Experimental results demonstrate that this cross-language approach significantly improves model performance, with RoBERTa-Base achieving the highest MAP@10 (0.34) and MRR (0.52), while DeBERTa-v3-Base excels in Recall@10 (0.50) and Precision@10 (0.24). These findings underscore the effectiveness of cross-language strategies in overcoming linguistic barriers and advancing Quranic QA systems', 'abstract_zh': '具有有限资源和稀缺数据的语言在问题回答系统中面临关键限制，这使得开发稳健的模型尤其具有挑战性。清真文问题回答系统具有重要意义，因为它有助于增进数十亿人理解清真文，这是他们的圣书。然而，这些系统面临独特的挑战，包括现代标准阿拉伯语撰写的问题与清真文中所找到的经典阿拉伯语答案之间的语言差异，以及现有数据集的规模较小，这进一步限制了模型性能。为了应对这些挑战，我们采用了跨语言方法，具体包括：\n\n1. 数据集扩充：通过机器翻译扩展现有数据集，将阿拉伯语问题转换为英语，通过改写问题来产生语言多样性，并从英语版清真文中检索答案，以满足多语言训练需求；\n2. 语言模型微调：利用预训练模型（如RoBERTa-Medium、DeBERTa-v3-Base、ELECTRA-Large、Flan-T5、Bloom、Falcon）来解决清真文问题回答的特定需求。\n\n实验结果表明，这种跨语言方法显著提高了模型的性能，其中RoBERTa-Medium在MAP@10（0.34）和MRR（0.52）方面表现最佳，而DeBERTa-v3-Base在召回率@10（0.50）和精度@10（0.24）方面表现出色。这些发现强调了跨语言策略在克服语言障碍以及推动清真文问题回答系统方面的作用。\n\n注释：在翻译过程中，“MAP@10”和“MRR”等统计学术语没有进行修改，因为它们是通用的机器学习/信息检索评价指标。其中，“MAP@10”表示平均每相关文档排名@10，“MRR”表示平均倒数排名。', 'title_zh': '跨语言方法在古兰经问答中的应用'}
{'arxiv_id': 'arXiv:2501.17420', 'title': 'Actions Speak Louder than Words: Agent Decisions Reveal Implicit Biases in Language Models', 'authors': 'Yuxuan Li, Hirokazu Shirado, Sauvik Das', 'link': 'https://arxiv.org/abs/2501.17420', 'abstract': 'While advances in fairness and alignment have helped mitigate overt biases exhibited by large language models (LLMs) when explicitly prompted, we hypothesize that these models may still exhibit implicit biases when simulating human behavior. To test this hypothesis, we propose a technique to systematically uncover such biases across a broad range of sociodemographic categories by assessing decision-making disparities among agents with LLM-generated, sociodemographically-informed personas. Using our technique, we tested six LLMs across three sociodemographic groups and four decision-making scenarios. Our results show that state-of-the-art LLMs exhibit significant sociodemographic disparities in nearly all simulations, with more advanced models exhibiting greater implicit biases despite reducing explicit biases. Furthermore, when comparing our findings to real-world disparities reported in empirical studies, we find that the biases we uncovered are directionally aligned but markedly amplified. This directional alignment highlights the utility of our technique in uncovering systematic biases in LLMs rather than random variations; moreover, the presence and amplification of implicit biases emphasizes the need for novel strategies to address these biases.', 'abstract_zh': '尽管在公平性与一致性的进步有助于减轻大型语言模型（LLMs）在明确提示下表现出的明显偏见，我们假设这些模型在模拟人类行为时仍可能表现出隐性偏见。为了检验这一假设，我们提出了一种技术，该技术可以系统地揭示这些偏见，涉及广泛的社会人口统计类别，并通过评估具有社会人口统计信息的LLM生成的个性的代理在决策中的差异来进行评估。使用该技术，我们在三个社会人口统计群体和四个决策情景中测试了六种LLM。结果表明，最先进的LLM在几乎所有的模拟中都表现出显著的社会人口统计差异，尽管高级模型减少了明确的偏见，但隐性偏见却更加明显。此外，当我们将我们的发现与实证研究中报告的实际差异进行比较时，发现我们揭示的偏见方向一致，但明显放大。这种方向一致表明，我们的技术有助于揭示LLM中的系统性偏差，而不是随机变化；同时，隐性偏见的存在及其放大强调了需要采用新的策略来解决这些偏见的必要性。', 'title_zh': '言行胜于言语：智能体决策揭示语言模型中的隐含偏见'}
{'arxiv_id': 'arXiv:2501.17399', 'title': 'MultiChallenge: A Realistic Multi-Turn Conversation Evaluation Benchmark Challenging to Frontier LLMs', 'authors': 'Ved Sirdeshmukh, Kaustubh Deshpande, Johannes Mols, Lifeng Jin, Ed-Yeremai Cardona, Dean Lee, Jeremy Kritz, Willow Primack, Summer Yue, Chen Xing', 'link': 'https://arxiv.org/abs/2501.17399', 'abstract': 'We present MultiChallenge, a pioneering benchmark evaluating large language models (LLMs) on conducting multi-turn conversations with human users, a crucial yet underexamined capability for their applications. MultiChallenge identifies four categories of challenges in multi-turn conversations that are not only common and realistic among current human-LLM interactions, but are also challenging to all current frontier LLMs. All 4 challenges require accurate instruction-following, context allocation, and in-context reasoning at the same time. We also develop LLM as judge with instance-level rubrics to facilitate an automatic evaluation method with fair agreement with experienced human raters. Despite achieving near-perfect scores on existing multi-turn evaluation benchmarks, all frontier models have less than 50% accuracy on MultiChallenge, with the top-performing Claude 3.5 Sonnet (June 2024) achieving just a 41.4% average accuracy.', 'abstract_zh': '我们提出了MultiChallenge，这是一个开创性的基准测试，用于评估大型语言模型（LLMs）在与人类用户进行多轮对话方面的性能，这是其应用中至关重要但尚未充分评估的能力。MultiChallenge 识别了四种多轮对话中的挑战，这些挑战不仅在当前的人类-LLM 交互中普遍存在且具有现实意义，而且对当前所有前沿的LLMs 都具有挑战性。这四个挑战同时需要准确的指令遵循、上下文分配和情境中的推理能力。我们还开发了基于实例级别的评分标准的LLMs 作为裁判，以促进一种公平且与有经验的人类评审员意见一致的自动评估方法。尽管所有现有评估基准的多轮对话得分接近满分，但在MultiChallenge 中，所有前沿模型的准确率均低于50%，其中表现最佳的Anthropic Claude 3.5 Sonnet（2024年6月）的平均准确率仅为41.4%。', 'title_zh': '多任务挑战：面向前沿大规模语言模型的现实化多轮对话评估基准'}
{'arxiv_id': 'arXiv:2501.17397', 'title': 'Leveraging In-Context Learning and Retrieval-Augmented Generation for Automatic Question Generation in Educational Domains', 'authors': 'Subhankar Maity, Aniket Deroy, Sudeshna Sarkar', 'link': 'https://arxiv.org/abs/2501.17397', 'abstract': 'Question generation in education is a time-consuming and cognitively demanding task, as it requires creating questions that are both contextually relevant and pedagogically sound. Current automated question generation methods often generate questions that are out of context. In this work, we explore advanced techniques for automated question generation in educational contexts, focusing on In-Context Learning (ICL), Retrieval-Augmented Generation (RAG), and a novel Hybrid Model that merges both methods. We implement GPT-4 for ICL using few-shot examples and BART with a retrieval module for RAG. The Hybrid Model combines RAG and ICL to address these issues and improve question quality. Evaluation is conducted using automated metrics, followed by human evaluation metrics. Our results show that both the ICL approach and the Hybrid Model consistently outperform other methods, including baseline models, by generating more contextually accurate and relevant questions.', 'abstract_zh': '教育中的问题生成是一个耗时且认知要求高的任务，因为它需要创建既符合上下文又具有教学意义的问题。目前的自动化问题生成方法通常会生成脱离上下文的问题。在这项工作中，我们探讨了在教育背景下自动问题生成的高级技术，重点关注上下文学习（In-Context Learning, ICL）、检索增强生成（Retrieval-Augmented Generation, RAG）以及一种新颖的混合模型，该模型将这两种方法结合在一起。我们使用少量示例来实现GPT-4进行ICL，并用带有检索模块的BART进行RAG。混合模型将RAG和ICL结合起来，以解决这些问题并提高问题的质量。评估使用了自动化指标，随后是对人类评价指标的评估。我们的结果显示，ICL方法和混合模型在生成更具上下文相关性和相关性的问题方面始终优于其他方法，包括基线模型。', 'title_zh': '利用上下文学习和检索增强生成技术自动生成教育领域中的问题'}
{'arxiv_id': 'arXiv:2501.17386', 'title': 'Context-Aware Semantic Recomposition Mechanism for Large Language Models', 'authors': 'Richard Katrix, Quentin Carroway, Rowan Hawkesbury, Matthias Heathfield', 'link': 'https://arxiv.org/abs/2501.17386', 'abstract': 'Context-aware processing mechanisms have increasingly become a critical area of exploration for improving the semantic and contextual capabilities of language generation models. The Context-Aware Semantic Recomposition Mechanism (CASRM) was introduced as a novel framework designed to address limitations in coherence, contextual adaptability, and error propagation in large-scale text generation tasks. Through the integration of dynamically generated context vectors and attention modulation layers, CASRM enhances the alignment between token-level representations and broader contextual dependencies. Experimental evaluations demonstrated significant improvements in semantic coherence across multiple domains, including technical, conversational, and narrative text. The ability to adapt to unseen domains and ambiguous inputs was evaluated using a diverse set of test scenarios, highlighting the robustness of the proposed mechanism. A detailed computational analysis revealed that while CASRM introduces additional processing overhead, the gains in linguistic precision and contextual relevance outweigh the marginal increase in complexity. The framework also successfully mitigates error propagation in sequential tasks, improving performance in dialogue continuation and multi-step text synthesis. Additional investigations into token-level attention distribution emphasized the dynamic focus shifts enabled through context-aware enhancements. The findings suggest that CASRM offers a scalable and flexible solution for integrating contextual intelligence into existing language model architectures.', 'abstract_zh': '情境感知处理机制已成为提高语言生成模型语义和上下文能力的关键研究领域。情境感知语义重组机制（CASRM）作为一种新型框架，旨在解决大规模文本生成任务中连贯性、上下文适应性和错误传播的局限性。通过集成动态生成的上下文向量和注意力调制层，CASRM 提高了词元级表征与更广泛上下文依赖之间的对齐度。实验评估显示，CASRM 在技术、对话和叙事文本等多个领域显著提高了语义连贯性。利用多样化测试场景评估其对未见领域和模糊输入的适应性，突显了所提出机制的稳健性。详细的计算分析表明，尽管 CASRM 引入了额外的处理开销，但在语言精确度和上下文相关性上的提升超过了复杂度小幅增加的成本。该框架还成功减轻了顺序任务中的错误传播，改善了对话延续和多步骤文本合成的表现。关于词元级注意力分布的额外研究强调了情境感知增强所允许的动态关注点转移。这些发现表明，CASRM 提供了一个可扩展且灵活的解决方案，可以整合情境智能到现有语言模型架构中。', 'title_zh': '面向上下文的语义重组机制 untuk 大型语言模型'}
{'arxiv_id': 'arXiv:2501.17348', 'title': 'Better Slow than Sorry: Introducing Positive Friction for Reliable Dialogue Systems', 'authors': 'Mert İnan, Anthony Sicilia, Suvodip Dey, Vardhan Dongre, Tejas Srinivasan, Jesse Thomason, Gökhan Tür, Dilek Hakkani-Tür, Malihe Alikhani', 'link': 'https://arxiv.org/abs/2501.17348', 'abstract': 'While theories of discourse and cognitive science have long recognized the value of unhurried pacing, recent dialogue research tends to minimize friction in conversational systems. Yet, frictionless dialogue risks fostering uncritical reliance on AI outputs, which can obscure implicit assumptions and lead to unintended consequences. To meet this challenge, we propose integrating positive friction into conversational AI, which promotes user reflection on goals, critical thinking on system response, and subsequent re-conditioning of AI systems. We hypothesize systems can improve goal alignment, modeling of user mental states, and task success by deliberately slowing down conversations in strategic moments to ask questions, reveal assumptions, or pause. We present an ontology of positive friction and collect expert human annotations on multi-domain and embodied goal-oriented corpora. Experiments on these corpora, along with simulated interactions using state-of-the-art systems, suggest incorporating friction not only fosters accountable decision-making, but also enhances machine understanding of user beliefs and goals, and increases task success rates.', 'abstract_zh': '尽管话语理论和认知科学理论很久以来就认识到从容的节奏的价值，近期的对话研究趋势倾向于在对话系统中最小化摩擦。然而，无摩擦的对话可能会促进用户对AI输出的无批判依赖，这可能导致隐含假设的模糊不清并产生意想不到的结果。为应对这一挑战，我们提出在对话AI中整合积极摩擦的策略，这可以促进用户对目标的反思，对系统响应进行批判性思考，并重新调整AI系统。我们认为，在关键时刻故意放慢对话节奏，提出问题，揭示假设或暂停，可以改善目标对齐、用户心理状态建模以及任务成功率。我们提出了积极摩擦的本体论，并收集了专业人士对多领域和具身目标导向语料库的人工注释。在这些语料库上的实验以及使用最新系统模拟的交互表明，整合摩擦不仅促进负责的决策制定，还能增强机器对用户信念和目标的理解，并提高任务成功率。', 'title_zh': '比后悔更好：为可靠对话系统引入积极摩擦力'}
{'arxiv_id': 'arXiv:2501.17338', 'title': 'Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection', 'authors': 'Mingyu Derek Ma, Yanna Ding, Zijie Huang, Jianxi Gao, Yizhou Sun, Wei Wang', 'link': 'https://arxiv.org/abs/2501.17338', 'abstract': 'Generative Language Models rely on autoregressive decoding to produce the output sequence token by token. Many tasks such as preference optimization, require the model to produce task-level output consisting of multiple tokens directly by selecting candidates from a pool as predictions. Determining a task-level prediction from candidates using the ordinary token-level decoding mechanism is constrained by time-consuming decoding and interrupted gradients by discrete token selection. Existing works have been using decoding-free candidate selection methods to obtain candidate probability from initial output logits over vocabulary. Though these estimation methods are widely used, they are not systematically evaluated, especially on end tasks. We introduce an evaluation of a comprehensive collection of decoding-free candidate selection approaches on a comprehensive set of tasks, including five multiple-choice QA tasks with a small candidate pool and four clinical decision tasks with a massive amount of candidates, some with 10k+ options. We evaluate the estimation methods paired with a wide spectrum of foundation LMs covering different architectures, sizes and training paradigms. The results and insights from our analysis inform the future model design.', 'abstract_zh': '生成语言模型依赖于自回归解码，逐个生成输出序列的令牌。许多任务，如偏好优化，要求模型能够直接通过从候选池中选择预测候选词来生成任务级别的输出，而不是逐步生成。使用普通基于令牌级解码机制来确定任务级别的预测会受到耗时解码和离散令牌选择中断梯度的限制。现有工作已经采用了解码-free的候选选择方法，通过初始输出词汇表概率来获取候选概率。尽管这些估计方法被广泛使用，但它们没有得到系统的评估，特别是在最终任务方面。我们提出了一个全面的解码-free候选选择方法的评估，包括五个带有小候选池的多项选择问答任务和四个带有大量候选词的临床决策任务，有些任务甚至有数千个选项。我们评估了与不同架构、规模和训练范式的广泛基础LM配对的估计方法。我们分析的结果和见解将为未来的模型设计提供指导。', 'title_zh': '从Logits推断：探索解码-free 生成候选选择的最佳实践'}
{'arxiv_id': 'arXiv:2501.17326', 'title': 'Memorize and Rank: Elevating Large Language Models for Clinical Diagnosis Prediction', 'authors': 'Mingyu Derek Ma, Xiaoxuan Wang, Yijia Xiao, Anthony Cuturrufo, Vijay S Nori, Eran Halperin, Wei Wang', 'link': 'https://arxiv.org/abs/2501.17326', 'abstract': "Clinical diagnosis prediction models, when provided with a patient's medical history, aim to detect potential diseases early, facilitating timely intervention and improving prognostic outcomes. However, the inherent scarcity of patient data and large disease candidate space often pose challenges in developing satisfactory models for this intricate task. The exploration of leveraging Large Language Models (LLMs) for encapsulating clinical decision processes has been limited. We introduce MERA, a clinical diagnosis prediction model that bridges pertaining natural language knowledge with medical practice. We apply hierarchical contrastive learning on a disease candidate ranking list to alleviate the large decision space issue. With concept memorization through fine-tuning, we bridge the natural language clinical knowledge with medical codes. Experimental results on MIMIC-III and IV datasets show that MERA achieves the state-of-the-art diagnosis prediction performance and dramatically elevates the diagnosis prediction capabilities of generative LMs.", 'abstract_zh': '基于患者医疗历史的临床诊断预测模型旨在早期检测潜在疾病，从而促进及时干预并改善预后效果。然而，患者数据的固有稀缺性和疾病候选空间的庞大往往给开发此类复杂任务的满意模型带来了挑战。利用大型语言模型（LLMs）来封装临床决策过程的探索仍较为有限。我们引入了MERA，这是一种将相关自然语言知识与医疗实践结合起来的临床诊断预测模型。我们通过分层对比学习对疾病候选排名列表进行学习，以缓解决策空间过大的问题。通过细调进行概念记忆，我们将自然语言临床知识与医学编码相结合。在MIMIC-III和IV数据集中进行的实验结果显示，MERA实现了最先进的诊断预测性能，并显著提升了生成型语言模型的诊断预测能力。', 'title_zh': '记忆与排序：提升用于临床诊断预测的大语言模型性能'}
{'arxiv_id': 'arXiv:2501.17295', 'title': 'Mitigating Hallucinated Translations in Large Language Models with Hallucination-focused Preference Optimization', 'authors': 'Zilu Tang, Rajen Chatterjee, Sarthak Garg', 'link': 'https://arxiv.org/abs/2501.17295', 'abstract': "Machine Translation (MT) is undergoing a paradigm shift, with systems based on fine-tuned large language models (LLM) becoming increasingly competitive with traditional encoder-decoder models trained specifically for translation tasks. However, LLM-based systems are at a higher risk of generating hallucinations, which can severely undermine user's trust and safety. Most prior research on hallucination mitigation focuses on traditional MT models, with solutions that involve post-hoc mitigation - detecting hallucinated translations and re-translating them. While effective, this approach introduces additional complexity in deploying extra tools in production and also increases latency. To address these limitations, we propose a method that intrinsically learns to mitigate hallucinations during the model training phase. Specifically, we introduce a data creation framework to generate hallucination focused preference datasets. Fine-tuning LLMs on these preference datasets reduces the hallucination rate by an average of 96% across five language pairs, while preserving overall translation quality. In a zero-shot setting our approach reduces hallucinations by 89% on an average across three unseen target languages.", 'abstract_zh': '机器翻译（MT）正在经历一场范式的变革，基于微调大型语言模型（LLM）的系统在性能上逐渐与专门针对翻译任务训练的编码器-解码器模型相媲美。然而，基于LLM的系统更容易产生幻觉，这可能会严重削弱用户信任和安全性。之前大部分关于幻觉抑制的研究集中在传统MT模型上，解决方案多涉及事后抑制——检测到生成的幻觉翻译后重新翻译。尽管有效，这种方法在生产环境中部署额外工具的同时也增加了延迟。为解决这些局限性，我们提出了一种在模型训练阶段内在地学习抑制幻觉的方法。具体而言，我们引入了一个数据生成框架，用于生成专注于幻觉的偏好数据集。在这些偏好数据集上微调LLM模型，能够平均降低五种语言对中幻觉的发生率96%，同时保持整体翻译质量。在零样本设置下，我们的方法平均在三种未知目标语言中将幻觉发生率降低了89%。', 'title_zh': '使用幻觉导向的偏好优化减轻大型语言模型中的幻觉翻译'}
{'arxiv_id': 'arXiv:2501.17273', 'title': 'Tailored Truths: Optimizing LLM Persuasion with Personalization and Fabricated Statistics', 'authors': 'Jasper Timm, Chetan Talele, Jacob Haimes', 'link': 'https://arxiv.org/abs/2501.17273', 'abstract': "Large Language Models (LLMs) are becoming increasingly persuasive, demonstrating the ability to personalize arguments in conversation with humans by leveraging their personal data. This may have serious impacts on the scale and effectiveness of disinformation campaigns. We studied the persuasiveness of LLMs in a debate setting by having humans $(n=33)$ engage with LLM-generated arguments intended to change the human's opinion. We quantified the LLM's effect by measuring human agreement with the debate's hypothesis pre- and post-debate and analyzing both the magnitude of opinion change, as well as the likelihood of an update in the LLM's direction. We compare persuasiveness across established persuasion strategies, including personalized arguments informed by user demographics and personality, appeal to fabricated statistics, and a mixed strategy utilizing both personalized arguments and fabricated statistics. We found that static arguments generated by humans and GPT-4o-mini have comparable persuasive power. However, the LLM outperformed static human-written arguments when leveraging the mixed strategy in an interactive debate setting. This approach had a $\\mathbf{51\\%}$ chance of persuading participants to modify their initial position, compared to $\\mathbf{32\\%}$ for the static human-written arguments. Our results highlight the concerning potential for LLMs to enable inexpensive and persuasive large-scale disinformation campaigns.", 'abstract_zh': '大型语言模型（LLMs）正变得越来越具有说服力，通过利用个人数据在其与人类的对话中个性化其论点。这可能对虚假信息运动的规模和有效性产生严重影响。我们通过让人类参与者（n=33）与生成的LLM论点进行互动，来研究LLM在辩论环境中的说服力。我们通过测量参与者对于辩论假说的赞成度在辩论前后的变化程度来量化LLM的影响，同时分析论点方向和说服程度的变化幅度。我们比较了几种已确立的说服策略，包括基于用户人口统计和个人特征的个性化论点、援引虚假统计数据，以及结合个性化论点和虚假统计数据的混合策略的说服效果。我们发现，由人类和GPT-4o-mini生成的静态论点在说服力上相差不大。然而，在交互式辩论环境中，当LLM利用混合策略时，其表现超过了静态的人类撰写论点。这种策略有$\\mathbf{51\\%}$的成功率使参与者改变初始观点，而静态的人类撰写论点的成功率仅为$\\mathbf{32\\%}$。我们的研究结果突显了LLMs在支持低成本、高说服力的大规模虚假信息运动方面的令人担忧的潜力。', 'title_zh': '量身定制的真相：通过个性化和虚构统计优化大型语言模型的说服力'}
{'arxiv_id': 'arXiv:2501.17270', 'title': 'Comprehensive Evaluation for a Large Scale Knowledge Graph Question Answering Service', 'authors': 'Saloni Potdar, Daniel Lee, Omar Attia, Varun Embar, De Meng, Ramesh Balaji, Chloe Seivwright, Eric Choi, Mina H. Farid, Yiwen Sun, Yunyao Li', 'link': 'https://arxiv.org/abs/2501.17270', 'abstract': 'Question answering systems for knowledge graph (KGQA), answer factoid questions based on the data in the knowledge graph. KGQA systems are complex because the system has to understand the relations and entities in the knowledge-seeking natural language queries and map them to structured queries against the KG to answer them. In this paper, we introduce Chronos, a comprehensive evaluation framework for KGQA at industry scale. It is designed to evaluate such a multi-component system comprehensively, focusing on (1) end-to-end and component-level metrics, (2) scalable to diverse datasets and (3) a scalable approach to measure the performance of the system prior to release. In this paper, we discuss the unique challenges associated with evaluating KGQA systems at industry scale, review the design of Chronos, and how it addresses these challenges. We will demonstrate how it provides a base for data-driven decisions and discuss the challenges of using it to measure and improve a real-world KGQA system.', 'abstract_zh': '基于知识图谱（KGQA）的问答系统，根据知识图谱中的数据回答事实性问题。KGQA系统复杂，因为系统需要理解知识求索自然语言查询中的关系和实体，并将它们映射到针对知识图谱的结构化查询以进行回答。本文介绍了一种名为Chronos的全面评价框架，用于大规模工业领域的KGQA系统评估。该框架旨在全面评估由多个组件构成的系统，重点关注（1）端到端和组件级指标（2）适用于多种数据集（3）在发布前可扩展地衡量系统性能。在本文中，我们将讨论在大规模工业领域评估KGQA系统所面临的独特挑战，回顾Chronos的设计及其如何解决这些问题。我们还将展示它如何为数据驱动决策提供基础，并讨论使用它来衡量和改进实际KGQA系统所面临的挑战。', 'title_zh': '大规模知识图谱问答服务的综合评估'}
{'arxiv_id': 'arXiv:2501.17265', 'title': 'Giving the Old a Fresh Spin: Quality Estimation-Assisted Constrained Decoding for Automatic Post-Editing', 'authors': 'Sourabh Deoghare, Diptesh Kanojia, Pushpak Bhattacharyya', 'link': 'https://arxiv.org/abs/2501.17265', 'abstract': 'Automatic Post-Editing (APE) systems often struggle with over-correction, where unnecessary modifications are made to a translation, diverging from the principle of minimal editing. In this paper, we propose a novel technique to mitigate over-correction by incorporating word-level Quality Estimation (QE) information during the decoding process. This method is architecture-agnostic, making it adaptable to any APE system, regardless of the underlying model or training approach. Our experiments on English-German, English-Hindi, and English-Marathi language pairs show the proposed approach yields significant improvements over their corresponding baseline APE systems, with TER gains of $0.65$, $1.86$, and $1.44$ points, respectively. These results underscore the complementary relationship between QE and APE tasks and highlight the effectiveness of integrating QE information to reduce over-correction in APE systems.', 'abstract_zh': '自动后编辑（APE）系统往往难以避免过度编辑的问题，即在翻译中做了不必要的修改，违背了最小编辑原则。本文提出了一种新的技术，通过在解码过程中结合词级质量评估（QE）信息来缓解过度编辑。该方法具有架构无关性，适用于任何APE系统，不论其底层模型或训练方法。我们在英语-德语、英语-印地语和英语-马拉地语语言对上的实验表明，所提出的方法在对应的基线APE系统上取得了显著的改进，分别在TER（翻译编辑比率）上提高了0.65、1.86和1.44个点。这些结果强调了QE和APE任务之间的互补关系，并突显了整合QE信息以减少APE系统中过度编辑的有效性。', 'title_zh': '给传统方法注入新活力：基于质量评估的约束解码自动后编辑'}
{'arxiv_id': 'arXiv:2501.17261', 'title': 'NUS-Emo at SemEval-2024 Task 3: Instruction-Tuning LLM for Multimodal Emotion-Cause Analysis in Conversations', 'authors': 'Meng Luo, Han Zhang, Shengqiong Wu, Bobo Li, Hong Han, Hao Fei', 'link': 'https://arxiv.org/abs/2501.17261', 'abstract': 'This paper describes the architecture of our system developed for Task 3 of SemEval-2024: Multimodal Emotion-Cause Analysis in Conversations. Our project targets the challenges of subtask 2, dedicated to Multimodal Emotion-Cause Pair Extraction with Emotion Category (MECPE-Cat), and constructs a dual-component system tailored to the unique challenges of this task. We divide the task into two subtasks: emotion recognition in conversation (ERC) and emotion-cause pair extraction (ECPE). To address these subtasks, we capitalize on the abilities of Large Language Models (LLMs), which have consistently demonstrated state-of-the-art performance across various natural language processing tasks and domains. Most importantly, we design an approach of emotion-cause-aware instruction-tuning for LLMs, to enhance the perception of the emotions with their corresponding causal rationales. Our method enables us to adeptly navigate the complexities of MECPE-Cat, achieving a weighted average 34.71% F1 score of the task, and securing the 2nd rank on the leaderboard. The code and metadata to reproduce our experiments are all made publicly available.', 'abstract_zh': '本文描述了我们为SemEval-2024任务3：对话多模态情感原因分析系统开发的架构。我们的项目针对子任务2，即多模态情感原因配对提取（带情感类别）（MECPE-Cat）所面临的挑战，并构建了一个双组件系统，以应对这一任务的独特挑战。我们将任务细分为两个子任务：对话中的情感识别（ERC）和情感原因配对提取（ECPE）。为了解决这些子任务，我们利用了大型语言模型（LLMs）的能力，这些模型在各种自然语言处理任务和领域中始终表现出最先进的性能。最重要的是，我们设计了一种情感-原因意识的指令微调方法，以增强LLMs对情感及其相应因果分析的感知能力。我们的方法使我们能够熟练应对MECPE-Cat的复杂性，任务加权平均F1得分为34.71%，并取得了排行榜第2名的成绩。我们已将复现实验所需的代码和元数据全部公开。', 'title_zh': '新加坡国立大学情感分析团队在SemEval-2024 任务3中的研究成果：通过指令调优大语言模型进行多模态对话情感成因分析'}
{'arxiv_id': 'arXiv:2501.17200', 'title': 'Improving LLM Leaderboards with Psychometrical Methodology', 'authors': 'Denis Federiakin', 'link': 'https://arxiv.org/abs/2501.17200', 'abstract': 'The rapid development of large language models (LLMs) has necessitated the creation of benchmarks to evaluate their performance. These benchmarks resemble human tests and surveys, as they consist of sets of questions designed to measure emergent properties in the cognitive behavior of these systems. However, unlike the well-defined traits and abilities studied in social sciences, the properties measured by these benchmarks are often vaguer and less rigorously defined. The most prominent benchmarks are often grouped into leaderboards for convenience, aggregating performance metrics and enabling comparisons between models. Unfortunately, these leaderboards typically rely on simplistic aggregation methods, such as taking the average score across benchmarks. In this paper, we demonstrate the advantages of applying contemporary psychometric methodologies - originally developed for human tests and surveys - to improve the ranking of large language models on leaderboards. Using data from the Hugging Face Leaderboard as an example, we compare the results of the conventional naive ranking approach with a psychometrically informed ranking. The findings highlight the benefits of adopting psychometric techniques for more robust and meaningful evaluation of LLM performance.', 'abstract_zh': '大型语言模型（LLMs）的快速发展促使我们创建基准来评估其性能。这些基准类似于人类测试和调查，它们由一系列旨在衡量这些系统认知行为中涌现属性的问题组成。然而，与社会科学中已经明确定义的特质和能力不同，这些基准所测量的属性通常较为模糊且定义不够严谨。最突出的基准通常出于便利性而被分组到排行榜中，汇总性能指标并使模型之间的比较成为可能。不幸的是，这些排行榜通常依赖于简单的汇总方法，例如取基准的平均分。在本文中，我们展示了将现代心理测量学方法应用于改进大型语言模型排行榜的优势——这些方法最初是为人类测试和调查开发的。使用Hugging Face排行榜的数据为例，我们将传统简单的排名方法与基于心理测量学的方法进行比较。研究结果突显了采用心理测量技术对大型语言模型性能进行更为稳健和有意义评估的优势。', 'title_zh': '使用心理测量方法提高大型语言模型排行榜效果'}
{'arxiv_id': 'arXiv:2501.17195', 'title': 'Atla Selene Mini: A General Purpose Evaluation Model', 'authors': 'Andrei Alexandru, Antonia Calvi, Henry Broomfield, Jackson Golden, Kyle Dai, Mathias Leys, Maurice Burger, Max Bartolo, Roman Engeler, Sashank Pisupati, Toby Drane, Young Sun Park', 'link': 'https://arxiv.org/abs/2501.17195', 'abstract': 'We introduce Atla Selene Mini, a state-of-the-art small language model-as-a-judge (SLMJ). Selene Mini is a general-purpose evaluator that outperforms the best SLMJs and GPT-4o-mini on overall performance across 11 out-of-distribution benchmarks, spanning absolute scoring, classification, and pairwise preference tasks. It is the highest-scoring 8B generative model on RewardBench, surpassing strong baselines like GPT-4o and specialized judges. To achieve this, we develop a principled data curation strategy that augments public datasets with synthetically generated critiques and ensures high quality through filtering and dataset ablations. We train our model on a combined direct preference optimization (DPO) and supervised fine-tuning (SFT) loss, and produce a highly promptable evaluator that excels in real-world scenarios. Selene Mini shows dramatically improved zero-shot agreement with human expert evaluations on financial and medical industry datasets. It is also robust to variations in prompt format. Preliminary results indicate that Selene Mini is the top-ranking evaluator in a live, community-driven Judge Arena. We release the model weights on HuggingFace (this https URL) and Ollama to encourage widespread community adoption.', 'abstract_zh': '我们介绍了Atla Selene Mini，这是一个最先进的小型语言模型作为法官（SLMJ）。Selene Mini 是一种通用的评估器，在11个跨分布基准测试中，在绝对评分、分类和成对偏好任务上总体表现优于现有的最佳SLMJ和GPT-4o-mini。它在RewardBench中以8B生成模型的身份获得了最高分，超过了包括GPT-4o和专门的评估器在内的强基线模型。为了实现这一目标，我们开发了一种原则性的数据策展策略，通过添加合成生成的批评意见来扩充公共数据集，并通过过滤和数据集裁剪确保高质量。我们在直接偏好优化（DPO）和监督微调（SFT）损失的基础上训练了我们的模型，生成了一个在现实世界场景中表现出色、响应能力极强的评估器。Selene Mini 在金融和医疗行业数据集上的零-shot一致性与人类专家评估相比显著提高，同时对提示格式的变化具有鲁棒性。初步结果显示，Selene Mini 在一个由社区驱动的实时法官赛场上排名最高。我们已在HuggingFace（https://）和Ollama上发布了模型权重，以促进社区广泛采用。', 'title_zh': '阿特拉塞勒内迷你：一个通用评估模型'}
{'arxiv_id': 'arXiv:2501.17194', 'title': 'AI-assisted German Employment Contract Review: A Benchmark Dataset', 'authors': 'Oliver Wardas, Florian Matthes', 'link': 'https://arxiv.org/abs/2501.17194', 'abstract': 'Employment contracts are used to agree upon the working conditions between employers and employees all over the world. Understanding and reviewing contracts for void or unfair clauses requires extensive knowledge of the legal system and terminology. Recent advances in Natural Language Processing (NLP) hold promise for assisting in these reviews. However, applying NLP techniques on legal text is particularly difficult due to the scarcity of expert-annotated datasets. To address this issue and as a starting point for our effort in assisting lawyers with contract reviews using NLP, we release an anonymized and annotated benchmark dataset for legality and fairness review of German employment contract clauses, alongside with baseline model evaluations.', 'abstract_zh': '就业合同用于世界各地的雇主与雇员约定工作条件。理解和审查合同中的无效或不公平条款需要广泛的法律体系和术语知识。近年来，自然语言处理（NLP）技术的发展为这些审查提供了希望。然而，由于缺乏经过专家注释的数据集，将NLP技术应用于法律文本特别困难。为了解决这一问题，并作为我们使用NLP辅助律师进行合同审查的努力的起点，我们发布了一个匿名且注释好的基准数据集，用于德国就业合同条款的合法性和公平性审查，并同时提供了基线模型评估。', 'title_zh': 'AI辅助的German Employment Contract审查：一个基准数据集'}
{'arxiv_id': 'arXiv:2501.17191', 'title': 'Aspect-Aware Decomposition for Opinion Summarization', 'authors': 'Miao Li, Jey Han Lau, Eduard Hovy, Mirella Lapata', 'link': 'https://arxiv.org/abs/2501.17191', 'abstract': 'Opinion summarization plays a key role in deriving meaningful insights from large-scale online reviews. To make this process more explainable and grounded, we propose a modular approach guided by review aspects which separates the tasks of aspect identification, opinion consolidation, and meta-review synthesis, enabling greater transparency and ease of inspection. We conduct extensive experiments across datasets representing scientific research, business, and product domains. Results show that our method generates more grounded summaries compared to strong baseline models, as verified through automated and human evaluations. Additionally, our modular approach, which incorporates reasoning based on review aspects, produces more informative intermediate outputs than knowledge-agnostic decomposed prompting. These intermediate outputs can also effectively support humans in summarizing opinions from large volumes of reviews.', 'abstract_zh': '意见总结在从大量在线评论中提取有意义的见解中起着关键作用。为了使这一过程更具可解释性和现实性，我们提出了一种模块化方法，该方法以评论方面为导向，将方面识别、意见整合和元评论综合的任务分离，从而增强透明度并简化检查。我们在涉及科学研究、商业和产品领域的数据集上进行了广泛的实验。结果表明，与强基线模型相比，我们的方法生成的总结更具现实性，经过自动和人工评估验证。此外，我们的模块化方法，其推理基于评论方面，生成的信息性中间输出优于缺乏知识的分解提示方法。这些中间输出也可以有效支持人们从大量评论中总结意见。', 'title_zh': '面向方面的情感总结分解方法'}
{'arxiv_id': 'arXiv:2501.17190', 'title': 'A Comprehensive Study on Fine-Tuning Large Language Models for Medical Question Answering Using Classification Models and Comparative Analysis', 'authors': 'Aysegul Ucar, Soumik Nayak, Anunak Roy, Burak Taşcı, Gülay Taşcı', 'link': 'https://arxiv.org/abs/2501.17190', 'abstract': 'This paper presents the overview of the development and fine-tuning of large language models (LLMs) designed specifically for answering medical questions. We are mainly improving the accuracy and efficiency of providing reliable answers to medical queries. In our approach, we have two stages, prediction of a specific label for the received medical question and then providing a predefined answer for this label. Various models such as RoBERTa and BERT were examined and evaluated based on their ability. The models are trained using the datasets derived from 6,800 samples that were scraped from Healthline. com with additional synthetic data. For evaluation, we conducted a comparative study using 5-fold cross-validation. For accessing performance we used metrics like, accuracy, precision, recall, and F1 score and also recorded the training time. The performance of the models was evaluated using 5-fold cross-validation. The LoRA Roberta-large model achieved an accuracy of 78.47%, precision of 72.91%, recall of 76.95%, and an F1 score of 73.56%. The Roberta-base model demonstrated high performance with an accuracy of 99.87%, precision of 99.81%, recall of 99.86%, and an F1 score of 99.82%. The Bert Uncased model showed strong results with an accuracy of 95.85%, precision of 94.42%, recall of 95.58%, and an F1 score of 94.72%. Lastly, the Bert Large Uncased model achieved the highest performance, with an accuracy, precision, recall, and F1 score of 100%. The results obtained have helped indicate the capability of the models in classifying the medical questions and generating accurate answers in the prescription of improved health-related AI solutions.', 'abstract_zh': '本文概述了专门针对医学问题回答的大语言模型（LLMs）的发展和微调过程。我们主要致力于提高提供可靠医学查询答案的准确性和效率。在我们的方法中，分为两个阶段：预测收到的医学问题的具体标签，然后提供预定义的相应答案。我们对RoBERTa和BERT等模型进行了评估，基于其能力对这些模型进行了考察。模型使用从Healthline.com抓取的6,800个样本数据集以及额外的合成数据进行训练。为评估模型性能，我们采用了5折交叉验证的方法，并使用了包括准确率、精确度、召回率和F1分数在内的指标，同时也记录了训练时间。模型性能通过5折交叉验证进行评估。LoRA RoBERTa-large模型的准确率为78.47%，精确度为72.91%，召回率为76.95%，F1分数为73.56%。RoBERTa-base模型表现出高水平的性能，准确率为99.87%，精确度为99.81%，召回率为99.86%，F1分数为99.82%。未加标点的BERT模型表现出强大的性能，准确率为95.85%，精确度为94.42%，召回率为95.58%，F1分数为94.72%。最后，未加标点的BERT-large模型达到最高性能，其准确度、精确度、召回率和F1分数均为100%。所获得的结果有助于表明模型在分类医学问题和生成准确答案方面的能力，并为进一步改善健康相关的人工智能解决方案提供了依据。', 'title_zh': '使用分类模型进行医疗问答的大规模语言模型微调综合研究及比较分析'}
{'arxiv_id': 'arXiv:2501.17187', 'title': 'Visualizing Uncertainty in Translation Tasks: An Evaluation of LLM Performance and Confidence Metrics', 'authors': 'Jin Hyun Park, Utsawb Laminchhane, Umer Farooq, Uma Sivakumar, Arpan Kumar', 'link': 'https://arxiv.org/abs/2501.17187', 'abstract': 'Large language models (LLMs) are increasingly utilized for machine translation, yet their predictions often exhibit uncertainties that hinder interpretability and user trust. Effectively visualizing these uncertainties can enhance the usability of LLM outputs, particularly in contexts where translation accuracy is critical. This paper addresses two primary objectives: (1) providing users with token-level insights into model confidence and (2) developing a web-based visualization tool to quantify and represent translation uncertainties. To achieve these goals, we utilized the T5 model with the WMT19 dataset for translation tasks and evaluated translation quality using established metrics such as BLEU, METEOR, and ROUGE. We introduced three novel uncertainty quantification (UQ) metrics: (1) the geometric mean of token probabilities, (2) the arithmetic mean of token probabilities, and (3) the arithmetic mean of the kurtosis of token distributions. These metrics provide a simple yet effective framework for evaluating translation performance. Our analysis revealed a linear relationship between the traditional evaluation metrics and our UQ metrics, demonstrating the validity of our approach. Additionally, we developed an interactive web-based visualization that uses a color gradient to represent token confidence. This tool offers users a clear and intuitive understanding of translation quality while providing valuable insights into model performance. Overall, we show that our UQ metrics and visualization are both robust and interpretable, offering practical tools for evaluating and accessing machine translation systems.', 'abstract_zh': '大型语言模型（LLMs）在机器翻译中的应用日益增多，但它们的预测常常表现出不确定性和不透明性，这妨碍了译文的可解释性和用户信任。有效地可视化这些不确定性可以提高LLM输出的可用性，尤其是在翻译准确性至关重要的情况下。本文旨在实现两个主要目标：（1）为用户提供模型置信度的字符级洞察；（2）开发一种基于网络的可视化工具来量化和表示翻译不确定性。为了实现这些目标，我们使用T5模型和WMT19数据集进行了翻译任务，并使用已建立的评价指标如BLEU、METEOR和ROUGE来评估翻译质量。我们引入了三项新颖的不确定性量化（UQ）指标：（1）令牌概率的几何平均值；（2）令牌概率的算术平均值；（3）令牌分布偏度的算术平均值。这些指标提供了一个简单且有效的框架来评估翻译性能。我们的分析揭示了传统评价指标与我们的UQ指标之间存在线性关系，这证明了我们方法的有效性。此外，我们还开发了一个交互式的基于网络的可视化工具，通过颜色渐变来表示令牌置信度。该工具为用户提供了一个清晰且直观的翻译质量理解方式，并提供了关于模型性能的重要洞察。总之，我们展示了我们的UQ指标和可视化工具既坚固又可解释，为评估和访问机器翻译系统提供了实用工具。', 'title_zh': '翻译如下，符合学术规范的中文标题：\n\n基于可视化方法在翻译任务中不确定性评估：大规模语言模型性能与信心度量评价'}
{'arxiv_id': 'arXiv:2501.17183', 'title': 'LLM Evaluation Based on Aerospace Manufacturing Expertise: Automated Generation and Multi-Model Question Answering', 'authors': 'Beiming Liu, Zhizhuo Cui, Siteng Hu, Xiaohua Li, Haifeng Lin, Zhengxin Zhang', 'link': 'https://arxiv.org/abs/2501.17183', 'abstract': 'Aerospace manufacturing demands exceptionally high precision in technical parameters. The remarkable performance of Large Language Models (LLMs), such as GPT-4 and QWen, in Natural Language Processing has sparked industry interest in their application to tasks including process design, material selection, and tool information retrieval. However, LLMs are prone to generating "hallucinations" in specialized domains, producing inaccurate or false information that poses significant risks to the quality of aerospace products and flight safety. This paper introduces a set of evaluation metrics tailored for LLMs in aerospace manufacturing, aiming to assess their accuracy by analyzing their performance in answering questions grounded in professional knowledge. Firstly, key information is extracted through in-depth textual analysis of classic aerospace manufacturing textbooks and guidelines. Subsequently, utilizing LLM generation techniques, we meticulously construct multiple-choice questions with multiple correct answers of varying difficulty. Following this, different LLM models are employed to answer these questions, and their accuracy is recorded. Experimental results demonstrate that the capabilities of LLMs in aerospace professional knowledge are in urgent need of improvement. This study provides a theoretical foundation and practical guidance for the application of LLMs in aerospace manufacturing, addressing a critical gap in the field.', 'abstract_zh': '航空航天制造对技术参数的要求极为严格。大型语言模型（LLMs），如GPT-4和Qwen，在自然语言处理领域的显著性能吸引了业界对其在工艺设计、材料选择和工具信息检索等方面应用的兴趣。然而，LLMs 在专业领域内容易产生“幻觉”，即生成不准确或虚假的信息，这对航空航天产品质量和飞行安全构成了重大风险。本文旨在为LLMs在航空航天制造中的应用提供一套定制化的评估指标，通过分析其在基于专业知识的问题回答中的表现来评估其准确性。首先，通过深入分析经典航空航天制造教科书和指导手册提取关键信息。其次，利用LLMs生成技术，精心构建了包含多个正确答案且难度不一的选择题。然后，使用不同的LLM模型回答这些问题，并记录其准确性。实验结果表明，LLMs在航空航天专业知识方面的能力亟待提升。本研究为LLMs在航空航天制造中的应用提供了理论基础和实践指导，填补了该领域的关键空白。', 'title_zh': '基于航空航天制造专业知识的大型语言模型评估：自动化生成与多模型问答'}
{'arxiv_id': 'arXiv:2501.17182', 'title': 'Dialogue Systems for Emotional Support via Value Reinforcement', 'authors': 'Juhee Kim, Chunghu Mok, Jisun Lee, Hyang Sook Kim, Yohan Jo', 'link': 'https://arxiv.org/abs/2501.17182', 'abstract': "Emotional support dialogue systems aim to reduce help-seekers' distress and help them overcome challenges. While human values$\\unicode{x2013}$core beliefs that shape an individual's priorities$\\unicode{x2013}$are increasingly emphasized in contemporary psychological therapy for their role in fostering internal transformation and long-term emotional well-being, their integration into emotional support systems remains underexplored. To bridge this gap, we present a value-driven method for training emotional support dialogue systems designed to reinforce positive values in seekers. Our model learns to identify which values to reinforce at each turn and how to do so, by leveraging online support conversations from Reddit. The model demonstrated superior performance in emotional support capabilities, outperforming various baselines. Notably, it more effectively explored and elicited values from seekers. Expert assessments by therapists highlighted two key strengths of our model: its ability to validate users' challenges and its effectiveness in emphasizing positive aspects of their situations$\\unicode{x2013}$both crucial elements of value reinforcement. Our work validates the effectiveness of value reinforcement for emotional support systems and establishes a foundation for future research.", 'abstract_zh': '情感支持对话系统旨在减轻寻求帮助者的情感困扰，并帮助他们克服挑战。随着人类价值观——塑造个体优先级的核心信念——在当代心理治疗中逐渐受到重视，因其在促进内在转变和长期情感福祉方面的作用，如何将其整合到情感支持系统中仍然有待进一步探索。为填补这一空白，我们提出了一种基于价值观的方法，用于训练情感支持对话系统，旨在强化寻求者的积极价值观。该模型通过利用来自Reddit的在线支持对话，学习在每次对话中识别应强化哪些价值观以及如何进行强化。实验证明，该模型在情感支持能力上表现 superior，优于各种基线模型。值得注意的是，它能更有效地探索和激发寻求者的价值观。治疗师的专业评估指出，该模型的两个关键优势在于其能够验证用户面临的挑战以及有效强调其情境中的积极方面——这些都是价值观强化的关键要素。我们的研究验证了价值观强化对情感支持系统的有效性，并为未来研究奠定了基础。', 'title_zh': '基于价值强化的对话系统在情感支持中的应用'}
{'arxiv_id': 'arXiv:2501.17178', 'title': 'Tuning LLM Judges Hyperparameters', 'authors': 'David Salinas, Omar Swelam, Frank Hutter', 'link': 'https://arxiv.org/abs/2501.17178', 'abstract': 'Evaluating Large Language Models (LLMs) often requires costly human annotations. To address this, LLM-based judges have been proposed, which compare the outputs of two LLMs enabling the ranking of models without human intervention. While several approaches have been proposed, many confounding factors are present between different papers. For instance the model, the prompt and other hyperparameters are typically changed at the same time making apple-to-apple comparisons challenging. In this paper, we propose to systematically analyze and tune hyperparameter of LLM judges. To alleviate the high cost of evaluating a judge, we propose to leverage multi-objective multi-fidelity which allows to find judges that trades accuracy for cost and also reduce significantly the cost of the search. Our method identifies judges that not only outperform existing benchmarks in accuracy and cost-efficiency but also utilize open-weight models, ensuring greater accessibility and reproducibility.', 'abstract_zh': '评估大型语言模型（LLMs）通常需要成本高昂的人工注释。为了解决这一问题，提出了基于LLM的裁判系统，这种系统可以通过比较两个LLM的输出来对模型进行排名，而无需人工干预。尽管已经提出了一些方法，但不同论文之间存在诸多混淆因素。例如，模型、提示和超参数通常同时变化，这使得直接对比变得困难。本文中，我们提出了一种系统的方法来分析和调整LLM裁判的超参数。为了减轻评估裁判的成本，我们提出了一种多目标多保真度方法，该方法可以在准确性和成本之间进行权衡，同时也大大降低了搜索成本。我们的方法不仅在准确性和成本效益上超越了现有基准，还利用了开放权重模型，从而确保了更大的可访问性和可重复性。', 'title_zh': '调整大语言模型法官的超参数'}
{'arxiv_id': 'arXiv:2501.17175', 'title': 'Document-Level Sentiment Analysis of Urdu Text Using Deep Learning Techniques', 'authors': 'Ammarah Irum, M. Ali Tahir', 'link': 'https://arxiv.org/abs/2501.17175', 'abstract': 'Document level Urdu Sentiment Analysis (SA) is a challenging Natural Language Processing (NLP) task as it deals with large documents in a resource-poor language. In large documents, there are ample amounts of words that exhibit different viewpoints. Deep learning (DL) models comprise of complex neural network architectures that have the ability to learn diverse features of the data to classify various sentiments. Besides audio, image and video classification; DL algorithms are now extensively used in text-based classification problems. To explore the powerful DL techniques for Urdu SA, we have applied five different DL architectures namely, Bidirectional Long Short Term Memory (BiLSTM), Convolutional Neural Network (CNN), Convolutional Neural Network with Bidirectional Long Short Term Memory (CNN-BiLSTM), Bidirectional Encoder Representation from Transformer (BERT). In this paper, we have proposed a DL hybrid model that integrates BiLSTM with Single Layer Multi Filter Convolutional Neural Network (BiLSTM-SLMFCNN). The proposed and baseline techniques are applied on Urdu Customer Support data set and IMDB Urdu movie review data set by using pretrained Urdu word embeddings that are suitable for (SA) at the document level. Results of these techniques are evaluated and our proposed model outperforms all other DL techniques for Urdu SA. BiLSTM-SLMFCNN outperformed the baseline DL models and achieved 83{\\%}, 79{\\%}, 83{\\%} and 94{\\%} accuracy on small, medium and large sized IMDB Urdu movie review data set and Urdu Customer Support data set respectively.', 'abstract_zh': '针对文档级乌尔都语情感分析（SA）的任务是一项挑战性的自然语言处理（NLP）任务，因为这涉及对资源贫乏语言中的大型文档进行分析。在大型文档中，存在大量表现出不同观点的单词。深度学习（DL）模型采用复杂的神经网络架构，能够学习数据的多种特征以分类各种情感。除了音频、图像和视频分类之外，DL 算法现在广泛应用于基于文本的情感分类问题中。为了探索强大的 DL 技术在乌尔都语情感分析中的应用，我们应用了五种不同的 DL 架构，包括双向长短时记忆网络（BiLSTM）、卷积神经网络（CNN）、带有双向长短时记忆网络的卷积神经网络（CNN-BiLSTM）以及来自变换器的双向编码表示（BERT）。在本文中，我们提出了一种结合双向长短时记忆网络和单层多滤波卷积神经网络的 DL 混合模型（BiLSTM-SLMFCNN）。提出的模型和基线方法分别在乌尔都语客户支持数据集和IMDB乌尔都语电影评论数据集上应用，并使用预训练的乌尔都语词嵌入，这些词嵌入适用于文档级的情感分析。这些技术的结果进行了评估，我们的提出模型在所有其他 DL 技术中表现最佳。在 IMDB 乌尔都语电影评论数据集和乌尔都语客户支持数据集的小型、中型和大型数据集上，BiLSTM-SLMFCNN 的准确率分别为 83%，79%，83% 和 94%。', 'title_zh': '使用深度学习技术的 Urdu 文本文档级情感分析'}
{'arxiv_id': 'arXiv:2501.17811', 'title': 'Janus-Pro: Unified Multimodal Understanding and Generation with Data and Model Scaling', 'authors': 'Xiaokang Chen, Zhiyu Wu, Xingchao Liu, Zizheng Pan, Wen Liu, Zhenda Xie, Xingkai Yu, Chong Ruan', 'link': 'https://arxiv.org/abs/2501.17811', 'abstract': 'In this work, we introduce Janus-Pro, an advanced version of the previous work Janus. Specifically, Janus-Pro incorporates (1) an optimized training strategy, (2) expanded training data, and (3) scaling to larger model size. With these improvements, Janus-Pro achieves significant advancements in both multimodal understanding and text-to-image instruction-following capabilities, while also enhancing the stability of text-to-image generation. We hope this work will inspire further exploration in the field. Code and models are publicly available.', 'abstract_zh': '在本文中，我们介绍了Janus-Pro，这是之前工作的Janus的先进版本。具体而言，Janus-Pro 包含以下改进：（1）优化的训练策略；（2）扩展的训练数据；以及（3）较大的模型规模。通过这些改进，Janus-Pro 在多模态理解以及文本到图像指令遵循能力方面取得了显著进步，同时提高了文本到图像生成的稳定性。我们希望本工作能够激发领域内的进一步探索。相关代码和模型已公开提供。', 'title_zh': 'Janus-Pro：统一的多模态理解和生成方法通过数据和模型扩展'}
{'arxiv_id': 'arXiv:2501.17762', 'title': 'Improving Privacy Benefits of Redaction', 'authors': 'Vaibhav Gusain, Douglas Leith', 'link': 'https://arxiv.org/abs/2501.17762', 'abstract': 'We propose a novel redaction methodology that can be used to sanitize natural text data. Our new technique provides better privacy benefits than other state of the art techniques while maintaining lower redaction levels.', 'abstract_zh': '我们提出了一种新颖的脱敏方法，可用于净化自然文本数据。与现有的其他先进方法相比，我们的新技术在保持较低脱敏程度的同时提供了更好的隐私保护效益。', 'title_zh': '提高脱敏处理的隐私保护效益'}
{'arxiv_id': 'arXiv:2501.17726', 'title': 'VICCA: Visual Interpretation and Comprehension of Chest X-ray Anomalies in Generated Report Without Human Feedback', 'authors': 'Sayeh Gholipour Picha, Dawood Al Chanti, Alice Caplier', 'link': 'https://arxiv.org/abs/2501.17726', 'abstract': 'As artificial intelligence (AI) becomes increasingly central to healthcare, the demand for explainable and trustworthy models is paramount. Current report generation systems for chest X-rays (CXR) often lack mechanisms for validating outputs without expert oversight, raising concerns about reliability and interpretability. To address these challenges, we propose a novel multimodal framework designed to enhance the semantic alignment and localization accuracy of AI-generated medical reports. Our framework integrates two key modules: a Phrase Grounding Model, which identifies and localizes pathologies in CXR images based on textual prompts, and a Text-to-Image Diffusion Module, which generates synthetic CXR images from prompts while preserving anatomical fidelity. By comparing features between the original and generated images, we introduce a dual-scoring system: one score quantifies localization accuracy, while the other evaluates semantic consistency. This approach significantly outperforms existing methods, achieving state-of-the-art results in pathology localization and text-to-image alignment. The integration of phrase grounding with diffusion models, coupled with the dual-scoring evaluation system, provides a robust mechanism for validating report quality, paving the way for more trustworthy and transparent AI in medical imaging.', 'abstract_zh': '随着人工智能（AI）在医疗保健领域的日益重要，可解释性和可信度模型的需求至关重要。当前的胸部X光片（CXR）报告生成系统在缺乏专家监督的情况下难以验证输出，这引发了可靠性和可解释性的担忧。为了解决这些问题，我们提出了一种新颖的多模态框架，旨在增强AI生成的医疗报告的语义对齐和定位准确性。该框架整合了两个关键模块：一个短语接地模型，该模型基于文本提示在CXR图像中识别并定位病理；以及一个文本到图像扩散模块，该模块根据提示生成合成的CXR图像，同时保留解剖的真实性。通过比较原始图像和生成图像之间的特征，我们引入了一种双评分系统：一个评分衡量定位准确性，而另一个则评估语义一致性。这种方法显著优于现有方法，在病理定位和文本到图像对齐方面达到了最先进的结果。将短语接地与扩散模型相结合，并采用双评分评估系统，提供了一种可靠的报告验证机制，为医疗成像中更可信和透明的人工智能铺平了道路。', 'title_zh': 'VICCA：生成报告中胸部X光异常的视觉解释与理解，无需人类反馈'}
{'arxiv_id': 'arXiv:2501.17725', 'title': 'Using Code Generation to Solve Open Instances of Combinatorial Design Problems', 'authors': 'Christopher D. Rosin', 'link': 'https://arxiv.org/abs/2501.17725', 'abstract': 'The Handbook of Combinatorial Designs catalogs many types of combinatorial designs, together with lists of open instances for which existence has not yet been determined. We develop a constructive protocol CPro1, which uses Large Language Models (LLMs) to generate code that constructs combinatorial designs and resolves some of these open instances. The protocol starts from a definition of a particular type of design, and a verifier that reliably confirms whether a proposed design is valid. The LLM selects strategies and implements them in code, and scaffolding provides automated hyperparameter tuning and execution feedback using the verifier. Most generated code fails, but by generating many candidates, the protocol automates exploration of a variety of standard methods (e.g. simulated annealing, genetic algorithms) and experimentation with variations (e.g. cost functions) to find successful approaches. Testing on 16 different types of designs, CPro1 constructs solutions to open instances for 6 of them: Symmetric and Skew Weighing Matrices, Equidistant Permutation Arrays, Packing Arrays, Balanced Ternary Designs, and Florentine Rectangles.', 'abstract_zh': '《组合设计手册》记载了多种类型的组合设计，并列出了存在性尚未确定的一些开放实例。我们开发了一种构造性协议CPro1，该协议利用大型语言模型（LLMs）生成构建组合设计的代码，并解决了一些开放实例。该协议从定义特定类型的组合设计及其验证器开始，验证器能够可靠地确认所提出的组合设计的有效性。大型语言模型选择策略并在代码中实现这些策略，同时使用验证器提供自动化超参数调整和执行反馈。尽管生成的大多数代码失败，但通过生成大量候选方案，该协议自动探索了多种标准方法（例如模拟退火、遗传算法）并实验了变体（例如成本函数），从而找到成功的解决方法。在对16种不同类型的组合设计进行测试后，CPro1为其中6种设计构建了解决方案：对称和斜对称度量矩阵、等距置换数组、装载数组、平衡三元设计和佛罗伦萨矩形。', 'title_zh': '使用代码生成解决组合设计问题的开放实例'}
{'arxiv_id': 'arXiv:2501.17630', 'title': 'Uncertainty Quantification and Decomposition for LLM-based Recommendation', 'authors': 'Wonbin Kweon, Sanghwan Jang, SeongKu Kang, Hwanjo Yu', 'link': 'https://arxiv.org/abs/2501.17630', 'abstract': 'Despite the widespread adoption of large language models (LLMs) for recommendation, we demonstrate that LLMs often exhibit uncertainty in their recommendations. To ensure the trustworthy use of LLMs in generating recommendations, we emphasize the importance of assessing the reliability of recommendations generated by LLMs. We start by introducing a novel framework for estimating the predictive uncertainty to quantitatively measure the reliability of LLM-based recommendations. We further propose to decompose the predictive uncertainty into recommendation uncertainty and prompt uncertainty, enabling in-depth analyses of the primary source of uncertainty. Through extensive experiments, we (1) demonstrate predictive uncertainty effectively indicates the reliability of LLM-based recommendations, (2) investigate the origins of uncertainty with decomposed uncertainty measures, and (3) propose uncertainty-aware prompting for a lower predictive uncertainty and enhanced recommendation. Our source code and model weights are available at this https URL', 'abstract_zh': '尽管大型语言模型（LLMs）在推荐系统中被广泛应用，我们证明LLMs在推荐时常常表现出不确定性。为了确保LLMs在生成推荐时的可信使用，我们强调了评估LLMs生成推荐可靠性的必要性。我们首先引入了一个新颖的框架，用于估算预测不确定性，以定量衡量基于LLMs的推荐可靠性。进一步地，我们提出将预测不确定性分解为推荐不确定性和提示不确定性，从而深入分析不确定性的主要来源。通过大量实验，我们（1）证明预测不确定性有效地指示了基于LLMs的推荐可靠性，（2）利用分解后的不确定性指标探讨了不确定性的来源，并（3）提出了基于不确定性的提示策略以降低预测不确定性并增强推荐效果。我们的源代码和模型权重可从以下网址获取：this <https://> URL', 'title_zh': '基于LLM的推荐系统的不确定性量化与分解'}
{'arxiv_id': 'arXiv:2501.17584', 'title': 'GLLM: Self-Corrective G-Code Generation using Large Language Models with User Feedback', 'authors': 'Mohamed Abdelaal, Samuel Lokadjaja, Gilbert Engert', 'link': 'https://arxiv.org/abs/2501.17584', 'abstract': 'This paper introduces GLLM, an innovative tool that leverages Large Language Models (LLMs) to automatically generate G-code from natural language instructions for Computer Numerical Control (CNC) machining. GLLM addresses the challenges of manual G-code writing by bridging the gap between human-readable task descriptions and machine-executable code. The system incorporates a fine-tuned StarCoder-3B model, enhanced with domain-specific training data and a Retrieval-Augmented Generation (RAG) mechanism. GLLM employs advanced prompting strategies and a novel self-corrective code generation approach to ensure both syntactic and semantic correctness of the generated G-code. The architecture includes robust validation mechanisms, including syntax checks, G-code-specific verifications, and functional correctness evaluations using Hausdorff distance. By combining these techniques, GLLM aims to democratize CNC programming, making it more accessible to users without extensive programming experience while maintaining high accuracy and reliability in G-code generation.', 'abstract_zh': '本文介绍了GLLM，这是一种创新工具，利用大型语言模型（LLMs）自动从自然语言指令生成计算机数字控制（CNC）加工所需的G代码。GLLM通过在人类可读的任务描述与机器可执行代码之间搭建桥梁，解决了手动编写G代码的挑战。该系统结合了经过特定领域训练的StarCoder-3B模型，并增强了检索增强生成（RAG）机制。GLLM采用先进的提示策略和新颖的自我纠正代码生成方法，确保生成的G代码在语法和语义上都是正确的。该架构包括了稳健的验证机制，包括语法检查、G代码特定验证以及通过豪斯多夫距离进行的功能正确性评估。通过结合这些技术，GLLM旨在将CNC编程知识平民化，使具有有限编程经验的用户也能更方便地进行编程，同时保持G代码生成的高准确性和可靠性。', 'title_zh': 'GLLM：使用大型语言模型并在用户反馈基础上进行自我纠正的G-代码生成'}
{'arxiv_id': 'arXiv:2501.17510', 'title': 'LLM Assistance for Pediatric Depression', 'authors': 'Mariia Ignashina, Paulina Bondaronek, Dan Santel, John Pestian, Julia Ive', 'link': 'https://arxiv.org/abs/2501.17510', 'abstract': 'Traditional depression screening methods, such as the PHQ-9, are particularly challenging for children in pediatric primary care due to practical limitations. AI has the potential to help, but the scarcity of annotated datasets in mental health, combined with the computational costs of training, highlights the need for efficient, zero-shot approaches. In this work, we investigate the feasibility of state-of-the-art LLMs for depressive symptom extraction in pediatric settings (ages 6-24). This approach aims to complement traditional screening and minimize diagnostic errors.\nOur findings show that all LLMs are 60% more efficient than word match, with Flan leading in precision (average F1: 0.65, precision: 0.78), excelling in the extraction of more rare symptoms like "sleep problems" (F1: 0.92) and "self-loathing" (F1: 0.8). Phi strikes a balance between precision (0.44) and recall (0.60), performing well in categories like "Feeling depressed" (0.69) and "Weight change" (0.78). Llama 3, with the highest recall (0.90), overgeneralizes symptoms, making it less suitable for this type of analysis. Challenges include the complexity of clinical notes and overgeneralization from PHQ-9 scores. The main challenges faced by LLMs include navigating the complex structure of clinical notes with content from different times in the patient trajectory, as well as misinterpreting elevated PHQ-9 scores.\nWe finally demonstrate the utility of symptom annotations provided by Flan as features in an ML algorithm, which differentiates depression cases from controls with high precision of 0.78, showing a major performance boost compared to a baseline that does not use these features.', 'abstract_zh': '传统抑郁筛查方法，如PHQ-9量表，在儿科初级保健中特别具有挑战性，主要是因为实际操作上的限制。人工智能有可能帮助解决这个问题，但是心理健康领域标注数据的缺乏，以及训练模型所需的高昂计算成本，凸显了需要高效且零样本的方法。在本研究中，我们探讨了最先进的语言模型（LLMs）在儿科环境中（年龄6-24岁）提取抑郁症状的可能性，目的是补充传统的筛查方法并减少诊断错误。\n\n我们的研究发现，所有LLMs在效率上比基于单词匹配的方法高60%，其中Flan在准确率（平均F1值：0.65，准确率：0.78）方面表现最好，特别擅长提取如“睡眠问题”（F1值：0.92）和“自虐情结”（F1值：0.8）等罕见症状。Phi则在准确率（0.44）和召回率（0.60）之间取得了平衡，在“感到抑郁”（0.69）和“体重变化”（0.78）等类别上表现良好。Llama 3虽然召回率最高（0.90），但在症状描述上过于泛化，不太适合这种类型的分析。面临的挑战包括临床笔记内容的复杂性以及PHQ-9评分的过度泛化。LLMs所面临的最大挑战包括理解和处理患者治疗历程中不同时段内容的复杂结构，以及错误解释PHQ-9评分增高的情况。\n\n最后，我们展示了Flan提供的症状标注作为机器学习算法特征的应用，该算法能够以78%的高准确率区分抑郁病例与对照组，显示出比不使用这些特征的基线模型更高的性能提升。', 'title_zh': '儿科抑郁症的大型语言模型辅助治疗'}
{'arxiv_id': 'arXiv:2501.17479', 'title': 'DFPE: A Diverse Fingerprint Ensemble for Enhancing LLM Performance', 'authors': 'Seffi Cohen, Niv Goldshlager, Nurit Cohen-Inger, Bracha Shapira, Lior Rokach', 'link': 'https://arxiv.org/abs/2501.17479', 'abstract': 'Large Language Models (LLMs) have shown remarkable capabilities across various natural language processing tasks but often struggle to excel uniformly in diverse or complex domains. We propose a novel ensemble method - Diverse Fingerprint Ensemble (DFPE), which leverages the complementary strengths of multiple LLMs to achieve more robust performance. Our approach involves: (1) clustering models based on response "fingerprints" patterns, (2) applying a quantile-based filtering mechanism to remove underperforming models at a per-subject level, and (3) assigning adaptive weights to remaining models based on their subject-wise validation accuracy. In experiments on the Massive Multitask Language Understanding (MMLU) benchmark, DFPE outperforms the best single model by 3% overall accuracy and 5% in discipline-level accuracy. This method increases the robustness and generalization of LLMs and underscores how model selection, diversity preservation, and performance-driven weighting can effectively address challenging, multi-faceted language understanding tasks.', 'abstract_zh': '大规模语言模型（LLMs）在各种自然语言处理任务中展现了出色的性能，但在面对多样或复杂的领域时，往往难以全面表现出色。我们提出了一个新颖的集成方法——不同的指纹集成（Diverse Fingerprint Ensemble，DFPE），该方法利用多个LLM的优势互补性以获得更 robust 的性能。我们的方法包括：（1）基于响应“指纹”模式对模型进行聚类；（2）应用基于分位数的过滤机制，按主题逐个去除表现不佳的模型；（3）根据主题验证准确率为剩余模型分配自适应权重。在大规模多任务语言理解（MMLU）基准上的实验表明，DFPE的整体准确率和学科准确率分别比最佳单一模型高出3%和5%。该方法增强了LLMs的稳健性和泛化能力，并强调了在模型选择、保持多样性以及基于性能赋予权重在应对复杂多面的语言理解任务中的有效作用。', 'title_zh': 'DFPE：一种多元指纹ensemble方法以增强大语言模型性能'}
{'arxiv_id': 'arXiv:2501.17459', 'title': 'Large Language Models for Single-Step and Multi-Step Flight Trajectory Prediction', 'authors': 'Kaiwei Luo, Jiliu Zhou', 'link': 'https://arxiv.org/abs/2501.17459', 'abstract': "Flight trajectory prediction is a critical time series task in aviation. While deep learning methods have shown significant promise, the application of large language models (LLMs) to this domain remains underexplored. This study pioneers the use of LLMs for flight trajectory prediction by reframing it as a language modeling problem. Specifically, We extract features representing the aircraft's position and status from ADS-B flight data to construct a prompt-based dataset, where trajectory waypoints are converted into language tokens. The dataset is then employed to fine-tune LLMs, enabling them to learn complex spatiotemporal patterns for accurate predictions. Comprehensive experiments demonstrate that LLMs achieve notable performance improvements in both single-step and multi-step predictions compared to traditional methods, with LLaMA-3.1 model achieving the highest overall accuracy. However, the high inference latency of LLMs poses a challenge for real-time applications, underscoring the need for further research in this promising direction.", 'abstract_zh': '飞行轨迹预测是航空领域中的一个关键的时间序列任务。虽然深度学习方法已经展现出显著的潜力，但将大型语言模型（LLMs）应用于该领域仍然少有人探索。本研究率先通过重新构架为语言建模问题来利用LLMs进行飞行轨迹预测。具体来说，我们从ADS-B飞行数据中提取表示飞机位置和状态的特征，构建基于提示的数据集，其中轨迹航点被转换为语言令牌。然后使用该数据集对LLMs进行微调，使其能够学习复杂的时空模式以进行准确的预测。全面的实验表明，与传统方法相比，LLMs在单步预测和多步预测中均取得了显著的性能提升，LLaMA-3.1模型实现了最高的总体准确率。然而，LLMs的高推理延迟为实时应用带来了挑战，这突显了对该有前途方向进一步研究的必要性。', 'title_zh': '大型语言模型在单步和多步飞行轨迹预测中的应用'}
{'arxiv_id': 'arXiv:2501.17456', 'title': 'A review on the novelty measurements of academic papers', 'authors': 'Yi Zhao, Chengzhi Zhang', 'link': 'https://arxiv.org/abs/2501.17456', 'abstract': 'Novelty evaluation is vital for the promotion and management of innovation. With the advancement of information techniques and the open data movement, some progress has been made in novelty measurements. Tracking and reviewing novelty measures provides a data-driven way to assess contributions, progress, and emerging directions in the science field. As academic papers serve as the primary medium for the dissemination, validation, and discussion of scientific knowledge, this review aims to offer a systematic analysis of novelty measurements for scientific papers. We began by comparing the differences between scientific novelty and four similar concepts, including originality, scientific innovation, creativity, and scientific breakthrough. Next, we reviewed the types of scientific novelty. Then, we classified existing novelty measures according to data types and reviewed the measures for each type. Subsequently, we surveyed the approaches employed in validating novelty measures and examined the current tools and datasets associated with these measures. Finally, we proposed several open issues for future studies.', 'abstract_zh': '创新性评价对于促进和管理创新至关重要。随着信息技术的进步和开放数据运动的发展，我们在创新性度量方面已取得了一些进展。通过跟踪和审查创新性度量，可以为评估科学领域中的贡献、进步和新兴方向提供数据驱动的方法。由于学术论文是科学知识传播、验证和讨论的主要媒介，本文旨在提供一个系统分析科学论文创新性度量的综述。我们首先比较了科学创新性与其他四个类似概念（原创性、科学创新、创造性、科学突破）之间的差异。接着，我们回顾了科学创新性的类型。然后，我们根据数据类型对现有的创新性度量进行了分类，并对其每种类型进行了审查。随后，我们调查了验证创新性度量所采用的方法，并分析了这些度量相关的当前工具和数据集。最后，我们提出了未来研究中需要关注的若干开放问题。', 'title_zh': '学术论文中新颖性测量的综述'}
{'arxiv_id': 'arXiv:2501.17441', 'title': 'Towards Making Flowchart Images Machine Interpretable', 'authors': 'Shreya Shukla, Prajwal Gatti, Yogesh Kumar, Vikash Yadav, Anand Mishra', 'link': 'https://arxiv.org/abs/2501.17441', 'abstract': 'Computer programming textbooks and software documentations often contain flowcharts to illustrate the flow of an algorithm or procedure. Modern OCR engines often tag these flowcharts as graphics and ignore them in further processing. In this paper, we work towards making flowchart images machine-interpretable by converting them to executable Python codes. To this end, inspired by the recent success in natural language to code generation literature, we present a novel transformer-based framework, namely FloCo-T5. Our model is well-suited for this task,as it can effectively learn semantics, structure, and patterns of programming languages, which it leverages to generate syntactically correct code. We also used a task-specific pre-training objective to pre-train FloCo-T5 using a large number of logic-preserving augmented code samples. Further, to perform a rigorous study of this problem, we introduce theFloCo dataset that contains 11,884 flowchart images and their corresponding Python codes. Our experiments show promising results, and FloCo-T5 clearly outperforms related competitive baselines on code generation metrics. We make our dataset and implementation publicly available.', 'abstract_zh': '计算机编程教材和软件文档中常包含流程图以阐明算法或过程的流程。现代光学字符识别（OCR）引擎通常会将这些流程图识别为图像，而在后续处理中忽略它们。本文旨在通过将流程图转换为可执行的Python代码，使流程图表图像能够被机器理解。为此，受到自然语言到代码生成文献中近期成功经验的启发，我们提出了一个新颖的基于变压器的框架，即FloCo-T5。我们的模型非常适合完成这项任务，因为它能够有效地学习编程语言的语义、结构和模式，并利用这些信息生成语法正确的代码。我们还使用了一个特定任务的预训练目标，通过大量保留逻辑信息的增删改动生成的代码样本对FloCo-T5进行了预训练。此外，为了对这个问题进行严格的探讨，我们引入了FloCo数据集，该数据集包含了11,884张流程图图像及其对应的Python代码。我们的实验显示了令人鼓舞的结果，FloCo-T5在代码生成指标上明显优于相关的竞争基线。我们已将数据集和实现公开。', 'title_zh': '朝着使流程图图像对机器可解释的方向努力'}
{'arxiv_id': 'arXiv:2501.17433', 'title': 'Virus: Harmful Fine-tuning Attack for Large Language Models Bypassing Guardrail Moderation', 'authors': 'Tiansheng Huang, Sihao Hu, Fatih Ilhan, Selim Furkan Tekin, Ling Liu', 'link': 'https://arxiv.org/abs/2501.17433', 'abstract': 'Recent research shows that Large Language Models (LLMs) are vulnerable to harmful fine-tuning attacks -- models lose their safety alignment ability after fine-tuning on a few harmful samples. For risk mitigation, a guardrail is typically used to filter out harmful samples before fine-tuning. By designing a new red-teaming method, we in this paper show that purely relying on the moderation guardrail for data filtration is not reliable. Our proposed attack method, dubbed Virus, easily bypasses the guardrail moderation by slightly modifying the harmful data. Experimental results show that the harmful data optimized by Virus is not detectable by the guardrail with up to 100\\% leakage ratio, and can simultaneously achieve superior attack performance. Finally, the key message we want to convey through this paper is that: \\textbf{it is reckless to consider guardrail moderation as a clutch at straws towards harmful fine-tuning attack}, as it cannot solve the inherent safety issue of the pre-trained LLMs. Our code is available at this https URL', 'abstract_zh': '近期的研究表明，大型语言模型（LLMs）在对少量有害样本进行微调后易受到有害微调攻击——模型在其安全对齐能力方面会出现问题。为了减小风险，通常会在微调前使用一个护栏机制来过滤掉有害样本。通过设计一种新的红队方法，本文展示了仅依赖于护栏机制的数据过滤是不可靠的。我们提出了一种名为“病毒”（Virus）的攻击方法，通过稍微修改有害数据，可以轻松绕过关护护栏的过滤机制。实验结果表明，通过“病毒”优化的有害数据的漏检率可达100%，并且能够同时达到优秀的攻击性能。最后，本文的主要观点是：将护栏机制视为应对有害微调攻击的救命稻草是危险的，因为它无法解决预训练大语言模型固有的安全性问题。我们的代码可在以下链接获取：[](https://)', 'title_zh': '病毒：规避护栏 Moderation 的有害微调攻击针对大型语言模型'}
{'arxiv_id': 'arXiv:2501.17403', 'title': 'General Scene Adaptation for Vision-and-Language Navigation', 'authors': 'Haodong Hong, Yanyuan Qiao, Sen Wang, Jiajun Liu, Qi Wu', 'link': 'https://arxiv.org/abs/2501.17403', 'abstract': 'Vision-and-Language Navigation (VLN) tasks mainly evaluate agents based on one-time execution of individual instructions across multiple environments, aiming to develop agents capable of functioning in any environment in a zero-shot manner. However, real-world navigation robots often operate in persistent environments with relatively consistent physical layouts, visual observations, and language styles from instructors. Such a gap in the task setting presents an opportunity to improve VLN agents by incorporating continuous adaptation to specific environments. To better reflect these real-world conditions, we introduce GSA-VLN, a novel task requiring agents to execute navigation instructions within a specific scene and simultaneously adapt to it for improved performance over time. To evaluate the proposed task, one has to address two challenges in existing VLN datasets: the lack of OOD data, and the limited number and style diversity of instructions for each scene. Therefore, we propose a new dataset, GSA-R2R, which significantly expands the diversity and quantity of environments and instructions for the R2R dataset to evaluate agent adaptability in both ID and OOD contexts. Furthermore, we design a three-stage instruction orchestration pipeline that leverages LLMs to refine speaker-generated instructions and apply role-playing techniques to rephrase instructions into different speaking styles. This is motivated by the observation that each individual user often has consistent signatures or preferences in their instructions. We conducted extensive experiments on GSA-R2R to thoroughly evaluate our dataset and benchmark various methods. Based on our findings, we propose a novel method, GR-DUET, which incorporates memory-based navigation graphs with an environment-specific training strategy, achieving state-of-the-art results on all GSA-R2R splits.', 'abstract_zh': '视觉语言导航（VLN）任务主要评估代理在多个环境中一次性执行个别指令的能力，旨在开发能够在任何环境中以零样本方式进行工作的代理。然而，现实世界中的导航机器人通常在物理布局相对一致且视觉观察和指导语言风格也相对一致的持久环境中运行。这种任务设置之间的差距为通过持续适应特定环境来改进VLN代理提供了机会。为了更好地反映这些现实条件，我们引入了GSA-VLN，这是一种新颖的任务，要求代理在特定场景中执行导航指令并同时适应该场景，以在时间上提高性能。为了评估该任务，必须解决现有VLN数据集中两个关键挑战：OOD（out-of-distribution）数据的缺失，以及每个场景中指令数量和风格的有限多样性。因此，我们提出了一种新的数据集GSA-R2R，该数据集显著扩展了R2R数据集中的环境和指令的多样性和数量，以评估代理在ID（in-distribution）和OOD（out-of-distribution）环境中的适应性。此外，我们设计了一个三阶段指令协调流水线，利用大模型（LLM）来优化生成的指令，并运用角色扮演技术将其重新表述为不同的话语风格。这一设计受到观察的启发，即每个用户往往在指令中表现出一致的特征或偏好。我们在GSA-R2R上进行了广泛实验，以全面评估我们的数据集并基准多种方法。根据我们的研究发现，我们提出了一种新颖的方法——GR-DUET，该方法结合了基于记忆的导航图与环境特定的训练策略，实现了在所有GSA-R2R分割上的前沿结果。', 'title_zh': '视觉语言导航中的通用场景适应'}
{'arxiv_id': 'arXiv:2501.17391', 'title': 'Learning Free Token Reduction for Multi-Modal LLM', 'authors': 'Zihui Zhao, Yingxin Li, Yang Li', 'link': 'https://arxiv.org/abs/2501.17391', 'abstract': 'Vision-Language Models (VLMs) have achieved remarkable success across a range of multimodal tasks; however, their practical deployment is often constrained by high computational costs and prolonged inference times. Since the vision modality typically carries more information than the text modality, compressing visual prompts offers a promising solution to alleviate these challenges. Existing approaches predominantly focus on refining model architectures or directly reducing the number of visual tokens. However, these methods often compromise inference performance due to a lack of consideration for the unique spatial and temporal characteristics of visual data. In this work, we propose a token compression paradigm that operates on both spatial and temporal dimensions. Our approach includes a learning-free, plug-and-play compression pipeline that can be seamlessly integrated into most Multimodal Large Language Model (MLLM) frameworks. By leveraging this method, we enhance the model inference capability while simultaneously reducing its computational cost. Experimental results on the Video-QA task demonstrate the effectiveness of the proposed approach, showcasing significant improvements in efficiency without sacrificing performance.', 'abstract_zh': '视觉-语言模型（Vision-Language Models, VLMs）在多种多模态任务中取得了显著的成功；然而，它们的实际部署往往受到高计算成本和长时间推理时间的限制。由于视觉模态通常比文本模态承载更多的信息，压缩视觉提示为缓解这些挑战提供了一种有前景的解决方案。现有的方法主要集中在优化模型架构或直接减少视觉令牌的数量。然而，这些方法往往因为缺乏对视觉数据独特时空特性的考虑而影响了推理性能。在本工作中，我们提出了一种在时空两个维度上进行令牌压缩的范式。我们的方法包括一个无需学习、即插即用的压缩流水线，该流水线可以无缝集成到大多数多模态大型语言模型（Multimodal Large Language Models, MLLMs）框架中。通过利用该方法，我们同时提升了模型的推理能力并降低了其计算成本。在Video-QA任务上的实验结果表明，所提出的方法有效，能够显著提高效率而不牺牲性能。', 'title_zh': '基于学习的自由 Tokens 减少方法在多模态 LLM 中的应用'}
{'arxiv_id': 'arXiv:2501.17330', 'title': 'Attribution analysis of legal language as used by LLM', 'authors': 'Richard K. Belew', 'link': 'https://arxiv.org/abs/2501.17330', 'abstract': "Three publicly-available LLM specifically designed for legal tasks have been implemented and shown that classification accuracy can benefit from training over legal corpora, but why and how? Here we use two publicly-available legal datasets, a simpler binary classification task of ``overruling'' texts, and a more elaborate multiple choice task identifying ``holding'' judicial decisions. We report on experiments contrasting the legal LLM and a generic BERT model for comparison, against both datasets. We use integrated gradient attribution techniques to impute ``causes'' of variation in the models' perfomance, and characterize them in terms of the tokenizations each use. We find that while all models can correctly classify some test examples from the casehold task, other examples can only be identified by only one, model, and attribution can be used to highlight the reasons for this. We find that differential behavior of the models' tokenizers accounts for most of the difference and analyze these differences in terms of the legal language they process. Frequency analysis of tokens generated by dataset texts, combined with use of known ``stop word'' lists, allow identification of tokens that are clear signifiers of legal topics.", 'abstract_zh': '已经实现了三个专为法律任务设计的公开可用的大语言模型，并展示了通过在法律语料库上训练可以提高分类准确性，但为什么和如何提高呢？在这项研究中，我们使用两个公开可用的法律数据集：一个简单的二元分类任务“推翻”文本，以及一个较为复杂的多项选择任务，用于识别“裁决”。我们使用实验对比了法律大语言模型和通用的BERT模型在两个数据集上的表现。我们采用集成梯度归因技术来解释模型性能的变化，并从它们的分词方式出发进行描述。我们发现，尽管所有模型都能正确分类部分案例持有任务的数据集示例，但其他示例只能被单一模型识别，归因分析可用于突出显示这种差异的原因。我们发现，模型分词器的差异性行为是主要差异所在，并借助这些差异解释它们处理的法律语言。通过对由数据集文本生成的词元进行频率分析，并结合已知的“停用词”列表，我们可以识别出明确的法律主题标志词。', 'title_zh': 'LLM 使用的法律语言归因分析'}
{'arxiv_id': 'arXiv:2501.17299', 'title': '"Ownership, Not Just Happy Talk": Co-Designing a Participatory Large Language Model for Journalism', 'authors': 'Emily Tseng, Meg Young, Marianne Aubin Le Quéré, Aimee Rinehart, Harini Suresh', 'link': 'https://arxiv.org/abs/2501.17299', 'abstract': "Journalism has emerged as an essential domain for understanding the uses, limitations, and impacts of large language models (LLMs) in the workplace. News organizations face divergent financial incentives: LLMs already permeate newswork processes within financially constrained organizations, even as ongoing legal challenges assert that AI companies violate their copyright. At stake are key questions about what LLMs are created to do, and by whom: How might a journalist-led LLM work, and what can participatory design illuminate about the present-day challenges about adapting ``one-size-fits-all'' foundation models to a given context of use? In this paper, we undertake a co-design exploration to understand how a participatory approach to LLMs might address opportunities and challenges around AI in journalism. Our 20 interviews with reporters, data journalists, editors, labor organizers, product leads, and executives highlight macro, meso, and micro tensions that designing for this opportunity space must address. From these desiderata, we describe the result of our co-design work: organizational structures and functionality for a journalist-controlled LLM. In closing, we discuss the limitations of commercial foundation models for workplace use, and the methodological implications of applying participatory methods to LLM co-design.", 'abstract_zh': '新闻学已成为理解大型语言模型（LLMs）在职场中的应用、限制及其影响的关键领域。新闻机构面临着截然不同的财务激励：尽管在财务受限的组织中，LLMs已经渗透到新闻工作的各个环节，但持续的法律挑战认为AI公司侵犯了版权。关键在于LLMs的目的及其创造者：记者主导的LLM如何运作，以及参与式设计如何揭示将“一揽子适用”的基础模型适应特定使用情境的当下挑战？在本文中，我们进行了共同设计探索，以了解如何通过参与式方法解决AI在新闻业中的机遇与挑战。我们对20位记者、数据记者、编辑、劳工组织者、产品负责人和企业管理者进行了访谈，揭示了宏观、中观和微观层面的设计挑战，这些挑战必须在这一机会空间的设计中予以解决。基于这些需求，我们描述了共同设计工作的结果：一个由记者控制的LLM的组织结构和功能。最后，我们讨论了商业基础模型在职场使用中的局限性，并探讨了将参与式方法应用于LLM联合设计的 metodological 意义。', 'title_zh': '“不仅仅是空谈所有权”：为 journalism 共同设计一个参与式大语言模型'}
{'arxiv_id': 'arXiv:2501.17286', 'title': 'Fine-Tuning Open-Source Large Language Models to Improve Their Performance on Radiation Oncology Tasks: A Feasibility Study to Investigate Their Potential Clinical Applications in Radiation Oncology', 'authors': 'Peilong Wang, Zhengliang Liu, Yiwei Li, Jason Holmes, Peng Shu, Lian Zhang, Xiang Li, Quanzheng Li, Brady S. Laughlin, Diego Santos Toesca, Sujay A. Vora, Samir H. Patel, Terence T. Sio, Tianming Liu, Wei Liu', 'link': 'https://arxiv.org/abs/2501.17286', 'abstract': 'Background: The radiation oncology clinical practice involves many steps relying on the dynamic interplay of abundant text data. Large language models have displayed remarkable capabilities in processing complex text information. But their direct applications in specific fields like radiation oncology remain underexplored.\nPurpose: This study aims to investigate whether fine-tuning LLMs with domain knowledge can improve the performance on Task (1) treatment regimen generation, Task (2) treatment modality selection (photon, proton, electron, or brachytherapy), and Task (3) ICD-10 code prediction in radiation oncology.\nMethods: Data for 15,724 patient cases were extracted. Cases where patients had a single diagnostic record, and a clearly identifiable primary treatment plan were selected for preprocessing and manual annotation to have 7,903 cases of the patient diagnosis, treatment plan, treatment modality, and ICD-10 code. Each case was used to construct a pair consisting of patient diagnostics details and an answer (treatment regimen, treatment modality, or ICD-10 code respectively) for the supervised fine-tuning of these three tasks. Open source LLaMA2-7B and Mistral-7B models were utilized for the fine-tuning with the Low-Rank Approximations method. Accuracy and ROUGE-1 score were reported for the fine-tuned models and original models. Clinical evaluation was performed on Task (1) by radiation oncologists, while precision, recall, and F-1 score were evaluated for Task (2) and (3). One-sided Wilcoxon signed-rank tests were used to statistically analyze the results.\nResults: Fine-tuned LLMs outperformed original LLMs across all tasks with p-value <= 0.001. Clinical evaluation demonstrated that over 60% of the fine-tuned LLMs-generated treatment regimens were clinically acceptable. Precision, recall, and F1-score showed improved performance of fine-tuned LLMs.', 'abstract_zh': '背景：放射肿瘤学临床实践涉及多个步骤，这些步骤依赖于大量文本数据的动态互动。大规模语言模型在处理复杂文本信息方面表现出显著的能力，但在像放射肿瘤学这样的特定领域中的直接应用依然被广泛探索。\n目的：本研究旨在探讨通过结合专业领域的知识微调大规模语言模型是否能在治疗方案生成（任务1）、治疗方式选择（光子、质子、电子或近距离放射治疗）（任务2）以及ICD-10编码预测（任务3）这些放射肿瘤学任务上取得更好的性能。\n方法：共提取了15,724例患者的病例数据。筛选出具有单一诊断记录且治疗计划明确的病例进行预处理和人工标注，最终获得7,903例包含诊断、治疗计划、治疗方式和ICD-10编码的患者病例。每例病例用于构建用于监督微调这三个任务的数据对（包含患者诊断细节和答案，分别对应治疗方案、治疗方式或ICD-10编码）。利用开源的LLaMA2-7B和Mistral-7B模型进行微调，采用低秩近似方法。报告了微调模型和原始模型的准确率和ROUGE-1分数。对于任务1，由放射肿瘤学专家进行了临床评估；对于任务2和任务3，则分别评估了精确度、召回率和F-1分数。采用单边Wilcoxon符号秩检验对结果进行了统计分析。\n结果：微调后的大规模语言模型在所有任务上均优于原始模型，p值小于或等于0.001。临床评估显示，超过60%的微调后模型生成的治疗方案是临床可接受的。精确度、召回率和F-1分数表明微调后的大规模语言模型性能有所提升。', 'title_zh': '利用微调开源大规模语言模型以提升其在放射肿瘤学任务上的性能：一项可行性研究，探讨其在放射肿瘤学临床应用的潜在可能性'}
{'arxiv_id': 'arXiv:2501.17282', 'title': 'From Natural Language to Extensive-Form Game Representations', 'authors': 'Shilong Deng, Yongzhao Wang, Rahul Savani', 'link': 'https://arxiv.org/abs/2501.17282', 'abstract': 'We introduce a framework for translating game descriptions in natural language into extensive-form representations in game theory, leveraging Large Language Models (LLMs) and in-context learning. Given the varying levels of strategic complexity in games, such as perfect versus imperfect information, directly applying in-context learning would be insufficient. To address this, we introduce a two-stage framework with specialized modules to enhance in-context learning, enabling it to divide and conquer the problem effectively. In the first stage, we tackle the challenge of imperfect information by developing a module that identifies information sets along and the corresponding partial tree structure. With this information, the second stage leverages in-context learning alongside a self-debugging module to produce a complete extensive-form game tree represented using pygambit, the Python API of a recognized game-theoretic analysis tool called Gambit. Using this python representation enables the automation of tasks such as computing Nash equilibria directly from natural language descriptions. We evaluate the performance of the full framework, as well as its individual components, using various LLMs on games with different levels of strategic complexity. Our experimental results show that the framework significantly outperforms baseline models in generating accurate extensive-form games, with each module playing a critical role in its success.', 'abstract_zh': '我们提出了一种框架，利用大型语言模型（LLMs）和基于上下文学习的方法，将自然语言中的游戏描述转换为博弈论中的广义形式表示。由于游戏的战略复杂性各不相同，如完美信息与不完美信息之间的区别，直接应用基于上下文学习的方法是不够的。为了解决这一问题，我们引入了一个两阶段框架，其中包含专门的模块来增强基于上下文的学习能力，使其能够有效地分解并解决这一问题。在第一阶段，我们通过开发一个模块来应对不完美信息的挑战，该模块能够识别信息集及其相应的部分树结构。在获得这些信息后，第二阶段利用基于上下文学习的方法，并结合一个自调试模块，使用python API（来自开源博弈论分析工具Gambit的pygambit）生成完整的广义形式博弈树。通过这种方式表示，可以自动化直接从自然语言描述计算纳什均衡等任务。我们使用不同战略复杂度的游戏对整个框架及其各个组件进行了评估。实验结果表明，该框架在生成准确的广义形式博弈方面显著优于基准模型，每个模块都对该框架的成功起到了关键作用。', 'title_zh': '从自然语言到广义形式游戏表示'}
{'arxiv_id': 'arXiv:2501.17202', 'title': 'Audio Large Language Models Can Be Descriptive Speech Quality Evaluators', 'authors': 'Chen Chen, Yuchen Hu, Siyin Wang, Helin Wang, Zhehuai Chen, Chao Zhang, Chao-Han Huck Yang, Eng Siong Chng', 'link': 'https://arxiv.org/abs/2501.17202', 'abstract': 'An ideal multimodal agent should be aware of the quality of its input modalities. Recent advances have enabled large language models (LLMs) to incorporate auditory systems for handling various speech-related tasks. However, most audio LLMs remain unaware of the quality of the speech they process. This limitation arises because speech quality evaluation is typically excluded from multi-task training due to the lack of suitable datasets. To address this, we introduce the first natural language-based speech evaluation corpus, generated from authentic human ratings. In addition to the overall Mean Opinion Score (MOS), this corpus offers detailed analysis across multiple dimensions and identifies causes of quality degradation. It also enables descriptive comparisons between two speech samples (A/B tests) with human-like judgment. Leveraging this corpus, we propose an alignment approach with LLM distillation (ALLD) to guide the audio LLM in extracting relevant information from raw speech and generating meaningful responses. Experimental results demonstrate that ALLD outperforms the previous state-of-the-art regression model in MOS prediction, with a mean square error of 0.17 and an A/B test accuracy of 98.6%. Additionally, the generated responses achieve BLEU scores of 25.8 and 30.2 on two tasks, surpassing the capabilities of task-specific models. This work advances the comprehensive perception of speech signals by audio LLMs, contributing to the development of real-world auditory and sensory intelligent agents.', 'abstract_zh': '理想的多模态代理应当意识到其输入模态的质量。近期的进展使大型语言模型（LLMs）能够集成声学系统以处理各种语音相关任务。然而，大多数音频LLMs仍然无法意识到其所处理语音的质量。这一限制主要是由于缺乏合适的数据集，导致语音质量评估通常不作为多任务训练的一部分。为解决这一问题，我们引入了第一个基于自然语言的语音评估语料库，该语料库源自真实的人员评分。除了总体的意见评分（MOS）之外，该语料库还提供了在多个维度上的详细分析，并确定了质量下降的原因。它还能够以类似于人类判断的方式对两个语音样本（A/B测试）进行描述性比较。通过利用该语料库，我们提出了一种利用LLM蒸馏的对齐方法（ALLD），以指导音频LLMs从原始语音中提取相关信息并生成有意义的响应。实验结果表明，ALLD在MOS预测方面的性能优于之前的最佳回归模型，均方误差为0.17，A/B测试准确率为98.6%。此外，生成的响应在两个任务上的BLEU分数分别为25.8和30.2，超过了专门模型的能力。本工作提高了音频LLMs对语音信号的综合感知，有助于开发实用的听觉和感觉智能代理。', 'title_zh': '音频大型语言模型可以作为描述性语音质量评估器'}
{'arxiv_id': 'arXiv:2501.17186', 'title': 'Complete Chess Games Enable LLM Become A Chess Master', 'authors': 'Yinqi Zhang, Xintian Han, Haolong Li, Kedi Chen, Shaohui Lin', 'link': 'https://arxiv.org/abs/2501.17186', 'abstract': "Large language models (LLM) have shown remarkable abilities in text generation, question answering, language translation, reasoning and many other tasks. It continues to advance rapidly and is becoming increasingly influential in various fields, from technology and business to education and entertainment. Despite LLM's success in multiple areas, its ability to play abstract games, such as chess, is underexplored. Chess-playing requires the language models to output legal and reasonable moves from textual inputs. Here, we propose the Large language model ChessLLM to play full chess games. We transform the game into a textual format with the best move represented in the Forsyth-Edwards Notation. We show that by simply supervised fine-tuning, our model has achieved a professional-level Elo rating of 1788 in matches against the standard Elo-rated Stockfish when permitted to sample 10 times. We further show that data quality is important. Long-round data supervision enjoys a 350 Elo rating improvement over short-round data.", 'abstract_zh': '大语言模型（LLM）在文本生成、问答、语言翻译、推理以及其他多种任务上展现了卓越的能力。它们不断取得快速进步，并在各个领域中变得越来越具有影响力，从科技和商业到教育和娱乐等。尽管大语言模型在多个领域取得了成功，但在诸如国际象棋这样的抽象游戏中的能力却相对较少被探索。国际象棋比赛要求语言模型从文本输入中输出合法且合理的走法。在此，我们提出了一个名为ChessLLM的大语言模型，使其能够进行完整的国际象棋对局。我们将游戏转化为文本格式，最佳走法使用福斯特-厄德伍德标记法表示。我们表明，通过简单的监督微调，我们的模型在受到标准elo评分的Stockfish挑战时，允许采样10次的情况下达到了专业的elo评分1788。进一步研究表明，数据质量至关重要。长时间回合的监督比短时间回合的监督提高了350个elo评分。', 'title_zh': '完整棋局使大语言模型成为象棋大师'}
{'arxiv_id': 'arXiv:2501.17181', 'title': 'An AI-Driven Live Systematic Reviews in the Brain-Heart Interconnectome: Minimizing Research Waste and Advancing Evidence Synthesis', 'authors': 'Arya Rahgozar, Pouria Mortezaagha, Jodi Edwards, Douglas Manuel, Jessie McGowen, Merrick Zwarenstein, Dean Fergusson, Andrea Tricco, Kelly Cobey, Margaret Sampson, Malcolm King, Dawn Richards, Alexandra Bodnaruc, David Moher', 'link': 'https://arxiv.org/abs/2501.17181', 'abstract': "The Brain-Heart Interconnectome (BHI) combines neurology and cardiology but is hindered by inefficiencies in evidence synthesis, poor adherence to quality standards, and research waste. To address these challenges, we developed an AI-driven system to enhance systematic reviews in the BHI domain. The system integrates automated detection of Population, Intervention, Comparator, Outcome, and Study design (PICOS), semantic search using vector embeddings, graph-based querying, and topic modeling to identify redundancies and underexplored areas. Core components include a Bi-LSTM model achieving 87% accuracy for PICOS compliance, a study design classifier with 95.7% accuracy, and Retrieval-Augmented Generation (RAG) with GPT-3.5, which outperformed GPT-4 for graph-based and topic-driven queries. The system provides real-time updates, reducing research waste through a living database and offering an interactive interface with dashboards and conversational AI. While initially developed for BHI, the system's adaptable architecture enables its application across various biomedical fields, supporting rigorous evidence synthesis, efficient resource allocation, and informed clinical decision-making.", 'abstract_zh': '脑-心互连网络（BHI）结合了神经学和心脏病学，但受到证据综述合成效率低下、质量标准遵守较差和研究浪费的问题阻碍。为解决这些问题，我们开发了一个基于AI的系统以增强BHI领域的系统综述。该系统整合了自动检测Population、Intervention、Comparator、Outcome、Study design（PICOS）的机制，使用向量嵌入进行语义搜索，基于图的查询和主题建模，以识别冗余和未充分探索的领域。核心组件包括一个Bi-LSTM模型，其在PICOS合规性方面达到87%的准确率，一个95.7%准确率的研究设计分类器，以及使用GPT-3.5的检索增强生成（RAG）系统，其在图谱和主题驱动查询中优于GPT-4。系统提供实时更新，通过生活数据库减少研究浪费，并提供具有仪表板和对话式AI的交互式界面。虽然最初是为BHI领域开发的，但该系统的可适应架构使其能够在各个生物医学领域广泛应用，支持严格的证据合成、高效的资源分配和基于科学的临床决策。', 'title_zh': '基于AI驱动的脑-心互联系统综述：减少研究浪费并推进证据合成'}
{'arxiv_id': 'arXiv:2501.17176', 'title': 'Prompt-Based Cost-Effective Evaluation and Operation of ChatGPT as a Computer Programming Teaching Assistant', 'authors': 'Marc Ballestero-Ribó, Daniel Ortiz-Martínez', 'link': 'https://arxiv.org/abs/2501.17176', 'abstract': "The dream of achieving a student-teacher ratio of 1:1 is closer than ever thanks to the emergence of large language models (LLMs). One potential application of these models in the educational field would be to provide feedback to students in university introductory programming courses, so that a student struggling to solve a basic implementation problem could seek help from an LLM available 24/7. This article focuses on studying three aspects related to such an application. First, the performance of two well-known models, GPT-3.5T and GPT-4T, in providing feedback to students is evaluated. The empirical results showed that GPT-4T performs much better than GPT-3.5T, however, it is not yet ready for use in a real-world scenario. This is due to the possibility of generating incorrect information that potential users may not always be able to detect. Second, the article proposes a carefully designed prompt using in-context learning techniques that allows automating important parts of the evaluation process, as well as providing a lower bound for the fraction of feedbacks containing incorrect information, saving time and effort. This was possible because the resulting feedback has a programmatically analyzable structure that incorporates diagnostic information about the LLM's performance in solving the requested task. Third, the article also suggests a possible strategy for implementing a practical learning tool based on LLMs, which is rooted on the proposed prompting techniques. This strategy opens up a whole range of interesting possibilities from a pedagogical perspective.", 'abstract_zh': '实现师生比1:1的梦想比以往任何时候都更加接近，得益于大型语言模型（LLMs）的出现。这些模型在教育领域的潜在应用之一是为大学入门编程课程的学生提供反馈，使得在编程中遇到基本问题的学生能够随时从不断线的LLM寻求帮助。本文主要研究了这一应用的三个方面。首先，评估了两个知名模型GPT-3.5T和GPT-4T为学生提供反馈的表现。实验证明，GPT-4T的表现明显优于GPT-3.5T，但尚不适用于实际场景使用。原因是生成错误信息的可能性使得潜在用户不一定能够察觉。其次，文章提出了一种巧妙设计的提示，利用上下文学习技术，实现了评估过程中的重要部分自动化，并为含有错误信息的反馈比例设定了下限，从而节省时间和精力。这得益于反馈具有可编程分析的结构，其中包含了LLM在完成指定任务时的诊断信息。最后，本文还提出了一种基于LLM实现实际学习工具的可能策略，该策略源于所提出的提示技术。这一策略从教育角度来看，为了一系列有趣的可能性打开了大门。', 'title_zh': '基于提示的经济高效评估与运行：将ChatGPT作为计算机编程辅导助手的应用研究'}
{'arxiv_id': 'arXiv:2501.17174', 'title': 'Extractive Schema Linking for Text-to-SQL', 'authors': 'Michael Glass, Mustafa Eyceoz, Dharmashankar Subramanian, Gaetano Rossiello, Long Vu, Alfio Gliozzo', 'link': 'https://arxiv.org/abs/2501.17174', 'abstract': 'Text-to-SQL is emerging as a practical interface for real world databases. The dominant paradigm for Text-to-SQL is cross-database or schema-independent, supporting application schemas unseen during training. The schema of a database defines the tables, columns, column types and foreign key connections between tables. Real world schemas can be large, containing hundreds of columns, but for any particular query only a small fraction will be relevant. Placing the entire schema in the prompt for an LLM can be impossible for models with smaller token windows and expensive even when the context window is large enough to allow it. Even apart from computational considerations, the accuracy of the model can be improved by focusing the SQL generation on only the relevant portion of the database. Schema linking identifies the portion of the database schema useful for the question. Previous work on schema linking has used graph neural networks, generative LLMs, and cross encoder classifiers. We introduce a new approach to adapt decoder-only LLMs to schema linking that is both computationally more efficient and more accurate than the generative approach. Additionally our extractive approach permits fine-grained control over the precision-recall trade-off for schema linking.', 'abstract_zh': 'Text-to-SQL 正在成为现实世界数据库的一个实用接口。当前 Text-to-SQL 的主导范式是非特定数据库或无模式范式，支持在训练时未见过的应用模式。数据库的模式定义了表、列、列类型及其表之间的外键连接。现实世界中的数据库模式可能非常庞大，包含数百个列，但对于任何特定查询而言，只有其中一小部分是相关的。对于具有较小token窗口的模型，将整个模式放入提示中可能是不可能的，而在足够的上下文窗口大小下，即便这样也会非常昂贵。除了计算考虑之外，通过仅聚焦于数据库的相关部分来进行SQL生成，可以使模型的准确性得到改善。Schema linking 负责识别用于回答问题的数据库模式部分。先前的 Schema linking 工作采用了图神经网络、生成型语言模型（LLM）和交叉编码器分类器。我们提出了一种新的方法，将仅解码器的LLM适应于Schema linking，这种方法在计算效率和准确性上都优于生成型方法。此外，我们的抽取方法允许对 Schema linking 的精确-召回权衡进行细粒度控制。', 'title_zh': '文本到SQL的提取式模式链接'}
{'arxiv_id': 'arXiv:2501.17170', 'title': 'Benchmarking Randomized Optimization Algorithms on Binary, Permutation, and Combinatorial Problem Landscapes', 'authors': 'Jethro Odeyemi, Wenjun Zhang', 'link': 'https://arxiv.org/abs/2501.17170', 'abstract': "In this paper, we evaluate the performance of four randomized optimization algorithms: Randomized Hill Climbing (RHC), Simulated Annealing (SA), Genetic Algorithms (GA), and MIMIC (Mutual Information Maximizing Input Clustering), across three distinct types of problems: binary, permutation, and combinatorial. We systematically compare these algorithms using a set of benchmark fitness functions that highlight the specific challenges and requirements of each problem category. Our study analyzes each algorithm's effectiveness based on key performance metrics, including solution quality, convergence speed, computational cost, and robustness. Results show that while MIMIC and GA excel in producing high-quality solutions for binary and combinatorial problems, their computational demands vary significantly. RHC and SA, while computationally less expensive, demonstrate limited performance in complex problem landscapes. The findings offer valuable insights into the trade-offs between different optimization strategies and provide practical guidance for selecting the appropriate algorithm based on the type of problems, accuracy requirements, and computational constraints.", 'abstract_zh': '在本文中，我们评估了四种随机优化算法：随机爬山法（RHC）、模拟退火法（SA）、遗传算法（GA）和最大互信息输入聚类算法（MIMIC）在三种不同类型的优化问题中的性能：二元问题、排列问题和组合问题。我们通过一组基准适应度函数，系统地比较了这些算法的性能，这些基准适应度函数凸显了每种问题类型的具体挑战和要求。研究基于关键性能指标（包括解的质量、收敛速度、计算成本和鲁棒性）分析了每种算法的有效性。结果表明，尽管MIMIC和GA在生成二元和组合问题高质量解方面表现出色，但它们的计算需求差异显著。RHC和SA尽管计算成本较低，但在复杂问题空间中的表现受限。这些发现为不同优化策略之间的权衡提供了宝贵见解，并为根据问题类型、准确性要求和计算约束选择合适的算法提供了实用指导。', 'title_zh': '在二进制、排列和组合问题景观上基准测试随机化优化算法'}
