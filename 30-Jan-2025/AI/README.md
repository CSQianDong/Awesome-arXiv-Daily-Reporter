# Janus-Pro: Unified Multimodal Understanding and Generation with Data and Model Scaling 

**Title (ZH)**: Janus-Pro：基于数据和模型扩展的统一多模态理解和生成 

**Authors**: Xiaokang Chen, Zhiyu Wu, Xingchao Liu, Zizheng Pan, Wen Liu, Zhenda Xie, Xingkai Yu, Chong Ruan  

**Link**: [PDF](https://arxiv.org/pdf/2501.17811)  

**Abstract**: In this work, we introduce Janus-Pro, an advanced version of the previous work Janus. Specifically, Janus-Pro incorporates (1) an optimized training strategy, (2) expanded training data, and (3) scaling to larger model size. With these improvements, Janus-Pro achieves significant advancements in both multimodal understanding and text-to-image instruction-following capabilities, while also enhancing the stability of text-to-image generation. We hope this work will inspire further exploration in the field. Code and models are publicly available. 

**Abstract (ZH)**: 在本文中，我们介绍了Janus-Pro，这是之前工作的Janus的高级版本。具体而言，Janus-Pro 包含以下改进：(1) 优化的训练策略，(2) 扩展的训练数据集，以及(3) 更大的模型规模。通过这些改进，Janus-Pro 在多模态理解和文本生成图像指令跟随能力上取得了显著进步，同时增强了文本生成图像的稳定性。我们希望这项工作能够激发更多对该领域的探索。相关代码和模型均已公开。 

---
# Using Code Generation to Solve Open Instances of Combinatorial Design Problems 

**Title (ZH)**: 使用代码生成解决组合设计问题的开源实例 

**Authors**: Christopher D. Rosin  

**Link**: [PDF](https://arxiv.org/pdf/2501.17725)  

**Abstract**: The Handbook of Combinatorial Designs catalogs many types of combinatorial designs, together with lists of open instances for which existence has not yet been determined. We develop a constructive protocol CPro1, which uses Large Language Models (LLMs) to generate code that constructs combinatorial designs and resolves some of these open instances. The protocol starts from a definition of a particular type of design, and a verifier that reliably confirms whether a proposed design is valid. The LLM selects strategies and implements them in code, and scaffolding provides automated hyperparameter tuning and execution feedback using the verifier. Most generated code fails, but by generating many candidates, the protocol automates exploration of a variety of standard methods (e.g. simulated annealing, genetic algorithms) and experimentation with variations (e.g. cost functions) to find successful approaches. Testing on 16 different types of designs, CPro1 constructs solutions to open instances for 6 of them: Symmetric and Skew Weighing Matrices, Equidistant Permutation Arrays, Packing Arrays, Balanced Ternary Designs, and Florentine Rectangles. 

**Abstract (ZH)**: 《组合设计手册》记录了多种类型的组合设计，并列出了至今存在性尚未确定的开放问题实例。我们开发了一种建构协议 CPro1，该协议利用大语言模型（LLMs）生成用于构建组合设计并解决某些开放问题的代码。该协议从特定类型设计的定义和一个可靠的验证器开始。大语言模型选择策略并在代码中实现这些策略，支架提供自动的超参数调整和使用验证器的执行反馈。尽管生成的大部分代码未能成功，但通过生成大量候选方案，该协议自动化地探索了各种标准方法（如模拟退火、遗传算法）和对这些方法的变种（如成本函数）的实验，以找到成功的方法。在对 16 种不同类型的组合设计进行测试后，CPro1 构建了解决其中 6 种设计开放问题的解决方案：对称和斜对称权值矩阵、等距离排列阵、装载体、平衡三元设计和佛罗伦萨矩形。 

---
# Inferring Implicit Goals Across Differing Task Models 

**Title (ZH)**: 跨不同任务模型推断隐含目标 

**Authors**: Silvia Tulli, Stylianos Loukas Vasileiou, Mohamed Chetouani, Sarath Sreedharan  

**Link**: [PDF](https://arxiv.org/pdf/2501.17704)  

**Abstract**: One of the significant challenges to generating value-aligned behavior is to not only account for the specified user objectives but also any implicit or unspecified user requirements. The existence of such implicit requirements could be particularly common in settings where the user's understanding of the task model may differ from the agent's estimate of the model. Under this scenario, the user may incorrectly expect some agent behavior to be inevitable or guaranteed. This paper addresses such expectation mismatch in the presence of differing models by capturing the possibility of unspecified user subgoal in the context of a task captured as a Markov Decision Process (MDP) and querying for it as required. Our method identifies bottleneck states and uses them as candidates for potential implicit subgoals. We then introduce a querying strategy that will generate the minimal number of queries required to identify a policy guaranteed to achieve the underlying goal. Our empirical evaluations demonstrate the effectiveness of our approach in inferring and achieving unstated goals across various tasks. 

**Abstract (ZH)**: 生成价值观一致的行为的一个重要挑战在于不仅需要考虑用户明确规定的目标，还需要考虑用户未明确规定或隐含的需求。在用户对任务模型的理解与智能体对模型的估计存在差异的情况下，这些隐含的需求可能尤为常见。在这种情况下，用户可能会错误地认为某些智能体的行为是必然或肯定会出现的。本文通过在以马尔可夫决策过程（MDP）形式捕获的任务中，捕捉和查询未明确规定子目标的可能性，来解决由于模型差异导致的期望不匹配问题。我们的方法识别瓶颈状态，并将这些状态作为潜在隐含子目标的候选对象。然后，我们提出了一种查询策略，该策略能够生成最少数量的查询，以识别出一个确保达到基本目标的策略。我们的实证评估表明，我们的方法在各种任务中能够有效地推断和实现未明确声明的目标。 

---
# Solving Urban Network Security Games: Learning Platform, Benchmark, and Challenge for AI Research 

**Title (ZH)**: 解决城市网络安全性博弈问题：人工智能研究的学习平台、基准和挑战 

**Authors**: Shuxin Zhuang, Shuxin Li, Tianji Yang, Muheng Li, Xianjie Shi, Bo An, Youzhi Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2501.17559)  

**Abstract**: After the great achievement of solving two-player zero-sum games, more and more AI researchers focus on solving multiplayer games. To facilitate the development of designing efficient learning algorithms for solving multiplayer games, we propose a multiplayer game platform for solving Urban Network Security Games (\textbf{UNSG}) that model real-world scenarios. That is, preventing criminal activity is a highly significant responsibility assigned to police officers in cities, and police officers have to allocate their limited security resources to interdict the escaping criminal when a crime takes place in a city. This interaction between multiple police officers and the escaping criminal can be modeled as a UNSG. The variants of UNSGs can model different real-world settings, e.g., whether real-time information is available or not, and whether police officers can communicate or not. The main challenges of solving this game include the large size of the game and the co-existence of cooperation and competition. While previous efforts have been made to tackle UNSGs, they have been hampered by performance and scalability issues. Therefore, we propose an open-source UNSG platform (\textbf{GraphChase}) for designing efficient learning algorithms for solving UNSGs. Specifically, GraphChase offers a unified and flexible game environment for modeling various variants of UNSGs, supporting the development, testing, and benchmarking of algorithms. We believe that GraphChase not only facilitates the development of efficient algorithms for solving real-world problems but also paves the way for significant advancements in algorithmic development for solving general multiplayer games. 

**Abstract (ZH)**: 在解决了两人零和博弈之后，越来越多的AI研究者开始关注 multiplayer 游戏的求解问题。为了促进高效学习算法设计以解决 multiplayer 游戏，我们提出了一个旨在解决城市网络安全博弈 (\textbf{UNSG}) 的 multiplayer 游戏平台。具体来说，防止犯罪活动是城市警察的首要职责之一，当城市中发生犯罪行为时，警察需要将其有限的安全资源分配给阻止逃犯的任务。这种多警察与逃犯之间的相互作用可以被建模为 UNSG。UNSG 的不同变体可以用于模拟不同的现实场景，例如是否可用实时信息，以及警察之间是否能进行沟通。解决这个博弈的主要挑战包括游戏规模庞大以及合作与竞争并存的问题。尽管已经有研究表明如何应对 UNSG，但这些研究受到性能和可扩展性问题的限制。因此，我们提出了一种开源的 UNSG 平台 (\textbf{GraphChase})，用于设计高效的算法来解决 UNSG。具体来说，GraphChase 提供了一个统一且灵活的游戏环境，用于建模各种 UNSG 变体，并支持算法的开发、测试和基准测试。我们相信，GraphChase 不仅为解决实际问题的高效算法开发提供了便利，也为解决通用 multiplayer 游戏的游戏算法研究开辟了新的途径。 

---
# Reflections on "Can AI Understand Our Universe?" 

**Title (ZH)**: 《对“AI能否理解我们的宇宙？”的思考》 

**Authors**: Yu Wang  

**Link**: [PDF](https://arxiv.org/pdf/2501.17507)  

**Abstract**: This article briefly discusses the philosophical and technical aspects of AI. It focuses on two concepts of understanding: intuition and causality, and highlights three AI technologies: Transformers, chain-of-thought reasoning, and multimodal processing. We anticipate that in principle AI could form understanding, with these technologies representing promising advancements. 

**Abstract (ZH)**: 本文简要探讨了人工智能的哲学和技术方面。文章侧重讨论了两种理解概念：直觉和因果关系，并强调了三项AI技术：变换器、链式推理和多模态处理。我们预期从原则上讲，AI能够形成理解，而这些技术则代表了潜在的进步方向。 

---
# SemML: Enhancing Automata-Theoretic LTL Synthesis with Machine Learning 

**Title (ZH)**: SemML：增强基于自动机的LTL综合的机器学习方法 

**Authors**: Jan Kretinsky, Tobias Meggendorfer, Maximilian Prokop, Ashkan Zarkhah  

**Link**: [PDF](https://arxiv.org/pdf/2501.17496)  

**Abstract**: Synthesizing a reactive system from specifications given in linear temporal logic (LTL) is a classical problem, finding its applications in safety-critical systems design. We present our tool SemML, which won this year's LTL realizability tracks of SYNTCOMP, after years of domination by Strix. While both tools are based on the automata-theoretic approach, ours relies heavily on (i) Semantic labelling, additional information of logical nature, coming from recent LTL-to-automata translations and decorating the resulting parity game, and (ii) Machine Learning approaches turning this information into a guidance oracle for on-the-fly exploration of the parity game (whence the name SemML). Our tool fills the missing gaps of previous suggestions to use such an oracle and provides an efficeint implementation with additional algorithmic improvements. We evaluate SemML both on the entire set of SYNTCOMP as well as a synthetic data set, compare it to Strix, and analyze the advantages and limitations. As SemML solves more instances on SYNTCOMP and does so significantly faster on larger instances, this demonstrates for the first time that machine-learning-aided approaches can out-perform state-of-the-art tools in real LTL synthesis. 

**Abstract (ZH)**: 将下面的论文内容或标题翻译成中文，符合学术规范：

从线性时序逻辑（LTL）规范合成反应系统是一个经典问题，其在关键安全系统设计领域得到了广泛应用。我们介绍了我们的工具SemML，该工具在今年的SYNTCOMP的LTL实现赛道上获胜，打破了Strix长期以来的垄断。尽管这两种工具都基于自动机理论方法，但我们的工具主要依赖于以下两点：(i) 语义标签，这种来自最近的LTL到自动机转换的额外逻辑信息，并通过这种信息对最终的优先级游戏进行装饰，以及(ii) 使用机器学习方法将这些信息转化为优先级游戏中即时探索的指导预言机（因此名为SemML）。我们的工具填补了以往建议使用此类预言机时存在的空白，并提供了高效的实现，同时包含了一些算法改进。我们在SYNTCOMP的整个数据集以及一个合成数据集上评估了SemML，并将其与Strix进行比较，分析了其优势与局限性。由于SemML在SYNTCOMP上解决更多实例，并且在解决更大规模问题时显著更快，这首次证明机器学习辅助方法在实际LTL合成中可以优于最先进的工具。 

---
# Certifying Pareto-Optimality in Multi-Objective Maximum Satisfiability 

**Title (ZH)**: 多目标最大满足性中的帕累托最优性认证 

**Authors**: Christoph Jabs, Jeremias Berg, Bart Bogaerts, Matti Järvisalo  

**Link**: [PDF](https://arxiv.org/pdf/2501.17493)  

**Abstract**: Due to the wide employment of automated reasoning in the analysis and construction of correct systems, the results reported by automated reasoning engines must be trustworthy. For Boolean satisfiability (SAT) solvers - and more recently SAT-based maximum satisfiability (MaxSAT) solvers - trustworthiness is obtained by integrating proof logging into solvers, making solvers capable of emitting machine-verifiable proofs to certify correctness of the reasoning steps performed. In this work, we enable for the first time proof logging based on the VeriPB proof format for multi-objective MaxSAT (MO-MaxSAT) optimization techniques. Although VeriPB does not offer direct support for multi-objective problems, we detail how preorders in VeriPB can be used to provide certificates for MO-MaxSAT algorithms computing a representative solution for each element in the non-dominated set of the search space under Pareto-optimality, without extending the VeriPB format or the proof checker. By implementing VeriPB proof logging into a state-of-the-art multi-objective MaxSAT solver, we show empirically that proof logging can be made scalable for MO-MaxSAT with reasonable overhead. 

**Abstract (ZH)**: 由于自动推理在系统分析和构建中的广泛应用，自动推理引擎的报告结果必须是可信赖的。对于布尔可满足性（SAT）求解器，以及最近的基于SAT的最大可满足性（MaxSAT）求解器而言，通过将证明记录集成到求解器中，使其能够产生机器可验证的证明以认证推理步骤的正确性，从而获得其可信赖性。在本文中，我们首次实现了基于VeriPB证明格式的多目标MaxSAT（MO-MaxSAT）优化技术的证明记录。尽管VeriPB不直接支持多目标问题，但我们详细说明了如何利用VeriPB中的预序关系来为在帕累托最优性下搜索空间的非支配解集中的每个元素提供代表性的解决方案的证书，而无需扩展VeriPB格式或证明检查器。通过将VeriPB证明记录实现到一个最先进的多目标MaxSAT求解器中，我们实验证明，可以以合理的开销使证明记录具备可扩展性。 

---
# Large Language Models for Single-Step and Multi-Step Flight Trajectory Prediction 

**Title (ZH)**: 大规模语言模型在单步骤和多步骤飞行轨迹预测中的应用 

**Authors**: Kaiwei Luo, Jiliu Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2501.17459)  

**Abstract**: Flight trajectory prediction is a critical time series task in aviation. While deep learning methods have shown significant promise, the application of large language models (LLMs) to this domain remains underexplored. This study pioneers the use of LLMs for flight trajectory prediction by reframing it as a language modeling problem. Specifically, We extract features representing the aircraft's position and status from ADS-B flight data to construct a prompt-based dataset, where trajectory waypoints are converted into language tokens. The dataset is then employed to fine-tune LLMs, enabling them to learn complex spatiotemporal patterns for accurate predictions. Comprehensive experiments demonstrate that LLMs achieve notable performance improvements in both single-step and multi-step predictions compared to traditional methods, with LLaMA-3.1 model achieving the highest overall accuracy. However, the high inference latency of LLMs poses a challenge for real-time applications, underscoring the need for further research in this promising direction. 

**Abstract (ZH)**: 航空领域的飞行轨迹预测是一项关键的时间序列任务。虽然深度学习方法已经显示出显著的潜力，但在航空领域应用大型语言模型（LLMs）的研究仍相对不足。本研究首次将LLMs应用于飞行轨迹预测，将其重新构想为一种语言模型问题。具体而言，我们从ADS-B飞行数据中提取表示飞机位置和状态的特征，构建基于提示的数据集，在该数据集中，轨迹航点被转换为语言标记。随后，该数据集用于微调LLMs，使它们能够学习复杂的空间时间模式，从而进行准确的预测。全面的实验表明，与传统方法相比，LLMs在单步和多步预测中均实现了显著的性能提升，其中LLaMA-3.1模型整体准确率最高。然而，LLMs的高推理延迟为其在实时应用中的使用带来了挑战，这凸显了这一有前景方向上进一步研究的必要性。 

---
# Intensional Inheritance Between Concepts: An Information-Theoretic Interpretation 

**Title (ZH)**: 概念间的意向性继承：一种信息论解释 

**Authors**: Ben Goertzel  

**Link**: [PDF](https://arxiv.org/pdf/2501.17393)  

**Abstract**: This paper addresses the problem of formalizing and quantifying the concept of "intensional inheritance" between two concepts. We begin by conceiving the intensional inheritance of $W$ from $F$ as the amount of information the proposition "x is $F$ " provides about the proposition "x is $W$. To flesh this out, we consider concepts $F$ and $W$ defined by sets of properties $\left\{F_{1}, F_{2}, \ldots, F_{n}\right\}$ and $\left\{W_{1}, W_{2}, \ldots, W_{m}\right\}$ with associated degrees $\left\{d_{1}, d_{2}, \ldots, d_{n}\right\}$ and $\left\{e_{1}, e_{2}, \ldots, e_{m}\right\}$, respectively, where the properties may overlap. We then derive formulas for the intensional inheritance using both Shannon information theory and algorithmic information theory, incorporating interaction information among properties. We examine a special case where all properties are mutually exclusive and calculate the intensional inheritance in this case in both frameworks. We also derive expressions for $P(W \mid F)$ based on the mutual information formula. Finally we consider the relationship between intensional inheritance and conventional set-theoretic "extensional" inheritance, concluding that in our information-theoretic framework, extensional inheritance emerges as a special case of intensional inheritance. 

**Abstract (ZH)**: 本文探讨了形式化和量化“内涵继承”这一概念之间关系的问题。我们首先将从概念 \(F\) 至概念 \(W\) 的内涵继承视为命题“x是 \(F\)”对命题“x是 \(W\)”所提供的信息量。为了进一步阐述这一点，我们考虑概念 \(F\) 和 \(W\) 分别由属性集 \(\{F_{1}, F_{2}, \ldots, F_{n}\}\) 和 \(\{W_{1}, W_{2}, \ldots, W_{m}\}\) 定义，并且这些属性分别具有相关程度 \(\{d_{1}, d_{2}, \ldots, d_{n}\}\) 和 \(\{e_{1}, e_{2}, \ldots, e_{m}\}\)，其中属性可能重叠。我们接着使用香农信息理论和算法信息理论推导内涵继承的公式，并考虑属性之间的交互信息。我们还探讨了一种特殊情况，即所有属性都是互斥的，并分别在这两个框架中计算这一情况下的内涵继承。此外，我们根据互信息公式推导了 \(P(W \mid F)\) 的表达式。最后，我们考虑内涵继承与传统集合论中“外延”继承之间的关系，得出在我们的信息论框架中，外延继承是内涵继承的一种特殊情况。 

---
# A sketch of an AI control safety case 

**Title (ZH)**: 人工智能控制安全性论证概要 

**Authors**: Tomek Korbak, Joshua Clymer, Benjamin Hilton, Buck Shlegeris, Geoffrey Irving  

**Link**: [PDF](https://arxiv.org/pdf/2501.17315)  

**Abstract**: As LLM agents gain a greater capacity to cause harm, AI developers might increasingly rely on control measures such as monitoring to justify that they are safe. We sketch how developers could construct a "control safety case", which is a structured argument that models are incapable of subverting control measures in order to cause unacceptable outcomes. As a case study, we sketch an argument that a hypothetical LLM agent deployed internally at an AI company won't exfiltrate sensitive information. The sketch relies on evidence from a "control evaluation,"' where a red team deliberately designs models to exfiltrate data in a proxy for the deployment environment. The safety case then hinges on several claims: (1) the red team adequately elicits model capabilities to exfiltrate data, (2) control measures remain at least as effective in deployment, and (3) developers conservatively extrapolate model performance to predict the probability of data exfiltration in deployment. This safety case sketch is a step toward more concrete arguments that can be used to show that a dangerously capable LLM agent is safe to deploy. 

**Abstract (ZH)**: 随着大规模语言模型（LLM）代理的能力增强，导致潜在危害的风险增加，AI开发者可能会越来越多地依赖控制措施（如监控），以证明模型是安全的。我们勾勒了开发者如何构建一个“控制安全性论证”，这是一种结构化的论据，表明模型无法通过规避控制措施导致不可接受的结果。作为案例研究，我们勾勒了一个论点，即一家AI公司在内部部署的假设LLM代理不会泄露敏感信息。这一论点的基础在于“控制评估”的证据，其中红队故意设计模型以泄露数据，作为部署环境的代理。然后，安全性论证依赖于以下几个主张：（1）红队充分揭示了模型泄露数据的能力；（2）在部署中，控制措施至少与评估环境一样有效；（3）开发者保守地外推模型在评估中的表现，以预测在部署中数据泄露的概率。这种安全性论证草图是朝着更具可操作性的论据发展的重要一步，这些论据可以用来显示一个功能强大的LLM代理是安全的，可以部署。 

---
# Probing LLM World Models: Enhancing Guesstimation with Wisdom of Crowds Decoding 

**Title (ZH)**: 探索大语言模型的世界模型：通过众多个体智慧增强猜测估算 

**Authors**: Yun-Shiuan Chuang, Nikunj Harlalka, Sameer Narendran, Alexander Cheung, Sizhe Gao, Siddharth Suresh, Junjie Hu, Timothy T. Rogers  

**Link**: [PDF](https://arxiv.org/pdf/2501.17310)  

**Abstract**: Guesstimation, the task of making approximate quantity estimates, is a common real-world challenge. However, it has been largely overlooked in large language models (LLMs) and vision language models (VLMs) research. We introduce a novel guesstimation dataset, MARBLES. This dataset requires one to estimate how many items (e.g., marbles) can fit into containers (e.g., a one-cup measuring cup), both with and without accompanying images. Inspired by the social science concept of the ``{Wisdom of Crowds'' (WOC) - taking the median from estimates from a crowd), which has proven effective in guesstimation, we propose ``WOC decoding'' strategy for LLM guesstimation. We show that LLMs/VLMs perform well on guesstimation, suggesting that they possess some level of a "world model" necessary for guesstimation. Moreover, similar to human performance, the WOC decoding method improves LLM/VLM guesstimation accuracy. Furthermore, the inclusion of images in the multimodal condition enhances model performance. These results highlight the value of WOC decoding strategy for LLMs/VLMs and position guesstimation as a probe for evaluating LLMs/VLMs' world model. 

**Abstract (ZH)**: 猜测估计，即做出近似数量估计的任务，在现实生活中是一个常见的挑战。然而，这一任务在大型语言模型（LLMs）和视觉语言模型（VLMs）的研究中却鲜有涉及。我们引入了一个新型的猜测估计数据集，即MARBLES。该数据集要求参与者估算特定物品（例如珠子）可以装入容器（例如1杯容量的量杯）中的数量，既包括配有图片的情况，也包括没有图片的情况。受社会学概念“群体的智慧”（Wisdom of Crowds, WOC）的启发，WOC是指从群体的估计中选取众数，这种方法在猜测估计任务中已被证明是有效的。基于此，我们提出了一种适用于LLMs的“WOC解码”策略。我们展示了LLMs/VLMs在猜测估计任务中的良好表现，这表明这些模型具备进行猜测估计所需的一些“世界模型”。此外，类似人类的表现，“WOC解码”方法提高了LLMs/VLMs的猜测估计准确性。进一步地，多模态条件下（包含图片）的模型表现更好。这些结果突显了WOC解码策略对于LLMs/VLMs的价值，并将猜测估计视为评估LLMs/VLMs世界模型的有效探针。 

---
# From Natural Language to Extensive-Form Game Representations 

**Title (ZH)**: 从自然语言到广义形式游戏表示 

**Authors**: Shilong Deng, Yongzhao Wang, Rahul Savani  

**Link**: [PDF](https://arxiv.org/pdf/2501.17282)  

**Abstract**: We introduce a framework for translating game descriptions in natural language into extensive-form representations in game theory, leveraging Large Language Models (LLMs) and in-context learning. Given the varying levels of strategic complexity in games, such as perfect versus imperfect information, directly applying in-context learning would be insufficient. To address this, we introduce a two-stage framework with specialized modules to enhance in-context learning, enabling it to divide and conquer the problem effectively. In the first stage, we tackle the challenge of imperfect information by developing a module that identifies information sets along and the corresponding partial tree structure. With this information, the second stage leverages in-context learning alongside a self-debugging module to produce a complete extensive-form game tree represented using pygambit, the Python API of a recognized game-theoretic analysis tool called Gambit. Using this python representation enables the automation of tasks such as computing Nash equilibria directly from natural language descriptions. We evaluate the performance of the full framework, as well as its individual components, using various LLMs on games with different levels of strategic complexity. Our experimental results show that the framework significantly outperforms baseline models in generating accurate extensive-form games, with each module playing a critical role in its success. 

**Abstract (ZH)**: 我们提出了一种框架，利用大型语言模型（LLMs）和增量学习方法，将自然语言中的游戏描述转化为博弈论中的扩展形式表示。由于不同游戏的战略复杂性各异，如完全信息与不完全信息之间的区别，直接应用增量学习是不够的。为此，我们引入了一种两阶段框架，并在其中添加了专门模块来增强增量学习，使它能够有效地分解和解决这个问题。在第一阶段，我们通过开发一个模块来解决不完全信息问题，该模块能够识别信息集及其相应的部分树结构。利用这些信息，第二阶段结合使用增量学习和一个自我调试模块，使用pygambit（博弈论分析工具Gambit的Python API）生成完整的扩展形式博弈树。通过使用这种Python表示法，可以实现直接从自然语言描述中计算纳什均衡等任务的自动化。我们使用不同战略复杂度级别的游戏，以及各种大型语言模型，对整个框架及其各个组件的性能进行了评估。实验结果显示，该框架在生成准确的扩展形式博弈方面显著优于基准模型，每个模块在其中的成功中都发挥了关键作用。 

---
# Integrating Reinforcement Learning and AI Agents for Adaptive Robotic Interaction and Assistance in Dementia Care 

**Title (ZH)**: 将以下论文内容或标题翻译成中文，并确保符合学术规范：

Original Title: Integrating Reinforcement Learning and AI Agents for Adaptive Robotic Interaction and Assistance in Dementia Care

Translated Title: 结合强化学习和人工智能代理实现痴呆护理中的自适应机器人互动与辅助

This translation maintains the academic tone and accurately conveys the meaning of the original title. 

**Authors**: Fengpei Yuan, Nehal Hasnaeen, Ran Zhang, Bryce Bible, Joseph Riley Taylor, Hairong Qi, Fenghui Yao, Xiaopeng Zhao  

**Link**: [PDF](https://arxiv.org/pdf/2501.17206)  

**Abstract**: This study explores a novel approach to advancing dementia care by integrating socially assistive robotics, reinforcement learning (RL), large language models (LLMs), and clinical domain expertise within a simulated environment. This integration addresses the critical challenge of limited experimental data in socially assistive robotics for dementia care, providing a dynamic simulation environment that realistically models interactions between persons living with dementia (PLWDs) and robotic caregivers. The proposed framework introduces a probabilistic model to represent the cognitive and emotional states of PLWDs, combined with an LLM-based behavior simulation to emulate their responses. We further develop and train an adaptive RL system enabling humanoid robots, such as Pepper, to deliver context-aware and personalized interactions and assistance based on PLWDs' cognitive and emotional states. The framework also generalizes to computer-based agents, highlighting its versatility. Results demonstrate that the RL system, enhanced by LLMs, effectively interprets and responds to the complex needs of PLWDs, providing tailored caregiving strategies. This research contributes to human-computer and human-robot interaction by offering a customizable AI-driven caregiving platform, advancing understanding of dementia-related challenges, and fostering collaborative innovation in assistive technologies. The proposed approach has the potential to enhance the independence and quality of life for PLWDs while alleviating caregiver burden, underscoring the transformative role of interaction-focused AI systems in dementia care. 

**Abstract (ZH)**: 本研究探索了一种将社会辅助机器人、强化学习（RL）、大型语言模型（LLMs）以及临床领域专业知识整合应用于痴呆症护理的新方法，该研究在模拟环境中进行。这种整合解决了社会辅助机器人在痴呆症护理中面临的实验数据有限的关键挑战，提供了一个动态模拟环境，能够真实地模拟患有痴呆症的人（PLWD）与机器人护理人员之间的互动。提出的框架引入了一个概率模型来表示PLWD的认知和情感状态，并结合基于LLM的行为模拟来模拟他们的反应。进一步开发并训练了一个自适应RL系统，使Pepper等类人机器人能够根据PLWD的认知和情感状态提供情境感知和个性化的互动和辅助。该框架还能够应用于基于计算机的代理，突显其实用性。研究结果表明，通过LLM增强的RL系统能够有效地解释并响应PLWD的复杂需求，提供量身定制的护理策略。本研究通过提供一个可定制的人工智能驱动护理平台，促进了人机交互和人机互动中对痴呆相关挑战的理解，并促进了辅助技术的协同创新。提出的这一方法有望增强PLWD的独立性和生活质量，同时减轻护理人员的负担，突出以交互为中心的人工智能系统在痴呆症护理中的变革作用。 

---
# Smart Cubing for Graph Search: A Comparative Study 

**Title (ZH)**: 智能立方体技术在图搜索中的对比研究 

**Authors**: Markus Kirchweger, Hai Xia, Tomáš Peitl, Stefan Szeider  

**Link**: [PDF](https://arxiv.org/pdf/2501.17201)  

**Abstract**: Parallel solving via cube-and-conquer is a key method for scaling SAT solvers to hard instances. While cube-and-conquer has proven successful for pure SAT problems, notably the Pythagorean triples conjecture, its application to SAT solvers extended with propagators presents unique challenges, as these propagators learn constraints dynamically during the search.
We study this problem using SAT Modulo Symmetries (SMS) as our primary test case, where a symmetry-breaking propagator reduces the search space by learning constraints that eliminate isomorphic graphs. Through extensive experimentation comprising over 10,000 CPU hours, we systematically evaluate different cube-and-conquer variants on three well-studied combinatorial problems. Our methodology combines prerun phases to collect learned constraints, various cubing strategies, and parameter tuning via algorithm configuration and LLM-generated design suggestions.
The comprehensive empirical evaluation provides new insights into effective cubing strategies for propagator-based SAT solving, with our best method achieving speedups of 2-3x from improved cubing and parameter tuning, providing an additional 1.5-2x improvement on harder instances. 

**Abstract (ZH)**: 并行求解技术“立方体与征服”是将 SAT 求解器扩展到硬实例的关键方法。虽然“立方体与征服”方法在纯 SAT 问题中表现出色，尤其是在证明勾股数猜想方面，但在将传播器扩展到 SAT 求解器时提出了一种独特的挑战，这些传播器在搜索过程中会动态学习约束条件。

我们使用 SAT 对称性模（SMS）作为主要测试案例，其中的对称性打破传播器通过学习消除同构图的约束条件来减少搜索空间。通过超过 10,000 个 CPU 小时的广泛实验，我们系统地评估了三种经典的组合问题上不同“立方体与征服”变体。我们的方法结合了预运行阶段以收集学习到的约束条件、多种立方体策略以及通过算法配置和基于人工语言模型（LLM）的设计建议进行参数调优。

全面的实证评估为我们提供了关于基于传播器的 SAT 求解有效立方体策略的新见解。我们最优的方法通过改进立方体策略和参数调优实现了 2-3 倍的加速，对更难的问题实例进一步提高了 1.5-2 倍的效率。 

---
# Letters, Colors, and Words: Constructing the Ideal Building Blocks Set 

**Title (ZH)**: 字母、颜色和词语：构建理想的构建块集合 

**Authors**: Ricardo Salazar, Shahrzad Jamshidi  

**Link**: [PDF](https://arxiv.org/pdf/2501.17188)  

**Abstract**: Define a building blocks set to be a collection of n cubes (each with six sides) where each side is assigned one letter and one color from a palette of m colors. We propose a novel problem of assigning letters and colors to each face so as to maximize the number of words one can spell from a chosen dataset that are either mono words, all letters have the same color, or rainbow words, all letters have unique colors. We explore this problem considering a chosen set of English words, up to six letters long, from a typical vocabulary of a US American 14 year old and explore the problem when n=6 and m=6, with the added restriction that each color appears exactly once on the cube. The problem is intractable, as the size of the solution space makes a brute force approach computationally infeasible. Therefore we aim to solve this problem using random search, simulated annealing, two distinct tree search approaches (greedy and best-first), and a genetic algorithm. To address this, we explore a range of optimization techniques: random search, simulated annealing, two distinct tree search methods (greedy and best-first), and a genetic algorithm. Additionally, we attempted to implement a reinforcement learning approach; however, the model failed to converge to viable solutions within the problem's constraints. Among these methods, the genetic algorithm delivered the best performance, achieving a total of 2846 mono and rainbow words. 

**Abstract (ZH)**: 定义一个由n个立方体组成的构建块集合（每个立方体有六个面），每个面上分配一个字母和一个来自m种颜色调色板的颜色。我们提出了一种新的问题，即如何在选择的数据集中为每个面分配字母和颜色，以便最大化能够拼出的单词数量。这些单词可以是单色词（所有字母颜色相同）或彩虹词（所有字母颜色各不相同）。我们考虑了一组最多六个字母的英语单词，这些单词来自典型的14岁美国人的词汇量，并探索了当n=6且m=6时的情况，同时有一个额外限制，即每个颜色在立方体上恰好出现一次。由于解空间的大小使得穷举搜索在计算上不可行，我们试图使用随机搜索、模拟退火、两种不同的树搜索方法（贪婪搜索和最佳优先搜索）以及遗传算法来解决这个问题。为了应对这一挑战，我们探索了一系列优化技术：随机搜索、模拟退火、两种不同的树搜索方法（贪婪搜索和最佳优先搜索）以及遗传算法。此外，我们尝试实施了一种强化学习方法，但由于模型未能在问题的约束条件下收敛到可行的解决方案，这一方法并未成功。在这些方法中，遗传算法表现最优，共产生了2846个单色词和彩虹词。 

---
# Complete Chess Games Enable LLM Become A Chess Master 

**Title (ZH)**: 完整的国际象棋完整对局使大规模语言模型成为国际象棋大师 

**Authors**: Yinqi Zhang, Xintian Han, Haolong Li, Kedi Chen, Shaohui Lin  

**Link**: [PDF](https://arxiv.org/pdf/2501.17186)  

**Abstract**: Large language models (LLM) have shown remarkable abilities in text generation, question answering, language translation, reasoning and many other tasks. It continues to advance rapidly and is becoming increasingly influential in various fields, from technology and business to education and entertainment. Despite LLM's success in multiple areas, its ability to play abstract games, such as chess, is underexplored. Chess-playing requires the language models to output legal and reasonable moves from textual inputs. Here, we propose the Large language model ChessLLM to play full chess games. We transform the game into a textual format with the best move represented in the Forsyth-Edwards Notation. We show that by simply supervised fine-tuning, our model has achieved a professional-level Elo rating of 1788 in matches against the standard Elo-rated Stockfish when permitted to sample 10 times. We further show that data quality is important. Long-round data supervision enjoys a 350 Elo rating improvement over short-round data. 

**Abstract (ZH)**: 大型语言模型（LLM）在文本生成、问答、语言翻译、推理和其他许多任务中展现出了显著的能力。它不断地在快速进步，并在技术、商业、教育和娱乐等多个领域中发挥着越来越重要的作用。尽管LLM在多个领域取得了成功，但在抽象游戏，如国际象棋方面的能力却尚未得到充分探索。国际象棋游戏要求语言模型从文本输入中输出合法且合理的走法。在这里，我们提出了一种名为ChessLLM的大型语言模型，用于完整地进行国际象棋游戏。我们将游戏转换成文本格式，最合适的走法用佛音-爱德华兹符号表示。我们证明，通过简单的监督微调，我们的模型在与标准Elo评级的Stockfish进行比赛时，允许采样10次的情况下，达到了专业级别的Elo评分为1788分。进一步的研究结果表明，数据质量至关重要。长时间的监督显著提高了350分Elo评级，而短期监督的效果则较差。 

---
# An AI-Driven Live Systematic Reviews in the Brain-Heart Interconnectome: Minimizing Research Waste and Advancing Evidence Synthesis 

**Title (ZH)**: 基于人工智能驱动的脑-心互连网络现场系统评价：减少研究浪费和促进证据综合 

**Authors**: Arya Rahgozar, Pouria Mortezaagha, Jodi Edwards, Douglas Manuel, Jessie McGowen, Merrick Zwarenstein, Dean Fergusson, Andrea Tricco, Kelly Cobey, Margaret Sampson, Malcolm King, Dawn Richards, Alexandra Bodnaruc, David Moher  

**Link**: [PDF](https://arxiv.org/pdf/2501.17181)  

**Abstract**: The Brain-Heart Interconnectome (BHI) combines neurology and cardiology but is hindered by inefficiencies in evidence synthesis, poor adherence to quality standards, and research waste. To address these challenges, we developed an AI-driven system to enhance systematic reviews in the BHI domain. The system integrates automated detection of Population, Intervention, Comparator, Outcome, and Study design (PICOS), semantic search using vector embeddings, graph-based querying, and topic modeling to identify redundancies and underexplored areas. Core components include a Bi-LSTM model achieving 87% accuracy for PICOS compliance, a study design classifier with 95.7% accuracy, and Retrieval-Augmented Generation (RAG) with GPT-3.5, which outperformed GPT-4 for graph-based and topic-driven queries. The system provides real-time updates, reducing research waste through a living database and offering an interactive interface with dashboards and conversational AI. While initially developed for BHI, the system's adaptable architecture enables its application across various biomedical fields, supporting rigorous evidence synthesis, efficient resource allocation, and informed clinical decision-making. 

**Abstract (ZH)**: 脑-心互联系统（Brain-Heart Interconnectome, BHI）结合了神经学与心脏病学，但受到证据综合效率低下、质量标准遵守不佳以及研究浪费等问题的阻碍。为应对这些挑战，我们开发了一个基于人工智能的系统，以提升BHI领域的系统综述质量。该系统集成了自动检测人群、干预措施、对照组、结局和研究设计（PICOS）的功能、基于向量嵌入的语义搜索、图查询和主题建模，以识别多余和未充分研究的领域。核心组件包括一个Bi-LSTM模型，其在PICOS合规性上的准确率达到87%，一个研究设计分类器，其准确率达到95.7%，以及使用GPT-3.5的检索增强生成（RAG），该方法在图基础和主题导向查询上优于GPT-4。该系统提供了实时更新功能，通过一个持续更新的数据库减少了研究浪费，并提供了一个交互界面，包括仪表板和对话式人工智能。尽管最初是为BHI领域开发的，但该系统的可适应架构使其能够在各种医学领域中得到应用，支持严谨的证据综合、高效的资源分配和基于证据的临床决策。 

---
# Dialogue is Better Than Monologue: Instructing Medical LLMs via Strategical Conversations 

**Title (ZH)**: 对话胜过独白：通过策略性对话指导医疗大语言模型 

**Authors**: Zijie Liu, Xinyu Zhao, Jie Peng, Zhuangdi Zhu, Qingyu Chen, Xia Hu, Tianlong Chen  

**Link**: [PDF](https://arxiv.org/pdf/2501.17860)  

**Abstract**: Current medical AI systems often fail to replicate real-world clinical reasoning, as they are predominantly trained and evaluated on static text and question-answer tasks. These tuning methods and benchmarks overlook critical aspects like evidence-based reasoning and handling distracting information. To bridge this gap, we introduce a novel benchmark that simulates real-world diagnostic scenarios, integrating noise and difficulty levels aligned with USMLE standards. Moreover, we explore dialogue-based fine-tuning, which transforms static datasets into conversational formats to better capture iterative reasoning processes. Experiments show that dialogue-tuned models outperform traditional methods, with improvements of $9.64\%$ in multi-round reasoning scenarios and $6.18\%$ in accuracy in a noisy environment. Our findings highlight dialogue tuning as a promising approach for advancing clinically aligned and robust medical AI systems. 

**Abstract (ZH)**: 当前的医疗AI系统常难以再现真实的临床推理过程，因为它们主要是在静态文本和问答任务上进行训练和评估。这些调优方法和评估标准忽视了基于证据的推理和处理干扰信息等关键方面。为弥合这一差距，我们提出了一种新的基准测试，该测试模拟了真实世界的诊断情景，并结合了与美国医学科学院临床评估标准（USMLE）相一致的噪声和难度水平。此外，我们探索了基于对话的调优方法，将静态数据集转换为对话格式，以更好地捕捉迭代推理过程。实验结果表明，基于对话调优的模型在多轮推理场景中表现优于传统方法，准确率提高了9.64%，在噪声环境中准确率提高了6.18%。我们的研究结果突出了基于对话调优是一种增强临床对齐和稳健的医疗AI系统的有前途的方法。 

---
# Improving Your Model Ranking on Chatbot Arena by Vote Rigging 

**Title (ZH)**: 通过投票操纵提高您在聊天机器人竞技场中的模型排名 

**Authors**: Rui Min, Tianyu Pang, Chao Du, Qian Liu, Minhao Cheng, Min Lin  

**Link**: [PDF](https://arxiv.org/pdf/2501.17858)  

**Abstract**: Chatbot Arena is a popular platform for evaluating LLMs by pairwise battles, where users vote for their preferred response from two randomly sampled anonymous models. While Chatbot Arena is widely regarded as a reliable LLM ranking leaderboard, we show that crowdsourced voting can be rigged to improve (or decrease) the ranking of a target model $m_{t}$. We first introduce a straightforward target-only rigging strategy that focuses on new battles involving $m_{t}$, identifying it via watermarking or a binary classifier, and exclusively voting for $m_{t}$ wins. However, this strategy is practically inefficient because there are over $190$ models on Chatbot Arena and on average only about $1\%$ of new battles will involve $m_{t}$. To overcome this, we propose omnipresent rigging strategies, exploiting the Elo rating mechanism of Chatbot Arena that any new vote on a battle can influence the ranking of the target model $m_{t}$, even if $m_{t}$ is not directly involved in the battle. We conduct experiments on around $1.7$ million historical votes from the Chatbot Arena Notebook, showing that omnipresent rigging strategies can improve model rankings by rigging only hundreds of new votes. While we have evaluated several defense mechanisms, our findings highlight the importance of continued efforts to prevent vote rigging. Our code is available at this https URL. 

**Abstract (ZH)**: Chatbot Arena 是一个流行的平台，通过一对一的对决来评估语言模型（LLM），用户在两个随机抽样的匿名模型之间投票选择他们更喜欢的回复。尽管 Chatbot Arena 被广泛认为是一个可靠的 LLM 排名领奖台，但研究表明，众筹投票可以通过策略性操作来改善（或降低）目标模型 $m_{t}$ 的排名。我们首先介绍了一种直接的目标定向操纵策略，专注于涉及 $m_{t}$ 的新对决，通过水印或二元分类器来标识 $m_{t}$，并仅为其赢得胜利进行投票。然而，这种策略在实践中效率较低，因为 Chatbot Arena 上有超过 190 个模型，平均只有约 1% 的新对决会涉及 $m_{t}$。为克服这一问题，我们提出了无处不在的操纵策略，利用 Chatbot Arena 的 Elo 排名机制，即使目标模型 $m_{t}$ 并未直接参与对决，新的投票也能影响其排名。我们通过 Chatbot Arena 笔记本中约 170 万历史投票进行了实验，结果显示，通过操纵数百次新投票即可提升模型排名。虽然我们评估了几种防御机制，但我们的研究结果强调了持续防止投票操纵的重要性。代码可以在以下链接获取：这个 https URL。 

---
# GRACE: Generalizing Robot-Assisted Caregiving with User Functionality Embeddings 

**Title (ZH)**: GRACE：基于用户功能嵌入的机器人辅助护理通用化 

**Authors**: Ziang Liu, Yuanchen Ju, Yu Da, Tom Silver, Pranav N. Thakkar, Jenna Li, Justin Guo, Katherine Dimitropoulou, Tapomayukh Bhattacharjee  

**Link**: [PDF](https://arxiv.org/pdf/2501.17855)  

**Abstract**: Robot caregiving should be personalized to meet the diverse needs of care recipients -- assisting with tasks as needed, while taking user agency in action into account. In physical tasks such as handover, bathing, dressing, and rehabilitation, a key aspect of this diversity is the functional range of motion (fROM), which can vary significantly between individuals. In this work, we learn to predict personalized fROM as a way to generalize robot decision-making in a wide range of caregiving tasks. We propose a novel data-driven method for predicting personalized fROM using functional assessment scores from occupational therapy. We develop a neural model that learns to embed functional assessment scores into a latent representation of the user's physical function. The model is trained using motion capture data collected from users with emulated mobility limitations. After training, the model predicts personalized fROM for new users without motion capture. Through simulated experiments and a real-robot user study, we show that the personalized fROM predictions from our model enable the robot to provide personalized and effective assistance while improving the user's agency in action. See our website for more visualizations: this https URL. 

**Abstract (ZH)**: 机器人护理应个性化以满足护理对象多样化的需求——在执行任务时考虑用户的行动自主权。在如传递物品、洗澡、穿衣和康复等物理任务中，这种多样性的一个关键方面是功能活动范围（fROM），不同个体之间的差异性很大。在这项研究中，我们通过预测个性化的fROM来推广机器人的决策过程，以应对广泛类型的护理任务。我们提出了一种基于数据的新方法，利用职业治疗中获得的功能评估分数来预测个性化的fROM。我们开发了一种神经网络模型，该模型能够将功能评估分数嵌入到用户的物理功能的潜在表示中。该模型使用模拟移动限制的用户的动捕数据进行训练。经过训练后，该模型可以预测新用户的个性化fROM，而无需使用动捕数据。通过模拟实验和实际机器人用户研究，我们展示了模型生成的个性化fROM预测使机器人能够提供个性化且有效的帮助，同时提高用户的行动自主权。更多信息和可视化请参见我们的网站：this https URL。 

---
# From Sparse to Dense: Toddler-inspired Reward Transition in Goal-Oriented Reinforcement Learning 

**Title (ZH)**: 从稀疏到密集：基于学步儿的奖励过渡在目标导向强化学习中的应用 

**Authors**: Junseok Park, Hyeonseo Yang, Min Whoo Lee, Won-Seok Choi, Minsu Lee, Byoung-Tak Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2501.17842)  

**Abstract**: Reinforcement learning (RL) agents often face challenges in balancing exploration and exploitation, particularly in environments where sparse or dense rewards bias learning. Biological systems, such as human toddlers, naturally navigate this balance by transitioning from free exploration with sparse rewards to goal-directed behavior guided by increasingly dense rewards. Inspired by this natural progression, we investigate the Toddler-Inspired Reward Transition in goal-oriented RL tasks. Our study focuses on transitioning from sparse to potential-based dense (S2D) rewards while preserving optimal strategies. Through experiments on dynamic robotic arm manipulation and egocentric 3D navigation tasks, we demonstrate that effective S2D reward transitions significantly enhance learning performance and sample efficiency. Additionally, using a Cross-Density Visualizer, we show that S2D transitions smooth the policy loss landscape, resulting in wider minima that improve generalization in RL models. In addition, we reinterpret Tolman's maze experiments, underscoring the critical role of early free exploratory learning in the context of S2D rewards. 

**Abstract (ZH)**: reinforcement 学习（RL）代理经常面临着在探索与利用之间取得平衡的挑战，特别是在奖励稀疏或密集时容易导致学习偏向的情况。生物系统，如人类婴儿，自然地通过从稀疏奖励的自由探索过渡到由越来越密集奖励引导的目标导向行为来解决这一平衡问题。受这一自然进程的启发，我们研究了在目标导向的 RL 任务中借鉴婴儿探索的奖励过渡方法。我们的研究主要集中在从稀疏奖励过渡到基于潜能的密集奖励（S2D）的过程中，同时保持最优策略不变。通过在动态机械臂操作和以自我为中心的3D导航任务中的实验，我们证明了有效的S2D奖励过渡显著提高了学习性能和样本效率。此外，利用交叉密度可视化工具，我们展示了S2D过渡平滑了策略损失景观，产生了更宽的极小值，从而提高了RL模型的一般性。此外，我们重新解读了托尔曼迷宫实验，突显了在S2D奖励的背景下早期自由探索学习的关键作用。 

---
# U2A: Unified Unimodal Adaptation for Robust and Efficient Multimodal Learning 

**Title (ZH)**: U2A：统一的单模态适应方法以实现鲁棒高效的多模态学习 

**Authors**: Md Kaykobad Reza, Niki Nezakati, Ameya Patil, Mashhour Solh, M. Salman Asif  

**Link**: [PDF](https://arxiv.org/pdf/2501.17823)  

**Abstract**: Multimodal learning often relies on designing new models and complex training strategies to achieve optimal performance. We present Unified Unimodal Adaptation (U2A), which jointly fine-tunes pretrained unimodal encoders using low-rank adaptation (LoRA) for various multimodal tasks. Our method significantly reduces the number of learnable parameters and eliminates the need for complex training strategies, such as alternating training, gradient modifications, or unimodal fine-tuning. To address missing modalities during both training and testing, we introduce Mask Tokens (MT), which generate missing modality features from available modalities using a single token per modality. This simplifies the process, removing the need for specialized feature estimation or prompt-tuning methods. Our evaluation demonstrates that U2A matches or outperforms state-of-the-art methods in both complete and missing modality settings, showcasing strong performance and robustness across various modalities, tasks, and datasets. We also analyze and report the effectiveness of Mask Tokens in different missing modality scenarios. Overall, our method provides a robust, flexible, and efficient solution for multimodal learning, with minimal computational overhead. 

**Abstract (ZH)**: 多模态学习经常依赖于设计新的模型和复杂的训练策略以实现最佳性能。我们提出了统一单模态适应（Unified Unimodal Adaptation, U2A），该方法利用低秩适应（Low-Rank Adaptation, LoRA）联合微调预训练的单模态编码器，以适应多种多模态任务。我们的方法显著减少了可学习参数的数量，并消除了交替训练、梯度修改或单模态微调等复杂训练策略的需要。为了解决训练和测试过程中缺失的模态，我们引入了掩码标记（Mask Tokens, MT），这种方法通过每个模态一个标记，从可用的模态中生成缺失模态特征。这简化了过程，消除了专门特征估算或提示调优方法的需要。我们的评估结果表明，在完整和缺失模态设置下，U2A 方法与其相比具有相当或更优的性能，展示了其在各种模态、任务和数据集上的强大性能和稳健性。我们还分析和报告了在不同缺失模态场景下掩码标记的有效性。总体而言，我们的方法提供了一种在最小计算开销下的稳健、灵活且高效的多模态学习解决方案。 

---
# Aggregation Schemes for Single-Vector WSI Representation Learning in Digital Pathology 

**Title (ZH)**: 数字病理学中单向量WSI表示学习的聚合方案 

**Authors**: Sobhan Hemati, Ghazal Alabtah, Saghir Alfasly, H.R. Tizhoosh  

**Link**: [PDF](https://arxiv.org/pdf/2501.17822)  

**Abstract**: A crucial step to efficiently integrate Whole Slide Images (WSIs) in computational pathology is assigning a single high-quality feature vector, i.e., one embedding, to each WSI. With the existence of many pre-trained deep neural networks and the emergence of foundation models, extracting embeddings for sub-images (i.e., tiles or patches) is straightforward. However, for WSIs, given their high resolution and gigapixel nature, inputting them into existing GPUs as a single image is not feasible. As a result, WSIs are usually split into many patches. Feeding each patch to a pre-trained model, each WSI can then be represented by a set of patches, hence, a set of embeddings. Hence, in such a setup, WSI representation learning reduces to set representation learning where for each WSI we have access to a set of patch embeddings. To obtain a single embedding from a set of patch embeddings for each WSI, multiple set-based learning schemes have been proposed in the literature. In this paper, we evaluate the WSI search performance of multiple recently developed aggregation techniques (mainly set representation learning techniques) including simple average or max pooling operations, Deep Sets, Memory networks, Focal attention, Gaussian Mixture Model (GMM) Fisher Vector, and deep sparse and binary Fisher Vector on four different primary sites including bladder, breast, kidney, and Colon from TCGA. Further, we benchmark the search performance of these methods against the median of minimum distances of patch embeddings, a non-aggregating approach used for WSI retrieval. 

**Abstract (ZH)**: 高效整合全视野图像（WSI）到计算病理学中的关键步骤之一是为每一张WSI分配一个高质量的特征向量，即一种嵌入表示。由于存在许多预训练的深度神经网络和基础模型的出现，从子图像（即切片或片段）中提取嵌入表示变得简单。然而，对于WSI，由于它们的高分辨率和格iga像素特性，将它们作为单个图像输入现有的GPU是不现实的。因此，WSI通常被分割成许多片段。将每个片段输入预训练模型后，每张WSI可以由一组片段表示，即一组嵌入。因此，在这种设置下，WSI的表示学习可以简化为集合表示学习，其中对于每一张WSI，我们可以访问一组片段嵌入。为了从每张WSI的一组片段嵌入中获得一个单一的嵌入，文献中提出了多种集合基学习方案。在这篇论文中，我们评估了几种最近开发的聚合技术（主要是集合表示学习技术），包括简单的平均池化或最大池化操作、Deep Sets、Memory Networks、Focal Attention、Gaussian Mixture Model（GMM）Fisher Vector以及深度稀疏和二元Fisher Vector方法在TCGA提供的四个不同原发病灶（包括膀胱、乳腺、肾脏和结肠）上的WSI搜索性能。此外，我们还将这些方法的搜索性能与用于WSI检索的片段嵌入最小距离的中位值进行了基准测试，这是一种非聚合方法。 

---
# P-TAME: Explain Any Image Classifier with Trained Perturbations 

**Title (ZH)**: P-TAME：通过训练扰动解释任何图像分类器 

**Authors**: Mariano V. Ntrougkas, Vasileios Mezaris, Ioannis Patras  

**Link**: [PDF](https://arxiv.org/pdf/2501.17813)  

**Abstract**: The adoption of Deep Neural Networks (DNNs) in critical fields where predictions need to be accompanied by justifications is hindered by their inherent black-box nature. In this paper, we introduce P-TAME (Perturbation-based Trainable Attention Mechanism for Explanations), a model-agnostic method for explaining DNN-based image classifiers. P-TAME employs an auxiliary image classifier to extract features from the input image, bypassing the need to tailor the explanation method to the internal architecture of the backbone classifier being explained. Unlike traditional perturbation-based methods, which have high computational requirements, P-TAME offers an efficient alternative by generating high-resolution explanations in a single forward pass during inference. We apply P-TAME to explain the decisions of VGG-16, ResNet-50, and ViT-B-16, three distinct and widely used image classifiers. Quantitative and qualitative results show that our method matches or outperforms previous explainability methods, including model-specific approaches. Code and trained models will be released upon acceptance. 

**Abstract (ZH)**: 在需要预测伴随合理解释的关键领域中，深度神经网络（DNNs）的应用受到其固有的黑箱性质的阻碍。本文中，我们介绍了一种模型通用的方法——P-TAME（基于扰动的可训练注意力机制以进行解释），该方法用于解释基于DNN的图像分类器。P-TAME使用一个辅助图像分类器从输入图像中提取特征，从而避免了针对所解释骨干分类器的内部架构定制解释方法的需求。不同于传统的基于扰动的方法，这些方法具有较高的计算要求，P-TAME通过在推理过程中的一次前向传递生成高分辨率的解释，提供了一种高效的替代方案。我们使用P-TAME解释了VGG-16、ResNet-50和ViT-B-16，这三个不同且广泛使用的图像分类器。定量和定性的结果表明，我们的方法与之前的方法相比，无论是特定模型的方法，都能匹配或表现出更优的效果。代码和训练模型将在论文被接受后公开。 

---
# International AI Safety Report 

**Title (ZH)**: 国际人工智能安全报告 

**Authors**: Yoshua Bengio, Sören Mindermann, Daniel Privitera, Tamay Besiroglu, Rishi Bommasani, Stephen Casper, Yejin Choi, Philip Fox, Ben Garfinkel, Danielle Goldfarb, Hoda Heidari, Anson Ho, Sayash Kapoor, Leila Khalatbari, Shayne Longpre, Sam Manning, Vasilios Mavroudis, Mantas Mazeika, Julian Michael, Jessica Newman, Kwan Yee Ng, Chinasa T. Okolo, Deborah Raji, Girish Sastry, Elizabeth Seger, Theodora Skeadas, Tobin South, Emma Strubell, Florian Tramèr, Lucia Velasco, Nicole Wheeler, Daron Acemoglu, Olubayo Adekanmbi, David Dalrymple, Thomas G. Dietterich, Edward W. Felten, Pascale Fung, Pierre-Olivier Gourinchas, Fredrik Heintz, Geoffrey Hinton, Nick Jennings, Andreas Krause, Susan Leavy, Percy Liang, Teresa Ludermir, Vidushi Marda, Helen Margetts, John McDermid, Jane Munga, Arvind Narayanan, Alondra Nelson, Clara Neppel, Alice Oh, Gopal Ramchurn, Stuart Russell, Marietje Schaake, Bernhard Schölkopf, Dawn Song, Alvaro Soto, Lee Tiedrich, Gaël Varoquaux, Andrew Yao, Ya-Qin Zhang, Fahad Albalawi, Marwan Alserkal, Olubunmi Ajala, Guillaume Avrin, Christian Busch, André Carlos Ponce de Leon Ferreira de Carvalho, Bronwyn Fox, Amandeep Singh Gill, Ahmet Halit Hatip, Juha Heikkilä, Gill Jolly, Ziv Katzir, Hiroaki Kitano, Antonio Krüger, Chris Johnson, Saif M. Khan, Kyoung Mu Lee, Dominic Vincent Ligot, Oleksii Molchanovskyi, Andrea Monti, Nusu Mwamanzi, Mona Nemer, Nuria Oliver, José Ramón López Portillo, Balaraman Ravindran, Raquel Pezoa Rivera, Hammam Riza, Crystal Rugege, Ciarán Seoighe, Jerry Sheehan, Haroon Sheikh, Denise Wong, Yi Zeng  

**Link**: [PDF](https://arxiv.org/pdf/2501.17805)  

**Abstract**: The first International AI Safety Report comprehensively synthesizes the current evidence on the capabilities, risks, and safety of advanced AI systems. The report was mandated by the nations attending the AI Safety Summit in Bletchley, UK. Thirty nations, the UN, the OECD, and the EU each nominated a representative to the report's Expert Advisory Panel. A total of 100 AI experts contributed, representing diverse perspectives and disciplines. Led by the report's Chair, these independent experts collectively had full discretion over the report's content. 

**Abstract (ZH)**: 《首次国际人工智能安全报告》全面综合了目前关于先进人工智能系统的功能、风险和安全性方面的证据。该报告由英国布莱切利举行的全球人工智能安全峰会上各国代表强制要求编制。共有30个国家、联合国、经济合作与发展组织（OECD）和欧盟每方指派了一名代表加入报告的专家咨询委员会。总计100位人工智能专家参与了报告编写，涵盖了不同的视角和学科领域。报告由主席领导，这些独立专家在内容上拥有完全的自主决定权。 

---
# BreezyVoice: Adapting TTS for Taiwanese Mandarin with Enhanced Polyphone Disambiguation -- Challenges and Insights 

**Title (ZH)**: BreezyVoice：增强多音字消岐的台式普通话朗读合成技术——挑战与见解

这个标题的翻译尽量保持了原文的学术用语和风格，同时确保了中文表达的准确性和流畅性。其中，“BreezyVoice”是系统或项目的名称，通常保持不变。如果是正式的学术论文或报告，可以保持“BreezyVoice”不变，只需要翻译其余部分。 

**Authors**: Chan-Jan Hsu, Yi-Cheng Lin, Chia-Chun Lin, Wei-Chih Chen, Ho Lam Chung, Chen-An Li, Yi-Chang Chen, Chien-Yu Yu, Ming-Ji Lee, Chien-Cheng Chen, Ru-Heng Huang, Hung-yi Lee, Da-Shan Shiu  

**Link**: [PDF](https://arxiv.org/pdf/2501.17790)  

**Abstract**: We present BreezyVoice, a Text-to-Speech (TTS) system specifically adapted for Taiwanese Mandarin, highlighting phonetic control abilities to address the unique challenges of polyphone disambiguation in the language. Building upon CosyVoice, we incorporate a $S^{3}$ tokenizer, a large language model (LLM), an optimal-transport conditional flow matching model (OT-CFM), and a grapheme to phoneme prediction model, to generate realistic speech that closely mimics human utterances. Our evaluation demonstrates BreezyVoice's superior performance in both general and code-switching contexts, highlighting its robustness and effectiveness in generating high-fidelity speech. Additionally, we address the challenges of generalizability in modeling long-tail speakers and polyphone disambiguation. Our approach significantly enhances performance and offers valuable insights into the workings of neural codec TTS systems. 

**Abstract (ZH)**: 我们介绍了BreezyVoice，这是一种专门为台湾普通话量身定制的文本到语音（TTS）系统，强调了其在解决语言中多音字消歧问题时的音素控制能力。基于CosyVoice，我们引入了$S^{3}$分词器、大型语言模型（LLM）、最优运输条件流匹配模型（OT-CFM）以及字母表到音素预测模型，以生成接近人类发音的真实语音。我们的评估表明，BreezyVoice 在通用和代码切换场景中均表现出色，突显了其在生成高保真语音方面的稳健性和有效性。此外，我们还解决了模型中长尾说话人的一般化能力和多音字消歧问题的挑战。我们的方法显著提升了性能，并为神经编码器-解码器TTS系统的运作机制提供了宝贵见解。 

---
# 2SSP: A Two-Stage Framework for Structured Pruning of LLMs 

**Title (ZH)**: 2SSP：一个两阶段框架，用于大规模语言模型的结构剪枝 

**Authors**: Fabrizio Sandri, Elia Cunegatti, Giovanni Iacca  

**Link**: [PDF](https://arxiv.org/pdf/2501.17771)  

**Abstract**: We propose a novel Two-Stage framework for Structured Pruning (2SSP) for pruning Large Language Models (LLMs), which combines two different strategies of pruning, namely Width and Depth Pruning. The first stage (Width Pruning) removes entire neurons, hence their corresponding rows and columns, aiming to preserve the connectivity among the pruned structures in the intermediate state of the Feed-Forward Networks in each Transformer block. This is done based on an importance score measuring the impact of each neuron over the output magnitude. The second stage (Depth Pruning), instead, removes entire Attention submodules. This is done by applying an iterative process that removes the Attention submodules with the minimum impact on a given metric of interest (in our case, perplexity). We also propose a novel mechanism to balance the sparsity rate of the two stages w.r.t. to the desired global sparsity. We test 2SSP on four LLM families and three sparsity rates (25\%, 37.5\%, and 50\%), measuring the resulting perplexity over three language modeling datasets as well as the performance over six downstream tasks. Our method consistently outperforms five state-of-the-art competitors over three language modeling and six downstream tasks, with an up to two-order-of-magnitude gain in terms of pruning time. The code is available at available at \url{this https URL}. 

**Abstract (ZH)**: 我们提出了一种新颖的两阶段框架（2SSP）用于大型语言模型（LLMs）的结构剪枝，该框架结合了宽度剪枝和深度剪枝这两种不同的剪枝策略。第一阶段（宽度剪枝）移除整个神经元及其对应的行和列，目标是在每个Transformer块的前馈网络中间状态中保持剪枝结构的连接性。这基于一个衡量每个神经元对输出幅度影响的重要性得分来进行。第二阶段（深度剪枝）则移除整个注意力子模块。这通过迭代过程实现，该过程移除对给定目标度量（在我们的情况下为困惑度）影响最小的注意力子模块。我们还提出了一种新的机制，用于根据所需的全局稀疏率平衡两个阶段的稀疏率。我们在四个LLM家族和三个稀疏率（25%，37.5%和50%）上测试了2SSP，测量了在三个语言建模数据集和六个下游任务上的结果困惑度以及性能。我们的方法在三个语言建模和六个下游任务上均优于五种最先进的竞争对手，剪枝时间提高了高达两个数量级。相关代码可在 \url{此链接} 获取。 

---
# Hybrid Graphs for Table-and-Text based Question Answering using LLMs 

**Title (ZH)**: 基于LLM的表文结合问答中的混合图模型 

**Authors**: Ankush Agarwal, Ganesh S, Chaitanya Devaguptapu  

**Link**: [PDF](https://arxiv.org/pdf/2501.17767)  

**Abstract**: Answering questions that require reasoning and aggregation across both structured (tables) and unstructured (raw text) data sources presents significant challenges. Current methods rely on fine-tuning and high-quality, human-curated data, which is difficult to obtain. Recent advances in Large Language Models (LLMs) have shown promising results for multi-hop question answering (QA) over single-source text data in a zero-shot setting, yet exploration into multi-source Table-Text QA remains limited. In this paper, we present a novel Hybrid Graph-based approach for Table-Text QA that leverages LLMs without fine-tuning. Our method constructs a unified Hybrid Graph from textual and tabular data, pruning information based on the input question to provide the LLM with relevant context concisely. We evaluate our approach on the challenging Hybrid-QA and OTT-QA datasets using state-of-the-art LLMs, including GPT-3.5, GPT-4, and LLaMA-3. Our method achieves the best zero-shot performance on both datasets, improving Exact Match scores by up to 10% on Hybrid-QA and 5.4% on OTT-QA. Moreover, our approach reduces token usage by up to 53% compared to the original context. 

**Abstract (ZH)**: 跨结构化（表格）和非结构化（原始文本）数据源进行推理和聚合以回答问题，面临着重大的挑战。当前的方法依赖于微调和高质量的人工标注数据，这些数据的获取非常困难。最近大型语言模型（LLMs）的进步在零样本设置下对单源文本数据进行多跳问答（QA）方面取得了令人鼓舞的结果，但在多源表文问答方面的探索仍然有限。在本文中，我们提出了一种新的基于混合图的方法，该方法在不需要微调的情况下利用了LLMs。我们的方法从文本和表格数据中构建一个统一的混合图，并根据输入问题修剪信息，以便简洁地为LLM提供相关上下文。我们使用最先进的LLMs（包括GPT-3.5、GPT-4和LLaMA-3）在具有挑战性的Hybrid-QA和OTT-QA数据集上评估了我们的方法。在两个数据集上，我们的方法均实现了最佳的零样本性能，Exact Match得分在Hybrid-QA上提高了多达10%，在OTT-QA上提高了5.4%。此外，与原始上下文相比，我们的方法将token使用量最多减少了53%。 

---
# Yin-Yang: Developing Motifs With Long-Term Structure And Controllability 

**Title (ZH)**: 阴阳： DEVELOPING MOLECULAR MOTIFS WITH LONG-TERM STRUCTURAL STABILITY AND CONTROLLABILITY

这里的翻译中，“阴阳”是对英文题目中“Yin-Yang”部分的直译，保留了原文的文化或概念含义。“DEVELOPING MOLECULAR MOTIFS”是对“Developing Motifs”的翻译，并且增加了“MOLECULAR”以便更加符合化学或分子生物学领域的学术表达。“WITH长短期结构和可控性”是对“With Long-Term Structure And Controllability”的翻译，调整了句式以符合中文的表达习惯。“STABILITY”在这里被译为“稳定性”，更能准确传达出长期结构稳定性的含义。 

**Authors**: Keshav Bhandari, Geraint A. Wiggins, Simon Colton  

**Link**: [PDF](https://arxiv.org/pdf/2501.17759)  

**Abstract**: Transformer models have made great strides in generating symbolically represented music with local coherence. However, controlling the development of motifs in a structured way with global form remains an open research area. One of the reasons for this challenge is due to the note-by-note autoregressive generation of such models, which lack the ability to correct themselves after deviations from the motif. In addition, their structural performance on datasets with shorter durations has not been studied in the literature. In this study, we propose Yin-Yang, a framework consisting of a phrase generator, phrase refiner, and phrase selector models for the development of motifs into melodies with long-term structure and controllability. The phrase refiner is trained on a novel corruption-refinement strategy which allows it to produce melodic and rhythmic variations of an original motif at generation time, thereby rectifying deviations of the phrase generator. We also introduce a new objective evaluation metric for quantifying how smoothly the motif manifests itself within the piece. Evaluation results show that our model achieves better performance compared to state-of-the-art transformer models while having the advantage of being controllable and making the generated musical structure semi-interpretable, paving the way for musical analysis. Our code and demo page can be found at this https URL. 

**Abstract (ZH)**: 变换器模型在生成具有局部连贯性的符号表示音乐方面取得了显著进展。然而，以结构化的方式控制主题的发展并在全局形式上进行调控仍然是一个待解决的研究领域。其中一个挑战的原因是，这类模型以逐音符的自回归方式生成音乐，缺乏在偏离主题后自我校正的能力。此外，它们在较短时长数据集上的结构性能在文献中尚未得到研究。在本研究中，我们提出了Yin-Yang框架，该框架由短语生成器、短语修饰器和短语选择器模型组成，用于发展具有长期结构和可控性的主题为旋律。短语修饰器通过一种新颖的破坏-修正策略进行训练，使其能够在生成时产生原始主题的旋律和节奏变化，从而修正短语生成器的偏离。我们还引入了一个新的客观评估指标来量化主题在乐曲中如何平滑地表现。评估结果表明，我们的模型在性能上优于最先进的变换器模型，同时具有可控性，使生成的音乐结构半可解释，为音乐分析开辟了道路。我们的代码和演示页面可以在以下链接找到：[此 https URL]。 

---
# AI Governance through Markets 

**Title (ZH)**: 通过市场机制进行的人工智能治理 

**Authors**: Philip Moreira Tomei, Rupal Jain, Matija Franklin  

**Link**: [PDF](https://arxiv.org/pdf/2501.17755)  

**Abstract**: This paper argues that market governance mechanisms should be considered a key approach in the governance of artificial intelligence (AI), alongside traditional regulatory frameworks. While current governance approaches have predominantly focused on regulation, we contend that market-based mechanisms offer effective incentives for responsible AI development. We examine four emerging vectors of market governance: insurance, auditing, procurement, and due diligence, demonstrating how these mechanisms can affirm the relationship between AI risk and financial risk while addressing capital allocation inefficiencies. While we do not claim that market forces alone can adequately protect societal interests, we maintain that standardised AI disclosures and market mechanisms can create powerful incentives for safe and responsible AI development. This paper urges regulators, economists, and machine learning researchers to investigate and implement market-based approaches to AI governance. 

**Abstract (ZH)**: 本文 argue 市场治理机制应被视为与传统监管框架并行的关键方法，以治理人工智能（AI）。尽管目前的治理方法主要集中在监管上，我们认为基于市场的机制能够提供有效的激励，促进负责任的AI发展。我们探讨了四种新兴的市场治理向量：保险、审计、采购和尽职调查，展示了这些机制如何证实AI风险与财务风险之间的关系，并解决资本分配的低效率问题。虽不主张市场力量本身足以全面保护社会利益，但我们认为标准化的AI披露和市场机制可以创造强大的激励，促进安全和负责任的AI发展。本文敦促监管者、经济学家和机器学习研究人员调查和实施以市场为基础的AI治理方法。 

---
# Early External Safety Testing of OpenAI's o3-mini: Insights from the Pre-Deployment Evaluation 

**Title (ZH)**: OpenAI的o3-mini的早期外部安全性测试：预部署评估的洞见 

**Authors**: Aitor Arrieta, Miriam Ugarte, Pablo Valle, José Antonio Parejo, Sergio Segura  

**Link**: [PDF](https://arxiv.org/pdf/2501.17749)  

**Abstract**: Large Language Models (LLMs) have become an integral part of our daily lives. However, they impose certain risks, including those that can harm individuals' privacy, perpetuate biases and spread misinformation. These risks highlight the need for robust safety mechanisms, ethical guidelines, and thorough testing to ensure their responsible deployment. Safety of LLMs is a key property that needs to be thoroughly tested prior the model to be deployed and accessible to the general users. This paper reports the external safety testing experience conducted by researchers from Mondragon University and University of Seville on OpenAI's new o3-mini LLM as part of OpenAI's early access for safety testing program. In particular, we apply our tool, ASTRAL, to automatically and systematically generate up to date unsafe test inputs (i.e., prompts) that helps us test and assess different safety categories of LLMs. We automatically generate and execute a total of 10,080 unsafe test input on a early o3-mini beta version. After manually verifying the test cases classified as unsafe by ASTRAL, we identify a total of 87 actual instances of unsafe LLM behavior. We highlight key insights and findings uncovered during the pre-deployment external testing phase of OpenAI's latest LLM. 

**Abstract (ZH)**: 大型语言模型（LLMs）已经成为我们日常生活的一部分。然而，它们也带来了一些风险，包括可能损害个人隐私、加剧偏见和传播假信息的风险。这些风险突出强调了需要建立 robust 的安全机制、遵循伦理准则以及进行彻底的测试，以确保其负责任地部署。LLM 的安全性是一项关键属性，在模型部署前需要对其进行彻底测试。本文报告了 Mondragon 大学和塞维利亚大学的研究人员在外部分析程序的背景下，对外部测试经验进行的测试，研究对象是 OpenAI 新的 o3-mini LLM，这是 OpenAI 安全测试早期访问计划的一部分。特别是，我们使用我们的工具 ASTRAL，自动并系统地生成了最新的不安全测试输入（即提示），帮助我们测试和评估不同安全类别的 LLM。我们自动生成并执行了 10,080 个不安全测试输入，针对早期的 o3-mini 测试版。在手动验证 ASTRA 鉴定为不安全的测试案例后，我们识别出了总计 87 个实际的不安全 LLM 行为实例。我们在 OpenAI 最新 LLM 的前期外部测试阶段发现了关键见解和研究成果。 

---
# Exact characterization of {\epsilon}-Safe Decision Regions for exponential family distributions and Multi Cost SVM approximation 

**Title (ZH)**: ε-Safe 决策区域的精确表征：指数族分布和多成本 SVM 近似 

**Authors**: Alberto Carlevaro, Teodoro Alamo, Fabrizio Dabbene, Maurizio Mongelli  

**Link**: [PDF](https://arxiv.org/pdf/2501.17731)  

**Abstract**: Probabilistic guarantees on the prediction of data-driven classifiers are necessary to define models that can be considered reliable. This is a key requirement for modern machine learning in which the goodness of a system is measured in terms of trustworthiness, clearly dividing what is safe from what is unsafe. The spirit of this paper is exactly in this direction. First, we introduce a formal definition of {\epsilon}-Safe Decision Region, a subset of the input space in which the prediction of a target (safe) class is probabilistically guaranteed. Second, we prove that, when data come from exponential family distributions, the form of such a region is analytically determined and controllable by design parameters, i.e. the probability of sampling the target class and the confidence on the prediction. However, the request of having exponential data is not always possible. Inspired by this limitation, we developed Multi Cost SVM, an SVM based algorithm that approximates the safe region and is also able to handle unbalanced data. The research is complemented by experiments and code available for reproducibility. 

**Abstract (ZH)**: 数据驱动分类器预测的概率保证是定义可靠模型所必需的。这对于现代机器学习而言是关键要求，在这种学习模式中，系统的优劣性是通过可信赖性来衡量的，从而明确区分安全与不安全的行为。本文的精神正是朝着这一方向努力。首先，我们提出了ε-安全决策区域的形式化定义，这是一个输入空间的子集，在该区域内对目标（安全）类别的预测具有概率保证。其次，我们证明了当数据来自指数族分布时，此类区域的形式可以由设计参数（即目标类别采样概率和预测置信度）来解析地确定和控制。然而，要求数据服从指数分布并不总是可行的。受这一限制的启发，我们开发了多成本支持向量机（Multi Cost SVM），这是一种基于支持向量机的算法，可以近似安全区域，并能够处理不平衡数据。研究还包括了可重现的实验和代码。 

---
# PulmoFusion: Advancing Pulmonary Health with Efficient Multi-Modal Fusion 

**Title (ZH)**: PulmoFusion：以高效多模态融合促进肺部健康的研究 

**Authors**: Ahmed Sharshar, Yasser Attia, Mohammad Yaqub, Mohsen Guizani  

**Link**: [PDF](https://arxiv.org/pdf/2501.17699)  

**Abstract**: Traditional remote spirometry lacks the precision required for effective pulmonary monitoring. We present a novel, non-invasive approach using multimodal predictive models that integrate RGB or thermal video data with patient metadata. Our method leverages energy-efficient Spiking Neural Networks (SNNs) for the regression of Peak Expiratory Flow (PEF) and classification of Forced Expiratory Volume (FEV1) and Forced Vital Capacity (FVC), using lightweight CNNs to overcome SNN limitations in regression tasks. Multimodal data integration is improved with a Multi-Head Attention Layer, and we employ K-Fold validation and ensemble learning to boost robustness. Using thermal data, our SNN models achieve 92% accuracy on a breathing-cycle basis and 99.5% patient-wise. PEF regression models attain Relative RMSEs of 0.11 (thermal) and 0.26 (RGB), with an MAE of 4.52% for FEV1/FVC predictions, establishing state-of-the-art performance. Code and dataset can be found on this https URL 

**Abstract (ZH)**: 传统远程肺功能检测缺乏有效的精准度。我们提出了一种新颖的非侵入性方法，该方法利用多模态预测模型整合RGB或热成像视频数据与患者元数据。该方法结合了节能型脉冲神经网络（SNNs）和轻量级CNNs，用于Pef最大呼气流量的回归及FEV1和FVC的分类。通过多头注意力层改进了多模态数据的集成，并采用K-Fold验证和集成学习来提高鲁棒性。使用热成像数据，我们的SNN模型在每次呼吸周期上的准确率为92%，个体水平上为99.5%。Pef回归模型获得了相对RMSE为0.11（热成像）和0.26（RGB），以及FEV1/FVC预测的MAE为4.52%，确立了最先进的性能。代码和数据集可以在以下链接找到：this https URL 

---
# Segmentation-Aware Generative Reinforcement Network (GRN) for Tissue Layer Segmentation in 3-D Ultrasound Images for Chronic Low-back Pain (cLBP) Assessment 

**Title (ZH)**: 具有分割意识的生成强化网络（GRN）在三维超声图像中进行慢性腰痛（cLBP）评估中的组织层分割 

**Authors**: Zixue Zeng, Xiaoyan Zhao, Matthew Cartier, Tong Yu, Jing Wang, Xin Meng, Zhiyu Sheng, Maryam Satarpour, John M Cormack, Allison Bean, Ryan Nussbaum, Maya Maurer, Emily Landis-Walkenhorst, Dinesh Kumbhare, Kang Kim, Ajay Wasan, Jiantao Pu  

**Link**: [PDF](https://arxiv.org/pdf/2501.17690)  

**Abstract**: We introduce a novel segmentation-aware joint training framework called generative reinforcement network (GRN) that integrates segmentation loss feedback to optimize both image generation and segmentation performance in a single stage. An image enhancement technique called segmentation-guided enhancement (SGE) is also developed, where the generator produces images tailored specifically for the segmentation model. Two variants of GRN were also developed, including GRN for sample-efficient learning (GRN-SEL) and GRN for semi-supervised learning (GRN-SSL). GRN's performance was evaluated using a dataset of 69 fully annotated 3D ultrasound scans from 29 subjects. The annotations included six anatomical structures: dermis, superficial fat, superficial fascial membrane (SFM), deep fat, deep fascial membrane (DFM), and muscle. Our results show that GRN-SEL with SGE reduces labeling efforts by up to 70% while achieving a 1.98% improvement in the Dice Similarity Coefficient (DSC) compared to models trained on fully labeled datasets. GRN-SEL alone reduces labeling efforts by 60%, GRN-SSL with SGE decreases labeling requirements by 70%, and GRN-SSL alone by 60%, all while maintaining performance comparable to fully supervised models. These findings suggest the effectiveness of the GRN framework in optimizing segmentation performance with significantly less labeled data, offering a scalable and efficient solution for ultrasound image analysis and reducing the burdens associated with data annotation. 

**Abstract (ZH)**: 我们介绍了一种新颖的结合分割感知联合训练框架，称为生成强化网络（GRN），该框架将分割损失反馈整合到单阶段中，以优化图像生成和分割性能。还开发了一种图像增强技术，称为分割引导增强（SGE），其中生成器为分割模型生成定制图像。此外，还开发了GRN的两种变体，包括用于样本高效学习的GRN（GRN-SEL）和用于半监督学习的GRN（GRN-SSL）。GRN 的性能使用包含 69 个完全注释的 3D 超声扫描的 29 个受试者的数据集进行了评估。注释包括六种解剖结构：真皮、表层脂肪、表层筋膜膜（SFM）、深层脂肪、深层筋膜膜（DFM）和肌肉。我们的结果表明，使用 SGE 的 GRN-SEL 可将标记工作量减少多达 70%，同时在Dice相似系数（DSC）方面相比完全标记数据集训练的模型提高 1.98% 的性能。仅使用 GRN-SEL 将标记工作量减少 60%，使用 SGE 的 GRN-SSL 将标记需求减少 70%，仅使用 GRN-SSL 减少 60%，同时保持与完全监督模型相当的性能。这些发现表明，GRN 框架在显著减少标记数据的情况下优化分割性能的有效性，为超声图像分析提供了一种可扩展且高效的解决方案，并减少了与数据标注相关的负担。 

---
# ContourFormer:Real-Time Contour-Based End-to-End Instance Segmentation Transformer 

**Title (ZH)**: ContourFormer：实时基于轮廓的端到端实例分割变换器 

**Authors**: Weiwei yao, Chen Li, Minjun Xiong, Wenbo Dong, Hao Chen, Xiong Xiao  

**Link**: [PDF](https://arxiv.org/pdf/2501.17688)  

**Abstract**: This paper presents Contourformer, a real-time contour-based instance segmentation algorithm. The method is fully based on the DETR paradigm and achieves end-to-end inference through iterative and progressive mechanisms to optimize contours. To improve efficiency and accuracy, we develop two novel techniques: sub-contour decoupling mechanisms and contour fine-grained distribution this http URL the sub-contour decoupling mechanism, we propose a deformable attention-based module that adaptively selects sampling regions based on the current predicted contour, enabling more effective capturing of object boundary information. Additionally, we design a multi-stage optimization process to enhance segmentation precision by progressively refining sub-contours. The contour fine-grained distribution refinement technique aims to further improve the ability to express fine details of this http URL innovations enable Contourformer to achieve stable and precise segmentation for each instance while maintaining real-time performance. Extensive experiments demonstrate the superior performance of Contourformer on multiple benchmark datasets, including SBD, COCO, and KINS. We conduct comprehensive evaluations and comparisons with existing state-of-the-art methods, showing significant improvements in both accuracy and inference this http URL work provides a new solution for contour-based instance segmentation tasks and lays a foundation for future research, with the potential to become a strong baseline method in this field. 

**Abstract (ZH)**: 本文提出了一种实时轮廓基实例分割算法——Contourformer。该方法完全基于DETR框架，通过迭代和渐进机制优化轮廓，以实现端到端的推理。为了提高效率和准确性，我们开发了两种新的技术：分支轮廓解耦机制和轮廓细粒度分布精炼。在分支轮廓解耦机制中，我们提出了一种基于变形注意力的模块，该模块根据当前预测的轮廓自适应地选择采样区域，从而更有效地捕捉对象边界信息。此外，我们设计了一个多阶段优化过程，通过逐步细化分支轮廓来增强分割精度。轮廓细粒度分布精炼技术旨在进一步增强表示细微细节的能力。这些创新使Contourformer能够在保持实时性能的同时，实现每个实例的稳定和精确分割。广泛的实验显示，Contourformer在包括SBD、COCO和KINS在内的多个基准数据集上表现出卓越的性能。我们进行了全面的评估和与现有先进方法的比较，显示出在准确性和推理速度上的显著改进。本文为轮廓基实例分割任务提供了一个新的解决方案，并为进一步研究奠定了基础，有可能成为该领域的强基线方法。 

---
# Planning with Vision-Language Models and a Use Case in Robot-Assisted Teaching 

**Title (ZH)**: 使用视觉-语言模型进行规划及一项基于机器人辅助教学的应用案例 

**Authors**: Xuzhe Dang, Lada Kudláčková, Stefan Edelkamp  

**Link**: [PDF](https://arxiv.org/pdf/2501.17665)  

**Abstract**: Automating the generation of Planning Domain Definition Language (PDDL) with Large Language Model (LLM) opens new research topic in AI planning, particularly for complex real-world tasks. This paper introduces Image2PDDL, a novel framework that leverages Vision-Language Models (VLMs) to automatically convert images of initial states and descriptions of goal states into PDDL problems. By providing a PDDL domain alongside visual inputs, Imasge2PDDL addresses key challenges in bridging perceptual understanding with symbolic planning, reducing the expertise required to create structured problem instances, and improving scalability across tasks of varying complexity. We evaluate the framework on various domains, including standard planning domains like blocksworld and sliding tile puzzles, using datasets with multiple difficulty levels. Performance is assessed on syntax correctness, ensuring grammar and executability, and content correctness, verifying accurate state representation in generated PDDL problems. The proposed approach demonstrates promising results across diverse task complexities, suggesting its potential for broader applications in AI planning. We will discuss a potential use case in robot-assisted teaching of students with Autism Spectrum Disorder. 

**Abstract (ZH)**: 使用大型语言模型（LLM）自动化生成Planning Domain Definition Language (PDDL) 为人工智能规划领域开辟了新的研究课题，尤其是针对复杂的现实任务。本文介绍了Image2PDDL，这是一种新颖的框架，利用视觉语言模型（VLMs）将初始状态的图像和目标状态的描述自动转换为PDDL问题。通过提供PDDL域和视觉输入，Image2PDDL解决了知觉理解和符号规划之间的桥梁构建难题，减少了创建结构化问题实例所需的专业知识，并提高了不同复杂度任务的可扩展性。我们在各种领域对框架进行了评估，包括标准规划域如积木世界和滑块拼图，使用具有多种难度级别的数据集。性能评估从语法正确性和内容正确性两个方面进行，确保语法正确、可执行性，并验证生成的PDDL问题中状态表示的准确性。提出的这种方法在不同任务复杂性下表现出有前途的结果，这表明其在人工智能规划中的广泛应用潜力。我们还将讨论其在自闭症谱系障碍学生辅助教学中的潜在应用场景。 

---
# Exploring Vision Language Models for Multimodal and Multilingual Stance Detection 

**Title (ZH)**: 探索视觉语言模型在多模态多语言立场检测中的应用 

**Authors**: Jake Vasilakes, Carolina Scarton, Zhixue Zhao  

**Link**: [PDF](https://arxiv.org/pdf/2501.17654)  

**Abstract**: Social media's global reach amplifies the spread of information, highlighting the need for robust Natural Language Processing tasks like stance detection across languages and modalities. Prior research predominantly focuses on text-only inputs, leaving multimodal scenarios, such as those involving both images and text, relatively underexplored. Meanwhile, the prevalence of multimodal posts has increased significantly in recent years. Although state-of-the-art Vision-Language Models (VLMs) show promise, their performance on multimodal and multilingual stance detection tasks remains largely unexamined. This paper evaluates state-of-the-art VLMs on a newly extended dataset covering seven languages and multimodal inputs, investigating their use of visual cues, language-specific performance, and cross-modality interactions. Our results show that VLMs generally rely more on text than images for stance detection and this trend persists across languages. Additionally, VLMs rely significantly more on text contained within the images than other visual content. Regarding multilinguality, the models studied tend to generate consistent predictions across languages whether they are explicitly multilingual or not, although there are outliers that are incongruous with macro F1, language support, and model size. 

**Abstract (ZH)**: 社交媒体的全球影响力放大了信息传播的速度，强调了在多种语言和模态下进行稳健自然语言处理任务（如立场检测）的必要性。之前的研究主要集中在文本输入上，而涉及图像和文本等多模态场景的情况相对较未被探索。同时，近年来多模态帖子的 prevalence 显著增加。尽管最新的视觉-语言模型（VLMs）显示出潜力，但它们在多模态和多语言立场检测任务上的表现仍需进一步研究。本文在一项覆盖七种语言和多种模态输入的新扩展数据集上评估了最新的 VLMs，探讨了其对视觉线索的利用、语言特定表现以及跨模态交互。研究结果显示，VLMs 通常更多依赖文本而非图像来进行立场检测，这一趋势在不同语言中依然保持。此外，模型更倾向于依赖图像中包含的文本信息，而非其他视觉内容。就多语言性而言，所研究的模型在是否明确支持多语言的情况下，通常能够产生一致的预测，尽管有少数模型的表现与宏观 F1 分数、语言支持和模型规模存在不一致性。 

---
# Tonguescape: Exploring Language Models Understanding of Vowel Articulation 

**Title (ZH)**: 《声带景观：探究语言模型对元音发音的理解》 

**Authors**: Haruki Sakajo, Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe  

**Link**: [PDF](https://arxiv.org/pdf/2501.17643)  

**Abstract**: Vowels are primarily characterized by tongue position. Humans have discovered these features of vowel articulation through their own experience and explicit objective observation such as using MRI. With this knowledge and our experience, we can explain and understand the relationship between tongue positions and vowels, and this knowledge is helpful for language learners to learn pronunciation. Since language models (LMs) are trained on a large amount of data that includes linguistic and medical fields, our preliminary studies indicate that an LM is able to explain the pronunciation mechanisms of vowels. However, it is unclear whether multi-modal LMs, such as vision LMs, align textual information with visual information. One question arises: do LMs associate real tongue positions with vowel articulation? In this study, we created video and image datasets from the existing real-time MRI dataset and investigated whether LMs can understand vowel articulation based on tongue positions using vision-based information. Our findings suggest that LMs exhibit potential for understanding vowels and tongue positions when reference examples are provided while they have difficulties without them. Our code for dataset building is available on GitHub. 

**Abstract (ZH)**: 元音主要由舌位决定。人类通过自身的经验以及明确的客观观察，如使用MRI，发现了这些元音发音特征。凭借这些知识和经验，我们可以解释和理解舌位与元音之间的关系，这对语言学习者掌握发音很有帮助。由于语言模型（LMs）在包括语言学和医学领域的大量数据上进行了训练，我们的初步研究显示，LMs能够解释元音发音机制。然而，尚未明确多模态LMs，如视觉LMs，是否会将文本信息与视觉信息对齐。由此产生了一个问题：LMs能否将实际的舌位与元音发音联系起来？在本研究中，我们从现有的实时MRI数据集创建了视频和图像数据集，并探讨了LMs是否可以通过基于视觉信息了解舌位与元音发音之间的关系。我们的研究结果表明，在提供参考示例的情况下，LMs在理解元音和舌位方面表现出潜力；而没有这些参考示例时，LMs会面临困难。我们用于数据集构建的代码可以在GitHub上获取。 

---
# In-Context Meta LoRA Generation 

**Title (ZH)**: 上下文引导的元LoRA生成 

**Authors**: Yihua Shao, Minxi Yan, Yang Liu, Siyu Chen, Wenjie Chen, Xinwei Long, Ziyang Yan, Lei Li, Chenyu Zhang, Nicu Sebe, Hao Tang, Yan Wang, Hao Zhao, Mengzhu Wang, Jingcai Guo  

**Link**: [PDF](https://arxiv.org/pdf/2501.17635)  

**Abstract**: Low-rank Adaptation (LoRA) has demonstrated remarkable capabilities for task specific fine-tuning. However, in scenarios that involve multiple tasks, training a separate LoRA model for each one results in considerable inefficiency in terms of storage and inference. Moreover, existing parameter generation methods fail to capture the correlations among these tasks, making multi-task LoRA parameter generation challenging. To address these limitations, we propose In-Context Meta LoRA (ICM-LoRA), a novel approach that efficiently achieves task-specific customization of large language models (LLMs). Specifically, we use training data from all tasks to train a tailored generator, Conditional Variational Autoencoder (CVAE). CVAE takes task descriptions as inputs and produces task-aware LoRA weights as outputs. These LoRA weights are then merged with LLMs to create task-specialized models without the need for additional fine-tuning. Furthermore, we utilize in-context meta-learning for knowledge enhancement and task mapping, to capture the relationship between tasks and parameter distributions. As a result, our method achieves more accurate LoRA parameter generation for diverse tasks using CVAE. ICM-LoRA enables more accurate LoRA parameter reconstruction than current parameter reconstruction methods and is useful for implementing task-specific enhancements of LoRA parameters. At the same time, our method occupies 283MB, only 1\% storage compared with the original LoRA. 

**Abstract (ZH)**: 低秩适应（LoRA）在特定任务微调方面展示了显著的能力。然而，在涉及多个任务的场景中，为每个任务分别训练一个LoRA模型会导致存储和推理效率方面的极大浪费。此外，现有的参数生成方法未能捕捉这些任务之间的相关性，使得多任务LoRA参数生成变得具有挑战性。为解决这些限制，我们提出了一种名为In-Context元LoRA（ICM-LoRA）的新颖方法，能够高效地为大型语言模型（LLMs）实现任务特定的定制化。具体而言，我们利用所有任务的数据训练一个定制生成器——条件变分自编码器（CVAE）。CVAE将任务描述作为输入，并生成任务感知的LoRA权重作为输出。这些LoRA权重随后与LLMs合并，以创建特定任务的模型，无需额外的微调。此外，我们使用上下文元学习来增强知识并进行任务映射，以捕捉任务之间的关系以及参数分布。因此，我们的方法能够利用CVAE更准确地生成多样任务的LoRA参数。ICM-LoRA相比现有参数重建方法能够更准确地重建LoRA参数，并且可用于实现LoRA参数的任务特定增强。同时，我们的方法仅占用283MB的存储空间，相较于原始的LoRA，仅为1%的存储量。 

---
# The Imitation Game According To Turing 

**Title (ZH)**: 图灵的模仿游戏 

**Authors**: Sharon Temtsin, Diane Proudfoot, David Kaber, Christoph Bartneck  

**Link**: [PDF](https://arxiv.org/pdf/2501.17629)  

**Abstract**: The current cycle of hype and anxiety concerning the benefits and risks to human society of Artificial Intelligence is fuelled, not only by the increasing use of generative AI and other AI tools by the general public, but also by claims made on behalf of such technology by popularizers and scientists. In particular, recent studies have claimed that Large Language Models (LLMs) can pass the Turing Test-a goal for AI since the 1950s-and therefore can "think". Large-scale impacts on society have been predicted as a result. Upon detailed examination, however, none of these studies has faithfully applied Turing's original instructions. Consequently, we conducted a rigorous Turing Test with GPT-4-Turbo that adhered closely to Turing's instructions for a three-player imitation game. We followed established scientific standards where Turing's instructions were ambiguous or missing. For example, we performed a Computer-Imitates-Human Game (CIHG) without constraining the time duration and conducted a Man-Imitates-Woman Game (MIWG) as a benchmark. All but one participant correctly identified the LLM, showing that one of today's most advanced LLMs is unable to pass a rigorous Turing Test. We conclude that recent extravagant claims for such models are unsupported, and do not warrant either optimism or concern about the social impact of thinking machines. 

**Abstract (ZH)**: 当前关于人工智能（AI）对人类社会带来的益处与风险所引发的热潮与焦虑周期，不仅受到公众日益增多地使用生成式AI和其他AI工具的影响，也被科技普及者和科学家们所做的相关宣称所推动。特别是，最近的研究声称大型语言模型（LLMs）可以通过图灵测试──自20世纪50年代以来AI领域的目标──因此被认为具有“思考”的能力。人们预测，这将对社会产生重大影响。然而，经过详细审查，这些研究中的任何一个都没有忠实执行图灵的原始指令。因此，我们使用GPT-4-Turbo进行了一个严格遵循图灵原始指令的三玩家模仿游戏，模拟图灵测试。我们遵循了图灵指令不明确或缺失时所建立的科学标准。例如，我们实施了一个计算机模仿人类的游戏（CIHG），没有限制时间，以及进行了一个男人模仿女人的游戏（MIWG）作为基准。几乎所有参与者都能正确识别出LLM，表明今天的最先进LLM无法通过严格的图灵测试。我们得出结论，近期对该类模型的夸张宣传缺乏依据，不应因为“思考机器”对社会影响的悲观或乐观情绪而产生过度关注。 

---
# VoicePrompter: Robust Zero-Shot Voice Conversion with Voice Prompt and Conditional Flow Matching 

**Title (ZH)**: VoicePrompter：基于语音提示和条件流匹配的鲁棒零-shot 语音转换 

**Authors**: Ha-Yeong Choi, Jaehan Park  

**Link**: [PDF](https://arxiv.org/pdf/2501.17612)  

**Abstract**: Despite remarkable advancements in recent voice conversion (VC) systems, enhancing speaker similarity in zero-shot scenarios remains challenging. This challenge arises from the difficulty of generalizing and adapting speaker characteristics in speech within zero-shot environments, which is further complicated by mismatch between the training and inference processes. To address these challenges, we propose VoicePrompter, a robust zero-shot VC model that leverages in-context learning with voice prompts. VoicePrompter is composed of (1) a factorization method that disentangles speech components and (2) a DiT-based conditional flow matching (CFM) decoder that conditions on these factorized features and voice prompts. Additionally, (3) latent mixup is used to enhance in-context learning by combining various speaker features. This approach improves speaker similarity and naturalness in zero-shot VC by applying mixup to latent representations. Experimental results demonstrate that VoicePrompter outperforms existing zero-shot VC systems in terms of speaker similarity, speech intelligibility, and audio quality. Our demo is available at \url{this https URL}. 

**Abstract (ZH)**: 尽管近年来语音转换（VC）系统取得了显著进步，但在零样本情景下增强说话人的一致性仍然具有挑战性。这种挑战源于在零样本环境中难以推广和适应语音中的说话人特征，并且训练过程和推断过程之间的不匹配加剧了这一挑战。为了解决这些挑战，我们提出了VoicePrompter，这是一种利用语音提示进行上下文学习的稳健零样本VC模型。VoicePrompter 由以下部分组成：（1）一种因子化方法，将语音成分分离；（2）一种基于DiT的条件流匹配（CFM）解码器，该解码器根据这些因子化特征和语音提示进行条件的概率建模。此外，（3）潜在Mixup 通过结合多种说话人特征来增强上下文学习。该方法通过将Mixup应用于潜在表示来提高零样本VC中的说话人一致性和自然度。实验结果表明，VoicePrompter 在说话人一致性、语音清晰度和音频质量方面优于现有的零样本VC系统。我们的演示可在 \url{此处提供链接} 获取。 

---
# CSEval: Towards Automated, Multi-Dimensional, and Reference-Free Counterspeech Evaluation using Auto-Calibrated LLMs 

**Title (ZH)**: CSEval：面向自动、多维度且无参考标准的反言评价系统，利用自校准的大语言模型 

**Authors**: Amey Hengle, Aswini Kumar, Anil Bandhakavi, Tanmoy Chakraborty  

**Link**: [PDF](https://arxiv.org/pdf/2501.17581)  

**Abstract**: Counterspeech has been popular as an effective approach to counter online hate speech, leading to increasing research interest in automated counterspeech generation using language models. However, this field lacks standardised evaluation protocols and robust automated evaluation metrics that align with human judgement. Current automatic evaluation methods, primarily based on similarity metrics, do not effectively capture the complex and independent attributes of counterspeech quality, such as contextual relevance, aggressiveness, or argumentative coherence. This has led to an increased dependency on labor-intensive human evaluations to assess automated counter-speech generation methods. To address these challenges, we introduce CSEval, a novel dataset and framework for evaluating counterspeech quality across four dimensions: contextual-relevance, aggressiveness, argument-coherence, and suitableness. Furthermore, we propose Auto-Calibrated COT for Counterspeech Evaluation (ACE), a prompt-based method with auto-calibrated chain-of-thoughts (CoT) for scoring counterspeech using large language models. Our experiments show that ACE outperforms traditional metrics like ROUGE, METEOR, and BertScore in correlating with human judgement, indicating a significant advancement in automated counterspeech evaluation. 

**Abstract (ZH)**: 以下是翻译成中文的内容，符合学术规范：

批评性言论作为一种有效的方法被广泛用于应对网络仇恨言论，这引发了对使用语言模型自动生成批评性言论的研究兴趣。然而，该领域缺乏标准化的评估协议和与人类判断相一致的稳健自动化评估指标。当前的自动评估方法主要基于相似度指标，无法有效捕捉批评性言论质量的复杂且独立的属性，如上下文相关性、攻击性或论辩一致性。这导致了对自动化批评性言论生成方法进行评估时需要更加依赖劳动密集型的人类评估。为了解决这些挑战，我们提出了CSEval，这是一种用于在上下文相关性、攻击性、论辩一致性以及适宜性四个维度上评估批评性言论质量的新颖数据集和框架。此外，我们还提出了一种基于提示的自动化校准思维链（Auto-Calibrated Chain-of-Thought, ACE）方法，用于使用大规模语言模型对批评性言论进行评分。我们的实验表明，ACE 在与人类判断相关性方面优于传统的ROUGE、METEOR和BertScore等度量指标，这表明在自动化批评性言论评估方面取得了显著进步。 

---
# Music2Latent2: Audio Compression with Summary Embeddings and Autoregressive Decoding 

**Title (ZH)**: Music2Latent2：使用摘要嵌入和自回归解码的音频压缩 

**Authors**: Marco Pasini, Stefan Lattner, George Fazekas  

**Link**: [PDF](https://arxiv.org/pdf/2501.17578)  

**Abstract**: Efficiently compressing high-dimensional audio signals into a compact and informative latent space is crucial for various tasks, including generative modeling and music information retrieval (MIR). Existing audio autoencoders, however, often struggle to achieve high compression ratios while preserving audio fidelity and facilitating efficient downstream applications. We introduce Music2Latent2, a novel audio autoencoder that addresses these limitations by leveraging consistency models and a novel approach to representation learning based on unordered latent embeddings, which we call summary embeddings. Unlike conventional methods that encode local audio features into ordered sequences, Music2Latent2 compresses audio signals into sets of summary embeddings, where each embedding can capture distinct global features of the input sample. This enables to achieve higher reconstruction quality at the same compression ratio. To handle arbitrary audio lengths, Music2Latent2 employs an autoregressive consistency model trained on two consecutive audio chunks with causal masking, ensuring coherent reconstruction across segment boundaries. Additionally, we propose a novel two-step decoding procedure that leverages the denoising capabilities of consistency models to further refine the generated audio at no additional cost. Our experiments demonstrate that Music2Latent2 outperforms existing continuous audio autoencoders regarding audio quality and performance on downstream tasks. Music2Latent2 paves the way for new possibilities in audio compression. 

**Abstract (ZH)**: 高效地将高维音频信号压缩到一个紧凑且具信息性的潜在空间对于各种任务（包括生成建模和音乐信息检索MIR）至关重要。然而，现有的音频自编码器往往难以在保持音频保真度的同时实现高压缩比，并且能够支持下游高效应用。本文介绍了一种名为Music2Latent2的新音频自编码器，它通过利用一致性模型和基于无序潜在嵌入的新型表示学习方法（我们称之为概要嵌入）来解决这些问题中的限制。与传统方法将局部音频特征编码成有序序列不同，Music2Latent2将音频信号压缩为一组概要嵌入，每个嵌入可以捕捉输入样本的不同全局特征。这在保持相同压缩比的情况下，可以实现更高的重构质量。为了处理任意长度的音频，Music2Latent2采用了一种自回归一致性模型，该模型在两个连续音频片段上进行训练，并以因果掩码确保在段边界处进行一致重构。此外，我们还提出了一种新的两步解码方法，利用一致性模型的去噪能力进一步细化生成的音频，而无需额外成本。实验结果表明，与现有的连续音频自编码器相比，Music2Latent2在音频质量和下游任务性能方面具有优势。Music2Latent2为音频压缩开辟了新的可能性。 

---
# Exploring the Potential of Wireless-enabled Multi-Chip AI Accelerators 

**Title (ZH)**: 探究无线 enabling 的多芯片 AI 加速器的潜力 

**Authors**: Emmanuel Irabor, Mariam Musavi, Abhijit Das, Sergi Abadal  

**Link**: [PDF](https://arxiv.org/pdf/2501.17567)  

**Abstract**: The insatiable appetite of Artificial Intelligence (AI) workloads for computing power is pushing the industry to develop faster and more efficient accelerators. The rigidity of custom hardware, however, conflicts with the need for scalable and versatile architectures capable of catering to the needs of the evolving and heterogeneous pool of Machine Learning (ML) models in the literature. In this context, multi-chiplet architectures assembling multiple (perhaps heterogeneous) accelerators are an appealing option that is unfortunately hindered by the still rigid and inefficient chip-to-chip interconnects. In this paper, we explore the potential of wireless technology as a complement to existing wired interconnects in this multi-chiplet approach. Using an evaluation framework from the state-of-the-art, we show that wireless interconnects can lead to speedups of 10% on average and 20% maximum. We also highlight the importance of load balancing between the wired and wireless interconnects, which will be further explored in future work. 

**Abstract (ZH)**: 以下是翻译成中文的论文内容或标题，符合学术规范：

人工智能（AI）工作负载对计算能力的无尽需求正在推进行业开发更快更高效的加速器。然而，自定义硬件的僵化与满足不断演化的异构机器学习（ML）模型需求的可扩展和多功能架构的需求相冲突。在这种背景下，结合多个（可能是异构的）加速器的多片上系统架构是一个有吸引力的选择，但由于片上系统之间的连接仍存在僵化和低效率的问题，这一选择受到了阻碍。本文探讨了无线技术作为现有有线连接的补充在多片上系统方法中的潜力。使用最新的评估框架，我们展示了无线连接在平均情况下可以带来高达10%的速度提升，在最坏情况下可以带来高达20%的速度提升。我们还强调了平衡有线和无线连接之间负载的重要性，这将在未来的研究中进一步探讨。 

---
# An Exceptional Dataset For Rare Pancreatic Tumor Segmentation 

**Title (ZH)**: 一种出色的Datasets，适用于罕见胰腺肿瘤分割 

**Authors**: Wenqi Li, Yingli Chen, Keyang Zhou, Xiaoxiao Hu, Zilu Zheng, Yue Yan, Xinpeng Zhang, Wei Tang, Zhenxing Qian  

**Link**: [PDF](https://arxiv.org/pdf/2501.17555)  

**Abstract**: Pancreatic NEuroendocrine Tumors (pNETs) are very rare endocrine neoplasms that account for less than 5% of all pancreatic malignancies, with an incidence of only 1-1.5 cases per 100,000. Early detection of pNETs is critical for improving patient survival, but the rarity of pNETs makes segmenting them from CT a very challenging problem. So far, there has not been a dataset specifically for pNETs available to researchers. To address this issue, we propose a pNETs dataset, a well-annotated Contrast-Enhanced Computed Tomography (CECT) dataset focused exclusively on Pancreatic Neuroendocrine Tumors, containing data from 469 patients. This is the first dataset solely dedicated to pNETs, distinguishing it from previous collections. Additionally, we provide the baseline detection networks with a new slice-wise weight loss function designed for the UNet-based model, improving the overall pNET segmentation performance. We hope that our dataset can enhance the understanding and diagnosis of pNET Tumors within the medical community, facilitate the development of more accurate diagnostic tools, and ultimately improve patient outcomes and advance the field of oncology. 

**Abstract (ZH)**: 胰腺神经内分泌肿瘤（pNETs）是一种极为罕见的内分泌肿瘤，仅占所有胰腺恶性肿瘤的不到5%，年发病率为每10万人中1-1.5例。早期检测pNETs对于提高患者生存率至关重要，但由于pNETs的罕见性，从CT图像中分割pNETs是一项极具挑战性的问题。迄今为止，研究人员尚未有专门针对pNETs的数据集。为解决这一问题，我们提出了一组pNETs数据集，这是一个专注于胰腺神经内分泌肿瘤的对比增强计算机断层扫描（CECT）数据集，并对469名患者的数据进行了详细标注。这是首个专门针对pNETs的数据集，与以往的数据集合形成了鲜明对比。此外，我们还提供了基于UNet模型的新切片权重损失函数，以提高pNET分割的整体性能。我们希望该数据集能够促进医学界对pNET肿瘤的理解和诊断，促进更准确诊断工具的开发，并最终改善患者预后，推动肿瘤学领域的发展。 

---
# Is Conversational XAI All You Need? Human-AI Decision Making With a Conversational XAI Assistant 

**Title (ZH)**: 对话式解释性人工智能足够吗？对话式解释性人工智能助手赋能的人机决策制定 

**Authors**: Gaole He, Nilay Aishwarya, Ujwal Gadiraju  

**Link**: [PDF](https://arxiv.org/pdf/2501.17546)  

**Abstract**: Explainable artificial intelligence (XAI) methods are being proposed to help interpret and understand how AI systems reach specific predictions. Inspired by prior work on conversational user interfaces, we argue that augmenting existing XAI methods with conversational user interfaces can increase user engagement and boost user understanding of the AI system. In this paper, we explored the impact of a conversational XAI interface on users' understanding of the AI system, their trust, and reliance on the AI system. In comparison to an XAI dashboard, we found that the conversational XAI interface can bring about a better understanding of the AI system among users and higher user trust. However, users of both the XAI dashboard and conversational XAI interfaces showed clear overreliance on the AI system. Enhanced conversations powered by large language model (LLM) agents amplified over-reliance. Based on our findings, we reason that the potential cause of such overreliance is the illusion of explanatory depth that is concomitant with both XAI interfaces. Our findings have important implications for designing effective conversational XAI interfaces to facilitate appropriate reliance and improve human-AI collaboration. Code can be found at this https URL 

**Abstract (ZH)**: 可解释的人工智能（XAI）方法正被提出，以帮助解释和理解人工智能系统是如何作出特定预测的。受先前关于对话式用户界面研究的启发，我们主张将对话式用户界面与现有的XAI方法结合，可以增加用户参与度并提升用户对人工智能系统的理解。在本文中，我们探讨了对话式XAI界面对用户理解人工智能系统、信任以及依赖程度的影响。与传统的XAI仪表板相比，我们发现对话式XAI界面能更好地帮助用户理解人工智能系统，并增加用户对人工智能系统的信任。然而，无论是使用XAI仪表板还是对话式XAI界面的用户都表现出对人工智能系统的过度依赖，而由大规模语言模型（LLM）代理支持的增强对话进一步加剧了这种过度依赖。基于我们的发现，我们推测导致这种过度依赖的原因与两种XAI界面都伴随的解释深度错觉有关。我们的研究结果对设计促进适当依赖并改进人类-人工智能协作的对话式XAI界面具有重要启示意义。代码可在以下链接找到：[提供链接] 

---
# RegD: Hierarchical Embeddings via Distances over Geometric Regions 

**Title (ZH)**: RegD：基于几何区域距离的层次嵌入 

**Authors**: Hui Yang, Jiaoyan Chen  

**Link**: [PDF](https://arxiv.org/pdf/2501.17518)  

**Abstract**: Hierarchical data are common in many domains like life sciences and e-commerce, and their embeddings often play a critical role. Although hyperbolic embeddings offer a grounded approach to representing hierarchical structures in low-dimensional spaces, their utility is hindered by optimization difficulties in hyperbolic space and dependence on handcrafted structural constraints. We propose RegD, a novel Euclidean framework that addresses these limitations by representing hierarchical data as geometric regions with two new metrics: (1) depth distance, which preserves the representational power of hyperbolic spaces for hierarchical data, and (2) boundary distance, which explicitly encodes set-inclusion relationships between regions in a general way. Our empirical evaluation on diverse real-world datasets shows consistent performance gains over state-of-the-art methods and demonstrates RegD's potential for broader applications beyond hierarchy alone tasks. 

**Abstract (ZH)**: 层次数据在生命科学、电子商务等领域非常常见，并且它们的嵌入往往至关重要。尽管超球面嵌入为在低维空间中表示层次结构提供了一种实用的方法，但其价值受到超球面优化困难和依赖手工设计的结构约束的限制。我们提出了一种新颖的欧几里得框架 RegD，以通过提出两种新的度量来解决这些局限性，即层次数据的几何区域表示方法：(1) 深度距离，这种度量保留了超球面空间对层次数据的表示能力；(2) 边界距离，这种度量以一般化的方式显式地编码了区域之间的集合包涵关系。我们在多样化的实际数据集上的实证评估表明，RegD 在各种任务中均优于现有最先进的方法，并展示了其超越单纯层次结构任务的广泛应用潜力。 

---
# LLM Assistance for Pediatric Depression 

**Title (ZH)**: 儿童抑郁症中大语言模型的辅助作用 

**Authors**: Mariia Ignashina, Paulina Bondaronek, Dan Santel, John Pestian, Julia Ive  

**Link**: [PDF](https://arxiv.org/pdf/2501.17510)  

**Abstract**: Traditional depression screening methods, such as the PHQ-9, are particularly challenging for children in pediatric primary care due to practical limitations. AI has the potential to help, but the scarcity of annotated datasets in mental health, combined with the computational costs of training, highlights the need for efficient, zero-shot approaches. In this work, we investigate the feasibility of state-of-the-art LLMs for depressive symptom extraction in pediatric settings (ages 6-24). This approach aims to complement traditional screening and minimize diagnostic errors.
Our findings show that all LLMs are 60% more efficient than word match, with Flan leading in precision (average F1: 0.65, precision: 0.78), excelling in the extraction of more rare symptoms like "sleep problems" (F1: 0.92) and "self-loathing" (F1: 0.8). Phi strikes a balance between precision (0.44) and recall (0.60), performing well in categories like "Feeling depressed" (0.69) and "Weight change" (0.78). Llama 3, with the highest recall (0.90), overgeneralizes symptoms, making it less suitable for this type of analysis. Challenges include the complexity of clinical notes and overgeneralization from PHQ-9 scores. The main challenges faced by LLMs include navigating the complex structure of clinical notes with content from different times in the patient trajectory, as well as misinterpreting elevated PHQ-9 scores.
We finally demonstrate the utility of symptom annotations provided by Flan as features in an ML algorithm, which differentiates depression cases from controls with high precision of 0.78, showing a major performance boost compared to a baseline that does not use these features. 

**Abstract (ZH)**: 传统的抑郁筛查方法，如PHQ-9量表，在儿科初级保健中特别具有挑战性，原因在于其实用限制。人工智能有潜力提供帮助，但心理健康领域标注数据的稀缺性，以及训练所需的巨大计算成本，凸显了需要高效且无需微调的方法的必要性。在本研究中，我们探讨了先进语言模型（LLMs）在儿科环境下的抑郁症状提取可行性（年龄范围为6-24岁），旨在补充传统筛查方法并减少诊断错误。

我们发现，所有LLM相比简单词匹配方法效率高出60%，Flan在这方面表现出色，其平均F1分数为0.65，精度为0.78，对罕见症状如“睡眠问题”（F1: 0.92）、“自我厌恶”（F1: 0.8）等的提取尤为有效。Phi在保持较高的精度（0.44）和召回率（0.60）的同时，在“感到抑郁”（0.69）和“体重变化”（0.78）等分类中表现出色。Llama3由于其最高的召回率（0.90）而倾向于过度概括症状，这使其在此类分析中不太适用。挑战包括病历记录的复杂性和PHQ-9分数的过度概括。LLM面临的主要挑战包括在患者病程中不同时间点的内容复杂结构的导航问题，以及对PHQ-9分数升高的错误解读。

我们最终展示了Flan提供的症状标注作为机器学习算法特征的实用性。这种方法在区分抑郁病例和对照组时具有高精度（0.78），相较于不使用这些特征的基线模型，表现出显著的性能提升。 

---
# Neural Spelling: A Spell-Based BCI System for Language Neural Decoding 

**Title (ZH)**: 神经拼写：基于拼写的BCI语言神经解码系统 

**Authors**: Xiaowei Jiang, Charles Zhou, Yiqun Duan, Ziyi Zhao, Thomas Do, Chin-Teng Lin  

**Link**: [PDF](https://arxiv.org/pdf/2501.17489)  

**Abstract**: Brain-computer interfaces (BCIs) present a promising avenue by translating neural activity directly into text, eliminating the need for physical actions. However, existing non-invasive BCI systems have not successfully covered the entire alphabet, limiting their practicality. In this paper, we propose a novel non-invasive EEG-based BCI system with Curriculum-based Neural Spelling Framework, which recognizes all 26 alphabet letters by decoding neural signals associated with handwriting first, and then apply a Generative AI (GenAI) to enhance spell-based neural language decoding tasks. Our approach combines the ease of handwriting with the accessibility of EEG technology, utilizing advanced neural decoding algorithms and pre-trained large language models (LLMs) to translate EEG patterns into text with high accuracy. This system show how GenAI can improve the performance of typical spelling-based neural language decoding task, and addresses the limitations of previous methods, offering a scalable and user-friendly solution for individuals with communication impairments, thereby enhancing inclusive communication options. 

**Abstract (ZH)**: 脑-机接口（BCIs）提供了一种有前途的途径，能够直接将神经活动转换为文本，从而消除对物理动作的需求。然而，现有的非侵入性BCI系统未能覆盖整个字母表，限制了其实用性。在本文中，我们提出了一种基于梯度学习的非侵入性脑电图（EEG）BCI系统，该系统首先通过解码与书写相关的神经信号来识别所有26个字母，然后利用生成人工智能（GenAI）增强基于拼写的神经语言解码任务。我们的方法结合了书写的优势和EEG技术的便利性，利用先进的神经解码算法和预训练的大语言模型（LLMs）将EEG模式高精度地转换为文本。该系统展示了GenAI如何提高典型基于拼写的神经语言解码任务的性能，并解决了先前方法的局限性，为沟通障碍的个体提供了一种可扩展且用户友好的解决方案，从而增强了包容性的沟通选项。 

---
# DINT Transformer 

**Title (ZH)**: "DINT 变量变换器"

注释：DINT在这里可能是特定论文或研究中的缩写，没有直接对应的学术术语。因此，我基于“Transformer”一词进行了翻译，并在后面补充了“变量变换器”来尽可能贴近原文的意思。如果DINT在特定上下文中具有特定含义，建议根据具体含义进行翻译或解释。 

**Authors**: Yueyang Cang, Yuhang Liu, Xiaoteng Zhang, Erlu Zhao, Li Shi  

**Link**: [PDF](https://arxiv.org/pdf/2501.17486)  

**Abstract**: DIFF Transformer addresses the issue of irrelevant context interference by introducing a differential attention mechanism that enhances the robustness of local attention. However, it has two critical limitations: the lack of global context modeling, which is essential for identifying globally significant tokens, and numerical instability due to the absence of strict row normalization in the attention matrix. To overcome these challenges, we propose DINT Transformer, which extends DIFF Transformer by incorporating a differential-integral mechanism. By computing global importance scores and integrating them into the attention matrix, DINT Transformer improves its ability to capture global dependencies. Moreover, the unified parameter design enforces row-normalized attention matrices, improving numerical stability. Experimental results demonstrate that DINT Transformer excels in accuracy and robustness across various practical applications, such as long-context language modeling and key information retrieval. These results position DINT Transformer as a highly effective and promising architecture. 

**Abstract (ZH)**: DIFF Transformer通过引入差异性注意力机制，增强了局部注意力的鲁棒性，从而解决了无关上下文干扰的问题。然而，它存在两个关键限制：缺乏全局上下文建模，这对于识别全局重要词至关重要；以及由于注意力矩阵中缺少严格的行归一化而导致的数值不稳定性。为克服这些挑战，我们提出了一种DINT Transformer，其扩展了DIFF Transformer，通过引入差异-积分机制。通过计算全局重要性得分并将其整合到注意力矩阵中，DINT Transformer提高了捕获全局依赖的能力。此外，统一的参数设计确保了注意力矩阵的行归一化，从而提高了数值稳定性。实验结果表明，DINT Transformer在长上下文语言建模和关键信息检索等多种实际应用中表现出色且鲁棒性更强。这些结果使DINT Transformer成为一种高效且有前途的架构。 

---
# DFPE: A Diverse Fingerprint Ensemble for Enhancing LLM Performance 

**Title (ZH)**: DFPE: 一种多样化的指纹ensemble方法以提升大型语言模型性能 

**Authors**: Seffi Cohen, Niv Goldshlager, Nurit Cohen-Inger, Bracha Shapira, Lior Rokach  

**Link**: [PDF](https://arxiv.org/pdf/2501.17479)  

**Abstract**: Large Language Models (LLMs) have shown remarkable capabilities across various natural language processing tasks but often struggle to excel uniformly in diverse or complex domains. We propose a novel ensemble method - Diverse Fingerprint Ensemble (DFPE), which leverages the complementary strengths of multiple LLMs to achieve more robust performance. Our approach involves: (1) clustering models based on response "fingerprints" patterns, (2) applying a quantile-based filtering mechanism to remove underperforming models at a per-subject level, and (3) assigning adaptive weights to remaining models based on their subject-wise validation accuracy. In experiments on the Massive Multitask Language Understanding (MMLU) benchmark, DFPE outperforms the best single model by 3% overall accuracy and 5% in discipline-level accuracy. This method increases the robustness and generalization of LLMs and underscores how model selection, diversity preservation, and performance-driven weighting can effectively address challenging, multi-faceted language understanding tasks. 

**Abstract (ZH)**: 大型语言模型（LLMs）在各种自然语言处理任务中展现出了显著的能力，但往往难以在多变或复杂的领域中均表现出色。我们提出了一种新颖的集成方法——多样指纹集成（DFPE），该方法通过利用多种LLM的互补优势以实现更稳健的性能。我们的方法包括以下步骤：（1）基于响应“指纹”模式对模型进行聚类；（2）应用基于分位数的筛选机制，在每个主题级别去除表现不佳的模型；（3）根据模型在各个主题上的验证准确性为其分配自适应权重。在大规模多任务语言理解（MMLU）基准测试中，DFPE在总体准确性和学科水平准确率上分别比最佳单一模型高出3%和5%。该方法提高了LLMs的稳健性和泛化能力，并强调了模型选择、多样性保留和基于性能加权在应对复杂多面的语言理解任务中的有效性。 

---
# Towards Making Flowchart Images Machine Interpretable 

**Title (ZH)**: 向使流程图图像变得机器可解析方向努力 

**Authors**: Shreya Shukla, Prajwal Gatti, Yogesh Kumar, Vikash Yadav, Anand Mishra  

**Link**: [PDF](https://arxiv.org/pdf/2501.17441)  

**Abstract**: Computer programming textbooks and software documentations often contain flowcharts to illustrate the flow of an algorithm or procedure. Modern OCR engines often tag these flowcharts as graphics and ignore them in further processing. In this paper, we work towards making flowchart images machine-interpretable by converting them to executable Python codes. To this end, inspired by the recent success in natural language to code generation literature, we present a novel transformer-based framework, namely FloCo-T5. Our model is well-suited for this task,as it can effectively learn semantics, structure, and patterns of programming languages, which it leverages to generate syntactically correct code. We also used a task-specific pre-training objective to pre-train FloCo-T5 using a large number of logic-preserving augmented code samples. Further, to perform a rigorous study of this problem, we introduce theFloCo dataset that contains 11,884 flowchart images and their corresponding Python codes. Our experiments show promising results, and FloCo-T5 clearly outperforms related competitive baselines on code generation metrics. We make our dataset and implementation publicly available. 

**Abstract (ZH)**: 计算机编程教材和软件文档中常包含流程图，以展示算法或过程的流程。现代OCR引擎通常将这些流程图识别为图形，并在后续处理中忽略它们。本文旨在通过将流程图图像转换为可执行的Python代码，使这些图像对机器变得可解释。为此，借鉴自然语言到代码生成领域的最新研究成果，我们提出了一种新颖的Transformer基座框架，即FloCo-T5。我们的模型非常适合此任务，因为它能够有效地学习编程语言的语义、结构和模式，并利用这些知识生成语法正确的代码。此外，我们还使用了一个任务特定的预训练目标，通过大量保留逻辑的代码增强样本对FloCo-T5进行了预训练。进一步地，为了对这个问题进行严格的探讨，我们引入了FloCo数据集，该数据集包含11,884个流程图图像及其对应的Python代码。我们的实验显示了有希望的结果，且FloCo-T5在代码生成指标上明显优于相关竞争基准。我们已将数据集和实现代码公开发布。 

---
# Virus: Harmful Fine-tuning Attack for Large Language Models Bypassing Guardrail Moderation 

**Title (ZH)**: 病毒：绕过护栏调节的有害微调攻击大型语言模型 

**Authors**: Tiansheng Huang, Sihao Hu, Fatih Ilhan, Selim Furkan Tekin, Ling Liu  

**Link**: [PDF](https://arxiv.org/pdf/2501.17433)  

**Abstract**: Recent research shows that Large Language Models (LLMs) are vulnerable to harmful fine-tuning attacks -- models lose their safety alignment ability after fine-tuning on a few harmful samples. For risk mitigation, a guardrail is typically used to filter out harmful samples before fine-tuning. By designing a new red-teaming method, we in this paper show that purely relying on the moderation guardrail for data filtration is not reliable. Our proposed attack method, dubbed Virus, easily bypasses the guardrail moderation by slightly modifying the harmful data. Experimental results show that the harmful data optimized by Virus is not detectable by the guardrail with up to 100\% leakage ratio, and can simultaneously achieve superior attack performance. Finally, the key message we want to convey through this paper is that: \textbf{it is reckless to consider guardrail moderation as a clutch at straws towards harmful fine-tuning attack}, as it cannot solve the inherent safety issue of the pre-trained LLMs. Our code is available at this https URL 

**Abstract (ZH)**: 最近的研究表明，大型语言模型（LLMs）对有害微调攻击非常脆弱——在少量有害样本上进行微调后，模型会丧失其安全性对齐的能力。为降低风险，通常会使用一个防护栏来过滤掉有害样本，然后再进行微调。通过设计一个新的红队方法，我们在这篇文章中表明，单纯依赖防护栏来进行数据过滤并不可靠。我们提出了一种名为“病毒”的攻击方法，通过稍微修改有害数据，可以轻松绕过防护栏的过滤。实验结果表明，“病毒”优化的有害数据能够在高达100%的泄露率下逃过防护栏的检测，并同时实现优异的攻击效果。最后，本文的关键信息是：**将防护栏过滤视为应对有害微调攻击的最后一根稻草是不负责任的**，因为它无法解决预训练LLMs固有的安全问题。我们的代码托管在以下链接： 

[此链接](this https URL) 

---
# Algorithmic Segmentation and Behavioral Profiling for Ransomware Detection Using Temporal-Correlation Graphs 

**Title (ZH)**: 使用时间相关图形进行勒索软件检测的算法分割与行为建模 

**Authors**: Ignatius Rollere, Caspian Hartsfield, Seraphina Courtenay, Lucian Fenwick, Aurelia Grunwald  

**Link**: [PDF](https://arxiv.org/pdf/2501.17429)  

**Abstract**: The rapid evolution of cyber threats has outpaced traditional detection methodologies, necessitating innovative approaches capable of addressing the adaptive and complex behaviors of modern adversaries. A novel framework was introduced, leveraging Temporal-Correlation Graphs to model the intricate relationships and temporal patterns inherent in malicious operations. The approach dynamically captured behavioral anomalies, offering a robust mechanism for distinguishing between benign and malicious activities in real-time scenarios. Extensive experiments demonstrated the framework's effectiveness across diverse ransomware families, with consistently high precision, recall, and overall detection accuracy. Comparative evaluations highlighted its better performance over traditional signature-based and heuristic methods, particularly in handling polymorphic and previously unseen ransomware variants. The architecture was designed with scalability and modularity in mind, ensuring compatibility with enterprise-scale environments while maintaining resource efficiency. Analysis of encryption speeds, anomaly patterns, and temporal correlations provided deeper insights into the operational strategies of ransomware, validating the framework's adaptability to evolving threats. The research contributes to advancing cybersecurity technologies by integrating dynamic graph analytics and machine learning for future innovations in threat detection. Results from this study underline the potential for transforming the way organizations detect and mitigate complex cyberattacks. 

**Abstract (ZH)**: 网络威胁的快速演变已经超越了传统检测方法的能力范围，因此需要创新的方法来应对现代对手具有适应性和复杂性的行为。我们引入了一种新的框架，利用时序关联图（Temporal-Correlation Graphs）来建模恶意操作中内在的复杂关系和时间模式。该方法动态捕捉行为异常，提供了一种在实时场景中区分良性与恶意活动的强大机制。广泛实验表明，该框架在多种勒索软件家族中表现出色，具有很高的精确率、召回率和总体检测精度。相比之下，其性能优于传统基于签名和启发式方法，特别是在处理多态性和之前未见过的勒索软件变种方面表现更佳。该架构设计注重可扩展性和模块性，确保其与企业规模环境兼容，同时保持资源效率。通过对加密速度、异常模式和时间关联的分析，我们获得了关于勒索软件运营策略的更深入见解，验证了该框架对不断演化的威胁具有适应性。这项研究通过将动态图分析和机器学习相结合，推动了网络安全技术的发展，为未来威胁检测创新做出了贡献。研究结果强调了该方法在组织检测和抵御复杂网络攻击中的潜力。 

---
# Actions Speak Louder than Words: Agent Decisions Reveal Implicit Biases in Language Models 

**Title (ZH)**: 行动胜于言语：代理决策揭示语言模型中的隐性偏见 

**Authors**: Yuxuan Li, Hirokazu Shirado, Sauvik Das  

**Link**: [PDF](https://arxiv.org/pdf/2501.17420)  

**Abstract**: While advances in fairness and alignment have helped mitigate overt biases exhibited by large language models (LLMs) when explicitly prompted, we hypothesize that these models may still exhibit implicit biases when simulating human behavior. To test this hypothesis, we propose a technique to systematically uncover such biases across a broad range of sociodemographic categories by assessing decision-making disparities among agents with LLM-generated, sociodemographically-informed personas. Using our technique, we tested six LLMs across three sociodemographic groups and four decision-making scenarios. Our results show that state-of-the-art LLMs exhibit significant sociodemographic disparities in nearly all simulations, with more advanced models exhibiting greater implicit biases despite reducing explicit biases. Furthermore, when comparing our findings to real-world disparities reported in empirical studies, we find that the biases we uncovered are directionally aligned but markedly amplified. This directional alignment highlights the utility of our technique in uncovering systematic biases in LLMs rather than random variations; moreover, the presence and amplification of implicit biases emphasizes the need for novel strategies to address these biases. 

**Abstract (ZH)**: 尽管在公平性和对齐性方面的进步有助于减少大型语言模型（LLM）在明确提示下表现出的显性偏见，我们假设这些模型在模拟人类行为时仍可能表现出隐性偏见。为了检验这一假设，我们提出了一种技术，通过评估由LLM生成且具有社会人口信息的人格所驱动的决策差异，系统地揭示这些偏见，覆盖广泛的社会人口分类。利用这种方法，我们对六个LLM在三个社会人口群体和四个决策情景中的表现进行了测试。结果显示，最先进的LLM在几乎所有的模拟中均表现出显著的社会人口差异，且更先进的模型尽管减少了显性偏见，但其隐性偏见更为显著。此外，将我们发现的偏见与现实世界中由实证研究报道的差异进行比较，我们发现我们揭示的偏见方向上一致，但得到显著放大。这种方向性的一致性突显了我们技术在揭示LLM中的系统性偏见而非随机变异性方面的用途；同时，隐性偏见的存在及其放大强调了需要采用新的策略来解决这些问题。 

---
# Reqo: A Robust and Explainable Query Optimization Cost Model 

**Title (ZH)**: Reqo：一种 robust 和可解释的查询优化成本模型 

**Authors**: Baoming Chang, Amin Kamali, Verena Kantere  

**Link**: [PDF](https://arxiv.org/pdf/2501.17414)  

**Abstract**: In recent years, there has been a growing interest in using machine learning (ML) in query optimization to select more efficient plans. Existing learning-based query optimizers use certain model architectures to convert tree-structured query plans into representations suitable for downstream ML tasks. As the design of these architectures significantly impacts cost estimation, we propose a tree model architecture based on Bidirectional Graph Neural Networks (Bi-GNN) aggregated by Gated Recurrent Units (GRUs) to achieve more accurate cost estimates. The inherent uncertainty of data and model parameters also leads to inaccurate cost estimates, resulting in suboptimal plans and less robust query performance. To address this, we implement a novel learning-to-rank cost model that effectively quantifies the uncertainty in cost estimates using approximate probabilistic ML. This model adaptively integrates quantified uncertainty with estimated costs and learns from comparing pairwise plans, achieving more robust performance. In addition, we propose the first explainability technique specifically designed for learning-based cost models. This technique explains the contribution of any subgraphs in the query plan to the final predicted cost, which can be integrated and trained with any learning-based cost model to significantly boost the model's explainability. By incorporating these innovations, we propose a cost model for a Robust and Explainable Query Optimizer, Reqo, that improves the accuracy, robustness, and explainability of cost estimation, outperforming state-of-the-art approaches in all three dimensions. 

**Abstract (ZH)**: 近年来，对在查询优化中使用机器学习（ML）以选择更高效的计划产生了越来越大的兴趣。现有的基于学习的查询优化器利用特定的模型结构将树状查询计划转换为适合下游ML任务的表示。这些模型结构的设计显著影响成本估算。为此，我们提出了一种基于门控循环单元（GRUs）聚合的双向图神经网络（Bi-GNN）的树模型架构，以实现更准确的成本估算。数据和模型参数的固有不确定性也导致成本估算不准确，从而产生次优计划和较低的查询性能。为了解决这一问题，我们实现了一种新的学习排序成本模型，该模型能够有效地量化成本估算的不确定性，使用近似概率ML进行建模。该模型能够自适应地将量化不确定性与估算成本结合，并通过比较成对的计划进行学习，从而实现更高的性能稳健性。此外，我们还提出了第一种专门为基于学习的成本模型设计的解释性技术。该技术解释了查询计划中任何子图对最终预测成本的贡献，并可以与任何基于学习的成本模型结合和训练，以显著提高模型的解释性。通过结合这些创新，我们提出了一种成本模型，用于稳健且具有解释性的查询优化器（Reqo），该模型在准确度、稳健性和解释性方面均优于现有的最先进的方法。 

---
# A Genetic Algorithm-Based Approach for Automated Optimization of Kolmogorov-Arnold Networks in Classification Tasks 

**Title (ZH)**: 基于遗传算法的方法在分类任务中自动优化柯尔莫哥洛夫-阿诺尔德网络 

**Authors**: Quan Long, Bin Wang, Bing Xue, Mengjie Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2501.17411)  

**Abstract**: To address the issue of interpretability in multilayer perceptrons (MLPs), Kolmogorov-Arnold Networks (KANs) are introduced in 2024. However, optimizing KAN structures is labor-intensive, typically requiring manual intervention and parameter tuning. This paper proposes GA-KAN, a genetic algorithm-based approach that automates the optimization of KANs, requiring no human intervention in the design process. To the best of our knowledge, this is the first time that evolutionary computation is explored to optimize KANs automatically. Furthermore, inspired by the use of sparse connectivity in MLPs in effectively reducing the number of parameters, GA-KAN further explores sparse connectivity to tackle the challenge of extensive parameter spaces in KANs. GA-KAN is validated on two toy datasets, achieving optimal results without the manual tuning required by the original KAN. Additionally, GA-KAN demonstrates superior performance across five classification datasets, outperforming traditional methods on all datasets and providing interpretable symbolic formulae for the Wine and Iris datasets, thereby enhancing model transparency. Furthermore, GA-KAN significantly reduces the number of parameters over the standard KAN across all the five datasets. The core contributions of GA-KAN include automated optimization, a new encoding strategy, and a new decoding process, which together improve the accuracy and interpretability, and reduce the number of parameters. 

**Abstract (ZH)**: 为了应对多层感知机（MLPs）可解释性方面的挑战，2024年引入了柯尔莫哥洛夫-阿诺尔德网络（KANs）。然而，优化KAN结构通常需要大量的人工干预和参数调优。本文提出了一种基于遗传算法（GA-KAN）的方法，该方法能够自动优化KAN结构，完全不需要人类在设计过程中的干预。据我们所知，这是首次尝试使用进化计算自动优化KAN结构。此外，受MLPs中稀疏连接能够有效减少参数数量的启发，GA-KAN进一步探索了KAN中稀疏连接的应用，以应对KAN参数空间广泛的挑战。GA-KAN在两个玩具数据集上进行了验证，取得了在无需手动调优的情况下达到最佳结果的效果。此外，GA-KAN在五个分类数据集上表现出优越的性能，在所有数据集中均超过了传统的方法，并且为Wine和Iris数据集提供了可解释的符号公式，从而提高了模型的透明度。GA-KAN还在所有五个数据集中显著减少了KAN的标准参数数量。GA-KAN的核心贡献包括自动化优化、一种新的编码策略和一种新的解码过程，这些一起提高了精度和可解释性，并减少了参数的数量。 

---
# General Scene Adaptation for Vision-and-Language Navigation 

**Title (ZH)**: 视觉语言导航的一般场景适应 

**Authors**: Haodong Hong, Yanyuan Qiao, Sen Wang, Jiajun Liu, Qi Wu  

**Link**: [PDF](https://arxiv.org/pdf/2501.17403)  

**Abstract**: Vision-and-Language Navigation (VLN) tasks mainly evaluate agents based on one-time execution of individual instructions across multiple environments, aiming to develop agents capable of functioning in any environment in a zero-shot manner. However, real-world navigation robots often operate in persistent environments with relatively consistent physical layouts, visual observations, and language styles from instructors. Such a gap in the task setting presents an opportunity to improve VLN agents by incorporating continuous adaptation to specific environments. To better reflect these real-world conditions, we introduce GSA-VLN, a novel task requiring agents to execute navigation instructions within a specific scene and simultaneously adapt to it for improved performance over time. To evaluate the proposed task, one has to address two challenges in existing VLN datasets: the lack of OOD data, and the limited number and style diversity of instructions for each scene. Therefore, we propose a new dataset, GSA-R2R, which significantly expands the diversity and quantity of environments and instructions for the R2R dataset to evaluate agent adaptability in both ID and OOD contexts. Furthermore, we design a three-stage instruction orchestration pipeline that leverages LLMs to refine speaker-generated instructions and apply role-playing techniques to rephrase instructions into different speaking styles. This is motivated by the observation that each individual user often has consistent signatures or preferences in their instructions. We conducted extensive experiments on GSA-R2R to thoroughly evaluate our dataset and benchmark various methods. Based on our findings, we propose a novel method, GR-DUET, which incorporates memory-based navigation graphs with an environment-specific training strategy, achieving state-of-the-art results on all GSA-R2R splits. 

**Abstract (ZH)**: 视觉与语言导航（VLN）任务主要基于一次执行多个环境中的单个指令来评估代理，旨在开发能够在任何环境中零样本工作的代理。然而，实际导航机器人通常在物理布局相对一致、视觉观察和教员语言风格相对一致的持久环境中运行。这种任务设置上的差距为通过持续适应特定环境来提升VLN代理提供了机会。为了更好地反映这些实际情况，我们引入了GSA-VLN，这是一种新的任务，要求代理在特定场景中执行导航指令并同时适应该场景，以随着时间的推移提高性能。为了评估提出的任务，必须解决现有VLN数据集中两个挑战：缺乏OOD数据，以及每个场景下的指令数量和风格多样性有限。因此，我们提出了一组新的数据集GSA-R2R，它显著扩展了环境和指令的多样性和数量，以评估代理在ID和OOD情境下的适应能力。此外，我们设计了一个三阶段指令协调管道，利用大语言模型（LLM）来精炼讲者生成的指令，并通过角色扮演技术将指令重新表述为不同的说话风格。这一设计动机源自观察到每个用户往往在其指令中有一致的签名或偏好。我们在GSA-R2R上进行了广泛的实验，以彻底评估我们的数据集并基准测试各种方法。基于我们的发现，我们提出了一种新的方法GR-DUET，它结合了基于记忆的导航图与环境特定的训练策略，实现了GSA-R2R所有分割上的最新成果。 

---
# MultiChallenge: A Realistic Multi-Turn Conversation Evaluation Benchmark Challenging to Frontier LLMs 

**Title (ZH)**: MultiChallenge：一个挑战前沿大规模语言模型的现实多重轮次对话评估基准 

**Authors**: Ved Sirdeshmukh, Kaustubh Deshpande, Johannes Mols, Lifeng Jin, Ed-Yeremai Cardona, Dean Lee, Jeremy Kritz, Willow Primack, Summer Yue, Chen Xing  

**Link**: [PDF](https://arxiv.org/pdf/2501.17399)  

**Abstract**: We present MultiChallenge, a pioneering benchmark evaluating large language models (LLMs) on conducting multi-turn conversations with human users, a crucial yet underexamined capability for their applications. MultiChallenge identifies four categories of challenges in multi-turn conversations that are not only common and realistic among current human-LLM interactions, but are also challenging to all current frontier LLMs. All 4 challenges require accurate instruction-following, context allocation, and in-context reasoning at the same time. We also develop LLM as judge with instance-level rubrics to facilitate an automatic evaluation method with fair agreement with experienced human raters. Despite achieving near-perfect scores on existing multi-turn evaluation benchmarks, all frontier models have less than 50% accuracy on MultiChallenge, with the top-performing Claude 3.5 Sonnet (June 2024) achieving just a 41.4% average accuracy. 

**Abstract (ZH)**: 我们提出了MultiChallenge，这是一个开创性的基准测试，用于评估大规模语言模型（LLMs）在与人类用户进行多轮对话的能力。这种能力对于LLM的应用至关重要，但却未被充分检验。MultiChallenge 确定了四种多轮对话中的挑战类别，这些挑战不仅在当前的人类-LLM 交互中普遍且具有现实性，同时也对所有当前的前沿LLM构成挑战。所有四种挑战均要求模型同时具备精确的指令跟随、上下文管理以及情境推理能力。此外，我们还开发了基于实例级别的评判标准，使评估方法自动化，并保持与经验丰富的手动评分者间的一致性。尽管所有前沿模型在现有的多轮对话评估基准测试中得分接近满分，但在 MultiChallenge 中的准确率却低于50%，表现最好的Claude 3.5 Sonnet（2024年6月版本）的平均准确率仅为41.4%。 

---
# Learning Free Token Reduction for Multi-Modal LLM 

**Title (ZH)**: 基于学习的自由 Tokens 减少技术在多模态大语言模型中的应用 

**Authors**: Zihui Zhao, Yingxin Li, Yang Li  

**Link**: [PDF](https://arxiv.org/pdf/2501.17391)  

**Abstract**: Vision-Language Models (VLMs) have achieved remarkable success across a range of multimodal tasks; however, their practical deployment is often constrained by high computational costs and prolonged inference times. Since the vision modality typically carries more information than the text modality, compressing visual prompts offers a promising solution to alleviate these challenges. Existing approaches predominantly focus on refining model architectures or directly reducing the number of visual tokens. However, these methods often compromise inference performance due to a lack of consideration for the unique spatial and temporal characteristics of visual data. In this work, we propose a token compression paradigm that operates on both spatial and temporal dimensions. Our approach includes a learning-free, plug-and-play compression pipeline that can be seamlessly integrated into most Multimodal Large Language Model (MLLM) frameworks. By leveraging this method, we enhance the model inference capability while simultaneously reducing its computational cost. Experimental results on the Video-QA task demonstrate the effectiveness of the proposed approach, showcasing significant improvements in efficiency without sacrificing performance. 

**Abstract (ZH)**: 视觉-语言模型（VLMs）在多种多模态任务中取得了显著的成功；然而，它们的实际部署常常受到高计算成本和长推断时间的限制。由于视觉模态通常携带比文本模态更多的信息，压缩视觉提示为缓解这些挑战提供了一种有前途的解决方案。现有的方法主要集中在改进模型架构或直接减少视觉标记的数量。然而，这些方法往往会因不考虑视觉数据的独特空间和时间特性而牺牲推断性能。在本工作中，我们提出了一种在空间和时间维度上同时操作的令牌压缩范式。我们的方法包括一个无需学习、插即用的压缩流水线，可以无缝集成到大多数多模态大型语言模型（MLLM）框架中。通过利用该方法，我们在降低计算成本的同时增强了模型的推断能力。实验结果表明，本方法在视频问答（Video-QA）任务上具有显著的效果，展示了在不牺牲性能的情况下大幅提升效率的能力。 

---
# Context-Aware Semantic Recomposition Mechanism for Large Language Models 

**Title (ZH)**: 面向上下文的语义重组机制用于大型语言模型 

**Authors**: Richard Katrix, Quentin Carroway, Rowan Hawkesbury, Matthias Heathfield  

**Link**: [PDF](https://arxiv.org/pdf/2501.17386)  

**Abstract**: Context-aware processing mechanisms have increasingly become a critical area of exploration for improving the semantic and contextual capabilities of language generation models. The Context-Aware Semantic Recomposition Mechanism (CASRM) was introduced as a novel framework designed to address limitations in coherence, contextual adaptability, and error propagation in large-scale text generation tasks. Through the integration of dynamically generated context vectors and attention modulation layers, CASRM enhances the alignment between token-level representations and broader contextual dependencies. Experimental evaluations demonstrated significant improvements in semantic coherence across multiple domains, including technical, conversational, and narrative text. The ability to adapt to unseen domains and ambiguous inputs was evaluated using a diverse set of test scenarios, highlighting the robustness of the proposed mechanism. A detailed computational analysis revealed that while CASRM introduces additional processing overhead, the gains in linguistic precision and contextual relevance outweigh the marginal increase in complexity. The framework also successfully mitigates error propagation in sequential tasks, improving performance in dialogue continuation and multi-step text synthesis. Additional investigations into token-level attention distribution emphasized the dynamic focus shifts enabled through context-aware enhancements. The findings suggest that CASRM offers a scalable and flexible solution for integrating contextual intelligence into existing language model architectures. 

**Abstract (ZH)**: 情境感知处理机制已成为提高语言生成模型语义和上下文能力的关键研究领域。情境感知语义重组机制（CASRM）作为一种新型框架被引入，旨在解决大规模文本生成任务中连贯性、上下文适应性和错误传播的局限性。通过结合动态生成的情境向量和注意力调制层，CASRM增强了token级表示与更广泛上下文依赖性的对齐。实验评估表明，在技术、对话和叙事文本等多个领域中，CASRM显著提高了语义连贯性。通过多种测试场景评估了其对未见过领域和模糊输入的适应能力，突显了提议机制的鲁棒性。详细的计算分析表明，虽然CASRM增加了额外的处理开销，但在语言精确性和上下文相关性方面的改进超过了复杂性的轻微增加。该框架还成功缓解了序列任务中的错误传播，提高了对话续写和多步文本合成的表现。对token级注意力分布的进一步研究强调了通过情境感知增强而实现的动态焦点转换。研究结果表明，CASRM提供了一种可扩展且灵活的解决方案，可用于将情境智能整合到现有的语言模型架构中。 

---
# A Dual-Agent Adversarial Framework for Robust Generalization in Deep Reinforcement Learning 

**Title (ZH)**: 一种双代理对抗框架，用于深度强化学习中的稳健泛化 

**Authors**: Zhengpeng Xie, Jiahang Cao, Yulong Zhang, Qiang Zhang, Renjing Xu  

**Link**: [PDF](https://arxiv.org/pdf/2501.17384)  

**Abstract**: Recently, empowered with the powerful capabilities of neural networks, reinforcement learning (RL) has successfully tackled numerous challenging tasks. However, while these models demonstrate enhanced decision-making abilities, they are increasingly prone to overfitting. For instance, a trained RL model often fails to generalize to even minor variations of the same task, such as a change in background color or other minor semantic differences. To address this issue, we propose a dual-agent adversarial policy learning framework, which allows agents to spontaneously learn the underlying semantics without introducing any human prior knowledge. Specifically, our framework involves a game process between two agents: each agent seeks to maximize the impact of perturbing on the opponent's policy by producing representation differences for the same state, while maintaining its own stability against such perturbations. This interaction encourages agents to learn generalizable policies, capable of handling irrelevant features from the high-dimensional observations. Extensive experimental results on the Procgen benchmark demonstrate that the adversarial process significantly improves the generalization performance of both agents, while also being applied to various RL algorithms, e.g., Proximal Policy Optimization (PPO). With the adversarial framework, the RL agent outperforms the baseline methods by a significant margin, especially in hard-level tasks, marking a significant step forward in the generalization capabilities of deep reinforcement learning. 

**Abstract (ZH)**: 近年来，得益于神经网络的强大能力，强化学习（RL）已成功解决了许多具有挑战性的任务。然而，随着这些模型展示出增强的决策能力，它们也越来越容易发生过拟合。例如，训练好的RL模型往往难以泛化到同一任务的细微变化，如背景颜色的改变或其他细微的语义差异。为应对这一问题，我们提出了一种双智能体对抗策略学习框架，该框架允许智能体自发地学习底层语义，而无需引入任何先验的人类知识。具体来说，我们的框架涉及两个智能体之间的游戏过程：每个智能体都力求通过为同一状态生成不同的表示来最大化对对手策略的影响，同时保持自己对这种扰动的稳定性。这种互动促使智能体学习出具备泛化能力的策略，能够处理高维观测中的无关特征。在Procgen基准测试上的广泛实验结果表明，通过对抗过程显著提高了两个智能体的泛化性能，同时该框架也能应用于各种强化学习算法，例如近端策略优化（PPO）。利用对抗框架，RL智能体在基线方法上表现出显著的优越性，尤其是在高级任务中，这标志着深度强化学习泛化能力的重要进展。 

---
# ASAP: Learning Generalizable Online Bin Packing via Adaptive Selection After Pruning 

**Title (ZH)**: ASAP：通过可适应性选择剪枝后的在线 bin 装填学习通用算法 

**Authors**: Han Fang, Paul Weng, Yutong Ban  

**Link**: [PDF](https://arxiv.org/pdf/2501.17377)  

**Abstract**: Recently, deep reinforcement learning (DRL) has achieved promising results in solving online 3D Bin Packing Problems (3D-BPP). However, these DRL-based policies may perform poorly on new instances due to distribution shift. Besides generalization, we also consider adaptation, completely overlooked by previous work, which aims at rapidly finetuning these policies to a new test distribution. To tackle both generalization and adaptation issues, we propose Adaptive Selection After Pruning (ASAP), which decomposes a solver's decision-making into two policies, one for pruning and one for selection. The role of the pruning policy is to remove inherently bad actions, which allows the selection policy to choose among the remaining most valuable actions. To learn these policies, we propose a training scheme based on a meta-learning phase of both policies followed by a finetuning phase of the sole selection policy to rapidly adapt it to a test distribution. Our experiments demonstrate that ASAP exhibits excellent generalization and adaptation capabilities on in-distribution and out-of-distribution instances under both discrete and continuous setup. 

**Abstract (ZH)**: 近年来，深度强化学习（DRL）在解决在线3D容器装载问题（3D-BPP）方面取得了令人瞩目的成果。然而，这些基于DRL的策略可能在新实例上表现不佳，这是因为分布的变化导致的。除了泛化之外，我们还考虑了适应性，这是之前工作中完全忽视的一个方面，其目标是快速微调这些策略以适应新的测试分布。为了解决泛化和适应性问题，我们提出了自适应剪枝后选择（ASAP）方法，该方法将解决问题的决策过程分解为两个策略，一个用于剪枝，一个用于选择。剪枝策略的作用是去除那些本就不良的动作，这使选择策略可以在剩余的价值最高的动作中进行选择。为了学习这些策略，我们提出了一种基于两策略的元学习阶段和仅选择策略的快速微调阶段的训练方案。我们的实验表明，ASAP在离分布和跨分布实例以及离散和连续设置下都表现出卓越的泛化和适应能力。 

---
# A Geometric Perspective for High-Dimensional Multiplex Graphs 

**Title (ZH)**: 高维多层图的几何视角 

**Authors**: Kamel Abdous, Nairouz Mrabah, Mohamed Bouguessa  

**Link**: [PDF](https://arxiv.org/pdf/2501.17374)  

**Abstract**: High-dimensional multiplex graphs are characterized by their high number of complementary and divergent dimensions. The existence of multiple hierarchical latent relations between the graph dimensions poses significant challenges to embedding methods. In particular, the geometric distortions that might occur in the representational space have been overlooked in the literature. This work studies the problem of high-dimensional multiplex graph embedding from a geometric perspective. We find that the node representations reside on highly curved manifolds, thus rendering their exploitation more challenging for downstream tasks. Moreover, our study reveals that increasing the number of graph dimensions can cause further distortions to the highly curved manifolds. To address this problem, we propose a novel multiplex graph embedding method that harnesses hierarchical dimension embedding and Hyperbolic Graph Neural Networks. The proposed approach hierarchically extracts hyperbolic node representations that reside on Riemannian manifolds while gradually learning fewer and more expressive latent dimensions of the multiplex graph. Experimental results on real-world high-dimensional multiplex graphs show that the synergy between hierarchical and hyperbolic embeddings incurs much fewer geometric distortions and brings notable improvements over state-of-the-art approaches on downstream tasks. 

**Abstract (ZH)**: 高维度复层网络图因其高度互补和发散的维度特征而被定义。图维度间存在的多种层次潜在关系给嵌入方法带来了重大挑战。特别是在以往的研究中，嵌入空间中可能出现的几何失真尚未得到充分关注。本文从几何角度研究了高维度复层网络图的嵌入问题。我们发现节点表示位于高度弯曲的流形上，从而增加了其在下游任务中应用的难度。此外，我们的研究还揭示，增加图维度可能导致高度弯曲流形出现进一步的几何失真。为解决这一问题，我们提出了一种新的复层网络图嵌入方法，该方法结合了层次维度嵌入和双曲图神经网络。该方法分层提取位于黎曼流形上的双曲节点表示，并逐步学习复层网络的更少但更具表现力的潜在维度。在实际高维度复层网络图上的实验结果表明，层次嵌入与双曲嵌入的协同作用导致了更少的几何失真，并在下游任务中显著优于现有方法。 

---
# Forecasting S&P 500 Using LSTM Models 

**Title (ZH)**: 使用LSTM模型预测标准普尔500指数 

**Authors**: Prashant Pilla, Raji Mekonen  

**Link**: [PDF](https://arxiv.org/pdf/2501.17366)  

**Abstract**: With the volatile and complex nature of financial data influenced by external factors, forecasting the stock market is challenging. Traditional models such as ARIMA and GARCH perform well with linear data but struggle with non-linear dependencies. Machine learning and deep learning models, particularly Long Short-Term Memory (LSTM) networks, address these challenges by capturing intricate patterns and long-term dependencies. This report compares ARIMA and LSTM models in predicting the S&P 500 index, a major financial benchmark.
Using historical price data and technical indicators, we evaluated these models using Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). The ARIMA model showed reasonable performance with an MAE of 462.1, RMSE of 614, and 89.8 percent accuracy, effectively capturing short-term trends but limited by its linear assumptions. The LSTM model, leveraging sequential processing capabilities, outperformed ARIMA with an MAE of 369.32, RMSE of 412.84, and 92.46 percent accuracy, capturing both short- and long-term dependencies. Notably, the LSTM model without additional features performed best, achieving an MAE of 175.9, RMSE of 207.34, and 96.41 percent accuracy, showcasing its ability to handle market data efficiently.
Accurately predicting stock movements is crucial for investment strategies, risk assessments, and market stability. Our findings confirm the potential of deep learning models in handling volatile financial data compared to traditional ones. The results highlight the effectiveness of LSTM and suggest avenues for further improvements. This study provides insights into financial forecasting, offering a comparative analysis of ARIMA and LSTM while outlining their strengths and limitations. 

**Abstract (ZH)**: 由于金融数据受到外部因素的影响而呈现出易变性和复杂性，股市预测面临着挑战。传统的模型如ARIMA和GARCH在处理线性数据时表现良好，但在处理非线性依赖关系时则显得力不从心。而机器学习和深度学习模型，特别是长短期记忆（Long Short-Term Memory，LSTM）网络，通过捕捉复杂的模式和长期依赖关系来应对这些挑战。本报告将在预测S&P 500指数（一个重要的金融基准）方面对比ARIMA和LSTM模型的性能。

我们使用历史价格数据和技术指标，通过均方绝对误差（MAE）和均方根误差（RMSE）来评估这些模型。ARIMA模型显示出合理的性能，其MAE为462.1，RMSE为614，准确率为89.8%，能够有效捕捉短期趋势，但受限于其线性假设。LSTM模型通过利用 sequential 处理能力，其性能优于ARIMA，MAE为369.32，RMSE为412.84，准确率为92.46%，能够同时捕捉短期和长期依赖关系。值得注意的是，不使用额外特征的LSTM模型表现最佳，其MAE为175.9，RMSE为207.34，准确率为96.41%，证明了其高效处理市场数据的能力。

准确预测股价变动对于投资策略、风险评估和市场稳定性至关重要。我们的研究结果证实了与传统模型相比，深度学习模型在处理波动性金融数据方面的潜力。研究结果突显了LSTM的有效性，并提出了进一步改进的道路。该研究提供了有关金融预测的见解，进行了一系列ARIMA和LSTM的比较分析，同时指出了它们的优势和局限性。 

---
# The M-factor: A Novel Metric for Evaluating Neural Architecture Search in Resource-Constrained Environments 

**Title (ZH)**: M因子：一种适用于资源受限环境的神经架构搜索评估新指标 

**Authors**: Srikanth Thudumu, Hy Nguyen, Hung Du, Nhat Duong, Zafaryab Rasool, Rena Logothetis, Scott Barnett, Rajesh Vasa, Kon Mouzakis  

**Link**: [PDF](https://arxiv.org/pdf/2501.17361)  

**Abstract**: Neural Architecture Search (NAS) aims to automate the design of deep neural networks. However, existing NAS techniques often focus on maximising accuracy, neglecting model efficiency. This limitation restricts their use in resource-constrained environments like mobile devices and edge computing systems. Moreover, current evaluation metrics prioritise performance over efficiency, lacking a balanced approach for assessing architectures suitable for constrained scenarios. To address these challenges, this paper introduces the M-factor, a novel metric combining model accuracy and size. Four diverse NAS techniques are compared: Policy-Based Reinforcement Learning, Regularised Evolution, Tree-structured Parzen Estimator (TPE), and Multi-trial Random Search. These techniques represent different NAS paradigms, providing a comprehensive evaluation of the M-factor. The study analyses ResNet configurations on the CIFAR-10 dataset, with a search space of 19,683 configurations. Experiments reveal that Policy-Based Reinforcement Learning and Regularised Evolution achieved M-factor values of 0.84 and 0.82, respectively, while Multi-trial Random Search attained 0.75, and TPE reached 0.67. Policy-Based Reinforcement Learning exhibited performance changes after 39 trials, while Regularised Evolution optimised within 20 trials. The research investigates the optimisation dynamics and trade-offs between accuracy and model size for each strategy. Findings indicate that, in some cases, random search performed comparably to more complex algorithms when assessed using the M-factor. These results highlight how the M-factor addresses the limitations of existing metrics by guiding NAS towards balanced architectures, offering valuable insights for selecting strategies in scenarios requiring both performance and efficiency. 

**Abstract (ZH)**: 神经架构搜索（NAS）旨在自动化设计深度神经网络。然而，现有的NAS技术往往侧重于最大化准确性，忽视了模型效率。这一局限性限制了它们在如移动设备和边缘计算系统等资源受限环境中应用的范围。此外，当前的评估指标更关注性能而忽视了效率，缺乏一种在受限场景中评估架构的平衡方法。为了解决这些挑战，本文引入了M因子，这是一种结合了模型准确度和大小的新颖度量标准。本文比较了四种不同的NAS方法：基于策略的强化学习、正则化进化、树形核估机（TPE）以及多轮随机搜索。这些方法代表了不同的NAS范式，提供了对M因子的全面评估。研究在CIFAR-10数据集上分析了ResNet配置，搜索空间包括19,683种配置。实验结果显示，基于策略的强化学习和正则化进化分别实现了M因子值0.84和0.82，而多轮随机搜索达到了0.75，TPE则为0.67。基于策略的强化学习在39次试验后表现出性能变化，而正则化进化在20次试验内实现了优化。研究探讨了每种策略的优化动态及其在准确性和模型大小之间的权衡。研究发现，在某些情况下，使用M因子评估时，随机搜索的表现与更复杂的算法相当。这些结果突显了M因子如何通过引导NAS朝着平衡架构的方向发展，解决了现有度量标准的局限性，为同时需要性能和效率的场景提供了重要见解。 

---
# On the Coexistence and Ensembling of Watermarks 

**Title (ZH)**: 关于水印共存与集成的研究 

**Authors**: Aleksandar Petrov, Shruti Agarwal, Philip H.S. Torr, Adel Bibi, John Collomosse  

**Link**: [PDF](https://arxiv.org/pdf/2501.17356)  

**Abstract**: Watermarking, the practice of embedding imperceptible information into media such as images, videos, audio, and text, is essential for intellectual property protection, content provenance and attribution. The growing complexity of digital ecosystems necessitates watermarks for different uses to be embedded in the same media. However, to detect and decode all watermarks, they need to coexist well with one another. We perform the first study of coexistence of deep image watermarking methods and, contrary to intuition, we find that various open-source watermarks can coexist with only minor impacts on image quality and decoding robustness. The coexistence of watermarks also opens the avenue for ensembling watermarking methods. We show how ensembling can increase the overall message capacity and enable new trade-offs between capacity, accuracy, robustness and image quality, without needing to retrain the base models. 

**Abstract (ZH)**: 将以下论文内容或标题翻译成中文，符合学术规范：

水印技术是指将不可感知的信息嵌入到图像、视频、音频和文本等媒体中，对于知识产权保护、内容源属性和归属具有重要意义。随着数字生态系统复杂性的增加，需要将不同用途的水印嵌入到同一媒体中。然而，为了检测和解码所有水印，这些水印需要相互兼容。我们首次进行了深度图像水印方法共存性的研究，并出乎意料地发现，各种开源水印在仅对图像质量和解码鲁棒性造成轻微影响的情况下可以共存。水印的共存也为水印方法的集成开辟了途径。我们展示了如何通过集成提高整体信息容量，并在无需重新训练基础模型的前提下，实现容量、准确度、鲁棒性和图像质量之间的全新权衡。 

---
# Deep-and-Wide Learning: Enhancing Data-Driven Inference via Synergistic Learning of Inter- and Intra-Data Representations 

**Title (ZH)**: 深层宽学习：通过跨内数据表示协同学习增强数据驱动推理 

**Authors**: Md Tauhidul Islam, Lei Xing  

**Link**: [PDF](https://arxiv.org/pdf/2501.17347)  

**Abstract**: Advancements in deep learning are revolutionizing science and engineering. The immense success of deep learning is largely due to its ability to extract essential high-dimensional (HD) features from input data and make inference decisions based on this information. However, current deep neural network (DNN) models face several challenges, such as the requirements of extensive amounts of data and computational resources. Here, we introduce a new learning scheme, referred to as deep-and-wide learning (DWL), to systematically capture features not only within individual input data (intra-data features) but also across the data (inter-data features). Furthermore, we propose a dual-interactive-channel network (D-Net) to realize the DWL, which leverages our Bayesian formulation of low-dimensional (LD) inter-data feature extraction and its synergistic interaction with the conventional HD representation of the dataset, for substantially enhanced computational efficiency and inference. The proposed technique has been applied to data across various disciplines for both classification and regression tasks. Our results demonstrate that DWL surpasses state-of-the-art DNNs in accuracy by a substantial margin with limited training data and improves the computational efficiency by order(s) of magnitude. The proposed DWL strategy dramatically alters the data-driven learning techniques, including emerging large foundation models, and sheds significant insights into the evolving field of AI. 

**Abstract (ZH)**: 深度学习的进步正在革新科学研究和工程技术。深度学习之所以取得巨大成功，主要是因为它能够从输入数据中提取出高维（HD）的关键特征，并基于这些信息作出推理决策。然而，当前的深度神经网络（DNN）模型面临着一些挑战，比如需要大量的数据和计算资源。在此，我们提出了一种新的学习方案，称为深度和宽泛学习（DWL），以系统性地捕捉不仅个体输入数据内部（内在数据特征）的特征，还有数据之间的（外在数据特征）特征。此外，我们还提出了一种双互动通道网络（D-Net）来实现DWL，该网络利用了我们对低维（LD）外在数据特征提取的贝叶斯表述，并将其与数据集的常规高维表示的协同作用相结合，以显著提高计算效率和推理能力。我们提出的这项技术已被应用于多个学科的数据中，用于分类和回归任务。实验结果表明，DWL在有限的训练数据下能够显著超越现有最先进的DNN，在准确性上具有明显优势，并且计算效率提高了数个数量级。所提出的DWL策略极大地改变了基于数据的机器学习技术，包括新兴的大规模基础模型，并为正在发展的AI领域提供了重要的见解。 

---
# Post-Training Quantization for 3D Medical Image Segmentation: A Practical Study on Real Inference Engines 

**Title (ZH)**: 针对3D医学影像分割的后训练量化：对实际推理引擎的一项实用研究 

**Authors**: Chongyu Qu, Ritchie Zhao, Ye Yu, Bin Liu, Tianyuan Yao, Junchao Zhu, Bennett A. Landman, Yucheng Tang, Yuankai Huo  

**Link**: [PDF](https://arxiv.org/pdf/2501.17343)  

**Abstract**: Quantizing deep neural networks ,reducing the precision (bit-width) of their computations, can remarkably decrease memory usage and accelerate processing, making these models more suitable for large-scale medical imaging applications with limited computational resources. However, many existing methods studied "fake quantization", which simulates lower precision operations during inference, but does not actually reduce model size or improve real-world inference speed. Moreover, the potential of deploying real 3D low-bit quantization on modern GPUs is still unexplored. In this study, we introduce a real post-training quantization (PTQ) framework that successfully implements true 8-bit quantization on state-of-the-art (SOTA) 3D medical segmentation models, i.e., U-Net, SegResNet, SwinUNETR, nnU-Net, UNesT, TransUNet, ST-UNet,and VISTA3D. Our approach involves two main steps. First, we use TensorRT to perform fake quantization for both weights and activations with unlabeled calibration dataset. Second, we convert this fake quantization into real quantization via TensorRT engine on real GPUs, resulting in real-world reductions in model size and inference latency. Extensive experiments demonstrate that our framework effectively performs 8-bit quantization on GPUs without sacrificing model performance. This advancement enables the deployment of efficient deep learning models in medical imaging applications where computational resources are constrained. The code and models have been released, including U-Net, TransUNet pretrained on the BTCV dataset for abdominal (13-label) segmentation, UNesT pretrained on the Whole Brain Dataset for whole brain (133-label) segmentation, and nnU-Net, SegResNet, SwinUNETR and VISTA3D pretrained on TotalSegmentator V2 for full body (104-label) segmentation. this https URL. 

**Abstract (ZH)**: 深度神经网络的量化，通过减少其计算精度（位宽），可以显著减少内存使用并加速处理，使这些模型更适合在计算资源有限的大规模医学成像应用中使用。然而，许多现有方法研究了“假量化”，即在推理过程中模拟较低精度的操作，但并未实际减少模型大小或提高实际推理速度。此外，现代GPU上部署真实的3D低位宽量化潜力仍未被开发。在本研究中，我们引入了一种真正的后训练量化（PTQ）框架，能够在最新的（SOTA）3D医学分割模型（如U-Net、SegResNet、SwinUNETR、nnU-Net、UNesT、TransUNet、ST-UNet和VISTA3D）上成功实施真正的8位量化。我们的方法涉及两个主要步骤。首先，我们使用TensorRT对未标记的校准数据集进行假量化，包括权重和激活。其次，我们通过TensorRT引擎将这种假量化转换为真实量化，从而在实际中减少模型大小和推理延迟。大量实验表明，我们的框架能够在不牺牲模型性能的情况下有效地在GPU上执行8位量化。这一进展使高效深度学习模型能够在受到计算资源限制的医学成像应用中部署。我们已公开了代码和模型，包括在BTCV数据集上预训练的用于腹部（13个标签）分割的TransUNet、在完整大脑数据集上预训练的用于完整大脑（133个标签）分割的UNesT、以及在TotalSegmentator V2数据集上预训练的用于全身（104个标签）分割的nnU-Net、SegResNet、SwinUNETR和VISTA3D。更多信息请参阅此链接：[提供链接] 

---
# Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection 

**Title (ZH)**: 从logits推理：探索无需解码的选择生成候选的最佳实践 

**Authors**: Mingyu Derek Ma, Yanna Ding, Zijie Huang, Jianxi Gao, Yizhou Sun, Wei Wang  

**Link**: [PDF](https://arxiv.org/pdf/2501.17338)  

**Abstract**: Generative Language Models rely on autoregressive decoding to produce the output sequence token by token. Many tasks such as preference optimization, require the model to produce task-level output consisting of multiple tokens directly by selecting candidates from a pool as predictions. Determining a task-level prediction from candidates using the ordinary token-level decoding mechanism is constrained by time-consuming decoding and interrupted gradients by discrete token selection. Existing works have been using decoding-free candidate selection methods to obtain candidate probability from initial output logits over vocabulary. Though these estimation methods are widely used, they are not systematically evaluated, especially on end tasks. We introduce an evaluation of a comprehensive collection of decoding-free candidate selection approaches on a comprehensive set of tasks, including five multiple-choice QA tasks with a small candidate pool and four clinical decision tasks with a massive amount of candidates, some with 10k+ options. We evaluate the estimation methods paired with a wide spectrum of foundation LMs covering different architectures, sizes and training paradigms. The results and insights from our analysis inform the future model design. 

**Abstract (ZH)**: 生成语言模型依赖于自回归解码，逐个生成输出序列中的令牌。许多任务，如偏好优化，要求模型直接从候选词汇池中选择候选项生成任务级输出。使用常规的令牌级解码机制从候选项中确定任务级预测受限于耗费时间的解码过程以及由离散的令牌选择引起的中断梯度。现有工作中已经使用解码-Free的候选选择方法从词汇表的初始输出logits中获得候选项的概率。尽管这些估算方法被广泛使用，但它们尚未系统地评估，特别是在终端任务上。我们探讨了在一系列任务上评估解码-Free候选选择方法的全面集合，涵盖了五个带有小候选池的多项选择问答任务和四个带有大量候选项的临床决策任务，其中一些有超过10000个选项。我们评估了一系列基础大型语言模型，这些模型覆盖了不同的架构、规模和训练范式。我们分析的结果和见解为未来模型的设计提供了指导。 

---
# Anomaly Detection in Cooperative Vehicle Perception Systems under Imperfect Communication 

**Title (ZH)**: 在 Imperfect 通信条件下的协同车辆感知系统中的异常检测 

**Authors**: Ashish Bastola, Hao Wang, Abolfazl Razi  

**Link**: [PDF](https://arxiv.org/pdf/2501.17329)  

**Abstract**: Anomaly detection is a critical requirement for ensuring safety in autonomous driving. In this work, we leverage Cooperative Perception to share information across nearby vehicles, enabling more accurate identification and consensus of anomalous behaviors in complex traffic scenarios. To account for the real-world challenge of imperfect communication, we propose a cooperative-perception-based anomaly detection framework (CPAD), which is a robust architecture that remains effective under communication interruptions, thereby facilitating reliable performance even in low-bandwidth settings. Since no multi-agent anomaly detection dataset exists for vehicle trajectories, we introduce 15,000 different scenarios with a 90,000 trajectories benchmark dataset generated through rule-based vehicle dynamics analysis. Empirical results demonstrate that our approach outperforms standard anomaly classification methods in F1-score, AUC and showcase strong robustness to agent connection interruptions. 

**Abstract (ZH)**: 异常检测是确保自动驾驶安全性的一个关键需求。本研究利用协同感知（Cooperative Perception，CP）技术，在相邻车辆之间共享信息，这使得在复杂交通场景中更准确地识别和达成一致的异常行为成为可能。为了应对通信不完善的实际挑战，我们提出了一个基于协同感知的异常检测框架（CPAD），该框架具有鲁棒性，能在通信中断的情况下保持有效性，从而在带宽较低的环境下也能实现可靠的性能。由于目前没有适用于车辆轨迹的多智能体异常检测数据集，我们通过基于规则的车辆动力学分析生成了一个包含15,000种不同场景和90,000条轨迹的基准数据集。通过实验证明，我们的方法在F1分数、AUC值上优于标准的异常分类方法，并且在智能体连接中断时展现出很强的鲁棒性。 

---
# Memorize and Rank: Elevating Large Language Models for Clinical Diagnosis Prediction 

**Title (ZH)**: 记忆与排序：提升临床诊断预测的大语言模型 

**Authors**: Mingyu Derek Ma, Xiaoxuan Wang, Yijia Xiao, Anthony Cuturrufo, Vijay S Nori, Eran Halperin, Wei Wang  

**Link**: [PDF](https://arxiv.org/pdf/2501.17326)  

**Abstract**: Clinical diagnosis prediction models, when provided with a patient's medical history, aim to detect potential diseases early, facilitating timely intervention and improving prognostic outcomes. However, the inherent scarcity of patient data and large disease candidate space often pose challenges in developing satisfactory models for this intricate task. The exploration of leveraging Large Language Models (LLMs) for encapsulating clinical decision processes has been limited. We introduce MERA, a clinical diagnosis prediction model that bridges pertaining natural language knowledge with medical practice. We apply hierarchical contrastive learning on a disease candidate ranking list to alleviate the large decision space issue. With concept memorization through fine-tuning, we bridge the natural language clinical knowledge with medical codes. Experimental results on MIMIC-III and IV datasets show that MERA achieves the state-of-the-art diagnosis prediction performance and dramatically elevates the diagnosis prediction capabilities of generative LMs. 

**Abstract (ZH)**: 基于患者医疗历史的临床诊断预测模型旨在早期检测潜在疾病，从而促进及时干预并改善预后效果。然而，患者的医疗数据稀缺性和大量疾病候选空间往往给开发此类复杂模型带来了挑战。利用大型语言模型（LLMs）来封装临床决策过程的研究相对有限。我们引入了MERA，这是一种结合了相关自然语言知识和医疗实践的临床诊断预测模型。通过分层对比学习对疾病候选排名列表进行处理，以缓解决策空间过大的问题。通过细调实现概念记忆，将自然语言临床知识与医疗代码相结合。在MIMIC-III和MIMIC-IV数据集上的实验结果显示，MERA实现了最先进的诊断预测性能，并显著提升了生成型LMs的诊断预测能力。 

---
# Connecting Federated ADMM to Bayes 

**Title (ZH)**: 将联邦ADMM与贝叶斯方法联系起来 

**Authors**: Siddharth Swaroop, Mohammad Emtiyaz Khan, Finale Doshi-Velez  

**Link**: [PDF](https://arxiv.org/pdf/2501.17325)  

**Abstract**: We provide new connections between two distinct federated learning approaches based on (i) ADMM and (ii) Variational Bayes (VB), and propose new variants by combining their complementary strengths. Specifically, we show that the dual variables in ADMM naturally emerge through the 'site' parameters used in VB with isotropic Gaussian covariances. Using this, we derive two versions of ADMM from VB that use flexible covariances and functional regularisation, respectively. Through numerical experiments, we validate the improvements obtained in performance. The work shows connection between two fields that are believed to be fundamentally different and combines them to improve federated learning. 

**Abstract (ZH)**: 我们将基于（i）ADMM和（ii）变分贝叶斯（VB）的两种不同联邦学习方法联系起来，并提出结合它们互补优势的新变体。具体来说，我们展示了ADMM中的对偶变量自然地通过VB中的“站点”参数（具有各向同性高斯协方差）出现。利用这一点，我们从VB出发推导出两种版本的ADMM，分别使用灵活的协方差和功能正则化。通过数值实验，我们验证了性能上的改进。这项工作在理论上展示了被视为根本不同的两个领域之间的联系，并将它们结合起来以提高联邦学习的性能。 

---
# Multi-Physics Simulations via Coupled Fourier Neural Operator 

**Title (ZH)**: 通过耦合傅里叶神经算子进行多物理场仿真 

**Authors**: Shibo Li, Tao Wang, Yifei Sun, Heiwei Tang  

**Link**: [PDF](https://arxiv.org/pdf/2501.17296)  

**Abstract**: Physical simulations are essential tools across critical fields such as mechanical and aerospace engineering, chemistry, meteorology, etc. While neural operators, particularly the Fourier Neural Operator (FNO), have shown promise in predicting simulation results with impressive performance and efficiency, they face limitations when handling real-world scenarios involving coupled multi-physics outputs. Current neural operator methods either overlook the correlations between multiple physical processes or employ simplistic architectures that inadequately capture these relationships. To overcome these challenges, we introduce a novel coupled multi-physics neural operator learning (COMPOL) framework that extends the capabilities of Fourier operator layers to model interactions among multiple physical processes. Our approach implements feature aggregation through recurrent and attention mechanisms, enabling comprehensive modeling of coupled interactions. Our method's core is an innovative system for aggregating latent features from multi-physics processes. These aggregated features serve as enriched information sources for neural operator layers, allowing our framework to capture complex physical relationships accurately. We evaluated our coupled multi-physics neural operator across diverse physical simulation tasks, including biological systems, fluid mechanics, and multiphase flow in porous media. Our proposed model demonstrates a two to three-fold improvement in predictive performance compared to existing approaches. 

**Abstract (ZH)**: 物理模拟是机械工程、航空航天工程、化学、气象学等关键领域中不可或缺的工具。尽管神经算子，特别是傅里叶神经算子（FNO），在预测模拟结果方面表现出色且高效，但在处理涉及耦合多物理场输出的实际场景时仍面临局限性。当前的神经算子方法要么忽略了多种物理过程之间的关联性，要么采用简化的架构难以充分捕捉这些关系。为了克服这些挑战，我们提出了一种新的多物理场耦合神经算子学习（COMPOL）框架，该框架扩展了傅里叶算子层的能力，以建模多种物理过程之间的相互作用。我们的方法通过递归和注意力机制实现特征聚合，从而能够全面建模耦合相互作用。我们方法的核心是用于从多物理场过程汇总潜特征的一个创新系统。这些汇总特征作为神经算子层的丰富信息来源，使我们的框架能够准确捕捉复杂的物理关系。我们在包括生物系统、流体力学和多相流体在多孔介质中的流动等多样化的物理模拟任务上评估了我们的多物理场耦合神经算子。与现有方法相比，我们提出的方法在预测性能上实现了两到三倍的提升。 

---
# Mitigating Hallucinated Translations in Large Language Models with Hallucination-focused Preference Optimization 

**Title (ZH)**: 使用幻觉焦点的偏好优化减轻大型语言模型中的幻觉翻译 

**Authors**: Zilu Tang, Rajen Chatterjee, Sarthak Garg  

**Link**: [PDF](https://arxiv.org/pdf/2501.17295)  

**Abstract**: Machine Translation (MT) is undergoing a paradigm shift, with systems based on fine-tuned large language models (LLM) becoming increasingly competitive with traditional encoder-decoder models trained specifically for translation tasks. However, LLM-based systems are at a higher risk of generating hallucinations, which can severely undermine user's trust and safety. Most prior research on hallucination mitigation focuses on traditional MT models, with solutions that involve post-hoc mitigation - detecting hallucinated translations and re-translating them. While effective, this approach introduces additional complexity in deploying extra tools in production and also increases latency. To address these limitations, we propose a method that intrinsically learns to mitigate hallucinations during the model training phase. Specifically, we introduce a data creation framework to generate hallucination focused preference datasets. Fine-tuning LLMs on these preference datasets reduces the hallucination rate by an average of 96% across five language pairs, while preserving overall translation quality. In a zero-shot setting our approach reduces hallucinations by 89% on an average across three unseen target languages. 

**Abstract (ZH)**: 机器翻译（MT）正经历一场范式的转变，基于微调的大语言模型（LLM）的系统越来越能够在翻译任务中与专门训练的编码器-解码器模型竞争。然而，基于大语言模型的系统在生成幻觉的风险上更高，这可能严重损害用户的信任和安全性。目前大多数关于幻觉缓解的研究主要集中在传统的MT模型上，解决方案通常涉及事后缓解——检测幻觉翻译并重新翻译。虽然这种方法有效，但它引入了生产中额外工具的复杂性，同时也增加了延迟。为了解决这些局限性，我们提出了一种在模型训练阶段内在地学习缓解幻觉的方法。具体而言，我们引入了一个数据生成框架，以生成专注于幻觉的偏好数据集。在这些偏好数据集上微调大语言模型，可在五个语言对上平均降低96%的幻觉率，同时保持整体翻译质量。在零样本设置中，我们的方法在三个未见过的目标语言上平均降低幻觉率89%。 

---
# Fine-Tuning Open-Source Large Language Models to Improve Their Performance on Radiation Oncology Tasks: A Feasibility Study to Investigate Their Potential Clinical Applications in Radiation Oncology 

**Title (ZH)**: 将开源大规模语言模型进行微调以提高其在放射肿瘤学任务上的性能：一项关于探索其在放射肿瘤学潜在临床应用可行性的研究 

**Authors**: Peilong Wang, Zhengliang Liu, Yiwei Li, Jason Holmes, Peng Shu, Lian Zhang, Xiang Li, Quanzheng Li, Brady S. Laughlin, Diego Santos Toesca, Sujay A. Vora, Samir H. Patel, Terence T. Sio, Tianming Liu, Wei Liu  

**Link**: [PDF](https://arxiv.org/pdf/2501.17286)  

**Abstract**: Background: The radiation oncology clinical practice involves many steps relying on the dynamic interplay of abundant text data. Large language models have displayed remarkable capabilities in processing complex text information. But their direct applications in specific fields like radiation oncology remain underexplored.
Purpose: This study aims to investigate whether fine-tuning LLMs with domain knowledge can improve the performance on Task (1) treatment regimen generation, Task (2) treatment modality selection (photon, proton, electron, or brachytherapy), and Task (3) ICD-10 code prediction in radiation oncology.
Methods: Data for 15,724 patient cases were extracted. Cases where patients had a single diagnostic record, and a clearly identifiable primary treatment plan were selected for preprocessing and manual annotation to have 7,903 cases of the patient diagnosis, treatment plan, treatment modality, and ICD-10 code. Each case was used to construct a pair consisting of patient diagnostics details and an answer (treatment regimen, treatment modality, or ICD-10 code respectively) for the supervised fine-tuning of these three tasks. Open source LLaMA2-7B and Mistral-7B models were utilized for the fine-tuning with the Low-Rank Approximations method. Accuracy and ROUGE-1 score were reported for the fine-tuned models and original models. Clinical evaluation was performed on Task (1) by radiation oncologists, while precision, recall, and F-1 score were evaluated for Task (2) and (3). One-sided Wilcoxon signed-rank tests were used to statistically analyze the results.
Results: Fine-tuned LLMs outperformed original LLMs across all tasks with p-value <= 0.001. Clinical evaluation demonstrated that over 60% of the fine-tuned LLMs-generated treatment regimens were clinically acceptable. Precision, recall, and F1-score showed improved performance of fine-tuned LLMs. 

**Abstract (ZH)**: 背景：放射肿瘤学临床实践中涉及众多步骤，依赖于大量动态交互的文本数据。大型语言模型在处理复杂文本信息方面展现了显著的能力，但在像放射肿瘤学这样的特定领域中的直接应用仍处于探索阶段。
目的：本研究旨在探讨利用领域知识微调大型语言模型是否能改进放射肿瘤学中的三项任务：治疗方案生成（Task 1），治疗方式选择（光子、质子、电子或近距离放射治疗，Task 2），以及ICD-10代码预测（Task 3）。
方法：从15,724例患者病例中提取数据。选择仅包含一个诊断记录且具有明确主要治疗计划的病例进行预处理和手动注释，共计7,903例患者的诊断、治疗计划、治疗方式和ICD-10代码。每个病例用于构建一个包含患者诊断细节及其相应答案（治疗方案、治疗方式或ICD-10代码）的监督微调样本对，以分别对这三个任务进行监督微调。使用开源的LLaMA2-7B和Mistral-7B模型，并采用低秩近似方法进行微调。报告微调后的模型和原始模型的准确性及ROUGE-1分数。Task 1的临床评价由放射肿瘤科医生进行，而Task 2和Task 3分别通过精确度、召回率和F1分数进行评估。采用单侧Wilcoxon符号秩检验对结果进行统计分析。
结果：微调后的大型语言模型在三项任务中均优于原始模型，p值≤0.001。临床评价显示，超过60%的微调后大型语言模型生成的治疗方案在临床中是可以接受的。精确度、召回率和F1分数表明微调后的大型语言模型性能有所提升。 

---
# ViT-2SPN: Vision Transformer-based Dual-Stream Self-Supervised Pretraining Networks for Retinal OCT Classification 

**Title (ZH)**: ViT-2SPN：基于视觉变换器的双流自监督预训练网络在视网膜OCT分类中的应用 

**Authors**: Mohammadreza Saraei, Igor Kozak, Eung-Joo Lee  

**Link**: [PDF](https://arxiv.org/pdf/2501.17260)  

**Abstract**: Optical Coherence Tomography (OCT) is a non-invasive imaging modality essential for diagnosing various eye diseases. Despite its clinical significance, developing OCT-based diagnostic tools faces challenges, such as limited public datasets, sparse annotations, and privacy concerns. Although deep learning has made progress in automating OCT analysis, these challenges remain unresolved. To address these limitations, we introduce the Vision Transformer-based Dual-Stream Self-Supervised Pretraining Network (ViT-2SPN), a novel framework designed to enhance feature extraction and improve diagnostic accuracy. ViT-2SPN employs a three-stage workflow: Supervised Pretraining, Self-Supervised Pretraining (SSP), and Supervised Fine-Tuning. The pretraining phase leverages the OCTMNIST dataset (97,477 unlabeled images across four disease classes) with data augmentation to create dual-augmented views. A Vision Transformer (ViT-Base) backbone extracts features, while a negative cosine similarity loss aligns feature representations. Pretraining is conducted over 50 epochs with a learning rate of 0.0001 and momentum of 0.999. Fine-tuning is performed on a stratified 5.129% subset of OCTMNIST using 10-fold cross-validation. ViT-2SPN achieves a mean AUC of 0.93, accuracy of 0.77, precision of 0.81, recall of 0.75, and an F1 score of 0.76, outperforming existing SSP-based methods. 

**Abstract (ZH)**: 光学相干断层扫描(Optical Coherence Tomography, OCT)是一种无创成像技术，对于诊断多种眼科疾病至关重要。尽管其在临床中有重要意义，但基于OCT的诊断工具的研发面临着诸多挑战，包括公共数据集有限、标注稀疏以及隐私问题。虽然深度学习在自动化OCT分析方面取得了进展，但这些挑战仍未解决。为应对这些限制，我们提出了一种名为Vision Transformer-based Dual-Stream Self-Supervised Pretraining Network (ViT-2SPN)的新框架，旨在增强特征提取并提高诊断准确性。ViT-2SPN采用三阶段工作流程：监督预训练、自监督预训练（SSP）和监督微调。预训练阶段使用OCTMNIST数据集（包含四个疾病类别的97,477张未标注图像），通过数据增强生成双增强视图。Vision Transformer (ViT-Base)骨干网络提取特征，而负余弦相似损失则对特征表示进行对齐。预训练在50个周期内进行，学习率为0.0001，动量为0.999。微调在经过分层交叉验证的OCTMNIST数据集的5.129%子集上进行。ViT-2SPN在十折交叉验证的细调后，达到了平均AUC为0.93、准确率为0.77、精确率为0.81、召回率为0.75和F1分为0.76的性能，优于现有自监督预训练方法。 

---
# Rethinking Functional Brain Connectome Analysis: Do Graph Deep Learning Models Help? 

**Title (ZH)**: 重新思考功能性脑连接网络分析：图深度学习模型有所帮助吗？ 

**Authors**: Keqi Han, Yao Su, Lifang He, Liang Zhan, Sergey Plis, Vince Calhoun, Carl Yang  

**Link**: [PDF](https://arxiv.org/pdf/2501.17207)  

**Abstract**: Functional brain connectome is crucial for deciphering the neural mechanisms underlying cognitive functions and neurological disorders. Graph deep learning models have recently gained tremendous popularity in this field. However, their actual effectiveness in modeling the brain connectome remains unclear. In this study, we re-examine graph deep learning models based on four large-scale neuroimaging studies encompassing diverse cognitive and clinical outcomes. Surprisingly, we find that the message aggregation mechanism, a hallmark of graph deep learning models, does not help with predictive performance as typically assumed, but rather consistently degrades it. To address this issue, we propose a hybrid model combining a linear model with a graph attention network through dual pathways, achieving robust predictions and enhanced interpretability by revealing both localized and global neural connectivity patterns. Our findings urge caution in adopting complex deep learning models for functional brain connectome analysis, emphasizing the need for rigorous experimental designs to establish tangible performance gains and perhaps more importantly, to pursue improvements in model interpretability. 

**Abstract (ZH)**: 功能性脑连接组对于理解认知功能和神经性疾病背后的神经机制至关重要。图形深度学习模型在这一领域最近获得了极大的关注。然而，它们在建模脑连接组的实际有效性仍然不得而知。在本研究中，我们基于四个大型神经影像学研究，涵盖了不同的认知和临床结果，重新审视了基于图形深度学习模型的效果。令人惊讶的是，我们发现了一种普遍假设中的图形深度学习模型的核心机制——信息聚合机制，并不提高预测性能，反而一致地降低了性能。为了解决这一问题，我们提出了一种结合线性模型与图形注意网络的混合模型，通过双路径实现稳健的预测和增强的可解释性，揭示了局部和全局的神经连接模式。我们的发现提醒研究者，在功能性脑连接组分析中谨慎采用复杂深度学习模型，强调需要严谨的实验设计以确立可量化的性能提升，并且更加重要的是，追求模型可解释性的改进。 

---
# Improving LLM Leaderboards with Psychometrical Methodology 

**Title (ZH)**: 使用心理测量方法提升大型语言模型排行榜的表现 

**Authors**: Denis Federiakin  

**Link**: [PDF](https://arxiv.org/pdf/2501.17200)  

**Abstract**: The rapid development of large language models (LLMs) has necessitated the creation of benchmarks to evaluate their performance. These benchmarks resemble human tests and surveys, as they consist of sets of questions designed to measure emergent properties in the cognitive behavior of these systems. However, unlike the well-defined traits and abilities studied in social sciences, the properties measured by these benchmarks are often vaguer and less rigorously defined. The most prominent benchmarks are often grouped into leaderboards for convenience, aggregating performance metrics and enabling comparisons between models. Unfortunately, these leaderboards typically rely on simplistic aggregation methods, such as taking the average score across benchmarks. In this paper, we demonstrate the advantages of applying contemporary psychometric methodologies - originally developed for human tests and surveys - to improve the ranking of large language models on leaderboards. Using data from the Hugging Face Leaderboard as an example, we compare the results of the conventional naive ranking approach with a psychometrically informed ranking. The findings highlight the benefits of adopting psychometric techniques for more robust and meaningful evaluation of LLM performance. 

**Abstract (ZH)**: 大型语言模型（LLMs）的迅速发展促使人们创建了各种基准来评估模型的性能。这些基准类似于人类测试和调查，主要是通过设计一系列问题来衡量这些系统在认知行为方面的新兴特性。然而，与社会科学中研究的明确特质和能力不同，这些基准测量的特性往往较为模糊且定义不够严谨。最突出的基准通常因方便而被归类到排行榜中，聚合了各种性能指标并允许模型之间的比较。不幸的是，这些排行榜通常依赖于简单的聚合方法，如取各项基准平均分。在这篇论文中，我们展示了将现代心理学测量方法应用于大型语言模型排行榜的优势。心理学测量方法原本是为人类测试和调查设计的。我们使用Hugging Face排行榜的数据为例，将传统的简单排名方法与基于心理学测量的原则进行比较。研究结果突显了使用心理学技术进行更稳健和有意义的LLM性能评估的优势。 

---
# Atla Selene Mini: A General Purpose Evaluation Model 

**Title (ZH)**: Atla Selene Mini：一个通用评估模型 

**Authors**: Andrei Alexandru, Antonia Calvi, Henry Broomfield, Jackson Golden, Kyle Dai, Mathias Leys, Maurice Burger, Max Bartolo, Roman Engeler, Sashank Pisupati, Toby Drane, Young Sun Park  

**Link**: [PDF](https://arxiv.org/pdf/2501.17195)  

**Abstract**: We introduce Atla Selene Mini, a state-of-the-art small language model-as-a-judge (SLMJ). Selene Mini is a general-purpose evaluator that outperforms the best SLMJs and GPT-4o-mini on overall performance across 11 out-of-distribution benchmarks, spanning absolute scoring, classification, and pairwise preference tasks. It is the highest-scoring 8B generative model on RewardBench, surpassing strong baselines like GPT-4o and specialized judges. To achieve this, we develop a principled data curation strategy that augments public datasets with synthetically generated critiques and ensures high quality through filtering and dataset ablations. We train our model on a combined direct preference optimization (DPO) and supervised fine-tuning (SFT) loss, and produce a highly promptable evaluator that excels in real-world scenarios. Selene Mini shows dramatically improved zero-shot agreement with human expert evaluations on financial and medical industry datasets. It is also robust to variations in prompt format. Preliminary results indicate that Selene Mini is the top-ranking evaluator in a live, community-driven Judge Arena. We release the model weights on HuggingFace (this https URL) and Ollama to encourage widespread community adoption. 

**Abstract (ZH)**: 我们介绍了Atla Selene Mini，这是一种最先进的小型语言模型作为裁判（SLMJ）。Selene Mini 是一种通用评估器，在11个跨分布外基准测试中脱颖而出，涵盖绝对评分、分类和成对偏好任务，整体性能超过了最佳的SLMJ和GPT-4o-mini。它是RewardBench上得分最高的8B生成模型，超越了如GPT-4o和专门的裁判的强劲基线。为了实现这一目标，我们开发了一种原则性的数据策展策略，通过增加合成生成的批评意见来扩充公共数据集，并通过过滤和数据集消减确保高质量。我们使用直接偏好优化（DPO）和监督微调（SFT）损失对模型进行训练，产生了一种高度可调用的评估器，能够在实际场景中表现出色。Selene Mini 在金融和医疗行业数据集上的零样本一致性显著提高，同时也对提示格式的变化具有鲁棒性。初步结果显示，Selene Mini 在一个活的、社区驱动的裁判竞技场中排名第一。我们已在HuggingFace（https://）和Ollama上发布了模型权重，以促进社区的广泛采用。 

---
# Visualizing Uncertainty in Translation Tasks: An Evaluation of LLM Performance and Confidence Metrics 

**Title (ZH)**: 翻译如下，符合学术规范：

可视化翻译任务中的不确定性：大语言模型性能及置信度指标评估 

**Authors**: Jin Hyun Park, Utsawb Laminchhane, Umer Farooq, Uma Sivakumar, Arpan Kumar  

**Link**: [PDF](https://arxiv.org/pdf/2501.17187)  

**Abstract**: Large language models (LLMs) are increasingly utilized for machine translation, yet their predictions often exhibit uncertainties that hinder interpretability and user trust. Effectively visualizing these uncertainties can enhance the usability of LLM outputs, particularly in contexts where translation accuracy is critical. This paper addresses two primary objectives: (1) providing users with token-level insights into model confidence and (2) developing a web-based visualization tool to quantify and represent translation uncertainties. To achieve these goals, we utilized the T5 model with the WMT19 dataset for translation tasks and evaluated translation quality using established metrics such as BLEU, METEOR, and ROUGE. We introduced three novel uncertainty quantification (UQ) metrics: (1) the geometric mean of token probabilities, (2) the arithmetic mean of token probabilities, and (3) the arithmetic mean of the kurtosis of token distributions. These metrics provide a simple yet effective framework for evaluating translation performance. Our analysis revealed a linear relationship between the traditional evaluation metrics and our UQ metrics, demonstrating the validity of our approach. Additionally, we developed an interactive web-based visualization that uses a color gradient to represent token confidence. This tool offers users a clear and intuitive understanding of translation quality while providing valuable insights into model performance. Overall, we show that our UQ metrics and visualization are both robust and interpretable, offering practical tools for evaluating and accessing machine translation systems. 

**Abstract (ZH)**: 大语言模型（LLMs）在机器翻译中的应用越来越广泛，但它们的预测往往表现出不确定性，这限制了模型的可解释性和用户信任。有效地可视化这些不确定性可以增强LLM输出的实用性，尤其是在翻译准确性至关重要的情况下。本文旨在实现两个主要目标：(1) 为用户提供关于模型置信度的token级洞察，(2) 开发一个网页工具来量化和呈现翻译不确定性。为了实现这些目标，我们使用T5模型和WMT19数据集进行翻译任务，并使用已建立的评估指标，如BLEU、METEOR和ROUGE来评估翻译质量。我们引入了三种新的不确定性量化（UQ）指标：(1) token概率的几何平均值，(2) token概率的算术平均值，(3) token分布的峰度的算术平均值。这些指标提供了一个简单而有效的框架来评估翻译性能。我们的分析显示，传统的评估指标与我们的UQ指标之间存在线性关系，证明了我们方法的有效性。此外，我们开发了一个交互式的网页可视化工具，使用颜色梯度来表示token置信度。该工具为用户提供了一个清晰且直观的翻译质量理解，同时也提供了关于模型性能的有价值见解。总之，我们表明，我们的UQ指标和可视化工具既稳健又可解释，为评估和使用机器翻译系统提供了实用工具。 

---
# LLM Evaluation Based on Aerospace Manufacturing Expertise: Automated Generation and Multi-Model Question Answering 

**Title (ZH)**: 基于航空航天制造业知识的LLM评估：自动化生成与多模型问答 

**Authors**: Beiming Liu, Zhizhuo Cui, Siteng Hu, Xiaohua Li, Haifeng Lin, Zhengxin Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2501.17183)  

**Abstract**: Aerospace manufacturing demands exceptionally high precision in technical parameters. The remarkable performance of Large Language Models (LLMs), such as GPT-4 and QWen, in Natural Language Processing has sparked industry interest in their application to tasks including process design, material selection, and tool information retrieval. However, LLMs are prone to generating "hallucinations" in specialized domains, producing inaccurate or false information that poses significant risks to the quality of aerospace products and flight safety. This paper introduces a set of evaluation metrics tailored for LLMs in aerospace manufacturing, aiming to assess their accuracy by analyzing their performance in answering questions grounded in professional knowledge. Firstly, key information is extracted through in-depth textual analysis of classic aerospace manufacturing textbooks and guidelines. Subsequently, utilizing LLM generation techniques, we meticulously construct multiple-choice questions with multiple correct answers of varying difficulty. Following this, different LLM models are employed to answer these questions, and their accuracy is recorded. Experimental results demonstrate that the capabilities of LLMs in aerospace professional knowledge are in urgent need of improvement. This study provides a theoretical foundation and practical guidance for the application of LLMs in aerospace manufacturing, addressing a critical gap in the field. 

**Abstract (ZH)**: 航空航天制造对技术参数的要求极为严格。大型语言模型（LLMs），如GPT-4和Qwen，在自然语言处理领域的出色表现引起了业界对其在过程设计、材料选择和工具信息检索等方面应用的兴趣。然而，LLMs在专业领域容易生成“幻觉”，产生不准确或虚假信息，这对航空航天产品质量和飞行安全构成了重大风险。本文针对航空航天制造领域引入了一套专门针对LLMs的评估指标，旨在通过分析模型在基于专业知识问题回答中的表现来评估其准确性。首先，通过对经典航空航天制造教材和指南进行深入文本分析提取关键信息。其次，利用LLM生成技术，精心构建包含多个正确答案的难度不同的多项选择题。随后，使用不同的LLM模型回答这些问题，并记录其准确性。实验结果表明，LLMs在航空航天专业知识方面的能力亟待改善。本研究为LLMs在航空航天制造中的应用提供了理论基础和实践指导，填补了领域内的关键空白。 

---
# Dialogue Systems for Emotional Support via Value Reinforcement 

**Title (ZH)**: 基于价值强化的对话系统在情感支持中的应用 

**Authors**: Juhee Kim, Chunghu Mok, Jisun Lee, Hyang Sook Kim, Yohan Jo  

**Link**: [PDF](https://arxiv.org/pdf/2501.17182)  

**Abstract**: Emotional support dialogue systems aim to reduce help-seekers' distress and help them overcome challenges. While human values$\unicode{x2013}$core beliefs that shape an individual's priorities$\unicode{x2013}$are increasingly emphasized in contemporary psychological therapy for their role in fostering internal transformation and long-term emotional well-being, their integration into emotional support systems remains underexplored. To bridge this gap, we present a value-driven method for training emotional support dialogue systems designed to reinforce positive values in seekers. Our model learns to identify which values to reinforce at each turn and how to do so, by leveraging online support conversations from Reddit. The model demonstrated superior performance in emotional support capabilities, outperforming various baselines. Notably, it more effectively explored and elicited values from seekers. Expert assessments by therapists highlighted two key strengths of our model: its ability to validate users' challenges and its effectiveness in emphasizing positive aspects of their situations$\unicode{x2013}$both crucial elements of value reinforcement. Our work validates the effectiveness of value reinforcement for emotional support systems and establishes a foundation for future research. 

**Abstract (ZH)**: 情感支持对话系统旨在减轻寻求帮助者的情感困扰，并帮助他们克服挑战。随着人类价值观——塑造个人优先事项的核心信念——在当代心理治疗中的作用日益受到重视，这些价值观对于促进内在转变和长期情感健康具有重要作用，但它们在情感支持系统中的整合仍处于未探索状态。为解决这一问题，我们提出了一种以价值观为导向的方法，用于训练情感支持对话系统，以强化寻求者的积极价值观。该模型通过利用来自Reddit的在线支持对话，学习在每次交互中识别哪些价值观需要强化以及如何进行强化。模型在情感支持能力方面表现出色，超过了各种基准模型。值得注意的是，它更有效地探索和引发了寻求者的价值观。治疗师的专业评估指出了我们的模型的两个关键优势：其能够验证用户面临的挑战，以及强调其情况的积极方面——这两者都是价值观强化的关键要素。我们这项工作验证了价值观强化对情感支持系统有效性的有效性，并为未来的研究奠定了基础。 

---
# Tuning LLM Judges Hyperparameters 

**Title (ZH)**: 调整大型语言模型法官的超参数 

**Authors**: David Salinas, Omar Swelam, Frank Hutter  

**Link**: [PDF](https://arxiv.org/pdf/2501.17178)  

**Abstract**: Evaluating Large Language Models (LLMs) often requires costly human annotations. To address this, LLM-based judges have been proposed, which compare the outputs of two LLMs enabling the ranking of models without human intervention. While several approaches have been proposed, many confounding factors are present between different papers. For instance the model, the prompt and other hyperparameters are typically changed at the same time making apple-to-apple comparisons challenging. In this paper, we propose to systematically analyze and tune hyperparameter of LLM judges. To alleviate the high cost of evaluating a judge, we propose to leverage multi-objective multi-fidelity which allows to find judges that trades accuracy for cost and also reduce significantly the cost of the search. Our method identifies judges that not only outperform existing benchmarks in accuracy and cost-efficiency but also utilize open-weight models, ensuring greater accessibility and reproducibility. 

**Abstract (ZH)**: 评估大规模语言模型（LLMs）通常需要昂贵的人工注释。为解决这一问题，提出了基于LLM的裁判方法，这些方法比较两个LLM的输出结果，从而在无需人工干预的情况下对模型进行排序。尽管已经提出了多种方法，但在不同的论文中仍然存在许多混淆因素。例如，模型、提示以及其他超参数通常会同时变化，这使得直接对比变得颇具挑战性。本文中，我们提出了系统地分析和调整LLM裁判的超参数的方法。为了降低评估裁判的成本，我们提出了多目标多精度的方法，这允许在提高准确性的同时降低计算成本，从而显著减少搜索成本。我们的方法不仅识别出在准确性和成本效益方面超越现有基准的裁判，还利用了开源权重模型，确保了更高的可访问性和可复现性。 

---
# Prompt-Based Cost-Effective Evaluation and Operation of ChatGPT as a Computer Programming Teaching Assistant 

**Title (ZH)**: 基于提示的低成本评估与运营ChatGPT作为计算机程序设计辅导助手 

**Authors**: Marc Ballestero-Ribó, Daniel Ortiz-Martínez  

**Link**: [PDF](https://arxiv.org/pdf/2501.17176)  

**Abstract**: The dream of achieving a student-teacher ratio of 1:1 is closer than ever thanks to the emergence of large language models (LLMs). One potential application of these models in the educational field would be to provide feedback to students in university introductory programming courses, so that a student struggling to solve a basic implementation problem could seek help from an LLM available 24/7. This article focuses on studying three aspects related to such an application. First, the performance of two well-known models, GPT-3.5T and GPT-4T, in providing feedback to students is evaluated. The empirical results showed that GPT-4T performs much better than GPT-3.5T, however, it is not yet ready for use in a real-world scenario. This is due to the possibility of generating incorrect information that potential users may not always be able to detect. Second, the article proposes a carefully designed prompt using in-context learning techniques that allows automating important parts of the evaluation process, as well as providing a lower bound for the fraction of feedbacks containing incorrect information, saving time and effort. This was possible because the resulting feedback has a programmatically analyzable structure that incorporates diagnostic information about the LLM's performance in solving the requested task. Third, the article also suggests a possible strategy for implementing a practical learning tool based on LLMs, which is rooted on the proposed prompting techniques. This strategy opens up a whole range of interesting possibilities from a pedagogical perspective. 

**Abstract (ZH)**: 由于大型语言模型（LLMs）的出现，实现师生比1:1的梦想比以往任何时候都更加接近。这些模型在教育领域的潜在应用之一是在大学入门级编程课程中为学生提供反馈。这样，遇到基础实现问题的学生就可以随时寻求24/7可用的语言模型的帮助。本文专注于探讨这种应用的三个方面。首先，评估了两种广为人知的模型——GPT-3.5T和GPT-4T——在为学生提供反馈方面的表现。实证结果显示，GPT-4T的表现远优于GPT-3.5T，但目前还不适合在实际场景中使用。这是因为生成错误信息的可能性导致潜在用户可能无法始终检测到这些错误。其次，本文提出了一种精心设计的提示，利用上下文学习技术，不仅允许自动化评价过程的重要部分，还能提供反馈中包含错误信息比例的下限，从而节省时间和精力。这是因为生成的反馈具有可编程分析的结构，能够反映语言模型在完成指定任务时的表现诊断信息。第三，本文还提出了一种基于语言模型实现实用学习工具的可能策略，该策略基于提出的提示技术。这一策略从教学角度来看，开辟了一系列有趣的可能性。 

---
# Document-Level Sentiment Analysis of Urdu Text Using Deep Learning Techniques 

**Title (ZH)**: 使用深度学习技术的乌尔都语文档级情感分析 

**Authors**: Ammarah Irum, M. Ali Tahir  

**Link**: [PDF](https://arxiv.org/pdf/2501.17175)  

**Abstract**: Document level Urdu Sentiment Analysis (SA) is a challenging Natural Language Processing (NLP) task as it deals with large documents in a resource-poor language. In large documents, there are ample amounts of words that exhibit different viewpoints. Deep learning (DL) models comprise of complex neural network architectures that have the ability to learn diverse features of the data to classify various sentiments. Besides audio, image and video classification; DL algorithms are now extensively used in text-based classification problems. To explore the powerful DL techniques for Urdu SA, we have applied five different DL architectures namely, Bidirectional Long Short Term Memory (BiLSTM), Convolutional Neural Network (CNN), Convolutional Neural Network with Bidirectional Long Short Term Memory (CNN-BiLSTM), Bidirectional Encoder Representation from Transformer (BERT). In this paper, we have proposed a DL hybrid model that integrates BiLSTM with Single Layer Multi Filter Convolutional Neural Network (BiLSTM-SLMFCNN). The proposed and baseline techniques are applied on Urdu Customer Support data set and IMDB Urdu movie review data set by using pretrained Urdu word embeddings that are suitable for (SA) at the document level. Results of these techniques are evaluated and our proposed model outperforms all other DL techniques for Urdu SA. BiLSTM-SLMFCNN outperformed the baseline DL models and achieved 83{\%}, 79{\%}, 83{\%} and 94{\%} accuracy on small, medium and large sized IMDB Urdu movie review data set and Urdu Customer Support data set respectively. 

**Abstract (ZH)**: Urdu 文档级情感分析（SA）是一个具有挑战性的自然语言处理（NLP）任务，因为它涉及到资源匮乏语言中的大型文档。在大型文档中，存在大量表现出不同观点的词汇。深度学习（DL）模型包含复杂的神经网络架构，能够学习数据的多样特征以分类不同的情感。除了音频、图像和视频分类外，DL 算法现在也广泛应用于基于文本的分类问题。为探索强大的DL技术在Urdu SA中的应用，我们应用了五种不同的DL架构，分别是双向长短期记忆（BiLSTM）、卷积神经网络（CNN）、卷积神经网络与双向长短期记忆（CNN-BiLSTM）、双向转换器编码器表示（BERT）。在本文中，我们提出了一种DL混合模型，该模型将双向长短期记忆（BiLSTM）与单层多滤波卷积神经网络（SLMFCNN）结合起来。我们提出了的技术和基线技术均应用于Urdu客户服务数据集和IMDB Urdu电影评论数据集，并使用预训练的适合文档级情感分析（SA）的Urdu词嵌入。这些技术的效果进行了评估，我们提出的模型在Urdu SA方面超过了所有其他DL技术。BiLSTM-SLMFCNN 在IMDB Urdu电影评论数据集（小、中、大型）和Urdu客户服务数据集上的准确率分别为83%、79%、83%和94%。 

---
# Extractive Schema Linking for Text-to-SQL 

**Title (ZH)**: 文本到SQL的提取式模式链接 

**Authors**: Michael Glass, Mustafa Eyceoz, Dharmashankar Subramanian, Gaetano Rossiello, Long Vu, Alfio Gliozzo  

**Link**: [PDF](https://arxiv.org/pdf/2501.17174)  

**Abstract**: Text-to-SQL is emerging as a practical interface for real world databases. The dominant paradigm for Text-to-SQL is cross-database or schema-independent, supporting application schemas unseen during training. The schema of a database defines the tables, columns, column types and foreign key connections between tables. Real world schemas can be large, containing hundreds of columns, but for any particular query only a small fraction will be relevant. Placing the entire schema in the prompt for an LLM can be impossible for models with smaller token windows and expensive even when the context window is large enough to allow it. Even apart from computational considerations, the accuracy of the model can be improved by focusing the SQL generation on only the relevant portion of the database. Schema linking identifies the portion of the database schema useful for the question. Previous work on schema linking has used graph neural networks, generative LLMs, and cross encoder classifiers. We introduce a new approach to adapt decoder-only LLMs to schema linking that is both computationally more efficient and more accurate than the generative approach. Additionally our extractive approach permits fine-grained control over the precision-recall trade-off for schema linking. 

**Abstract (ZH)**: 将文本转换为SQL查询正在成为现实世界数据库的实际接口。当前主流的文本到SQL查询范式是跨数据库或无模式依赖的，能够在训练中不涉及具体应用程序模式的情况下支持未知的应用程序模式。数据库的模式定义了表、列、列类型以及表之间的外键连接。现实世界的模式可以非常庞大，包含数百个列，但对任何特定查询来说，只有一小部分列是相关的。将整个模式放入提示中，对于具有较小标记窗口的模型来说可能是不可能的，即使在标记窗口足够大可以容纳整个模式的情况下，这样做也可能非常昂贵。除了从计算角度来看，通过聚焦于数据库的相关部分来生成SQL查询可以提高模型的准确性。模式链接（Schema Linking）是确定数据库模式中对问题有用的那部分。先前的研究中，模式链接使用了图神经网络、生成型语言模型（LLM）和交叉编码器分类器。我们引入了一种新的方法，将仅解码器的LLM适应于模式链接，这种方法在计算效率和准确性方面都优于生成型方法。此外，我们提出的方法还允许对模式链接的精确召回权衡进行精细控制。 

---
# Separated Inter/Intra-Modal Fusion Prompts for Compositional Zero-Shot Learning 

**Title (ZH)**: 分离的跨模态/同模态融合提示用于组合零样本学习 

**Authors**: Sua Jung  

**Link**: [PDF](https://arxiv.org/pdf/2501.17171)  

**Abstract**: Compositional Zero-Shot Learning (CZSL) aims to recognize subtle differences in meaning or the combination of states and objects through the use of known and unknown concepts during training. Existing methods either focused on prompt configuration or on using prompts to tune the pre-trained Vision-Language model. However, these methods faced challenges in accurately identifying subtle differences in meaning or combining states with objects. To jointly eradicate the above issues and construct an efficient and effective CZSL technique, we suggest a method to improve attribute recognition performance by utilizing diverse Prompt Learning with an Inter/Intra-Modality Fusion Synthesizer in scene understanding involving subtle semantic differences and multiple objects. 

**Abstract (ZH)**: 组合零样本学习（CZSL）旨在通过在训练过程中利用已知和未知概念来识别意义上的细微差别或状态与对象的组合差异。现有方法要么侧重于提示配置，要么利用提示调整预训练的视觉-语言模型。然而，这些方法在准确识别意义上的细微差别或组合状态与对象方面遇到了挑战。为了共同解决上述问题并构建一种高效且有效的CZSL技术，我们建议利用具有跨模态/同模态融合合成器的多样化提示学习方法，以场景理解中涉及细微语义差异和多种物体的属性识别性能提升为目的。 

---
# Benchmarking Randomized Optimization Algorithms on Binary, Permutation, and Combinatorial Problem Landscapes 

**Title (ZH)**: 将下列论文的内容或标题翻译成中文，符合学术规范：

Benchmarking 随机优化算法在二进制、排列和组合问题景观上的性能

完整的翻译为：

《在二进制、排列和组合问题景观上Benchmark随机优化算法的性能》 

**Authors**: Jethro Odeyemi, Wenjun Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2501.17170)  

**Abstract**: In this paper, we evaluate the performance of four randomized optimization algorithms: Randomized Hill Climbing (RHC), Simulated Annealing (SA), Genetic Algorithms (GA), and MIMIC (Mutual Information Maximizing Input Clustering), across three distinct types of problems: binary, permutation, and combinatorial. We systematically compare these algorithms using a set of benchmark fitness functions that highlight the specific challenges and requirements of each problem category. Our study analyzes each algorithm's effectiveness based on key performance metrics, including solution quality, convergence speed, computational cost, and robustness. Results show that while MIMIC and GA excel in producing high-quality solutions for binary and combinatorial problems, their computational demands vary significantly. RHC and SA, while computationally less expensive, demonstrate limited performance in complex problem landscapes. The findings offer valuable insights into the trade-offs between different optimization strategies and provide practical guidance for selecting the appropriate algorithm based on the type of problems, accuracy requirements, and computational constraints. 

**Abstract (ZH)**: 在本文中，我们评估了四种随机优化算法在三种不同类型的优化问题中的性能：随机爬山法（RHC）、模拟退火法（SA）、遗传算法（GA）和MIMIC（互信息最大化输入聚类）。我们使用一组基准fitness函数，针对每种问题类别中的特定挑战和要求进行了系统性的比较。研究基于关键性能指标（如解的质量、收敛速度、计算成本和鲁棒性）分析了每种算法的有效性。结果表明，MIMIC和GA在二进制和组合问题中能够产生高质量的解，但它们的计算需求差异显著。相比之下，RHC和SA虽然计算成本较低，但在复杂问题环境中表现出有限的效果。这些发现为我们提供了不同优化策略之间的权衡关系的理解，并提供了根据问题类型、精度要求和计算约束选择适当算法的实用指导。 

---
# EvoGP: A GPU-accelerated Framework for Tree-Based Genetic Programming 

**Title (ZH)**: EvoGP：一种基于GPU加速的树型遗传编程框架 

**Authors**: Lishuang Wang, Zhihong Wu, Kebin Sun, Zhuozhao Li, Ran Cheng  

**Link**: [PDF](https://arxiv.org/pdf/2501.17168)  

**Abstract**: Tree-based Genetic Programming (TGP) is a key evolutionary algorithm widely used in symbolic regression, feature engineering, and scientific modeling. Its high computational demands make GPU acceleration essential for scalable and high-performance evolutionary computation. However, GPU acceleration of TGP faces three key challenges: inefficient tree encoding, highly heterogeneous genetic operations, and limited parallelism in fitness evaluation. To address these challenges, we introduce EvoGP, a comprehensive GPU-accelerated TGP framework. First, we design a tensorized encoding scheme to represent tree with different structures as tensors with the same shape, optimizing memory access and enabling efficient parallel execution. Second, we propose a unified parallel framework for genetic operations by leveraging shared computational primitives and implementing dedicated CUDA kernels for scalable performance. Third, we present a fully parallel fitness evaluation strategy for symbolic regression, exploiting both population-level and data-level parallelism to maximize GPU utilization. Moreover, we implement a comprehensive library to provide rich algorithm operators and benchmark problems. EvoGP is extensively tested on various tasks, including symbolic regression, classification, and robotics control, demonstrating its versatility and effectiveness across diverse application scenarios. Experimental results show that EvoGP achieves up to a 140.89x speedup over the state-of-the-art GPU-based TGP implementation, while maintaining or exceeding the accuracy of baseline methods. EvoGP is open-source and accessible at: this https URL. 

**Abstract (ZH)**: 基于树的遗传编程（TGP）是一种广泛应用于符号回归、特征工程和科学建模的关键进化算法。由于其对计算能力的高需求，使用GPU加速对于实现可扩展的高性能进化计算是必不可少的。然而，GPU加速TGP面临三大挑战：低效的树编码、高度异构的遗传操作以及适应性评估中的有限并行性。为了解决这些挑战，我们提出了EvoGP，一个全面的GPU加速TGP框架。首先，我们设计了一个张量化的编码方案，将具有不同结构的树表示为具有相同形状的张量，优化了内存访问并实现了高效的并行执行。其次，我们提出了一种统一的并行框架来实现遗传操作，通过利用共享计算原语并为可扩展性能实现特定的CUDA内核。第三，我们提出了一种全面的并行适应性评估策略，用于符号回归，通过同时探索群体级和数据级并行性来最大化GPU的利用效率。此外，我们实现了一个综合库，提供了丰富的算法操作和基准问题。EvoGP已在多种任务中进行了广泛测试，包括符号回归、分类和机器人控制，展示了其在多种应用场景中的通用性和有效性。实验结果表明，EvoGP相比当前最先进的GPU加速TGP实现可实现高达140.89倍的加速，同时保持或超越基线方法的准确性。EvoGP开源并可从以下链接访问：this https URL。 

---
# QualityFlow: An Agentic Workflow for Program Synthesis Controlled by LLM Quality Checks 

**Title (ZH)**: QualityFlow：由LLM质量检查控制的代理工作流程程序合成 

**Authors**: Yaojie Hu, Qiang Zhou, Qihong Chen, Xiaopeng Li, Linbo Liu, Dejiao Zhang, Amit Kachroo, Talha Oz, Omer Tripp  

**Link**: [PDF](https://arxiv.org/pdf/2501.17167)  

**Abstract**: We introduce QualityFlow, a dynamic agentic workflow for program synthesis. Given the English description of a programming problem and a set of unit tests, the model's goal is to synthesize the correct program that solves the problem and passes the tests. QualityFlow consists of multiple large language model (LLM) agents that resemble a software development team, including code generation, testing, and self-debugging. Existing program synthesis methods face three major limitations: assumption of visible unit test conformity, bottleneck of synthesized test quality, and deviation of self-debugging trajectory. To address them, we propose the LLM Quality Checker, which explicitly "imagines" whether the synthesized programs' execution would conform to the unit tests. The Quality Checks dynamically control the workflow, including actions to submit the final answer, clarify the problem statement, and revert previous workflow steps. As a result, our Quality Checker can precisely accept any correct program, mitigate faulty synthesized tests, and prevent potential workflow deviation. The success of the Quality Checker further enables Diversified Prompting, which encourages variations in LLM responses to maximize the possibility that a correct program appears and passes the quality check. In experiments, QualityFlow establishes the state-of-the-art results on four program synthesis benchmarks: MBPP, HumanEval, and the stricter evaluations of both MBPP and HumanEval from EvalPlus. Our systematic analysis shows that the dynamic workflow controlled by LLM quality checks can outperform static workflows and single-attempt zero-shot synthesis. The Quality Checker is the center of our investigation, and we dissect its individual performance and integrated impact on the workflow accuracy, as well as other ablations experiments to justify our workflow design. 

**Abstract (ZH)**: 我们引入了QualityFlow，这是一种动态代理工作流，用于程序合成。给定编程问题的英文描述和一组单元测试，模型的目标是合成正确的程序以解决问题并通过这些测试。QualityFlow 包含多个大的语言模型（LLM）代理，这些代理类似于软件开发团队，包括代码生成、测试和自我调试。现有的程序合成方法面临三大限制：单元测试一致性可见性的假设、合成测试质量的瓶颈以及自我调试轨迹的偏差。为了解决这些问题，我们提出了一种LLM质量检查器，明确“设想”合成的程序执行是否符合单元测试。质量检查动态控制工作流程，包括提交最终答案、澄清问题描述以及回滚先前的工作流程步骤。因此，我们的质量检查器可以精确接受任何正确的程序，减轻错误的合成测试，并防止潜在的工作流程偏移。质量检查的成功进一步使多样化提示成为可能，鼓励LLM响应的变化以最大化正确程序出现并通过质量检查的可能性。在实验中，QualityFlow 在四个程序合成基准测试（MBPP、HumanEval 及从EvalPlus的更严格的评估）中达到了最先进的结果。我们的系统分析表明，由LLM质量检查控制的动态工作流程可以优于静态工作流程和单一尝试的零次合成。质量检查器是我们研究的核心，我们剖析了其单独的性能和综合影响对工作流程准确性的影响，并进行了其他消融实验以证明我们的工作流程设计的有效性。 

---
# Split Knowledge Distillation for Large Models in IoT: Architecture, Challenges, and Solutions 

**Title (ZH)**: 物联网中大模型的知识分割蒸馏：架构、挑战与解决方案 

**Authors**: Zuguang Li, Wen Wu, Shaohua Wu, Qiaohua Lin, Yaping Sun, Hui Wang  

**Link**: [PDF](https://arxiv.org/pdf/2501.17164)  

**Abstract**: Large models (LMs) have immense potential in Internet of Things (IoT) systems, enabling applications such as intelligent voice assistants, predictive maintenance, and healthcare monitoring. However, training LMs on edge servers raises data privacy concerns, while deploying them directly on IoT devices is constrained by limited computational and memory resources. We analyze the key challenges of training LMs in IoT systems, including energy constraints, latency requirements, and device heterogeneity, and propose potential solutions such as dynamic resource management, adaptive model partitioning, and clustered collaborative training. Furthermore, we propose a split knowledge distillation framework to efficiently distill LMs into smaller, deployable versions for IoT devices while ensuring raw data remains local. This framework integrates knowledge distillation and split learning to minimize energy consumption and meet low model training delay requirements. A case study is presented to evaluate the feasibility and performance of the proposed framework. 

**Abstract (ZH)**: 大型模型（LMs）在物联网（IoT）系统中具有巨大的潜力，能够支持智能语音助手、预测性维护和健康管理等应用。然而，在边缘服务器上训练LMs会引发数据隐私问题，而将LMs直接部署到物联网设备上则受到有限计算能力和内存资源的限制。我们分析了在物联网系统中训练LMs所面临的几个关键挑战，包括能量限制、延迟要求以及设备异构性，并提出了相应的潜在解决方案，如动态资源管理、自适应模型分区和集群协作训练。此外，我们提出了一种分割知识蒸馏框架，以高效地将LMs压缩成更小、更易于部署的版本，同时确保原始数据保持本地存储。该框架结合了知识蒸馏和分割学习，以减少能量消耗并满足低模型训练延迟的要求。我们还进行了案例研究，以评估所提出的框架的可行性和性能。 

---
