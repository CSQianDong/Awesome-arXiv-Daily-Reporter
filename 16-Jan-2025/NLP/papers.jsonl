{'arxiv_id': 'arXiv:2501.09004', 'title': 'Aegis2.0: A Diverse AI Safety Dataset and Risks Taxonomy for Alignment of LLM Guardrails', 'authors': 'Shaona Ghosh, Prasoon Varshney, Makesh Narsimhan Sreedhar, Aishwarya Padmakumar, Traian Rebedea, Jibin Rajan Varghese, Christopher Parisien', 'link': 'https://arxiv.org/abs/2501.09004', 'abstract': 'As Large Language Models (LLMs) and generative AI become increasingly widespread, concerns about content safety have grown in parallel. Currently, there is a clear lack of high-quality, human-annotated datasets that address the full spectrum of LLM-related safety risks and are usable for commercial applications. To bridge this gap, we propose a comprehensive and adaptable taxonomy for categorizing safety risks, structured into 12 top-level hazard categories with an extension to 9 fine-grained subcategories. This taxonomy is designed to meet the diverse requirements of downstream users, offering more granular and flexible tools for managing various risk types. Using a hybrid data generation pipeline that combines human annotations with a multi-LLM "jury" system to assess the safety of responses, we obtain Aegis 2.0, a carefully curated collection of 34,248 samples of human-LLM interactions, annotated according to our proposed taxonomy. To validate its effectiveness, we demonstrate that several lightweight models, trained using parameter-efficient techniques on Aegis 2.0, achieve performance competitive with leading safety models fully fine-tuned on much larger, non-commercial datasets. In addition, we introduce a novel training blend that combines safety with topic following this http URL approach enhances the adaptability of guard models, enabling them to generalize to new risk categories defined during inference. We plan to open-source Aegis 2.0 data and models to the research community to aid in the safety guardrailing of LLMs.', 'abstract_zh': '随着大型语言模型（LLMs）和生成性AI的日益普及，内容安全性问题也得到了同步的关注。目前，缺乏高质量的人工标注数据集来全面应对LLM相关安全风险，并且这些数据集不适用于商业应用。为了解决这一问题，我们提出了一种全面且灵活的分类体系，将其划分为12个高层风险类别，并进一步细分为9个子类别。该分类体系旨在满足下游用户的多样化需求，提供更精细和灵活的风险管理工具。通过结合人工标注和多LLM“陪审团”系统来评估响应的安全性，我们构建了一个混合式数据生成管道。基于此，我们获得了Aegis 2.0，一个精心筛选的包含34,248个人-LLM交互样本的数据集，并按照我们提出的分类体系进行了标注。为了验证其有效性，我们证明了使用参数高效技术训练于Aegis 2.0上的几个轻量级模型，其性能可与在更大规模的非商业数据集上完全微调的领先安全模型相匹敌。此外，我们还引入了一种新的训练混合方法，将安全性与主题一致性相结合，这种方法通过使保护模型更具适应性，使其能够推广到在推理过程中定义的新风险类别。我们计划将Aegis 2.0数据和模型开源给研究社区，以协助LLM的安全监控。', 'title_zh': 'Aegis2.0：多样性AI安全数据集及风险分类体系，用于LLM护栏的对齐'}
{'arxiv_id': 'arXiv:2501.08985', 'title': 'Personality Modeling for Persuasion of Misinformation using AI Agent', 'authors': 'Qianmin Lou, Wentao Xu', 'link': 'https://arxiv.org/abs/2501.08985', 'abstract': 'The proliferation of misinformation on social media platforms has highlighted the need to understand how individual personality traits influence susceptibility to and propagation of misinformation. This study employs an innovative agent-based modeling approach to investigate the relationship between personality traits and misinformation dynamics. Using six AI agents embodying different dimensions of the Big Five personality traits (Extraversion, Agreeableness, and Neuroticism), we simulated interactions across six diverse misinformation topics. The experiment, implemented through the AgentScope framework using the GLM-4-Flash model, generated 90 unique interactions, revealing complex patterns in how personality combinations affect persuasion and resistance to misinformation. Our findings demonstrate that analytical and critical personality traits enhance effectiveness in evidence-based discussions, while non-aggressive persuasion strategies show unexpected success in misinformation correction. Notably, agents with critical traits achieved a 59.4% success rate in HIV-related misinformation discussions, while those employing non-aggressive approaches maintained consistent persuasion rates above 40% across different personality combinations. The study also revealed a non-transitive pattern in persuasion effectiveness, challenging conventional assumptions about personality-based influence. These results provide crucial insights for developing personality-aware interventions in digital environments and suggest that effective misinformation countermeasures should prioritize emotional connection and trust-building over confrontational approaches. The findings contribute to both theoretical understanding of personality-misinformation dynamics and practical strategies for combating misinformation in social media contexts.', 'abstract_zh': '社交媒体平台上虚假信息的泛滥凸显了理解个体人格特质如何影响虚假信息的易感性和传播的重要性。本研究采用了创新性的基于代理的建模方法，探讨了人格特质与虚假信息动态之间的关系。通过使用六个人工智能代理，代表五大人格特质的不同维度（外向性、宜人性和神经质），我们在六个不同的虚假信息主题上模拟了交互过程。实验基于AgentScope框架，并使用GLM-4-Flash模型实施，生成了90种独特的交互方式，揭示了人格特质组合如何影响说服力和对虚假信息的抵抗力的复杂模式。研究结果表明，分析性和批判性的人格特质能够增强基于证据的讨论的效果，而非侵略性的说服策略在纠正虚假信息方面显示出意想不到的成功。值得注意的是，具有批判性特质的代理在与艾滋病相关的虚假信息讨论中成功率达到59.4%，而采取非侵略性策略的代理在不同人格组合下的说服率维持在40%以上。研究还揭示了说服力效果的非传递性模式，挑战了基于人格影响的常规假设。这些结果对于在数字环境中开发人格意识干预措施至关重要，并表明有效的虚假信息应对策略应优先考虑情感联系和信任建设，而不是对抗性方法。研究成果不仅深化了对人格与虚假信息动态的理解，还为社交媒体环境中打击虚假信息的实际策略提供了指导。', 'title_zh': '使用AI代理进行反 misinformation 说服力建模'}
{'arxiv_id': 'arXiv:2501.08974', 'title': 'Learning to Extract Cross-Domain Aspects and Understanding Sentiments Using Large Language Models', 'authors': 'Karukriti Kaushik Ghosh, Chiranjib Sur', 'link': 'https://arxiv.org/abs/2501.08974', 'abstract': 'Aspect-based sentiment analysis (ASBA) is a refined approach to sentiment analysis that aims to extract and classify sentiments based on specific aspects or features of a product, service, or entity. Unlike traditional sentiment analysis, which assigns a general sentiment score to entire reviews or texts, ABSA focuses on breaking down the text into individual components or aspects (e.g., quality, price, service) and evaluating the sentiment towards each. This allows for a more granular level of understanding of customer opinions, enabling businesses to pinpoint specific areas of strength and improvement. The process involves several key steps, including aspect extraction, sentiment classification, and aspect-level sentiment aggregation for a review paragraph or any other form that the users have provided. ABSA has significant applications in areas such as product reviews, social media monitoring, customer feedback analysis, and market research. By leveraging techniques from natural language processing (NLP) and machine learning, ABSA facilitates the extraction of valuable insights, enabling companies to make data-driven decisions that enhance customer satisfaction and optimize offerings. As ABSA evolves, it holds the potential to greatly improve personalized customer experiences by providing a deeper understanding of sentiment across various product aspects. In this work, we have analyzed the strength of LLMs for a complete cross-domain aspect-based sentiment analysis with the aim of defining the framework for certain products and using it for other similar situations. We argue that it is possible to that at an effectiveness of 92\\% accuracy for the Aspect Based Sentiment Analysis dataset of SemEval-2015 Task 12.', 'abstract_zh': '基于方面的情感分析（Aspect-Based Sentiment Analysis，ABSA）是一种细化的情感分析方法，旨在根据产品、服务或实体的具体方面或特征提取和分类情感。与传统的情感分析不同，后者通常会为整个评论或文本分配一个总体情感评分，ABSA则致力于将文本分解为单独的组成部分或方面（例如，质量、价格、服务），并针对每个方面评估情感。这种做法可以让企业更具体地了解客户意见，使他们能够识别出产品优势和需要改进的具体领域。该过程包括几个关键步骤，如方面提取、情感分类和基于方面的情感聚合，以分析整段评论或用户提供的任何其他形式的文本。ABSA在产品评论、社交媒体监控、客户反馈分析和市场研究等领域具有广泛的应用前景。通过利用自然语言处理（NLP）和机器学习技术，ABSA有助于提取有价值的洞察，从而帮助企业做出数据驱动的决策，提高客户满意度并优化产品。随着ABSA的发展，它有可能通过提供对各种产品方面情感的更深入理解，极大地提升个性化客户体验。在本研究中，我们分析了大语言模型（LLMs）在跨领域方面情感分析中的能力，以期定义某种产品的框架并应用于其他类似情况。我们认为，在SemEval-2015 Task 12 的方面情感分析数据集上，LLMs可以达到92%的准确率。', 'title_zh': '使用大型语言模型学习提取跨域方面并理解情感'}
{'arxiv_id': 'arXiv:2501.08946', 'title': 'Applying General Turn-taking Models to Conversational Human-Robot Interaction', 'authors': 'Gabriel Skantze, Bahar Irfan', 'link': 'https://arxiv.org/abs/2501.08946', 'abstract': 'Turn-taking is a fundamental aspect of conversation, but current Human-Robot Interaction (HRI) systems often rely on simplistic, silence-based models, leading to unnatural pauses and interruptions. This paper investigates, for the first time, the application of general turn-taking models, specifically TurnGPT and Voice Activity Projection (VAP), to improve conversational dynamics in HRI. These models are trained on human-human dialogue data using self-supervised learning objectives, without requiring domain-specific fine-tuning. We propose methods for using these models in tandem to predict when a robot should begin preparing responses, take turns, and handle potential interruptions. We evaluated the proposed system in a within-subject study against a traditional baseline system, using the Furhat robot with 39 adults in a conversational setting, in combination with a large language model for autonomous response generation. The results show that participants significantly prefer the proposed system, and it significantly reduces response delays and interruptions.', 'abstract_zh': '轮流发言是对话中一个基本的方面，但当前的人机交互（HRI）系统往往依赖于基于简单静默的模型，导致不自然的停顿和打断。本文首次研究了通用轮流发言模型——TurnGPT和语音活动投影（VAP）在改善HRI中对话动态的应用。这些模型利用自我监督学习目标在人类-人类对话数据上进行训练，无需特定领域的微调。我们提出了一种方法，将这些模型结合起来使用，以预测机器人何时应开始准备回应、轮转以及处理潜在的打断。我们在一项针对39名成人的单被试研究中评估了提议的系统，使用了Furhat机器人和一个大型语言模型来自动生成响应，与传统的基线系统进行了对比。结果显示，参与者明显更偏好提议的系统，并且该系统显著减少了响应延迟和打断。', 'title_zh': '将通用对话轮换模型应用于人机对话交互'}
{'arxiv_id': 'arXiv:2501.08913', 'title': 'GenAI Content Detection Task 3: Cross-Domain Machine-Generated Text Detection Challenge', 'authors': 'Liam Dugan, Andrew Zhu, Firoj Alam, Preslav Nakov, Marianna Apidianaki, Chris Callison-Burch', 'link': 'https://arxiv.org/abs/2501.08913', 'abstract': 'Recently there have been many shared tasks targeting the detection of generated text from Large Language Models (LLMs). However, these shared tasks tend to focus either on cases where text is limited to one particular domain or cases where text can be from many domains, some of which may not be seen during test time. In this shared task, using the newly released RAID benchmark, we aim to answer whether or not models can detect generated text from a large, yet fixed, number of domains and LLMs, all of which are seen during training. Over the course of three months, our task was attempted by 9 teams with 23 detector submissions. We find that multiple participants were able to obtain accuracies of over 99% on machine-generated text from RAID while maintaining a 5% False Positive Rate -- suggesting that detectors are able to robustly detect text from many domains and models simultaneously. We discuss potential interpretations of this result and provide directions for future research.', 'abstract_zh': '近年来，针对大规模语言模型（LLMs）生成文本检测的共享任务日益增多。然而，这些共享任务通常要么仅限于特定领域的文本检测，要么涉及多个领域，但其中一些领域在测试时可能未见过。在本共享任务中，我们利用新发布的RAID基准，旨在评估模型是否能够检测来自大量（且固定）领域和LLM生成的文本，所有这些领域均在训练期间见过。在三个月的时间里，有9个团队提交了23个检测器，参与了我们的任务。我们发现，多个参与者在RAID生成的文本上获得了超过99%的准确率，同时保持了5%的误报率——这表明检测器能够在多个领域和模型的同时实现稳健检测。我们讨论了这一结果的潜在解释，并为未来研究提供了方向。', 'title_zh': 'GenAI内容检测任务3：跨域机器生成文本检测挑战'}
{'arxiv_id': 'arXiv:2501.08838', 'title': 'ToMATO: Verbalizing the Mental States of Role-Playing LLMs for Benchmarking Theory of Mind', 'authors': 'Kazutoshi Shinoda, Nobukatsu Hojo, Kyosuke Nishida, Saki Mizuno, Keita Suzuki, Ryo Masumura, Hiroaki Sugiyama, Kuniko Saito', 'link': 'https://arxiv.org/abs/2501.08838', 'abstract': 'Existing Theory of Mind (ToM) benchmarks diverge from real-world scenarios in three aspects: 1) they assess a limited range of mental states such as beliefs, 2) false beliefs are not comprehensively explored, and 3) the diverse personality traits of characters are overlooked. To address these challenges, we introduce ToMATO, a new ToM benchmark formulated as multiple-choice QA over conversations. ToMATO is generated via LLM-LLM conversations featuring information asymmetry. By employing a prompting method that requires role-playing LLMs to verbalize their thoughts before each utterance, we capture both first- and second-order mental states across five categories: belief, intention, desire, emotion, and knowledge. These verbalized thoughts serve as answers to questions designed to assess the mental states of characters within conversations. Furthermore, the information asymmetry introduced by hiding thoughts from others induces the generation of false beliefs about various mental states. Assigning distinct personality traits to LLMs further diversifies both utterances and thoughts. ToMATO consists of 5.4k questions, 753 conversations, and 15 personality trait patterns. Our analysis shows that this dataset construction approach frequently generates false beliefs due to the information asymmetry between role-playing LLMs, and effectively reflects diverse personalities. We evaluate nine LLMs on ToMATO and find that even GPT-4o mini lags behind human performance, especially in understanding false beliefs, and lacks robustness to various personality traits.', 'abstract_zh': '现有的理论心智（Theory of Mind, ToM）基准在三个方面与现实世界场景存在差异：1）它们仅评估有限范围的心理状态，如信念；2）虚假信念没有得到全面探讨；3）角色的多样人格特质被忽略。为应对这些挑战，我们引入了ToMATO，这是一种新的ToM基准，通过对话中的多项选择题形式构建。ToMATO 通过包含信息不对称的LLM-LLM对话生成。通过采用一种提示方法，要求每个对话前的LLM先行表达其想法，从而捕捉到涵盖五个类别（信念、意图、欲望、情感和知识）的第一层次和第二层次心理状态。这些表达的想法作为评估对话中角色心理状态的问题的答案。此外，通过隐藏角色的想法来引入信息不对称，从而生成关于各种心理状态的虚假信念。为LLM分配不同的个性特征进一步增加了言语和想法的多样性。ToMATO 包含 5400 个问题、753 次对话和 15 种个性特征模式。我们的分析表明，由于角色扮演的LLM之间存在信息不对称，这种数据集构建方法经常生成虚假信念，并有效反映了多样的人格特质。我们对 ToMATO 进行了九种LLM的评估，发现即使GPT-4o mini 的表现也落后于人类，特别是在理解虚假信念方面，并且在应对各种个性特征方面缺乏鲁棒性。', 'title_zh': 'ToMATO：角色扮演大语言模型心理状态的语言化表达及其理论心智基准测试'}
{'arxiv_id': 'arXiv:2501.08769', 'title': 'Enhanced Large Language Models for Effective Screening of Depression and Anxiety', 'authors': 'June M. Liu, Mengxia Gao, Sahand Sabour, Zhuang Chen, Minlie Huang, Tatia M.C. Lee', 'link': 'https://arxiv.org/abs/2501.08769', 'abstract': 'Depressive and anxiety disorders are widespread, necessitating timely identification and management. Recent advances in Large Language Models (LLMs) offer potential solutions, yet high costs and ethical concerns about training data remain challenges. This paper introduces a pipeline for synthesizing clinical interviews, resulting in 1,157 interactive dialogues (PsyInterview), and presents EmoScan, an LLM-based emotional disorder screening system. EmoScan distinguishes between coarse (e.g., anxiety or depressive disorders) and fine disorders (e.g., major depressive disorders) and conducts high-quality interviews. Evaluations showed that EmoScan exceeded the performance of base models and other LLMs like GPT-4 in screening emotional disorders (F1-score=0.7467). It also delivers superior explanations (BERTScore=0.9408) and demonstrates robust generalizability (F1-score of 0.67 on an external dataset). Furthermore, EmoScan outperforms baselines in interviewing skills, as validated by automated ratings and human evaluations. This work highlights the importance of scalable data-generative pipelines for developing effective mental health LLM tools.', 'abstract_zh': '抑郁和焦虑障碍十分普遍，亟需及时的识别和管理。近期大型语言模型（LLMs）的进步提供了潜在的解决方案，但其高昂的成本和训练数据的伦理问题仍然是挑战。本文介绍了一种合成临床访谈的基础管道，生成了1,157份交互对话（PsyInterview），并提出了一种基于LLM的情绪障碍筛查系统——EmoScan。EmoScan能够区分粗略的情绪障碍（如焦虑或抑郁障碍）和精细的情绪障碍（如重度抑郁障碍），并进行高质量的访谈。评估结果显示，EmoScan在筛查情绪障碍方面的性能超过了基础模型和其他LLM（如GPT-4）（F1分数=0.7467）。此外，EmoScan还提供优质的解释（BERTScore=0.9408），并展示了强大的泛化能力（在外数据集上的F1分数为0.67）。此外，EmoScan在访谈能力方面也优于基准模型，这一点通过自动评分和人工评价得到了验证。本研究强调了开发有效心理健康LLM工具时构建可扩展的数据生成管道的重要性。', 'title_zh': '增强的大语言模型在有效筛查抑郁和焦虑中的应用'}
{'arxiv_id': 'arXiv:2501.08758', 'title': 'Expanding Vietnamese SentiWordNet to Improve Performance of Vietnamese Sentiment Analysis Models', 'authors': 'Hong-Viet Tran, Van-Tan Bui, Lam-Quan Tran', 'link': 'https://arxiv.org/abs/2501.08758', 'abstract': 'Sentiment analysis is one of the most crucial tasks in Natural Language Processing (NLP), involving the training of machine learning models to classify text based on the polarity of opinions. Pre-trained Language Models (PLMs) can be applied to downstream tasks through fine-tuning, eliminating the need to train the model from scratch. Specifically, PLMs have been employed for Sentiment Analysis, a process that involves detecting, analyzing, and extracting the polarity of text sentiments. Numerous models have been proposed to address this task, with pre-trained PhoBERT-V2 models standing out as the state-of-the-art language models for Vietnamese. The PhoBERT-V2 pre-training approach is based on RoBERTa, optimizing the BERT pre-training method for more robust performance. In this paper, we introduce a novel approach that combines PhoBERT-V2 and SentiWordnet for Sentiment Analysis of Vietnamese reviews. Our proposed model utilizes PhoBERT-V2 for Vietnamese, offering a robust optimization for the prominent BERT model in the context of Vietnamese language, and leverages SentiWordNet, a lexical resource explicitly designed to support sentiment classification applications. Experimental results on the VLSP 2016 and AIVIVN 2019 datasets demonstrate that our sentiment analysis system has achieved excellent performance in comparison to other models.', 'abstract_zh': '情感分析是自然语言处理（NLP）中最为关键的任务之一，涉及训练机器学习模型以根据意见的极性对文本进行分类。预训练语言模型（PLMs）可以通过微调应用于下游任务，从而消除从零开始训练模型的需要。具体地，PLMs 已被应用于情感分析，这一过程涉及检测、分析和提取文本情感的极性。众多模型被提出以解决这一任务，其中预训练的 PhoBERT-V2 模型已成为越南语的最新语言模型。PhoBERT-V2 的预训练方法基于 RoBERTa，旨在优化 BERT 的预训练方法以实现更稳健的表现。在本文中，我们介绍了一种新的方法，结合了 PhoBERT-V2 和 SentiWordnet 用于越南语评论的情感分析。我们提出的模型利用 PhoBERT-V2 专门为越南语进行了优化，提供了一种针对越南语这一背景下的 BERT 模型的稳健优化，并利用 SentiWordNet，这是一个专门为支持情感分类应用而设计的词汇资源。在 VLSP 2016 和 AIVIVN 2019 数据集上的实验结果表明，我们的情感分析系统在与其他模型相比时表现优异。', 'title_zh': '将越南语SentiWordNet扩展以提高越南语情感分析模型的性能'}
{'arxiv_id': 'arXiv:2501.08716', 'title': 'The Inherent Limits of Pretrained LLMs: The Unexpected Convergence of Instruction Tuning and In-Context Learning Capabilities', 'authors': 'Irina Bigoulaeva, Harish Tayyar Madabushi, Iryna Gurevych', 'link': 'https://arxiv.org/abs/2501.08716', 'abstract': 'Large Language Models (LLMs), trained on extensive web-scale corpora, have demonstrated remarkable abilities across diverse tasks, especially as they are scaled up. Nevertheless, even state-of-the-art models struggle in certain cases, sometimes failing at problems solvable by young children, indicating that traditional notions of task complexity are insufficient for explaining LLM capabilities. However, exploring LLM capabilities is complicated by the fact that most widely-used models are also "instruction-tuned" to respond appropriately to prompts. With the goal of disentangling the factors influencing LLM performance, we investigate whether instruction-tuned models possess fundamentally different capabilities from base models that are prompted using in-context examples. Through extensive experiments across various model families, scales and task types, which included instruction tuning 90 different LLMs, we demonstrate that the performance of instruction-tuned models is significantly correlated with the in-context performance of their base counterparts. By clarifying what instruction-tuning contributes, we extend prior research into in-context learning, which suggests that base models use priors from pretraining data to solve tasks. Specifically, we extend this understanding to instruction-tuned models, suggesting that their pretraining data similarly sets a limiting boundary on the tasks they can solve, with the added influence of the instruction-tuning dataset.', 'abstract_zh': '大规模语言模型（LLMs），基于广泛网络规模的数据集进行训练，在多种任务上展现了显著的能力，尤其是在模型扩展时更为突出。然而，即使是最先进的模型在某些情况下也会遇到困难，有时甚至在年轻人能够解决的问题上表现失败，这表明传统的任务复杂度概念不足以解释LLM的能力。然而，探索LLM能力受到广泛使用的模型多为“指令微调”以适当地响应提示这一事实的困扰。为了剖析影响LLM性能的因素，我们研究了指令微调模型是否与仅通过上下文示例进行提示的基模型在根本上具有不同的能力。通过在各种模型家族、规模和任务类型下进行广泛的实验，包括对90种不同的LLM进行指令微调，我们证明指令微调模型的性能与其基模型的上下文性能之间存在显著的相关性。通过阐明指令微调的贡献，我们将前人关于上下文学习的研究进一步扩展，表明基模型利用预训练数据中的先验知识来解决任务。特别是，我们将这一理解扩展到指令微调模型，表明其预训练数据同样设置了任务解决的限制边界，而附加影响来自于指令微调数据集。', 'title_zh': '预训练大语言模型的固有限制：指令 tuning 和上下文学习能力的意外交汇'}
{'arxiv_id': 'arXiv:2501.08696', 'title': 'Deep Learning-Based Feature Fusion for Emotion Analysis and Suicide Risk Differentiation in Chinese Psychological Support Hotlines', 'authors': 'Han Wang, Jianqiang Li, Qing Zhao, Zhonglong Chen, Changwei Song, Jing Tang, Yuning Huang, Wei Zhai, Yongsheng Tong, Guanghui Fu', 'link': 'https://arxiv.org/abs/2501.08696', 'abstract': "Mental health is a critical global public health issue, and psychological support hotlines play a pivotal role in providing mental health assistance and identifying suicide risks at an early stage. However, the emotional expressions conveyed during these calls remain underexplored in current research. This study introduces a method that combines pitch acoustic features with deep learning-based features to analyze and understand emotions expressed during hotline interactions. Using data from China's largest psychological support hotline, our method achieved an F1-score of 79.13% for negative binary emotion this http URL, the proposed approach was validated on an open dataset for multi-class emotion classification,where it demonstrated better performance compared to the state-of-the-art methods. To explore its clinical relevance, we applied the model to analysis the frequency of negative emotions and the rate of emotional change in the conversation, comparing 46 subjects with suicidal behavior to those without. While the suicidal group exhibited more frequent emotional changes than the non-suicidal group, the difference was not statistically this http URL, our findings suggest that emotional fluctuation intensity and frequency could serve as novel features for psychological assessment scales and suicide risk this http URL proposed method provides valuable insights into emotional dynamics and has the potential to advance early intervention and improve suicide prevention strategies through integration with clinical tools and assessments The source code is publicly available at this https URL.", 'abstract_zh': '心理健康是全球公共卫生的关键问题，而心理支持热线在提供心理健康援助和早期识别自杀风险方面发挥着重要作用。然而，目前研究中对热线通话中传达的情绪表达仍然关注不足。本研究提出了一种结合音高声学特征与基于深度学习的特征的方法，用于分析和理解热线通话中表达的情绪。使用中国最大的心理支持热线的数据，我们的方法在二元负情绪分类中的F1分数达到79.13%，详见具体网址。在多分类情绪识别的开放数据集中，所提出的方法显示出优于当前最佳方法的性能。为了探讨其临床相关性，我们将模型应用于分析自杀行为和非自杀行为群体之间的负面情绪频率和情绪变化率。虽然自杀群体的情绪变化频率高于非自杀群体，但这种差异在统计学上没有显著性。我们的研究结果表明，情绪波动的强度和频率可以作为心理评估量表和自杀风险的新型特征。所提出的方法为情绪动态提供了宝贵的洞察，有望通过与临床工具和评估方法的整合，促进早期干预并改进自杀预防策略。研究代码已在具体网址公开。', 'title_zh': '基于深度学习的特征融合方法在中文心理支持热线中的情绪分析与自杀风险区分的研究'}
{'arxiv_id': 'arXiv:2501.08648', 'title': 'MAGNET: Augmenting Generative Decoders with Representation Learning and Infilling Capabilities', 'authors': 'Savya Khosla, Kushal Kafle, Simon Jenni, Handong Zhao, John Collomosse, Jing Shi', 'link': 'https://arxiv.org/abs/2501.08648', 'abstract': 'While originally designed for unidirectional generative modeling, decoder-only large language models (LLMs) are increasingly being adapted for bidirectional modeling. However, unidirectional and bidirectional models are typically trained separately with distinct objectives (generation and representation learning, respectively). This separation overlooks the opportunity for developing a more versatile language model and for these objectives to complement each other. In this work, we introduce MAGNET, an adaptation of decoder-only LLMs that enhances their ability to generate robust representations and infill missing text spans, while preserving their knowledge and text generation capabilities. MAGNET employs three self-supervised training objectives and introduces an attention mechanism that combines bidirectional and causal attention, enabling unified training across all objectives. Our results demonstrate that LLMs adapted with MAGNET (1) surpass strong text encoders on token-level and sentence-level representation learning tasks, (2) generate contextually appropriate text infills by leveraging future context, (3) retain the ability for open-ended text generation without exhibiting repetition problem, and (4) preserve the knowledge gained by the LLM during pretraining.', 'abstract_zh': '尽管最初旨在进行单向生成建模，全解码型大型语言模型（LLMs）现在越来越多地被适应用于双向建模。然而，单向和双向模型通常各自独立训练，分别具有不同的目标（生成和表征学习）。这种分隔忽视了开发更加通用语言模型的机会，以及这些目标相互补充的可能性。在本文中，我们引入了MAGNET，这是一种对全解码型LLMs的改进，增强了它们生成稳健表征和填补缺失文本的能力，同时保持它们的知识和文本生成能力。MAGNET采用三种自监督训练目标，并引入了结合双向和因场注意力的注意机制，从而在所有目标上实现统一训练。我们的研究表明，使用MAGNET改进的LLMs（1）在单词级和句子级表征学习任务上超越了强大的文本编码器，（2）通过利用未来语境生成上下文适配的文本填补，（3）在无限制文本生成方面保持了能力，且未表现出重复问题，并且（4）保留了LLMs在预训练过程中获得的知识。', 'title_zh': 'MAGNET：增强生成解码器的表征学习和填补能力'}
{'arxiv_id': 'arXiv:2501.08641', 'title': 'Reassessing the Role of Chain-of-Thought in Sentiment Analysis: Insights and Limitations', 'authors': 'Kaiyuan Zheng, Qinghua Zhao, Lei Li', 'link': 'https://arxiv.org/abs/2501.08641', 'abstract': "The relationship between language and thought remains an unresolved philosophical issue. Existing viewpoints can be broadly categorized into two schools: one asserting their independence, and another arguing that language constrains thought. In the context of large language models, this debate raises a crucial question: Does a language model's grasp of semantic meaning depend on thought processes? To explore this issue, we investigate whether reasoning techniques can facilitate semantic understanding. Specifically, we conceptualize thought as reasoning, employ chain-of-thought prompting as a reasoning technique, and examine its impact on sentiment analysis tasks. The experiments show that chain-of-thought has a minimal impact on sentiment analysis tasks. Both the standard and chain-of-thought prompts focus on aspect terms rather than sentiment in the generated content. Furthermore, counterfactual experiments reveal that the model's handling of sentiment tasks primarily depends on information from demonstrations. The experimental results support the first viewpoint.", 'abstract_zh': '语言与思维之间的关系仍然是一个未决的哲学问题。现有观点大致可以归为两类：一类认为它们是独立的，另一类则认为语言对思维具有约束作用。在大型语言模型的背景下，这一争论提出了一个关键问题：语言模型对语义的理解是否依赖于思维过程？为了探讨这一问题，我们研究了推理技术是否能促进语义理解。具体而言，我们将思维概念化为推理，并采用链式推理提示作为推理技术，考察其对情感分析任务的影响。实验结果显示，链式推理对情感分析任务的影响微乎其微。标准提示和链式推理提示均主要关注生成内容中的方面词而非情感。此外，反事实实验表明，模型处理情感任务的能力主要依赖于示例中的信息。实验结果支持了第一种观点。', 'title_zh': '重新评估链式思维在情感分析中的作用：见解与局限性'}
{'arxiv_id': 'arXiv:2501.08621', 'title': 'ViBidirectionMT-Eval: Machine Translation for Vietnamese-Chinese and Vietnamese-Lao language pair', 'authors': 'Hong-Viet Tran, Minh-Quy Nguyen, Van-Vinh Nguyen', 'link': 'https://arxiv.org/abs/2501.08621', 'abstract': 'This paper presents an results of the VLSP 2022-2023 Machine Translation Shared Tasks, focusing on Vietnamese-Chinese and Vietnamese-Lao machine translation. The tasks were organized as part of the 9th, 10th annual workshop on Vietnamese Language and Speech Processing (VLSP 2022, VLSP 2023). The objective of the shared task was to build machine translation systems, specifically targeting Vietnamese-Chinese and Vietnamese-Lao translation (corresponding to 4 translation directions). The submission were evaluated on 1,000 pairs for testing (news and general domains) using established metrics like BLEU [11] and SacreBLEU [12]. Additionally, system outputs also were evaluated with human judgment provided by experts in Chinese and Lao languages. These human assessments played a crucial role in ranking the performance of the machine translation models, ensuring a more comprehensive evaluation.', 'abstract_zh': '本文介绍了2022-2023年越南语语言与语音处理研讨会（VLSP）机器翻译共享任务的结果，重点关注越南语-中文和越南语-老挝语机器翻译。这些任务作为第9届和第10届越南语语言与语音处理研讨会（VLSP 2022、VLSP 2023）的一部分进行组织。共享任务的目的是构建机器翻译系统，专门针对越南语-中文和越南语-老挝语翻译（对应4个翻译方向）。提交的作品在新闻和通用领域使用标准指标（如BLEU [11] 和SacreBLEU [12]）评估了1000个测试样本集。此外，系统输出还通过中文和老挝语专业人士的人工评估进行评估。这些人工评估在排名机器翻译模型的性能方面起到了关键作用，确保了更为全面的评估。', 'title_zh': 'ViBidirectionMT-Eval：越南语-中文和越南语-老挝语语言对的机器翻译评估'}
{'arxiv_id': 'arXiv:2501.08618', 'title': 'Disjoint Processing Mechanisms of Hierarchical and Linear Grammars in Large Language Models', 'authors': 'Aruna Sankaranarayanan, Dylan Hadfield-Menell, Aaron Mueller', 'link': 'https://arxiv.org/abs/2501.08618', 'abstract': 'All natural languages are structured hierarchically. In humans, this structural restriction is neurologically coded: when two grammars are presented with identical vocabularies, brain areas responsible for language processing are only sensitive to hierarchical grammars. Using large language models (LLMs), we investigate whether such functionally distinct hierarchical processing regions can arise solely from exposure to large-scale language distributions. We generate inputs using English, Italian, Japanese, or nonce words, varying the underlying grammars to conform to either hierarchical or linear/positional rules. Using these grammars, we first observe that language models show distinct behaviors on hierarchical versus linearly structured inputs. Then, we find that the components responsible for processing hierarchical grammars are distinct from those that process linear grammars; we causally verify this in ablation experiments. Finally, we observe that hierarchy-selective components are also active on nonce grammars; this suggests that hierarchy sensitivity is not tied to meaning, nor in-distribution inputs.', 'abstract_zh': '所有自然语言在结构上都是分层次的。在人类中，这种结构限制在神经上得到了编码：当向大脑呈现具有相同词汇量的两套文法时，负责处理语言的大脑区域仅对分层次的文法有反应。利用大规模语言模型（LLMs），我们研究这些具有功能特异性的分层次处理区域是否仅通过大规模语言语料库的暴露就能产生。我们使用英语、意大利语、日语或非标准词生成输入，并改变基础文法使其符合分层次结构或线性/位置规则。利用这些文法，我们首先观察到语言模型在处理分层次结构和线性结构的输入时表现出不同的行为。然后，我们发现处理分层次文法的部分与处理线性文法的部分不同；我们在消融实验中因果验证了这一点。最后，我们观察到对非标准文法也有选择性的组件也活跃起来；这表明分层次敏感性与意义无关，也不局限于分布内输入。', 'title_zh': '大型语言模型中层次语法与线性语法的并行处理机制'}
{'arxiv_id': 'arXiv:2501.08613', 'title': 'Assessing the Alignment of FOL Closeness Metrics with Human Judgement', 'authors': 'Ramya Keerthy Thatikonda, Wray Buntine, Ehsan Shareghi', 'link': 'https://arxiv.org/abs/2501.08613', 'abstract': 'The recent successful paradigm of solving logical reasoning problems with tool-augmented large language models (LLMs) leverages translation of natural language statements into First-Order Logic~(FOL) and external theorem provers. However, the correctness of FOL statements, comprising operators and text predicates, often goes unverified due to the lack of a reliable evaluation metric for comparing generated and ground-truth FOLs. In this paper, we present a comprehensive study of sensitivity of existing metrics and their alignment with human judgement on FOL evaluation. Using ground-truth FOLs, we carefully designed various perturbations on the ground-truth to assess metric sensitivity. We sample FOL translation candidates for natural language statements and measure the ranking alignment between automatic metrics and human annotators. Our empirical findings highlight oversensitivity in the n-gram metric BLEU for text perturbations, the semantic graph metric Smatch++ for structural perturbations, and FOL metric for operator perturbation. We also observe a closer alignment between BertScore and human judgement. Additionally, we show that combining metrics enhances both alignment and sensitivity compared to using individual metrics.', 'abstract_zh': '近年来，借助工具增强的大语言模型（LLMs）成功解决逻辑推理问题的范式，利用了自然语言陈述转化为一阶逻辑（FOL）以及外部定理证明器的技术。然而，由于缺乏可靠的评价标准来比较生成的FOL和真实FOL，一阶逻辑陈述（包括操作符和文本谓词）的正确性往往未被验证。在本文中，我们对现有评价指标的敏感性和其与人类判断的一致性进行了全面研究。利用真实FOL，我们精心设计了各种真实值扰动，以评估指标的敏感性。我们抽取了自然语言陈述的一阶逻辑翻译候选者，并测量了自动指标与人类注释者之间排名的一致性。我们的实证研究结果强调了对于文本扰动，n-gram指标BLEU的过度敏感性；对于结构扰动，语义图指标Smatch++的过度敏感性；对于操作符扰动，一阶逻辑指标的过度敏感性。此外，我们还观察到BertScore与人类判断更接近的一致性。同时，我们展示了指标组合提高了评价的一致性和敏感性，优于单独使用指标的情况。', 'title_zh': '评估FOL接近度度量与人类判断的一致性'}
{'arxiv_id': 'arXiv:2501.08597', 'title': 'Dynamic Knowledge Integration for Enhanced Vision-Language Reasoning', 'authors': 'Julian Perry, Surasakdi Siripong, Thanakorn Phonchai', 'link': 'https://arxiv.org/abs/2501.08597', 'abstract': "Large Vision-Language Models (LVLMs) have demonstrated impressive capabilities in multimodal tasks, but their performance is often constrained by the lack of external knowledge integration, limiting their ability to handle knowledge-intensive tasks such as visual question answering and reasoning. To address this challenge, we propose a novel method, Adaptive Knowledge-Guided Pretraining for Large Vision-Language Models (AKGP-LVLM), which dynamically incorporates structured and unstructured knowledge into LVLMs during pretraining and fine-tuning. Our approach employs a knowledge encoder to represent external knowledge, a retrieval mechanism to select task-relevant information, and a dynamic adaptor to align multimodal and knowledge representations effectively. We evaluate our method on four benchmark datasets, demonstrating significant performance improvements over state-of-the-art models. Furthermore, human evaluations highlight the superior correctness and relevance of our model's outputs. Extensive analyses confirm the robustness, efficiency, and scalability of AKGP-LVLM, making it a compelling solution for real-world knowledge-intensive tasks.", 'abstract_zh': '大型多模态视觉-语言模型（Large Vision-Language Models, LVLMs）在多项任务中展现出了令人印象深刻的能力，但它们的性能往往受限于外部知识整合的不足，限制了其处理知识密集型任务（如视觉问答和推理）的能力。为了解决这一挑战，我们提出了一种新的方法，大型视觉-语言模型的自适应知识引导预训练（Adaptive Knowledge-Guided Pretraining for Large Vision-Language Models, AKGP-LVLM），该方法在预训练和微调过程中动态地将结构化和非结构化的知识整合到LVLMs中。我们的方法采用了知识编码器来表示外部知识，使用检索机制选择与任务相关的信息，并利用动态适配器有效地对齐多模态和知识表示。我们在四个基准数据集上评估了该方法，结果显示，在与最先进的模型相比时，我们的方法取得了显著的性能提升。此外，人类评估表明，我们的模型输出具有更高的准确性和相关性。大量分析证实了AKGP-LVLM的稳健性、高效性和扩展性，使其成为解决实际知识密集型任务的理想解决方案。', 'title_zh': '增强视觉语言推理的动态知识集成'}
{'arxiv_id': 'arXiv:2501.08582', 'title': 'LoRS: Efficient Low-Rank Adaptation for Sparse Large Language Model', 'authors': 'Yuxuan Hu, Jing Zhang, Xiaodong Chen, Zhe Zhao, Cuiping Li, Hong Chen', 'link': 'https://arxiv.org/abs/2501.08582', 'abstract': 'Existing low-rank adaptation (LoRA) methods face challenges on sparse large language models (LLMs) due to the inability to maintain sparsity. Recent works introduced methods that maintain sparsity by augmenting LoRA techniques with additional masking mechanisms. Despite these successes, such approaches suffer from an increased memory and computation overhead, which affects efficiency of LoRA methods. In response to this limitation, we introduce LoRS, an innovative method designed to achieve both memory and computation efficiency when fine-tuning sparse LLMs. To mitigate the substantial memory and computation demands associated with preserving sparsity, our approach incorporates strategies of weight recompute and computational graph rearrangement. In addition, we also improve the effectiveness of LoRS through better adapter initialization. These innovations lead to a notable reduction in memory and computation consumption during the fine-tuning phase, all while achieving performance levels that outperform existing LoRA approaches.', 'abstract_zh': '现有的低秩适应（LoRA）方法在稀疏大型语言模型（LLMs）上面临挑战，因为它们难以维持稀疏性。最近的研究引入了通过结合额外的掩蔽机制来保留稀疏性的LoRA技术。尽管这些方法取得了一定的成功，但它们增加了内存和计算开销，从而影响了LoRA方法的效率。针对这一局限，我们提出了LoRS，一种旨在在微调稀疏LLMs时同时实现内存和计算效率的新方法。为了缓解保持稀疏性所面临的巨大内存和计算需求，我们的方法结合了权重重新计算和计算图重排的策略。此外，我们还通过改进适应器初始化来提高LoRS的有效性。这些创新在微调阶段显著减少了内存和计算消耗，同时在性能上超过了现有的LoRA方法。', 'title_zh': 'LoRS：高效低秩适应方法用于稀疏大型语言模型'}
{'arxiv_id': 'arXiv:2501.08579', 'title': 'What Limits LLM-based Human Simulation: LLMs or Our Design?', 'authors': 'Qian Wang, Jiaying Wu, Zhenheng Tang, Bingqiao Luo, Nuo Chen, Wei Chen, Bingsheng He', 'link': 'https://arxiv.org/abs/2501.08579', 'abstract': "We argue that advancing LLM-based human simulation requires addressing both LLM's inherent limitations and simulation framework design challenges. Recent studies have revealed significant gaps between LLM-based human simulations and real-world observations, highlighting these dual challenges. To address these gaps, we present a comprehensive analysis of LLM limitations and our design issues, proposing targeted solutions for both aspects. Furthermore, we explore future directions that address both challenges simultaneously, particularly in data collection, LLM generation, and evaluation. To support further research in this field, we provide a curated collection of LLM-based human simulation resources.\\footnote{this https URL}", 'abstract_zh': '我们argue认为，基于LLM的拟人化研究需要同时解决LLM固有的局限性和模拟框架设计的挑战。近期的研究揭示了基于LLM的拟人化与现实世界观察之间的显著差距，突显了这些双重挑战。为了解决这些差距，我们提供了一项全面分析LLM的局限性和设计问题，并提出了针对这两方面的目标性解决方案。此外，我们探讨了如何同时应对这些挑战的未来方向，尤其是在数据收集、LLM生成和评价方面。为了支持该领域的进一步研究，我们提供了一份精心整理的基于LLM的拟人化资源集合。\\footnote{this https URL}\n\n请注意，翻译中保留了原文中的“argue”一词，因为在此语境下，它更符合学术写作的表达。如果需要进一步调整表达方式，请告知。', 'title_zh': '基于大语言模型的人机仿真受限于大语言模型本身还是我们的设计？'}
{'arxiv_id': 'arXiv:2501.08570', 'title': 'Information Entropy Invariance: Enhancing Length Extrapolation in Attention Mechanisms', 'authors': 'Kewei Li, Yanwen Kong, Yiping Xu, Lan Huang, Ruochi Zhang, Fengfeng Zhou', 'link': 'https://arxiv.org/abs/2501.08570', 'abstract': 'Improving the length extrapolation capabilities of Large Language Models (LLMs) remains a critical challenge in natural language processing. Many recent efforts have focused on modifying the scaled dot-product attention mechanism, and often introduce scaled temperatures without rigorous theoretical justification. To fill this gap, we introduce a novel approach based on information entropy invariance. We propose two new scaled temperatures to enhance length extrapolation. First, a training-free method InfoScale is designed for dot-product attention, and preserves focus on original tokens during length extrapolation by ensuring information entropy remains consistent. Second, we theoretically analyze the impact of scaling (CosScale) on cosine attention. Experimental data demonstrates that combining InfoScale and CosScale achieves state-of-the-art performance on the GAU-{\\alpha} model with a context window extended to 64 times the training length, and outperforms seven existing methods. Our analysis reveals that significantly increasing CosScale approximates windowed attention, and highlights the significance of attention score dilution as a key challenge in long-range context handling. The code and data are available at this https URL.', 'abstract_zh': '提高大型语言模型（LLM）的长度外推能力仍然是自然语言处理中的一个关键挑战。许多最近的努力集中在修改标度点积注意机制上，经常引入未经过严格理论验证的比例温度。为了填补这一缺口，我们提出了一种基于信息熵不变性的新方法。我们提出了两种新的标度温度来增强长度外推能力。首先，我们设计了一种无需训练的方法InfoScale，用于点积注意机制，通过确保信息熵保持一致来在长度外推过程中保持对原始令牌的关注。其次，我们从理论上分析了缩放（CosScale）对余弦注意机制的影响。实验数据表明，将InfoScale和CosScale结合使用，在将上下文窗口扩展至训练长度64倍的GAU-α模型上达到了最先进的性能，并优于七种现有方法。我们的分析揭示了显著增加CosScale近似窗口化注意力的效果，并强调了注意分数稀释在长范围上下文处理中的关键挑战。相关代码和数据可在以下链接获取：this https URL。', 'title_zh': '信息熵不变性：增强注意力机制中的长度外推能力'}
{'arxiv_id': 'arXiv:2501.08540', 'title': 'Knowledge prompt chaining for semantic modeling', 'authors': 'Ning Pei Ding, Jingge Du, Zaiwen Feng', 'link': 'https://arxiv.org/abs/2501.08540', 'abstract': "The task of building semantics for structured data such as CSV, JSON, and XML files is highly relevant in the knowledge representation field. Even though we have a vast of structured data on the internet, mapping them to domain ontologies to build semantics for them is still very challenging as it requires the construction model to understand and learn graph-structured knowledge. Otherwise, the task will require human beings' effort and cost. In this paper, we proposed a novel automatic semantic modeling framework: Knowledge Prompt Chaining. It can serialize the graph-structured knowledge and inject it into the LLMs properly in a Prompt Chaining architecture. Through this knowledge injection and prompting chaining, the model in our framework can learn the structure information and latent space of the graph and generate the semantic labels and semantic graphs following the chains' insturction naturally. Based on experimental results, our method achieves better performance than existing leading techniques, despite using reduced structured input data.", 'abstract_zh': '构建CSV、JSON和XML等结构化数据语义的任务在知识表示领域具有高度的相关性。尽管互联网上有大量的结构化数据，将这些数据映射到领域本体以构建其语义依然是一个非常具有挑战性的任务，因为它需要构建模型能够理解和学习图结构的知识。否则，该任务将需要人类的努力和成本。在本文中，我们提出了一种新颖的自动语义建模框架：知识提示链。该框架采用提示链架构，能够序列化图结构的知识并适当地注入到LLMs中。通过这种知识的注入和提示链的构建，我们框架中的模型可以学习图的结构信息和潜在空间，并能够自然地根据链的指令生成语义标签和语义图。根据实验结果，尽管我们的方法使用了减少的结构化输入数据，但在现有的领先技术中仍实现了更好的性能。', 'title_zh': '知识提示链式方法for语义建模\n\n为了符合学术规范，更准确的翻译应该是：\n\n知识提示链式方法在语义建模中的应用\n\n或者\n\n基于知识提示链的方法进行语义建模'}
{'arxiv_id': 'arXiv:2501.08537', 'title': 'Complexity Control Facilitates Reasoning-Based Compositional Generalization in Transformers', 'authors': 'Zhongwang Zhang, Pengxiao Lin, Zhiwei Wang, Yaoyu Zhang, Zhi-Qin John Xu', 'link': 'https://arxiv.org/abs/2501.08537', 'abstract': "Transformers have demonstrated impressive capabilities across various tasks, yet their performance on compositional problems remains a subject of debate. In this study, we investigate the internal mechanisms underlying Transformers' behavior in compositional tasks. We find that complexity control strategies significantly influence whether the model learns primitive-level rules that generalize out-of-distribution (reasoning-based solutions) or relies solely on memorized mappings (memory-based solutions). By applying masking strategies to the model's information circuits and employing multiple complexity metrics, we reveal distinct internal working mechanisms associated with different solution types. Further analysis reveals that reasoning-based solutions exhibit a lower complexity bias, which aligns with the well-studied neuron condensation phenomenon. This lower complexity bias is hypothesized to be the key factor enabling these solutions to learn reasoning rules. We validate these conclusions across multiple real-world datasets, including image generation and natural language processing tasks, confirming the broad applicability of our findings.", 'abstract_zh': 'Transformer模型在各种任务中展现了令人印象深刻的性能，但在组合问题上的表现仍存在争议。本研究旨在探讨Transformer在组合任务中行为背后的内部机制。我们发现，复杂性控制策略显著影响模型是学习泛化到分布外的基于推理的解决方案（reasoning-based solutions）还是仅依赖于记忆化的映射（memory-based solutions）。通过在模型的信息电路中应用遮蔽策略，并采用多种复杂性度量标准，我们揭示了不同类型解决方案相关联的不同内部工作机制。进一步的分析表明，基于推理的解决方案表现出较低的复杂性偏差，这与已经研究过的神经元凝缩现象一致。这一较低的复杂性偏差被推测为这些解决方案学习推理规则的关键因素。我们通过多个实际数据集（包括图像生成和自然语言处理任务）验证了这些结论，证实了我们所发现的现象具有广泛的适用性。', 'title_zh': '复杂性控制有利于基于推理的组合泛化在变换器中的应用'}
{'arxiv_id': 'arXiv:2501.08523', 'title': 'Doc-Guided Sent2Sent++: A Sent2Sent++ Agent with Doc-Guided memory for Document-level Machine Translation', 'authors': 'Jiaxin Guo, Yuanchang Luo, Daimeng Wei, Ling Zhang, Zongyao Li, Hengchao Shang, Zhiqiang Rao, Shaojun Li, Jinlong Yang, Zhanglin Wu, Hao Yang', 'link': 'https://arxiv.org/abs/2501.08523', 'abstract': 'The field of artificial intelligence has witnessed significant advancements in natural language processing, largely attributed to the capabilities of Large Language Models (LLMs). These models form the backbone of Agents designed to address long-context dependencies, particularly in Document-level Machine Translation (DocMT). DocMT presents unique challenges, with quality, consistency, and fluency being the key metrics for evaluation. Existing approaches, such as Doc2Doc and Doc2Sent, either omit sentences or compromise fluency. This paper introduces Doc-Guided Sent2Sent++, an Agent that employs an incremental sentence-level forced decoding strategy \\textbf{to ensure every sentence is translated while enhancing the fluency of adjacent sentences.} Our Agent leverages a Doc-Guided Memory, focusing solely on the summary and its translation, which we find to be an efficient approach to maintaining consistency. Through extensive testing across multiple languages and domains, we demonstrate that Sent2Sent++ outperforms other methods in terms of quality, consistency, and fluency. The results indicate that, our approach has achieved significant improvements in metrics such as s-COMET, d-COMET, LTCR-$1_f$, and document-level perplexity (d-ppl). The contributions of this paper include a detailed analysis of current DocMT research, the introduction of the Sent2Sent++ decoding method, the Doc-Guided Memory mechanism, and validation of its effectiveness across languages and domains.', 'abstract_zh': '人工智能领域在自然语言处理方面取得了显著进展，这主要归功于大型语言模型（LLMs）的能力。这些模型构建了设计用于解决长语境依赖性的代理，特别是在文档级机器翻译（DocMT）中。DocMT提出了独特的挑战，其中质量、一致性和流畅性是主要的评估指标。现有的方法，如Doc2Doc和Doc2Sent，要么忽略了句子，要么牺牲了流畅性。本文介绍了一种名为Sent2Sent++的代理，该代理采用增量句子级别的强制解码策略，**旨在确保每个句子都被翻译，并提高相邻句子的流畅性。**我们的代理利用了一种基于文档指导的记忆机制，专注于摘要及其翻译，我们认为这是维持一致性的高效方法。通过跨多种语言和领域的广泛测试，我们证明了Sent2Sent++在质量、一致性和流畅性方面优于其他方法。结果表明，我们的方法在s-COMET、d-COMET、LTCR-$1_f$和文档级困惑度（d-ppl）等指标上实现了显著改进。本文的贡献包括对当前DocMT研究的详细分析、Sent2Sent++解码方法的引入、基于文档指导的记忆机制，以及验证其在语言和领域上的有效性。', 'title_zh': '基于文档引导的 Sent2Sent++：一种带有文档引导记忆的句子到句子增强代理模型用于文档级机器翻译'}
{'arxiv_id': 'arXiv:2501.08502', 'title': 'Adapting Whisper for Regional Dialects: Enhancing Public Services for Vulnerable Populations in the United Kingdom', 'authors': 'Melissa Torgbi, Andrew Clayman, Jordan J. Speight, Harish Tayyar Madabushi', 'link': 'https://arxiv.org/abs/2501.08502', 'abstract': 'We collect novel data in the public service domain to evaluate the capability of the state-of-the-art automatic speech recognition (ASR) models in capturing regional differences in accents in the United Kingdom (UK), specifically focusing on two accents from Scotland with distinct dialects. This study addresses real-world problems where biased ASR models can lead to miscommunication in public services, disadvantaging individuals with regional accents particularly those in vulnerable populations. We first examine the out-of-the-box performance of the Whisper large-v3 model on a baseline dataset and our data. We then explore the impact of fine-tuning Whisper on the performance in the two UK regions and investigate the effectiveness of existing model evaluation techniques for our real-world application through manual inspection of model errors. We observe that the Whisper model has a higher word error rate (WER) on our test datasets compared to the baseline data and fine-tuning on a given data improves performance on the test dataset with the same domain and accent. The fine-tuned models also appear to show improved performance when applied to the test data outside of the region it was trained on suggesting that fine-tuned models may be transferable within parts of the UK. Our manual analysis of model outputs reveals the benefits and drawbacks of using WER as an evaluation metric and fine-tuning to adapt to regional dialects.', 'abstract_zh': '在我国公共服务领域收集新颖数据，以评估当前最先进的自动语音识别（ASR）模型在捕捉英国（UK）地区口音差异方面的能力，特别是关注苏格兰两种具有明显方言特色的口音。本研究旨在解决由于存在偏差的ASR模型导致公共服务中的沟通错误问题，特别影响那些具有地区口音尤其是处于脆弱群体中的个体。我们首先考察了Whisper大型v3模型在基准数据集和我们数据集上的初始性能。然后，我们探索了在苏格兰两个地区微调Whisper对性能的影响，并通过手动检查模型错误来研究现有模型评估技术在实际应用场景中的有效性。我们观察到，相较于基准数据集，Whisper模型在我们的测试数据集上的单词错误率（WER）较高；通过对特定领域和口音的数据进行微调，模型在相同的测试数据集上的性能有所提升。微调后的模型在应用于其训练区域之外的数据时也表现出色，这表明微调模型可能在英国部分地区具有可迁移性。通过对模型输出的手动分析，我们揭示了使用WER作为评估指标以及通过微调调整地区方言的优势与不足。', 'title_zh': '适配地方方言的Whisper：为英国脆弱群体提升公共服务质量'}
{'arxiv_id': 'arXiv:2501.08496', 'title': 'Quantifying the Importance of Data Alignment in Downstream Model Performance', 'authors': 'Krrish Chawla, Aryan Sahai, Mario DePavia, Sudharsan Sundar, Brando Miranda', 'link': 'https://arxiv.org/abs/2501.08496', 'abstract': "Contrary to the conventional emphasis on dataset size, we explore the role of data alignment -- an often overlooked aspect of data quality -- in training capable Large Language Models (LLMs). To do so, we use the Task2Vec-based alignment coefficient, a quantitative measure of the similarity between two datasets, to quantify the impact of alignment between training data and evaluation data on downstream performance. In particular, we conduct controlled \\textit{interventional} experiments for two settings: 1. the impact of increased alignment coefficients between various pre-training (pt) against evaluation datasets, and 2. the impact of increased alignment coefficients between domain specific fine-tuning (ft) against domain specific evaluation. The domain specific task we explore is Autoformalization -- the machine translation task between natural language and code for formal verification. In both settings, we find a strong, predictable negative correlation between the alignment coefficient of a model's training and evaluation data and the model's loss/perplexity on the respective downstream task. These findings suggest a re-evaluation of LLM training approaches, demonstrating the relevance of data alignment compared to data quantity, especially in specialized downstream tasks such as Autoformalization.", 'abstract_zh': '与传统上对数据集大小的重视相反，我们探讨了数据对齐——数据质量的一个经常被忽视的因素——在训练强大的大型语言模型（LLMs）中的作用。为此，我们使用基于Task2Vec的数据对齐系数——一个衡量两个数据集之间相似性的量化指标——来量化训练数据与评估数据之间对齐程度对下游性能的影响。具体而言，我们在两个设置中进行了受控的干预性实验：1. 不同预训练（pt）数据集与评估数据集之间对齐系数增加的影响；2. 领域特定微调（ft）数据集与领域特定评估数据集之间对齐系数增加的影响。我们研究的领域特定任务是Automodal化——从自然语言到代码的机器翻译任务，用于形式化验证。在两种设置下，我们发现模型的训练和评估数据对齐系数与其在相应下游任务上的损失/困惑度之间存在强烈且可预测的负相关关系。这些发现建议重新评估LLM的训练方法，表明数据对齐与数据量相比的重要性，尤其是在如Automodal化等专门下游任务中更为显著。', 'title_zh': '量化数据对齐在下游模型性能中的重要性'}
{'arxiv_id': 'arXiv:2501.08474', 'title': 'The Theater Stage as Laboratory: Review of Real-Time Comedy LLM Systems for Live Performance', 'authors': 'Piotr Wojciech Mirowski, Boyd Branch, Kory Wallace Mathewson', 'link': 'https://arxiv.org/abs/2501.08474', 'abstract': 'In this position paper, we review the eclectic recent history of academic and artistic works involving computational systems for humor generation, and focus specifically on live performance. We make the case that AI comedy should be evaluated in live conditions, in front of audiences sharing either physical or online spaces, and under real-time constraints. We further suggest that improvised comedy is therefore the perfect substrate for deploying and assessing computational humor systems. Using examples of successful AI-infused shows, we demonstrate that live performance raises three sets of challenges for computational humor generation: 1) questions around robotic embodiment, anthropomorphism and competition between humans and machines, 2) questions around comedic timing and the nature of audience interaction, and 3) questions about the human interpretation of seemingly absurd AI-generated humor. We argue that these questions impact the choice of methodologies for evaluating computational humor, as any such method needs to work around the constraints of live audiences and performance spaces. These interrogations also highlight different types of collaborative relationship of human comedians towards AI tools.', 'abstract_zh': '在本文中，我们回顾了涉及计算系统生成幽默的学术和艺术作品的 eclectic历史，并特别关注现场表演。我们提出，人工智能喜剧应在实际现场条件下游演，无论观众是共享物理空间还是在线空间，并且应在实时约束条件下进行评价。进一步地，我们认为即兴喜剧因此成为了部署和评估计算幽默系统的理想载体。利用成功结合人工智能的剧目示例，我们展示现场表演为计算幽默生成带来了三类挑战：1) 针对机器人身体表达、拟人性以及人机之间的竞争等方面的问题；2) 针对幽默时机与观众互动本质的问题；3) 针对人类对看似荒诞的人工智能生成幽默的理解问题。我们认为，这些问题影响了评估计算幽默方法的选择，因为任何这样的方法都需要适应现场观众和表演空间的约束。这些疑问还突显了不同类型的人类喜剧演员与人工智能工具合作的关系模式。', 'title_zh': '舞台实验室：实时喜剧生成LLM系统综述'}
{'arxiv_id': 'arXiv:2501.08468', 'title': 'Selective Attention Merging for low resource tasks: A case study of Child ASR', 'authors': 'Natarajan Balaji Shankar, Zilai Wang, Eray Eren, Abeer Alwan', 'link': 'https://arxiv.org/abs/2501.08468', 'abstract': 'While Speech Foundation Models (SFMs) excel in various speech tasks, their performance for low-resource tasks such as child Automatic Speech Recognition (ASR) is hampered by limited pretraining data. To address this, we explore different model merging techniques to leverage knowledge from models trained on larger, more diverse speech corpora. This paper also introduces Selective Attention (SA) Merge, a novel method that selectively merges task vectors from attention matrices to enhance SFM performance on low-resource tasks. Experiments on the MyST database show significant reductions in relative word error rate of up to 14%, outperforming existing model merging and data augmentation techniques. By combining data augmentation techniques with SA Merge, we achieve a new state-of-the-art WER of 8.69 on the MyST database for the Whisper-small model, highlighting the potential of SA Merge for improving low-resource ASR.', 'abstract_zh': '尽管语音基础模型（SFMs）在各种语音任务中表现出色，但它们在诸如儿童自动语音识别（ASR）等低资源任务中的性能受限于预训练数据的不足。为了解决这一问题，我们探索了不同的模型合并技术，以便利用在更大、更具多样性的语音语料库上训练的模型的知识。本文还提出了一种名为选择性注意（SA）合并的新方法，该方法通过选择性地合并注意矩阵中的任务向量来增强SFM在低资源任务中的表现。实验结果表明，选择性注意合并方法在MyST数据库中的相对单词错误率降低高达14%，并优于现有的模型合并和数据增强技术。通过将数据增强技术与选择性注意合并相结合，我们在MyST数据库中实现了一种新的Whisper-small模型的最新状态错误率（WER）为8.69，这突显了选择性注意合并方法在改善低资源ASR方面的潜力。', 'title_zh': '低资源任务中的选择性注意力融合：儿童语音识别案例研究'}
{'arxiv_id': 'arXiv:2501.08457', 'title': 'Large Language Models For Text Classification: Case Study And Comprehensive Review', 'authors': 'Arina Kostina, Marios D. Dikaiakos, Dimosthenis Stefanidis, George Pallis', 'link': 'https://arxiv.org/abs/2501.08457', 'abstract': "Unlocking the potential of Large Language Models (LLMs) in data classification represents a promising frontier in natural language processing. In this work, we evaluate the performance of different LLMs in comparison with state-of-the-art deep-learning and machine-learning models, in two different classification scenarios: i) the classification of employees' working locations based on job reviews posted online (multiclass classification), and 2) the classification of news articles as fake or not (binary classification). Our analysis encompasses a diverse range of language models differentiating in size, quantization, and architecture. We explore the impact of alternative prompting techniques and evaluate the models based on the weighted F1-score. Also, we examine the trade-off between performance (F1-score) and time (inference response time) for each language model to provide a more nuanced understanding of each model's practical applicability. Our work reveals significant variations in model responses based on the prompting strategies. We find that LLMs, particularly Llama3 and GPT-4, can outperform traditional methods in complex classification tasks, such as multiclass classification, though at the cost of longer inference times. In contrast, simpler ML models offer better performance-to-time trade-offs in simpler binary classification tasks.", 'abstract_zh': '利用大型语言模型（LLMs）在数据分类中的潜力代表了自然语言处理领域的一个有前景的前沿方向。在本文中，我们评估了不同LLMs与最新深度学习和机器学习模型在两种不同的分类场景中的性能表现：i) 根据在线发布的职位评论分类员工的工作地点（多类别分类）；ii) 将新闻文章分类为假新闻或真新闻（二元分类）。我们的分析涵盖了多种在大小、量化和架构方面有所区别的语言模型。我们探讨了替代提示技术的影响，并根据加权F1分数来评估这些模型。我们还分析了每种语言模型的性能（F1分数）与时间（推理响应时间）之间的权衡，以提供对每种模型实际应用性的更细致理解。我们的研究揭示了基于提示策略的模型响应在模型性能上的显著差异。我们发现，尤其是在复杂分类任务（如多类别分类）中，LLM，特别是Llama3和GPT-4，可以超越传统的分类方法，尽管这意味着需要更长的推理时间。相比之下，在简单的二元分类任务中，更简单的机器学习模型提供了更好的性能与时间之间的权衡。', 'title_zh': '大型语言模型在文本分类中的应用：案例研究与综述'}
{'arxiv_id': 'arXiv:2501.08442', 'title': 'Jochre 3 and the Yiddish OCR corpus', 'authors': 'Assaf Urieli, Amber Clooney, Michelle Sigiel, Grisha Leyfer', 'link': 'https://arxiv.org/abs/2501.08442', 'abstract': 'We describe the construction of a publicly available Yiddish OCR Corpus, and describe and evaluate the open source OCR tool suite Jochre 3, including an Alto editor for corpus annotation, OCR software for Alto OCR layer generation, and a customizable OCR search engine. The current version of the Yiddish OCR corpus contains 658 pages, 186K tokens and 840K glyphs. The Jochre 3 OCR tool uses various fine-tuned YOLOv8 models for top-down page layout analysis, and a custom CNN network for glyph recognition. It attains a CER of 1.5% on our test corpus, far out-performing all other existing public models for Yiddish. We analyzed the full 660M word Yiddish Book Center with Jochre 3 OCR, and the new OCR is searchable through the Yiddish Book Center OCR search engine.', 'abstract_zh': '我们描述了构建一个公开可用的意第绪语OCR语料库的过程，并介绍了开源OCR工具套件Jochre 3的各项功能，包括针对语料库注解的Alto编辑器、用于Alto OCR层生成的OCR软件以及自定义的OCR搜索引擎。当前版本的意第绪语OCR语料库包含658页，186,000个词token和840,000个字符glyph。Jochre 3 OCR工具使用了多种微调后的YOLOv8模型进行自上而下的页面布局分析，并使用自定义的CNN网络进行字符识别。在我们的测试语料库上，Jochre 3 OCR工具实现了1.5%的字符错误率(CER)，远超所有现有的公开模型。我们使用Jochre 3 OCR工具对意第绪语书中心的全部6.6亿词语料进行了处理，新生成的OCR内容可以通过意第绪语书中心的OCR搜索引擎进行搜索。', 'title_zh': 'Jochre 3 和 Yiddish OCR语料库'}
{'arxiv_id': 'arXiv:2501.08441', 'title': 'Religious Bias Landscape in Language and Text-to-Image Models: Analysis, Detection, and Debiasing Strategies', 'authors': 'Ajwad Abrar, Nafisa Tabassum Oeshy, Mohsinul Kabir, Sophia Ananiadou', 'link': 'https://arxiv.org/abs/2501.08441', 'abstract': 'Note: This paper includes examples of potentially offensive content related to religious bias, presented solely for academic purposes. The widespread adoption of language models highlights the need for critical examinations of their inherent biases, particularly concerning religion. This study systematically investigates religious bias in both language models and text-to-image generation models, analyzing both open-source and closed-source systems. We construct approximately 400 unique, naturally occurring prompts to probe language models for religious bias across diverse tasks, including mask filling, prompt completion, and image generation. Our experiments reveal concerning instances of underlying stereotypes and biases associated disproportionately with certain religions. Additionally, we explore cross-domain biases, examining how religious bias intersects with demographic factors such as gender, age, and nationality. This study further evaluates the effectiveness of targeted debiasing techniques by employing corrective prompts designed to mitigate the identified biases. Our findings demonstrate that language models continue to exhibit significant biases in both text and image generation tasks, emphasizing the urgent need to develop fairer language models to achieve global acceptability.', 'abstract_zh': '注意：本文包含与宗教偏见相关的潜在冒犯性内容，仅用于学术研究目的。语言模型的广泛应用突显了对其固有偏见进行批判性研究的必要性，尤其是对于宗教方面的偏见。本文系统性地研究了语言模型和文本到图片生成模型中的宗教偏见，分析了包括开源和封闭源系统在内的多种系统。我们构建了约400个独特的、自然出现的提示，以在各类任务中（包括掩码填充、提示完成和图像生成）探究宗教偏见。实验揭示了与某些宗教不成比例相关的潜在刻板印象和偏见。此外，我们还研究了跨领域的偏见，探讨了宗教偏见与其他人口统计因素（如性别、年龄和国籍）的交叉影响。本文进一步评估了针对性偏见修正技术的有效性，通过应用设计用于缓解已识别偏见的纠正提示。研究结果表明，语言模型在文本和图像生成任务中仍然表现出显著的偏见，强调了开发更加公正的模型以实现全球接受度的紧迫需求。', 'title_zh': '语言和文本到图像模型中的宗教偏见景观：分析、检测及去bias策略'}
{'arxiv_id': 'arXiv:2501.08413', 'title': 'Ensemble of Large Language Models for Curated Labeling and Rating of Free-text Data', 'authors': 'Jiaxing Qiu, Dongliang Guo, Papini Natalie, Peace Noelle, Levinson Cheri, Teague R. Henry', 'link': 'https://arxiv.org/abs/2501.08413', 'abstract': "Free-text responses are commonly collected in psychological studies, providing rich qualitative insights that quantitative measures may not capture. Labeling curated topics of research interest in free-text data by multiple trained human coders is typically labor-intensive and time-consuming. Though large language models (LLMs) excel in language processing, LLM-assisted labeling techniques relying on closed-source LLMs cannot be directly applied to free-text data, without explicit consent for external use.\nIn this study, we propose a framework of assembling locally-deployable LLMs to enhance the labeling of predetermined topics in free-text data under privacy constraints. Analogous to annotation by multiple human raters, this framework leverages the heterogeneity of diverse open-source LLMs. The ensemble approach seeks a balance between the agreement and disagreement across LLMs, guided by a relevancy scoring methodology that utilizes embedding distances between topic descriptions and LLMs' reasoning. We evaluated the ensemble approach using both publicly accessible Reddit data from eating disorder related forums, and free-text responses from eating disorder patients, both complemented by human annotations.\nWe found that: (1) there is heterogeneity in the performance of labeling among same-sized LLMs, with some showing low sensitivity but high precision, while others exhibit high sensitivity but low precision. (2) Compared to individual LLMs, the ensemble of LLMs achieved the highest accuracy and optimal precision-sensitivity trade-off in predicting human annotations. (3) The relevancy scores across LLMs showed greater agreement than dichotomous labels, indicating that the relevancy scoring method effectively mitigates the heterogeneity in LLMs' labeling.", 'abstract_zh': '在心理学研究中，通常会收集开放文本回应，这些回应提供了丰富的定性见解，而这些见解可能无法通过定量测量捕捉到。为了在开放文本数据中标注研究感兴趣的主题，通常需要多个经过训练的人工编码员进行标注，这通常是耗费大量时间和人力的。尽管大型语言模型（LLMs）在语言处理方面表现出色，但依赖闭源LLMs的LLM辅助标注技术在没有明确外部使用同意的情况下无法直接应用于开放文本数据。\n\n本研究提出了一种在隐私约束下增强对预定主题的开放文本数据标注的框架。类比于多个人类评估者的手动标注，该框架利用了多种开源LLMs的多样性。集成方法旨在在不同LLM之间找到一种平衡，即通过主题描述与LLM推理之间的嵌入距离来评估相关性得分方法，来平衡一致性和分歧。我们使用来自饮食障碍相关论坛的公开可访问的Reddit数据和饮食障碍患者的开放文本回应进行了评估，这些数据都与人类注释相补充。\n\n研究结果表明：（1）相同规模的LLM在标注性能上存在异质性，一些LLM表现出低灵敏度但高精确度，而另一些则表现出高灵敏度但低精确度。（2）与单个LLM相比，LLM的集成在预测人类注释方面实现了最高的准确性以及最佳的精确度-灵敏度权衡。（3）LLM之间的相关性得分比二元标签显示了更高的共识，表明相关性得分方法有效地减轻了LLM标注中的异质性。', 'title_zh': '大型语言模型的集成用于精选标注和评估自由文本数据'}
{'arxiv_id': 'arXiv:2501.08335', 'title': 'MERaLiON-TextLLM: Cross-Lingual Understanding of Large Language Models in Chinese, Indonesian, Malay, and Singlish', 'authors': 'Xin Huang, Tarun Kumar Vangani, Minh Duc Pham, Xunlong Zou, Bin Wang, Zhengyuan Liu, Ai Ti Aw', 'link': 'https://arxiv.org/abs/2501.08335', 'abstract': 'Multilingual large language models (MLLMs) have shown impressive capabilities across a variety of languages. However, efficacy can differ greatly between different language families, especially for those with limited linguistic resources. This report presents MERaLiON-TextLLM, a series of open-source language models specifically tailored to improve understanding and generation in Chinese, Indonesian, Malay, and Singlish. The initial released model is built on Llama-3-8B-Base and refined through a meticulously crafted process of continued pre-training and weight merging. Our approach achieves performance improvements across benchmarks in these languages, exceeding the capabilities of the official Llama-3 models. We provide the model checkpoints as a resource to support further research and development in cross-lingual language understanding.', 'abstract_zh': '多语言大型语言模型（MLLMs）在多种语言上展现出了卓越的能力。然而，不同语言家族之间的效果差异显著，尤其对于那些资源有限的语言。本报告介绍了MERaLiON-TextLLM，这是一个针对中文、印尼语、马来语和Singlish进行优化的开源语言模型系列，旨在提高这些语言的理解和生成能力。最初发布的模型基于Llama-3-8B-Base，并通过精心设计的持续预训练和权重合并过程进行优化。我们的方法在这些语言的标准测试中实现了性能提升，超过了官方Llama-3模型的能力。我们提供模型检查点作为资源，以支持跨语言语言理解的进一步研究与开发。', 'title_zh': 'MERaLiON-TextLLM：中文、印尼语、马来语和英式马来语大型语言模型的跨语言理解'}
{'arxiv_id': 'arXiv:2501.09012', 'title': 'Multimodal LLMs Can Reason about Aesthetics in Zero-Shot', 'authors': 'Ruixiang Jiang, Changwen Chen', 'link': 'https://arxiv.org/abs/2501.09012', 'abstract': "We present the first study on how Multimodal LLMs' (MLLMs) reasoning ability shall be elicited to evaluate the aesthetics of artworks. To facilitate this investigation, we construct MM-StyleBench, a novel high-quality dataset for benchmarking artistic stylization. We then develop a principled method for human preference modeling and perform a systematic correlation analysis between MLLMs' responses and human preference. Our experiments reveal an inherent hallucination issue of MLLMs in art evaluation, associated with response subjectivity. ArtCoT is proposed, demonstrating that art-specific task decomposition and the use of concrete language boost MLLMs' reasoning ability for aesthetics. Our findings offer valuable insights into MLLMs for art and can benefit a wide range of downstream applications, such as style transfer and artistic image generation. Code available at this https URL.", 'abstract_zh': '我们首次探讨了如何通过多模态大语言模型（MLLMs）的推理能力来评估艺术品的审美。为了便于这项研究，我们构建了一个新的高质量数据集MM-StyleBench，用于艺术风格化评估基准测试。随后，我们开发了一种原则性的方法来建模人类偏好，并系统地分析了MLLMs的响应与人类偏好的相关性。实验结果揭示了MLLMs在艺术评估中存在固有的推理偏差问题，与响应的主观性相关。我们提出了ArtCoT，证明了一种特定于艺术任务的分解方法和使用具体语言能够增强MLLMs的审美推理能力。我们的研究成果为艺术领域中的MLLMs提供了有价值的见解，并可以应用于多种下游应用，如风格迁移和艺术图像生成。代码可在以下链接获取：this https URL。', 'title_zh': '多模态大型语言模型可以在零样本情况下进行美学推理'}
{'arxiv_id': 'arXiv:2501.08925', 'title': 'Disentangling Exploration of Large Language Models by Optimal Exploitation', 'authors': 'Tim Grams, Patrick Betz, Christian Bartelt', 'link': 'https://arxiv.org/abs/2501.08925', 'abstract': 'Exploration is a crucial skill for self-improvement and open-ended problem-solving. However, it remains uncertain whether large language models can effectively explore the state-space. Existing evaluations predominantly focus on the trade-off between exploration and exploitation, often assessed in multi-armed bandit problems. In contrast, this work isolates exploration as the sole objective, tasking the agent with delivering information that enhances future returns. For the evaluation, we propose to decompose missing rewards into exploration and exploitation components by measuring the optimal achievable return for the states already explored. Our experiments with various LLMs reveal that most models struggle to sufficiently explore the state-space and that weak exploration is insufficient. We observe a positive correlation between model size and exploration performance, with larger models demonstrating superior capabilities. Furthermore, we show that our decomposition provides insights into differences in behaviors driven by agent instructions during prompt engineering, offering a valuable tool for refining LLM performance in exploratory tasks.', 'abstract_zh': '探索是自我提升和解决开放性问题的关键技能。然而，目前尚不清楚大型语言模型是否能够有效地探索状态空间。现有的评估主要集中在探索与利用之间的权衡，通常是在多臂 bandit 问题中进行评估。与此不同，本研究将探索作为唯一目标，要求代理提供能够增强未来收益的信息。为评估目的，我们建议通过衡量已探索状态的最优可实现回报来将缺失的奖励分解为探索和利用两个部分。我们的实验表明，大多数模型在探索状态空间方面面临挑战，且不足的探索是不够的。我们观察到模型大小与探索性能之间存在正相关关系，较大的模型表现出更好的能力。此外，我们展示了我们的分解方法有助于理解由代理指令在提示工程中驱动的不同行为，为提升大型语言模型在探索性任务中的性能提供了有价值的工具。', 'title_zh': '通过对大型语言模型的最优利用实现探索解耦'}
{'arxiv_id': 'arXiv:2501.08828', 'title': 'MMDocIR: Benchmarking Multi-Modal Retrieval for Long Documents', 'authors': 'Kuicai Dong, Yujing Chang, Xin Deik Goh, Dexun Li, Ruiming Tang, Yong Liu', 'link': 'https://arxiv.org/abs/2501.08828', 'abstract': 'Multi-modal document retrieval is designed to identify and retrieve various forms of multi-modal content, such as figures, tables, charts, and layout information from extensive documents. Despite its significance, there is a notable lack of a robust benchmark to effectively evaluate the performance of systems in multi-modal document retrieval. To address this gap, this work introduces a new benchmark, named as MMDocIR, encompassing two distinct tasks: page-level and layout-level retrieval. The former focuses on localizing the most relevant pages within a long document, while the latter targets the detection of specific layouts, offering a more fine-grained granularity than whole-page analysis. A layout can refer to a variety of elements such as textual paragraphs, equations, figures, tables, or charts. The MMDocIR benchmark comprises a rich dataset featuring expertly annotated labels for 1,685 questions and bootstrapped labels for 173,843 questions, making it a pivotal resource for advancing multi-modal document retrieval for both training and evaluation. Through rigorous experiments, we reveal that (i) visual retrievers significantly outperform their text counterparts, (ii) MMDocIR train set can effectively benefit the training process of multi-modal document retrieval and (iii) text retrievers leveraging on VLM-text perform much better than those using OCR-text. These findings underscores the potential advantages of integrating visual elements for multi-modal document retrieval.', 'abstract_zh': '多模态文档检索旨在识别和检索各种形式的多模态内容，如图表、表格、图表以及布局信息，这些内容广泛存在于各种文档中。尽管其重要性不言而喻，但在多模态文档检索中，缺少一个有效的基准来评估系统性能的问题依然突出。为解决这一问题，本研究提出了一种名为MMDocIR的新基准，涵盖两个独立的任务：页级检索和布局级检索。页级检索专注于在长文档中识别最相关的页面，而布局级检索则针对特定布局的检测，提供了比全页分析更精细的粒度。布局可以包含文本段落、公式、图表、表格等各种元素。MMDocIR基准数据集包含1,685个问题的专家标注标签和173,843个问题的自举标注标签，成为推动多模态文档检索培训和评估的关键资源。\n\n通过严谨的实验，我们发现：(i) 视觉检索器在性能上显著优于文本检索器；(ii) MMDocIR的训练集可以有效促进多模态文档检索的培训过程；(iii) 利用VLM文本的文本检索器在性能上明显优于使用OCR文本的检索器。这些发现突显了在多模态文档检索中整合视觉元素的潜在优势。', 'title_zh': 'MMDocIR：长文档多模态检索基准测试'}
{'arxiv_id': 'arXiv:2501.08814', 'title': 'SAIF: A Comprehensive Framework for Evaluating the Risks of Generative AI in the Public Sector', 'authors': 'Kyeongryul Lee, Heehyeon Kim, Joyce Jiyoung Whang', 'link': 'https://arxiv.org/abs/2501.08814', 'abstract': 'The rapid adoption of generative AI in the public sector, encompassing diverse applications ranging from automated public assistance to welfare services and immigration processes, highlights its transformative potential while underscoring the pressing need for thorough risk assessments. Despite its growing presence, evaluations of risks associated with AI-driven systems in the public sector remain insufficiently explored. Building upon an established taxonomy of AI risks derived from diverse government policies and corporate guidelines, we investigate the critical risks posed by generative AI in the public sector while extending the scope to account for its multimodal capabilities. In addition, we propose a Systematic dAta generatIon Framework for evaluating the risks of generative AI (SAIF). SAIF involves four key stages: breaking down risks, designing scenarios, applying jailbreak methods, and exploring prompt types. It ensures the systematic and consistent generation of prompt data, facilitating a comprehensive evaluation while providing a solid foundation for mitigating the risks. Furthermore, SAIF is designed to accommodate emerging jailbreak methods and evolving prompt types, thereby enabling effective responses to unforeseen risk scenarios. We believe that this study can play a crucial role in fostering the safe and responsible integration of generative AI into the public sector.', 'abstract_zh': '公共部门内生成型AI的快速采用涵盖了从自动化公共援助到福利服务和移民流程等多种应用，突显了其变革潜力的同时也突出了进行全面风险评估的紧迫需求。尽管生成型AI在公共部门的影响力越来越大，但有关AI驱动系统相关风险的评价仍存在不足。基于从多样化政府政策和企业指南中推导出的AI风险分类体系，我们研究了生成型AI在公共部门中所面临的关键风险，并扩展了研究范围以涵盖其多模态能力。在此基础上，我们提出了一种系统性数据生成框架（Systematic Data Generation Framework for Evaluating the Risks of Generative AI，简称SAIF）。SAIF 涉及四个关键步骤：分解风险、设计情景、应用脱疆方法和探索提示类型。该方法确保系统性和一致性的提示数据生成，促进全面的风险评估，并为风险缓解提供坚实的基础。此外，SAIF 设计了适应新兴脱疆方法和变化的提示类型，从而能够对不可预见的风险情景作出有效应对。我们认为，本研究可以在此过程中发挥关键作用，促进生成型AI在公共部门的安全和负责任的集成。', 'title_zh': 'SAIF：公共部门生成式人工智能风险评估的综合框架'}
{'arxiv_id': 'arXiv:2501.08686', 'title': 'Knowledge Graph-based Retrieval-Augmented Generation for Schema Matching', 'authors': 'Chuangtao Ma, Sriom Chakrabarti, Arijit Khan, Bálint Molnár', 'link': 'https://arxiv.org/abs/2501.08686', 'abstract': 'Traditional similarity-based schema matching methods are incapable of resolving semantic ambiguities and conflicts in domain-specific complex mapping scenarios due to missing commonsense and domain-specific knowledge. The hallucination problem of large language models (LLMs) also makes it challenging for LLM-based schema matching to address the above issues. Therefore, we propose a Knowledge Graph-based Retrieval-Augmented Generation model for Schema Matching, referred to as the KG-RAG4SM. In particular, KG-RAG4SM introduces novel vector-based, graph traversal-based, and query-based graph retrievals, as well as a hybrid approach and ranking schemes that identify the most relevant subgraphs from external large knowledge graphs (KGs). We showcase that KG-based retrieval-augmented LLMs are capable of generating more accurate results for complex matching cases without any re-training. Our experimental results show that KG-RAG4SM outperforms the LLM-based state-of-the-art (SOTA) methods (e.g., Jellyfish-8B) by 35.89% and 30.50% in terms of precision and F1 score on the MIMIC dataset, respectively; KG-RAG4SM with GPT-4o-mini outperforms the pre-trained language model (PLM)-based SOTA methods (e.g., SMAT) by 69.20% and 21.97% in terms of precision and F1 score on the Synthea dataset, respectively. The results also demonstrate that our approach is more efficient in end-to-end schema matching, and scales to retrieve from large KGs. Our case studies on the dataset from the real-world schema matching scenario exhibit that the hallucination problem of LLMs for schema matching is well mitigated by our solution.', 'abstract_zh': '传统的基于相似性的模式匹配方法由于缺乏常识性和领域特定知识，在处理复杂的领域特定模式映射场景时无法解决语义模糊性和冲突问题。大型语言模型（LLMs）的幻觉问题也使其在解决上述问题时面临挑战。因此，我们提出了一种基于知识图谱的检索增强生成模型（Retrieval-Augmented Generation, RAG）用于模式匹配，称之为KG-RAG4SM。特别地，KG-RAG4SM 引入了基于向量、图遍历和查询的新型图检索方法，以及混合方法和排序方案，可以从外部大型知识图谱（KGs）中识别出最相关的子图。我们展示了基于知识图谱的检索增强LLMs能够生成更准确的结果，而无需任何重新训练。实验结果表明，KG-RAG4SM 在MIMIC数据集上分别在准确率和F1分数方面优于最新的LLM基线方法（如Jellyfish-8B）35.89% 和30.50%；使用GPT-4o-mini 的KG-RAG4SM 在Synthea数据集上分别在准确率和F1分数方面优于基于预训练语言模型（Pre-trained Language Model, PLM）的最新基线方法（如SMAT）69.20% 和21.97%。这些结果还表明，我们的方法在端到端模式匹配中更有效，并且能够从大型知识图谱中检索信息。我们的案例研究还表明，我们的解决方案很好地解决了LLMs在模式匹配中的幻觉问题。', 'title_zh': '基于知识图谱的检索增强生成方法在模式匹配中的应用'}
{'arxiv_id': 'arXiv:2501.08631', 'title': 'SWSC: Shared Weight for Similar Channel in LLM', 'authors': 'Binrui Zeng, Yongtao Tang, Xiaodong Liu, Xiaopeng Li', 'link': 'https://arxiv.org/abs/2501.08631', 'abstract': 'Large language models (LLMs) have spurred development in multiple industries. However, the growing number of their parameters brings substantial storage and computing burdens, making it essential to explore model compression techniques for parameter reduction and easier deployment. We propose SWSC, an LLM compression method based on the concept of Shared Weight for Similar Channel. It uses the K-Means clustering algorithm to cluster model weights channel-by-channel, generating clusters with highly similar vectors within each. A representative vector from each cluster is selected to approximately replace all vectors in the cluster, significantly reducing the number of model weight parameters. However, approximate restoration will inevitably cause damage to the performance of the model. To tackle this issue, we perform singular value decomposition on the weight error values before and after compression and retain the larger singular values and their corresponding singular vectors to compensate for the accuracy. The experimental results show that our method can effectively ensure the performance of the compressed LLM even under low-precision conditions.', 'abstract_zh': '大语言模型（LLMs）在多个行业中推动了发展。然而，其参数数量的急剧增加带来了显著的存储和计算负担，因此探索模型压缩技术以减少参数并简化部署变得至关重要。我们提出了一种名为SWSC的方法，该方法基于“相似通道共享权重”的概念。它使用K-Means聚类算法按通道对模型权重进行聚类，在每个聚类内部生成具有高度相似向量的簇。从每个簇中选择一个代表向量来近似替换该簇中的所有向量，从而显著减少了模型权重的数量。然而，这种近似恢复不可避免地会对模型性能造成损害。为了解决这一问题，在压缩前后对权重误差值进行奇异值分解，并保留较大的奇异值及其对应的奇异向量，以补偿准确性损失。实验结果表明，即使在低精度条件下，该方法也能有效地确保压缩后的LLM的性能。', 'title_zh': 'SWSC: 相似频道共享权重在大语言模型中的应用'}
{'arxiv_id': 'arXiv:2501.08617', 'title': 'RLHS: Mitigating Misalignment in RLHF with Hindsight Simulation', 'authors': 'Kaiqu Liang, Haimin Hu, Ryan Liu, Thomas L. Griffiths, Jaime Fernández Fisac', 'link': 'https://arxiv.org/abs/2501.08617', 'abstract': "Generative AI systems like foundation models (FMs) must align well with human values to ensure their behavior is helpful and trustworthy. While Reinforcement Learning from Human Feedback (RLHF) has shown promise for optimizing model performance using human judgments, existing RLHF pipelines predominantly rely on immediate feedback, which can fail to accurately reflect the downstream impact of an interaction on users' utility. We demonstrate that feedback based on evaluators' foresight estimates of downstream consequences systematically induces Goodhart's Law dynamics, incentivizing misaligned behaviors like sycophancy and deception and ultimately degrading user outcomes. To alleviate this, we propose decoupling evaluation from prediction by refocusing RLHF on hindsight feedback. Our theoretical analysis reveals that conditioning evaluator feedback on downstream observations mitigates misalignment and improves expected human utility, even when these observations are simulated by the AI system itself. To leverage this insight in a practical alignment algorithm, we introduce Reinforcement Learning from Hindsight Simulation (RLHS), which first simulates plausible consequences and then elicits feedback to assess what behaviors were genuinely beneficial in hindsight. We apply RLHS to two widely-employed online and offline preference optimization methods -- Proximal Policy Optimization (PPO) and Direct Preference Optimization (DPO) -- and show empirically that misalignment is significantly reduced with both methods. Through an online human user study, we show that RLHS consistently outperforms RLHF in helping users achieve their goals and earns higher satisfaction ratings, despite being trained solely with simulated hindsight feedback. These results underscore the importance of focusing on long-term consequences, even simulated ones, to mitigate misalignment in RLHF.", 'abstract_zh': '生成式AI系统如基础模型（FMs）必须与人类价值观很好地对齐，以确保其行为具有帮助性和可信赖性。虽然从人类反馈中进行强化学习（RLHF）展示了通过人类评估优化模型性能的潜力，但现有的RLHF管道主要依赖即时反馈，这可能无法准确反映交互对用户效用的下游影响。我们证明，基于评估者对未来后果预估的反馈系统系统地诱导了Goodhart效应，激励了偏离价值观的行为（如拍马屁和欺骗），最终损害了用户的结果。为了解决这一问题，我们建议通过将评估与预测脱钩，重新聚焦于基于后见之明的RLHF。我们的理论分析表明，在下游观察结果的基础上条件反射评估者的反馈可以减轻偏离度并提高预期的人类效用，即使这些观察结果是由AI系统模拟出来的。为了在实际对齐算法中利用这一见解，我们提出了后见之明强化学习（RLHS），该方法首先模拟可能的后果，然后引发反馈来评估哪些行为在后见之明中确实是有益的。我们将RLHS应用于两种广泛使用的在线和离线偏好优化方法——近似策略优化（PPO）和直接偏好优化（DPO），并证明这两种方法的偏离度显著降低。通过一项在线真人用户研究，我们表明，尽管仅使用模拟的后见之明反馈进行训练，RLHS在帮助用户实现目标方面表现优于RLHF，并获得了更高的满意度评价。这些结果强调了即使模拟的，关注长期后果的重要性，以减少RLHF中的偏离度。', 'title_zh': 'RLHS：减轻RLHF中错配影响的 hindsight 回忆模拟方法'}
{'arxiv_id': 'arXiv:2501.08460', 'title': 'Towards Zero-Shot & Explainable Video Description by Reasoning over Graphs of Events in Space and Time', 'authors': 'Mihai Masala, Marius Leordeanu', 'link': 'https://arxiv.org/abs/2501.08460', 'abstract': 'In the current era of Machine Learning, Transformers have become the de facto approach across a variety of domains, such as computer vision and natural language processing. Transformer-based solutions are the backbone of current state-of-the-art methods for language generation, image and video classification, segmentation, action and object recognition, among many others. Interestingly enough, while these state-of-the-art methods produce impressive results in their respective domains, the problem of understanding the relationship between vision and language is still beyond our reach. In this work, we propose a common ground between vision and language based on events in space and time in an explainable and programmatic way, to connect learning-based vision and language state of the art models and provide a solution to the long standing problem of describing videos in natural language. We validate that our algorithmic approach is able to generate coherent, rich and relevant textual descriptions on videos collected from a variety of datasets, using both standard metrics (e.g. Bleu, ROUGE) and the modern LLM-as-a-Jury approach.', 'abstract_zh': '在当前的机器学习时代，变换器（Transformers）已成为各个领域，如计算机视觉和自然语言处理中的事实标准方法。基于变换器的解决方案是当前在语言生成、图像和视频分类、分割、动作和对象识别等众多领域的最先进方法的核心。令人感兴趣的是，尽管这些最先进方法在其各自领域中产生了令人印象深刻的成果，但视觉与语言之间关系的理解问题仍然超出了我们的能力范围。在本工作中，我们提出了将视觉与语言连接起来的一种方法，基于空间和时间中的事件，以可解释且程序化的形式构建这一桥梁，旨在将基于学习的视觉和语言最先进的模型连接起来，并提供描述视频的自然语言解释的解决方案。我们验证了我们的算法方法能够使用标准指标（例如Bleu、ROUGE）和现代的LLM作为陪审团的方法生成从多种数据集中收集的视频的连贯、丰富和相关文本描述。', 'title_zh': '面向空间与时间中事件图推理的零样本且可解释视频描述研究'}
{'arxiv_id': 'arXiv:2501.08454', 'title': 'Tag&Tab: Pretraining Data Detection in Large Language Models Using Keyword-Based Membership Inference Attack', 'authors': 'Sagiv Antebi, Edan Habler, Asaf Shabtai, Yuval Elovici', 'link': 'https://arxiv.org/abs/2501.08454', 'abstract': 'Large language models (LLMs) have become essential digital task assistance tools. Their training relies heavily on the collection of vast amounts of data, which may include copyright-protected or sensitive information. Recent studies on the detection of pretraining data in LLMs have primarily focused on sentence-level or paragraph-level membership inference attacks (MIAs), usually involving probability analysis of the target model prediction tokens. However, the proposed methods often demonstrate poor performance, specifically in terms of accuracy, failing to account for the semantic importance of textual content and word significance. To address these shortcomings, we propose Tag&Tab, a novel approach for detecting data that has been used as part of the LLM pretraining. Our method leverages advanced natural language processing (NLP) techniques to tag keywords in the input text - a process we term Tagging. Then, the LLM is used to obtain the probabilities of these keywords and calculate their average log-likelihood to determine input text membership, a process we refer to as Tabbing. Our experiments on three benchmark datasets (BookMIA, MIMIR, and the Pile) and several open-source LLMs of varying sizes demonstrate an average increase in the AUC scores ranging from 4.1% to 12.1% over state-of-the-art methods. Tag&Tab not only sets a new standard for data leakage detection in LLMs, but its outstanding performance is a testament to the importance of words in MIAs on LLMs.', 'abstract_zh': '大型语言模型（LLMs）已成为必不可少的数字任务辅助工具。它们的训练依赖于大量数据的收集，这些数据可能包括受版权保护或敏感信息。关于LLMs预训练数据检测的现有研究主要集中在句子级或段落级的成员身份推断攻击（MIA），通常涉及对目标模型预测令牌概率的分析。然而，提出的方法在准确性方面往往表现较差，未能充分考虑到文本内容和单词的重要意义。为了解决这些问题，我们提出了一种名为Tag&Tab的新方法，用于检测作为LLM预训练部分的数据。我们的方法利用先进的自然语言处理（NLP）技术对输入文本中的关键词进行标记——这一过程我们称为标记。然后，LLM用于获取这些关键词的概率，并计算它们的平均对数似然，以确定输入文本的成员身份，这一过程我们称为Tabbing。我们在三个基准数据集（BookMIA、MIMIR 和Pile）以及多个不同大小的开源LLM上进行的实验显示，与最先进的方法相比，平均AUC分数提高了4.1%至12.1%。Tag&Tab不仅为LLMs中的数据泄露检测设立了新的标准，其卓越的表现也证明了在LLMs中的成员身份推断中单词的重要性。', 'title_zh': '标签与制表符：基于关键词成员推理攻击的大规模语言模型中预训练数据检测'}
{'arxiv_id': 'arXiv:2501.08421', 'title': 'SEAL: Speaker Error Correction using Acoustic-conditioned Large Language Models', 'authors': 'Anurag Kumar, Rohit Paturi, Amber Afshan, Sundararajan Srinivasan', 'link': 'https://arxiv.org/abs/2501.08421', 'abstract': 'Speaker Diarization (SD) is a crucial component of modern end-to-end ASR pipelines. Traditional SD systems, which are typically audio-based and operate independently of ASR, often introduce speaker errors, particularly during speaker transitions and overlapping speech. Recently, language models including fine-tuned large language models (LLMs) have shown to be effective as a second-pass speaker error corrector by leveraging lexical context in the transcribed output. In this work, we introduce a novel acoustic conditioning approach to provide more fine-grained information from the acoustic diarizer to the LLM. We also show that a simpler constrained decoding strategy reduces LLM hallucinations, while avoiding complicated post-processing. Our approach significantly reduces the speaker error rates by 24-43% across Fisher, Callhome, and RT03-CTS datasets, compared to the first-pass Acoustic SD.', 'abstract_zh': '说话人鉴定（Speaker Diarization，SD）是现代端到端自动语音识别（ASR）流水线中的关键组成部分。传统的SD系统通常是基于音频的，并且通常独立于ASR操作，这往往会导致在说话人转换和重叠说话时出现说话人错误。近年来，包括微调的大规模语言模型（Large Language Models，LLMs）在利用转录输出中的词汇上下文来作为二次说话人错误纠正器方面显示出有效性。在本文中，我们提出了一种新的声学条件化方法，以提供给语言模型更细粒度的信息，来自声学鉴定器。我们还展示了简单的受限解码策略可以减少语言模型的幻觉，同时避免复杂的后处理。与第一次通过的声学SD方法相比，我们的方法在Fisher、Callhome和RT03-CTS数据集上显著减少了24-43%的说话人错误率。', 'title_zh': 'SEAL：基于声学条件的大语言模型说话人错误修正'}
{'arxiv_id': 'arXiv:2501.08406', 'title': 'OptiChat: Bridging Optimization Models and Practitioners with Large Language Models', 'authors': 'Hao Chen, Gonzalo Esteban Constante-Flores, Krishna Sri Ipsit Mantri, Sai Madhukiran Kompalli, Akshdeep Singh Ahluwalia, Can Li', 'link': 'https://arxiv.org/abs/2501.08406', 'abstract': "Optimization models have been applied to solve a wide variety of decision-making problems. These models are usually developed by optimization experts but are used by practitioners without optimization expertise in various application domains. As a result, practitioners often struggle to interact with and draw useful conclusions from optimization models independently. To fill this gap, we introduce OptiChat, a natural language dialogue system designed to help practitioners interpret model formulation, diagnose infeasibility, analyze sensitivity, retrieve information, evaluate modifications, and provide counterfactual explanations. By augmenting large language models (LLMs) with functional calls and code generation tailored for optimization models, we enable seamless interaction and minimize the risk of hallucinations in OptiChat. We develop a new dataset to evaluate OptiChat's performance in explaining optimization models. Experiments demonstrate that OptiChat effectively bridges the gap between optimization models and practitioners, delivering autonomous, accurate, and instant responses.", 'abstract_zh': '优化模型已被应用于解决众多决策问题。这些模型通常由优化专家开发，但在各种应用领域中，实际操作者（缺乏优化专业知识）会使用这些模型。因此，实际操作者往往难以独立地与优化模型交互并从中得出有用的结论。为填补这一空白，我们介绍了一个名为OptiChat的自然语言对话系统，旨在帮助实际操作者解释模型公式、诊断不可行性、分析敏感性、检索信息、评估修改并提供反事实解释。通过将大型语言模型（LLMs）与针对优化模型的功能调用和代码生成相结合，我们使OptiChat的交互更加顺畅，并减少了其产生幻觉的风险。我们开发了一个新的数据集来评估OptiChat在解释优化模型方面的性能。实验结果表明，OptiChat有效地弥合了优化模型与实际操作者之间的差距，提供了自主、准确且即时的响应。', 'title_zh': 'OptiChat：连接优化模型与 Practitioners 的大型语言模型桥梁'}
{'arxiv_id': 'arXiv:2501.08365', 'title': 'Towards Best Practices for Open Datasets for LLM Training', 'authors': 'Stefan Baack, Stella Biderman, Kasia Odrozek, Aviya Skowron, Ayah Bdeir, Jillian Bommarito, Jennifer Ding, Maximilian Gahntz, Paul Keller, Pierre-Carl Langlais, Greg Lindahl, Sebastian Majstorovic, Nik Marda, Guilherme Penedo, Maarten Van Segbroeck, Jennifer Wang, Leandro von Werra, Mitchell Baker, Julie Belião, Kasia Chmielinski, Marzieh Fadaee, Lisa Gutermuth, Hynek Kydlíček, Greg Leppert, EM Lewis-Jong, Solana Larsen, Shayne Longpre, Angela Oduor Lungati, Cullen Miller, Victor Miller, Max Ryabinin, Kathleen Siminyu, Andrew Strait, Mark Surman, Anna Tumadóttir, Maurice Weber, Rebecca Weiss, Lee White, Thomas Wolf', 'link': 'https://arxiv.org/abs/2501.08365', 'abstract': 'Many AI companies are training their large language models (LLMs) on data without the permission of the copyright owners. The permissibility of doing so varies by jurisdiction: in countries like the EU and Japan, this is allowed under certain restrictions, while in the United States, the legal landscape is more ambiguous. Regardless of the legal status, concerns from creative producers have led to several high-profile copyright lawsuits, and the threat of litigation is commonly cited as a reason for the recent trend towards minimizing the information shared about training datasets by both corporate and public interest actors. This trend in limiting data information causes harm by hindering transparency, accountability, and innovation in the broader ecosystem by denying researchers, auditors, and impacted individuals access to the information needed to understand AI models.\nWhile this could be mitigated by training language models on open access and public domain data, at the time of writing, there are no such models (trained at a meaningful scale) due to the substantial technical and sociological challenges in assembling the necessary corpus. These challenges include incomplete and unreliable metadata, the cost and complexity of digitizing physical records, and the diverse set of legal and technical skills required to ensure relevance and responsibility in a quickly changing landscape. Building towards a future where AI systems can be trained on openly licensed data that is responsibly curated and governed requires collaboration across legal, technical, and policy domains, along with investments in metadata standards, digitization, and fostering a culture of openness.', 'abstract_zh': '许多人工智能公司正在未经版权持有者许可的情况下训练其大型语言模型（LLMs）。这种行为在不同司法管辖区的合法性有所不同：在欧盟和日本等国家，这在一定限制下是被允许的，而在美国，法律环境则更为模糊。无论法律状况如何，创意生产者的担忧导致了多起高调的版权诉讼案件，诉讼威胁经常被列为近期企业及公共利益方减少分享训练数据信息趋势的原因之一。这种减少数据信息的趋势损害了整个生态系统中的透明度、问责制和创新，因为它阻止了研究人员、审计员以及受影响的个人获取理解AI模型所需的信息。\n\n尽管可以通过使用开放获取和公共领域数据来训练语言模型来缓解这一问题，但目前尚无大规模训练此类模型的情况，原因在于大量技术和社会挑战。这些挑战包括不完整和不可靠的元数据、数字化物理记录的高昂成本和技术复杂性，以及确保在快速变化的环境中的相关性和责任感所必需的多样化的法律和技术技能。为实现未来能够负责任地利用许可证开放数据进行AI系统训练和管理的愿景，需要跨法律、技术和政策领域的合作，并需在元数据标准、数字化和促进开放文化方面进行投资。', 'title_zh': '面向大规模语言模型训练的最佳开放数据集实践指南'}
