{'arxiv_id': 'arXiv:2501.08686', 'title': 'Knowledge Graph-based Retrieval-Augmented Generation for Schema Matching', 'authors': 'Chuangtao Ma, Sriom Chakrabarti, Arijit Khan, Bálint Molnár', 'link': 'https://arxiv.org/abs/2501.08686', 'abstract': 'Traditional similarity-based schema matching methods are incapable of resolving semantic ambiguities and conflicts in domain-specific complex mapping scenarios due to missing commonsense and domain-specific knowledge. The hallucination problem of large language models (LLMs) also makes it challenging for LLM-based schema matching to address the above issues. Therefore, we propose a Knowledge Graph-based Retrieval-Augmented Generation model for Schema Matching, referred to as the KG-RAG4SM. In particular, KG-RAG4SM introduces novel vector-based, graph traversal-based, and query-based graph retrievals, as well as a hybrid approach and ranking schemes that identify the most relevant subgraphs from external large knowledge graphs (KGs). We showcase that KG-based retrieval-augmented LLMs are capable of generating more accurate results for complex matching cases without any re-training. Our experimental results show that KG-RAG4SM outperforms the LLM-based state-of-the-art (SOTA) methods (e.g., Jellyfish-8B) by 35.89% and 30.50% in terms of precision and F1 score on the MIMIC dataset, respectively; KG-RAG4SM with GPT-4o-mini outperforms the pre-trained language model (PLM)-based SOTA methods (e.g., SMAT) by 69.20% and 21.97% in terms of precision and F1 score on the Synthea dataset, respectively. The results also demonstrate that our approach is more efficient in end-to-end schema matching, and scales to retrieve from large KGs. Our case studies on the dataset from the real-world schema matching scenario exhibit that the hallucination problem of LLMs for schema matching is well mitigated by our solution.', 'abstract_zh': '传统基于相似性的模式匹配方法在处理领域特定复杂的映射场景时难以解决语义歧义和冲突，因为这些方法缺乏常识和领域特定的知识。大型语言模型（LLMs）的幻觉问题也使其难以解决上述问题。因此，我们提出了一种基于知识图谱的检索增强生成模型，称之为KG-RAG4SM。特别地，KG-RAG4SM 引入了基于向量的、基于图遍历的和基于查询的图检索方法，以及一种混合方法和排名方案，从而从外部大型知识图谱（KGs）中识别出最相关的子图。我们展示了基于知识图谱的检索增强LLMs能够在无需重新训练的情况下生成更准确的结果。实验结果表明，KG-RAG4SM 在 MIMIC 数据集上的准确率和F1 分数分别比基于LLMs的最先进的（SOTA）方法（例如Jellyfish-8B）高出35.89%和30.50%；使用GPT-4o-mini的KG-RAG4SM在Synthea数据集上的准确率和F1 分数分别比基于预训练语言模型（PLM）的SOTA 方法（例如SMAT）高69.20%和21.97%。实验结果还表明，我们的方法在端到端模式匹配中更有效率，并且能够扩展到从大规模知识图谱中检索。我们在实际模式匹配场景中的数据集上进行的案例研究显示，通过我们的解决方案可以很好地缓解LLMs在模式匹配中的幻觉问题。', 'title_zh': '基于知识图谱的检索增强生成方法在模式匹配中的应用'}
