{'arxiv_id': 'arXiv:2412.17259', 'title': 'LegalAgentBench: Evaluating LLM Agents in Legal Domain', 'authors': 'Haitao Li, Junjie Chen, Jingli Yang, Qingyao Ai, Wei Jia, Youfeng Liu, Kai Lin, Yueyue Wu, Guozhi Yuan, Yiran Hu, Wuyue Wang, Yiqun Liu, Minlie Huang', 'link': 'https://arxiv.org/abs/2412.17259', 'abstract': 'With the increasing intelligence and autonomy of LLM agents, their potential applications in the legal domain are becoming increasingly apparent. However, existing general-domain benchmarks cannot fully capture the complexity and subtle nuances of real-world judicial cognition and decision-making. Therefore, we propose LegalAgentBench, a comprehensive benchmark specifically designed to evaluate LLM Agents in the Chinese legal domain. LegalAgentBench includes 17 corpora from real-world legal scenarios and provides 37 tools for interacting with external knowledge. We designed a scalable task construction framework and carefully annotated 300 tasks. These tasks span various types, including multi-hop reasoning and writing, and range across different difficulty levels, effectively reflecting the complexity of real-world legal scenarios. Moreover, beyond evaluating final success, LegalAgentBench incorporates keyword analysis during intermediate processes to calculate progress rates, enabling more fine-grained evaluation. We evaluated eight popular LLMs, highlighting the strengths, limitations, and potential areas for improvement of existing models and methods. LegalAgentBench sets a new benchmark for the practical application of LLMs in the legal domain, with its code and data available at \\url{this https URL}.', 'abstract_zh': '随着大型语言模型（LLM）代理的智能和自主性的增强，它们在法律领域的潜在应用变得愈发明显。然而，现有的通用领域基准无法全面捕捉到现实司法认知和决策中的复杂性和细微差别。因此，我们提出了一个专门针对中国法律领域的基准测试，即LegalAgentBench。LegalAgentBench 包括来自真实法律情境的17个语料库，并提供了37种与外部知识交互的工具。我们设计了一个可扩展的任务构建框架，并仔细标注了300个任务。这些任务涵盖了多种类型，包括多步推理和写作，并涵盖了不同的难度级别，有效地反映了现实法律情境的复杂性。此外，与仅仅评价最终的成功不同，LegalAgentBench 在中间过程中也进行了关键词分析以计算进度率，从而实现更为精细的评价。我们评估了八个流行的LLM，突显了现有模型和方法的优点、局限性和改进潜力。LegalAgentBench 为LLM在法律领域的实践应用设立了新的基准，其代码和数据可在 \\url{this https URL} 获取。', 'title_zh': 'LegalAgentBench：评估法律领域中的语言模型代理'}
{'arxiv_id': 'arXiv:2412.16725', 'title': 'Argumentation Computation with Large Language Models : A Benchmark Study', 'authors': 'Zhaoqun Li, Xiaotong Fang, Chen Chen, Mengze Li, Beishui Liao', 'link': 'https://arxiv.org/abs/2412.16725', 'abstract': "In recent years, large language models (LLMs) have made significant advancements in neuro-symbolic computing. However, the combination of LLM with argumentation computation remains an underexplored domain, despite its considerable potential for real-world applications requiring defeasible reasoning. In this paper, we aim to investigate the capability of LLMs in determining the extensions of various abstract argumentation semantics. To achieve this, we develop and curate a benchmark comprising diverse abstract argumentation frameworks, accompanied by detailed explanations of algorithms for computing extensions. Subsequently, we fine-tune LLMs on the proposed benchmark, focusing on two fundamental extension-solving tasks. As a comparative baseline, LLMs are evaluated using a chain-of-thought approach, where they struggle to accurately compute semantics. In the experiments, we demonstrate that the process explanation plays a crucial role in semantics computation learning. Models trained with explanations show superior generalization accuracy compared to those trained solely with question-answer pairs. Furthermore, by leveraging the self-explanation capabilities of LLMs, our approach provides detailed illustrations that mitigate the lack of transparency typically associated with neural networks. Our findings contribute to the broader understanding of LLMs' potential in argumentation computation, offering promising avenues for further research in this domain.", 'abstract_zh': '近年来，大型语言模型（LLMs）在神经符号计算方面取得了显著进展。然而，尽管架设LLMs与论证计算相结合具有重要的现实应用潜力，尤其是在要求进行可撤销推理的情况下，这一领域仍相对未被充分探索。本文旨在探讨LLMs在确定各种抽象论证语义扩展方面的潜力。为此，我们构建并整理了一个基准数据集，该数据集包含多种不同的抽象论证框架，并附带上详细的算法解释。接着，我们针对两个基本的扩展求解任务对LLMs进行微调。为了进行比较，我们采用链式思考的方法评估LLMs，结果显示它们在准确计算语义方面存在困难。在实验中，我们证明了过程解释在语义计算学习中的关键作用。使用带有解释训练的模型表现出比仅使用问答对训练的模型更好的泛化准确性。此外，通过利用LLMs的自我解释能力，我们的方法提供了详细的示例图，减轻了神经网络固有的透明度不足问题。我们的发现为更广泛理解LLMs在论证计算中的潜力做出了贡献，并为该领域的进一步研究提供了有希望的途径。', 'title_zh': '大规模语言模型中的论辩计算：一项基准研究'}
