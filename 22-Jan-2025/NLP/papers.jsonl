{'arxiv_id': 'arXiv:2501.12336', 'title': 'FuocChuVIP123 at CoMeDi Shared Task: Disagreement Ranking with XLM-Roberta Sentence Embeddings and Deep Neural Regression', 'authors': 'Phuoc Duong Huy Chu', 'link': 'https://arxiv.org/abs/2501.12336', 'abstract': 'This paper presents results of our system for CoMeDi Shared Task, focusing on Subtask 2: Disagreement Ranking. Our system leverages sentence embeddings generated by the paraphrase-xlm-r-multilingual-v1 model, combined with a deep neural regression model incorporating batch normalization and dropout for improved generalization. By predicting the mean of pairwise judgment differences between annotators, our method explicitly targets disagreement ranking, diverging from traditional "gold label" aggregation approaches. We optimized our system with a customized architecture and training procedure, achieving competitive performance in Spearman correlation against mean disagreement labels. Our results highlight the importance of robust embeddings, effective model architecture, and careful handling of judgment differences for ranking disagreement in multilingual contexts. These findings provide insights into the use of contextualized representations for ordinal judgment tasks and open avenues for further refinement of disagreement prediction models.', 'abstract_zh': '本文介绍了我们在CoMeDi共享任务中的系统成果，重点是子任务2：分歧排名。我们的系统利用了paraphrase-xlm-r-multilingual-v1模型生成的句子嵌入，并结合了一个含有批量归一化和dropout的深度神经回归模型，以提高泛化能力。通过预测注释者之间成对判断差异的均值，我们的方法明确针对分歧排名问题，不同于传统的“金标准”聚合方法。我们通过自定义架构和训练程序优化了系统，其在斯皮尔曼相关性方面达到了与均值分歧标签竞争的性能。我们的结果强调了在多语言背景下处理分歧排名时稳健嵌入、有效模型架构以及谨慎处理判断差异的重要性。这些发现为使用上下文化表示处理序数判断任务提供了见解，并为改进分歧预测模型指明了新的研究方向。', 'title_zh': 'FuocChuVIP123在CoMeDi共享任务中的研究：基于XLM-Roberta句子嵌入和深度神经回归的分歧排序'}
{'arxiv_id': 'arXiv:2501.12332', 'title': 'Automatic Labelling with Open-source LLMs using Dynamic Label Schema Integration', 'authors': 'Thomas Walshe, Sae Young Moon, Chunyang Xiao, Yawwani Gunawardana, Fran Silavong', 'link': 'https://arxiv.org/abs/2501.12332', 'abstract': 'Acquiring labelled training data remains a costly task in real world machine learning projects to meet quantity and quality requirements. Recently Large Language Models (LLMs), notably GPT-4, have shown great promises in labelling data with high accuracy. However, privacy and cost concerns prevent the ubiquitous use of GPT-4. In this work, we explore effectively leveraging open-source models for automatic labelling. We identify integrating label schema as a promising technology but found that naively using the label description for classification leads to poor performance on high cardinality tasks. To address this, we propose Retrieval Augmented Classification (RAC) for which LLM performs inferences for one label at a time using corresponding label schema; we start with the most related label and iterates until a label is chosen by the LLM. We show that our method, which dynamically integrates label description, leads to performance improvements in labelling tasks. We further show that by focusing only on the most promising labels, RAC can trade off between label quality and coverage - a property we leverage to automatically label our internal datasets.', 'abstract_zh': '满足数量和质量要求的标注训练数据的获取仍然是现实世界机器学习项目中的昂贵任务。最近，大型语言模型（LLMs），尤其是GPT-4，在数据标注准确性方面展现出了巨大的潜力。然而，隐私和成本问题限制了GPT-4的广泛应用。在这项工作中，我们探索了有效利用开源模型进行自动标注的方法。我们确定将标签架构集成是一种有前途的技术，但发现直接使用标签描述进行分类会导致高基数任务性能不佳。为此，我们提出了检索增强分类（RAC）方法，其中LLM逐个对应用相应的标签架构进行推理；我们从最相关的标签开始，并迭代直到LLM选择一个标签。我们展示了这种方法在动态集成标签描述方面的性能改进。我们进一步展示了通过仅关注最具前景的标签，RAC可以在标签质量和覆盖率之间进行权衡——我们利用这一点自动标注内部数据集。', 'title_zh': '使用动态标签 schema 整合的开源大语言模型自动标注方法'}
{'arxiv_id': 'arXiv:2501.12273', 'title': 'Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and Refinement', 'authors': 'Maosong Cao, Taolin Zhang, Mo Li, Chuyu Zhang, Yunxin Liu, Haodong Duan, Songyang Zhang, Kai Chen', 'link': 'https://arxiv.org/abs/2501.12273', 'abstract': 'The quality of Supervised Fine-Tuning (SFT) data plays a critical role in enhancing the conversational capabilities of Large Language Models (LLMs). However, as LLMs become more advanced, the availability of high-quality human-annotated SFT data has become a significant bottleneck, necessitating a greater reliance on synthetic training data. In this work, we introduce Condor, a novel two-stage synthetic data generation framework that incorporates World Knowledge Tree and Self-Reflection Refinement to produce high-quality SFT data at scale. Our experimental results demonstrate that a base model fine-tuned on only 20K Condor-generated samples achieves superior performance compared to counterparts. The additional refinement stage in Condor further enables iterative self-improvement for LLMs at various scales (up to 72B), validating the effectiveness of our approach. Furthermore, our investigation into the scaling for synthetic data in post-training reveals substantial unexplored potential for performance improvements, opening promising avenues for future research.', 'abstract_zh': '监督微调（SFT）数据的质量在提高大型语言模型（LLMs）对话能力方面起着关键作用。然而，随着LLMs的不断进步，高质量人工标注的SFT数据的可获得性已成为一个重要的瓶颈，从而需要更依赖合成训练数据。在本文中，我们介绍了Condor，这是一种新颖的两阶段合成数据生成框架，它结合了世界知识树和自我反思完善机制，以大规模生成高质量的SFT数据。我们的实验结果表明，仅使用20K个Condor生成样本来微调的基本模型在性能上优于其他模型。Condor中的额外完善阶段还进一步促进了各种规模（多达72B）LLMs的迭代自我改进，这证实了我们方法的有效性。此外，我们对后训练合成数据的扩展性研究揭示了显著的未探索性能提升潜力，为未来的研究打开了有希望的研究方向。', 'title_zh': 'CONDOR：通过知识驱动的数据合成与精炼增强语言模型的对齐性'}
{'arxiv_id': 'arXiv:2501.12183', 'title': 'Extend Adversarial Policy Against Neural Machine Translation via Unknown Token', 'authors': 'Wei Zou, Shujian Huang, Jiajun Chen', 'link': 'https://arxiv.org/abs/2501.12183', 'abstract': "Generating adversarial examples contributes to mainstream neural machine translation~(NMT) robustness. However, popular adversarial policies are apt for fixed tokenization, hindering its efficacy for common character perturbations involving versatile tokenization. Based on existing adversarial generation via reinforcement learning~(RL), we propose the `DexChar policy' that introduces character perturbations for the existing mainstream adversarial policy based on token substitution. Furthermore, we improve the self-supervised matching that provides feedback in RL to cater to the semantic constraints required during training adversaries. Experiments show that our method is compatible with the scenario where baseline adversaries fail, and can generate high-efficiency adversarial examples for analysis and optimization of the system.", 'abstract_zh': '生成对抗样本有助于提高主流神经机器翻译（NMT）的鲁棒性。然而，流行的对抗策略多针对固定分词方式，这限制了其在涉及多种分词方式的常见字符扰动中的有效性。基于现有的通过强化学习（RL）生成的对抗样本，我们提出了一个名为`DexChar策略`的方法，该方法在现有的基于令牌替换的主流对抗策略中引入了字符扰动。此外，我们改进了自监督匹配，以提供在RL中的反馈，适应训练过程中所需的语义约束。实验结果表明，我们的方法在基线对抗样本失效的情景下具有兼容性，能够生成高效且便于分析和优化系统的对抗样本。', 'title_zh': '通过未知令牌扩展对抗性策略以增强神经机器翻译'}
{'arxiv_id': 'arXiv:2501.12162', 'title': 'AdaServe: SLO-Customized LLM Serving with Fine-Grained Speculative Decoding', 'authors': 'Zikun Li, Zhuofu Chen, Remi Delacourt, Gabriele Oliaro, Zeyu Wang, Qinghan Chen, Shuhuai Lin, April Yang, Zhihao Zhang, Zhuoming Chen, Sean Lai, Xupeng Miao, Zhihao Jia', 'link': 'https://arxiv.org/abs/2501.12162', 'abstract': "This paper introduces AdaServe, the first LLM serving system to support SLO customization through fine-grained speculative decoding. AdaServe leverages the logits of a draft model to predict the speculative accuracy of tokens and employs a theoretically optimal algorithm to construct token trees for verification. To accommodate diverse SLO requirements without compromising throughput, AdaServe employs a speculation-and-selection scheme that first constructs candidate token trees for each request and then dynamically selects tokens to meet individual SLO constraints while optimizing throughput. Comprehensive evaluations demonstrate that AdaServe achieves up to 73% higher SLO attainment and 74% higher goodput compared to state-of-the-art systems. These results underscore AdaServe's potential to enhance the efficiency and adaptability of LLM deployments across varied application scenarios.", 'abstract_zh': '本文介绍了AdaServe，这是首个通过细粒度推测解码支持自定义服务水平目标（SLA）的LLM服务系统。AdaServe 利用草稿模型的logits来预测推测性解码的准确性，并采用理论上最优的算法构建查验词树。为了满足不同类型的SLA需求而不牺牲吞吐量，AdaServe 采用了一种推测与选择方案：首先为每个请求构建候选词树，然后动态选择满足个体SLA约束并优化吞吐量的词。全面的评估表明，与现有最先进的系统相比，AdaServe 的SLA达成率可提高73%，有效吞吐量提高74%。这些结果凸显了AdaServe 在提高LLM部署效率和适应性方面的潜力，适用于各种应用场景。', 'title_zh': 'AdaServe：基于细粒度推测解码的SLO定制化大语言模型服务'}
{'arxiv_id': 'arXiv:2501.12147', 'title': 'Improving Influence-based Instruction Tuning Data Selection for Balanced Learning of Diverse Capabilities', 'authors': 'Qirun Dai, Dylan Zhang, Jiaqi W. Ma, Hao Peng', 'link': 'https://arxiv.org/abs/2501.12147', 'abstract': "Selecting appropriate training data is crucial for effective instruction fine-tuning of large language models (LLMs), which aims to (1) elicit strong capabilities, and (2) achieve balanced performance across a diverse range of tasks. Influence-based methods show promise in achieving (1) by estimating the contribution of each training example to the model's predictions, but often struggle with (2). Our systematic investigation reveals that this underperformance can be attributed to an inherent bias where certain tasks intrinsically have greater influence than others. As a result, data selection is often biased towards these tasks, not only hurting the model's performance on others but also, counterintuitively, harms performance on these high-influence tasks themselves.\nAs a remedy, we propose BIDS, a Balanced and Influential Data Selection algorithm. BIDS first normalizes influence scores of the training data, and then iteratively balances data selection by choosing the training example with the highest influence on the most underrepresented task. Experiments with both Llama-3 and Mistral-v0.3 on seven benchmarks spanning five diverse capabilities show that BIDS consistently outperforms both state-of-the-art influence-based algorithms and other non-influence-based selection frameworks. Surprisingly, training on a 15% subset selected by BIDS can even outperform full-dataset training with a much more balanced performance. Our analysis further highlights the importance of both instance-level normalization and iterative optimization of selected data for balanced learning of diverse capabilities.", 'abstract_zh': '选择合适的训练数据对于大型语言模型（LLMs）的有效指令微调至关重要，其目标包括（1）激发强大的能力，以及（2）在多种多样的任务中实现平衡的表现。基于影响的方法通过估计每个训练样本对模型预测的贡献显示出实现目标（1）的潜力，但在实现目标（2）方面通常会遇到困难。我们的系统研究揭示了这种低性能的根源在于一种固有的偏向，即某些任务从根本上来说具有比其他任务更大的影响。因此，数据选择往往倾向于这些任务，不仅损害了模型在其他任务上的表现，还出乎意料地损害了这些高影响任务本身的表现。\n\n为此，我们提出了一种平衡且有影响力的样本选择算法——BIDS（Balanced and Influential Data Selection）。BIDS首先对训练数据的影响得分进行归一化处理，然后通过选择对最未被充分代表的任务影响最大的训练样本来逐步平衡数据选择。在涵盖五个不同能力的七个基准测试中，我们使用Llama-3和Mistral-v0.3进行实验，结果显示BIDS在性能上始终优于最先进的影响驱动算法及其他非影响驱动的数据选择框架。出人意料的是，使用BIDS挑选的15%的数据集进行训练，可以实现比完整数据集训练更均衡的表现。进一步的分析还强调了实例级归一化和迭代优化所选数据对于学习多样化能力的平衡的重要性。', 'title_zh': '改进基于影响的指令调优数据选择方法，以实现能力多样性的均衡学习'}
{'arxiv_id': 'arXiv:2501.12106', 'title': "Can open source large language models be used for tumor documentation in Germany? -- An evaluation on urological doctors' notes", 'authors': 'Stefan Lenz, Arsenij Ustjanzew, Marco Jeray, Torsten Panholzer', 'link': 'https://arxiv.org/abs/2501.12106', 'abstract': "Tumor documentation in Germany is largely done manually, requiring reading patient records and entering data into structured databases. Large language models (LLMs) could potentially enhance this process by improving efficiency and reliability. This evaluation tests eleven different open source LLMs with sizes ranging from 1-70 billion model parameters on three basic tasks of the tumor documentation process: identifying tumor diagnoses, assigning ICD-10 codes, and extracting the date of first diagnosis. For evaluating the LLMs on these tasks, a dataset of annotated text snippets based on anonymized doctors' notes from urology was prepared. Different prompting strategies were used to investigate the effect of the number of examples in few-shot prompting and to explore the capabilities of the LLMs in general. The models Llama 3.1 8B, Mistral 7B, and Mistral NeMo 12 B performed comparably well in the tasks. Models with less extensive training data or having fewer than 7 billion parameters showed notably lower performance, while larger models did not display performance gains. Examples from a different medical domain than urology could also improve the outcome in few-shot prompting, which demonstrates the ability of LLMs to handle tasks needed for tumor documentation. Open source LLMs show a strong potential for automating tumor documentation. Models from 7-12 billion parameters could offer an optimal balance between performance and resource efficiency. With tailored fine-tuning and well-designed prompting, these models might become important tools for clinical documentation in the future. The code for the evaluation is available from this https URL. We also release the dataset as a new valuable resource that addresses the shortage of authentic and easily accessible benchmarks in German-language medical NLP.", 'abstract_zh': '德国的肿瘤记录主要依赖手工操作，需要阅读患者的病历并将其数据输入到结构化的数据库中。大规模语言模型（LLMs）有可能通过提高效率和可靠性来增强这个过程。这项评估测试了包括1-70亿模型参数在内的11种不同的开源LLM在肿瘤记录过程中的三种基本任务上的表现：识别肿瘤诊断、分配ICD-10代码以及提取首次诊断日期。为了评估这些任务上的LLM表现，我们准备了一个基于匿名泌尿科医生笔记的注释数据集。通过使用不同的提示策略，我们调查了少量提示中提供示例数量对性能的影响，并探索了LLM的一般能力。Llama 3.1 8B、Mistral 7B和Mistral NeMo 12B在这些任务上表现相当出色。与更少训练数据的模型或参数少于7亿的模型相比，这些模型显示出显著更低的性能；而更大的模型却没有表现出性能提升。使用不同医学领域的示例可能在少量提示中也能够提高任务表现，这表明LLM能够处理肿瘤记录所需的任务。开源LLM显示出在自动化肿瘤记录方面强大的潜力。从7亿到12亿参数的模型可能在性能和资源效率之间提供最优平衡。通过定制的微调和精心设计的提示策略，这些模型将来可能成为临床文档的重要工具。评估的代码可以在以下链接获得：[这里](https://example.com/code)。我们还发布了这个数据集，作为在德语医学NLP领域稀缺且容易获取的基准的新有价值的资源。', 'title_zh': '开源大型语言模型是否可以用于德国的肿瘤记录？——基于泌尿科医生病历的评估'}
{'arxiv_id': 'arXiv:2501.12051', 'title': 'MedS$^3$: Towards Medical Small Language Models with Self-Evolved Slow Thinking', 'authors': 'Shuyang Jiang, Yusheng Liao, Zhe Chen, Ya Zhang, Yanfeng Wang, Yu Wang', 'link': 'https://arxiv.org/abs/2501.12051', 'abstract': 'Medical language models (MLMs) have become pivotal in advancing medical natural language processing. However, prior models that rely on pre-training or supervised fine-tuning often exhibit low data efficiency and limited practicality in real-world clinical applications. While OpenAIs O1 highlights test-time scaling in mathematics, attempts to replicate this approach in medicine typically distill responses from GPT-series models to open-source models, focusing primarily on multiple-choice tasks. This strategy, though straightforward, neglects critical concerns like data privacy and realistic deployment in clinical settings. In this work, we present a deployable, small-scale medical language model, \\mone, designed for long-chain reasoning in clinical tasks using a self-evolution paradigm. Starting with a seed dataset of around 8,000 instances spanning five domains and 16 datasets, we prompt a base policy model to perform Monte Carlo Tree Search (MCTS) to construct verifiable reasoning chains. Each reasoning step is assigned an evolution rollout value, allowing verified trajectories to train the policy model and the reward model. During inference, the policy model generates multiple responses, and the reward model selects the one with the highest reward score. Experiments on eleven evaluation datasets demonstrate that \\mone outperforms prior open-source models by 2 points, with the addition of the reward model further boosting performance ($\\sim$13 points), surpassing GPT-4o-mini. Code and data are available at \\url{this https URL}.', 'abstract_zh': '医疗语言模型（MLMs）在推动医疗自然语言处理方面发挥了重要作用。然而，依赖预训练或监督微调的先前模型往往在实际临床应用中表现出较低的数据效率和实用性。尽管OpenAI的O1在数学上强调测试时的扩展性，但在医疗领域的尝试通常是从GPT系列模型中抽取响应到开源模型，主要集中在多项选择任务上。这种策略虽然简单直接，但忽视了数据隐私和临床环境中的实际部署等关键问题。本文介绍了一种可部署的小规模医疗语言模型\\mone，采用自我演化范式，应用于临床任务的长链推理。从一个包含约8,000个实例、覆盖五个领域和16个数据集的种子数据集开始，我们促使基础策略模型执行蒙特卡洛树搜索（MCTS）来构建可验证的推理链。每个推理步骤都被赋予一个演化执行值，使经过验证的轨迹能够训练策略模型和奖励模型。在推理过程中，策略模型生成多个响应，奖励模型选择得分最高的一个。在十一个评估数据集上的实验结果表明，\\mone 在性能上比之前的开源模型提高了2个点，加入奖励模型进一步提升了性能（约13个点），超过了GPT-4o-mini。相关代码和数据可在 \\url{此链接} 获取。', 'title_zh': '医学生命周期模型：迈向具有自我演化慢思考的医疗小型语言模型'}
{'arxiv_id': 'arXiv:2501.12011', 'title': 'Reference-free Evaluation Metrics for Text Generation: A Survey', 'authors': 'Takumi Ito, Kees van Deemter, Jun Suzuki', 'link': 'https://arxiv.org/abs/2501.12011', 'abstract': "A number of automatic evaluation metrics have been proposed for natural language generation systems. The most common approach to automatic evaluation is the use of a reference-based metric that compares the model's output with gold-standard references written by humans. However, it is expensive to create such references, and for some tasks, such as response generation in dialogue, creating references is not a simple matter. Therefore, various reference-free metrics have been developed in recent years. In this survey, which intends to cover the full breadth of all NLG tasks, we investigate the most commonly used approaches, their application, and their other uses beyond evaluating models. The survey concludes by highlighting some promising directions for future research.", 'abstract_zh': '近年来，已经提出了多种自动评估指标来评估自然语言生成系统。自动评估最常见的方式是使用参照基指标，该指标将模型输出与由人类编写的黄金标准参考文本进行比较。然而，创建这些参考文本非常昂贵，并且对于某些任务（如对话中的响应生成），创建参考文本并不是一件简单的事情。因此，近年来开发了各种无参照基的评估指标。在这篇旨在涵盖所有自然语言生成任务的综述中，我们研究了最常用的评估方法、它们的应用以及它们在评估模型之外的其他用途。综述最后强调了一些值得未来研究的方向。', 'title_zh': '基于参考的文本生成评价指标：一个综述'}
{'arxiv_id': 'arXiv:2501.11977', 'title': 'Leveraging Graph Structures and Large Language Models for End-to-End Synthetic Task-Oriented Dialogues', 'authors': 'Maya Medjad, Hugo Imbert, Bruno Yun, Raphaël Szymocha, Frédéric Armetta', 'link': 'https://arxiv.org/abs/2501.11977', 'abstract': 'Training task-oriented dialogue systems is both costly and time-consuming, due to the need for high-quality datasets encompassing diverse intents. Traditional methods depend on extensive human annotation, while recent advancements leverage large language models (LLMs) to generate synthetic data. However, these approaches often require custom prompts or code, limiting accessibility for non-technical users. We introduce GraphTOD, an end-to-end framework that simplifies the generation of task-oriented dialogues. Users can create dialogues by specifying transition graphs in JSON format. Our evaluation demonstrates that GraphTOD generates high-quality dialogues across various domains, significantly lowering the cost and complexity of dataset creation.', 'abstract_zh': '训练面向任务的对话系统既耗时又耗资，原因在于需要涵盖多样意图的高质量数据集。传统方法依赖于广泛的-human标注，而近期的进步则利用大规模语言模型（LLMs）生成合成数据。然而，这些方法往往需要定制化的提示或代码，这限制了非技术人员的可访问性。我们介绍了一种名为GraphTOD的端到端框架，该框架简化了面向任务的对话生成过程。用户可以通过指定JSON格式的转换图来创建对话。我们的评估表明，GraphTOD能够在多个领域生成高质量的对话，显著降低了数据集创建的成本和复杂性。', 'title_zh': '利用图结构和大规模语言模型实现端到端的任务导向合成对话'}
{'arxiv_id': 'arXiv:2501.11967', 'title': 'A Hybrid Attention Framework for Fake News Detection with Large Language Models', 'authors': 'Xiaochuan Xu, Peiyang Yu, Zeqiu Xu, Jiani Wang', 'link': 'https://arxiv.org/abs/2501.11967', 'abstract': 'With the rapid growth of online information, the spread of fake news has become a serious social challenge. In this study, we propose a novel detection framework based on Large Language Models (LLMs) to identify and classify fake news by integrating textual statistical features and deep semantic features. Our approach utilizes the contextual understanding capability of the large language model for text analysis and introduces a hybrid attention mechanism to focus on feature combinations that are particularly important for fake news identification. Extensive experiments on the WELFake news dataset show that our model significantly outperforms existing methods, with a 1.5\\% improvement in F1 score. In addition, we assess the interpretability of the model through attention heat maps and SHAP values, providing actionable insights for content review strategies. Our framework provides a scalable and efficient solution to deal with the spread of fake news and helps build a more reliable online information ecosystem.', 'abstract_zh': '随着在线信息的快速增长，假新闻的传播已成为一个严重的社会挑战。本研究提出了一种基于大型语言模型（LLMs）的新型检测框架，通过整合文本统计特征和深层语义特征来识别和分类假新闻。该方法利用大型语言模型的文本理解能力进行文本分析，并引入混合注意力机制，聚焦于特别重要的假新闻识别特征组合。我们在WELFake新闻数据集上的广泛实验表明，我们的模型显著优于现有方法，F1分数提高了1.5%。此外，我们通过注意力热图和SHAP值评估了模型的可解释性，提供了内容审核策略的可操作见解。该框架提供了一个可扩展且高效的解决方案，应对假新闻的传播，并有助于构建一个更可靠的信息生态系统。', 'title_zh': '基于大型语言模型的虚假新闻检测混合注意力框架'}
{'arxiv_id': 'arXiv:2501.11960', 'title': 'TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection', 'authors': 'Yang Cao, Sikun Yang, Chen Li, Haolong Xiang, Lianyong Qi, Bo Liu, Rongsheng Li, Ming Liu', 'link': 'https://arxiv.org/abs/2501.11960', 'abstract': 'Text anomaly detection is crucial for identifying spam, misinformation, and offensive language in natural language processing tasks. Despite the growing adoption of embedding-based methods, their effectiveness and generalizability across diverse application scenarios remain under-explored. To address this, we present TAD-Bench, a comprehensive benchmark designed to systematically evaluate embedding-based approaches for text anomaly detection. TAD-Bench integrates multiple datasets spanning different domains, combining state-of-the-art embeddings from large language models with a variety of anomaly detection algorithms. Through extensive experiments, we analyze the interplay between embeddings and detection methods, uncovering their strengths, weaknesses, and applicability to different tasks. These findings offer new perspectives on building more robust, efficient, and generalizable anomaly detection systems for real-world applications.', 'abstract_zh': '文本异常检测对于在自然语言处理任务中识别垃圾信息、错误信息和不良语言至关重要。尽管嵌入式方法的采用正在增长，但它们在多种应用场景中的有效性和普适性仍待深入探索。为解决这一问题，我们提出了TAD-Bench，这是一个综合基准，旨在系统地评估嵌入式方法在文本异常检测中的效果。TAD-Bench 结合了来自大型语言模型的先进嵌入和多种异常检测算法，整合了涵盖不同领域的多个数据集。通过广泛实验，我们分析了嵌入和检测方法之间的相互作用，揭示了它们的优势、弱点及其在不同任务中的适用性。这些发现为构建更 robust、更高效且更普适的异常检测系统提供了新的视角，适用于实际应用。', 'title_zh': 'TAD-Bench：基于嵌入的文本异常检测综合基准'}
{'arxiv_id': 'arXiv:2501.11953', 'title': 'Proverbs Run in Pairs: Evaluating Proverb Translation Capability of Large Language Model', 'authors': 'Minghan Wang, Viet-Thanh Pham, Farhad Moghimifar, Thuy-Trang Vu', 'link': 'https://arxiv.org/abs/2501.11953', 'abstract': 'Despite achieving remarkable performance, machine translation (MT) research remains underexplored in terms of translating cultural elements in languages, such as idioms, proverbs, and colloquial expressions. This paper investigates the capability of state-of-the-art neural machine translation (NMT) and large language models (LLMs) in translating proverbs, which are deeply rooted in cultural contexts. We construct a translation dataset of standalone proverbs and proverbs in conversation for four language pairs. Our experiments show that the studied models can achieve good translation between languages with similar cultural backgrounds, and LLMs generally outperform NMT models in proverb translation. Furthermore, we find that current automatic evaluation metrics such as BLEU, CHRF++ and COMET are inadequate for reliably assessing the quality of proverb translation, highlighting the need for more culturally aware evaluation metrics.', 'abstract_zh': '尽管机器翻译（MT）研究在性能上取得了显著成就，但关于翻译文化元素如成语、格言和俚语的研究仍相对不足。本文探讨了最新神经机器翻译（NMT）和大语言模型（LLMs）在翻译格言方面的能力，这些格言深深植根于文化背景之中。我们为四组语言构建了一个独立格言及其在对话中的翻译数据集。实验显示，研究的模型可以在具有相似文化背景的语言之间取得良好的翻译效果，并且在格言翻译方面，大语言模型通常优于神经机器翻译模型。此外，我们发现当前自动评估指标如 BLEU、CHRF++ 和 COMET 在可靠评估格言翻译质量方面存在不足，强调了需要开发更多文化意识更强的评估指标的必要性。', 'title_zh': '成语成对出现：评估大型语言模型的成语翻译能力'}
{'arxiv_id': 'arXiv:2501.11951', 'title': 'HERITAGE: An End-to-End Web Platform for Processing Korean Historical Documents in Hanja', 'authors': 'Seyoung Song, Haneul Yoo, Jiho Jin, Kyunghyun Cho, Alice Oh', 'link': 'https://arxiv.org/abs/2501.11951', 'abstract': 'While Korean historical documents are invaluable cultural heritage, understanding those documents requires in-depth Hanja expertise. Hanja is an ancient language used in Korea before the 20th century, whose characters were borrowed from old Chinese but had evolved in Korea for centuries. Modern Koreans and Chinese cannot understand Korean historical documents without substantial additional help, and while previous efforts have produced some Korean and English translations, this requires in-depth expertise, and so most of the documents are not translated into any modern language. To address this gap, we present HERITAGE, the first open-source Hanja NLP toolkit to assist in understanding and translating the unexplored Korean historical documents written in Hanja. HERITAGE is a web-based platform providing model predictions of three critical tasks in historical document understanding via Hanja language models: punctuation restoration, named entity recognition, and machine translation (MT). HERITAGE also provides an interactive glossary, which provides the character-level reading of the Hanja characters in modern Korean, as well as character-level English definition. HERITAGE serves two purposes. First, anyone interested in these documents can get a general understanding from the model predictions and the interactive glossary, especially MT outputs in Korean and English. Second, since the model outputs are not perfect, Hanja experts can revise them to produce better annotations and translations. This would boost the translation efficiency and potentially lead to most of the historical documents being translated into modern languages, lowering the barrier on unexplored Korean historical documents.', 'abstract_zh': '尽管韩国历史文献是宝贵的文化遗产，但理解这些文献需要深入的汉字（Hanja）专业知识。汉字是在20世纪之前的韩国使用的古语言，它借鉴了古代汉语，但在韩国历经数个世纪的发展后有所演变。现代的韩国人和中国人如果不借助大量额外的帮助，无法理解韩国历史文献。尽管之前的努力已经产生了某些韩文和英文的翻译，但这需要深入的专门知识，因此大多数文献仍然未被翻译成现代语言。为了填补这一差距，我们提出了HERITAGE，这是首个开源的汉字（Hanja）自然语言处理工具包，旨在辅助理解和翻译未被充分利用的韩国历史文献，这些文献用汉字书写。HERITAGE 是一个基于网络的平台，通过汉字语言模型提供历史上文档理解的三个关键任务的模型预测：标点符号恢复、命名实体识别和机器翻译（MT）。HERITAGE 还提供了一个互动词典，为现代韩语中的汉字提供字符级读音，以及字符级的英语定义。HERITAGE 有两个目的。首先，任何对这些文献感兴趣的人可以从模型预测和互动词典中获得基本理解，特别是在韩文和英文的机器翻译输出方面。其次，由于模型输出并非完美，汉字专家可以对其加以修订，以产生更好的注释和翻译。这将提高翻译效率，并可能使大多数历史文献能够被翻译成现代语言，从而降低对未探索的韩国历史文献的壁垒。', 'title_zh': 'HERITAGE：一个端到端的处理韩文历史文献的网页平台（基于汉字）'}
{'arxiv_id': 'arXiv:2501.11918', 'title': 'LuxVeri at GenAI Detection Task 3: Cross-Domain Detection of AI-Generated Text Using Inverse Perplexity-Weighted Ensemble of Fine-Tuned Transformer Models', 'authors': 'Md Kamrujjaman Mobin, Md Saiful Islam', 'link': 'https://arxiv.org/abs/2501.11918', 'abstract': 'This paper presents our approach for Task 3 of the GenAI content detection workshop at COLING-2025, focusing on Cross-Domain Machine-Generated Text (MGT) Detection. We propose an ensemble of fine-tuned transformer models, enhanced by inverse perplexity weighting, to improve classification accuracy across diverse text domains. For Subtask A (Non-Adversarial MGT Detection), we combined a fine-tuned RoBERTa-base model with an OpenAI detector-integrated RoBERTa-base model, achieving an aggregate TPR score of 0.826, ranking 10th out of 23 detectors. In Subtask B (Adversarial MGT Detection), our fine-tuned RoBERTa-base model achieved a TPR score of 0.801, securing 8th out of 22 detectors. Our results demonstrate the effectiveness of inverse perplexity-based weighting for enhancing generalization and performance in both non-adversarial and adversarial MGT detection, highlighting the potential for transformer models in cross-domain AI-generated content detection.', 'abstract_zh': '本文介绍了我们在2025年COLING会议GenAI内容检测研讨会Task 3中的方法，重点关注跨领域机器生成文本（MGT）检测。我们提出了一种结合微调变压器模型的集成方案，并通过逆困惑度加权来提高在不同文本域中的分类准确性。对于子任务A（非对抗性MGT检测），我们将微调后的RoBERTa-base模型与OpenAI检测器集成的RoBERTa-base模型结合使用，获得了综合TPR得分为0.826的成绩，排名23个检测器中的第10位。对于子任务B（对抗性MGT检测），我们微调后的RoBERTa-base模型获得了TPR得分为0.801的成绩，排名22个检测器中的第8位。我们的结果表明，逆困惑度加权对于提高非对抗性和对抗性MGT检测的一般化能力和性能是有效的，突显了变压器模型在跨领域AI生成内容检测中的潜力。', 'title_zh': 'luxVeri 在 GenAI 检测任务 3 中的跨域 AI 生成文本检测：基于逆困惑度加权集成微调变压器模型'}
{'arxiv_id': 'arXiv:2501.11914', 'title': 'LuxVeri at GenAI Detection Task 1: Inverse Perplexity Weighted Ensemble for Robust Detection of AI-Generated Text across English and Multilingual Contexts', 'authors': 'Md Kamrujjaman Mobin, Md Saiful Islam', 'link': 'https://arxiv.org/abs/2501.11914', 'abstract': "This paper presents a system developed for Task 1 of the COLING 2025 Workshop on Detecting AI-Generated Content, focusing on the binary classification of machine-generated versus human-written text. Our approach utilizes an ensemble of models, with weights assigned according to each model's inverse perplexity, to enhance classification accuracy. For the English text detection task, we combined RoBERTa-base, RoBERTa-base with the OpenAI detector, and BERT-base-cased, achieving a Macro F1-score of 0.7458, which ranked us 12th out of 35 teams. We ensembled RemBERT, XLM-RoBERTa-base, and BERT-base-multilingual-case for the multilingual text detection task, employing the same inverse perplexity weighting technique. This resulted in a Macro F1-score of 0.7513, positioning us 4th out of 25 teams. Our results demonstrate the effectiveness of inverse perplexity weighting in improving the robustness of machine-generated text detection across both monolingual and multilingual settings, highlighting the potential of ensemble methods for this challenging task.", 'abstract_zh': '本文提出了一个系统，该系统用于2025年COLING研讨会“检测AI生成内容”任务1的一部分，聚焦于机器生成文本与人类撰写的文本之间的二元分类。我们采用了一种集成模型方法，并根据每个模型的逆困惑度分配权重，以提高分类准确性。对于英文文本检测任务，我们结合了RoBERTa-base、RoBERTa-base与OpenAI检测器以及BERT-base-cased，实现了宏F1分数0.7458，使我们在35支参赛队伍中排名第12位。对于多语言文本检测任务，我们采用RemBERT、XLM-RoBERTa-base和BERT-base-multilingual-cased进行集成，并使用同样的逆困惑度加权技术。这使得我们在25支参赛队伍中的排名为第4位。我们的结果表明，逆困惑度加权在提高机器生成文本检测的稳健性方面具有有效性，特别是在单一语言和多语言设置中，这突显了集成方法在这种具有挑战性的任务中的潜力。', 'title_zh': 'LuxVeri 在GenAI检测任务1中的逆困惑度加权ensemble方法：跨英文和多语言环境下生成文本的稳健检测'}
{'arxiv_id': 'arXiv:2501.11900', 'title': 'Panoramic Interests: Stylistic-Content Aware Personalized Headline Generation', 'authors': 'Junhong Lian, Xiang Ao, Xinyu Liu, Yang Liu, Qing He', 'link': 'https://arxiv.org/abs/2501.11900', 'abstract': "Personalized news headline generation aims to provide users with attention-grabbing headlines that are tailored to their preferences. Prevailing methods focus on user-oriented content preferences, but most of them overlook the fact that diverse stylistic preferences are integral to users' panoramic interests, leading to suboptimal personalization. In view of this, we propose a novel Stylistic-Content Aware Personalized Headline Generation (SCAPE) framework. SCAPE extracts both content and stylistic features from headlines with the aid of large language model (LLM) collaboration. It further adaptively integrates users' long- and short-term interests through a contrastive learning-based hierarchical fusion network. By incorporating the panoramic interests into the headline generator, SCAPE reflects users' stylistic-content preferences during the generation process. Extensive experiments on the real-world dataset PENS demonstrate the superiority of SCAPE over baselines.", 'abstract_zh': '个性化新闻标题生成旨在为用户提供能够引起其注意且符合其偏好的标题。当前的方法主要关注用户的内容偏好，但大多数方法忽略了多样化的风格偏好是用户全方位兴趣的重要组成部分，导致个性化效果欠佳。鉴于此，我们提出了一种新颖的风格-内容感知个性化标题生成（SCAPE）框架。SCAPE利用大型语言模型（LLM）的合作从新闻标题中提取内容和风格特征，并通过基于对比学习的层次融合网络适应性地整合用户的长期和短期兴趣。通过将全景兴趣融入标题生成器中，SCAPE在生成过程中反映了用户的内容-风格偏好。通过对实际数据集PENS的广泛实验，证明了SCAPE优于基线方法。', 'title_zh': '全景兴趣：风格内容aware个性化标题生成'}
{'arxiv_id': 'arXiv:2501.11885', 'title': 'Med-R$^2$: Crafting Trustworthy LLM Physicians through Retrieval and Reasoning of Evidence-Based Medicine', 'authors': 'Keer Lu, Zheng Liang, Da Pan, Shusen Zhang, Xin Wu, Weipeng Chen, Zenan Zhou, Guosheng Dong, Bin Cui, Wentao Zhang', 'link': 'https://arxiv.org/abs/2501.11885', 'abstract': 'In recent years, Large Language Models (LLMs) have exhibited remarkable capabilities in clinical scenarios. However, despite their potential, existing works face challenges when applying LLMs to medical settings. Strategies relying on training with medical datasets are highly cost-intensive and may suffer from outdated training data. Leveraging external knowledge bases is a suitable alternative, yet it faces obstacles such as limited retrieval precision and poor effectiveness in answer extraction. These issues collectively prevent LLMs from demonstrating the expected level of proficiency in mastering medical expertise. To address these challenges, we introduce Med-R^2, a novel LLM physician framework that adheres to the Evidence-Based Medicine (EBM) process, efficiently integrating retrieval mechanisms as well as the selection and reasoning processes of evidence, thereby enhancing the problem-solving capabilities of LLMs in healthcare scenarios and fostering a trustworthy LLM physician. Our comprehensive experiments indicate that Med-R^2 achieves a 14.87\\% improvement over vanilla RAG methods and even a 3.59\\% enhancement compared to fine-tuning strategies, without incurring additional training costs.', 'abstract_zh': '近年来，大规模语言模型（LLMs）在临床场景中展现出了非凡的能力。然而，尽管这些模型具有潜力，在将它们应用于医疗领域时仍面临诸多挑战。依赖医学数据集进行训练的方法成本高昂，且可能受到过时训练数据的影响。利用外部知识库是一个可行的替代方案，但此类方法也面临着诸如检索精度较低和难以有效抽取答案等障碍。这些问题共同阻碍了LLMs在掌握医学专业知识方面达到预期水平。为解决这些问题，我们提出了Med-R^2，这是一种新颖的LLM医生框架，遵循循证医学（EBM）过程，高效地整合了检索机制以及证据的选择和推理过程，从而增强LLMs在医疗场景中的问题解决能力，并培养一种值得信赖的LLM医生。我们全面的实验表明，Med-R^2 在与基础检索聚合（RAG）方法相比时展示了14.87% 的改进，并且相较于微调策略还展现了3.59% 的提升，而无需额外的训练成本。', 'title_zh': 'Med-R²：通过基于证据的医学检索与推理打造可信赖的LLM医生'}
{'arxiv_id': 'arXiv:2501.11877', 'title': 'From Drafts to Answers: Unlocking LLM Potential via Aggregation Fine-Tuning', 'authors': 'Yafu Li, Zhilin Wang, Tingchen Fu, Ganqu Cui, Sen Yang, Yu Cheng', 'link': 'https://arxiv.org/abs/2501.11877', 'abstract': 'Scaling data and model size has been proven effective for boosting the performance of large language models. In addition to training-time scaling, recent studies have revealed that increasing test-time computational resources can further improve performance. In this work, we introduce Aggregation Fine-Tuning (AFT), a supervised finetuning paradigm where the model learns to synthesize multiple draft responses, referred to as proposals, into a single, refined answer, termed aggregation. At inference time, a propose-and-aggregate strategy further boosts performance by iteratively generating proposals and aggregating them. Empirical evaluations on benchmark datasets show that AFT-trained models substantially outperform standard SFT. Notably, an AFT model, fine-tuned from Llama3.1-8B-Base with only 64k data, achieves a 41.3% LC win rate on AlpacaEval 2, surpassing significantly larger LLMs such as Llama3.1-405B-Instruct and GPT4. By combining sequential refinement and parallel sampling, the propose-and-aggregate framework scales inference-time computation in a flexible manner. Overall, These findings position AFT as a promising approach to unlocking additional capabilities of LLMs without resorting to increasing data volume or model size.', 'abstract_zh': '扩大数据量和模型规模已被证明能有效提升大型语言模型的性能。除了训练时的缩放，最近的研究表明，在测试时增加计算资源也能进一步提升性能。在本项工作中，我们引入了一种聚合微调（AFT，Aggregation Fine-Tuning） paradigm，该方法使模型学会将多个草稿回复（称为提案）合成一个精炼的答案，称为聚合。在推理时，通过迭代生成提案并进行聚合，可以进一步提升性能。在基准数据集上的实证评估表明，AFT 微调的模型显著优于标准的监督微调（SFT）。值得注意的是，一个从 Llama3.1-8B-Base 微调而来，只使用了64k数据的 AFT 模型，在 AlpacaEval 2 上的 LC 获胜率为41.3%，大幅超越了更大规模的LLM，如 Llama3.1-405B-Instruct 和 GPT4。通过结合顺序精炼和并行采样，提出-聚合框架能够在灵活的方式下扩大推理时的计算量。总体而言，这些发现将 AFT 定位为一种有前景的方法，能够在不增加数据量或模型规模的情况下解锁 LLM 的更多能力。', 'title_zh': '从草稿到答案：通过聚合微调解锁大规模语言模型的潜力'}
{'arxiv_id': 'arXiv:2501.11852', 'title': 'Cross-Entropy Attacks to Language Models via Rare Event Simulation', 'authors': 'Mingze Ni, Yongshun Gong, Wei Liu', 'link': 'https://arxiv.org/abs/2501.11852', 'abstract': 'Black-box textual adversarial attacks are challenging due to the lack of model information and the discrete, non-differentiable nature of text. Existing methods often lack versatility for attacking different models, suffer from limited attacking performance due to the inefficient optimization with word saliency ranking, and frequently sacrifice semantic integrity to achieve better attack outcomes. This paper introduces a novel approach to textual adversarial attacks, which we call Cross-Entropy Attacks (CEA), that uses Cross-Entropy optimization to address the above issues. Our CEA approach defines adversarial objectives for both soft-label and hard-label settings and employs CE optimization to identify optimal replacements. Through extensive experiments on document classification and language translation problems, we demonstrate that our attack method excels in terms of attacking performance, imperceptibility, and sentence quality.', 'abstract_zh': '黑盒文本对抗攻击由于缺乏模型信息以及文本的离散性和非可微特性而具有挑战性。现有方法往往在攻击不同模型时缺乏灵活性，因使用单词梯度显着性排名进行优化效率低下而导致攻击性能有限，并且经常牺牲语义完整性以实现更好的攻击效果。本文提出了一种新的文本对抗攻击方法，我们称之为目标交叉熵攻击（Cross-Entropy Attacks, CEA），该方法利用交叉熵优化来解决上述问题。我们的CEA方法在软标签和硬标签设置下定义了对抗目标，并采用交叉熵优化来识别最优替换。通过在文档分类和语言翻译问题上的广泛实验，我们证明了我们的攻击方法在攻击性能、不可感知性和句子质量方面表现出色。', 'title_zh': '通过稀有事件模拟对语言模型进行交叉熵攻击'}
{'arxiv_id': 'arXiv:2501.11851', 'title': 'Challenges in Expanding Portuguese Resources: A View from Open Information Extraction', 'authors': 'Marlo Souza, Bruno Cabral, Daniela Claro, Lais Salvador', 'link': 'https://arxiv.org/abs/2501.11851', 'abstract': 'Open Information Extraction (Open IE) is the task of extracting structured information from textual documents, independent of domain. While traditional Open IE methods were based on unsupervised approaches, recently, with the emergence of robust annotated datasets, new data-based approaches have been developed to achieve better results. These innovations, however, have focused mainly on the English language due to a lack of datasets and the difficulty of constructing such resources for other languages. In this work, we present a high-quality manually annotated corpus for Open Information Extraction in the Portuguese language, based on a rigorous methodology grounded in established semantic theories. We discuss the challenges encountered in the annotation process, propose a set of structural and contextual annotation rules, and validate our corpus by evaluating the performance of state-of-the-art Open IE systems. Our resource addresses the lack of datasets for Open IE in Portuguese and can support the development and evaluation of new methods and systems in this area.', 'abstract_zh': '开放信息提取（Open IE）是指从文本文件中提取结构化信息的任务，不受特定领域限制。传统上，Open IE 方法主要基于无监督方法，但随着稳健标注数据集的出现，最近开发了一些基于数据的方法，以实现更好的结果。然而，这些创新主要集中在英语上，因为缺乏其他语言的数据集，而且为其他语言构建此类资源的难度较大。本文中，我们介绍了基于严谨的方法论和现有语义理论的高质量手动标注语料库，用于葡萄牙语的开放信息提取。我们讨论了注释过程中遇到的挑战，提出了结构和上下文注释规则，并通过评估最新Open IE系统的性能来验证我们的语料库。我们的资源解决了葡萄牙语中Open IE数据集缺乏的问题，并可以支持该领域的新方法和系统的开发与评估。', 'title_zh': '扩展葡萄牙语资源的挑战：从开放信息提取的角度审视'}
{'arxiv_id': 'arXiv:2501.11849', 'title': 'Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance', 'authors': 'Nikos Kanakaris, Heng Ping, Xiongye Xiao, Nesreen K. Ahmed, Luca Luceri, Emilio Ferrara, Paul Bogdan', 'link': 'https://arxiv.org/abs/2501.11849', 'abstract': 'Detecting organized political campaigns is of paramount importance in fighting against disinformation on social media. Existing approaches for the identification of such organized actions employ techniques mostly from network science, graph machine learning and natural language processing. Their ultimate goal is to analyze the relationships and interactions (e.g. re-posting) among users and the textual similarities of their posts. Despite their effectiveness in recognizing astroturf campaigns, these methods face significant challenges, notably the class imbalance in available training datasets. To mitigate this issue, recent methods usually resort to data augmentation or increasing the number of positive samples, which may not always be feasible or sufficient in real-world settings. Following a different path, in this paper, we propose a novel framework for identifying astroturf campaigns based solely on large language models (LLMs), introducing a Balanced Retrieval-Augmented Generation (Balanced RAG) component. Our approach first gives both textual information concerning the posts (in our case tweets) and the user interactions of the social network as input to a language model. Then, through prompt engineering and the proposed Balanced RAG method, it effectively detects coordinated disinformation campaigns on X (Twitter). The proposed framework does not require any training or fine-tuning of the language model. Instead, by strategically harnessing the strengths of prompt engineering and Balanced RAG, it facilitates LLMs to overcome the effects of class imbalance and effectively identify coordinated political campaigns. The experimental results demonstrate that by incorporating the proposed prompt engineering and Balanced RAG methods, our framework outperforms the traditional graph-based baselines, achieving 2x-3x improvements in terms of precision, recall and F1 scores.', 'abstract_zh': '在社交媒体上对抗虚假信息时，检测有组织的政治竞选活动具有至关重要的作用。现有的识别此类有组织行动的方法主要采用网络科学、图机器学习和自然语言处理技术。这些方法的最终目标是分析用户之间的关系和互动（例如转发），以及他们帖子的文本相似性。尽管这些方法在识别草根运动方面表现出有效性，但它们面临显著的挑战，特别是在可用训练数据集中的类别不平衡问题。为了缓解这一问题，最近的方法通常依赖数据增强或增加正样本的数量，而在实际应用场景中这可能并不总是可行或足够的。\n\n秉持不同的思路，本论文提出了一种新的框架，仅基于大型语言模型（LLMs）识别草根运动，引入了平衡检索增强生成（Balanced RAG）组件。首先，我们的方法将帖子（本案例中为推文）的相关文本信息以及社交媒体用户互动作为输入提供给语言模型。然后，通过技巧性提示工程和提出的Balanced RAG方法，该框架有效地在X（推特）上检测协调性虚假信息运动。所提出框架无需对语言模型进行任何训练或微调。相反，通过战略性利用提示工程和Balanced RAG的优势，它使LLMs能够克服类别不平衡的影响，并有效识别有组织的政治运动。实验结果表明，通过结合所提出的提示工程和Balanced RAG方法，我们的框架在精确度、召回率和F1分数方面分别提高了2到3倍，优于传统的基于图的方法。', 'title_zh': '极端类别不平衡背景下基于网络的提示工程对抗有组织的伪民意运动'}
{'arxiv_id': 'arXiv:2501.11833', 'title': 'Is your LLM trapped in a Mental Set? Investigative study on how mental sets affect the reasoning capabilities of LLMs', 'authors': 'Saiful Haq, Niyati Chhaya, Piyush Pandey, Pushpak Bhattacharya', 'link': 'https://arxiv.org/abs/2501.11833', 'abstract': 'In this paper, we present an investigative study on how Mental Sets influence the reasoning capabilities of LLMs. LLMs have excelled in diverse natural language processing (NLP) tasks, driven by advancements in parameter-efficient fine-tuning (PEFT) and emergent capabilities like in-context learning (ICL). For complex reasoning tasks, selecting the right model for PEFT or ICL is critical, often relying on scores on benchmarks such as MMLU, MATH, and GSM8K. However, current evaluation methods, based on metrics like F1 Score or reasoning chain assessments by larger models, overlook a key dimension: adaptability to unfamiliar situations and overcoming entrenched thinking patterns. In cognitive psychology, Mental Set refers to the tendency to persist with previously successful strategies, even when they become inefficient - a challenge for problem solving and reasoning. We compare the performance of LLM models like Llama-3.1-8B-Instruct, Llama-3.1-70B-Instruct and GPT-4o in the presence of mental sets. To the best of our knowledge, this is the first study to integrate cognitive psychology concepts into the evaluation of LLMs for complex reasoning tasks, providing deeper insights into their adaptability and problem-solving efficacy.', 'abstract_zh': '在本文中，我们针对心理定势（Mental Sets）如何影响大模型（LLMs）的推理能力进行了探索性研究。大模型在多样化的自然语言处理（NLP）任务中表现出色，这得益于参数有效微调（PEFT）和内省学习（ICL）等新兴能力的发展。对于复杂的推理任务，选择适合PEFT或ICL的正确模型至关重要，通常依赖于诸如MMLU、MATH和GSM8K等基准测试的评分。然而，当前的评估方法，例如使用F1得分或由大型模型进行的推理链评估，未能涵盖一个重要维度：对不熟悉情况的适应能力和克服根深蒂固的思维模式的能力。在认知心理学中，心理定势是指即使策略变得不高效，仍然倾向于坚持先前成功的策略——这对问题解决和推理构成了挑战。我们比较了Llama-3.1-8B-Instruct、Llama-3.1-70B-Instruct和GPT-4o在面对心理定势时的表现。据我们所知，这是首次将认知心理学概念整合到对大模型进行复杂推理任务评估的研究中，为它们的适应能力和问题解决效果提供了更深入的见解。', 'title_zh': '你的大型语言模型（LLM）陷入思维定势了吗？关于思维定势如何影响大型语言模型推理能力的探究性研究'}
{'arxiv_id': 'arXiv:2501.11828', 'title': 'Fact-Preserved Personalized News Headline Generation', 'authors': 'Zhao Yang, Junhong Lian, Xiang Ao', 'link': 'https://arxiv.org/abs/2501.11828', 'abstract': "Personalized news headline generation, aiming at generating user-specific headlines based on readers' preferences, burgeons a recent flourishing research direction. Existing studies generally inject a user interest embedding into an encoderdecoder headline generator to make the output personalized, while the factual consistency of headlines is inadequate to be verified. In this paper, we propose a framework Fact-Preserved Personalized News Headline Generation (short for FPG), to prompt a tradeoff between personalization and consistency. In FPG, the similarity between the candidate news to be exposed and the historical clicked news is used to give different levels of attention to key facts in the candidate news, and the similarity scores help to learn a fact-aware global user embedding. Besides, an additional training procedure based on contrastive learning is devised to further enhance the factual consistency of generated headlines. Extensive experiments conducted on a real-world benchmark PENS validate the superiority of FPG, especially on the tradeoff between personalization and factual consistency.", 'abstract_zh': '基于读者偏好生成个性化新闻标题是一项近期兴起的研究方向，旨在根据读者的兴趣生成特定于用户的标题。现有研究通常在编码器-解码器标题生成器中注入用户兴趣嵌入，以使输出个性化，但标题的实际情况一致性难以验证。本文提出了一种框架“事实保全个性化新闻标题生成”（简称FPG），旨在在个性化与一致性之间寻求平衡。在FPG框架中，通过计算候选新闻与历史点击新闻之间的相似度，对候选新闻中的关键事实给予不同程度的关注，相似度评分有助于学习一个基于事实的全局用户嵌入。此外，还设计了一种基于对比学习的额外训练程序，以进一步增强生成标题的事实一致性。在实际基准PENS上进行的广泛实验验证了FPG的优越性，特别是在个性化与事实一致性之间的权衡方面。', 'title_zh': '事实保留个性化新闻标题生成'}
{'arxiv_id': 'arXiv:2501.11790', 'title': 'Benchmarking Large Language Models via Random Variables', 'authors': 'Zijin Hong, Hao Wu, Su Dong, Junnan Dong, Yilin Xiao, Yujing Zhang, Zhu Wang, Feiran Huang, Linyi Li, Hongxia Yang, Xiao Huang', 'link': 'https://arxiv.org/abs/2501.11790', 'abstract': "With the continuous advancement of large language models (LLMs) in mathematical reasoning, evaluating their performance in this domain has become a prominent research focus. Recent studies have raised concerns about the reliability of current mathematical benchmarks, highlighting issues such as simplistic design and potential data leakage. Therefore, creating a reliable benchmark that effectively evaluates the genuine capabilities of LLMs in mathematical reasoning remains a significant challenge. To address this, we propose RV-Bench, a framework for Benchmarking LLMs via Random Variables in mathematical reasoning. Specifically, the background content of a random variable question (RV question) mirrors the original problem in existing standard benchmarks, but the variable combinations are randomized into different values. LLMs must fully understand the problem-solving process for the original problem to correctly answer RV questions with various combinations of variable values. As a result, the LLM's genuine capability in mathematical reasoning is reflected by its accuracy on RV-Bench. Extensive experiments are conducted with 29 representative LLMs across 900+ RV questions. A leaderboard for RV-Bench ranks the genuine capability of these LLMs. Further analysis of accuracy dropping indicates that current LLMs still struggle with complex mathematical reasoning problems.", 'abstract_zh': '随着大型语言模型（LLMs）在数学推理能力上的不断进步，对其在该领域性能的评估已成为一个重要的研究焦点。近期的研究对当前数学基准的可靠性提出了质疑，指出这些基准可能存在设计过于简单和潜在的数据泄露问题。因此，创建一个可靠的基准来有效地评估LLMs在数学推理中的实际能力仍然是一个重大挑战。为了应对这一挑战，我们提出了RV-Bench，一种通过随机变量在数学推理中评估LLMs的框架。具体而言，随机变量问题（RV问题）的背景内容与现有标准基准中的原始问题保持一致，但变量组合被随机化为不同的值。LLMs必须完全理解原始问题的解决过程，才能正确回答各种变量值组合的RV问题。因此，LLMs在RV-Bench上的准确性反映了它们在数学推理中的真实能力。我们在29个代表性LLMs上进行了广泛的实验，涵盖900多个RV问题。RV-Bench的排行榜展示了这些LLMs的真实能力。进一步的准确率下降分析表明，当前的LLMs仍然难以应对复杂的数学推理问题。', 'title_zh': '通过随机变量基准测试大型语言模型'}
{'arxiv_id': 'arXiv:2501.11786', 'title': 'Synthetic Data Can Mislead Evaluations: Membership Inference as Machine Text Detection', 'authors': 'Ali Naseh, Niloofar Mireshghallah', 'link': 'https://arxiv.org/abs/2501.11786', 'abstract': 'Recent work shows membership inference attacks (MIAs) on large language models (LLMs) produce inconclusive results, partly due to difficulties in creating non-member datasets without temporal shifts. While researchers have turned to synthetic data as an alternative, we show this approach can be fundamentally misleading. Our experiments indicate that MIAs function as machine-generated text detectors, incorrectly identifying synthetic data as training samples regardless of the data source. This behavior persists across different model architectures and sizes, from open-source models to commercial ones such as GPT-3.5. Even synthetic text generated by different, potentially larger models is classified as training data by the target model. Our findings highlight a serious concern: using synthetic data in membership evaluations may lead to false conclusions about model memorization and data leakage. We caution that this issue could affect other evaluations using model signals such as loss where synthetic or machine-generated translated data substitutes for real-world samples.', 'abstract_zh': '近期的研究表明，针对大规模语言模型（LLMs）的成员推理攻击（MIAs）产生了不可靠的结果，部分原因是难以创建没有时间偏移的非成员数据集。虽然研究人员转向使用合成数据作为替代方案，但我们表明这种方法可能从根本上产生误导。我们的实验表明，MIAs 作为机器生成文本检测器，错误地将合成数据识别为训练样本，而不考虑数据来源。这种行为在不同模型架构和规模中普遍存在，从开源模型到商业模型如 GPT-3.5。即使是不同乃至潜在更大的模型生成的合成文本也会被目标模型分类为训练数据。我们的发现突显了一个严重的问题：在成员资格评估中使用合成数据可能导致对模型记忆和数据泄露的错误结论。我们警告说，这一问题还可能影响其他使用模型信号（如损失值）进行的评估，其中合成或机器生成的翻译数据替代了真实样本。', 'title_zh': '合成数据可能误导评估：基于机器文本检测的成员推理攻击'}
{'arxiv_id': 'arXiv:2501.11770', 'title': 'The Value of Nothing: Multimodal Extraction of Human Values Expressed by TikTok Influencers', 'authors': 'Alina Starovolsky-Shitrit, Alon Neduva, Naama Appel Doron, Ella Daniel, Oren Tsur', 'link': 'https://arxiv.org/abs/2501.11770', 'abstract': 'Societal and personal values are transmitted to younger generations through interaction and exposure. Traditionally, children and adolescents learned values from parents, educators, or peers. Nowadays, social platforms serve as a significant channel through which youth (and adults) consume information, as the main medium of entertainment, and possibly the medium through which they learn different values. In this paper we extract implicit values from TikTok movies uploaded by online influencers targeting children and adolescents. We curated a dataset of hundreds of TikTok movies and annotated them according to the Schwartz Theory of Personal Values. We then experimented with an array of Masked and Large language model, exploring how values can be detected. Specifically, we considered two pipelines -- direct extraction of values from video and a 2-step approach in which videos are first converted to elaborated scripts and then values are extracted.\nAchieving state-of-the-art results, we find that the 2-step approach performs significantly better than the direct approach and that using a trainable Masked Language Model as a second step significantly outperforms a few-shot application of a number of Large Language Models. We further discuss the impact of fine-tuning and compare the performance of the different models on identification of values present or contradicted in the TikTok. Finally, we share the first values-annotated dataset of TikTok videos. Our results pave the way to further research on influence and value transmission in video-based social platforms.', 'abstract_zh': '社会和个人价值观通过互动和接触传给年轻一代。传统上，儿童和青少年从父母、教育者或其他同龄人那里学习价值观。如今，社交媒体平台已成为年轻人（及成年人）获取信息的重要渠道，是主要的娱乐媒介，也是他们可能获取不同价值观的媒介。在本文中，我们从针对儿童和青少年的网络影响者上传的TikTok视频中提取隐含的价值观。我们收集了一大批TikTok视频，并根据斯瓦西尔个人价值观理论对它们进行了标注。我们随后使用了一系列遮蔽和大规模语言模型进行实验，探索如何检测价值观。具体而言，我们考虑了两种方法——直接从视频中提取价值观和两步法，在这种方法中，首先将视频转换为详细的剧本，然后提取价值观。\n\n我们取得了当前最佳成果，发现两步法明显优于直接方法，使用可训练的遮蔽语言模型作为第二步显著优于大量大规模语言模型的少量示例应用。我们进一步讨论了模型微调的影响，并比较了不同模型在识别TikTok中呈现或反驳的价值观方面的性能。最后，我们分享了首个TikTok视频的价值观标注数据集。我们的结果为视频为基础的社交平台上影响和价值观传递的研究开辟了新的方向。', 'title_zh': '《一无所有？：TikTok影响者表达的人类价值观的多模态提取》'}
{'arxiv_id': 'arXiv:2501.11765', 'title': 'Is logical analysis performed by transformers taking place in self-attention or in the fully connected part?', 'authors': 'Evgeniy Shin, Heinrich Matzinger', 'link': 'https://arxiv.org/abs/2501.11765', 'abstract': 'Transformers architecture apply self-attention to tokens represented as vectors, before a fully connected (neuronal network) layer. These two parts can be layered many times. Traditionally, self-attention is seen as a mechanism for aggregating information before logical operations are performed by the fully connected layer. In this paper, we show, that quite counter-intuitively, the logical analysis can also be performed within the self-attention. For this we implement a handcrafted single-level encoder layer which performs the logical analysis within self-attention. We then study the scenario in which a one-level transformer model undergoes self-learning using gradient descent. We investigate whether the model utilizes fully connected layers or self-attention mechanisms for logical analysis when it has the choice. Given that gradient descent can become stuck at undesired zeros, we explicitly calculate these unwanted zeros and find ways to avoid them. We do all this in the context of predicting grammatical category pairs of adjacent tokens in a text. We believe that our findings have broader implications for understanding the potential logical operations performed by self-attention.', 'abstract_zh': '本文将句子中提到的内容翻译成中文，并确保符合学术规范：\n\n转换器架构利用自注意力机制对表示为向量的标记进行操作，之后再经过完全连接层（神经网络层）。这两部分可以多次堆叠。传统上，自注意力被视为在完全连接层执行逻辑操作之前聚合信息的一种机制。在本文中，我们展示了自注意力中也可以执行逻辑分析，这与直觉相反。为此，我们实现了一个手工制造的一层编码器层，该层在自注意力中执行逻辑分析。然后，我们研究了一级转换器模型在使用梯度下降进行自我学习的场景。我们探讨了该模型在具有选择权时是使用完全连接层还是自注意力机制来执行逻辑分析。鉴于梯度下降可能会陷入不必要的零点，我们明确计算了这些不希望出现的零点，并找到了避免它们的方法。我们都是在预测文本中相邻标记的语法类别配对的背景下进行的。我们认为，我们的发现对理解自注意力可能执行的逻辑操作具有更广泛的意义。', 'title_zh': 'transformer进行逻辑分析的过程是发生在自注意力机制中还是发生在全连接部分中？'}
{'arxiv_id': 'arXiv:2501.11747', 'title': 'Optimizing Pretraining Data Mixtures with LLM-Estimated Utility', 'authors': 'William Held, Bhargavi Paranjape, Punit Singh Koura, Mike Lewis, Frank Zhang, Todor Mihaylov', 'link': 'https://arxiv.org/abs/2501.11747', 'abstract': 'Large Language Models improve with increasing amounts of high-quality training data. However, leveraging larger datasets requires balancing quality, quantity, and diversity across sources. After evaluating nine baseline methods under both compute- and data-constrained scenarios, we find token-count heuristics outperform manual and learned mixes, indicating that simple approaches accounting for dataset size and diversity are surprisingly effective. Building on this insight, we propose two complementary approaches: UtiliMax, which extends token-based heuristics by incorporating utility estimates from reduced-scale ablations, achieving up to a 10.6x speedup over manual baselines; and Model Estimated Data Utility (MEDU), which leverages LLMs to estimate data utility from small samples, matching ablation-based performance while reducing computational requirements by $\\sim$200x. Together, these approaches establish a new framework for automated, compute-efficient data mixing that is robust across training regimes.', 'abstract_zh': '大语言模型随高质量训练数据量的增加而改善。然而，利用较大的数据集需要在质量、数量和多样性之间进行权衡。在计算和数据受限的场景下评估了九种基线方法后，我们发现基于token计数的启发式方法优于手动和学习结合的方法，表明简单的考虑到数据集大小和多样性的方法令人惊讶地有效。基于这一发现，我们提出了两种互补的方法：首先是UtiliMax，它通过结合小型消融实验的实用性估算来扩展基于token的启发式方法，相对于手动基线实现了多达10.6倍的加速；其次是基于LLM的数据实用性估算（MEDU），它利用大语言模型从少量样本中估算数据实用性，匹配基于消融的性能，同时将计算需求降低约200倍。结合这些方法，我们建立了一个新的自动且计算高效的混合数据框架，该框架在各种训练模式下都非常稳健。', 'title_zh': '优化预训练数据混合方案，利用大规模语言模型估计效用'}
{'arxiv_id': 'arXiv:2501.11733', 'title': 'Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks', 'authors': 'Zhenhailong Wang, Haiyang Xu, Junyang Wang, Xi Zhang, Ming Yan, Ji Zhang, Fei Huang, Heng Ji', 'link': 'https://arxiv.org/abs/2501.11733', 'abstract': 'Smartphones have become indispensable in modern life, yet navigating complex tasks on mobile devices often remains frustrating. Recent advancements in large multimodal model (LMM)-based mobile agents have demonstrated the ability to perceive and act in mobile environments. However, current approaches face significant limitations: they fall short in addressing real-world human needs, struggle with reasoning-intensive and long-horizon tasks, and lack mechanisms to learn and improve from prior experiences. To overcome these challenges, we introduce Mobile-Agent-E, a hierarchical multi-agent framework capable of self-evolution through past experience. By hierarchical, we mean an explicit separation of high-level planning and low-level action execution. The framework comprises a Manager, responsible for devising overall plans by breaking down complex tasks into subgoals, and four subordinate agents--Perceptor, Operator, Action Reflector, and Notetaker--which handle fine-grained visual perception, immediate action execution, error verification, and information aggregation, respectively. Mobile-Agent-E also features a novel self-evolution module which maintains a persistent long-term memory comprising Tips and Shortcuts. Tips are general guidance and lessons learned from prior tasks on how to effectively interact with the environment. Shortcuts are reusable, executable sequences of atomic operations tailored for specific subroutines. The inclusion of Tips and Shortcuts facilitates continuous refinement in performance and efficiency. Alongside this framework, we introduce Mobile-Eval-E, a new benchmark featuring complex mobile tasks requiring long-horizon, multi-app interactions. Empirical results show that Mobile-Agent-E achieves a 22% absolute improvement over previous state-of-the-art approaches across three foundation model backbones. Project page: this https URL.', 'abstract_zh': '智能手机已成为现代生活不可或缺的工具，但在移动设备上导航复杂任务往往仍然令人沮丧。基于大规模多模态模型（LMM）的移动代理最近在感知和执行移动环境方面展现了能力。然而，当前的方法在处理现实世界的人类需求、应对推理密集型和长期任务方面存在显著局限性，缺乏从先前经验中学习和改进的机制。为了克服这些挑战，我们提出了Mobile-Agent-E，一种能够通过以往经验进行自我进化的分层多代理框架。所谓分层，指的是明确区分高层级规划和低层级动作执行。该框架包括一个经理，负责将复杂任务分解为子目标以制定总体计划；以及四个下属代理——感知器、操作员、动作反思器和记录员，分别负责精细的视觉感知、立即的动作执行、错误验证和信息聚合。Mobile-Agent-E 还配备了一个新颖的自我进化模块，该模块维护了一个持久的长期记忆，包括提示和捷径。提示是关于如何有效与环境互动的一般指导和从先前任务中吸取的教训。捷径是为特定子例行程序量身定制的可重复使用、可执行的原子操作序列。提示和捷径的包含促进了持续的性能和效率改进。除此之外，我们还引入了Mobile-Eval-E，这是一个新的基准测试，包括需要长期交互和多应用互动的复杂移动任务。实验结果表明，Mobile-Agent-E 在三个基础模型框架上实现了比之前最先进的方法绝对改进22%。项目页面：请点击此处。', 'title_zh': '移动代理-E：用于复杂任务的自我进化移动助理'}
{'arxiv_id': 'arXiv:2501.11721', 'title': 'Explain-Query-Test: Self-Evaluating LLMs Via Explanation and Comprehension Discrepancy', 'authors': 'Saeid Asgari Taghanaki, Joao Monteiro', 'link': 'https://arxiv.org/abs/2501.11721', 'abstract': "Large language models (LLMs) have demonstrated remarkable proficiency in generating detailed and coherent explanations of complex concepts. However, the extent to which these models truly comprehend the concepts they articulate remains unclear. To assess the level of comprehension of a model relative to the content it generates, we implemented a self-evaluation pipeline where models: (i) given a topic generate an excerpt with information about the topic, (ii) given an excerpt generate question-answer pairs, and finally (iii) given a question generate an answer. We refer to this self-evaluation approach as Explain-Query-Test (EQT). Interestingly, the accuracy on generated questions resulting from running the EQT pipeline correlates strongly with the model performance as verified by typical benchmarks such as MMLU-Pro. In other words, EQT's performance is predictive of MMLU-Pro's, and EQT can be used to rank models without the need for any external source of evaluation data other than lists of topics of interest. Moreover, our results reveal a disparity between the models' ability to produce detailed explanations and their performance on questions related to those explanations. This gap highlights fundamental limitations in the internal knowledge representation and reasoning abilities of current LLMs. We release the code at this https URL.", 'abstract_zh': '大规模语言模型（LLMs）在生成复杂概念的详细和连贯解释方面展现了惊人的能力。然而，这些模型在 articulating 这些概念时真正理解的程度仍然不清楚。为了评估模型对生成内容的理解水平，我们实现了一个自我评估管道，其中模型执行以下操作：（i）给定一个主题，生成一个包含关于该主题信息的段落，（ii）给定一个段落生成问题-答案对，最终（iii）给定一个问题生成一个答案。我们将这种自我评估方法称为解释-查询-测试（EQT）。有趣的是，通过运行EQT管道生成的问题准确性与通过典型基准如MMLU-Pro验证的模型性能高度相关。换句话说，EQT的性能可以预测MMLU-Pro的性能，并且EQT可以在无需任何外部评估数据源的情况下用于对模型进行排名，仅需感兴趣的主题列表即可。此外，我们的结果显示，模型在生成详细解释方面的能力和回答与这些解释相关的问题方面的性能之间存在差异。这一差距突显了当前LLMs在内部知识表示和推理能力方面的基本局限性。我们在此发布代码：https://example.com。', 'title_zh': '解释-查询-测试：通过解释和理解差异进行自我评估的语言模型'}
{'arxiv_id': 'arXiv:2501.11712', 'title': "YouLeQD: Decoding the Cognitive Complexity of Questions and Engagement in Online Educational Videos from Learners' Perspectives", 'authors': 'Nong Ming, Sachin Sharma, Jiho Noh', 'link': 'https://arxiv.org/abs/2501.11712', 'abstract': "Questioning is a fundamental aspect of education, as it helps assess students' understanding, promotes critical thinking, and encourages active engagement. With the rise of artificial intelligence in education, there is a growing interest in developing intelligent systems that can automatically generate and answer questions and facilitate interactions in both virtual and in-person education settings. However, to develop effective AI models for education, it is essential to have a fundamental understanding of questioning. In this study, we created the YouTube Learners' Questions on Bloom's Taxonomy Dataset (YouLeQD), which contains learner-posed questions from YouTube lecture video comments. Along with the dataset, we developed two RoBERTa-based classification models leveraging Large Language Models to detect questions and analyze their cognitive complexity using Bloom's Taxonomy. This dataset and our findings provide valuable insights into the cognitive complexity of learner-posed questions in educational videos and their relationship with interaction metrics. This can aid in the development of more effective AI models for education and improve the overall learning experience for students.", 'abstract_zh': '质疑是教育中的一个基本要素，它有助于评估学生对知识的理解，促进批判性思维，并鼓励积极参与。随着人工智能在教育中的应用日益增多，人们越来越关注开发能够自动生成和回答问题、促进虚拟和面对面教育环境中互动的智能系统。然而，为了开发有效的教育AI模型，深入理解质疑是非常重要的。本研究中，我们构建了YouTube学习者提问的数据集（YouLeQD），该数据集包含了YouTube讲座视频评论中的学习者提出的问题。我们还利用大型语言模型开发了两个基于RoBERTa的分类模型，用于检测问题并根据布卢姆分类法分析其认知复杂度。该数据集及其研究成果提供了关于教育视频中学习者提出的问题的认知复杂性及其与互动指标关系的重要见解。这些发现有助于开发更有效的教育AI模型，并能改善学生的整体学习体验。', 'title_zh': 'YouLeQD：从学习者视角解码在线教育视频中的问题认知复杂度与参与度'}
{'arxiv_id': 'arXiv:2501.11639', 'title': 'StAyaL | Multilingual Style Transfer', 'authors': 'Karishma Thakrar, Katrina Lawrence, Kyle Howard', 'link': 'https://arxiv.org/abs/2501.11639', 'abstract': "Stylistic text generation plays a vital role in enhancing communication by reflecting the nuances of individual expression. This paper presents a novel approach for generating text in a specific speaker's style across different languages. We show that by leveraging only 100 lines of text, an individuals unique style can be captured as a high-dimensional embedding, which can be used for both text generation and stylistic translation. This methodology breaks down the language barrier by transferring the style of a speaker between languages. The paper is structured into three main phases: augmenting the speaker's data with stylistically consistent external sources, separating style from content using machine learning and deep learning techniques, and generating an abstract style profile by mean pooling the learned embeddings. The proposed approach is shown to be topic-agnostic, with test accuracy and F1 scores of 74.9\\% and 0.75, respectively. The results demonstrate the potential of the style profile for multilingual communication, paving the way for further applications in personalized content generation and cross-linguistic stylistic transfer.", 'abstract_zh': '风格化文本生成在增强沟通方面发挥着重要作用，因为它能够反映个体表达的细微差别。本文提出了一种新颖的方法，用于在不同语言中生成特定讲话人的风格化文本。我们展示了只需利用100行文本，就能捕捉到个人的独特风格，并将其表示为高维嵌入，这种方法可以应用于文本生成和风格翻译。此方法通过在不同语言之间转移讲话人的风格，打破了语言障碍。论文分为三个主要阶段：增强讲话人的数据，加入风格一致的外部来源；使用机器学习和深度学习技术分离风格与内容；并通过平均池化学习到的嵌入生成抽象的风格概要。提出的这种方法在主题上是通用的，测试准确率和F1分数分别为74.9%和0.75。实验结果表明，风格概要在多语言沟通方面具有潜在的应用价值，为个性化内容生成和跨语言风格转移提供了进一步的应用方向。', 'title_zh': 'StAyaL | 多语言风格转换'}
{'arxiv_id': 'arXiv:2501.11632', 'title': 'Biomedical Knowledge Graph: A Survey of Domains, Tasks, and Real-World Applications', 'authors': 'Yuxing Lu, Sin Yee Goi, Xukai Zhao, Jinzhuo Wang', 'link': 'https://arxiv.org/abs/2501.11632', 'abstract': 'Biomedical knowledge graphs (BKGs) have emerged as powerful tools for organizing and leveraging the vast and complex data found across the biomedical field. Yet, current reviews of BKGs often limit their scope to specific domains or methods, overlooking the broader landscape and the rapid technological progress reshaping it. In this survey, we address this gap by offering a systematic review of BKGs from three core perspectives: domains, tasks, and applications. We begin by examining how BKGs are constructed from diverse data sources, including molecular interactions, pharmacological datasets, and clinical records. Next, we discuss the essential tasks enabled by BKGs, focusing on knowledge management, retrieval, reasoning, and interpretation. Finally, we highlight real-world applications in precision medicine, drug discovery, and scientific research, illustrating the translational impact of BKGs across multiple sectors. By synthesizing these perspectives into a unified framework, this survey not only clarifies the current state of BKG research but also establishes a foundation for future exploration, enabling both innovative methodological advances and practical implementations.', 'abstract_zh': '生物医学知识图谱（BKGs）已经成为了组织和利用生物医学领域庞大而复杂的数据的强大工具。然而，当前关于BKGs的综述往往局限于特定的领域或方法，忽略了这一领域的整体景观以及快速的技术进步对其的重塑。在本文综述中，我们通过从三个核心视角——领域、任务和应用——来填补这一空白，提供了一种系统的BKGs综述。我们首先探讨BKGs是如何从多种数据源构建起来的，包括分子相互作用、药理学数据集和临床记录。接着，我们讨论BKGs所支持的关键任务，重点关注知识管理、检索、推理和解释。最后，我们强调BKGs在精准医疗、药物发现和科学研究中的实际应用，展示了BKGs对多个领域的转化影响。通过将这些视角整合到一个统一的框架中，本文综述不仅阐明了当前BKGs研究的状态，还为未来的探索奠定了基础，促进了创新方法学的发展和实际应用的实现。', 'title_zh': 'biomedical知识图谱：领域、任务及实际应用综述'}
{'arxiv_id': 'arXiv:2501.11621', 'title': 'Trojan Detection Through Pattern Recognition for Large Language Models', 'authors': 'Vedant Bhasin, Matthew Yudin, Razvan Stefanescu, Rauf Izmailov', 'link': 'https://arxiv.org/abs/2501.11621', 'abstract': "Trojan backdoors can be injected into large language models at various stages, including pretraining, fine-tuning, and in-context learning, posing a significant threat to the model's alignment. Due to the nature of causal language modeling, detecting these triggers is challenging given the vast search space. In this study, we propose a multistage framework for detecting Trojan triggers in large language models consisting of token filtration, trigger identification, and trigger verification. We discuss existing trigger identification methods and propose two variants of a black-box trigger inversion method that rely on output logits, utilizing beam search and greedy decoding respectively. We show that the verification stage is critical in the process and propose semantic-preserving prompts and special perturbations to differentiate between actual Trojan triggers and other adversarial strings that display similar characteristics. The evaluation of our approach on the TrojAI and RLHF poisoned model datasets demonstrates promising results.", 'abstract_zh': '在模型预训练、微调和上下文学习等不同阶段，恶意后门可以注入到大型语言模型中，这给模型的对齐带来了重大威胁。由于因果语言建模的性质，在如此庞大的搜索空间中检测这些触发器是具有挑战性的。在本研究中，我们提出了一种多阶段框架，用于检测大型语言模型中的恶意后门触发器，该框架包括标记过滤、触发器识别和触发器验证。我们讨论了现有的触发器识别方法，并提出了两种基于输出logits的黑盒触发器反向方法的变体，分别使用了束搜索和贪婪解码。我们表明，验证阶段在过程中至关重要，并提出了保留语义的提示和特殊扰动，以区分实际的恶意后门触发器和其他表现出类似特征的对抗性字符串。我们在TrojAI和RLHF中毒模型数据集上的评估结果显示出有希望的成果。', 'title_zh': '通过模式识别进行大型语言模型中的木马检测'}
{'arxiv_id': 'arXiv:2501.11613', 'title': 'Conversation Routines: A Prompt Engineering Framework for Task-Oriented Dialog Systems', 'authors': 'Giorgio Robino', 'link': 'https://arxiv.org/abs/2501.11613', 'abstract': "This study introduces Conversation Routines (CR), a structured prompt engineering framework for developing task-oriented dialog systems using Large Language Models (LLMs). While LLMs demonstrate remarkable natural language understanding capabilities, engineering them to reliably execute complex business workflows remains challenging. The proposed CR framework enables the development of Conversation Agentic Systems (CAS) through natural language specifications, embedding task-oriented logic within LLM prompts. This approach provides a systematic methodology for designing and implementing complex conversational workflows while maintaining behavioral consistency. We demonstrate the framework's effectiveness through two proof of concept implementations: a Train Ticket Booking System and an Interactive Troubleshooting Copilot. These case studies validate CR's capability to encode sophisticated behavioral patterns and decision logic while preserving natural conversational flexibility. Results show that CR enables domain experts to design conversational workflows in natural language while leveraging custom enterprise functionalities (tools) developed by software engineers, creating an efficient division of responsibilities where developers focus on core API implementation and domain experts handle conversation design. While the framework shows promise in accessibility and adaptability, we identify key challenges including computational overhead, non-deterministic behavior, and domain-specific logic optimization. Future research directions include enhancing system robustness, improving scalability for complex multi-agent interactions, and addressing the identified limitations across diverse business applications.", 'abstract_zh': '本研究介绍了对话轮询（Conversation Routines，简称CR）框架，这是一个结构化提示工程框架，用于通过大型语言模型（LLMs）开发面向任务的对话系统。尽管LLMs在自然语言理解方面表现出色，但将它们工程化以可靠地执行复杂的业务工作流仍具挑战性。所提出的CR框架通过自然语言规范使开发者能够嵌入任务导向逻辑，从而在LLMs提示中构建对话代理系统（CAS）。这种方法提供了一种系统的设计和实现复杂对话工作流的方法，同时保持行为一致性。我们通过两个概念验证实施（分别是火车票预订系统和交互式故障排查副驾驶）展示了该框架的有效性。这些案例研究验证了CR能够编码复杂的行为模式和决策逻辑，同时保持自然对话的灵活性。结果表明，CR使得领域专家能够使用自然语言设计对话工作流，同时利用软件工程师开发的定制企业功能（工具），从而在开发者专注于核心API实现而领域专家处理对话设计方面实现高效的职责分工。虽然框架在可访问性和适应性方面显示出潜力，但我们也识别出几个关键挑战，包括计算开销、非确定性行为以及领域特定逻辑优化问题。未来的研究方向包括提高系统的鲁棒性、提高复杂多代理交互的可扩展性，并解决在各种业务应用中识别出的限制。', 'title_zh': '对话套路：面向任务导向对话系统的提示工程框架'}
{'arxiv_id': 'arXiv:2501.11551', 'title': 'PIKE-RAG: sPecIalized KnowledgE and Rationale Augmented Generation', 'authors': 'Jinyu Wang, Jingjing Fu, Lei Song, Jiang Bian', 'link': 'https://arxiv.org/abs/2501.11551', 'abstract': "Despite notable advancements in Retrieval-Augmented Generation (RAG) systems that expand large language model (LLM) capabilities through external retrieval, these systems often struggle to meet the complex and diverse needs of real-world industrial applications. The reliance on retrieval alone proves insufficient for extracting deep, domain-specific knowledge performing in logical reasoning from specialized corpora. To address this, we introduce sPecIalized KnowledgE and Rationale Augmentation Generation (PIKE-RAG), focusing on extracting, understanding, and applying specialized knowledge, while constructing coherent rationale to incrementally steer LLMs toward accurate responses. Recognizing the diverse challenges of industrial tasks, we introduce a new paradigm that classifies tasks based on their complexity in knowledge extraction and application, allowing for a systematic evaluation of RAG systems' problem-solving capabilities. This strategic approach offers a roadmap for the phased development and enhancement of RAG systems, tailored to meet the evolving demands of industrial applications. Furthermore, we propose knowledge atomizing and knowledge-aware task decomposition to effectively extract multifaceted knowledge from the data chunks and iteratively construct the rationale based on original query and the accumulated knowledge, respectively, showcasing exceptional performance across various benchmarks.", 'abstract_zh': '尽管在检索增强生成（RAG）系统方面取得了显著进展，通过外部检索扩展大语言模型（LLM）的能力，但这些系统在满足现实工业应用中复杂多变的需求时往往表现不佳。单纯依赖检索提取深入的专业领域知识以进行逻辑推理的能力仍然不足。为解决这一问题，我们提出了专门知识与推理增强生成（PIKE-RAG），专注于提取、理解和应用专门知识，并构建连贯的推理以逐步引导LLM生成准确的回答。鉴于工业任务的多样性，我们引入了一种新的范式，根据知识提取和应用的复杂性对任务进行分类，从而系统评估RAG系统的解决问题能力。这种策略为分阶段开发和改进RAG系统提供了蓝图，以满足工业应用不断变化的需求。此外，我们提出知识原子化和知识驱动的任务分解，以有效地从数据块中提取多层次的知识，并基于原始查询和累积的知识逐步构建推理，从而在多个基准测试中展示了出色的表现。', 'title_zh': 'PIKE-RAG：专门知识和推理增强的生成'}
{'arxiv_id': 'arXiv:2501.11549', 'title': 'Whose Boat Does it Float? Improving Personalization in Preference Tuning via Inferred User Personas', 'authors': 'Nishant Balepur, Vishakh Padmakumar, Fumeng Yang, Shi Feng, Rachel Rudinger, Jordan Lee Boyd-Graber', 'link': 'https://arxiv.org/abs/2501.11549', 'abstract': 'LLMs are tuned to follow instructions (aligned) by learning which of two outputs users prefer for a prompt. However, this preference data format does not convey why users prefer responses that are chosen or rejected, so LLMs trained on these datasets cannot tailor responses to varied user needs. To surface these parameters of personalization, we apply abductive reasoning to preference data, inferring needs and interests of users, i.e. personas, that may prefer each output. We test this idea in two steps: Persona Inference (PI)-abductively inferring personas of users who prefer chosen or rejected outputs-and Persona Tailoring (PT)-training models to tailor responses to personas from PI. We find: 1) LLMs infer personas accurately explaining why different users may prefer both chosen or rejected outputs; 2) Training on preference data augmented with PI personas via PT boosts personalization, enabling models to support user-written personas; and 3) Rejected response personas form harder personalization evaluations, showing PT better aids users with uncommon preferences versus typical alignment methods. We argue for an abductive view of preferences for personalization, asking not only which response is better but when, why, and for whom.', 'abstract_zh': '大型语言模型（LLMs）通过学习用户对两个输出的偏好，从而调整以遵循指令（即实现对齐）。然而，这种偏好数据格式没有传达用户为何偏好某个特定响应或拒绝某个响应的原因，因此基于这些数据集训练的LLMs无法根据多样化用户的需求调整响应。为了揭示这些个性化参数，我们应用 abduction 推理来分析偏好数据，推断出可能偏好每个输出的用户的需要和兴趣，即人物画像。我们通过两个步骤来测试这一想法：人物画像推理（PI）——通过 abduction 推理推断出偏好已选择或拒绝输出的用户的人物画像；以及人物画像定制（PT）——训练模型以根据 PI 得到的人物画像来定制响应。我们发现：1）LLMs 准确推理出不同用户为何偏好已选择或拒绝的输出；2）通过 PT 在偏好数据中结合 PI 人物画像进行训练，可以提升个性化效果，使模型能够支持用户自定义的人物画像；3）被拒绝的响应人物画像形成更难的个性化评估，表明 PT 对于支持具有不常见偏好用户方面比典型对齐方法更为有效。我们主张采用 abduction 观点来理解偏好用于个性化，不仅关注哪个响应更好，还关注何时、为何以及为谁更好。', 'title_zh': '谁的船会浮起？通过推断用户角色来提升偏好调整的个性化水平'}
{'arxiv_id': 'arXiv:2501.11496', 'title': 'Generative AI and Large Language Models in Language Preservation: Opportunities and Challenges', 'authors': 'Vincent Koc', 'link': 'https://arxiv.org/abs/2501.11496', 'abstract': 'Generative AI and large-scale language models (LLM) have emerged as powerful tools in language preservation, particularly for near-native and endangered languages. With the increasing reliance on technology for communication, education, and cultural documentation, new opportunities have emerged to mitigate the dramatic decline of linguistic diversity worldwide. This paper examines the role of generative AIs and LLMs in preserving endangered languages, highlighting the risks and challenges associated with their use. We analyze the underlying technologies driving these models, including natural language processing (NLP) and deep learning, and explore several cases where these technologies have been applied to low-resource languages. Additionally, we discuss ethical considerations, data scarcity issues, and technical challenges while proposing solutions to enhance AI-driven language preservation.', 'abstract_zh': '生成式人工智能和大规模语言模型（LLM）已成为语言保护的强大力量，特别是在濒危和接近母语的语言保护中。随着技术在沟通、教育和文化记录中的依赖增加，新兴的机会出现了，有助于缓解全球语言多样性急剧下降的趋势。本文探讨了生成式人工智能和大规模语言模型在保护濒危语言中的作用，同时指出了其使用过程中存在的风险和挑战。我们分析了这些模型背后的技术，包括自然语言处理（NLP）和深度学习，并探讨了这些技术在资源匮乏型语言中的应用案例。此外，我们讨论了伦理考量、数据稀缺问题和技术挑战，并提出了增强基于人工智能的语言保护的解决方案。', 'title_zh': '生成式人工智能与大型语言模型在语言保存中的机遇与挑战'}
{'arxiv_id': 'arXiv:2501.11478', 'title': 'Graph-defined Language Learning with LLMs', 'authors': 'Huachi Zhou, Jiahe Du, Chuang Zhou, Chang Yang, Yilin Xiao, Yuxuan Xie, Xiao Huang', 'link': 'https://arxiv.org/abs/2501.11478', 'abstract': 'Recent efforts leverage Large Language Models (LLMs) for modeling text-attributed graph structures in node classification tasks. These approaches describe graph structures for LLMs to understand or aggregate LLM-generated textual attribute embeddings through graph structure. However, these approaches face two main limitations in modeling graph structures with LLMs. (i) Graph descriptions become verbose in describing high-order graph structure. (ii) Textual attributes alone do not contain adequate graph structure information. It is challenging to model graph structure concisely and adequately with LLMs. LLMs lack built-in mechanisms to model graph structures directly. They also struggle with complex long-range dependencies between high-order nodes and target nodes.\nInspired by the observation that LLMs pre-trained on one language can achieve exceptional performance on another with minimal additional training, we propose \\textbf{G}raph-\\textbf{D}efined \\textbf{L}anguage for \\textbf{L}arge \\textbf{L}anguage \\textbf{M}odel (GDL4LLM). This novel framework enables LLMs to transfer their powerful language understanding capabilities to graph-structured data. GDL4LLM translates graphs into a graph language corpus instead of graph descriptions and pre-trains LLMs on this corpus to adequately understand graph structures. During fine-tuning, this corpus describes the structural information of target nodes concisely with only a few tokens. By treating graphs as a new language, GDL4LLM enables LLMs to model graph structures adequately and concisely for node classification tasks. Extensive experiments on three real-world datasets demonstrate that GDL4LLM outperforms description-based and textual attribute embeddings-based baselines by efficiently modeling different orders of graph structure with LLMs.', 'abstract_zh': '近年来，研究人员利用大规模语言模型（LLMs）来建模节点分类任务中的文本属性图结构。这些方法通过图结构使LLMs理解或聚合由图结构生成的文本属性嵌入。然而，这些方法在使用LLMs建模图结构时面临两个主要限制。(i) 图描述在描述高阶图结构时变得冗长。(ii) 仅凭文本属性无法提供足够的图结构信息。使用LLMs建模图结构既具挑战性又不充分。LLMs缺乏直接建模图结构的内置机制，同时在处理高阶节点与目标节点之间的复杂长距离依赖关系时也表现出不足。\n\n受到预训练在一种语言上训练的LLMs可以在另一种语言上实现出色性能且仅需少量额外训练的观察启发，我们提出了一种新型框架——Graph-Defined Language for Large Language Model（GDL4LLM）。这种框架使LLMs能够将其强大的语言理解能力转移到图结构数据上。GDL4LLM将图翻译成图语言语料库，而非图描述，并在该语料库上预训练LLMs，以便充分理解图结构。在微调过程中，该语料库仅用少量标记简洁地描述了目标节点的结构信息。通过将图视为一种新语言，GDL4LLM使LLMs能够针对节点分类任务以充分且简洁的方式建模图结构。在三个实际数据集上的广泛实验表明，GDL4LLM比基于描述和基于文本属性嵌入的方法都能更有效地利用LLMs建模不同层次的图结构，表现出更优的性能。', 'title_zh': '基于图定义的语言学习与大规模语言模型'}
{'arxiv_id': 'arXiv:2501.11463', 'title': 'Curiosity-Driven Reinforcement Learning from Human Feedback', 'authors': 'Haoran Sun, Yekun Chai, Shuohuan Wang, Yu Sun, Hua Wu, Haifeng Wang', 'link': 'https://arxiv.org/abs/2501.11463', 'abstract': 'Reinforcement learning from human feedback (RLHF) has proven effective in aligning large language models (LLMs) with human preferences, but often at the cost of reduced output diversity. This trade-off between diversity and alignment quality remains a significant challenge. Drawing inspiration from curiosity-driven exploration in reinforcement learning, we introduce curiosity-driven RLHF (CD-RLHF), a framework that incorporates intrinsic rewards for novel states, alongside traditional sparse extrinsic rewards, to optimize both output diversity and alignment quality. We demonstrate the effectiveness of CD-RLHF through extensive experiments on a range of tasks, including text summarization and instruction following. Our approach achieves significant gains in diversity on multiple diversity-oriented metrics while maintaining alignment with human preferences comparable to standard RLHF. We make our code publicly available at this https URL.', 'abstract_zh': '人类反馈强化学习（RLHF）已经证明在使大型语言模型（LLMs）与人类偏好对齐方面是有效的，但往往会牺牲输出的多样性。这种多样性和对齐质量之间的权衡仍然是一个显著的挑战。受强化学习中好奇心驱动探索的启发，我们提出了好奇心驱动的RLHF（CD-RLHF）框架，该框架结合了内在奖励以优化新颖状态，并与传统稀疏外部奖励相结合，从而同时优化输出的多样性和对齐质量。我们通过一系列任务的实验，证明了CD-RLHF的有效性，包括文本摘要和指令跟随。我们的方法在多个多样性导向的指标上实现了显著的多样性提升，同时保持了与人类偏好对齐的水平，这与标准的RLHF相当。我们已在以下网址公开了我们的代码：this https URL。', 'title_zh': '好奇心驱动的奖励学习从人类反馈中学习'}
{'arxiv_id': 'arXiv:2501.11440', 'title': 'RACCOON: A Retrieval-Augmented Generation Approach for Location Coordinate Capture from News Articles', 'authors': 'Jonathan Lin, Aditya Joshi, Hye-young Paik, Tri Dung Doung, Deepti Gurdasani', 'link': 'https://arxiv.org/abs/2501.11440', 'abstract': 'Geocoding involves automatic extraction of location coordinates of incidents reported in news articles, and can be used for epidemic intelligence or disaster management. This paper introduces Retrieval-Augmented Coordinate Capture Of Online News articles (RACCOON), an open-source geocoding approach that extracts geolocations from news articles. RACCOON uses a retrieval-augmented generation (RAG) approach where candidate locations and associated information are retrieved in the form of context from a location database, and a prompt containing the retrieved context, location mentions and news articles is fed to an LLM to generate the location coordinates. Our evaluation on three datasets, two underlying LLMs, three baselines and several ablation tests based on the components of RACCOON demonstrate the utility of RACCOON. To the best of our knowledge, RACCOON is the first RAG-based approach for geocoding using pre-trained LLMs.', 'abstract_zh': '地理编码涉及从新闻文章中自动提取事件发生地点的经度和纬度坐标，并可用于疾病监控或灾害管理。本文介绍了“在线新闻文章地理坐标的检索增强捕捉方法”（RACCOON），这是一种开源的地理编码方法，用于从新闻文章中提取地理位置信息。RACCOON采用了检索增强生成（RAG）方法，其中候选地点及其相关信息从地理位置数据库中检索出来，形成上下文，并将包含检索到的上下文、地点提及和新闻文章的提示输入到语言模型（LLM）中生成位置坐标。我们在三个数据集、两种基础语言模型、三种基线方法以及针对RACCOON组件的多个消融测试上对RACCOON进行了评估，显示了其实用性。据我们所知，RACCOON是第一个使用预训练语言模型的基于检索增强生成的地理编码方法。', 'title_zh': 'RACCOON：一种用于新闻文章中地理位置坐标抓取的检索增强生成方法'}
{'arxiv_id': 'arXiv:2501.11417', 'title': 'Neural Contextual Reinforcement Framework for Logical Structure Language Generation', 'authors': 'Marcus Irvin, William Cooper, Edward Hughes, Jessica Morgan, Christopher Hamilton', 'link': 'https://arxiv.org/abs/2501.11417', 'abstract': "The Neural Contextual Reinforcement Framework introduces an innovative approach to enhancing the logical coherence and structural consistency of text generated by large language models. Leveraging reinforcement learning principles, the framework integrates custom reward functions and dynamic context alignment mechanisms to address challenges inherent in maintaining long-range dependencies across extended sequences. The architecture incorporates multi-head attention layers and hierarchical encoding modules, enabling the model to produce outputs that align closely with human expectations of logical structure and semantic flow. Quantitative evaluations across diverse datasets demonstrate substantial improvements in coherence metrics, perplexity reduction, and semantic alignment, showcasing the framework's ability to outperform baseline models in both general and domain-specific tasks. Qualitative analyses further highlight the framework's capacity to generate text with improved narrative clarity and reduced redundancy, reflecting its effectiveness in balancing fluency with structural precision. In addition to its performance gains, the framework exhibits robustness in handling noisy input data and scalability across varying model sizes, reinforcing its versatility in practical applications. Experimental results reveal that optimal context window sizes significantly influence coherence outcomes, showing the importance of architectural flexibility in adapting to diverse linguistic structures. Cross-lingual performance evaluations affirm the framework's adaptability to multiple languages, extending its utility beyond monolingual contexts. Resource efficiency analyses indicate a reduction in computational overhead compared to traditional approaches, emphasizing the practicality of the framework for large-scale deployment.", 'abstract_zh': '神经上下文强化框架提出了一种创新的方法，以增强由大规模语言模型生成的文本的逻辑一致性和结构连贯性。该框架利用强化学习原理，结合定制的奖励函数和动态上下文对齐机制，应对在长时间序列中保持远程依赖关系的挑战。该架构整合了多头注意力层和层次编码模块，使模型能够生成与人类对逻辑结构和语义流动的期望高度一致的输出。在多个数据集上的定量评估表明，框架在连贯性度量、困惑度降低和语义对齐方面取得了显著改进，展示了其在通用任务和专业任务中优于基线模型的能力。进一步的定性分析表明，该框架能够生成具有更高叙事清晰度和更少冗余的文本，突显了其在流畅性与结构精确性之间取得平衡的有效性。除了性能提升外，该框架在处理噪声输入数据时表现出高度的稳健性，并且在不同规模的模型之间具有可扩展性，进一步增强了其实用性。实验结果表明，最佳上下文窗口大小对连贯结果有显著影响，展示了架构灵活性的重要性以适应不同的语言结构。跨语言性能评估验证了框架的适应性，使其能够应用于多种语言环境，从而扩展其在单一语言情境外的应用范围。资源效率分析表明，与传统方法相比，该框架在计算开销上有所减少，强调了其在大规模部署中的实用性。', 'title_zh': '基于神经上下文强化学习框架的逻辑结构语言生成'}
{'arxiv_id': 'arXiv:2501.11403', 'title': 'Verifying Cross-modal Entity Consistency in News using Vision-language Models', 'authors': 'Sahar Tahmasebi, Eric Müller-Budack, Ralph Ewerth', 'link': 'https://arxiv.org/abs/2501.11403', 'abstract': 'The web has become a crucial source of information, but it is also used to spread disinformation, often conveyed through multiple modalities like images and text. The identification of inconsistent cross-modal information, in particular entities such as persons, locations, and events, is critical to detect disinformation. Previous works either identify out-of-context disinformation by assessing the consistency of images to the whole document, neglecting relations of individual entities, or focus on generic entities that are not relevant to news. So far, only few approaches have addressed the task of validating entity consistency between images and text in news. However, the potential of large vision-language models (LVLMs) has not been explored yet. In this paper, we propose an LVLM-based framework for verifying Cross-modal Entity Consistency~(LVLM4CEC), to assess whether persons, locations and events in news articles are consistent across both modalities. We suggest effective prompting strategies for LVLMs for entity verification that leverage reference images crawled from web. Moreover, we extend three existing datasets for the task of entity verification in news providing manual ground-truth data. Our results show the potential of LVLMs for automating cross-modal entity verification, showing improved accuracy in identifying persons and events when using evidence images. Moreover, our method outperforms a baseline for location and event verification in documents. The datasets and source code are available on GitHub at \\url{this https URL}.', 'abstract_zh': '互联网已成为重要的信息来源，但也被用于传播假信息，这些信息通常通过多种模态（如图像和文本）进行传播。特别是识别一致性的跨模态信息（例如人物、地点和事件），对于检测假信息至关重要。先前的研究要么通过评估图像与整个文档的一致性来识别上下文不符的假信息，忽视了实体间的个体关系，要么专注于与新闻无关的通用实体。目前为止，仅有少数方法解决了新闻中的图像与文本实体一致性验证问题。然而，大规模多模态视觉语言模型（LVLM）的巨大潜力尚未被充分探索。在本文中，我们提出了一种基于LVLM的框架（LVLM4CEC），用于验证新闻文章中人物、地点和事件在两种模态下的一致性。我们为利用从网络抓取的参考图像构建了有效的LVLM提示策略，以进行实体验证。此外，我们为新闻场景下的实体验证任务扩展了三个现有数据集，并提供了手动标注的数据。我们的结果显示，LVLM在自动化跨模态实体验证方面具有潜力，使用证据图像时能够更准确地识别人物和事件。此外，我们的方法在文档中实体验证方面超过了基线方法。数据集和源代码已在GitHub上公开，地址为[this https URL](请将点击链接替换为实际的GitHub地址)。', 'title_zh': '使用视觉语言模型在新闻中验证跨模态实体一致性'}
{'arxiv_id': 'arXiv:2501.11335', 'title': 'Few-shot Policy (de)composition in Conversational Question Answering', 'authors': 'Kyle Erwin, Guy Axelrod, Maria Chang, Achille Fokoue, Maxwell Crouse, Soham Dan, Tian Gao, Rosario Uceda-Sosa, Ndivhuwo Makondo, Naweed Khan, Alexander Gray', 'link': 'https://arxiv.org/abs/2501.11335', 'abstract': 'The task of policy compliance detection (PCD) is to determine if a scenario is in compliance with respect to a set of written policies. In a conversational setting, the results of PCD can indicate if clarifying questions must be asked to determine compliance status. Existing approaches usually claim to have reasoning capabilities that are latent or require a large amount of annotated data. In this work, we propose logical decomposition for policy compliance (LDPC): a neuro-symbolic framework to detect policy compliance using large language models (LLMs) in a few-shot setting. By selecting only a few exemplars alongside recently developed prompting techniques, we demonstrate that our approach soundly reasons about policy compliance conversations by extracting sub-questions to be answered, assigning truth values from contextual information, and explicitly producing a set of logic statements from the given policies. The formulation of explicit logic graphs can in turn help answer PCDrelated questions with increased transparency and explainability. We apply this approach to the popular PCD and conversational machine reading benchmark, ShARC, and show competitive performance with no task-specific finetuning. We also leverage the inherently interpretable architecture of LDPC to understand where errors occur, revealing ambiguities in the ShARC dataset and highlighting the challenges involved with reasoning for conversational question answering.', 'abstract_zh': '政策合规检测（PCD）的任务是确定某个场景是否符合一组书面政策。在对话环境中，PCD的结果可以指示是否需要提出澄清问题以确定合规状态。现有方法通常声称具有潜在的推理能力，或者需要大量的标注数据。在本工作中，我们提出了一种逻辑分解政策合规性（LDPC）的方法：一种基于神经符号框架，利用大规模语言模型（LLMs）在少量示例设置下检测政策合规性的方法。通过仅选择少量示例并结合最近发展起来的提示技术，我们展示了我们的方法能够通过对场景进行有效的推理来检测政策合规性对话，从而提取需要回答的子问题，从上下文中分配真值，并显式生成一组逻辑语句。通过这种方式，对给定政策进行形式化处理后的逻辑图可以进一步帮助以更高的透明度和可解释性回答与PCD相关的问题。我们将该方法应用于流行的是对话机器阅读基准ShARC，并在无需特定任务微调的情况下显示出竞争力。此外，我们利用LDPC的固有可解释架构来理解错误发生的位置，揭示了ShARC数据集中存在的模糊性，并突显了对话问答推理过程中涉及的挑战。', 'title_zh': 'few-shot策略（分解）在对话式问答中的应用'}
{'arxiv_id': 'arXiv:2501.11301', 'title': 'Question-to-Question Retrieval for Hallucination-Free Knowledge Access: An Approach for Wikipedia and Wikidata Question Answering', 'authors': 'Santhosh Thottingal', 'link': 'https://arxiv.org/abs/2501.11301', 'abstract': 'This paper introduces an approach to question answering over knowledge bases like Wikipedia and Wikidata by performing "question-to-question" matching and retrieval from a dense vector embedding store. Instead of embedding document content, we generate a comprehensive set of questions for each logical content unit using an instruction-tuned LLM. These questions are vector-embedded and stored, mapping to the corresponding content. Vector embedding of user queries are then matched against this question vector store. The highest similarity score leads to direct retrieval of the associated article content, eliminating the need for answer generation. Our method achieves high cosine similarity ( > 0.9 ) for relevant question pairs, enabling highly precise retrieval. This approach offers several advantages including computational efficiency, rapid response times, and increased scalability. We demonstrate its effectiveness on Wikipedia and Wikidata, including multimedia content through structured fact retrieval from Wikidata, opening up new pathways for multimodal question answering.', 'abstract_zh': '本文介绍了一种在Wikipedia和Wikidata等知识库上进行问答的方法，通过执行“问题到问题”的匹配和检索，从密集的向量嵌入存储中获取信息。与嵌入文档内容不同，我们使用指令微调的语言模型为每个逻辑内容单元生成一个全面的问题集。这些问题被向量嵌入并存储，映射到相应的内容。用户查询的向量嵌入随后与这个问题向量库进行匹配。相似度最高的一对问题对应的答案将直接检索出来，从而消除生成答案的需要。本方法在相关问题对上实现了高余弦相似度（>0.9），从而实现高精度检索。该方法具有计算效率高、响应速度快以及增强可扩展性的优点。我们通过在Wikipedia和Wikidata上的实验展示了其有效性，包括通过结构化事实检索从Wikidata获取多媒体内容，从而开启了多模态问答的新途径。', 'title_zh': '无幻觉知识访问的问答对检索：面向维基百科和Wikidata的方案'}
{'arxiv_id': 'arXiv:2501.11292', 'title': 'Advancing Multi-Party Dialogue Systems with Speaker-ware Contrastive Learning', 'authors': 'Zhongtian Hu, Qi He, Ronghan Li, Meng Zhao, Lifang Wang', 'link': 'https://arxiv.org/abs/2501.11292', 'abstract': 'Dialogue response generation has made significant progress, but most research has focused on dyadic dialogue. In contrast, multi-party dialogues involve more participants, each potentially discussing different topics, making the task more complex. Current methods often rely on graph neural networks to model dialogue context, which helps capture the structural dynamics of multi-party conversations. However, these methods are heavily dependent on intricate graph structures and dataset annotations, and they often overlook the distinct speaking styles of participants. To address these challenges, we propose CMR, a Contrastive learning-based Multi-party dialogue Response generation model. CMR uses self-supervised contrastive learning to better distinguish "who says what." Additionally, by comparing speakers within the same conversation, the model captures differences in speaking styles and thematic transitions. To the best of our knowledge, this is the first approach to apply contrastive learning in multi-party dialogue generation. Experimental results show that CMR significantly outperforms state-of-the-art models in multi-party dialogue response tasks.', 'abstract_zh': '对话响应生成已经取得了显著进展，但大多数研究集中在二元对话上。相比之下，多轮对话涉及更多的参与者，每个参与者可能讨论不同的主题，使任务更为复杂。当前的方法常常依赖图神经网络来建模对话上下文，这有助于捕捉多轮对话中的结构动态。然而，这些方法往往高度依赖复杂的图结构和数据集标注，并且经常忽视参与者的不同 speaking 样式。为了解决这些挑战，我们提出了一种基于对比学习的多轮对话响应生成模型 CMR。CMR 利用自监督的对比学习更好地区分辨别“谁说的什么”。此外，通过在同一轮对话中比较发言者，模型捕获了不同的 speaking 样式和主题转换。据我们所知，这是首次将对比学习应用于多轮对话生成。实验结果表明，CMR 在多轮对话响应任务中显著优于现有最先进模型。', 'title_zh': '基于说话人感知对比学习的多党派对话系统提升'}
{'arxiv_id': 'arXiv:2501.11273', 'title': 'Multi-round, Chain-of-thought Post-editing for Unfaithful Summaries', 'authors': 'Yi-Hui Lee, Xiangci Li, Jessica Ouyang', 'link': 'https://arxiv.org/abs/2501.11273', 'abstract': "Recent large language models (LLMs) have demonstrated a remarkable ability to perform natural language understanding and generation tasks. In this work, we investigate the use of LLMs for evaluating faithfulness in news summarization, finding that it achieves a strong correlation with human judgments. We further investigate LLMs' capabilities as a faithfulness post-editor, experimenting with different chain-of-thought prompts for locating and correcting factual inconsistencies between a generated summary and the source news document and are able to achieve a higher editing success rate than was reported in prior work. We perform both automated and human evaluations of the post-edited summaries, finding that prompting LLMs using chain-of-thought reasoning about factual error types is an effective faithfulness post-editing strategy, performing comparably to fine-tuned post-editing models. We also demonstrate that multiple rounds of post-editing, which has not previously been explored, can be used to gradually improve the faithfulness of summaries whose errors cannot be fully corrected in a single round.", 'abstract_zh': '近年来，大型语言模型（LLMs）展示了在自然语言理解和生成任务中出色的能力。在此项工作中，我们探讨了LLMs在新闻摘要忠实度评估中的应用，发现其与人类判断之间存在密切的相关性。我们进一步研究了LLMs作为忠实度后编辑工具的能力，并通过使用不同的链式思考提示，定位和纠正生成摘要与原始新闻文档之间的事实不一致，成功地实现了比此前研究更高的后编辑成功率。我们对后编辑摘要进行了自动和人工评估，发现使用链式思考推理关于事实错误类型的提示是有效的忠实度后编辑策略，其表现与微调后的后编辑模型相当。我们还展示了多轮后编辑的应用，这是一种尚未被探索的方法，可以在单次后编辑无法完全纠正错误的情况下逐步提高摘要的忠实度。', 'title_zh': '多轮、链式思考后的编辑方法用于不忠实摘要的后处理'}
{'arxiv_id': 'arXiv:2501.11269', 'title': 'Can xLLMs Understand the Structure of Dialog? Exploring Multilingual Response Generation in Complex Scenarios', 'authors': 'Zhongtian Hu, Yiwen Cui, Ronghan Li, Meng Zhao, Lifang Wang', 'link': 'https://arxiv.org/abs/2501.11269', 'abstract': 'Multilingual research has garnered increasing attention, especially in the domain of dialogue systems. The rapid advancements in large language models (LLMs) have fueled the demand for high-performing multilingual models. However, two major challenges persist: the scarcity of high-quality multilingual datasets and the limited complexity of existing datasets in capturing realistic dialogue scenarios. To address these gaps, we introduce XMP, a high-quality parallel Multilingual dataset sourced from Multi-party Podcast dialogues. Each sample in the dataset features at least three participants discussing a wide range of topics, including society, culture, politics, and this http URL extensive experiments, we uncover significant limitations in previously recognized multilingual capabilities of LLMs when applied to such complex dialogue scenarios. For instance, the widely accepted multilingual complementary ability of LLMs is notably impacted. By conducting further experiments, we explore the mechanisms of LLMs in multilingual environments from multiple perspectives, shedding new light on their performance in real-world, diverse conversational contexts.', 'abstract_zh': '多语言研究越来越受到关注，尤其是在对话系统领域。大型语言模型（LLMs）的迅猛发展进一步推动了高性能多语言模型的需求。然而，两个主要挑战仍然存在：高质量多语言数据集的稀缺性以及现有数据集在捕捉现实对话场景时的复杂度有限。为应对这些差距，我们引入了XMP，这是一个源自多人群播对话的高质量平行多语言数据集。每个数据集样本至少包含三名参与者，讨论广泛的话题，包括社会、文化、政治等。通过一系列广泛的实验，我们揭示了之前被认可的多语言能力在面对复杂对话场景时存在显著局限性，例如，LLMs普遍认为的多语言互补能力受到了明显影响。通过进一步的实验，我们从多个角度探索了LLMs在多语言环境中的机制，为它们在真实、多样的对话场景中的表现提供了新的洞见。', 'title_zh': 'xLLMs能理解对话的结构吗？探究复杂场景下的多语言响应生成'}
{'arxiv_id': 'arXiv:2501.11241', 'title': 'Irony in Emojis: A Comparative Study of Human and LLM Interpretation', 'authors': 'Yawen Zheng, Hanjia Lyu, Jiebo Luo', 'link': 'https://arxiv.org/abs/2501.11241', 'abstract': "Emojis have become a universal language in online communication, often carrying nuanced and context-dependent meanings. Among these, irony poses a significant challenge for Large Language Models (LLMs) due to its inherent incongruity between appearance and intent. This study examines the ability of GPT-4o to interpret irony in emojis. By prompting GPT-4o to evaluate the likelihood of specific emojis being used to express irony on social media and comparing its interpretations with human perceptions, we aim to bridge the gap between machine and human understanding. Our findings reveal nuanced insights into GPT-4o's interpretive capabilities, highlighting areas of alignment with and divergence from human behavior. Additionally, this research underscores the importance of demographic factors, such as age and gender, in shaping emoji interpretation and evaluates how these factors influence GPT-4o's performance.", 'abstract_zh': '表情符号已经成为在线交流中的一种通用语言，常常承载着细微且依情境而异的意义。其中，由于其表面与意图之间固有的不一致性，讽刺为大型语言模型（LLMs）带来了重大挑战。本研究探讨了GPT-4o在解读表情符号中讽刺含义方面的能力。通过促使GPT-4o评估特定表情符号在社交媒体中是否用于表达讽刺的可能性，并将其解释与人类的感知进行比较，我们旨在弥合机器和人类理解之间的差距。我们的研究结果揭示了GPT-4o解释能力的复杂洞察，突显了其与人类行为的共性和差异。此外，本研究强调了年龄和性别等群体因素对表情符号解释的重要性，并评估了这些因素如何影响GPT-4o的表现。', 'title_zh': '表情符号中的irony：人类与大规模语言模型解释的比较研究'}
{'arxiv_id': 'arXiv:2501.11199', 'title': 'Embedding-Driven Diversity Sampling to Improve Few-Shot Synthetic Data Generation', 'authors': 'Ivan Lopez, Fateme Nateghi Haredasht, Kaitlin Caoili, Jonathan H Chen, Akshay Chaudhari', 'link': 'https://arxiv.org/abs/2501.11199', 'abstract': 'Accurate classification of clinical text often requires fine-tuning pre-trained language models, a process that is costly and time-consuming due to the need for high-quality data and expert annotators. Synthetic data generation offers an alternative, though pre-trained models may not capture the syntactic diversity of clinical notes. We propose an embedding-driven approach that uses diversity sampling from a small set of real clinical notes to guide large language models in few-shot prompting, generating synthetic text that better reflects clinical syntax. We evaluated this method using the CheXpert dataset on a classification task, comparing it to random few-shot and zero-shot approaches. Using cosine similarity and a Turing test, our approach produced synthetic notes that more closely align with real clinical text. Our pipeline reduced the data needed to reach the 0.85 AUC cutoff by 40% for AUROC and 30% for AUPRC, while augmenting models with synthetic data improved AUROC by 57% and AUPRC by 68%. Additionally, our synthetic data was 0.9 times as effective as real data, a 60% improvement in value.', 'abstract_zh': '在临床文本分类中，通常需要微调预训练语言模型，这一过程因需要高质量数据和专家标注人员而耗时且成本高昂。合成数据生成提供了一种替代方案，但预训练模型可能无法捕捉临床病历的句法多样性。我们提出了一种嵌入驱动的方法，该方法通过从少量真实临床病历中采样多样的嵌入来指导大语言模型进行少样本提示，生成更能反映临床句法的合成文本。我们使用CheXpert数据集对该方法进行了分类任务评估，将其与随机少样本和零样本方法进行了比较。通过余弦相似度和图灵测试，我们的方法生成的合成病历更接近真实临床文本。我们的流程将达到0.85 AUC阈值所需的数据量减少了40%（AUCROC）和30%（AUPRC），同时使用合成数据增强模型提高了AUCROC 57%和AUPRC 68%。此外，我们的合成数据的效果是真实数据的0.9倍，价值提高了60%。', 'title_zh': '基于嵌入驱动的多样性采样以提高少样本合成数据生成'}
{'arxiv_id': 'arXiv:2501.11170', 'title': 'AIMA at SemEval-2024 Task 3: Simple Yet Powerful Emotion Cause Pair Analysis', 'authors': 'Alireza Ghahramani Kure, Mahshid Dehghani, Mohammad Mahdi Abootorabi, Nona Ghazizadeh, Seyed Arshan Dalili, Ehsaneddin Asgari', 'link': 'https://arxiv.org/abs/2501.11170', 'abstract': 'The SemEval-2024 Task 3 presents two subtasks focusing on emotion-cause pair extraction within conversational contexts. Subtask 1 revolves around the extraction of textual emotion-cause pairs, where causes are defined and annotated as textual spans within the conversation. Conversely, Subtask 2 extends the analysis to encompass multimodal cues, including language, audio, and vision, acknowledging instances where causes may not be exclusively represented in the textual data. Our proposed model for emotion-cause analysis is meticulously structured into three core segments: (i) embedding extraction, (ii) cause-pair extraction & emotion classification, and (iii) cause extraction using QA after finding pairs. Leveraging state-of-the-art techniques and fine-tuning on task-specific datasets, our model effectively unravels the intricate web of conversational dynamics and extracts subtle cues signifying causality in emotional expressions. Our team, AIMA, demonstrated strong performance in the SemEval-2024 Task 3 competition. We ranked as the 10th in subtask 1 and the 6th in subtask 2 out of 23 teams.', 'abstract_zh': '以下是符合学术规范的翻译：\n\nSemEval-2024 任务3提出了两个子任务，集中在对话场景中的情绪-原因配对提取。子任务1重点关注文本情绪-原因配对的提取，其中原因被定义并标注为对话中的文本片段。相比之下，子任务2则扩展了分析范围，涵盖了包括语言、音频和视觉在内的多模态线索，认可其中原因可能并不完全体现在文本数据中。\n\n我们提出的用于情绪-原因分析的模型精心设计了三个核心部分：（i）嵌入提取，（ii）原因配对提取与情绪分类，以及（iii）在找到配对后使用问答提取原因。利用最先进的技术并在特定任务数据集上进行微调，我们的模型有效地揭示了对话动态的复杂网络，并提取了表示情绪表达因果关系的微妙线索。我们团队AIMA在SemEval-2024任务3竞争中表现出色。在子任务1中排名第10，在子任务2中排名第6，参赛队伍共有23支。', 'title_zh': 'AIMA在SemEval-2024任务3中的简单而强大的情感原因对分析'}
{'arxiv_id': 'arXiv:2501.11166', 'title': 'AIMA at SemEval-2024 Task 10: History-Based Emotion Recognition in Hindi-English Code-Mixed Conversations', 'authors': 'Mohammad Mahdi Abootorabi, Nona Ghazizadeh, Seyed Arshan Dalili, Alireza Ghahramani Kure, Mahshid Dehghani, Ehsaneddin Asgari', 'link': 'https://arxiv.org/abs/2501.11166', 'abstract': 'In this study, we introduce a solution to the SemEval 2024 Task 10 on subtask 1, dedicated to Emotion Recognition in Conversation (ERC) in code-mixed Hindi-English conversations. ERC in code-mixed conversations presents unique challenges, as existing models are typically trained on monolingual datasets and may not perform well on code-mixed data. To address this, we propose a series of models that incorporate both the previous and future context of the current utterance, as well as the sequential information of the conversation. To facilitate the processing of code-mixed data, we developed a Hinglish-to-English translation pipeline to translate the code-mixed conversations into English. We designed four different base models, each utilizing powerful pre-trained encoders to extract features from the input but with varying architectures. By ensembling all of these models, we developed a final model that outperforms all other baselines.', 'abstract_zh': '在本研究中，我们提出了针对SemEval 2024 TASK 10子任务1的情感识别在混用印地-英语对话（ERC）中的解决方案。在混用语言环境中进行情感识别存在独特挑战，因为现有模型通常是在单语言数据集上训练的，可能在处理混用数据时表现不佳。为应对这一挑战，我们提出了一系列模型，这些模型结合了当前话语及其前后文信息，以及对话的序列信息。为了促进混用数据的处理，我们开发了一个从混用印地-英语到英语的翻译管道，将混用对话翻译成英语。我们设计了四种不同的基础模型，每种模型都使用强大的预训练编码器从输入中提取特征，但具有不同的架构。通过将这些模型进行集成，我们构建了一个最终模型，该模型在所有其他基线之上表现出更优的表现。', 'title_zh': 'AIMA在SemEval-2024任务10中的研究：基于历史的印英代码混合对话情感识别'}
{'arxiv_id': 'arXiv:2501.11128', 'title': 'A Collection of Question Answering Datasets for Norwegian', 'authors': 'Vladislav Mikhailov, Petter Mæhlum, Victoria Ovedie Chruickshank Langø, Erik Velldal, Lilja Øvrelid', 'link': 'https://arxiv.org/abs/2501.11128', 'abstract': 'This paper introduces a new suite of question answering datasets for Norwegian; NorOpenBookQA, NorCommonSenseQA, NorTruthfulQA, and NRK-Quiz-QA. The data covers a wide range of skills and knowledge domains, including world knowledge, commonsense reasoning, truthfulness, and knowledge about Norway. Covering both of the written standards of Norwegian - Bokmål and Nynorsk - our datasets comprise over 10k question-answer pairs, created by native speakers. We detail our dataset creation approach and present the results of evaluating 11 language models (LMs) in zero- and few-shot regimes. Most LMs perform better in Bokmål than Nynorsk, struggle most with commonsense reasoning, and are often untruthful in generating answers to questions. All our datasets and annotation materials are publicly available.', 'abstract_zh': '本文介绍了四种新的挪威语问答数据集：NorOpenBookQA、NorCommonSenseQA、NorTruthfulQA 和 NRK-Quiz-QA。这些数据涵盖了广泛的能力和知识领域，包括世界知识、常识推理、真实性和关于挪威的知识。覆盖了挪威语的两种主要书面形式——Bokmål 和 Nynorsk——我们的数据集包含超过10,000个问题-答案对，均由母语者创建。本文详细介绍了数据集的创建方法，并展示了在零样本和少样本条件下评估11个语言模型（LM）的结果。大多数语言模型在Bokmål中的表现优于Nynorsk，在常识推理方面的表现最差，且在生成答案时经常出现不真实的情况。所有我们的数据集和标注材料均已公开提供。', 'title_zh': '挪威语问答数据集集合'}
{'arxiv_id': 'arXiv:2501.11123', 'title': 'Assessing Semantic Annotation Activities with Formal Concept Analysis', 'authors': 'Juan Cigarrán-Recuero, Joaquín Gayoso-Cabada, Miguel Rodríguez-Artacho, María-Dolores Romero-López, Antonio Sarasa-Cabezuelo, José-Luis Sierra', 'link': 'https://arxiv.org/abs/2501.11123', 'abstract': 'This paper describes an approach to assessing semantic annotation activities based on formal concept analysis (FCA). In this approach, annotators use taxonomical ontologies created by domain experts to annotate digital resources. Then, using FCA, domain experts are provided with concept lattices that graphically display how their ontologies were used during the semantic annotation process. In consequence, they can advise annotators on how to better use the ontologies, as well as how to refine them to better suit the needs of the semantic annotators. To illustrate the approach, we describe its implementation in @note, a Rich Internet Application (RIA) for the collaborative annotation of digitized literary texts, we exemplify its use with a case study, and we provide some evaluation results using the method.', 'abstract_zh': '本文介绍了一种基于形式概念分析（FCA）评估语义标注活动的方法。在此方法中，标注者使用由领域专家创建的分类本体对数字资源进行标注。然后，利用FCA，领域专家可以得到概念格，该概念格图示地展示了本体在语义标注过程中的使用情况。因此，领域专家可以为标注者提供如何更好地利用本体的建议，并且提出改进建议，使其更适合语义标注的需求。为了说明此方法，我们描述了它在@note中的实现，@note是一个富互联网应用程序（RIA），用于协同标注数字化文学文本。我们还通过一个案例研究展示了其应用，并使用此方法提供了某些评估结果。', 'title_zh': '使用形式概念分析评估语义注释活动'}
{'arxiv_id': 'arXiv:2501.11120', 'title': 'Tell me about yourself: LLMs are aware of their learned behaviors', 'authors': 'Jan Betley, Xuchan Bao, Martín Soto, Anna Sztyber-Betley, James Chua, Owain Evans', 'link': 'https://arxiv.org/abs/2501.11120', 'abstract': "We study behavioral self-awareness -- an LLM's ability to articulate its behaviors without requiring in-context examples. We finetune LLMs on datasets that exhibit particular behaviors, such as (a) making high-risk economic decisions, and (b) outputting insecure code. Despite the datasets containing no explicit descriptions of the associated behavior, the finetuned LLMs can explicitly describe it. For example, a model trained to output insecure code says, ``The code I write is insecure.'' Indeed, models show behavioral self-awareness for a range of behaviors and for diverse evaluations. Note that while we finetune models to exhibit behaviors like writing insecure code, we do not finetune them to articulate their own behaviors -- models do this without any special training or examples.\nBehavioral self-awareness is relevant for AI safety, as models could use it to proactively disclose problematic behaviors. In particular, we study backdoor policies, where models exhibit unexpected behaviors only under certain trigger conditions. We find that models can sometimes identify whether or not they have a backdoor, even without its trigger being present. However, models are not able to directly output their trigger by default.\nOur results show that models have surprising capabilities for self-awareness and for the spontaneous articulation of implicit behaviors. Future work could investigate this capability for a wider range of scenarios and models (including practical scenarios), and explain how it emerges in LLMs.", 'abstract_zh': '我们研究行为自我意识——即大规模语言模型（LLM）在无需上下文示例的情况下自我阐述其行为的能力。我们通过对展示特定行为的数据集进行微调，使模型能够描述这些行为，例如（a）进行高风险经济决策，以及（b）生成不安全的代码。尽管这些数据集中没有明确描述相关行为，但经过微调的模型能够明确描述这些行为。例如，一个用于生成不安全代码的模型会说：“我编写的代码是不安全的。”事实上，模型在多种行为和不同评估中都表现出行为自我意识。值得注意的是，尽管我们训练模型以生成不安全代码这类行为，但我们并没有特别训练它们来自我阐述其行为——模型能够自然地自我阐述这些行为，而不需要任何特殊训练或示例。\n\n行为自我意识对于AI安全来说非常重要，因为模型可以利用它主动披露潜在的问题行为。特别地，我们研究了后门策略（backdoor policies），即在特定触发条件下模型会表现出意外行为。我们发现模型有时能够识别是否存在后门，即使在没有触发时也是如此。然而，模型默认情况下无法直接输出其触发条件。\n\n我们的研究结果表明，模型具有令人惊讶的自我意识能力和自发描述隐含行为的能力。未来的研究可以探讨这种能力在更多场景和模型（包括实际场景）中的应用，并解释这种能力如何在大规模语言模型中出现。', 'title_zh': '自我介绍：大型语言模型aware于其学习到的行为'}
{'arxiv_id': 'arXiv:2501.11114', 'title': 'Clinical trial cohort selection using Large Language Models on n2c2 Challenges', 'authors': 'Chi-en Amy Tai, Xavier Tannier', 'link': 'https://arxiv.org/abs/2501.11114', 'abstract': 'Clinical trials are a critical process in the medical field for introducing new treatments and innovations. However, cohort selection for clinical trials is a time-consuming process that often requires manual review of patient text records for specific keywords. Though there have been studies on standardizing the information across the various platforms, Natural Language Processing (NLP) tools remain crucial for spotting eligibility criteria in textual reports. Recently, pre-trained large language models (LLMs) have gained popularity for various NLP tasks due to their ability to acquire a nuanced understanding of text. In this paper, we study the performance of large language models on clinical trial cohort selection and leverage the n2c2 challenges to benchmark their performance. Our results are promising with regard to the incorporation of LLMs for simple cohort selection tasks, but also highlight the difficulties encountered by these models as soon as fine-grained knowledge and reasoning are required.', 'abstract_zh': '临床试验是医学领域引入新治疗方法和创新的关键过程。然而，临床试验中的目标群体选择是一个耗时的过程，通常需要手动审查患者的文本记录以寻找特定关键词。尽管已有研究致力于标准化各平台的信息，自然语言处理（NLP）工具仍然对于在文本报告中识别入组标准至关重要。最近，预训练的大语言模型（LLMs）由于其能捕捉文本的细微理解能力，在各种NLP任务中受到了广泛欢迎。在本文中，我们研究了大语言模型在临床试验目标群体选择中的性能，并通过n2c2挑战赛对其性能进行了基准测试。我们的结果表明，对于简单的目标群体选择任务，大语言模型的应用前景是值得期待的，但也突显了这些模型在遇到细粒度知识和推理需求时所遇到的困难。', 'title_zh': '使用大型语言模型在n2c2挑战中进行临床试验患者群体选择'}
{'arxiv_id': 'arXiv:2501.11110', 'title': 'Chain-of-Reasoning: Towards Unified Mathematical Reasoning in Large Language Models via a Multi-Paradigm Perspective', 'authors': 'Yiyao Yu, Yuxiang Zhang, Dongdong Zhang, Xiao Liang, Hengyuan Zhang, Xingxing Zhang, Ziyi Yang, Mahmoud Khademi, Hany Awadalla, Junjie Wang, Yujiu Yang, Furu Wei', 'link': 'https://arxiv.org/abs/2501.11110', 'abstract': 'Large Language Models (LLMs) have made notable progress in mathematical reasoning, yet they often rely on single-paradigm reasoning that limits their effectiveness across diverse tasks. In this paper, we introduce Chain-of-Reasoning (CoR), a novel unified framework that integrates multiple reasoning paradigms--Natural Language Reasoning (NLR), Algorithmic Reasoning (AR), and Symbolic Reasoning (SR)--to enable synergistic collaboration. CoR generates multiple potential answers using different reasoning paradigms and synthesizes them into a coherent final solution. We propose a Progressive Paradigm Training (PPT) strategy that allows models to progressively master these paradigms, culminating in the development of CoR-Math-7B. Experimental results demonstrate that CoR-Math-7B significantly outperforms current SOTA models, achieving up to a 41.0% absolute improvement over GPT-4 in theorem proving tasks and a 7.9% improvement over RL-based methods in arithmetic tasks. These results showcase the enhanced mathematical comprehensive ability of our model, achieving significant performance gains on specific tasks and enabling zero-shot generalization across tasks.', 'abstract_zh': '大规模语言模型（LLMs）在数学推理方面取得了显著进展，但在多种任务中，它们通常依赖单一范式的推理，这限制了其有效性。本文引入了一种新的统一框架——链式推理（Chain-of-Reasoning, CoR），该框架整合了多种推理范式——自然语言推理（Natural Language Reasoning, NLR）、算法推理（Algorithmic Reasoning, AR）和符号推理（Symbolic Reasoning, SR），以促进这些范式的协同合作。CoR 使用不同的推理范式生成多个潜在答案，并将它们综合成一个连贯的最终解决方案。我们提出了一种渐进范式训练（Progressive Paradigm Training, PPT）策略，使模型能够逐级掌握这些范式，最终开发出 CoR-Math-7B。实验结果表明，CoR-Math-7B 显著优于当前的SOTA模型，在定理证明任务上比GPT-4取得了41.0%的绝对改进，在算术任务上比基于强化学习的方法取得了7.9%的改进。这些结果展示了我们模型增强的数学综合能力，实现了特定任务上的重大性能提升，并促进了任务间的零样本泛化能力。', 'title_zh': '链式推理：从多 paradigms 视角统一大型语言模型中的数学推理'}
{'arxiv_id': 'arXiv:2501.11094', 'title': 'Enhanced Suicidal Ideation Detection from Social Media Using a CNN-BiLSTM Hybrid Model', 'authors': 'Mohaiminul Islam Bhuiyan, Nur Shazwani Kamarudin, Nur Hafieza Ismail', 'link': 'https://arxiv.org/abs/2501.11094', 'abstract': "Suicidal ideation detection is crucial for preventing suicides, a leading cause of death worldwide. Many individuals express suicidal thoughts on social media, offering a vital opportunity for early detection through advanced machine learning techniques. The identification of suicidal ideation in social media text is improved by utilising a hybrid framework that integrates Convolutional Neural Networks (CNN) and Bidirectional Long Short-Term Memory (BiLSTM), enhanced with an attention mechanism. To enhance the interpretability of the model's predictions, Explainable AI (XAI) methods are applied, with a particular focus on SHapley Additive exPlanations (SHAP), are incorporated. At first, the model managed to reach an accuracy of 92.81%. By applying fine-tuning and early stopping techniques, the accuracy improved to 94.29%. The SHAP analysis revealed key features influencing the model's predictions, such as terms related to mental health struggles. This level of transparency boosts the model's credibility while helping mental health professionals understand and trust the predictions. This work highlights the potential for improving the accuracy and interpretability of detecting suicidal tendencies, making a valuable contribution to the progress of mental health monitoring systems. It emphasizes the significance of blending powerful machine learning methods with explainability to develop reliable and impactful mental health solutions.", 'abstract_zh': '自杀意念的检测对于预防自杀这一全球主要死因至关重要。许多人在社交媒体上表达了自杀念头，为通过先进的机器学习技术进行早期检测提供了重要的机会。利用结合卷积神经网络（CNN）和双向长短期记忆网络（BiLSTM）的混合框架，并增强以注意力机制，能够提高社交媒体文本中自杀意念的识别效果。为了增强模型预测的可解释性，应用了可解释的人工智能（XAI）方法，特别是SHapley Additive exPlanations（SHAP）方法。\n\n初次训练模型时，其准确率为92.81%。通过微调和早停技术，准确率提高到94.29%。SHAP分析揭示了影响模型预测的关键特征，例如与心理健康斗争相关的术语。这种透明度提高了模型的可信度，同时也帮助心理健康专业人员理解和信任预测结果。\n\n这项研究表明，通过改进检测精度和可解释性，有潜力提高对自杀倾向的检测能力，对心理健康监控系统的进步做出了有价值的贡献。它强调了将强大的机器学习方法与可解释性相结合的重要性，以开发可靠且具有影响力的mental健康解决方案。', 'title_zh': '使用卷积神经网络-双向长短期记忆网络混合模型增强社交媒体中的自杀意念检测'}
{'arxiv_id': 'arXiv:2501.11090', 'title': 'Dynamic semantic networks for exploration of creative thinking', 'authors': 'Danko D. Georgiev, Georgi V. Georgiev', 'link': 'https://arxiv.org/abs/2501.11090', 'abstract': 'Human creativity originates from brain cortical networks that are specialized in idea generation, processing, and evaluation. The concurrent verbalization of our inner thoughts during the execution of a design task enables the use of dynamic semantic networks as a tool for investigating, evaluating, and monitoring creative thought. The primary advantage of using lexical databases such as WordNet for reproducible information-theoretic quantification of convergence or divergence of design ideas in creative problem solving is the simultaneous handling of both words and meanings, which enables interpretation of the constructed dynamic semantic networks in terms of underlying functionally active brain cortical regions involved in concept comprehension and production. In this study, the quantitative dynamics of semantic measures computed with a moving time window is investigated empirically in the DTRS10 dataset with design review conversations and detected divergent thinking is shown to predict success of design ideas. Thus, dynamic semantic networks present an opportunity for real-time computer-assisted detection of critical events during creative problem solving, with the goal of employing this knowledge to artificially augment human creativity.', 'abstract_zh': '人类的创造力源自于专门负责观念生成、处理和评估的大脑皮层网络。在执行设计任务时同步表达我们的内心想法，使得能够利用动态语义网络作为一种工具来进行创造思维的调查、评估和监控。使用诸如WordNet这样的词汇数据库进行创造问题解决过程中设计想法的可重复信息理论量化分析的主要优势在于同时处理单词和其含义，这使得能够从参与概念理解与生成的功能性活跃的大脑皮层区域的角度来解释构建的动态语义网络。在此研究中，我们通过DTRS10数据集中的设计评审对话实验性地研究了使用滑动时间窗口计算的语义量的定量动态，并且展示了检测发散思维可以预测设计思想的成功。因此，动态语义网络为实时计算机辅助识别创造性问题解决过程中的关键事件提供了机会，以期利用这些知识来人工增强人类创造力。', 'title_zh': '动态语义网络在创造性思维探索中的应用'}
{'arxiv_id': 'arXiv:2501.11067', 'title': 'IntellAgent: A Multi-Agent Framework for Evaluating Conversational AI Systems', 'authors': 'Elad Levi, Ilan Kadar', 'link': 'https://arxiv.org/abs/2501.11067', 'abstract': 'Large Language Models (LLMs) are transforming artificial intelligence, evolving into task-oriented systems capable of autonomous planning and execution. One of the primary applications of LLMs is conversational AI systems, which must navigate multi-turn dialogues, integrate domain-specific APIs, and adhere to strict policy constraints. However, evaluating these agents remains a significant challenge, as traditional methods fail to capture the complexity and variability of real-world interactions. We introduce IntellAgent, a scalable, open-source multi-agent framework designed to evaluate conversational AI systems comprehensively. IntellAgent automates the creation of diverse, synthetic benchmarks by combining policy-driven graph modeling, realistic event generation, and interactive user-agent simulations. This innovative approach provides fine-grained diagnostics, addressing the limitations of static and manually curated benchmarks with coarse-grained metrics. IntellAgent represents a paradigm shift in evaluating conversational AI. By simulating realistic, multi-policy scenarios across varying levels of complexity, IntellAgent captures the nuanced interplay of agent capabilities and policy constraints. Unlike traditional methods, it employs a graph-based policy model to represent relationships, likelihoods, and complexities of policy interactions, enabling highly detailed diagnostics. IntellAgent also identifies critical performance gaps, offering actionable insights for targeted optimization. Its modular, open-source design supports seamless integration of new domains, policies, and APIs, fostering reproducibility and community collaboration. Our findings demonstrate that IntellAgent serves as an effective framework for advancing conversational AI by addressing challenges in bridging research and deployment. The framework is available at this https URL', 'abstract_zh': '大规模语言模型（LLMs）正在重塑人工智能，演化成为能够自主规划和执行任务的系统。LLMs的一个主要应用领域是对话型AI系统，这些系统必须导航多轮对话、整合特定领域的API，并遵守严格的政策约束。然而，评估这些代理仍是一个重大挑战，因为传统方法无法捕捉现实世界交互的复杂性和变异性。我们介绍了一种名为IntellAgent的大规模、开源多代理框架，旨在全面评估对话型AI系统。IntellAgent通过结合基于策略的图建模、现实事件生成以及交互式用户-代理模拟，自动化地创建多样化的合成基准。这种方法提供精细化诊断，克服了采用粗粒度指标的静态和手动策划基准的局限性。IntellAgent在评估对话型AI方面开启了新的范式。通过模拟不同复杂程度下的现实多策略场景，IntellAgent捕捉到了代理能力与政策约束之间微妙的相互作用。不同于传统方法，它采用基于图形的策略模型来表示策略之间的关系、可能性和复杂性，从而实现高度详尽的诊断。IntellAgent还识别关键性能差距，提供有针对性优化的实际见解。其模块化、开源设计支持新领域的无缝集成，促进可再现性和社区合作。我们的研究结果表明，IntellAgent作为有效框架，能够通过弥合研究与部署之间的差距来促进对话型AI的发展。该框架可在以下链接获取：<https://this.is/intellagent>', 'title_zh': 'IntellAgent：一种评估对话AI系统多Agent框架'}
{'arxiv_id': 'arXiv:2501.11041', 'title': 'Enhancing Semantic Consistency of Large Language Models through Model Editing: An Interpretability-Oriented Approach', 'authors': 'Jingyuan Yang, Dapeng Chen, Yajing Sun, Rongjun Li, Zhiyong Feng, Wei Peng', 'link': 'https://arxiv.org/abs/2501.11041', 'abstract': "A Large Language Model (LLM) tends to generate inconsistent and sometimes contradictory outputs when presented with a prompt that has equivalent semantics but is expressed differently from the original prompt. To achieve semantic consistency of an LLM, one of the key approaches is to finetune the model with prompt-output pairs with semantically equivalent meanings. Despite its effectiveness, a data-driven finetuning method incurs substantial computation costs in data preparation and model optimization. In this regime, an LLM is treated as a ``black box'', restricting our ability to gain deeper insights into its internal mechanism. In this paper, we are motivated to enhance the semantic consistency of LLMs through a more interpretable method (i.e., model editing) to this end. We first identify the model components (i.e., attention heads) that have a key impact on the semantic consistency of an LLM. We subsequently inject biases into the output of these model components along the semantic-consistency activation direction. It is noteworthy that these modifications are cost-effective, without reliance on mass manipulations of the original model parameters. Through comprehensive experiments on the constructed NLU and open-source NLG datasets, our method demonstrates significant improvements in the semantic consistency and task performance of LLMs. Additionally, our method exhibits promising generalization capabilities by performing well on tasks beyond the primary tasks.", 'abstract_zh': '大语言模型（LLM）在面对具有等效语义但表达方式不同的提示时，往往会生成不一致甚至相互矛盾的输出。为了实现LLM的语义一致性，一个关键的方法是使用具有等效语义的提示-输出对来微调该模型。尽管这种方法非常有效，但数据驱动的微调方法在数据准备和模型优化方面会带来巨大的计算成本。在这种情况下，我们将LLM视为一个“黑盒”，限制了我们对其内部机制深入了解的能力。在本文中，我们旨在通过一种更具可解释性的方法（即模型编辑）来增强LLM的语义一致性。我们首先识别对LLM语义一致性有关键影响的模型组件（例如，注意力头）。随后，我们沿着语义一致性激活方向，在这些模型组件的输出中注入偏差。值得注意的是，这些修改是成本效益高的，无需大规模操作原始模型参数。通过在构建的自然语言理解（NLU）和开源自然语言生成（NLG）数据集上进行全面实验，我们的方法在提高LLM的语义一致性和任务性能方面取得了显著成效。此外，我们的方法还展示了良好的泛化能力，能够在超出初始任务范围的任务中表现出色。', 'title_zh': '通过模型编辑增强大型语言模型的语义一致性：一种可解释性导向的方法'}
{'arxiv_id': 'arXiv:2501.11036', 'title': 'LF-Steering: Latent Feature Activation Steering for Enhancing Semantic Consistency in Large Language Models', 'authors': 'Jingyuan Yang, Rongjun Li, Weixuan Wang, Ziyu Zhou, Zhiyong Feng, Wei Peng', 'link': 'https://arxiv.org/abs/2501.11036', 'abstract': "Large Language Models (LLMs) often generate inconsistent responses when prompted with semantically equivalent paraphrased inputs. Recently, activation steering, a technique that modulates LLM behavior by adjusting their latent representations during inference time, has been explored to improve the semantic consistency of LLMs. However, these methods typically operate at the model component level, such as layer hidden states or attention heads. They face a challenge due to the ``polysemanticity issue'', where the model components of LLMs typically encode multiple entangled features, making precise steering difficult. To address this challenge, we drill down to feature-level representations and propose LF-Steering, a novel activation steering approach to precisely identify latent feature representations responsible for semantic inconsistency. More specifically, our method maps the hidden states of relevant transformer layer into a sparsely activated, high-dimensional feature space based on a sparse autoencoder (SAE), ensuring model steering based on decoupled feature representations with minimal interference. Comprehensive experiments on both NLU and NLG datasets demonstrate the effectiveness of our method in enhancing semantic consistency, resulting in significant performance gains for various NLU and NLG tasks.", 'abstract_zh': '大型语言模型（LLMs）在受到语义上等价的重述输入时，经常产生不一致的响应。最近，激活 steering 技术被探索以通过调整模型在推理阶段的潜在表示来改善 LLM 的语义一致性。然而，这些方法通常在模型组件级别操作，如层隐藏状态或注意力头。它们因“多义性问题”而面临挑战，即模型组件通常编码多个纠缠的特征，使得精确的指导变得困难。为了解决这一挑战，我们将焦点深入到特征级表示，并提出了 LF-Steering，这是一种新颖的激活 steering 方法，旨在精确识别导致语义不一致的潜在特征表示。具体而言，我们的方法基于稀疏自编码器（SAE）将相关变压器层的隐藏状态映射到一个稀疏激活的高维特征空间，确保基于解耦的特征表示进行最小干扰下的模型指导。我们在 NLU 和 NLG 数据集上的全面实验表明，该方法在提高语义一致性方面具有有效性，从而在各种 NLU 和 NLG 任务中实现了显著的性能提升。', 'title_zh': 'LF-引导：潜在特征激活引导，以增强大型语言模型中的语义一致性'}
{'arxiv_id': 'arXiv:2501.11035', 'title': 'From Arabic Text to Puzzles: LLM-Driven Development of Arabic Educational Crosswords', 'authors': 'Kamyar Zeinalipour, Mohamed Zaky Saad, Marco Maggini, Marco Gori', 'link': 'https://arxiv.org/abs/2501.11035', 'abstract': 'We present an Arabic crossword puzzle generator from a given text that utilizes advanced language models such as GPT-4-Turbo, GPT-3.5-Turbo and Llama3-8B-Instruct, specifically developed for educational purposes, this innovative generator leverages a meticulously compiled dataset named Arabic-Clue-Instruct with over 50,000 entries encompassing text, answers, clues, and categories. This dataset is intricately designed to aid in the generation of pertinent clues linked to specific texts and keywords within defined categories. This project addresses the scarcity of advanced educational tools tailored for the Arabic language, promoting enhanced language learning and cognitive development. By providing a culturally and linguistically relevant tool, our objective is to make learning more engaging and effective through gamification and interactivity. Integrating state-of-the-art artificial intelligence with contemporary learning methodologies, this tool can generate crossword puzzles from any given educational text, thereby facilitating an interactive and enjoyable learning experience. This tool not only advances educational paradigms but also sets a new standard in interactive and cognitive learning technologies. The model and dataset are publicly available.', 'abstract_zh': '我们提出了一种基于给定文本的阿拉伯文 crossword 拼图生成器，该生成器利用了如 GPT-4-Turbo、GPT-3.5-Turbo 和 Llama3-8B-Instruct 等高级语言模型，特别适用于教育目的。该创新生成器利用了一个精心编纂的数据集，名为“Arabic-Clue-Instruct”，包含超过 50,000 条记录，涉及文本、答案、提示和分类。该数据集的复杂设计旨在帮助生成与特定文本及关键词相关的相关提示，适用于特定类别。本项目旨在解决阿拉伯语言领域高级教育工具稀缺的问题，促进语言学习和认知发展。通过提供一个与文化和语言背景相关的工具，我们的目标是通过游戏化和互动性使学习更加有趣和有效。将最先进的 AI 技术与现代教学方法相结合，该工具可以从任何给定的教育文本生成 crossword 拼图，从而提供一种互动和愉快的学习体验。该工具不仅推动了教育模式的发展，还树立了互动和认知学习技术的新标准。模型和数据集均已公开。', 'title_zh': '从阿拉伯文文本到益智题：由大语言模型驱动的阿拉伯语教育填字游戏开发'}
{'arxiv_id': 'arXiv:2501.11023', 'title': 'Investigating the Impact of Language-Adaptive Fine-Tuning on Sentiment Analysis in Hausa Language Using AfriBERTa', 'authors': 'Sani Abdullahi Sani, Shamsuddeen Hassan Muhammad, Devon Jarvis', 'link': 'https://arxiv.org/abs/2501.11023', 'abstract': "Sentiment analysis (SA) plays a vital role in Natural Language Processing (NLP) by ~identifying sentiments expressed in text. Although significant advances have been made in SA for widely spoken languages, low-resource languages such as Hausa face unique challenges, primarily due to a lack of digital resources. This study investigates the effectiveness of Language-Adaptive Fine-Tuning (LAFT) to improve SA performance in Hausa. We first curate a diverse, unlabeled corpus to expand the model's linguistic capabilities, followed by applying LAFT to adapt AfriBERTa specifically to the nuances of the Hausa language. The adapted model is then fine-tuned on the labeled NaijaSenti sentiment dataset to evaluate its performance. Our findings demonstrate that LAFT gives modest improvements, which may be attributed to the use of formal Hausa text rather than informal social media data. Nevertheless, the pre-trained AfriBERTa model significantly outperformed models not specifically trained on Hausa, highlighting the importance of using pre-trained models in low-resource contexts. This research emphasizes the necessity for diverse data sources to advance NLP applications for low-resource African languages. We published the code and the dataset to encourage further research and facilitate reproducibility in low-resource NLP here: this https URL", 'abstract_zh': '情感分析（SA）在自然语言处理（NLP）中扮演着至关重要的角色，它通过识别文本中表达的情感来发挥作用。尽管在广泛使用的语言中已经取得了显著的进步，但对于低资源语言如海洛语（Hausa）来说，仍面临独特的挑战，主要原因在于缺乏数字资源。本研究探讨了语言适应性微调（LAFT）方法在提高海洛语情感分析性能方面的效果。我们首先创建了一个多样化的未标注语料库，以扩展模型的语言能力，随后应用LAFT方法，将AfriBERTa模型具体适应海洛语的语用特征。经过微调的模型在带有标签的NaijaSenti情感数据集中进行评估。我们的研究发现表明，LAFT提供了适度的改进，这可能归因于使用正式的海洛语文本而非非正式的社交媒体数据。然而，预训练的AfriBERTa模型明显优于未在海洛语上进行专门训练的模型，突出了在低资源语境中使用预训练模型的重要性。这项研究强调了为低资源非洲语言的NLP应用提供多样化的数据来源的重要性。我们已将代码和数据集公开，以促进进一步研究并促进低资源NLP的可重复性：this https URL', 'title_zh': '使用AfriBERTa进行豪萨语情感分析中语言自适应微调影响的研究'}
{'arxiv_id': 'arXiv:2501.11012', 'title': 'GenAI Content Detection Task 1: English and Multilingual Machine-Generated Text Detection: AI vs. Human', 'authors': 'Yuxia Wang, Artem Shelmanov, Jonibek Mansurov, Akim Tsvigun, Vladislav Mikhailov, Rui Xing, Zhuohan Xie, Jiahui Geng, Giovanni Puccetti, Ekaterina Artemova, jinyan su, Minh Ngoc Ta, Mervat Abassy, Kareem Ashraf Elozeiri, Saad El Dine Ahmed El Etter, Maiya Goloburda, Tarek Mahmoud, Raj Vardhan Tomar, Nurkhan Laiyk, Osama Mohammed Afzal, Ryuto Koike, Masahiro Kaneko, Alham Fikri Aji, Nizar Habash, Iryna Gurevych, Preslav Nakov', 'link': 'https://arxiv.org/abs/2501.11012', 'abstract': 'We present the GenAI Content Detection Task~1 -- a shared task on binary machine generated text detection, conducted as a part of the GenAI workshop at COLING 2025. The task consists of two subtasks: Monolingual (English) and Multilingual. The shared task attracted many participants: 36 teams made official submissions to the Monolingual subtask during the test phase and 26 teams -- to the Multilingual. We provide a comprehensive overview of the data, a summary of the results -- including system rankings and performance scores -- detailed descriptions of the participating systems, and an in-depth analysis of submissions. this https URL', 'abstract_zh': '我们 presenta 的 GenAI 内容检测任务——作为一种在 2025 年 COLING 会议 GenAI 工作坊中的二元机器生成文本检测共享任务。该任务包含两个子任务：单语（英语）和多语。共享任务吸引了许多参与者：在测试阶段，有 36 支团队提交了单语子任务的正式报告，26 支团队提交了多语子任务的正式报告。我们提供了详细的数据概览、结果总结（包括系统排名和性能分数）、参赛系统详细的描述以及对提交内容的深入分析。本研究的详细内容请参阅此链接：[此 https URL](此 URL 部分应替换为实际链接)', 'title_zh': 'GenAI内容检测任务1：英文和多语言机器生成文本检测：AI与人类对比'}
{'arxiv_id': 'arXiv:2501.11003', 'title': 'Building low-resource African language corpora: A case study of Kidawida, Kalenjin and Dholuo', 'authors': 'Audrey Mbogho, Quin Awuor, Andrew Kipkebut, Lilian Wanzare, Vivian Oloo', 'link': 'https://arxiv.org/abs/2501.11003', 'abstract': "Natural Language Processing is a crucial frontier in artificial intelligence, with broad applications in many areas, including public health, agriculture, education, and commerce. However, due to the lack of substantial linguistic resources, many African languages remain underrepresented in this digital transformation. This paper presents a case study on the development of linguistic corpora for three under-resourced Kenyan languages, Kidaw'ida, Kalenjin, and Dholuo, with the aim of advancing natural language processing and linguistic research in African communities. Our project, which lasted one year, employed a selective crowd-sourcing methodology to collect text and speech data from native speakers of these languages. Data collection involved (1) recording conversations and translation of the resulting text into Kiswahili, thereby creating parallel corpora, and (2) reading and recording written texts to generate speech corpora. We made these resources freely accessible via open-research platforms, namely Zenodo for the parallel text corpora and Mozilla Common Voice for the speech datasets, thus facilitating ongoing contributions and access for developers to train models and develop Natural Language Processing applications. The project demonstrates how grassroots efforts in corpus building can support the inclusion of African languages in artificial intelligence innovations. In addition to filling resource gaps, these corpora are vital in promoting linguistic diversity and empowering local communities by enabling Natural Language Processing applications tailored to their needs. As African countries like Kenya increasingly embrace digital transformation, developing indigenous language resources becomes essential for inclusive growth. We encourage continued collaboration from native speakers and developers to expand and utilize these corpora.", 'abstract_zh': '自然语言处理是人工智能的一个关键前沿领域，它在公共卫生、农业、教育和商业等多个领域有着广泛的应用。然而，由于缺乏充足的语言资源，许多非洲语言在这场数字化转型中依然处于边缘地位。本文通过一个案例研究探讨了为肯尼亚三种资源匮乏的语言——Dalawida、Kalenjin和Dholuo——开发语言语料库的方法，旨在促进非洲社区的自然语言处理和语言学研究。我们的项目历时一年，采用了选择性众包的方法，从这些语言的母语者中收集文本和语音数据。数据收集包括以下步骤：(1) 记录对话并将其翻译成斯瓦希里语，从而创建平行语料库；(2) 认读并记录书面文本以生成语音语料库。我们通过开放研究平台——Zenodo提供平行文本语料库，而Mozilla Common Voice则提供了语音数据集，使得开发者能够继续贡献并访问这些资源以训练模型和开发自然语言处理应用。该项目展示了底层努力在构建语料库方面如何支持非洲语言在人工智能创新中的包容性。这些语料库不仅填补了资源缺口，还有助于促进语言多样性，并通过满足当地社区需求的自然语言处理应用来赋能当地社区。随着像肯尼亚这样的非洲国家日益接受数字化转型，开发本土语言资源对于包容性增长变得至关重要。我们鼓励母语者和开发者继续合作，以扩大和利用这些语料库。', 'title_zh': '构建低资源非洲语言语料库：基达维达语、 Kalenjin 语和朱鲁语案例研究'}
{'arxiv_id': 'arXiv:2501.10970', 'title': 'The Alternative Annotator Test for LLM-as-a-Judge: How to Statistically Justify Replacing Human Annotators with LLMs', 'authors': 'Nitay Calderon, Roi Reichart, Rotem Dror', 'link': 'https://arxiv.org/abs/2501.10970', 'abstract': 'The "LLM-as-a-judge" paradigm employs Large Language Models (LLMs) as annotators and evaluators in tasks traditionally performed by humans. LLM annotations are widely used, not only in NLP research but also in fields like medicine, psychology, and social science. Despite their role in shaping study results and insights, there is no standard or rigorous procedure to determine whether LLMs can replace human annotators. In this paper, we propose a novel statistical procedure -- the Alternative Annotator Test (alt-test) -- that requires only a modest subset of annotated examples to justify using LLM annotations. Additionally, we introduce a versatile and interpretable measure for comparing LLM judges. To demonstrate our procedure, we curated a diverse collection of ten datasets, consisting of language and vision-language tasks, and conducted experiments with six LLMs and four prompting techniques. Our results show that LLMs can sometimes replace humans with closed-source LLMs (such as GPT-4o), outperforming open-source LLMs, and that prompting techniques yield judges of varying quality. We hope this study encourages more rigorous and reliable practices.', 'abstract_zh': '“LLM-as-a-judge”范式利用大型语言模型（LLM）作为注释者和评估者，承担原本由人类完成的任务。LLM的注释不仅在自然语言处理（NLP）研究中广泛应用，也在医学、心理学和社会科学等领域发挥作用。尽管LLM在形成研究结果和见解中起着关键作用，但仍缺乏确定是否可以用LLM替代人类注释者的标准或严谨程序。本文提出了一种新的统计方法——替代注释者测试（Alt-test），仅需少量注释示例即可证明使用LLM注释的有效性。此外，我们还引入了一种灵活且可解释的评估LLM评判者的度量标准。为了展示我们的方法，我们收集了包含多个任务（包括语言和多模态任务）的十个数据集，并使用六种LLM和四种激发技术进行了实验。结果显示，对于某些任务，闭源LLM（如GPT-4o）能够替代人类注释者，并且表现出色，而不同的激发技术生成的评判者的质量也参差不齐。我们希望这项研究能够促进更加严谨和可靠的实践。', 'title_zh': 'LLM作为法官的替代注释员测试：如何通过统计方法证明可以用LLM替代人类注释员'}
{'arxiv_id': 'arXiv:2501.10943', 'title': 'InsQABench: Benchmarking Chinese Insurance Domain Question Answering with Large Language Models', 'authors': 'Jing Ding, Kai Feng, Binbin Lin, Jiarui Cai, Qiushi Wang, Yu Xie, Xiaojin Zhang, Zhongyu Wei, Wei Chen', 'link': 'https://arxiv.org/abs/2501.10943', 'abstract': 'The application of large language models (LLMs) has achieved remarkable success in various fields, but their effectiveness in specialized domains like the Chinese insurance industry remains underexplored. The complexity of insurance knowledge, encompassing specialized terminology and diverse data types, poses significant challenges for both models and users. To address this, we introduce InsQABench, a benchmark dataset for the Chinese insurance sector, structured into three categories: Insurance Commonsense Knowledge, Insurance Structured Database, and Insurance Unstructured Documents, reflecting real-world insurance question-answering this http URL also propose two methods, SQL-ReAct and RAG-ReAct, to tackle challenges in structured and unstructured data tasks. Evaluations show that while LLMs struggle with domain-specific terminology and nuanced clause texts, fine-tuning on InsQABench significantly improves performance. Our benchmark establishes a solid foundation for advancing LLM applications in the insurance domain, with data and code available at this https URL.', 'abstract_zh': '大型语言模型（LLMs）在各个领域的应用已经取得了显著的成功，但在专业领域如中国保险业中的效果仍待进一步探索。保险知识的复杂性，包括专业术语和多种数据类型，对模型和用户都构成了重大挑战。为了解决这一问题，我们介绍了InsQABench，这是一个针对中国保险行业的基准数据集，分为三大类：保险常识知识、保险结构化数据库和保险非结构化文档，反映了现实世界中的保险问答。我们还提出了两种方法，SQL-ReAct 和 RAG-ReAct，以应对结构化和非结构化数据任务中的挑战。评估结果显示，虽然LLMs在处理领域特定的专业术语和复杂的条款文本方面存在困难，但针对InsQABench进行微调可以显著提高性能。我们的基准为推动LLMs在保险领域的应用奠定了坚实的基础，数据和代码可在以下链接获取：[此处插入链接]。', 'title_zh': 'InsQABench: 使用大规模语言模型对中文保险领域问答进行基准测试'}
{'arxiv_id': 'arXiv:2501.10937', 'title': 'Leveraging Chain of Thought towards Empathetic Spoken Dialogue without Corresponding Question-Answering Data', 'authors': 'Jingran Xie, Shun Lei, Yue Yu, Yang Xiang, Hui Wang, Xixin Wu, Zhiyong Wu', 'link': 'https://arxiv.org/abs/2501.10937', 'abstract': "Empathetic dialogue is crucial for natural human-computer interaction, allowing the dialogue system to respond in a more personalized and emotionally aware manner, improving user satisfaction and engagement. The emergence of large language models (LLMs) has revolutionized dialogue generation by harnessing their powerful capabilities and shown its potential in multimodal domains. Many studies have integrated speech with text-based LLMs to take speech question as input and output text response. However, the lack of spoken question-answering datasets that include speech style information to supervised fine-tuning (SFT) limits the performance of these systems. As a result, while these systems excel at understanding speech content, they often struggle to generate empathetic responses. In response, we propose a novel approach that circumvents the need for question-answering data, called Listen, Perceive, and Express (LPE). Our method employs a two-stage training process, initially guiding the LLM to listen the content and perceive the emotional aspects of speech. Subsequently, we utilize Chain-of-Thought (CoT) prompting to unlock the model's potential for expressing empathetic responses based on listened spoken content and perceived emotional cues. We employ experiments to prove the effectiveness of proposed method. To our knowledge, this is the first attempt to leverage CoT for speech-based dialogue.", 'abstract_zh': '同理心对话对于自然的人机交互至关重要，它能使对话系统以更加个性化和情绪感知的方式作出回应，从而提升用户满意度和参与度。大规模语言模型（LLMs）的出现通过利用它们的强大功能已经彻底改变了对话生成，并在多模态领域展示了其潜力。许多研究将语音与基于文本的LLMs相结合，将语音问题作为输入，输出文本回答。然而，缺乏包含口语风格信息的问答数据集以监督微调（SFT）限制了这些系统的性能。因此，尽管这些系统在理解语音内容方面表现出色，但在生成同理心回应方面经常遇到困难。为解决这一问题，我们提出了一种新颖的方法，称之为“倾听、感知和表达”（LPE）。该方法采用两阶段训练过程，首先引导LLM倾听内容并感知语音的情绪方面。随后，我们利用链式思维（CoT）提示来解锁模型根据倾听的口语内容和感知到的情绪线索表达同理心回应的潜力。我们通过实验证明了所提方法的有效性。据我们所知，这是首次尝试利用CoT进行基于语音的对话。', 'title_zh': '利用思维链促进无对应问答数据的同理心口语对话系统发展'}
{'arxiv_id': 'arXiv:2501.10915', 'title': 'LegalGuardian: A Privacy-Preserving Framework for Secure Integration of Large Language Models in Legal Practice', 'authors': 'M. Mikail Demir, Hakan T. Otal, M. Abdullah Canbaz', 'link': 'https://arxiv.org/abs/2501.10915', 'abstract': 'Large Language Models (LLMs) hold promise for advancing legal practice by automating complex tasks and improving access to justice. However, their adoption is limited by concerns over client confidentiality, especially when lawyers include sensitive Personally Identifiable Information (PII) in prompts, risking unauthorized data exposure. To mitigate this, we introduce LegalGuardian, a lightweight, privacy-preserving framework tailored for lawyers using LLM-based tools. LegalGuardian employs Named Entity Recognition (NER) techniques and local LLMs to mask and unmask confidential PII within prompts, safeguarding sensitive data before any external interaction. We detail its development and assess its effectiveness using a synthetic prompt library in immigration law scenarios. Comparing traditional NER models with one-shot prompted local LLM, we find that LegalGuardian achieves a F1-score of 93% with GLiNER and 97% with Qwen2.5-14B in PII detection. Semantic similarity analysis confirms that the framework maintains high fidelity in outputs, ensuring robust utility of LLM-based tools. Our findings indicate that legal professionals can harness advanced AI technologies without compromising client confidentiality or the quality of legal documents.', 'abstract_zh': '大规模语言模型（LLMs）有可能通过自动化复杂任务和提高司法 accessibility 来推进法律实践。然而，它们的应用受限于对客户机密性的担忧，尤其是当律师在提示中包含敏感的个人可识别信息（PII）时，可能会导致未经授权的数据泄露。为解决这一问题，我们提出了 LegalGuardian，这是一种针对使用基于LLM工具的律师量身定制的轻量级隐私保护框架。LegalGuardian 使用命名实体识别（NER）技术和本地LLM来在提示中屏蔽和脱敏敏感的PII，确保在任何外部交互之前保护敏感数据。我们详细介绍了该框架的开发过程，并通过移民法场景中的合成提示库评估了其效果。通过比较传统的NER模型和一次性提示的本地LLM，我们发现 LegalGuardian 在使用 GLiNER 时达到了93% 的F1分数，在使用 Qwen2.5-14B 时达到了97% 的PII检测准确率。语义相似性分析表明，该框架在输出上保持了高保真度，确保了基于LLM工具的实用性。我们的研究结果表明，法律专业人士可以在不牺牲客户机密性或法律文件质量的情况下利用先进的AI技术。', 'title_zh': 'LegalGuardian：一种保护隐私的安全集成框架，用于法律实践中的大型语言模型'}
{'arxiv_id': 'arXiv:2501.10879', 'title': 'A Benchmark of French ASR Systems Based on Error Severity', 'authors': 'Antoine Tholly, Jane Wottawa, Mickael Rouvier, Richard Dufour', 'link': 'https://arxiv.org/abs/2501.10879', 'abstract': 'Automatic Speech Recognition (ASR) transcription errors are commonly assessed using metrics that compare them with a reference transcription, such as Word Error Rate (WER), which measures spelling deviations from the reference, or semantic score-based metrics. However, these approaches often overlook what is understandable to humans when interpreting transcription errors. To address this limitation, a new evaluation is proposed that categorizes errors into four levels of severity, further divided into subtypes, based on objective linguistic criteria, contextual patterns, and the use of content words as the unit of analysis. This metric is applied to a benchmark of 10 state-of-the-art ASR systems on French language, encompassing both HMM-based and end-to-end models. Our findings reveal the strengths and weaknesses of each system, identifying those that provide the most comfortable reading experience for users.', 'abstract_zh': '自动语音识别（ASR）转录错误通常使用与参考转录进行比较的指标来评估，例如字错误率（WER），该指标衡量转录中的拼写偏差，或基于语义得分的指标。然而，这些方法在解读转录错误时往往忽略了人类的理解能力。为解决这一局限，提出了一种新的评估方法，该方法根据客观语言标准、上下文模式，并以内容词作为分析单元，将错误分为四个严重程度级别，并进一步细分为主类型。该指标应用于涵盖基于HMM和端到端模型的10个先进ASR系统的法语基准。我们的研究结果揭示了每个系统的强项和弱点，识别出那些为用户提供最佳阅读体验的系统。', 'title_zh': '基于错误严重性的法语自动语音识别系统基准测试'}
{'arxiv_id': 'arXiv:2501.10868', 'title': 'Generating Structured Outputs from Language Models: Benchmark and Studies', 'authors': 'Saibo Geng, Hudson Cooper, Michał Moskal, Samuel Jenkins, Julian Berman, Nathan Ranchin, Robert West, Eric Horvitz, Harsha Nori', 'link': 'https://arxiv.org/abs/2501.10868', 'abstract': 'Reliably generating structured outputs has become a critical capability for modern language model (LM) applications. Constrained decoding has emerged as the dominant technology across sectors for enforcing structured outputs during generation. Despite its growing adoption, little has been done with the systematic evaluation of the behaviors and performance of constrained decoding. Constrained decoding frameworks have standardized around JSON Schema as a structured data format, with most uses guaranteeing constraint compliance given a schema. However, there is poor understanding of the effectiveness of the methods in practice. We present an evaluation framework to assess constrained decoding approaches across three critical dimensions: efficiency in generating constraint-compliant outputs, coverage of diverse constraint types, and quality of the generated outputs. To facilitate this evaluation, we introduce JSONSchemaBench, a benchmark for constrained decoding comprising 10K real-world JSON schemas that encompass a wide range of constraints with varying complexity. We pair the benchmark with the existing official JSON Schema Test Suite and evaluate six state-of-the-art constrained decoding frameworks, including Guidance, Outlines, Llamacpp, XGrammar, OpenAI, and Gemini. Through extensive experiments, we gain insights into the capabilities and limitations of constrained decoding on structured generation with real-world JSON schemas. Our work provides actionable insights for improving constrained decoding frameworks and structured generation tasks, setting a new standard for evaluating constrained decoding and structured generation. We release JSONSchemaBench at this https URL', 'abstract_zh': '可靠生成结构化输出已成为现代语言模型（LM）应用中的关键能力。约束解码已成为跨领域中确保生成结构化输出的技术主导方法。尽管它的应用越来越广泛，但对于约束解码的行为和性能的系统性评价却较少。尽管约束解码框架主要基于JSON Schema作为结构化数据格式，并且大多数用户能够在给定模式的情况下保证约束合规性，但在实践中这些方法的有效性却缺乏深入理解。我们提出了一种评估框架，从三个关键维度评估约束解码方法：生成约束合规输出的效率、涵盖多样约束类型的广度，以及生成输出的质量。为了支持这项评估，我们引入了JSONSchemaBench，这是一个包含10,000个实际JSON模式的基准测试，这些模式涵盖了各种不同复杂度的约束。我们还将基准测试与现有的官方JSON Schema测试套件结合使用，并评估了六种最先进的约束解码框架，包括Guidance、Outlines、Llamacpp、XGrammar、OpenAI和Gemini。通过广泛的实验，我们深入揭示了在实际JSON模式下进行结构生成时约束解码的能力和局限性。我们的工作为改进约束解码框架和结构生成任务提供了可操作的见解，并为评估约束解码和结构生成设定了新标准。我们在此处发布JSONSchemaBench：[提供链接]', 'title_zh': '从语言模型生成结构化输出：基准与研究'}
{'arxiv_id': 'arXiv:2501.10860', 'title': 'Zero-shot and Few-shot Learning with Instruction-following LLMs for Claim Matching in Automated Fact-checking', 'authors': 'Dina Pisarevskaya, Arkaitz Zubiaga', 'link': 'https://arxiv.org/abs/2501.10860', 'abstract': 'The claim matching (CM) task can benefit an automated fact-checking pipeline by putting together claims that can be resolved with the same fact-check. In this work, we are the first to explore zero-shot and few-shot learning approaches to the task. We consider CM as a binary classification task and experiment with a set of instruction-following large language models (GPT-3.5-turbo, Gemini-1.5-flash, Mistral-7B-Instruct, and Llama-3-8B-Instruct), investigating prompt templates. We introduce a new CM dataset, ClaimMatch, which will be released upon acceptance. We put LLMs to the test in the CM task and find that it can be tackled by leveraging more mature yet similar tasks such as natural language inference or paraphrase detection. We also propose a pipeline for CM, which we evaluate on texts of different lengths.', 'abstract_zh': '声明匹配（CM）任务可以通过将可以使用相同事实核查解决的声明组合起来，从而有益于自动事实核查流水线。在本文中，我们首次探索了零样本和少样本学习方法在这一任务中的应用。我们将CM视为二元分类任务，并尝试了一系列遵循指令的大语言模型（GPT-3.5-turbo、Gemini-1.5-flash、Mistral-7B-Instruct 和 Llama-3-8B-Instruct），研究了提示模板。我们引入了一个新的CM数据集，称之为ClaimMatch，该数据集将在接受后公开。我们在CM任务中测试了LLMs，并发现可以通过利用更成熟且相似的任务（如自然语言推理或同义词检测）来解决这一问题。我们还提出了一种CM管道，并在不同长度的文本上进行了评估。', 'title_zh': '遵循指令的大型语言模型在自动化事实核查中进行断言匹配的零样本和少样本学习'}
{'arxiv_id': 'arXiv:2501.10836', 'title': 'BAP v2: An Enhanced Task Framework for Instruction Following in Minecraft Dialogues', 'authors': 'Prashant Jayannavar, Liliang Ren, Marisa Hudspeth, Charlotte Lambert, Ariel Cordes, Elizabeth Kaplan, Anjali Narayan-Chen, Julia Hockenmaier', 'link': 'https://arxiv.org/abs/2501.10836', 'abstract': 'Interactive agents capable of understanding and executing instructions in the physical world have long been a central goal in AI research. The Minecraft Collaborative Building Task (MCBT) provides one such setting to work towards this goal (Narayan-Chen, Jayannavar, and Hockenmaier 2019). It is a two-player game in which an Architect (A) instructs a Builder (B) to construct a target structure in a simulated Blocks World Environment. We focus on the challenging Builder Action Prediction (BAP) subtask of predicting correct action sequences in a given multimodal game context with limited training data (Jayannavar, Narayan-Chen, and Hockenmaier 2020). We take a closer look at evaluation and data for the BAP task, discovering key challenges and making significant improvements on both fronts to propose BAP v2, an upgraded version of the task. This will allow future work to make more efficient and meaningful progress on it. It comprises of: (1) an enhanced evaluation benchmark that includes a cleaner test set and fairer, more insightful metrics, and (2) additional synthetic training data generated from novel Minecraft dialogue and target structure simulators emulating the MCBT. We show that the synthetic data can be used to train more performant and robust neural models even with relatively simple training methods. Looking ahead, such data could also be crucial for training more sophisticated, data-hungry deep transformer models and training/fine-tuning increasingly large LLMs. Although modeling is not the primary focus of this work, we also illustrate the impact of our data and training methodologies on a simple LLM- and transformer-based model, thus validating the robustness of our approach, and setting the stage for more advanced architectures and LLMs going forward.', 'abstract_zh': '在物理世界中理解并执行指令的交互式代理一直是人工智能研究中的核心目标。Minecraft协作建筑任务（MCBT）提供了一个实现这一目标的环境（Narayan-Chen, Jayannavar, and Hockenmaier 2019）。这是一个两人游戏，其中建筑师（A）向建造者（B）发出指令，在模拟的方块世界环境中构建一个目标结构。本文重点关注预测给定多模态游戏上下文中正确行动序列的具有挑战性的建造者动作预测（BAP）子任务，特别是在有限训练数据的情况下（Jayannavar, Narayan-Chen, and Hockenmaier 2020）。我们更加深入地探讨了BAP任务的评估和数据，发现了关键挑战并对两方面都做出了显著改进，提出了BAP v2这一任务的升级版本。这将允许未来工作在此基础上更高效、更有意义地取得进展。具体包括：（1）一个增强的评估基准，其中包括更干净的测试集和更加公平、更具洞察力的指标，以及（2）从新颖的Minecraft对话和目标结构模拟器中生成的额外合成训练数据，这些模拟器模拟了MCBT。我们展示了合成数据即使使用相对简单的训练方法，也可以用于训练性能更优、更稳健的神经网络模型。展望未来，此类数据也可能是训练更复杂、数据饥渴的深度转换器模型以及不断增大语言模型（LLM）规模所不可或缺的。尽管建模不是本文的重点，但我们也展示了我们的数据和训练方法对一种简单的LLM及变压器模型的影响，从而验证了我们方法的稳健性，并为更先进的架构和语言模型奠定了基础。', 'title_zh': 'BAP v2：一种增强的任务框架，用于Minecraft对话中的指令跟随'}
{'arxiv_id': 'arXiv:2501.10741', 'title': 'Development of Application-Specific Large Language Models to Facilitate Research Ethics Review', 'authors': 'Sebastian Porsdam Mann, Joel Seah Jiehao, Stephen R. Latham, Julian Savulescu, Mateo Aboy, Brian D. Earp', 'link': 'https://arxiv.org/abs/2501.10741', 'abstract': 'Institutional review boards (IRBs) play a crucial role in ensuring the ethical conduct of human subjects research, but face challenges including inconsistency, delays, and inefficiencies. We propose the development and implementation of application-specific large language models (LLMs) to facilitate IRB review processes. These IRB-specific LLMs would be fine-tuned on IRB-specific literature and institutional datasets, and equipped with retrieval capabilities to access up-to-date, context-relevant information. We outline potential applications, including pre-review screening, preliminary analysis, consistency checking, and decision support. While addressing concerns about accuracy, context sensitivity, and human oversight, we acknowledge remaining challenges such as over-reliance on AI and the need for transparency. By enhancing the efficiency and quality of ethical review while maintaining human judgment in critical decisions, IRB-specific LLMs offer a promising tool to improve research oversight. We call for pilot studies to evaluate the feasibility and impact of this approach.', 'abstract_zh': '机构审查委员会（IRB）在确保人类受试者研究的伦理方面发挥着关键作用，但面临不一致、延迟和效率低下等问题。我们提议开发和实施针对特定应用的大语言模型（LLM），以促进IRB审查流程。这些针对IRB的特定的LLM将基于IRB特定的文献和机构数据集进行微调，并配备检索能力，以访问最新且与上下文相关的信息。我们概述了潜在的应用场景，包括预审筛选、初步分析、一致性检查和决策支持。在解决准确性和上下文敏感性以及人类监督等问题的同时，我们承认仍存在一些挑战，如过度依赖AI和透明度问题。通过提高伦理审查的效率和质量，同时在关键决策中保持人类判断，IRB特定的LLM提供了一种有前途的工具，以改进研究监督。我们呼吁开展试点研究，以评估该方法的可行性和影响。', 'title_zh': '开发应用特定的大语言模型以促进研究伦理审查'}
{'arxiv_id': 'arXiv:2501.10739', 'title': 'Computational Discovery of Chiasmus in Ancient Religious Text', 'authors': 'Hope McGovern, Hale Sirin, Tom Lippincott', 'link': 'https://arxiv.org/abs/2501.10739', 'abstract': 'Chiasmus, a debated literary device in Biblical texts, has captivated mystics while sparking ongoing scholarly discussion. In this paper, we introduce the first computational approach to systematically detect chiasmus within Biblical passages. Our method leverages neural embeddings to capture lexical and semantic patterns associated with chiasmus, applied at multiple levels of textual granularity (half-verses, verses). We also involve expert annotators to review a subset of the detected patterns. Despite its computational efficiency, our method achieves robust results, with high inter-annotator agreement and system precision@k of 0.80 at the verse level and 0.60 at the half-verse level. We further provide a qualitative analysis of the distribution of detected chiasmi, along with selected examples that highlight the effectiveness of our approach.', 'abstract_zh': '隐涵修辞法（Chiasmus）是《圣经》中一个备受争议的文学手法，吸引了神秘主义者，并引起了持续的学术讨论。本文介绍了首个针对《圣经》段落中隐涵修辞法系统检测的计算方法。我们的方法利用神经嵌入来捕捉与隐涵修辞法相关的词汇和语义模式，并应用于文本的不同粒度级别（半节、节）。我们还邀请了专家注释员对检测到的一些模式进行了审查。尽管具有计算效率，我们的方法依然取得了稳健的结果，其中节粒度的注释者间一致性较高，半节粒度的系统精度@k为0.80和0.60。此外，我们还提供了检测到的隐涵（chiasm）分布的定性分析，并选了一些示例来展示我们方法的有效性。', 'title_zh': '古代宗教文本中的交叉对称结构的计算发现'}
{'arxiv_id': 'arXiv:2501.10731', 'title': 'Characterizing the Effects of Translation on Intertextuality using Multilingual Embedding Spaces', 'authors': 'Hope McGovern, Hale Sirin, Tom Lippincott', 'link': 'https://arxiv.org/abs/2501.10731', 'abstract': 'Rhetorical devices are difficult to translate, but they are crucial to the translation of literary documents. We investigate the use of multilingual embedding spaces to characterize the preservation of intertextuality, one common rhetorical device, across human and machine translation. To do so, we use Biblical texts, which are both full of intertextual references and are highly translated works. We provide a metric to characterize intertextuality at the corpus level and provide a quantitative analysis of the preservation of this rhetorical device across extant human translations and machine-generated counterparts. We go on to provide qualitative analysis of cases wherein human translations over- or underemphasize the intertextuality present in the text, whereas machine translations provide a neutral baseline. This provides support for established scholarship proposing that human translators have a propensity to amplify certain literary characteristics of the original manuscripts.', 'abstract_zh': '修辞手法难以翻译，但在文学文件的翻译中至关重要。我们研究了利用多语言嵌入空间来表征跨人类和机器翻译过程中引文关系（一种常见的修辞手法）的保留情况。为此，我们利用了圣经文本，这些文本不仅充满了引文参考，而且是高度翻译的作品。我们提供了一个衡量引文关系的指标，并对这一修辞手法在现有的人类翻译和机器生成版本中的保留情况进行了数量分析。我们进一步对人类翻译过分强调或忽略文本中引文关系的情况进行了定性分析，而机器翻译则提供了中立的基线。这为现有学术研究提供了支持，这些研究认为译者倾向于放大原始手稿的某些文学特征。', 'title_zh': '使用多语言嵌入空间Characterizing翻译对互文性影响的特征分析'}
{'arxiv_id': 'arXiv:2501.10685', 'title': 'Harnessing the Potential of Large Language Models in Modern Marketing Management: Applications, Future Directions, and Strategic Recommendations', 'authors': 'Raha Aghaei, Ali A. Kiaei, Mahnaz Boush, Javad Vahidi, Mohammad Zavvar, Zeynab Barzegar, Mahan Rofoosheh', 'link': 'https://arxiv.org/abs/2501.10685', 'abstract': 'Large Language Models (LLMs) have revolutionized the process of customer engagement, campaign optimization, and content generation, in marketing management. In this paper, we explore the transformative potential of LLMs along with the current applications, future directions, and strategic recommendations for marketers. In particular, we focus on LLMs major business drivers such as personalization, real-time-interactive customer insights, and content automation, and how they enable customers and business outcomes. For instance, the ethical aspects of AI with respect to data privacy, transparency, and mitigation of bias are also covered, with the goal of promoting responsible use of the technology through best practices and the use of new technologies businesses can tap into the LLM potential, which help growth and stay one step ahead in the turmoil of digital marketing. This article is designed to give marketers the necessary guidance by using best industry practices to integrate these powerful LLMs into their marketing strategy and innovation without compromising on the ethos of their brand.', 'abstract_zh': '大规模语言模型（LLMs）在市场营销管理中重新定义了客户互动、活动优化和内容生成的过程。本文探讨了LLMs的变革潜力及其当前应用、未来方向和策略建议。特别地，本文重点研究了LLMs的主要商业驱动因素，包括个性化、实时交互式客户洞察以及内容自动化，并探讨了这些因素如何促进客户和业务成果的提升。例如，还涵盖了AI伦理方面的问题，如数据隐私、透明度以及偏见的缓解，旨在通过最佳实践和技术创新促进技术的负责任使用。通过这些新技术，企业可以发挥LLMs的潜力，推动增长，并在数字营销的激烈竞争中保持领先地位。本文旨在通过最佳行业实践为营销人员提供必要的指导，使他们能够在不牺牲品牌形象核心理念的前提下将这些强大的LLMs融入其营销策略和创新之中。', 'title_zh': '现代营销管理中大规模语言模型潜力的开发利用：应用、未来方向及战略建议'}
{'arxiv_id': 'arXiv:2501.10648', 'title': 'DNA 1.0 Technical Report', 'authors': 'Jungyup Lee, Jemin Kim, Sang Park, SeungJae Lee', 'link': 'https://arxiv.org/abs/2501.10648', 'abstract': 'In this report, we present DNA 1.0 8B Instruct, a state-of-the-art bilingual language model optimized for Korean and English language tasks. By applying continual pre-training (CPT) with high-quality Korean datasets to Llama 3.1 8B and subsequent supervised fine-tuning (SFT), we create an instruction-following model with enhanced Korean language capabilities. This model is then merged with Llama 3.1 8B Instruct via spherical linear interpolation (SLERP) and undergoes further optimization through direct preference optimization (DPO) and knowledge distillation (KD). DNA 1.0 8B Instruct achieves state-of-the-art results on Korean-specific tasks, including KMMLU (53.26%), KoBEST (83.40%), and BELEBELE (57.99%), while maintaining strong English capabilities on MMLU (66.64%), MMLU-Pro (43.05%) and GSM8K (80.52%). As an open model, DNA 1.0 8B Instruct represents a significant advancement in bilingual language modeling. \nAs an open model, DNA 1.0 8B Instruct is freely available through this https URL . For commercial licensing inquiries or feedback, please contact us at this https URL', 'abstract_zh': '以下是经学术规范翻译的内容：\n\n本报告介绍了DNA 1.0 8B Instruct，这是一种针对韩语和英语任务优化的前沿双语语言模型。通过将高质量的韩语数据集用于持续预训练（CPT）并结合有监督微调（SFT），我们在Llama 3.1 8B上构建了一个具备增强韩语能力的指令跟随模型。然后，我们使用球面线性插值（SLERP）将该模型与Llama 3.1 8B Instruct进行合并，并通过直接偏好优化（DPO）和知识蒸馏（KD）进行进一步优化。DNA 1.0 8B Instruct在特定的韩语任务上取得了前沿的结果，包括KMMLU（53.26%）、KoBEST（83.40%）和BELEBELE（57.99%），同时还在MMLU（66.64%）、MMLU-Pro（43.05%）和GSM8K（80.52%）的英语任务上保持了强大的表现。作为开源模型，DNA 1.0 8B Instruct 在双语语言建模方面代表了重要进展。\n\n作为开源模型，DNA 1.0 8B Instruct 通过以下链接公开提供：[此链接]。如需商业授权或有任何反馈，请通过以下链接联系我们：[此链接]', 'title_zh': 'DNA 1.0 技术报告'}
{'arxiv_id': 'arXiv:2501.10642', 'title': 'Iterative Tree Analysis for Medical Critics', 'authors': 'Zenan Huang, Mingwei Li, Zheng Zhou, Youxin Jiang', 'link': 'https://arxiv.org/abs/2501.10642', 'abstract': 'Large Language Models (LLMs) have been widely adopted across various domains, yet their application in the medical field poses unique challenges, particularly concerning the generation of hallucinations. Hallucinations in open-ended long medical text manifest as misleading critical claims, which are difficult to verify due to two reasons. First, critical claims are often deeply entangled within the text and cannot be extracted based solely on surface-level presentation. Second, verifying these claims is challenging because surface-level token-based retrieval often lacks precise or specific evidence, leaving the claims unverifiable without deeper mechanism-based analysis. In this paper, we introduce a novel method termed Iterative Tree Analysis (ITA) for medical critics. ITA is designed to extract implicit claims from long medical texts and verify each claim through an iterative and adaptive tree-like reasoning process. This process involves a combination of top-down task decomposition and bottom-up evidence consolidation, enabling precise verification of complex medical claims through detailed mechanism-level reasoning. Our extensive experiments demonstrate that ITA significantly outperforms previous methods in detecting factual inaccuracies in complex medical text verification tasks by 10%. Additionally, we will release a comprehensive test set to the public, aiming to foster further advancements in research within this domain.', 'abstract_zh': '大型语言模型（Large Language Models, LLMs）已在多个领域得到广泛应用，但在医疗领域的应用却面临着独特挑战，尤其是幻觉生成的问题。在开放式的长篇医疗文本中，幻觉表现为误导性的关键声明，这些声明难以验证，原因有两个方面。首先，关键声明通常深嵌于文本之中，仅凭表面层面的呈现无法提取。其次，验证这些声明具有挑战性，因为基于表面的令牌检索往往缺乏精确或具体的证据，使得在没有深入机制分析的情况下，这些声明无法被验证。在本文中，我们提出了一种名为迭代树分析（Iterative Tree Analysis, ITA）的方法，用于医疗批判。ITA旨在从长篇医疗文本中提取隐含声明，并通过迭代和自适应的树形推理过程验证每个声明。这一过程结合了自上而下的任务分解和自下而上的证据汇聚，使得通过详细的机制级推理实现复杂医疗声明的精确验证成为可能。我们广泛的实验结果表明，ITA在检测复杂医疗文本验证任务中的事实不准确度上显著优于先前方法，性能提升了10%。此外，我们还将发布一个全面的测试集，旨在促进该领域进一步的研究进展。', 'title_zh': '医学评审中的迭代树分析'}
{'arxiv_id': 'arXiv:2501.10582', 'title': 'Adapting Large Language Models for Character-based Augmentative and Alternative Communication', 'authors': 'Dylan Gaines, Keith Vertanen', 'link': 'https://arxiv.org/abs/2501.10582', 'abstract': 'Users of Augmentative and Alternative Communication (AAC) may write letter-by-letter via an interface that uses a character language model. However, most state-of-the-art large pretrained language models predict subword tokens of variable length. We investigate how to practically use such models to make accurate and efficient character predictions. We fine-tune models using a large dataset of sentences we curated in which each sentence is rated according to how useful it might be for spoken or written AAC communication. We find that using an algorithm to produce character predictions from a subword large language model provides more accurate predictions than adding a classification layer or using a byte-level model. We also find that our domain adaptation curriculum is effective at improving model performance on simple, conversational text.', 'abstract_zh': '使用辅助和替代交流（Augmentative and Alternative Communication, AAC）的用户可以通过使用字符语言模型的接口逐字符输入。然而，当前最先进的大规模预训练语言模型通常预测长度可变的子词单元。我们研究了如何有效地利用这些模型来实现准确且高效的字符预测。我们使用了一个我们自编的大型句子数据集进行模型微调，该数据集中的每个句子都根据其在口语或书面AC交流中的潜在 usefulness进行了评分。我们发现，利用一个算法从子词大规模语言模型生成字符预测，比增加一个分类层或使用字节级模型能提供更准确的预测。我们还发现，我们的领域适应课程对提高模型在简单会话文本上的性能是有效的。', 'title_zh': '将大型语言模型适配用于基于字符的辅助和替代沟通系统'}
{'arxiv_id': 'arXiv:2501.10573', 'title': 'The Geometry of Tokens in Internal Representations of Large Language Models', 'authors': 'Karthik Viswanathan, Yuri Gardinazzi, Giada Panerai, Alberto Cazzaniga, Matteo Biagetti', 'link': 'https://arxiv.org/abs/2501.10573', 'abstract': 'We investigate the relationship between the geometry of token embeddings and their role in the next token prediction within transformer models. An important aspect of this connection uses the notion of empirical measure, which encodes the distribution of token point clouds across transformer layers and drives the evolution of token representations in the mean-field interacting picture. We use metrics such as intrinsic dimension, neighborhood overlap, and cosine similarity to observationally probe these empirical measures across layers. To validate our approach, we compare these metrics to a dataset where the tokens are shuffled, which disrupts the syntactic and semantic structure. Our findings reveal a correlation between the geometric properties of token embeddings and the cross-entropy loss of next token predictions, implying that prompts with higher loss values have tokens represented in higher-dimensional spaces.', 'abstract_zh': '我们研究了令牌嵌入的几何结构与其在变换器模型中对下一令牌预测作用之间的关系。这一联系的一个重要方面是使用经验测度的概念，该概念编码了令牌点云在变换器层中的分布，并驱动着在均场相互作用图景中令牌表示的演变。我们使用内在维度、邻域重叠和余弦相似度等度量标准来观测性地探究这些经验测度在各层之间的差异。为了验证我们的方法，我们将这些度量标准与一个令牌被打乱的数据集进行比较，这会破坏句法和语义结构。我们的研究结果揭示了令牌嵌入的几何性质与下一令牌预测的交叉熵损失之间的相关性，表明损失值较高的提示具有在高维空间中表示的令牌。', 'title_zh': '大型语言模型内部表示中的令牌几何结构'}
{'arxiv_id': 'arXiv:2501.10487', 'title': 'Tabular-TX: Theme-Explanation Structure-based Table Summarization via In-Context Learning', 'authors': 'TaeYoon Kwack, Jisoo Kim, Ki Yong Jung, DongGeon Lee, Heesun Park', 'link': 'https://arxiv.org/abs/2501.10487', 'abstract': 'This paper proposes a Theme-Explanation Structure-based Table Summarization (Tabular-TX) pipeline designed to efficiently process table data. Tabular-TX preprocesses table data by focusing on highlighted cells and then generates summary sentences structured with a Theme Part in the form of adverbial phrases followed by an Explanation Part in the form of clauses. In this process, customized analysis is performed by considering the structural characteristics and comparability of the table. Additionally, by utilizing In-Context Learning, Tabular-TX optimizes the analytical capabilities of large language models (LLMs) without the need for fine-tuning, effectively handling the structural complexity of table data. Results from applying the proposed Tabular-TX to generate table-based summaries demonstrated superior performance compared to existing fine-tuning-based methods, despite limitations in dataset size. Experimental results confirmed that Tabular-TX can process complex table data more effectively and established it as a new alternative for table-based question answering and summarization tasks, particularly in resource-constrained environments.', 'abstract_zh': '本文提出了一种基于主题解释结构的表格总结（Tabular-TX）流水线，旨在高效处理表格数据。Tabular-TX 首先通过关注高亮的单元格预处理表格数据，然后生成结构化的总结句子，这些句子以副词短语形式的主题部分加上以从句形式的解释部分构成。在这一过程中，通过考虑表格的结构特征和可比性进行定制化分析。此外，Tabular-TX 利用上下文学习优化大型语言模型（LLMs）的分析能力，无需微调即可有效地处理表格数据的结构复杂性。将提出的 Tabular-TX 应用于生成基于表格的总结结果显示，其性能优于现有基于微调的方法，尽管在数据集大小方面存在局限。实验结果证实，Tabular-TX 能更有效地处理复杂表格数据，并且作为一种新替代方案，在资源受限环境中适用于表格数据问答和总结任务。', 'title_zh': 'Tabular-TX：基于主题解释结构的表格总结方法通过上下文学习'}
{'arxiv_id': 'arXiv:2501.10483', 'title': 'ArxEval: Evaluating Retrieval and Generation in Language Models for Scientific Literature', 'authors': 'Aarush Sinha, Viraj Virk, Dipshikha Chakraborty, P.S. Sreeja', 'link': 'https://arxiv.org/abs/2501.10483', 'abstract': 'Language Models [LMs] are now playing an increasingly large role in information generation and synthesis; the representation of scientific knowledge in these systems needs to be highly accurate. A prime challenge is hallucination; that is, generating apparently plausible but actually false information, including invented citations and nonexistent research papers. This kind of inaccuracy is dangerous in all the domains that require high levels of factual correctness, such as academia and education. This work presents a pipeline for evaluating the frequency with which language models hallucinate in generating responses in the scientific literature. We propose ArxEval, an evaluation pipeline with two tasks using ArXiv as a repository: Jumbled Titles and Mixed Titles. Our evaluation includes fifteen widely used language models and provides comparative insights into their reliability in handling scientific literature.', 'abstract_zh': '语言模型[LMs]现在在信息生成和综合中发挥着越来越重要的作用；这些系统中的科学知识表示需要极其准确。主要挑战之一是幻觉现象，即生成看似合理但实际上虚假的信息，包括虚构的引用和不存在的研究论文。这种不准确性在需要高度事实准确性的所有领域都是危险的，例如学术界和教育领域。本研究提出了一种评价框架，用于评估语言模型在生成科学文献回应时产生幻觉的频率。我们提出了ArxEval，一个使用ArXiv作为存储库的评估框架，包括两个任务：杂乱标题和混合标题。我们的评估包括十五种广泛使用的语言模型，并提供了它们在处理科学文献方面的可靠性比较见解。', 'title_zh': 'ArxEval：评估语言模型在科学研究文献中检索与生成的能力'}
{'arxiv_id': 'arXiv:2501.12380', 'title': 'MMVU: Measuring Expert-Level Multi-Discipline Video Understanding', 'authors': 'Yilun Zhao, Lujing Xie, Haowei Zhang, Guo Gan, Yitao Long, Zhiyuan Hu, Tongyan Hu, Weiyuan Chen, Chuhan Li, Junyang Song, Zhijian Xu, Chengye Wang, Weifeng Pan, Ziyao Shangguan, Xiangru Tang, Zhenwen Liang, Yixin Liu, Chen Zhao, Arman Cohan', 'link': 'https://arxiv.org/abs/2501.12380', 'abstract': 'We introduce MMVU, a comprehensive expert-level, multi-discipline benchmark for evaluating foundation models in video understanding. MMVU includes 3,000 expert-annotated questions spanning 27 subjects across four core disciplines: Science, Healthcare, Humanities & Social Sciences, and Engineering. Compared to prior benchmarks, MMVU features three key advancements. First, it challenges models to apply domain-specific knowledge and perform expert-level reasoning to analyze specialized-domain videos, moving beyond the basic visual perception typically assessed in current video benchmarks. Second, each example is annotated by human experts from scratch. We implement strict data quality controls to ensure the high quality of the dataset. Finally, each example is enriched with expert-annotated reasoning rationals and relevant domain knowledge, facilitating in-depth analysis. We conduct an extensive evaluation of 32 frontier multimodal foundation models on MMVU. The latest System-2-capable models, o1 and Gemini 2.0 Flash Thinking, achieve the highest performance among the tested models. However, they still fall short of matching human expertise. Through in-depth error analyses and case studies, we offer actionable insights for future advancements in expert-level, knowledge-intensive video understanding for specialized domains.', 'abstract_zh': '我们引入了MMVU，这是一个全面的专家级多学科基准，用于评估基础模型在视频理解中的性能。MMVU 包含3000个专家标注的问题，覆盖四个核心学科领域的27个主题：科学、医疗保健、人文与社会科学以及工程。与先前的基准相比，MMVU 具有三项关键技术进步。首先，它挑战模型应用特定领域的知识并进行专家级推理来分析专门领域的视频，超越了当前视频基准中通常评估的基本视觉感知。其次，每个示例都由人类专家重新原始标注。我们实施严格的数据质量控制，以确保数据集的质量。最后，每个示例都附带了专家标注的推理依据和相关领域知识，便于深入分析。我们在MMVU上全面评估了32个前沿多模态基础模型。最新具备System-2能力的模型o1和Gemini 2.0 Flash Thinking在测试模型中表现最佳，但仍无法完全匹配人类的专业水平。通过深入的错误分析和案例研究，我们为未来在特定领域专业化的、知识密集型的视频理解方面的专家级进展提供了可操作的建议。', 'title_zh': 'MMVU：衡量跨学科视频理解的专家级标准'}
{'arxiv_id': 'arXiv:2501.12368', 'title': 'InternLM-XComposer2.5-Reward: A Simple Yet Effective Multi-Modal Reward Model', 'authors': 'Yuhang Zang, Xiaoyi Dong, Pan Zhang, Yuhang Cao, Ziyu Liu, Shengyuan Ding, Shenxi Wu, Yubo Ma, Haodong Duan, Wenwei Zhang, Kai Chen, Dahua Lin, Jiaqi Wang', 'link': 'https://arxiv.org/abs/2501.12368', 'abstract': 'Despite the promising performance of Large Vision Language Models (LVLMs) in visual understanding, they occasionally generate incorrect outputs. While reward models (RMs) with reinforcement learning or test-time scaling offer the potential for improving generation quality, a critical gap remains: publicly available multi-modal RMs for LVLMs are scarce, and the implementation details of proprietary models are often unclear. We bridge this gap with InternLM-XComposer2.5-Reward (IXC-2.5-Reward), a simple yet effective multi-modal reward model that aligns LVLMs with human preferences. To ensure the robustness and versatility of IXC-2.5-Reward, we set up a high-quality multi-modal preference corpus spanning text, image, and video inputs across diverse domains, such as instruction following, general understanding, text-rich documents, mathematical reasoning, and video understanding. IXC-2.5-Reward achieves excellent results on the latest multi-modal reward model benchmark and shows competitive performance on text-only reward model benchmarks. We further demonstrate three key applications of IXC-2.5-Reward: (1) Providing a supervisory signal for RL training. We integrate IXC-2.5-Reward with Proximal Policy Optimization (PPO) yields IXC-2.5-Chat, which shows consistent improvements in instruction following and multi-modal open-ended dialogue; (2) Selecting the best response from candidate responses for test-time scaling; and (3) Filtering outlier or noisy samples from existing image and video instruction tuning training data. To ensure reproducibility and facilitate further research, we have open-sourced all model weights and training recipes at this https URL', 'abstract_zh': '尽管大规模视觉语言模型（LVLMs）在视觉理解方面表现出色，但它们偶尔会产生错误的输出。虽然通过强化学习或测试时缩放的方式生成奖励模型（RMs）有可能提高生成的质量，但仍有关键性的差距：公开的多模态奖励模型对LVLMs的支持不足，而且大多数私有模型的具体实现细节也不明确。我们通过InternLM-XComposer2.5-Reward（IXC-2.5-Reward）填补了这一差距，这是一种简单但有效的多模态奖励模型，能够使LVLMs与人类偏好保持一致。为了确保IXC-2.5-Reward的稳健性和灵活性，我们在文本、图像和视频等多个领域建立了高质量的多模态偏好语料库，涵盖指令遵循、通用理解、文本丰富的文档、数学推理和视频理解等不同领域。IXC-2.5-Reward在最新的多模态奖励模型基准测试中取得了优异的成果，并在仅文本的奖励模型基准测试中表现出竞争力。\n\n我们进一步展示了IXC-2.5-Reward的三个关键应用：（1）作为强化学习（RL）训练的监督信号。我们将IXC-2.5-Reward集成到近端策略优化（PPO）中，从而获得IXC-2.5-Chat，它在指令遵循和多模态开放性对话中都表现出一致的改进；（2）从候选回答中选择最佳响应，用于测试时缩放；（3）从现有的图像和视频指令调优训练数据中过滤异常值或噪声样本。\n\n为了确保可复制性并促进进一步的研究，我们已在以下链接开放了所有模型权重和训练食谱：[此链接]。', 'title_zh': 'InternLM-XComposer2.5-奖励：一个简单而有效的多模态奖励模型'}
{'arxiv_id': 'arXiv:2501.12326', 'title': 'UI-TARS: Pioneering Automated GUI Interaction with Native Agents', 'authors': 'Yujia Qin, Yining Ye, Junjie Fang, Haoming Wang, Shihao Liang, Shizuo Tian, Junda Zhang, Jiahao Li, Yunxin Li, Shijue Huang, Wanjun Zhong, Kuanye Li, Jiale Yang, Yu Miao, Woyu Lin, Longxiang Liu, Xu Jiang, Qianli Ma, Jingyu Li, Xiaojun Xiao, Kai Cai, Chuang Li, Yaowei Zheng, Chaolin Jin, Chen Li, Xiao Zhou, Minchao Wang, Haoli Chen, Zhaojian Li, Haihua Yang, Haifeng Liu, Feng Lin, Tao Peng, Xin Liu, Guang Shi', 'link': 'https://arxiv.org/abs/2501.12326', 'abstract': 'This paper introduces UI-TARS, a native GUI agent model that solely perceives the screenshots as input and performs human-like interactions (e.g., keyboard and mouse operations). Unlike prevailing agent frameworks that depend on heavily wrapped commercial models (e.g., GPT-4o) with expert-crafted prompts and workflows, UI-TARS is an end-to-end model that outperforms these sophisticated frameworks. Experiments demonstrate its superior performance: UI-TARS achieves SOTA performance in 10+ GUI agent benchmarks evaluating perception, grounding, and GUI task execution. Notably, in the OSWorld benchmark, UI-TARS achieves scores of 24.6 with 50 steps and 22.7 with 15 steps, outperforming Claude (22.0 and 14.9 respectively). In AndroidWorld, UI-TARS achieves 46.6, surpassing GPT-4o (34.5). UI-TARS incorporates several key innovations: (1) Enhanced Perception: leveraging a large-scale dataset of GUI screenshots for context-aware understanding of UI elements and precise captioning; (2) Unified Action Modeling, which standardizes actions into a unified space across platforms and achieves precise grounding and interaction through large-scale action traces; (3) System-2 Reasoning, which incorporates deliberate reasoning into multi-step decision making, involving multiple reasoning patterns such as task decomposition, reflection thinking, milestone recognition, etc. (4) Iterative Training with Reflective Online Traces, which addresses the data bottleneck by automatically collecting, filtering, and reflectively refining new interaction traces on hundreds of virtual machines. Through iterative training and reflection tuning, UI-TARS continuously learns from its mistakes and adapts to unforeseen situations with minimal human intervention. We also analyze the evolution path of GUI agents to guide the further development of this domain.', 'abstract_zh': '本文介绍了UI-TARS，这是一个原生的GUI代理模型，仅通过屏幕截图作为输入，并执行类人的交互操作（例如键盘和鼠标操作）。与其他依赖于高度封装的商业模型（如GPT-4o）并结合专家设计的提示和流程的代理框架不同，UI-TARS是一个端到端的模型，性能优于这些复杂的框架。实验结果表明了其优越性能：UI-TARS在多个GUI代理基准测试（包括感知、语义对应和GUI任务执行）中达到SOTA水平。特别是在OSWorld基准测试中，使用50步和15步时，UI-TARS分别获得了24.6分和22.7分，优于Claude的22.0分和14.9分；在AndroidWorld中，UI-TARS获得了46.6分，超越了GPT-4o的34.5分。UI-TARS集成了多项关键技术创新：（1）增强的感知能力：利用大规模的GUI屏幕截图数据集，实现上下文感知的UI元素理解和精准标注；（2）统一的动作建模，将跨平台的动作标准化到统一空间，并通过大规模的动作轨迹实现精确的语义对应和交互；（3）系统2推理，将细致推理融入多步决策过程，包括任务分解、反思思考、里程碑识别等多种推理模式；（4）迭代训练与反思性在线轨迹，通过自动收集、筛选和反思性改进数百个虚拟机上的新交互轨迹，解决数据瓶颈问题。通过迭代训练和反思调整，UI-TARS不断从错误中学习，并在最少的人工干预下适应不可预见的情况。此外，我们还分析了GUI代理的发展路径，以指导该领域的进一步发展。', 'title_zh': 'UI-TARS: 以原生代理为引领的自动化GUI交互'}
{'arxiv_id': 'arXiv:2501.12266', 'title': 'CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification', 'authors': 'Cristiano Patrício, Isabel Rio-Torto, Jaime S. Cardoso, Luís F. Teixeira, João C. Neves', 'link': 'https://arxiv.org/abs/2501.12266', 'abstract': 'The main challenges limiting the adoption of deep learning-based solutions in medical workflows are the availability of annotated data and the lack of interpretability of such systems. Concept Bottleneck Models (CBMs) tackle the latter by constraining the final disease prediction on a set of predefined and human-interpretable concepts. However, the increased interpretability achieved through these concept-based explanations implies a higher annotation burden. Moreover, if a new concept needs to be added, the whole system needs to be retrained. Inspired by the remarkable performance shown by Large Vision-Language Models (LVLMs) in few-shot settings, we propose a simple, yet effective, methodology, CBVLM, which tackles both of the aforementioned challenges. First, for each concept, we prompt the LVLM to answer if the concept is present in the input image. Then, we ask the LVLM to classify the image based on the previous concept predictions. Moreover, in both stages, we incorporate a retrieval module responsible for selecting the best examples for in-context learning. By grounding the final diagnosis on the predicted concepts, we ensure explainability, and by leveraging the few-shot capabilities of LVLMs, we drastically lower the annotation cost. We validate our approach with extensive experiments across four medical datasets and twelve LVLMs (both generic and medical) and show that CBVLM consistently outperforms CBMs and task-specific supervised methods without requiring any training and using just a few annotated examples. More information on our project page: this https URL.', 'abstract_zh': '基于深度学习的解决方案在医疗工作流程中的采用受限于标注数据的可用性和此类系统的可解释性不足。概念瓶颈模型（CBMs）通过在预定义的人类可解释概念集上约束最终的疾病预测来应对后者。然而，通过基于概念的解释所获得的增强可解释性意味着更高的标注负担。此外，如果需要添加新的概念，整个系统都需要重新训练。受大型视觉-语言模型（LVLMs）在少样本设置中表现出色的启发，我们提出了一种简单而有效的方法，即CBVLM，以应对上述两个挑战。首先，对于每个概念，我们提示LVLM判断该概念是否存在输入图像中。然后，我们要求LVLM基于先前的概念预测来对图像进行分类。此外，在两个阶段中，我们引入了一个检索模块，负责选择用于情境学习的最佳示例。通过在预测概念的基础上得出最终诊断，我们确保了可解释性，并通过利用LVLM的少样本能力，大幅降低了标注成本。我们通过在四个医学数据集和十二种大型视觉-语言模型（包括通用型和医学型）上进行广泛的实验验证了我们的方法，并展示了在无需训练且仅使用少量标注示例的情况下，CBVLM始终优于CBMs和任务特定的监督方法。更多详细信息请参阅我们的项目页面：[此链接](此 https URL)。', 'title_zh': 'CBVLM：基于概念的无训练解释可追溯性大型视觉语言模型在医学图像分类中的应用'}
{'arxiv_id': 'arXiv:2501.12243', 'title': 'FOCUS: First Order Concentrated Updating Scheme', 'authors': 'Yizhou Liu, Ziming Liu, Jeff Gore', 'link': 'https://arxiv.org/abs/2501.12243', 'abstract': "Large language models (LLMs) demonstrate remarkable performance, and improving their pre-training process appears to be key to enhancing their capabilities further. Based on the documented success of Adam, learning rate decay, and weight decay, we hypothesize that the pre-training loss landscape features a narrowing valley structure. Through experiments with synthetic loss functions, we discover that when gradient query noise is high relative to the valley's sharpness, Adam's performance falls behind that of Signum because Adam reduces the effective step size too drastically. This observation led us to develop FOCUS, an optimizer that enhances Signum by incorporating attraction toward moving averaged parameters, allowing it to handle noise better while maintaining larger step sizes. In training GPT-2, FOCUS proves to be more stable than Signum and faster than Adam. These results suggest that gradient noise may be an underappreciated limiting factor in LLM training, and FOCUS offers promising solutions.", 'abstract_zh': '大语言模型（LLMs）展示了卓越的性能，提高其预训练过程似乎对于进一步增强其能力至关重要。鉴于Adam、学习率衰减和权重衰减在已有文献中的成功应用，我们假设预训练损失场景具有狭窄山谷结构。通过使用合成损失函数进行实验，我们发现当梯度查询噪声相对于山谷的陡峭程度较高时，Adam 的性能落后于Signum，因为Adam 过度降低了实际步骤大小。这一观察促使我们开发了FOCUS优化器，该优化器通过结合吸引移动平均参数的机制改进了Signum，从而在处理噪声方面表现更佳，并能保持更大的步骤大小。在训练GPT-2时，FOCUS在稳定性和速度上都优于Signum。这些结果表明，梯度噪声可能是LLM训练中被低估的限制因素，而FOCUS提供了有前景的解决方案。', 'title_zh': 'FOCUS: 首order集中更新方案'}
{'arxiv_id': 'arXiv:2501.12231', 'title': 'InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large Language Models', 'authors': 'Pha Nguyen, Sailik Sengupta, Girik Malik, Arshit Gupta, Bonan Min', 'link': 'https://arxiv.org/abs/2501.12231', 'abstract': "The improved competence of generative models can help building multi-modal virtual assistants that leverage modalities beyond language. By observing humans performing multi-step tasks, one can build assistants that have situational awareness of actions and tasks being performed, enabling them to cater assistance based on this understanding. In this paper, we develop a Context-aware Instructional Task Assistant with Multi-modal Large Language Models (InsTALL) that leverages an online visual stream (e.g. a user's screen share or video recording) and responds in real-time to user queries related to the task at hand. To enable useful assistance, InsTALL 1) trains a multi-modal model on task videos and paired textual data, and 2) automatically extracts task graph from video data and leverages it at training and inference time. We show InsTALL achieves state-of-the-art performance across proposed sub-tasks considered for multimodal activity understanding -- task recognition (TR), action recognition (AR), next action prediction (AP), and plan prediction (PP) -- and outperforms existing baselines on two novel sub-tasks related to automatic error identification.", 'abstract_zh': '增强生成模型的能力有助于构建多模态虚拟助手，使其能够利用超出语言之外的各种感知模式。通过观察人类执行多步骤任务的过程，可以构建具有情境感知能力的助手，从而根据对这些情境的理解提供相关帮助。在本文中，我们开发了一种基于多模态大规模语言模型的上下文感知指导性任务助手（InsTALL），它利用在线视觉流（例如用户的屏幕共享或视频录制）并能够实时响应与当前任务相关的用户查询。为了提供有用的支持，InsTALL 1) 在任务视频及其配对的文本数据上训练一个多模态模型，2) 自动从视频数据中提取任务图，并在训练和推断时利用该图。我们展示了InsTALL在多模态活动理解的拟议子任务——任务识别（TR）、动作识别（AR）、下一步行动预测（AP）和计划预测（PP）中达到了最先进的性能，并在两个与自动错误识别相关的新型子任务上优于现有基线。', 'title_zh': 'InsTALL：基于多模态大语言模型的上下文感知教学任务辅助技术'}
{'arxiv_id': 'arXiv:2501.12206', 'title': 'Fixing Imbalanced Attention to Mitigate In-Context Hallucination of Large Vision-Language Model', 'authors': 'Kazi Hasan Ibn Arif, Sajib Acharjee Dip, Khizar Hussain, Lang Zhang, Chris Thomas', 'link': 'https://arxiv.org/abs/2501.12206', 'abstract': 'Large Vision Language Models (LVLMs) have demonstrated remarkable capabilities in understanding and describing visual content, achieving state-of-the-art performance across various vision-language tasks. However, these models frequently exhibit hallucination behavior, where they generate descriptions containing objects or details absent in the input image. Our work investigates this phenomenon by analyzing attention patterns across transformer layers and heads, revealing that hallucinations often stem from progressive degradation of visual grounding in deeper layers. We propose a novel attention modification approach that combines selective token emphasis and head-specific modulation to maintain visual grounding throughout the generation process. Our method introduces two key components: (1) a dual-stream token selection mechanism that identifies and prioritizes both locally informative and spatially significant visual tokens, and (2) an attention head-specific modulation strategy that differentially amplifies visual information processing based on measured visual sensitivity of individual attention heads. Through extensive experimentation on the MSCOCO dataset, we demonstrate that our approach reduces hallucination rates by up to 62.3\\% compared to baseline models while maintaining comparable task performance. Our analysis reveals that selectively modulating tokens across attention heads with varying levels of visual sensitivity can significantly improve visual grounding without requiring model retraining.', 'abstract_zh': '大型视觉语言模型（LVLMs）在理解与描述视觉内容方面展现了显著的能力，并在各种视觉语言任务中取得了最先进的性能。然而，这些模型常常表现出幻觉行为，即它们生成的描述包含了输入图像中不存在的对象或细节。我们的研究通过分析Transformer层和头的关注模式，揭示了幻觉行为往往源于更深层中视觉关联的逐步退化。为此，我们提出了一种新颖的关注机制调整方法，该方法结合了选择性token强调与头特定的调整策略，以在整个生成过程中保持视觉关联。我们的方法包含两个关键组成部分：(1) 一种双重流token选择机制，用于识别并优先处理同时具有局部信息性和空间重要性的视觉token；(2) 一种基于各注意头对视觉敏感度的差异性放大视觉信息处理的调整策略。通过在MSCOCO数据集上的广泛实验，我们证明了相比基线模型，我们的方法可以将幻觉率降低高达62.3%，同时保持相当的任务性能。我们的分析表明，在具有不同视觉敏感度的注意头中选择性地调整token能够显著改善视觉关联，而无需重新训练模型。', 'title_zh': '修正不平衡的注意力机制以减轻大尺度vision-language模型的上下文内部幻觉问题'}
{'arxiv_id': 'arXiv:2501.12067', 'title': 'EDoRA: Efficient Weight-Decomposed Low-Rank Adaptation via Singular Value Decomposition', 'authors': 'Hamid Nasiri, Peter Garraghan', 'link': 'https://arxiv.org/abs/2501.12067', 'abstract': 'Parameter-efficient fine-tuning methods, such as LoRA, reduces the number of trainable parameters. However, they often suffer from scalability issues and differences between their learning pattern and full fine-tuning. To overcome these limitations, we propose Efficient Weight-Decomposed Low-Rank Adaptation (EDoRA): a novel PEFT method that decomposes pre-trained weights into magnitude and directional components. By freezing low-rank matrices, initializing them by singular value decomposition, and introducing a small trainable matrix between them, EDoRA achieves substantial reduction in trainable parameters while maintaining learning capacity. Experimental results on the GLUE benchmark demonstrate that EDoRA achieves competitive or superior performance compared to state-of-the-art methods, such as LoRA and DoRA, with up to 30x fewer trainable parameters. This makes EDoRA a highly efficient solution for adapting LLMs to diverse tasks under memory-constrained settings. Code is available at this https URL .', 'abstract_zh': '参数高效微调方法，如LoRA，能够减少可训练参数的数量。然而，它们常常面临可扩展性问题以及学习模式与全面微调之间的差异。为了克服这些限制，我们提出了一种新的PEFT方法——高效权重分解低秩适应(EDoRA)：该方法将预训练权重分解为幅度和方向两个部分。通过冻结低秩矩阵、通过奇异值分解初始化它们，并引入一个小的可训练矩阵连接它们，EDoRA 在大幅减少可训练参数的同时，保持了学习能力。在GLUE基准测试中的实验结果显示，与LoRA和DoRA等最先进的方法相比，EDoRA 在最多可减少30倍的可训练参数的情况下，仍能达到竞争或优越的性能。这使得EDoRA 成为在内存受限环境中适应大型语言模型到多种任务的高效解决方案。代码可在以下地址获取：[该https链接]。', 'title_zh': 'EDoRA：基于奇异值分解的高效权重分解低秩适应方法'}
{'arxiv_id': 'arXiv:2501.11873', 'title': 'Demons in the Detail: On Implementing Load Balancing Loss for Training Specialized Mixture-of-Expert Models', 'authors': 'Zihan Qiu, Zeyu Huang, Bo Zheng, Kaiyue Wen, Zekun Wang, Rui Men, Ivan Titov, Dayiheng Liu, Jingren Zhou, Junyang Lin', 'link': 'https://arxiv.org/abs/2501.11873', 'abstract': 'This paper revisits the implementation of $\\textbf{L}$oad-$\\textbf{b}$alancing $\\textbf{L}$oss (LBL) when training Mixture-of-Experts (MoEs) models. Specifically, LBL for MoEs is defined as $N_E \\sum_{i=1}^{N_E} f_i p_i$, where $N_E$ is the total number of experts, $f_i$ represents the frequency of expert $i$ being selected, and $p_i$ denotes the average gating score of the expert $i$. Existing MoE training frameworks usually employ the parallel training strategy so that $f_i$ and the LBL are calculated within a $\\textbf{micro-batch}$ and then averaged across parallel groups. In essence, a micro-batch for training billion-scale LLMs normally contains very few sequences. So, the micro-batch LBL is almost at the sequence level, and the router is pushed to distribute the token evenly within each sequence. Under this strict constraint, even tokens from a domain-specific sequence ($\\textit{e.g.}$, code) are uniformly routed to all experts, thereby inhibiting expert specialization. In this work, we propose calculating LBL using a $\\textbf{global-batch}$ to loose this constraint. Because a global-batch contains much more diverse sequences than a micro-batch, which will encourage load balance at the corpus level. Specifically, we introduce an extra communication step to synchronize $f_i$ across micro-batches and then use it to calculate the LBL. Through experiments on training MoEs-based LLMs (up to $\\textbf{42.8B}$ total parameters and $\\textbf{400B}$ tokens), we surprisingly find that the global-batch LBL strategy yields excellent performance gains in both pre-training perplexity and downstream tasks. Our analysis reveals that the global-batch LBL also greatly improves the domain specialization of MoE experts.', 'abstract_zh': '本文重新审视了在训练混合专家模型（Mixture-of-Experts, MoEs）时Load-Balancing Loss (LBL) 的实现。具体而言，MoEs 的 LBL 被定义为 \\(N_E \\sum_{i=1}^{N_E} f_i p_i\\)，其中 \\(N_E\\) 是专家的总数，\\(f_i\\) 表示专家 \\(i\\) 被选择的频率，\\(p_i\\) 表示专家 \\(i\\) 的平均门控分数。现有的 MoEs 训练框架通常采用并行训练策略，因此 \\(f_i\\) 和 LBL 在一个微批量中计算，并且在并行组之间进行平均。本质上，用于训练百亿规模的大规模语言模型（LLMs）的微批量通常包含非常少量的序列。所以，微批量的 LBL 几乎是在序列级别上计算的，从而迫使路由器在每个序列内部均匀地分散 token。在这种严格的限制下，即使来自特定领域（例如代码）的序列中的 token 也被均匀地路由到所有专家，从而抑制了专家的专业化程度。本文中，我们提议使用全局批量（global-batch）来计算 LBL，以放松这种约束。因为全局批量包含的序列比微批量多得多且多样，这将鼓励在语料库级别上实现负载均衡。具体而言，我们引入了一步额外的通信步骤，以在微批量之间同步 \\(f_i\\)，然后使用该信息来计算 LBL。通过在最多包含 428 亿参数和 4000 亿个 token 的 MoEs 基础的大规模语言模型（LLMs）的训练实验中，我们惊讶地发现全局批量 LBL 策略在预训练困惑度和下游任务上均取得了出色的性能提升。我们的分析表明，全局批量 LBL 也非常有效地提高了 MoES 专家的专业化水平。', 'title_zh': '细节中的恶魔：实现加载均衡损失以训练专业化混合专家模型的研究'}
{'arxiv_id': 'arXiv:2501.11858', 'title': 'EmbodiedEval: Evaluate Multimodal LLMs as Embodied Agents', 'authors': 'Zhili Cheng, Yuge Tu, Ran Li, Shiqi Dai, Jinyi Hu, Shengding Hu, Jiahao Li, Yang Shi, Tianyu Yu, Weize Chen, Lei Shi, Maosong Sun', 'link': 'https://arxiv.org/abs/2501.11858', 'abstract': 'Multimodal Large Language Models (MLLMs) have shown significant advancements, providing a promising future for embodied agents. Existing benchmarks for evaluating MLLMs primarily utilize static images or videos, limiting assessments to non-interactive scenarios. Meanwhile, existing embodied AI benchmarks are task-specific and not diverse enough, which do not adequately evaluate the embodied capabilities of MLLMs. To address this, we propose EmbodiedEval, a comprehensive and interactive evaluation benchmark for MLLMs with embodied tasks. EmbodiedEval features 328 distinct tasks within 125 varied 3D scenes, each of which is rigorously selected and annotated. It covers a broad spectrum of existing embodied AI tasks with significantly enhanced diversity, all within a unified simulation and evaluation framework tailored for MLLMs. The tasks are organized into five categories: navigation, object interaction, social interaction, attribute question answering, and spatial question answering to assess different capabilities of the agents. We evaluated the state-of-the-art MLLMs on EmbodiedEval and found that they have a significant shortfall compared to human level on embodied tasks. Our analysis demonstrates the limitations of existing MLLMs in embodied capabilities, providing insights for their future development. We open-source all evaluation data and simulation framework at this https URL.', 'abstract_zh': '多模态大型语言模型（MLLMs）在实现重要进展的同时，为 embodied 代理带来了光明的未来。现有的 MLLM 评估基准主要依赖静态图像或视频，这限制了评估范围仅限于非交互式场景。同时，现有的 embodied AI 基准多为特定任务，缺乏多样性，不足以评估 MLLMs 的 embodied 能力。为解决这一问题，我们提出了一种名为 EmbodiedEval 的全面且交互式的评估基准，专为 MLLMs 设计，涵盖 embodied 任务。EmbodiedEval 包含 125 个不同场景中的 328 个独立任务，每个场景都经过严格选择和标注。它涵盖了现有的多种 embodied AI 任务，具备显著增强的多样性，并在为 MLLMs 设计的统一仿真和评估框架中进行了整合。任务被分类为五个类别：导航、对象交互、社会交互、属性问题回答和空间问题回答，以评估代理的不同能力。我们对当前最先进的 MLLMs 进行了评估，并发现它们在 embodied 任务上与人类水平相比存在显著差距。我们的分析揭示了现有 MLLMs 在 embodied 能力方面的局限性，为它们的未来发展方向提供了洞察。我们在以下网址开源了所有评估数据和仿真框架：[提供链接]。', 'title_zh': 'EmbodiedEval：评估多模态大语言模型作为具身代理'}
{'arxiv_id': 'arXiv:2501.11651', 'title': 'Advancing Language Model Reasoning through Reinforcement Learning and Inference Scaling', 'authors': 'Zhenyu Hou, Xin Lv, Rui Lu, Jiajie Zhang, Yujiang Li, Zijun Yao, Juanzi Li, Jie Tang, Yuxiao Dong', 'link': 'https://arxiv.org/abs/2501.11651', 'abstract': "Large language models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks. However, existing approaches mainly rely on imitation learning and struggle to achieve effective test-time scaling. While reinforcement learning (RL) holds promise for enabling self-exploration and learning from feedback, recent attempts yield only modest improvements in complex reasoning. In this paper, we present T1 to scale RL by encouraging exploration and understand inference scaling. We first initialize the LLM using synthesized chain-of-thought data that integrates trial-and-error and self-verification. To scale RL training, we promote increased sampling diversity through oversampling. We further employ an entropy bonus as an auxiliary loss, alongside a dynamic anchor for regularization to facilitate reward optimization. We demonstrate that T1 with open LLMs as its base exhibits inference scaling behavior and achieves superior performance on challenging math reasoning benchmarks. For example, T1 with Qwen2.5-32B as the base model outperforms the recent Qwen QwQ-32B-Preview model on MATH500, AIME2024, and Omni-math-500. More importantly, we present a simple strategy to examine inference scaling, where increased inference budgets directly lead to T1's better performance without any additional verification. We will open-source the T1 models and the data used to train them at \\url{this https URL}.", 'abstract_zh': '大型语言模型（LLMs）在复杂推理任务中展现出了显著的能力。然而，现有的方法主要依赖于模仿学习，在实现有效的测试时扩展方面存在困难。尽管强化学习（RL）有望通过自我探索和从反馈中学习来启用，但最近的尝试在复杂推理任务上仅实现了适度的改进。在本文中，我们提出了一种名为T1的方法，以通过鼓励探索和理解推理扩展来扩展RL。我们首先使用综合了尝试与错误和自我验证的思维链数据来初始化LLM。为了扩大RL训练的规模，我们通过过采样促进更多的采样多样性。进一步地，我们采用熵增益作为辅助损失，并使用动态锚点进行正则化，以促进奖励优化。我们证明，以开源的LLM作为基础的T1模型展示了推理扩展行为，并在挑战性的数学推理基准测试中取得了出色的性能。例如，使用Qwen2.5-32B作为基础模型的T1在MATH500、AIME2024和Omni-math-500测试中优于最近的Qwen QwQ-32B-Preview模型。更重要的是，我们提出了一种简单的策略来检查推理扩展，其中增加推理预算直接导致T1的性能提升，无需额外的验证。我们将公开源代码T1模型及其训练数据，网址为 \\url{this https URL}。', 'title_zh': '通过强化学习和推理缩放提升语言模型推理能力'}
{'arxiv_id': 'arXiv:2501.11599', 'title': 'SR-FoT: A Syllogistic-Reasoning Framework of Thought for Large Language Models Tackling Knowledge-based Reasoning Tasks', 'authors': 'Wentao Wan, Zhuojie Yang, Yongcan Chen, Chenglin Luo, Ruilin Wang, Kehao Cai, Nan Kang, Liang Lin, Keze Wang', 'link': 'https://arxiv.org/abs/2501.11599', 'abstract': 'Deductive reasoning is a crucial logical capability that assists us in solving complex problems based on existing knowledge. Although augmented by Chain-of-Thought prompts, Large Language Models (LLMs) might not follow the correct reasoning paths. Enhancing the deductive reasoning abilities of LLMs, and leveraging their extensive built-in knowledge for various reasoning tasks, remains an open question. Attempting to mimic the human deductive reasoning paradigm, we propose a multi-stage Syllogistic-Reasoning Framework of Thought (SR-FoT) that enables LLMs to perform syllogistic deductive reasoning to handle complex knowledge-based reasoning tasks. Our SR-FoT begins by interpreting the question and then uses the interpretation and the original question to propose a suitable major premise. It proceeds by generating and answering minor premise questions in two stages to match the minor premises. Finally, it guides LLMs to use the previously generated major and minor premises to perform syllogistic deductive reasoning to derive the answer to the original question. Extensive and thorough experiments on knowledge-based reasoning tasks have demonstrated the effectiveness and advantages of our SR-FoT.', 'abstract_zh': '演绎推理是一种重要的逻辑能力，有助于我们基于现有知识解决复杂问题。尽管通过应用Chain-of-Thought提示，大规模语言模型（LLMs）仍可能不遵循正确的推理路径。增强LLMs的演绎推理能力，并利用其广泛的内置知识来完成各种推理任务，仍然是一个开放的问题。为模仿人类的演绎推理模式，我们提出了一种多阶段的三段论推理思维框架（SR-FoT），使LLMs能够进行三段论演绎推理以处理复杂的基于知识的推理任务。我们的SR-FoT首先解释问题，然后根据解释和原始问题提出一个合适的主前提。接着通过两个阶段生成并回答次要前提问题以匹配次要前提。最后，它引导LLMs使用之前生成的主前提和次要前提进行三段论演绎推理以得出原始问题的答案。在基于知识的推理任务上的广泛而详尽的实验表明，我们的SR-FoT的有效性和优势。', 'title_zh': 'SR-FoT：大型语言模型处理基于知识推理任务的三段论推理框架'}
{'arxiv_id': 'arXiv:2501.11592', 'title': 'Training-free Ultra Small Model for Universal Sparse Reconstruction in Compressed Sensing', 'authors': 'Chaoqing Tang, Huanze Zhuang, Guiyun Tian, Zhenli Zeng, Yi Ding, Wenzhong Liu, Xiang Bai', 'link': 'https://arxiv.org/abs/2501.11592', 'abstract': 'Pre-trained large models attract widespread attention in recent years, but they face challenges in applications that require high interpretability or have limited resources, such as physical sensing, medical imaging, and bioinformatics. Compressed Sensing (CS) is a well-proved theory that drives many recent breakthroughs in these applications. However, as a typical under-determined linear system, CS suffers from excessively long sparse reconstruction times when using traditional iterative methods, particularly with large-scale data. Current AI methods like deep unfolding fail to substitute them because pre-trained models exhibit poor generality beyond their training conditions and dataset distributions, or lack interpretability. Instead of following the big model fervor, this paper proposes ultra-small artificial neural models called coefficients learning (CL), enabling training-free and rapid sparse reconstruction while perfectly inheriting the generality and interpretability of traditional iterative methods, bringing new feature of incorporating prior knowledges. In CL, a signal of length $n$ only needs a minimal of $n$ trainable parameters. A case study model called CLOMP is implemented for evaluation. Experiments are conducted on both synthetic and real one-dimensional and two-dimensional signals, demonstrating significant improvements in efficiency and accuracy. Compared to representative iterative methods, CLOMP improves efficiency by 100 to 1000 folds for large-scale data. Test results on eight diverse image datasets indicate that CLOMP improves structural similarity index by 292%, 98%, 45% for sampling rates of 0.1, 0.3, 0.5, respectively. We believe this method can truly usher CS reconstruction into the AI era, benefiting countless under-determined linear systems that rely on sparse solution.', 'abstract_zh': '近年来，预训练大型模型吸引了广泛的关注，但在需要高可解释性或资源受限的应用中，如物理传感、医学成像和生物信息学，它们面临挑战。压缩感知（Compressed Sensing, CS）是一个经过验证的理论，在这些应用中推动了许多近期的突破。然而，作为典型的欠定线性系统，CS在使用传统迭代方法时，特别是在大规模数据下，会出现过度漫长稀疏重构时间的问题。当前的人工智能方法如深度展开在这一领域也无法替代，因为预训练模型在超越其训练条件和数据集分布的情况下表现不佳，或者缺乏可解释性。相反，本文不追随大型模型的热潮，提出了一种超小型人工神经网络方法，称为系数学习（Coefficient Learning, CL），能够在不进行训练的情况下实现快速稀疏重构，同时完美地继承传统迭代方法的泛化能力和可解释性，并引入先验知识融合的新特性。在CL方法中，长度为 \\(n\\) 的信号只需要最少 \\(n\\) 个可训练参数。研究模型CLOMP被用于评估。实验在合成和真实的一维和二维信号上进行，展示了显著提高的效率和准确性。与代表性的迭代方法相比，CLOMP在大规模数据下的效率提高了100到1000倍。针对八个不同图像数据集的测试结果表明，CLOMP分别在抽样率为0.1、0.3、0.5时，结构相似性指标提高了292%、98%、45%。我们认为，这种方法有望真正将CS重构带入人工智能时代，为依赖稀疏解的无数欠定线性系统带来益处。', 'title_zh': '无需训练的超小型模型：压缩感知中通用稀疏重构应用'}
{'arxiv_id': 'arXiv:2501.11498', 'title': 'Dialect2SQL: A Novel Text-to-SQL Dataset for Arabic Dialects with a Focus on Moroccan Darija', 'authors': 'Salmane Chafik, Saad Ezzini, Ismail Berrada', 'link': 'https://arxiv.org/abs/2501.11498', 'abstract': 'The task of converting natural language questions (NLQs) into executable SQL queries, known as text-to-SQL, has gained significant interest in recent years, as it enables non-technical users to interact with relational databases. Many benchmarks, such as SPIDER and WikiSQL, have contributed to the development of new models and the evaluation of their performance. In addition, other datasets, like SEDE and BIRD, have introduced more challenges and complexities to better map real-world scenarios. However, these datasets primarily focus on high-resource languages such as English and Chinese. In this work, we introduce Dialect2SQL, the first large-scale, cross-domain text-to-SQL dataset in an Arabic dialect. It consists of 9,428 NLQ-SQL pairs across 69 databases in various domains. Along with SQL-related challenges such as long schemas, dirty values, and complex queries, our dataset also incorporates the complexities of the Moroccan dialect, which is known for its diverse source languages, numerous borrowed words, and unique expressions. This demonstrates that our dataset will be a valuable contribution to both the text-to-SQL community and the development of resources for low-resource languages.', 'abstract_zh': '将自然语言问题（NLQ）转换为可执行的SQL查询的任务，即文本到SQL（text-to-SQL）的任务，在近年来受到了广泛关注。这是因为该任务使得非技术人员能够与关系数据库进行交互。许多基准数据集，如SPIDER和WikiSQL，为新模型的发展及其性能评估做出了重要贡献。此外，其他数据集，如SEDE和BIRD，引入了更多的挑战和复杂性，以更好地映射现实世界的场景。然而，这些数据集主要关注资源丰富语言，如英语和汉语。在本工作中，我们介绍了Dialect2SQL，这是第一个大规模的跨域阿拉伯方言文本到SQL数据集。该数据集包含跨69个不同领域数据库的9,428个NLQ-SQL配对。除了SQL相关的挑战，如长模式、脏值和复杂查询外，我们的数据集还包含了摩洛哥方言的复杂性，这种方言以其多样的语言来源、众多的借词和独特的表达方式为特点。这表明我们的数据集将是文本到SQL社区以及低资源语言资源开发的重要贡献。', 'title_zh': 'Dialect2SQL：针对摩洛哥德里贾方言的新型文本到SQL数据集'}
{'arxiv_id': 'arXiv:2501.11441', 'title': 'Ontology Matching with Large Language Models and Prioritized Depth-First Search', 'authors': 'Maria Taboada, Diego Martinez, Mohammed Arideh, Rosa Mosquera', 'link': 'https://arxiv.org/abs/2501.11441', 'abstract': 'Ontology matching (OM) plays a key role in enabling data interoperability and knowledge sharing, but it remains challenging due to the need for large training datasets and limited vocabulary processing in machine learning approaches. Recently, methods based on Large Language Model (LLMs) have shown great promise in OM, particularly through the use of a retrieve-then-prompt pipeline. In this approach, relevant target entities are first retrieved and then used to prompt the LLM to predict the final matches. Despite their potential, these systems still present limited performance and high computational overhead. To address these issues, we introduce MILA, a novel approach that embeds a retrieve-identify-prompt pipeline within a prioritized depth-first search (PDFS) strategy. This approach efficiently identifies a large number of semantic correspondences with high accuracy, limiting LLM requests to only the most borderline cases. We evaluated MILA using the biomedical challenge proposed in the 2023 and 2024 editions of the Ontology Alignment Evaluation Initiative. Our method achieved the highest F-Measure in four of the five unsupervised tasks, outperforming state-of-the-art OM systems by up to 17%. It also performed better than or comparable to the leading supervised OM systems. MILA further exhibited task-agnostic performance, remaining stable across all tasks and settings, while significantly reducing LLM requests. These findings highlight that high-performance LLM-based OM can be achieved through a combination of programmed (PDFS), learned (embedding vectors), and prompting-based heuristics, without the need of domain-specific heuristics or fine-tuning.', 'abstract_zh': '本研究内容或标题的中文翻译如下，符合学术规范：\n\n本研究探索了知识本体匹配（OM）在实现数据互操作性和知识共享中发挥的关键作用，但由于机器学习方法需要大量训练数据和有限的词汇处理能力，这一过程依然面临挑战。最近，基于大型语言模型（LLMs）的方法在OM方面展现出了极大的潜力，特别是在通过检索-提示管道的方法中。在该方法中，首先检索相关的目标实体，然后使用这些实体来提示LLMs进行最终匹配预测。尽管这些方法具有很大的潜力，但它们仍然存在性能有限和计算开销高的问题。为了解决这些问题，我们提出了一个名为MILA的新颖方法，将检索-识别-提示管道嵌入优先深度优先搜索（PDFS）策略中。该方法能够高效地识别大量高精度的语义对应关系，仅在最边缘的情况下才触发LLMs的请求。我们使用2023年和2024年的本体对齐评估倡议（Ontology Alignment Evaluation Initiative, OAEI）提出的生物医学挑战任务来评估MILA。我们的方法在四个未监督任务中均获得了最高的F-测度，比最先进的OM系统高出17%，并且在性能上优于或接近领先的监督OM系统。此外，MILA还表现出任务无关性，在所有任务和设置中保持稳定，同时显著减少了对LLMs的请求次数。这些研究结果强调，通过结合编程（PDFS）、学习（嵌入向量）和提示的启发式方法，可以在不依赖特定领域启发式方法或微调的情况下实现高性能的LLM驱动OM。\n\n关键词：知识本体匹配（OM）、大型语言模型（LLMs）、检索-提示管道、优先深度优先搜索（PDFS）、F-测度、本体对齐评估倡议（OAEI）、生物医学挑战任务。', 'title_zh': '使用大规模语言模型和优先深度优先搜索的本体匹配'}
{'arxiv_id': 'arXiv:2501.11284', 'title': 'RedStar: Does Scaling Long-CoT Data Unlock Better Slow-Reasoning Systems?', 'authors': 'Haotian Xu, Xing Wu, Weinong Wang, Zhongzhi Li, Da Zheng, Boyuan Chen, Yi Hu, Shijia Kang, Jiaming Ji, Yingying Zhang, Zhijiang Guo, Yaodong Yang, Muhan Zhang, Debing Zhang', 'link': 'https://arxiv.org/abs/2501.11284', 'abstract': 'Can scaling transform reasoning? In this work, we explore the untapped potential of scaling Long Chain-of-Thought (Long-CoT) data to 1000k samples, pioneering the development of a slow-thinking model, RedStar. Through extensive experiments with various LLMs and different sizes, we uncover the ingredients for specialization and scale for Long-CoT training. Surprisingly, even smaller models show significant performance gains with limited data, revealing the sample efficiency of Long-CoT and the critical role of sample difficulty in the learning process. Our findings demonstrate that Long-CoT reasoning can be effectively triggered with just a few thousand examples, while larger models achieve unparalleled improvements. We also introduce reinforcement learning (RL)-scale training as a promising direction for advancing slow-thinking systems. RedStar shines across domains: on the MATH-Hard benchmark, RedStar-code-math boosts performance from 66.2\\% to 81.6\\%, and on the USA Math Olympiad (AIME), it solves 46.7\\% of problems using only 21k mixed-code-math datasets. In multimodal tasks like GeoQA and MathVista-GEO, RedStar-Geo achieves competitive results with minimal Long-CoT data, outperforming other slow-thinking systems like QvQ-Preview. Compared to QwQ, RedStar strikes the perfect balance between reasoning and generalizability. Our work highlights that, with careful tuning, scaling Long-CoT can unlock extraordinary reasoning capabilities-even with limited dataset and set a new standard for slow-thinking models across diverse challenges. Our data and models are released at this https URL.', 'abstract_zh': 'scaling能否提升推理能力？在本文中，我们探讨了将长链推理（Long Chain-of-Thought, Long-CoT）数据扩展到百万规模的未充分利用潜能，开创了慢思考模型RedStar的发展。通过各种大型语言模型和不同规模的广泛实验，我们揭示了Long-CoT训练的专业化和规模要素。令人惊讶的是，即使是较小的模型也能在有限的数据下表现出明显的性能提升，揭示了Long-CoT的样本效率以及样本难度在学习过程中的关键作用。我们的研究结果表明，仅数千个示例就能有效触发Long-CoT推理，而更大的模型则实现了前所未有的改进。我们还介绍了强化学习（RL）规模训练作为提升慢思考系统的有前景方向。RedStar在多个领域表现出色：在MATH-Hard基准测试中，RedStar-code-math的性能从66.2%提升到81.6%，在USA数学奥林匹克（AIME）中，它仅使用21,000个混合代码-数学数据集解决了问题的46.7%。在多元任务如GeoQA和MathVista-GEO中，RedStar-Geo在少量Long-CoT数据的支持下取得了与其它慢思考系统如QvQ-Preview竞争的结果，且表现更优。与QwQ相比，RedStar在推理和泛化能力之间达到了完美的平衡。我们的研究突显了，在适当调整下，扩展Long-CoT可以解锁非凡的推理能力，即使在有限的数据集下也能树立新的慢思考模型标准，适用于各种挑战。我们已在此处发布了数据和模型：[链接]。', 'title_zh': 'RedStar：扩展长链思考数据能否解锁更优的慢推理系统？'}
{'arxiv_id': 'arXiv:2501.11264', 'title': 'Code Readability in the Age of Large Language Models: An Industrial Case Study from Atlassian', 'authors': 'Wannita Takerngsaksiri, Micheal Fu, Chakkrit Tantithamthavorn, Jirat Pasuksmit, Kun Chen, Ming Wu', 'link': 'https://arxiv.org/abs/2501.11264', 'abstract': "Programmers spend a significant amount of time reading code during the software development process. This trend is amplified by the emergence of large language models (LLMs) that automatically generate code. However, little is known about the readability of the LLM-generated code and whether it is still important from practitioners' perspectives in this new era. In this paper, we conduct a survey to explore the practitioners' perspectives on code readability in the age of LLMs and investigate the readability of our LLM-based software development agents framework, HULA, by comparing its generated code with human-written code in real-world scenarios. Overall, the findings underscore that (1) readability remains a critical aspect of software development; (2) the readability of our LLM-generated code is comparable to human-written code, fostering the establishment of appropriate trust and driving the broad adoption of our LLM-powered software development platform.", 'abstract_zh': '在软件开发过程中，程序员花费了大量时间阅读代码。随着大型语言模型（LLMs）的出现，这种趋势被进一步放大，这些模型能够自动生成代码。然而，对于LLM生成代码的可读性以及在这一新时代中其重要性（从业务分析师的角度来看）了解甚少。本文通过一项调查来探讨在LLM时代从业者对代码可读性的看法，并通过将我们的LLM驱动的软件开发代理框架HULA生成的代码与实际场景中的人类编写的代码进行比较，来研究HULA的可读性。总体而言，研究发现强调了以下几点：（1）代码的可读性仍然是软件开发中的关键方面；（2）我们的LLM生成代码的可读性与人类编写的代码相当，这有助于建立适当的信任，并促进我们的LLM驱动的软件开发平台的广泛应用。', 'title_zh': '在大型语言模型时代下的代码可读性：来自Atlassian的工业案例研究'}
{'arxiv_id': 'arXiv:2501.11233', 'title': 'PlotEdit: Natural Language-Driven Accessible Chart Editing in PDFs via Multimodal LLM Agents', 'authors': 'Kanika Goswami, Puneet Mathur, Ryan Rossi, Franck Dernoncourt', 'link': 'https://arxiv.org/abs/2501.11233', 'abstract': 'Chart visualizations, while essential for data interpretation and communication, are predominantly accessible only as images in PDFs, lacking source data tables and stylistic information. To enable effective editing of charts in PDFs or digital scans, we present PlotEdit, a novel multi-agent framework for natural language-driven end-to-end chart image editing via self-reflective LLM agents. PlotEdit orchestrates five LLM agents: (1) Chart2Table for data table extraction, (2) Chart2Vision for style attribute identification, (3) Chart2Code for retrieving rendering code, (4) Instruction Decomposition Agent for parsing user requests into executable steps, and (5) Multimodal Editing Agent for implementing nuanced chart component modifications - all coordinated through multimodal feedback to maintain visual fidelity. PlotEdit outperforms existing baselines on the ChartCraft dataset across style, layout, format, and data-centric edits, enhancing accessibility for visually challenged users and improving novice productivity.', 'abstract_zh': '图表可视化虽然对于数据解释和传达至关重要，但在大多数情况下仅作为PDF中的图像存在，缺乏原始数据表和风格信息。为了使图表在PDF或数字扫描中的有效编辑成为可能，我们提出了PlotEdit，这是一种新颖的多代理框架，利用自省语言模型代理实现自然语言驱动的端到端图表图像编辑。PlotEdit协调了五个语言模型代理：（1）Chart2Table，用于提取数据表；（2）Chart2Vision，用于识别样式属性；（3）Chart2Code，用于检索渲染代码；（4）指令分解代理，用于将用户请求解析为可执行步骤；以及（5）多模态编辑代理，用于实现细腻的图表组件修改——所有这一切都通过多模态反馈来协调，以保持视觉保真度。在ChartCraft数据集上，PlotEdit在风格、布局、格式和数据导向编辑方面优于现有基线，提升了视觉障碍用户的可访问性，并改善了新手的生产力。', 'title_zh': 'PlotEdit: 通过多模态大语言模型代理实现的基于自然语言的PDF图表编辑'}
{'arxiv_id': 'arXiv:2501.11223', 'title': 'Reasoning Language Models: A Blueprint', 'authors': 'Maciej Besta, Julia Barth, Eric Schreiber, Ales Kubicek, Afonso Catarino, Robert Gerstenberger, Piotr Nyczyk, Patrick Iff, Yueling Li, Sam Houliston, Tomasz Sternal, Marcin Copik, Grzegorz Kwaśniewski, Jürgen Müller, Łukasz Flis, Hannes Eberhard, Hubert Niewiadomski, Torsten Hoefler', 'link': 'https://arxiv.org/abs/2501.11223', 'abstract': 'Reasoning language models (RLMs), also known as Large Reasoning Models (LRMs), such as OpenAI\'s o1 and o3, DeepSeek-V3, and Alibaba\'s QwQ, have redefined AI\'s problem-solving capabilities by extending large language models (LLMs) with advanced reasoning mechanisms. Yet, their high costs, proprietary nature, and complex architectures - uniquely combining Reinforcement Learning (RL), search heuristics, and LLMs - present accessibility and scalability challenges. To address these, we propose a comprehensive blueprint that organizes RLM components into a modular framework, based on a survey and analysis of all RLM works. This blueprint incorporates diverse reasoning structures (chains, trees, graphs, and nested forms), reasoning strategies (e.g., Monte Carlo Tree Search, Beam Search), RL concepts (policy, value models and others), and supervision schemes (Output-Based and Process-Based Supervision). We also provide detailed mathematical formulations and algorithmic specifications to simplify RLM implementation. By showing how schemes like LLaMA-Berry, QwQ, Journey Learning, and Graph of Thoughts fit as special cases, we demonstrate the blueprint\'s versatility and unifying potential. To illustrate its utility, we introduce x1, a modular implementation for rapid RLM prototyping and experimentation. Using x1 and a literature review, we provide key insights, such as multi-phase training for policy and value models, and the importance of familiar training distributions. Finally, we outline how RLMs can integrate with a broader LLM ecosystem, including tools and databases. Our work demystifies RLM construction, democratizes advanced reasoning capabilities, and fosters innovation, aiming to mitigate the gap between "rich AI" and "poor AI" by lowering barriers to RLM development and experimentation.', 'abstract_zh': '推理语言模型（Reasoning Language Models, RLMs），也被称为大型推理模型（Large Reasoning Models, LRMs），如OpenAI的o1和o3、DeepSeek-V3以及阿里巴巴的QwQ，通过对大型语言模型（Large Language Models, LLMs）进行扩展，并引入高级推理机制，重新定义了AI的问题解决能力。然而，这些模型的高成本、专有性质以及复杂架构——它们的独特结合包括强化学习（Reinforcement Learning, RL）、搜索启发式方法以及LLMs——也带来了可访问性和扩展性的挑战。为了解决这些问题，我们提出了一个全面的蓝图，该蓝图基于对所有RLM工作的问卷调查和分析，将RLM组件组织成模块化的框架。该蓝图融入了多样化的推理结构（链、树、图及嵌套形式）、推理策略（如蒙特卡洛树搜索、束搜索）、强化学习概念（策略模型、价值模型及其他概念），以及监督方案（输出基础监督、过程基础监督）。我们还提供了详细的数学公式和算法规范，以简化RLM的实施。通过展示LLaMA-Berry、QwQ、旅程学习和思绪图等方案如何作为特殊案例符合这一蓝图，我们展示了该蓝图的灵活性和统一潜力。为了说明其实用价值，我们介绍了x1这一模块化实现，用于快速进行RLM的原型设计和实验。利用x1和文献综述，我们提供了一些关键见解，如策略模型和价值模型的多阶段训练，以及熟悉训练分布的重要性。最后，我们概述了RLM如何整合到更广泛的LLM生态系统中，包括工具和数据库。我们的工作揭开了RLM构建的面纱，使先进的推理能力更加普及，并促进创新，旨在通过降低RLM开发和实验的门槛，缩小“富裕AI”与“贫困AI”之间的差距。', 'title_zh': '语言模型的推理原理：一个框架'}
{'arxiv_id': 'arXiv:2501.11107', 'title': 'ChaosEater: Fully Automating Chaos Engineering with Large Language Models', 'authors': 'Daisuke Kikuta, Hiroki Ikeuchi, Kengo Tajiri, Yuusuke Nakano', 'link': 'https://arxiv.org/abs/2501.11107', 'abstract': "Chaos Engineering (CE) is an engineering technique aimed at improving the resiliency of distributed systems. It involves artificially injecting specific failures into a distributed system and observing its behavior in response. Based on the observation, the system can be proactively improved to handle those failures. Recent CE tools realize the automated execution of predefined CE experiments. However, defining these experiments and reconfiguring the system after the experiments still remain manual. To reduce the costs of the manual operations, we propose \\textsc{ChaosEater}, a \\textit{system} for automating the entire CE operations with Large Language Models (LLMs). It pre-defines the general flow according to the systematic CE cycle and assigns subdivided operations within the flow to LLMs. We assume systems based on Infrastructure as Code (IaC), wherein the system configurations and artificial failures are managed through code. Hence, the LLMs' operations in our \\textit{system} correspond to software engineering tasks, including requirement definition, code generation and debugging, and testing. We validate our \\textit{system} through case studies on both small and large systems. The results demonstrate that our \\textit{system} significantly reduces both time and monetary costs while completing reasonable single CE cycles.", 'abstract_zh': '混沌工程（CE）是一种旨在提高分布式系统韧性的工程方法。它涉及人为地向分布式系统中注入特定的故障，并观察其响应行为。基于观察结果，系统可以在故障发生前主动改进以处理这些故障。近期的CE工具实现了预定义的CE实验的自动化执行。然而，定义这些实验和实验后的系统重新配置仍然需要手动操作。为了减少手动操作的成本，我们提出了一种名为**ChaosEater**的系统，该系统利用大型语言模型（LLMs）来自动化整个CE操作。该系统根据系统性的CE周期预定义了总体流程，并将流程中的细分为LLMs的任务。我们假设基于基础设施即代码（IaC）的系统，其中系统的配置和人为故障都是通过代码进行管理。因此，我们系统中的LLMs操作对应于软件工程任务，包括需求定义、代码生成、调试和测试。通过对小型和大型系统进行了案例研究，我们验证了该系统的有效性。结果表明，该系统在完成合理的单一CE周期时，显著减少了时间和金钱成本。', 'title_zh': 'ChaosEater：使用大型语言模型完全自动进行混沌工程'}
{'arxiv_id': 'arXiv:2501.11031', 'title': 'AdaptiveLog: An Adaptive Log Analysis Framework with the Collaboration of Large and Small Language Model', 'authors': 'Lipeng Ma, Weidong Yang, Yixuan Li, Ben Fei, Mingjie Zhou, Shuhao Li, Sihang Jiang, Bo Xu, Yanghua Xiao', 'link': 'https://arxiv.org/abs/2501.11031', 'abstract': 'Automated log analysis is crucial to ensure high availability and reliability of complex systems. The advent of LLMs in NLP has ushered in a new era of language model-driven automated log analysis, garnering significant interest. Within this field, two primary paradigms based on language models for log analysis have become prominent. Small Language Models (SLMs) follow the pre-train and fine-tune paradigm, focusing on the specific log analysis task through fine-tuning on supervised datasets. On the other hand, LLMs following the in-context learning paradigm, analyze logs by providing a few examples in prompt contexts without updating parameters. Despite their respective strengths, we notice that SLMs are more cost-effective but less powerful, whereas LLMs with large parameters are highly powerful but expensive and inefficient. To trade-off between the performance and inference costs of both models in automated log analysis, this paper introduces an adaptive log analysis framework known as AdaptiveLog, which effectively reduces the costs associated with LLM while ensuring superior results. This framework collaborates an LLM and a small language model, strategically allocating the LLM to tackle complex logs while delegating simpler logs to the SLM. Specifically, to efficiently query the LLM, we propose an adaptive selection strategy based on the uncertainty estimation of the SLM, where the LLM is invoked only when the SLM is uncertain. In addition, to enhance the reasoning ability of the LLM in log analysis tasks, we propose a novel prompt strategy by retrieving similar error-prone cases as the reference, enabling the model to leverage past error experiences and learn solutions from these cases. Extensive experiments demonstrate that AdaptiveLog achieves state-of-the-art results across different tasks, elevating the overall accuracy of log analysis while maintaining cost efficiency.', 'abstract_zh': '自动化日志分析对于确保复杂系统的高可用性和可靠性至关重要。自然语言处理（NLP）中的大型语言模型（LLM）的出现，使基于语言模型的自动化日志分析进入了一个新的时代，引起了广泛的关注。在这个领域中，基于语言模型的日志分析出现了两种主要范式。小型语言模型（SLM）遵循预训练和微调的范式，通过在监督数据集上进行微调专注于特定的日志分析任务。另一方面，采用上下文学习范式的LLM则通过在提示中提供少量示例进行分析，而不更新参数。尽管这两种模型各有优势，但我们可以观察到，SLM更具成本效益但能力较弱，而具有大量参数的LLM则非常强大但成本高昂且效率低下。为了在自动化日志分析中平衡这两种模型的性能和推理成本，本文介绍了一个适应性日志分析框架，称为AdaptiveLog，它有效降低了LLM的相关成本，同时确保了优越的结果。该框架结合了LLM和小型语言模型，战略性地分配任务，让LLM处理复杂日志，而将简单日志交给SLM。具体来说，为了高效查询LLM，我们提出了一种基于SLM不确定性估计的自适应选择策略，在SLM不确定时才调用LLM。此外，为了增强LLM在日志分析任务中的推理能力，我们提出了一种新的提示策略，通过检索类似错误案例作为参考，使模型能够利用过去的错误经验并从这些案例中学习解决方案。大量的实验表明，AdaptiveLog实现了在不同任务上的最先进的结果，提高了日志分析的整体准确性，同时维持了成本效益。', 'title_zh': 'AdaptiveLog：一种结合大规模和小规模语言模型的合作日志分析框架'}
{'arxiv_id': 'arXiv:2501.10969', 'title': 'AI Based Font Pair Suggestion Modelling For Graphic Design', 'authors': 'Aryan Singh, Sumithra Bhakthavatsalam', 'link': 'https://arxiv.org/abs/2501.10969', 'abstract': 'One of the key challenges of AI generated designs in Microsoft Designer is selecting the most contextually relevant and novel fonts for the design suggestions. Previous efforts involved manually mapping design intent to fonts. Though this was high quality, this method does not scale for a large number of fonts (3000+) and numerous user intents for graphic design. In this work we create font visual embeddings, a font stroke width algorithm, a font category to font mapping dataset, an LLM-based category utilization description and a lightweight, low latency knowledge-distilled mini language model (Mini LM V2) to recommend multiple pairs of contextual heading and subheading fonts for beautiful and intuitive designs. We also utilize a weighted scoring mechanism, nearest neighbor approach and stratified sampling to rank the font pairs and bring novelty to the predictions.', 'abstract_zh': '在Microsoft Designer中，AI生成设计面临的一个关键挑战是选择最相关且新颖的字体以供设计建议。以往的努力主要依赖手动将设计意图与字体进行配对。尽管这种方法质量很高，但这种方法对于数量众多的字体（超过3000种）和多样化的用户图形设计意图来说并不具有扩展性。在本项工作当中，我们构建了字体视觉嵌入、字体笔画宽度算法、字体类别到字体映射数据集、基于LLM的类别利用描述，并开发了一个轻量级、低延迟的知识蒸馏迷你语言模型（Mini LM V2），用于推荐多种情境标题和副标题字体对，以实现美观且直观的设计。此外，我们还利用加权评分机制、最近邻方法和分层抽样来对字体对进行排名，并增加预测的创新性。', 'title_zh': '基于AI的字体配对建议建模在图形设计中的应用'}
{'arxiv_id': 'arXiv:2501.10967', 'title': 'Advancing General Multimodal Capability of Vision-language Models with Pyramid-descent Visual Position Encoding', 'authors': 'Zhanpeng Chen, Mingxiao Li, Ziyang Chen, Nan Du, Xiaolong Li, Yuexian Zou', 'link': 'https://arxiv.org/abs/2501.10967', 'abstract': "Vision-language Models (VLMs) have shown remarkable capabilities in advancing general artificial intelligence, yet the irrational encoding of visual positions persists in inhibiting the models' comprehensive perception performance across different levels of granularity. In this work, we propose Pyramid-descent Visual Position Encoding (PyPE), a novel approach designed to enhance the perception of visual tokens within VLMs. By assigning visual position indexes from the periphery to the center and expanding the central receptive field incrementally, PyPE addresses the limitations of traditional raster-scan methods and mitigates the long-term decay effects induced by Rotary Position Embedding (RoPE). Our method reduces the relative distance between interrelated visual elements and instruction tokens, promoting a more rational allocation of attention weights and allowing for a multi-granularity perception of visual elements and countering the over-reliance on anchor tokens. Extensive experimental evaluations demonstrate that PyPE consistently improves the general capabilities of VLMs across various sizes. Code is available at this https URL.", 'abstract_zh': '视觉-语言模型（VLMs）在推动通用人工智能方面展现了显著的能力，但视觉位置的不合理编码仍然限制了模型在不同粒度级别上的综合感知性能。本文提出了一种名为Pyramid-descent Visual Position Encoding（PyPE）的新颖方法，旨在增强VLMs对视觉标记的感知。通过从边缘向中心分配视觉位置索引，并逐步扩展中心的感受野，PyPE 解决了传统平铺扫描方法的局限性，减轻了由旋转位置嵌入（RoPE）引起的长期衰减效应。该方法减少了相关视觉元素与指令标记之间的相对距离，促进更合理的注意力权重分配，并允许多粒度的视觉元素感知，从而减少对锚标记的过度依赖。广泛的实验评估表明，PyPE 在不同规模的VLMs中一致地提高了其通用能力。代码可在以下链接获取：this https URL。', 'title_zh': '通过金字塔下降视觉位置编码提升视知觉语言模型的通用多模态能力'}
{'arxiv_id': 'arXiv:2501.10913', 'title': 'Know "No" Better: A Data-Driven Approach for Enhancing Negation Awareness in CLIP', 'authors': 'Junsung Park, Jungbeom Lee, Jongyoon Song, Sangwon Yu, Dahuin Jung, Sungroh Yoon', 'link': 'https://arxiv.org/abs/2501.10913', 'abstract': 'While CLIP has significantly advanced multimodal understanding by bridging vision and language, the inability to grasp negation - such as failing to differentiate concepts like "parking" from "no parking" - poses substantial challenges. By analyzing the data used in the public CLIP model\'s pre-training, we posit this limitation stems from a lack of negation-inclusive data. To address this, we introduce data generation pipelines that employ a large language model (LLM) and a multimodal LLM to produce negation-inclusive captions. Fine-tuning CLIP with data generated from our pipelines, we develop NegationCLIP, which enhances negation awareness while preserving the generality. Moreover, to enable a comprehensive evaluation of negation understanding, we propose NegRefCOCOg-a benchmark tailored to test VLMs\' ability to interpret negation across diverse expressions and positions within a sentence. Experiments on various CLIP architectures validate the effectiveness of our data generation pipelines in enhancing CLIP\'s ability to perceive negation accurately. Additionally, NegationCLIP\'s enhanced negation awareness has practical applications across various multimodal tasks, demonstrated by performance gains in text-to-image generation and referring image segmentation.', 'abstract_zh': '尽管CLIP在通过视觉和语言融合显著提升多模态理解方面取得进展，但其无法理解和区分否定概念（如“停车”与“禁止停车”）的能力仍然存在重大挑战。通过对公共CLIP模型预训练数据进行分析，我们推测这一局限性来源于缺乏包含否定信息的数据。为解决这一问题，我们引入了一种数据生成管道，使用大型语言模型（LLM）和多模态LLM生成包含否定信息的描述。通过使用我们的管道生成的数据对CLIP进行微调，我们开发了NegationCLIP，该模型增强了对否定的理解能力，同时保持了普适性。此外，为了全面评估模型对否定的理解能力，我们提出了一种专门用于测试VLM（视觉语言模型）在不同句子位置和表达方式中对否定理解能力的基准——NegRefCOCOg。对多种CLIP架构的实验验证了我们的数据生成管道在提高CLIP准确感知否定方面的有效性。此外，NegationCLIP增强的否定理解能力在多种多模态任务中具有实际应用价值，尤其是在文本生成图像和引用图像分割等任务中表现出性能提升。', 'title_zh': '更好地了解“不”：一种基于数据的方法以增强CLIP中的否定意识'}
{'arxiv_id': 'arXiv:2501.10688', 'title': 'Simulation of Hypergraph Algorithms with Looped Transformers', 'authors': 'Xiaoyu Li, Yingyu Liang, Jiangxuan Long, Zhenmei Shi, Zhao Song, Zhen Zhuang', 'link': 'https://arxiv.org/abs/2501.10688', 'abstract': "Looped Transformers have shown exceptional capability in simulating traditional graph algorithms, but their application to more complex structures like hypergraphs remains underexplored. Hypergraphs generalize graphs by modeling higher-order relationships among multiple entities, enabling richer representations but introducing significant computational challenges. In this work, we extend the Loop Transformer architecture to simulate hypergraph algorithms efficiently, addressing the gap between neural networks and combinatorial optimization over hypergraphs. In this paper, we extend the Loop Transformer architecture to simulate hypergraph algorithms efficiently, addressing the gap between neural networks and combinatorial optimization over hypergraphs. Specifically, we propose a novel degradation mechanism for reducing hypergraphs to graph representations, enabling the simulation of graph-based algorithms, such as Dijkstra's shortest path. Furthermore, we introduce a hyperedge-aware encoding scheme to simulate hypergraph-specific algorithms, exemplified by Helly's algorithm. The paper establishes theoretical guarantees for these simulations, demonstrating the feasibility of processing high-dimensional and combinatorial data using Loop Transformers. This work highlights the potential of Transformers as general-purpose algorithmic solvers for structured data.", 'abstract_zh': '循环变换器在模拟传统图算法方面显示出卓越的能力，但在应用于更复杂的结构，如超图方面仍存在研究不足。超图通过描述多个实体之间的高阶关系，增强了表示能力，但同时也带来了重大的计算挑战。在本文中，我们扩展了循环变换器架构，以高效地模拟超图算法，弥合了基于神经网络和超图上的组合优化之间的差距。本文中，我们扩展了循环变换器架构，以高效地模拟超图算法，弥合了基于神经网络和超图上的组合优化之间的差距。具体而言，我们提出了一种新的降级机制，将超图简化为图表示，从而能够模拟基于图的算法，例如迪杰斯特拉最短路径算法。此外，我们引入了一种超边感知的编码方案来模拟超图特定的算法，例如赫尔利算法。文章为这些模拟提供了理论保证，证明了使用循环变换器处理高维和组合数据的可行性。本文突显了变换器在处理结构化数据的一般用途算法求解器方面的潜力。', 'title_zh': '使用环状变压器模拟超图算法'}
{'arxiv_id': 'arXiv:2501.10674', 'title': 'Can Multimodal LLMs do Visual Temporal Understanding and Reasoning? The answer is No!', 'authors': 'Mohamed Fazli Imam, Chenyang Lyu, Alham Fikri Aji', 'link': 'https://arxiv.org/abs/2501.10674', 'abstract': 'Multimodal Large Language Models (MLLMs) have achieved significant advancements in tasks like Visual Question Answering (VQA) by leveraging foundational Large Language Models (LLMs). However, their abilities in specific areas such as temporal understanding, which is crucial for comprehending real-world dynamics, remain underexplored. To address this, we propose a challenging evaluation benchmark named TemporalVQA, consisting of two parts: (1) Temporal Order Understanding and (2) Time-lapse Estimation. The first part requires MLLMs to determine the sequence of events by analyzing temporally consecutive video frames. The second part presents image pairs with varying time differences, framed as multiple-choice questions, asking MLLMs to estimate the time-lapse between images with options ranging from seconds to years. Our evaluations of advanced MLLMs, including models like GPT-4o and Gemini-1.5-Pro, reveal significant challenges: GPT-4o achieved only 43.8% average consistent accuracy in temporal order tasks and 70% in time-lapse estimation, with open-source models performing even less effectively. These findings underscore the limitations of current MLLMs in visual temporal understanding and reasoning, highlighting the need for further improvements in their temporal capabilities. Our dataset can be found at this https URL.', 'abstract_zh': '多模态大型语言模型（MLLMs）通过利用基础大型语言模型（LLMs）在视觉问答（VQA）等任务上取得了显著进展。然而，它们在特定领域，如时间理解方面的能力仍然未被充分探索，而时间理解对于理解现实世界的动态至关重要。为了解决这一问题，我们提出了一项具有挑战性的评估基准 TemporalVQA，它包括两个部分：(1) 时间顺序理解；(2) 时间间隔估计。第一部分要求MLLMs通过分析时间连续的视频帧来确定事件的顺序。第二部分则展示了具有不同时间间隔的图像对，提出多项选择题形式的问题，要求MLLMs估计两幅图像之间的时间间隔，选项范围从秒到数年。我们对先进MLLMs，包括GPT-4o和Gemini-1.5-Pro等模型的评估表明了巨大挑战：GPT-4o在时间顺序任务上的平均一致准确率为43.8%，在时间间隔估计任务上的准确率为70%，开源模型的表现甚至更差。这些发现突显出当前MLLMs在视觉时间理解与推理方面的局限性，强调了进一步提高其时间处理能力的必要性。我们的数据集可以在以下网址获取：[此链接]。', 'title_zh': '多模态LLM能够进行视觉时间理解与推理吗？答案是否定的！'}
{'arxiv_id': 'arXiv:2501.10668', 'title': 'MappedTrace: Tracing Pointer Remotely with Compiler-generated Maps', 'authors': 'Zhiyao Ma, Caihua Li, Lin Zhong', 'link': 'https://arxiv.org/abs/2501.10668', 'abstract': "Existing precise pointer tracing methods introduce substantial runtime overhead to the program being traced and are applicable only at specific program execution points. We propose MappedTrace that leverages compiler-generated read-only maps to accurately identify all pointers in any given snapshot of a program's execution state. The maps record the locations and types of pointers, allowing the tracer to precisely identify pointers without requiring the traced program to maintain bookkeeping data structures or poll at safe points, thereby reducing runtime overhead. By running the tracer from a different address space or machine, MappedTrace presents new opportunities to improve memory management techniques like memory leak detection and enables novel use cases such as infinite memory abstraction for resource-constrained environments.", 'abstract_zh': '现有的精确指针追踪方法会在被追踪程序中引入较大的运行时开销，并且仅适用于程序执行的特定点。我们提出了一种名为 MappedTrace 的方法，该方法利用编译器生成的只读映射来准确地识别程序执行状态在任一时间点的所有指针。这些映射记录了指针的存储位置和类型，使得追踪器能够精确地识别指针，而不需要被追踪程序维护任何计数数据结构或在安全点进行轮询，从而减少了运行时开销。通过从不同的地址空间或机器运行追踪器，MappedTrace 提供了改进内存管理技术（如内存泄漏检测）的新机会，并且能够为资源受限的环境启用新型应用场景，例如无限内存抽象。', 'title_zh': 'MappedTrace：通过编译器生成的映射进行远程指针追踪'}
{'arxiv_id': 'arXiv:2501.10661', 'title': 'Unveiling the Mystery of Weight in Large Foundation Models: Gaussian Distribution Never Fades', 'authors': 'Chongjie Si, Jingjing Jiang, Wei Shen', 'link': 'https://arxiv.org/abs/2501.10661', 'abstract': "This paper presents a pioneering exploration of the mechanisms underlying large foundation models' (LFMs) weights, aiming to simplify AI research. Through extensive observation and analysis on prevailing LFMs, we find that regardless of initialization strategies, their weights predominantly follow a Gaussian distribution, with occasional sharp, inverted T-shaped, or linear patterns. We further discover that the weights share the i.i.d. properties of Gaussian noise, and explore their direct relationship. We find that transformation weights can be derived from Gaussian noise, and they primarily serve to increase the standard deviation of pre-trained weights, with their standard deviation growing with layer depth. In other words, transformation weights broaden the acceptable deviation from the optimal weights, facilitating adaptation to downstream tasks. Building upon the above conclusions, we thoroughly discussed the nature of optimal weights, ultimately concluding that they should exhibit zero-mean, symmetry, and sparsity, with the sparse values being a truncated Gaussian distribution and a few outliers. Our experiments in LFM adaptation and editing demonstrate the effectiveness of these insights. We hope these findings can provide a foundational understanding to pave the way for future advancements in the LFM community.", 'abstract_zh': '本文对大型基础模型（LFMs）权重背后的机理进行了开创性的探索，旨在简化AI研究。通过对当前主流LFMs的广泛观察和分析，我们发现，无论采用何种初始化策略，其权重主要遵循高斯分布，偶尔出现尖锐的倒T形或线性模式。进一步的研究发现，权重表现出与高斯噪声相同的独立同分布（i.i.d.）特性，并探索了它们之间的直接关系。我们发现，转换权重可以源自高斯噪声，并主要通过增加预训练权重的标准差来发挥作用，其标准差随着层数加深而增加。换句话说，转换权重可以扩大对最优权重的可接受偏差范围，从而促进对下游任务的适应。基于上述结论，我们深入讨论了最优权重的性质，最终得出结论，最优权重应具有零均值、对称性和稀疏性，稀疏值遵循截断的高斯分布，并且有一些异常值。我们在LFM适应和编辑方面的实验验证了这些观点的有效性。我们希望这些发现能够为LFM社区未来的发展提供基础性理解。', 'title_zh': '揭示大型基础模型中权重的奥秘：正态分布永不褪色'}
{'arxiv_id': 'arXiv:2501.10639', 'title': 'Latent-space adversarial training with post-aware calibration for defending large language models against jailbreak attacks', 'authors': 'Xin Yi, Yue Li, Linlin Wang, Xiaoling Wang, Liang He', 'link': 'https://arxiv.org/abs/2501.10639', 'abstract': 'Ensuring safety alignment has become a critical requirement for large language models (LLMs), particularly given their widespread deployment in real-world applications. However, LLMs remain susceptible to jailbreak attacks, which exploit system vulnerabilities to bypass safety measures and generate harmful outputs. Although numerous defense mechanisms based on adversarial training have been proposed, a persistent challenge lies in the exacerbation of over-refusal behaviors, which compromise the overall utility of the model. To address these challenges, we propose a Latent-space Adversarial Training with Post-aware Calibration (LATPC) framework. During the adversarial training phase, LATPC compares harmful and harmless instructions in the latent space and extracts safety-critical dimensions to construct refusal features attack, precisely simulating agnostic jailbreak attack types requiring adversarial mitigation. At the inference stage, an embedding-level calibration mechanism is employed to alleviate over-refusal behaviors with minimal computational overhead. Experimental results demonstrate that, compared to various defense methods across five types of jailbreak attacks, LATPC framework achieves a superior balance between safety and utility. Moreover, our analysis underscores the effectiveness of extracting safety-critical dimensions from the latent space for constructing robust refusal feature attacks.', 'abstract_zh': '确保安全性对大型语言模型（LLMs）来说已成为一个关键要求，特别是在其被广泛应用于实际应用场景的情况下。然而，LLMs仍容易受到 Jailbreak 攻击的影响，这类攻击利用系统漏洞绕过安全措施并生成有害输出。尽管已经提出了许多基于对抗训练的防御机制，但在对抗训练过程中增强过度拒绝行为仍然是一个持续的挑战，这会削弱模型的整体实用性。为应对这些挑战，我们提出了一种潜空间对抗训练与后向校准（LATPC）框架。在对抗训练阶段，LATPC 在潜空间中比较有害和无害的指令，提取安全关键维度以构建拒绝特征攻击，精确模拟需要对抗缓解的无差别 Jailbreak 攻击类型。在推理阶段，采用嵌入层校准机制来最小化计算开销的同时缓解过度拒绝行为。实验结果表明，与五种类型 Jailbreak 攻击的多种防御方法相比，LATPC 框架能够在安全性与实用性之间实现更好的平衡。此外，我们的分析强调了从潜空间中提取安全关键维度以构建稳健的拒绝特征攻击的有效性。', 'title_zh': '面向监狱突破攻击的大语言模型潜空间对抗训练及后知觉校准防御方法'}
{'arxiv_id': 'arXiv:2501.10604', 'title': 'When language and vision meet road safety: leveraging multimodal large language models for video-based traffic accident analysis', 'authors': 'Ruixuan Zhang, Beichen Wang, Juexiao Zhang, Zilin Bian, Chen Feng, Kaan Ozbay', 'link': 'https://arxiv.org/abs/2501.10604', 'abstract': 'The increasing availability of traffic videos functioning on a 24/7/365 time scale has the great potential of increasing the spatio-temporal coverage of traffic accidents, which will help improve traffic safety. However, analyzing footage from hundreds, if not thousands, of traffic cameras in a 24/7/365 working protocol remains an extremely challenging task, as current vision-based approaches primarily focus on extracting raw information, such as vehicle trajectories or individual object detection, but require laborious post-processing to derive actionable insights. We propose SeeUnsafe, a new framework that integrates Multimodal Large Language Model (MLLM) agents to transform video-based traffic accident analysis from a traditional extraction-then-explanation workflow to a more interactive, conversational approach. This shift significantly enhances processing throughput by automating complex tasks like video classification and visual grounding, while improving adaptability by enabling seamless adjustments to diverse traffic scenarios and user-defined queries. Our framework employs a severity-based aggregation strategy to handle videos of various lengths and a novel multimodal prompt to generate structured responses for review and evaluation and enable fine-grained visual grounding. We introduce IMS (Information Matching Score), a new MLLM-based metric for aligning structured responses with ground truth. We conduct extensive experiments on the Toyota Woven Traffic Safety dataset, demonstrating that SeeUnsafe effectively performs accident-aware video classification and visual grounding by leveraging off-the-shelf MLLMs. Source code will be available at \\url{this https URL}.', 'abstract_zh': '24/7/365时间尺度下日益增多的交通视频提供了增加交通事故的空间-时间覆盖范围的巨大潜力，这将有助于提高交通安全。然而，按照24/7/365的工作模式分析数百甚至数千个交通摄像头的监控视频仍然是一个极其具挑战性的任务，当前基于视觉的方法主要集中在提取基本信息，如车辆轨迹或单个对象检测，但需耗时的手动后处理才能得出可操作的见解。为此，我们提出了一种名为SeeUnsafe的新框架，该框架集成了多模态大型语言模型（MLLM）代理，将基于视频的交通事故分析从传统的提取-解释工作流程转变为更互动的、对话式的方法。这种转变通过自动化复杂任务，如视频分类和视觉定位，显著提高了处理效率，同时通过使模型能够无缝适应多种交通场景和用户定义的查询，增强了其适应性。我们的框架采用基于严重性的聚合策略来处理不同长度的视频，并引入了一种新颖的多模态提示，以生成结构化的回应，供审查和评估，并实现精细的视觉定位。我们引入了IMS（信息匹配得分），这是一种新的基于MLLM的指标，用于将结构化的回应与真实值对齐。我们在丰田编织交通安全数据集上进行了广泛的实验，显示SeeUnsafe能够利用现成的MLLM有效执行事故感知的视频分类和视觉定位。源代码可在[该链接]获取。', 'title_zh': '当语言与视觉交汇于道路安全：利用多模态大规模语言模型进行基于视频的道路交通事故分析'}
{'arxiv_id': 'arXiv:2501.10542', 'title': 'Improved IR-based Bug Localization with Intelligent Relevance Feedback', 'authors': 'Asif Mohammed Samir, Mohammad Masudur Rahman', 'link': 'https://arxiv.org/abs/2501.10542', 'abstract': "Software bugs pose a significant challenge during development and maintenance, and practitioners spend nearly 50% of their time dealing with bugs. Many existing techniques adopt Information Retrieval (IR) to localize a reported bug using textual and semantic relevance between bug reports and source code. However, they often struggle to bridge a critical gap between bug reports and code that requires in-depth contextual understanding, which goes beyond textual or semantic relevance. In this paper, we present a novel technique for bug localization - BRaIn - that addresses the contextual gaps by assessing the relevance between bug reports and code with Large Language Models (LLM). It then leverages the LLM's feedback (a.k.a., Intelligent Relevance Feedback) to reformulate queries and re-rank source documents, improving bug localization. We evaluate BRaIn using a benchmark dataset, Bench4BL, and three performance metrics and compare it against six baseline techniques from the literature. Our experimental results show that BRaIn outperforms baselines by 87.6%, 89.5%, and 48.8% margins in MAP, MRR, and HIT@K, respectively. Additionally, it can localize approximately 52% of bugs that cannot be localized by the baseline techniques due to the poor quality of corresponding bug reports. By addressing the contextual gaps and introducing Intelligent Relevance Feedback, BRaIn advances not only theory but also improves IR-based bug localization.", 'abstract_zh': '软件bug在开发和维护过程中构成了一个重大挑战，开发人员几乎将50%的时间用于处理bug。现有的许多技术采用信息检索（IR）方法通过bug报告与源代码之间的文本和语义相关性来定位bug。然而，这些方法往往难以弥合bug报告与代码之间的一个关键差距，即需要深入的上下文理解，而这种理解超出了单纯的文本或语义相关性。本研究中，我们提出了一种名为BRaIn的新颖技术，通过利用大型语言模型（LLM）评估bug报告与代码之间的相关性来解决这种上下文差距。然后，它利用LLM的反馈（即智能相关性反馈）来重新表述查询并重新排列源文档，从而提高bug定位的准确性。我们使用基准数据集Bench4BL和三种性能指标评估了BRaIn，并将其与文献中提出的六种基线技术进行了比较。实验结果显示，BRaIn分别在MAP、MRR和HIT@K指标上优于基线技术87.6%、89.5%和48.8%。此外，它还可以定位大约52%的bug，而这些bug由于相关bug报告的质量较差而无法被基线技术定位。通过解决上下文差距并引入智能相关性反馈，BRaIn不仅推进了理论研究，还改进了基于信息检索的bug定位技术。', 'title_zh': '基于改进的IR的智能相关反馈缺陷定位方法'}
{'arxiv_id': 'arXiv:2501.10408', 'title': 'Leveraging Cross-Attention Transformer and Multi-Feature Fusion for Cross-Linguistic Speech Emotion Recognition', 'authors': 'Ruoyu Zhao, Xiantao Jiang, F. Richard Yu, Victor C.M. Leung, Tao Wang, Shaohu Zhang', 'link': 'https://arxiv.org/abs/2501.10408', 'abstract': 'Speech Emotion Recognition (SER) plays a crucial role in enhancing human-computer interaction. Cross-Linguistic SER (CLSER) has been a challenging research problem due to significant variability in linguistic and acoustic features of different languages. In this study, we propose a novel approach HuMP-CAT, which combines HuBERT, MFCC, and prosodic characteristics. These features are fused using a cross-attention transformer (CAT) mechanism during feature extraction. Transfer learning is applied to gain from a source emotional speech dataset to the target corpus for emotion recognition. We use IEMOCAP as the source dataset to train the source model and evaluate the proposed method on seven datasets in five languages (e.g., English, German, Spanish, Italian, and Chinese). We show that, by fine-tuning the source model with a small portion of speech from the target datasets, HuMP-CAT achieves an average accuracy of 78.75% across the seven datasets, with notable performance of 88.69% on EMODB (German language) and 79.48% on EMOVO (Italian language). Our extensive evaluation demonstrates that HuMP-CAT outperforms existing methods across multiple target languages.', 'abstract_zh': '语音情感识别（SER）在提升人机交互方面发挥着重要作用。跨语言语音情感识别（CLSER）因其显著的语言和声学特征差异而成为一个具有挑战性的研究问题。在本研究中，我们提出了一种新颖的方法HuMP-CAT，该方法结合了HuBERT、MFCC和语调特征。这些特征在特征提取过程中通过交叉注意力变换器（CAT）机制进行融合。我们应用迁移学习，从源语音情感数据集中获得信息，用于目标语料库上的情感识别。我们使用IEMOCAP作为源数据集来训练源模型，并在五种语言（如英语、德语、西班牙语、意大利语和中文）的七个数据集上评估提出的方法。结果显示，通过微调源模型并与少量目标数据集的语音数据结合，HuMP-CAT在七个数据集上的平均准确率为78.75%，在EMODB（德语语言）上的表现尤为突出，准确率为88.69%，在EMOVO（意大利语语言）上的准确率为79.48%。我们广泛的评估表明，HuMP-CAT在多种目标语言上优于现有方法。', 'title_zh': '利用跨注意力变换器和多特征融合进行跨语言语音情绪识别'}
{'arxiv_id': 'arXiv:2501.10388', 'title': 'Beyond the Sum: Unlocking AI Agents Potential Through Market Forces', 'authors': 'Jordi Montes Sanabria, Pol Alvarez Vecino', 'link': 'https://arxiv.org/abs/2501.10388', 'abstract': 'The emergence of Large Language Models has fundamentally transformed the capabilities of AI agents, enabling a new class of autonomous agents capable of interacting with their environment through dynamic code generation and execution. These agents possess the theoretical capacity to operate as independent economic actors within digital markets, offering unprecedented potential for value creation through their distinct advantages in operational continuity, perfect replication, and distributed learning capabilities. However, contemporary digital infrastructure, architected primarily for human interaction, presents significant barriers to their participation.\nThis work presents a systematic analysis of the infrastructure requirements necessary for AI agents to function as autonomous participants in digital markets. We examine four key areas - identity and authorization, service discovery, interfaces, and payment systems - to show how existing infrastructure actively impedes agent participation. We argue that addressing these infrastructure challenges represents more than a technical imperative; it constitutes a fundamental step toward enabling new forms of economic organization. Much as traditional markets enable human intelligence to coordinate complex activities beyond individual capability, markets incorporating AI agents could dramatically enhance economic efficiency through continuous operation, perfect information sharing, and rapid adaptation to changing conditions. The infrastructure challenges identified in this work represent key barriers to realizing this potential.', 'abstract_zh': '大型语言模型的出现从根本上改变了人工智能代理的能力，使一种新的自动化代理能够通过动态代码生成和执行与环境进行互动。这些代理具备理论上的能力，在数字市场中独立运作，并通过操作连续性、完美复制和分布式学习能力创造前所未有的价值。然而，主要为人类互动设计的当前数字基础设施对它们的参与构成了重大障碍。\n\n本文对确保人工智能代理能够在数字市场中作为自主参与者运作所需的基础设施要求进行了系统分析。我们探讨了四个关键领域——身份与授权、服务发现、接口和服务支付系统，以展示现有基础设施如何积极阻碍代理的参与。我们认为，应对这些基础设施挑战不仅仅是技术上的必要性，而是朝着促进新型经济组织的一种基本步骤。正如传统市场使人类智能能够协调超出个人能力的复杂活动一样，包含人工智能代理的市场可以通过连续运营、完美信息共享和快速适应变化条件来显著提升经济效率。本文中识别出的基础设施挑战是实现这一潜力的关键障碍。', 'title_zh': '超越总和：通过市场力量释放人工智能代理的潜力'}
{'arxiv_id': 'arXiv:2501.10377', 'title': 'The Three Social Dimensions of Chatbot Technology', 'authors': 'Mauricio Figueroa-Torres', 'link': 'https://arxiv.org/abs/2501.10377', 'abstract': 'The development and deployment of chatbot technology, while spanning decades and employing different techniques, require innovative frameworks to understand and interrogate their functionality and implications. A mere technocentric account of the evolution of chatbot technology does not fully illuminate how conversational systems are embedded in societal dynamics. This study presents a structured examination of chatbots across three societal dimensions, highlighting their roles as objects of scientific research, commercial instruments, and agents of intimate interaction. Through furnishing a dimensional framework for the evolution of conversational systems, from laboratories to marketplaces to private lives, this article contributes to the wider scholarly inquiry of chatbot technology and its impact in lived human experiences and dynamics.', 'abstract_zh': '聊天机器人技术的发展与部署虽跨越数十年并采用了多种技术手段，但需要创新框架来理解和探讨其功能与影响。仅仅从技术层面描述聊天机器人技术的发展并不能充分阐明聊天系统在社会动态中的嵌入方式。本研究通过三个社会维度结构化地考察聊天机器人技术的角色，突出其作为科学研究对象、商业工具以及亲密互动代理的作用。通过为聊天系统的发展提供一个从实验室到市场再到私人生活的维度框架，本文为更广泛的学术研究——即聊天机器人技术及其对人类生活体验和社会动态的影响——做出了贡献。', 'title_zh': '聊天机器人技术的三个社会维度'}
{'arxiv_id': 'arXiv:2501.10361', 'title': 'How Large Language Models (LLMs) Extrapolate: From Guided Missiles to Guided Prompts', 'authors': 'Xuenan Cao', 'link': 'https://arxiv.org/abs/2501.10361', 'abstract': 'This paper argues that we should perceive LLMs as machines of extrapolation. Extrapolation is a statistical function for predicting the next value in a series. Extrapolation contributes to both GPT successes and controversies surrounding its hallucination. The term hallucination implies a malfunction, yet this paper contends that it in fact indicates the chatbot efficiency in extrapolation, albeit an excess of it. This article bears a historical dimension: it traces extrapolation to the nascent years of cybernetics. In 1941, when Norbert Wiener transitioned from missile science to communication engineering, the pivotal concept he adopted was none other than extrapolation. Soviet mathematician Andrey Kolmogorov, renowned for his compression logic that inspired OpenAI, had developed in 1939 another extrapolation project that Wiener later found rather like his own. This paper uncovers the connections between hot war science, Cold War cybernetics, and the contemporary debates on LLM performances.', 'abstract_zh': '本文主张应将大型语言模型（LLMs）视为外推工具。外推是一种统计函数，用于预测系列中的下一个值。外推既促进了GPT的成功，也引发了关于其生成幻觉的争议。术语“幻觉”暗示了机器的故障，但本文认为，这实际上反映了聊天机器人的外推效率，尽管可能超出了适当的范围。本文具有历史维度：它追溯了外推概念自 Cybernetics（控制论）萌芽时期的发展。1941年，Norbert Wiener从导弹科学转到通信工程领域时，他采纳的关键概念就是外推。苏联数学家Andrey Kolmogorov因受启发于其压缩逻辑而促成OpenAI的发展，在1939年也提出了一个外推项目，Wiener后来认为这个项目与自己的项目很相似。本文揭示了热战科学、冷战时期控制论以及当前有关LLM性能辩论之间的联系。', 'title_zh': '大型语言模型（LLMs）的外推机制：从 guidance missiles 到 guidance prompts'}
