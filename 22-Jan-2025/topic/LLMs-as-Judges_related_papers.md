# The Alternative Annotator Test for LLM-as-a-Judge: How to Statistically Justify Replacing Human Annotators with LLMs 

**Title (ZH)**: LLM作为法官的替代注释员测试：如何通过统计方法证明可以用LLM替代人类注释员 

**Authors**: Nitay Calderon, Roi Reichart, Rotem Dror  

**Link**: [PDF](https://arxiv.org/pdf/2501.10970)  

**Abstract**: The "LLM-as-a-judge" paradigm employs Large Language Models (LLMs) as annotators and evaluators in tasks traditionally performed by humans. LLM annotations are widely used, not only in NLP research but also in fields like medicine, psychology, and social science. Despite their role in shaping study results and insights, there is no standard or rigorous procedure to determine whether LLMs can replace human annotators. In this paper, we propose a novel statistical procedure -- the Alternative Annotator Test (alt-test) -- that requires only a modest subset of annotated examples to justify using LLM annotations. Additionally, we introduce a versatile and interpretable measure for comparing LLM judges. To demonstrate our procedure, we curated a diverse collection of ten datasets, consisting of language and vision-language tasks, and conducted experiments with six LLMs and four prompting techniques. Our results show that LLMs can sometimes replace humans with closed-source LLMs (such as GPT-4o), outperforming open-source LLMs, and that prompting techniques yield judges of varying quality. We hope this study encourages more rigorous and reliable practices. 

**Abstract (ZH)**: “LLM-as-a-judge”范式利用大型语言模型（LLMs）作为传统上由人类完成的任务中的注释员和评估者。LLM注解在多个领域广泛使用，不仅限于自然语言处理研究，还涉及到医学、心理学和社会科学等领域。尽管LLMs在研究结果和见解的形成中起着重要作用，但对于是否能够替代人类注释员并没有标准和严谨的鉴定程序。本文提出了一种新的统计方法——替代注释员检验（alt-test），仅需要少量注释示例即可证明使用LLM注解的有效性。此外，我们介绍了用于比较LLM评审员的灵活且可解释性较强的度量标准。为了展示我们的方法，我们精选了十个多样化的数据集，其中包括语言和视觉-语言任务，并采用了六种LLM和四种提示技术进行了实验。结果表明，在某些情况下，闭源LLM（如GPT-4o）可以替代人类，表现优于开源LLM，并且提示技术产生了不同质量的评审员。我们希望这项研究能够促进更加严谨和可靠的实践。 

---
