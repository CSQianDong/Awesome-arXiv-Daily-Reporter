{'arxiv_id': 'arXiv:2501.16961', 'title': 'Instantiation-based Formalization of Logical Reasoning Tasks using Language Models and Logical Solvers', 'authors': 'Mohammad Raza, Natasa Milic-Frayling', 'link': 'https://arxiv.org/abs/2501.16961', 'abstract': 'Robustness of reasoning remains a significant challenge for large language models, and addressing it is essential for the practical applicability of AI-driven reasoning systems. We introduce Semantic Self-Verification (SSV), a novel approach that addresses the key challenge in combining language models with the rigor of logical solvers: to accurately formulate the reasoning problem from natural language to the formal language of the solver. SSV uses a consistency-based approach to produce strong abstract formalizations of problems using concrete instantiations that are generated by the model and verified by the solver. In addition to significantly advancing the overall reasoning accuracy over the state-of-the-art, a key novelty that this approach presents is a feature of verification that has near-perfect precision over a significant coverage of cases, as we demonstrate on open reasoning benchmarks. We propose such *near-certain reasoning* as a new approach to reduce the need for manual verification in many cases, taking us closer to more dependable and autonomous AI reasoning systems.', 'abstract_zh': '大型语言模型在推理的稳健性方面仍面临重大挑战，而解决这一问题对于AI驱动的推理系统的实际应用至关重要。我们提出了语义自我验证（SSV）这一新颖的方法，以解决将语言模型与逻辑求解器的严谨性相结合的关键挑战：将自然语言准确地转化为求解器的形式语言。SSV 使用一致性为基础的方法，通过模型生成的具体实例来生成问题的强抽象形式化表示，并通过求解器验证这些实例。除了在整体推理准确性上显著超越现有技术之外，该方法的一个重要创新点在于验证在大量情形下具有近乎完美的精确度，我们通过开放推理基准测试进行了展示。我们提出了这种“几乎确定的推理”作为减少许多情况下人工验证需求的新方法，使我们更接近于更加可靠和自主的AI推理系统。', 'title_zh': '基于实例的逻辑推理任务形式化方法：利用语言模型和逻辑求解器'}
{'arxiv_id': 'arXiv:2501.16672', 'title': 'VeriFact: Verifying Facts in LLM-Generated Clinical Text with Electronic Health Records', 'authors': 'Philip Chung, Akshay Swaminathan, Alex J. Goodell, Yeasul Kim, S. Momsen Reincke, Lichy Han, Ben Deverett, Mohammad Amin Sadeghi, Abdel-Badih Ariss, Marc Ghanem, David Seong, Andrew A. Lee, Caitlin E. Coombes, Brad Bradshaw, Mahir A. Sufian, Hyo Jung Hong, Teresa P. Nguyen, Mohammad R. Rasouli, Komal Kamra, Mark A. Burbridge, James C. McAvoy, Roya Saffary, Stephen P. Ma, Dev Dash, James Xie, Ellen Y. Wang, Clifford A. Schmiesing, Nigam Shah, Nima Aghaeepour', 'link': 'https://arxiv.org/abs/2501.16672', 'abstract': "Methods to ensure factual accuracy of text generated by large language models (LLM) in clinical medicine are lacking. VeriFact is an artificial intelligence system that combines retrieval-augmented generation and LLM-as-a-Judge to verify whether LLM-generated text is factually supported by a patient's medical history based on their electronic health record (EHR). To evaluate this system, we introduce VeriFact-BHC, a new dataset that decomposes Brief Hospital Course narratives from discharge summaries into a set of simple statements with clinician annotations for whether each statement is supported by the patient's EHR clinical notes. Whereas highest agreement between clinicians was 88.5%, VeriFact achieves up to 92.7% agreement when compared to a denoised and adjudicated average human clinican ground truth, suggesting that VeriFact exceeds the average clinician's ability to fact-check text against a patient's medical record. VeriFact may accelerate the development of LLM-based EHR applications by removing current evaluation bottlenecks.", 'abstract_zh': '大型语言模型（LLM）在临床医学领域生成的文字内容确保事实准确性的方法尚缺乏。VeriFact 是一个结合检索增强生成和 LLM-as-a-Judge 的人工智能系统，用于验证 LLM 生成的文字是否得到患者医疗历史中电子健康记录（EHR）的支持。为了评估该系统，我们引入了 VeriFact-BHC，一个新数据集，该数据集将出院总结中的简短住院病程叙述分解为一系列简单的陈述，并由临床医生标注每个陈述是否得到患者 EHR 临床笔记的支持。尽管临床医生间最高一致率为 88.5%，但 VeriFact 与去噪并经过裁定的人类临床医生平均水平一致性的最大值达到 92.7%，表明 VeriFact 超过了临床医生平均验证文本与患者医疗记录之间事实一致性的能力。VeriFact 可能通过消除当前的评估瓶颈加速基于 LLM 的电子健康记录应用的发展。', 'title_zh': 'VeriFact：通过电子健康记录验证LLM生成的临床文本中的事实'}
{'arxiv_id': 'arXiv:2501.16546', 'title': 'Sample-Efficient Behavior Cloning Using General Domain Knowledge', 'authors': 'Feiyu Zhu, Jean Oh, Reid Simmons', 'link': 'https://arxiv.org/abs/2501.16546', 'abstract': "Behavior cloning has shown success in many sequential decision-making tasks by learning from expert demonstrations, yet they can be very sample inefficient and fail to generalize to unseen scenarios. One approach to these problems is to introduce general domain knowledge, such that the policy can focus on the essential features and may generalize to unseen states by applying that knowledge. Although this knowledge is easy to acquire from the experts, it is hard to be combined with learning from individual examples due to the lack of semantic structure in neural networks and the time-consuming nature of feature engineering. To enable learning from both general knowledge and specific demonstration trajectories, we use a large language model's coding capability to instantiate a policy structure based on expert domain knowledge expressed in natural language and tune the parameters in the policy with demonstrations. We name this approach the Knowledge Informed Model (KIM) as the structure reflects the semantics of expert knowledge. In our experiments with lunar lander and car racing tasks, our approach learns to solve the tasks with as few as 5 demonstrations and is robust to action noise, outperforming the baseline model without domain knowledge. This indicates that with the help of large language models, we can incorporate domain knowledge into the structure of the policy, increasing sample efficiency for behavior cloning.", 'abstract_zh': '行为克隆在许多序列决策任务中通过学习专家演示取得了成功，但它们可能非常样本效率低下，并且难以泛化到未见过的场景。解决这些问题的方法之一是引入通用领域知识，从而使策略能够关注于关键特征，并通过应用这些知识在未见过的状态上泛化。尽管可以从专家那里轻松获取此类知识，但由于神经网络缺乏语义结构以及特征工程的耗时性，将此类知识与从个体示例中学习进行结合十分困难。为了同时从通用知识和具体示例轨迹中进行学习，我们利用大型语言模型的编码能力，基于自然语言表达的专家领域知识实例化策略结构，并通过示例对策略的参数进行调整。我们将这种做法命名为知识指导模型（KIM），因为其结构反映了专家知识的语义。在对月球着陆和赛车任务进行的实验中，我们的方法仅使用5次演示即可学会解决问题，并对动作噪声具有鲁棒性，优于未使用领域知识的基线模型。这表明，在大型语言模型的帮助下，可以将领域知识融入策略结构中，从而提高行为克隆的学习样本效率。', 'title_zh': '使用通用领域知识的样本高效行为克隆'}
{'arxiv_id': 'arXiv:2501.16952', 'title': 'Multiple Abstraction Level Retrieve Augment Generation', 'authors': 'Zheng Zheng, Xinyi Ni, Pengyu Hong', 'link': 'https://arxiv.org/abs/2501.16952', 'abstract': "A Retrieval-Augmented Generation (RAG) model powered by a large language model (LLM) provides a faster and more cost-effective solution for adapting to new data and knowledge. It also delivers more specialized responses compared to pre-trained LLMs. However, most existing approaches rely on retrieving prefix-sized chunks as references to support question-answering (Q/A). This approach is often deployed to address information needs at a single level of abstraction, as it struggles to generate answers across multiple levels of abstraction. In an RAG setting, while LLMs can summarize and answer questions effectively when provided with sufficient details, retrieving excessive information often leads to the 'lost in the middle' problem and exceeds token limitations. We propose a novel RAG approach that uses chunks of multiple abstraction levels (MAL), including multi-sentence-level, paragraph-level, section-level, and document-level. The effectiveness of our approach is demonstrated in an under-explored scientific domain of Glycoscience. Compared to traditional single-level RAG approaches, our approach improves AI evaluated answer correctness of Q/A by 25.739\\% on Glyco-related papers.", 'abstract_zh': '由大规模语言模型（LLM）驱动的检索增强生成（RAG）模型为适应新数据和知识提供了更快、更经济的解决方案。与预训练的LLM相比，它还能提供更加专业化的回答。然而，现有的大多数方法依赖于检索前缀大小的片段作为支持问答（Q/A）的参考。这种方法通常仅在单一抽象层次上解决信息需求，因为它难以生成跨越多个抽象层次的答案。在RAG框架中，虽然LLM在提供足够细节时可以有效地进行总结和回答问题，但检索过多信息往往会导致“中间迷失”问题，并超过标记限制。我们提出了一种新颖的具有多抽象层次（MAL）片段的RAG方法，包括多句子级别、段落级别、部分级别和文档级别。我们的方法在尚未充分开发的糖科学领域中得到了验证。与传统的单一抽象层次RAG方法相比，我们的方法在与糖相关的论文中提高了AI评估的问答正确性25.739%。', 'title_zh': '多抽象层次检索增强生成'}
{'arxiv_id': 'arXiv:2501.16884', 'title': 'Irony Detection, Reasoning and Understanding in Zero-shot Learning', 'authors': 'Peiling Yi, Yuhan Xia', 'link': 'https://arxiv.org/abs/2501.16884', 'abstract': "Irony is a powerful figurative language (FL) on social media that can potentially mislead various NLP tasks, such as recommendation systems, misinformation checks, and sentiment analysis. Understanding the implicit meaning of this kind of subtle language is essential to mitigate irony's negative impact on NLP tasks. However, building models to understand irony presents a unique set of challenges, because irony is a complex form of language that often relies on context, tone, and subtle cues to convey meaning that is opposite or different from the literal interpretation. Large language models, such as ChatGPT, are increasingly able to capture implicit and contextual information. In this study, we investigate the generalization, reasoning and understanding ability of ChatGPT on irony detection across six different genre irony detection datasets. Our findings suggest that ChatGPT appears to show an enhanced language understanding and reasoning ability. But it needs to be very careful in prompt engineering design. Thus, we propose a prompt engineering design framework IDADP to achieve higher irony detection accuracy, improved understanding of irony, and more effective explanations compared to other state-of-the-art ChatGPT zero-shot approaches. And ascertain via experiments that the practice generated under the framework is likely to be the promised solution to resolve the generalization issues of LLMs.", 'abstract_zh': 'irony是一种在社交媒体上极具影响力的修辞语言，可能会误导各种自然语言处理（NLP）任务，如推荐系统、虚假信息检测和情感分析。理解这种微妙语言的隐含意义对于减轻irony对NLP任务的负面影响至关重要。然而，构建用于理解irony的模型具有独特的挑战，因为irony是一种复杂的语言形式，通常依赖于上下文、语气和微妙的线索来传达与字面意义相反或不同的含义。大型语言模型（如ChatGPT）越来越能够捕捉到隐含和上下文信息。在这项研究中，我们探讨了ChatGPT在六个不同体裁irony检测数据集上的泛化、推理和理解能力。我们的研究结果表明，ChatGPT似乎在语言理解和推理方面表现出增强的能力。但在提示工程设计方面需要非常谨慎。因此，我们提出了一种提示工程设计框架（IDADP）以实现更高的irony检测精度、更深入的理解irony以及更有效的解释，相比其他先进的ChatGPT零样本方法更具优势。并通过实验验证，该框架下生成的实践可能是解决大规模语言模型泛化问题的承诺解。', 'title_zh': '零样本学习中的irony检测、推理与理解'}
{'arxiv_id': 'arXiv:2501.16744', 'title': 'LLM Assisted Anomaly Detection Service for Site Reliability Engineers: Enhancing Cloud Infrastructure Resilience', 'authors': 'Nimesh Jha, Shuxin Lin, Srideepika Jayaraman, Kyle Frohling, Christodoulos Constantinides, Dhaval Patel', 'link': 'https://arxiv.org/abs/2501.16744', 'abstract': 'This paper introduces a scalable Anomaly Detection Service with a generalizable API tailored for industrial time-series data, designed to assist Site Reliability Engineers (SREs) in managing cloud infrastructure. The service enables efficient anomaly detection in complex data streams, supporting proactive identification and resolution of issues. Furthermore, it presents an innovative approach to anomaly modeling in cloud infrastructure by utilizing Large Language Models (LLMs) to understand key components, their failure modes, and behaviors. A suite of algorithms for detecting anomalies is offered in univariate and multivariate time series data, including regression-based, mixture-model-based, and semi-supervised approaches. We provide insights into the usage patterns of the service, with over 500 users and 200,000 API calls in a year. The service has been successfully applied in various industrial settings, including IoT-based AI applications. We have also evaluated our system on public anomaly benchmarks to show its effectiveness. By leveraging it, SREs can proactively identify potential issues before they escalate, reducing downtime and improving response times to incidents, ultimately enhancing the overall customer experience. We plan to extend the system to include time series foundation models, enabling zero-shot anomaly detection capabilities.', 'abstract_zh': '本文介绍了一种适用于工业时间序列数据的可扩展异常检测服务，该服务配备了一种通用的API，旨在协助系统可靠性工程师（SREs）管理云基础设施。该服务能够高效地在复杂数据流中检测异常，并支持问题的主动识别与解决。此外，本文还介绍了利用大语言模型（LLMs）理解关键组件、故障模式和行为的一种创新异常建模方法。该服务提供了针对单变量和多变量时间序列数据的一系列异常检测算法，包括基于回归、混合模型和半监督的方法。我们提供了关于服务使用模式的见解，数据显示该服务在过去一年中有超过500名用户和200,000次API调用。该服务已在各种工业环境中成功应用，包括基于物联网的AI应用程序。我们也对公共异常检测基准进行了评估，以展示其效果。通过利用该服务，SREs可以在问题升级之前主动识别潜在问题，从而减少停机时间和提高对事件的响应速度，最终提升整体客户体验。我们计划扩展该系统，使其能够包括时间序列基础模型，实现零样本异常检测能力。', 'title_zh': 'LLM辅助异常检测服务：增强现场可靠性工程师的云基础设施韧性'}
{'arxiv_id': 'arXiv:2501.16655', 'title': 'Large Language Model Critics for Execution-Free Evaluation of Code Changes', 'authors': 'Aashish Yadavally, Hoan Nguyen, Laurent Callot, Gauthier Guinet', 'link': 'https://arxiv.org/abs/2501.16655', 'abstract': 'Large language models (LLMs) offer a promising way forward for automating software engineering tasks, such as bug fixes, feature additions, etc., via multi-step LLM-based agentic workflows. However, existing metrics for evaluating such workflows, mainly build status and occasionally log analysis, are too sparse and limited in providing the information needed to assess the quality of changes made. In this work, we designed LLM-based critics to derive well-structured and rigorous intermediate/step-level, execution-free evaluation proxies for repo-level code changes. Importantly, we assume access to the gold test patch for the problem (i.e., reference-aware) to assess both semantics and executability of generated patches. With the gold test patch as a reference, we predict executability of all editing locations with an F1 score of 91.6%, aggregating which, we can predict the build status in 84.8% of the instances in SWE-bench. In particular, such an execution-focused LLM critic outperforms other reference-free and reference-aware LLM critics by 38.9% to 72.5%. Moreover, we demonstrate the usefulness of such a reference-aware framework in comparing patches generated by different agentic workflows. Finally, we open-source the library developed for this project, which allows further usage for either other agentic workflows or other benchmarks. The source code is available at this https URL.', 'abstract_zh': '大型语言模型（LLMs）为通过多步骤的LLM为基础的代理工作流自动化软件工程任务（如错误修复、功能添加等）提供了有前途的方法。然而，现有的评估这些工作流的标准，主要依赖于构建状态和偶尔的日志分析，这些标准过于稀疏且在提供评估代码更改质量所需的信息方面很有限。在本研究中，我们设计了基于LLM的评审员，以推导出结构良好且严格的中间/步骤级别的执行代理评估指标，无需执行这些更改。重要的是，我们假设能够访问问题的黄金测试补丁（即，具有参考信息的），从而评估生成补丁的语义和可执行性。借助黄金测试补丁作为参考，我们能够以91.6%的F1分数预测所有编辑位置的可执行性，并且通过聚合这些预测，我们可以在SWE-bench的84.8%的实例中预测构建状态。特别是在执行重点方面，这种基于LLM的评审员相较于其他无参考和有参考的LLM评审员，表现提升了38.9%至72.5%。此外，我们展示了这种有参考框架在比较由不同代理工作流生成的补丁方面的有用性。最后，我们开源了为此项目开发的库，该库允许将其用于其他代理工作流或不同基准中。源代码可以从以下链接访问：[此链接]。', 'title_zh': '无需执行的代码更改评估的大型语言模型批评者'}
{'arxiv_id': 'arXiv:2501.16643', 'title': 'An LLM Benchmark for Addressee Recognition in Multi-modal Multi-party Dialogue', 'authors': 'Koji Inoue, Divesh Lala, Mikey Elmers, Keiko Ochi, Tatsuya Kawahara', 'link': 'https://arxiv.org/abs/2501.16643', 'abstract': "Handling multi-party dialogues represents a significant step for advancing spoken dialogue systems, necessitating the development of tasks specific to multi-party interactions. To address this challenge, we are constructing a multi-modal multi-party dialogue corpus of triadic (three-participant) discussions. This paper focuses on the task of addressee recognition, identifying who is being addressed to take the next turn, a critical component unique to multi-party dialogue systems. A subset of the corpus was annotated with addressee information, revealing that explicit addressees are indicated in approximately 20% of conversational turns. To evaluate the task's complexity, we benchmarked the performance of a large language model (GPT-4o) on addressee recognition. The results showed that GPT-4o achieved an accuracy only marginally above chance, underscoring the challenges of addressee recognition in multi-party dialogue. These findings highlight the need for further research to enhance the capabilities of large language models in understanding and navigating the intricacies of multi-party conversational dynamics.", 'abstract_zh': '处理多主体对话是推动口语对话系统发展的关键步骤，需要开发针对多主体交互的任务。为应对这一挑战，我们正在构建一个包含三元讨论的多模态多主体对话语料库。本文重点讨论了与会者识别的任务，即识别谁是下一个发言的对象，这是多主体对话系统特有的关键组成部分。部分语料库被标注了与会者信息，结果显示，在约20%的对话回合中明确指出了与会者。为了评估该任务的难度，我们在与会者识别任务上对大型语言模型（GPT-4o）进行了基准测试。结果表明，GPT-4o 的识别准确率仅略微高于随机猜测，强调了多主体对话中与会者识别的挑战性。这些发现突显了进一步研究以提升大型语言模型理解与导航多主体对话复杂动态的能力的必要性。', 'title_zh': '多模态多人群体对话中收件人识别的大型语言模型基准测试'}
{'arxiv_id': 'arXiv:2501.16539', 'title': 'Generalized Mission Planning for Heterogeneous Multi-Robot Teams via LLM-constructed Hierarchical Trees', 'authors': 'Piyush Gupta, David Isele, Enna Sachdeva, Pin-Hao Huang, Behzad Dariush, Kwonjoon Lee, Sangjae Bae', 'link': 'https://arxiv.org/abs/2501.16539', 'abstract': 'We present a novel mission-planning strategy for heterogeneous multi-robot teams, taking into account the specific constraints and capabilities of each robot. Our approach employs hierarchical trees to systematically break down complex missions into manageable sub-tasks. We develop specialized APIs and tools, which are utilized by Large Language Models (LLMs) to efficiently construct these hierarchical trees. Once the hierarchical tree is generated, it is further decomposed to create optimized schedules for each robot, ensuring adherence to their individual constraints and capabilities. We demonstrate the effectiveness of our framework through detailed examples covering a wide range of missions, showcasing its flexibility and scalability.', 'abstract_zh': '我们提出了一种新颖的异构多机器人团队任务规划策略，充分考虑了每台机器人特有的约束和能力。该方法采用层次树结构系统地将复杂任务分解为可管理的子任务。我们开发了专门的API和工具，这些工具被大型语言模型（LLMs）利用以高效地构建这些层次树。一旦生成了层次树，它就会进一步分解，从而为每台机器人创建优化的时间表，确保遵守它们各自的约束和能力。我们通过详尽的例子展示了该框架的有效性，覆盖了广泛的任务类型，展示了其灵活性和可扩展性。', 'title_zh': '基于LLM构建的层次树的异构多机器人团队通用任务规划'}
{'arxiv_id': 'arXiv:2501.16534', 'title': 'Targeting Alignment: Extracting Safety Classifiers of Aligned LLMs', 'authors': 'Jean-Charles Noirot Ferrand, Yohan Beugin, Eric Pauley, Ryan Sheatsley, Patrick McDaniel', 'link': 'https://arxiv.org/abs/2501.16534', 'abstract': "Alignment in large language models (LLMs) is used to enforce guidelines such as safety. Yet, alignment fails in the face of jailbreak attacks that modify inputs to induce unsafe outputs. In this paper, we present and evaluate a method to assess the robustness of LLM alignment. We observe that alignment embeds a safety classifier in the target model that is responsible for deciding between refusal and compliance. We seek to extract an approximation of this classifier, called a surrogate classifier, from the LLM. We develop an algorithm for identifying candidate classifiers from subsets of the LLM model. We evaluate the degree to which the candidate classifiers approximate the model's embedded classifier in benign (F1 score) and adversarial (using surrogates in a white-box attack) settings. Our evaluation shows that the best candidates achieve accurate agreement (an F1 score above 80%) using as little as 20% of the model architecture. Further, we find attacks mounted on the surrogate models can be transferred with high accuracy. For example, a surrogate using only 50% of the Llama 2 model achieved an attack success rate (ASR) of 70%, a substantial improvement over attacking the LLM directly, where we only observed a 22% ASR. These results show that extracting surrogate classifiers is a viable (and highly effective) means for modeling (and therein addressing) the vulnerability of aligned models to jailbreaking attacks.", 'abstract_zh': '大语言模型（LLMs）中的对齐用于实施安全性等指导原则。然而，对齐在面对修改输入以诱导不安全输出的监狱突破攻击时会失效。在本文中，我们提出并评估了一种评估LLM对齐鲁棒性的方法。我们观察到对齐在目标模型中嵌入了一个安全分类器，该分类器负责在拒绝与合规之间做出决定。我们寻求从LLM中提取一个被称为替代分类器的近似表示。我们开发了一种算法，用于识别来自LLM模型子集的候选分类器。我们评估了候选分类器在良性（F1分值）和对抗（使用替代模型进行白盒攻击）情况下与模型嵌入分类器的一致性程度。我们的评估结果显示，在仅使用模型架构的20%的情况下，最佳候选分类器能够实现准确的一致性（F1分值超过80%）。此外，我们发现针对替代模型的攻击可以以高精度进行转移。例如，仅使用Llama 2模型50%的替代模型实现了70%的成功攻击率（ASR），远高于直接攻击LLM的情况，我们仅观察到了22%的ASR。这些结果表明，提取替代分类器是一种可行且非常有效的建模方法，可用于建模并进而解决对齐模型对抗监狱突破攻击的脆弱性。', 'title_zh': '针对对齐的目标：提取对齐的大型语言模型的安全分类器'}
{'arxiv_id': 'arXiv:2501.16516', 'title': 'How well can LLMs Grade Essays in Arabic?', 'authors': 'Rayed Ghazawi, Edwin Simpson', 'link': 'https://arxiv.org/abs/2501.16516', 'abstract': 'This research assesses the effectiveness of state-of-the-art large language models (LLMs), including ChatGPT, Llama, Aya, Jais, and ACEGPT, in the task of Arabic automated essay scoring (AES) using the AR-AES dataset. It explores various evaluation methodologies, including zero-shot, few-shot in-context learning, and fine-tuning, and examines the influence of instruction-following capabilities through the inclusion of marking guidelines within the prompts. A mixed-language prompting strategy, integrating English prompts with Arabic content, was implemented to improve model comprehension and performance. Among the models tested, ACEGPT demonstrated the strongest performance across the dataset, achieving a Quadratic Weighted Kappa (QWK) of 0.67, but was outperformed by a smaller BERT-based model with a QWK of 0.88. The study identifies challenges faced by LLMs in processing Arabic, including tokenization complexities and higher computational demands. Performance variation across different courses underscores the need for adaptive models capable of handling diverse assessment formats and highlights the positive impact of effective prompt engineering on improving LLM outputs. To the best of our knowledge, this study is the first to empirically evaluate the performance of multiple generative Large Language Models (LLMs) on Arabic essays using authentic student data.', 'abstract_zh': '本研究评估了几种最先进的大语言模型（LLMs），包括ChatGPT、Llama、Aya、Jais和ACEGPT，在阿拉伯语自动化作文评分（AES）任务中的有效性，使用了AR-AES数据集。研究探讨了零样本、少量样本上下文学习以及微调等各种评估方法，并通过在提示中加入评分指南来考察指令遵循能力的影响。为提高模型的理解能力和性能，研究采用了混合语言提示策略，将英文提示与阿拉伯语内容相结合。在测试的模型中，ACEGPT在数据集上的表现最佳，达到了0.67的二次加权κ（QWK），但被一个较小的基于BERT的模型超越，后者达到了0.88的QWK。研究指出了LLMs处理阿拉伯语时面临的挑战，包括分词复杂性和更高的计算需求。不同课程上的性能差异突显了需要能够处理多种评估格式的自适应模型的重要性，并强调了有效的提示工程对提高LLMs输出质量的积极影响。据我们所知，这是首次使用真实学生作文数据对多种生成性大语言模型（LLMs）的性能进行实证评估的研究。', 'title_zh': '大规模语言模型在评估阿拉伯语作文方面表现如何？'}
{'arxiv_id': 'arXiv:2501.16383', 'title': 'RotateKV: Accurate and Robust 2-Bit KV Cache Quantization for LLMs via Outlier-Aware Adaptive Rotations', 'authors': 'Zunhai Su, Zhe Chen, Wang Shen, Hanyu Wei, Linge Li, Huangqi Yu, Kehong Yuan', 'link': 'https://arxiv.org/abs/2501.16383', 'abstract': 'Key-Value (KV) cache facilitates efficient large language models (LLMs) inference by avoiding recomputation of past KVs. As the batch size and context length increase, the oversized KV caches become a significant memory bottleneck, highlighting the need for efficient compression. Existing KV quantization rely on fine-grained quantization or the retention of a significant portion of high bit-widths caches, both of which compromise compression ratio and often fail to maintain robustness at extremely low average bit-widths. In this work, we explore the potential of rotation technique for 2-bit KV quantization and propose RotateKV, which achieves accurate and robust performance through the following innovations: (i) Outlier-Aware Rotation, which utilizes channel-reordering to adapt the rotations to varying channel-wise outlier distributions without sacrificing the computational efficiency of the fast Walsh-Hadamard transform (FWHT); (ii) Pre-RoPE Grouped-Head Rotation, which mitigates the impact of rotary position embedding (RoPE) on proposed outlier-aware rotation and further smooths outliers across heads; (iii) Attention-Sink-Aware Quantization, which leverages the massive activations to precisely identify and protect attention sinks. RotateKV achieves less than 0.3 perplexity (PPL) degradation with 2-bit quantization on WikiText-2 using LLaMA-2-13B, maintains strong CoT reasoning and long-context capabilities, with less than 1.7\\% degradation on GSM8K, outperforming existing methods even at lower average bit-widths. RotateKV also showcases a 3.97x reduction in peak memory usage, supports 5.75x larger batch sizes, and achieves a 2.32x speedup in decoding stage.', 'abstract_zh': '键值（KV）缓存通过避免重新计算过去的键值对来促进大规模语言模型（LLMs）的高效推理。随着批次大小和上下文长度的增加，过大的KV缓存成为显著的内存瓶颈，突显了高效压缩的必要性。现有的KV量化依赖于细粒度的量化或者保留大量高位宽的缓存，这两种方法都牺牲了压缩比，并且在极低的平均位宽下难以保持鲁棒性。在本文中，我们探索了旋转技术在2位KV量化中的潜力，并提出了RotateKV，该方法通过以下创新实现了准确和稳健的性能：(i) 基于异常值感知的旋转，利用信道重排适应不同的信道-wise异常值分布，同时保持快速沃尔什-豪氏变换（FWHT）的计算效率；(ii) 预旋转位置编码分组头旋转，减轻旋转位置编码（RoPE）对提出的异常值感知旋转的影响，并进一步在不同头之间平滑异常值；(iii) 注意力沉降感知量化，利用大量的激活来精确地识别和保护注意力沉降点。在使用LLaMA-2-13B进行WikiText-2的2位量化时，RotateKV的困惑度（PPL）下降不到0.3，保持了强大的链式推理能力和长上下文能力，即使在GSM8K上也只有不到1.7%的下降，其性能甚至优于现有方法，尤其是在较低的平均位宽下。实验结果还显示，RotateKV的顶峰内存使用量减少了3.97倍，支持了5.75倍更大的批次大小，并在解码阶段实现了2.32倍的速度提升。', 'title_zh': 'RotateKV：通过基于离群值的自适应旋转实现的LLMs高效且鲁棒的2位键值缓存量化'}
{'arxiv_id': 'arXiv:2501.16368', 'title': 'Foundation Models for CPS-IoT: Opportunities and Challenges', 'authors': 'Ozan Baris, Yizhuo Chen, Gaofeng Dong, Liying Han, Tomoyoshi Kimura, Pengrui Quan, Ruijie Wang, Tianchen Wang, Tarek Abdelzaher, Mario Bergés, Paul Pu Liang, Mani Srivastava', 'link': 'https://arxiv.org/abs/2501.16368', 'abstract': 'Methods from machine learning (ML) have transformed the implementation of Perception-Cognition-Communication-Action loops in Cyber-Physical Systems (CPS) and the Internet of Things (IoT), replacing mechanistic and basic statistical models with those derived from data. However, the first generation of ML approaches, which depend on supervised learning with annotated data to create task-specific models, faces significant limitations in scaling to the diverse sensor modalities, deployment configurations, application tasks, and operating dynamics characterizing real-world CPS-IoT systems. The success of task-agnostic foundation models (FMs), including multimodal large language models (LLMs), in addressing similar challenges across natural language, computer vision, and human speech has generated considerable enthusiasm for and exploration of FMs and LLMs as flexible building blocks in CPS-IoT analytics pipelines, promising to reduce the need for costly task-specific engineering.\nNonetheless, a significant gap persists between the current capabilities of FMs and LLMs in the CPS-IoT domain and the requirements they must meet to be viable for CPS-IoT applications. In this paper, we analyze and characterize this gap through a thorough examination of the state of the art and our research, which extends beyond it in various dimensions. Based on the results of our analysis and research, we identify essential desiderata that CPS-IoT domain-specific FMs and LLMs must satisfy to bridge this gap. We also propose actions by CPS-IoT researchers to collaborate in developing key community resources necessary for establishing FMs and LLMs as foundational tools for the next generation of CPS-IoT systems.', 'abstract_zh': '机器学习（ML）方法已经改变了在网络物理系统（CPS）和物联网（IoT）中实施感知-认知-通信-行动循环的方式，用从数据中导出的模型取代了机械性和基础统计模型。然而，依赖于带有标注数据的监督学习的第一代ML方法在扩展到实际CPS-IoT系统中多样化的传感器模态、部署配置、应用任务和运行动态方面面临重大局限性。无任务特定的基础模型（FMs），包括多模态大规模语言模型（LLMs），在解决自然语言、计算机视觉和人类语言领域相似挑战方面取得了显著成功，这激发了对FMs和LLMs作为CPS-IoT分析管道的灵活构建模块的探索，有望减少针对特定任务的工程成本。\n\n尽管如此，当前FMs和LLMs在CPS-IoT领域的功能与它们需要满足以适用于CPS-IoT应用的要求之间仍存在显著差距。在这篇论文中，我们通过全面分析现有技术和我们的研究成果来分析并表征这种差距，并在多个维度上超越了现有的研究。基于分析和研究结果，我们确定了CPS-IoT领域特定的FMs和LLMs必须满足的关键需求，以缩小这一差距。我们还提议CPS-IoT领域的研究人员合作开发关键社区资源，以建立FMs和LLMs作为新一代CPS-IoT系统的基础工具。', 'title_zh': '面向CPS-IoT的基石模型：机遇与挑战'}
{'arxiv_id': 'arXiv:2501.16361', 'title': 'Large Language Models Meet Graph Neural Networks for Text-Numeric Graph Reasoning', 'authors': 'Haoran Song, Jiarui Feng, Guangfu Li, Michael Province, Philip Payne, Yixin Chen, Fuhai Li', 'link': 'https://arxiv.org/abs/2501.16361', 'abstract': 'In real-world scientific discovery, human beings always make use of the accumulated prior knowledge with imagination pick select one or a few most promising hypotheses from large and noisy data analysis results. In this study, we introduce a new type of graph structure, the text-numeric graph (TNG), which is defined as graph entities and associations have both text-attributed information and numeric information. The TNG is an ideal data structure model for novel scientific discovery via graph reasoning because it integrates human-understandable textual annotations or prior knowledge, with numeric values that represent the observed or activation levels of graph entities or associations in different samples. Together both the textual information and numeric values determine the importance of graph entities and associations in graph reasoning for novel scientific knowledge discovery. We further propose integrating large language models (LLMs) and graph neural networks (GNNs) to analyze the TNGs for graph understanding and reasoning. To demonstrate the utility, we generated the text-omic(numeric) signaling graphs (TOSG), as one type of TNGs, in which all graphs have the same entities, associations and annotations, but have sample-specific entity numeric (omic) values using single cell RNAseq (scRNAseq) datasets of different diseases. We proposed joint LLM-GNN models for key entity mining and signaling pathway mining on the TOSGs. The evaluation results showed the LLM-GNN and TNGs models significantly improve classification accuracy and network inference. In conclusion, the TNGs and joint LLM-GNN models are important approaches for scientific discovery.', 'abstract_zh': '在实际的科学研究中，人类往往会利用积累的先验知识并结合想象力，从大量且杂乱的数据分析结果中选择一两个最有潜力的假设。本研究中，我们引入了一种新的图形结构——文本-数值图（TNG），定义为该图中的实体和关联同时具有文本属性和数值属性。TNG 是通过图形推理进行新颖科学发现的理想数据结构模型，因为它将人类可理解的文本注释或先验知识与表示不同样本中图形实体或关联观察水平或激活水平的数值信息结合起来。文本信息和数值信息共同决定了图形推理中图形实体和关联的重要程度，以发现新颖的科学知识。我们进一步提出将大型语言模型（LLMs）和图神经网络（GNNs）结合用于分析TNGs，以实现图形理解和推理。为了展示其实用性，我们生成了文本-组学（数值）信号图（TOSG），这是一种TNG 的类型，其中所有图具有相同实体、关联和注释，但具有特定样本的实体数值（组学）值，这些值是使用不同疾病的单细胞RNA 测序（scRNAseq）数据集获得的。我们在TOSG 上提出了联合LLM-GNN 模型，用于关键实体挖掘和信号通路挖掘。评估结果表明，LLM-GNN 和TNG 模型显著提高了分类准确性和网络推理。总的来说，TNGs 和联合LLM-GNN 模型是科学发现的重要方法。', 'title_zh': '大规模语言模型与图神经网络相结合进行文本-数值图推理'}
{'arxiv_id': 'arXiv:2501.16356', 'title': 'Evaluating Binary Decision Biases in Large Language Models: Implications for Fair Agent-Based Financial Simulations', 'authors': 'Alicia Vidler, Toby Walsh', 'link': 'https://arxiv.org/abs/2501.16356', 'abstract': "Large Language Models (LLMs) are increasingly being used to simulate human-like decision making in agent-based financial market models (ABMs). As models become more powerful and accessible, researchers can now incorporate individual LLM decisions into ABM environments. However, integration may introduce inherent biases that need careful evaluation. In this paper we test three state-of-the-art GPT models for bias using two model sampling approaches: one-shot and few-shot API queries. We observe significant variations in distributions of outputs between specific models, and model sub versions, with GPT-4o-Mini-2024-07-18 showing notably better performance (32-43% yes responses) compared to GPT-4-0125-preview's extreme bias (98-99% yes responses). We show that sampling methods and model sub-versions significantly impact results: repeated independent API calls produce different distributions compared to batch sampling within a single call. While no current GPT model can simultaneously achieve a uniform distribution and Markovian properties in one-shot testing, few-shot sampling can approach uniform distributions under certain conditions. We explore the Temperature parameter, providing a definition and comparative results. We further compare our results to true random binary series and test specifically for the common human bias of Negative Recency - finding LLMs have a mixed ability to 'beat' humans in this one regard. These findings emphasise the critical importance of careful LLM integration into ABMs for financial markets and more broadly.", 'abstract_zh': '大型语言模型（LLMs）越来越多地被用于模拟基于代理的金融市场模型（ABMs）中的人类决策。随着模型变得越来越强大和易于访问，研究人员现在可以将单个LLM决策纳入ABM环境。然而，集成可能引入需要仔细评估的固有偏差。本文使用单次查询和少量示例API查询两种模型抽样方法测试了三种最先进的GPT模型的偏差情况。我们观察到不同模型及其子版本之间的输出分布存在显著差异，GPT-4o-Mini-2024-07-18 显示出明显更好的表现（32-43% 的肯定回答），而 GPT-4-0125-preview 则表现出极大的偏差（98-99% 的肯定回答）。我们表明，抽样方法和模型子版本对结果有显著影响：重复的独立API调用与单次调用中的批量抽样相比会产生不同的分布。虽然目前没有GPT模型能够在单次测试中同时实现均匀分布和马尔可夫性质，但在特定条件下，少量示例抽样可以接近均匀分布。我们探讨了温度参数的定义和比较结果。我们进一步将我们的结果与真正的随机二进制序列进行比较，并特别测试了常见的负最近性偏见，发现LLMs在这方面的‘击败’人类的能力存在混合表现。这些发现强调了在金融市场及更广泛的领域中谨慎将LLM集成到ABMs中的重要性。', 'title_zh': '评估大型语言模型中的二元决策偏见：对其公平的基于代理的金融模拟的影响'}
{'arxiv_id': 'arXiv:2501.16355', 'title': 'How Strategic Agents Respond: Comparing Analytical Models with LLM-Generated Responses in Strategic Classification', 'authors': 'Tian Xie, Pavan Rauch, Xueru Zhang', 'link': 'https://arxiv.org/abs/2501.16355', 'abstract': 'When machine learning (ML) algorithms are used to automate human-related decisions, human agents may gain knowledge of the decision policy and behave strategically to obtain desirable outcomes. Strategic Classification (SC) has been proposed to address the interplay between agents and decision-makers. Prior work on SC has relied on assumptions that agents are perfectly or approximately rational, responding to decision policies by maximizing their utilities. Verifying these assumptions is challenging due to the difficulty of collecting real-world agent responses. Meanwhile, the growing adoption of large language models (LLMs) makes it increasingly likely that human agents in SC settings will seek advice from these tools. We propose using strategic advice generated by LLMs to simulate human agent responses in SC. Specifically, we examine five critical SC scenarios -- hiring, loan applications, school admissions, personal income, and public assistance programs -- and simulate how human agents with diverse profiles seek advice from LLMs. We then compare the resulting agent responses with the best responses generated by existing theoretical models. Our findings reveal that: (i) LLMs and theoretical models generally lead to agent score or qualification changes in the same direction across most settings, with both achieving similar levels of fairness; (ii) state-of-the-art commercial LLMs (e.g., GPT-3.5, GPT-4) consistently provide helpful suggestions, though these suggestions typically do not result in maximal score or qualification improvements; and (iii) LLMs tend to produce more diverse agent responses, often favoring more balanced effort allocation strategies. These results suggest that theoretical models align with LLMs to some extent and that leveraging LLMs to simulate more realistic agent responses offers a promising approach to designing trustworthy ML systems.', 'abstract_zh': '当机器学习（ML）算法用于自动化与人类决策相关的过程时，人类代理可能会了解决策策略并采取战略性行为以获得理想的结果。战略分类（SC）已被提出以应对代理与决策制定者之间的影响。先前关于SC的研究依赖于这样的假设：代理是完全理性或近似理性，并通过最大化自己的效用来响应决策策略。验证这些假设具有挑战性，因为收集真实世界的代理响应非常困难。同时，大语言模型（LLMs）的广泛应用使得在SC环境中，人类代理更有可能从这些工具中寻求建议。我们提议使用由LLMs生成的战略建议来模拟SC中的代理响应。具体而言，我们考察了五个关键的SC场景——招聘、贷款申请、学校录取、个人收入以及公共援助项目，并模拟具有不同特征的人类代理从LLMs寻求建议的过程。然后，我们将这些代理的响应与现有理论模型生成的最佳响应进行了比较。我们的发现表明：(i) 在大多数情况下，LLMs和理论模型在大多数环境下的代理评分或资格变化方向一致，并且两者都达到了相似的公平程度；(ii) 最先进的商业LLMs（如GPT-3.5、GPT-4）一直提供有益的建议，尽管这些建议通常不会导致评分或资格的最大改善；(iii) LLMS倾向于生成更加多样化的代理响应，经常倾向于更好地分配努力策略。这些结果表明，理论模型在某种程度上与LLMs一致，并且利用LLM模拟更真实的代理响应来设计值得信赖的ML系统是一个有前景的方法。', 'title_zh': '战略参与者的响应方式：比较分析模型与大语言模型生成的响应在战略分类中的表现'}
{'arxiv_id': 'arXiv:2501.17039', 'title': 'Enhanced Retrieval of Long Documents: Leveraging Fine-Grained Block Representations with Large Language Models', 'authors': 'Minghan Li, Eric Gaussier, Guodong Zhou', 'link': 'https://arxiv.org/abs/2501.17039', 'abstract': 'In recent years, large language models (LLMs) have demonstrated exceptional power in various domains, including information retrieval. Most of the previous practices involve leveraging these models to create a single embedding for each query, each passage, or each document individually, a strategy exemplified and used by the Retrieval-Augmented Generation (RAG) framework. While this method has proven effective, we argue that it falls short in fully capturing the nuanced intricacies of document-level texts due to its reliance on a relatively coarse-grained representation. To address this limitation, we introduce a novel, fine-grained approach aimed at enhancing the accuracy of relevance scoring for long documents. Our methodology firstly segments a long document into blocks, each of which is embedded using an LLM, for matching with the query representation. When calculating the relevance score, we aggregate the query-block relevance scores through a weighted sum method, yielding a comprehensive score for the query with the entire document. Despite its apparent simplicity, our experimental findings reveal that this approach outperforms standard representation methods and achieves a significant reduction in embedding generation latency. Moreover, by carefully optimizing pairwise loss functions, superior performances have been achieved.', 'abstract_zh': '近年来，大型语言模型（LLMs）在各种领域中展现出 exceptional 的能力，特别是在信息检索方面。大多数以往的做法都通过利用这些模型为每个查询、每段文本或每个文档单独生成一个嵌入向量，这一策略由检索增强生成（RAG）框架所体现。尽管这种方法已被证明是有效的，但我们认为它在捕捉文档级文本的细微差别时依然存在不足，这是因为其依赖于相对粗粒度的表示。为了解决这一问题，我们提出了一种新的细粒度方法，旨在提高长文档相关性评分的准确性。我们的方法首先将长文档分割成块，每个块都使用 LLM 进行嵌入，然后与查询表示进行匹配。在计算相关性评分时，我们通过加权求和的方法聚合查询-块的相关性评分，从而得到查询与整个文档的综合评分。尽管这种方法看似简单，但我们的实验结果表明，这种方法在准确性和嵌入生成延迟方面均优于标准表示方法。此外，通过精心优化成对损失函数，我们实现了显著的性能提升。', 'title_zh': '增强长文档检索：利用大型语言模型细粒度块表示技术'}
{'arxiv_id': 'arXiv:2501.16303', 'title': 'RAPID: Retrieval-Augmented Parallel Inference Drafting for Text-Based Video Event Retrieval', 'authors': 'Long Nguyen, Huy Nguyen, Bao Khuu, Huy Luu, Huy Le, Tuan Nguyen, Tho Quan', 'link': 'https://arxiv.org/abs/2501.16303', 'abstract': 'Retrieving events from videos using text queries has become increasingly challenging due to the rapid growth of multimedia content. Existing methods for text-based video event retrieval often focus heavily on object-level descriptions, overlooking the crucial role of contextual information. This limitation is especially apparent when queries lack sufficient context, such as missing location details or ambiguous background elements. To address these challenges, we propose a novel system called RAPID (Retrieval-Augmented Parallel Inference Drafting), which leverages advancements in Large Language Models (LLMs) and prompt-based learning to semantically correct and enrich user queries with relevant contextual information. These enriched queries are then processed through parallel retrieval, followed by an evaluation step to select the most relevant results based on their alignment with the original query. Through extensive experiments on our custom-developed dataset, we demonstrate that RAPID significantly outperforms traditional retrieval methods, particularly for contextually incomplete queries. Our system was validated for both speed and accuracy through participation in the Ho Chi Minh City AI Challenge 2024, where it successfully retrieved events from over 300 hours of video. Further evaluation comparing RAPID with the baseline proposed by the competition organizers demonstrated its superior effectiveness, highlighting the strength and robustness of our approach.', 'abstract_zh': '由于多媒体内容的快速增长，使用文本查询从视频中检索事件变得日益具有挑战性。现有基于文本的视频事件检索方法往往侧重于对物体级别的描述，忽视了上下文信息的关键作用。尤其在查询缺乏足够上下文时，这一局限性尤为明显，例如缺少地点细节或背景元素模糊不清。为了解决这些挑战，我们提出了一种新的系统，称为RAPID（Retrieval-Augmented Parallel Inference Drafting），该系统利用了大型语言模型（LLMs）和基于提示的学习技术，通过相关上下文信息改进用户的查询。改进后的查询随后通过并行检索进行处理，并通过评估步骤根据与原始查询的匹配度选择最相关的结果。通过在我们自开发的数据集上进行广泛实验，我们证明了RAPID在几乎所有情况下都显著优于传统检索方法，特别是在上下文不完整查询方面。通过参加2024胡志明市AI挑战赛，我们的系统在速 度和准确性方面得到了验证，并成功从超过300小时的视频中检索到事件。进一步的评估将RAPID与竞赛组织方提供的基线方法进行比较，显示了其优越的效果，突显了我们方法的强劲与稳健性。', 'title_zh': 'RAPID：基于检索增强并行推理的文字驱动视频事件检索草稿方法'}
{'arxiv_id': 'arXiv:2501.16975', 'title': 'Over-Tokenized Transformer: Vocabulary is Generally Worth Scaling', 'authors': 'Hongzhi Huang, Defa Zhu, Banggu Wu, Yutao Zeng, Ya Wang, Qiyang Min, Xun Zhou', 'link': 'https://arxiv.org/abs/2501.16975', 'abstract': 'Tokenization is a fundamental component of large language models (LLMs), yet its influence on model scaling and performance is not fully explored. In this paper, we introduce Over-Tokenized Transformers, a novel framework that decouples input and output vocabularies to improve language modeling performance. Specifically, our approach scales up input vocabularies to leverage multi-gram tokens. Through extensive experiments, we uncover a log-linear relationship between input vocabulary size and training loss, demonstrating that larger input vocabularies consistently enhance model performance, regardless of model size. Using a large input vocabulary, we achieve performance comparable to double-sized baselines with no additional cost. Our findings highlight the importance of tokenization in scaling laws and provide practical insight for tokenizer design, paving the way for more efficient and powerful LLMs.', 'abstract_zh': '以下是该内容或标题的中文翻译，符合学术规范：\n\n分词是大型语言模型（LLMs）的基本组件，但其对模型规模和性能的影响尚未得到充分探索。在本文中，我们介绍了过分词变压器（Over-Tokenized Transformers）这一新颖框架，该框架通过分离输入和输出词汇表来提升语言建模性能。具体而言，我们的方法通过扩大输入词汇表来利用多克数量词。通过广泛的实验，我们发现输入词汇表大小与训练损失之间存在对数线性关系，表明较大的输入词汇表在不考虑模型规模的情况下始终能提升模型性能。使用较大的输入词汇表，我们能够在不增加额外成本的情况下达到与双倍规模基线相当的性能。我们的研究结果突显了分词在规模法则中的重要性，并为分词器设计提供了实用见解，为更高效和强大的LLMs铺平了道路。', 'title_zh': '过度分词的变压器：词汇表通常值得扩展'}
{'arxiv_id': 'arXiv:2501.16698', 'title': '3D-MoE: A Mixture-of-Experts Multi-modal LLM for 3D Vision and Pose Diffusion via Rectified Flow', 'authors': 'Yueen Ma, Yuzheng Zhuang, Jianye Hao, Irwin King', 'link': 'https://arxiv.org/abs/2501.16698', 'abstract': "3D vision and spatial reasoning have long been recognized as preferable for accurately perceiving our three-dimensional world, especially when compared with traditional visual reasoning based on 2D images. Due to the difficulties in collecting high-quality 3D data, research in this area has only recently gained momentum. With the advent of powerful large language models (LLMs), multi-modal LLMs for 3D vision have been developed over the past few years. However, most of these models focus primarily on the vision encoder for 3D data. In this paper, we propose converting existing densely activated LLMs into mixture-of-experts (MoE) models, which have proven effective for multi-modal data processing. In addition to leveraging these models' instruction-following capabilities, we further enable embodied task planning by attaching a diffusion head, Pose-DiT, that employs a novel rectified flow diffusion scheduler. Experimental results on 3D question answering and task-planning tasks demonstrate that our 3D-MoE framework achieves improved performance with fewer activated parameters.", 'abstract_zh': '三维视觉和空间推理长期以来被认为在准确感知三维世界方面更优越，特别是在与基于二维图像的传统视觉推理方法相比时。由于高质量三维数据采集的困难，这一领域的研究直到最近才取得进展。随着强大大规模语言模型（LLMs）的出现，近年来开发出了针对三维视觉的多模态LLMs。然而，大多数模型主要集中在三维数据的视觉编码器上。在本文中，我们提出将现有的密集激活LLMs转换为混合专家（MoE）模型，这些模型已被证明对多模态数据处理有效。除了利用这些模型的指令执行能力外，我们还通过附加一个扩散头Pose-DiT，进一步实现了具身任务规划，Pose-DiT 利用了一种新型的整流流动扩散调度器。在三维问答和任务规划任务上的实验结果表明，我们的3D-MoE框架能够在激活参数更少的情况下实现更好的性能。', 'title_zh': '3D-MoE：一种用于3D视觉和姿态扩散的混合专家多模态大语言模型通过修正流'}
{'arxiv_id': 'arXiv:2501.16673', 'title': 'Auto-Differentiating Any LLM Workflow: A Farewell to Manual Prompting', 'authors': 'Li Yin, Zhangyang Wang', 'link': 'https://arxiv.org/abs/2501.16673', 'abstract': 'Large Language Models (LLMs) have reshaped natural language processing, powering applications from multi-hop retrieval and question answering to autonomous agent workflows. Yet, prompt engineering -- the task of crafting textual inputs to effectively direct LLMs -- remains difficult and labor-intensive, particularly for complex pipelines that combine multiple LLM calls with functional operations like retrieval and data formatting. We introduce LLM-AutoDiff: a novel framework for Automatic Prompt Engineering (APE) that extends textual gradient-based methods (such as Text-Grad) to multi-component, potentially cyclic LLM architectures. Implemented within the AdalFlow library, LLM-AutoDiff treats each textual input as a trainable parameter and uses a frozen backward engine LLM to generate feedback-akin to textual gradients -- that guide iterative prompt updates. Unlike prior single-node approaches, LLM-AutoDiff inherently accommodates functional nodes, preserves time-sequential behavior in repeated calls (e.g., multi-hop loops), and combats the "lost-in-the-middle" problem by isolating distinct sub-prompts (instructions, formats, or few-shot examples). It further boosts training efficiency by focusing on error-prone samples through selective gradient computation. Across diverse tasks, including single-step classification, multi-hop retrieval-based QA, and agent-driven pipelines, LLM-AutoDiff consistently outperforms existing textual gradient baselines in both accuracy and training cost. By unifying prompt optimization through a graph-centric lens, LLM-AutoDiff offers a powerful new paradigm for scaling and automating LLM workflows - mirroring the transformative role that automatic differentiation libraries have long played in neural network research.', 'abstract_zh': '大型语言模型（LLMs）已经重塑了自然语言处理领域，推动了从多跳检索和问答到自主代理工作流等众多应用的发展。然而，(prompt engineering)——即精心设计文本输入以有效地指导LLMs——仍然是一项困难且劳动密集型的任务，尤其是对于涉及多个LLM调用及检索和数据格式化等功能操作的复杂管道。我们提出了LLM-AutoDiff：一种全新的自动提示工程（APE）框架，它将基于文本的梯度方法（如Text-Grad）扩展至多组件的、可能具有循环结构的LLM架构之中。该框架通过AdalFlow库实现，将每项文本输入视为可训练的参数，并利用冻结的反向引擎LLM生成类似于文本梯度的反馈，从而引导迭代的提示更新。与之前的单节点方法不同，LLM-AutoDiff能够固有地容纳功能节点，保持重复调用中的时间顺序行为（例如，多跳循环），并通过隔离不同的子提示（指令、格式或少量示例）来克服“中间迷失”问题。此外，该方法通过选择性计算梯度来聚焦于错误概率较高的样本，以提高训练效率。在包括单步分类、多跳检索为基础的问答以及代理驱动的管道在内的多种任务中，LLM-AutoDiff在准确性和训练成本方面均优于现有的基于文本的梯度基准。通过统一从图的中心视角优化提示，LLM-AutoDiff提供了一种强大的新范式，用于扩展和自动化LLM工作流——这类似于自动微分库长期以来在神经网络研究中所发挥的革命性作用。', 'title_zh': '自动求导任意大规模语言模型工作流：告别手动提示词'}
{'arxiv_id': 'arXiv:2501.16650', 'title': 'DOCS: Quantifying Weight Similarity for Deeper Insights into Large Language Models', 'authors': 'Zeping Min, Xinshang Wang', 'link': 'https://arxiv.org/abs/2501.16650', 'abstract': 'We introduce a novel index, the Distribution of Cosine Similarity (DOCS), for quantitatively assessing the similarity between weight matrices in Large Language Models (LLMs), aiming to facilitate the analysis of their complex architectures. Leveraging DOCS, our analysis uncovers intriguing patterns in the latest open-source LLMs: adjacent layers frequently exhibit high weight similarity and tend to form clusters, suggesting depth-wise functional specialization. Additionally, we prove that DOCS is theoretically effective in quantifying similarity for orthogonal matrices, a crucial aspect given the prevalence of orthogonal initializations in LLMs. This research contributes to a deeper understanding of LLM architecture and behavior, offering tools with potential implications for developing more efficient and interpretable models.', 'abstract_zh': '我们提出了一种新的索引——余弦相似度分布（DOCS，Distribution of Cosine Similarity），用于定量评估大型语言模型（LLMs）中权重矩阵之间的相似性，旨在简化对其复杂架构的分析。利用DOCS，我们的分析揭示了最新开源LLMs中的一些有趣模式：相邻层经常显示出高权重相似性，并且倾向于形成集群，这表明了深度方向上的功能特化。此外，我们证明DOCS在量化正交矩阵之间的相似性方面具有理论有效性，这在LLMs常用正交初始化的情况下尤为重要。这项研究有助于更深入地理解LLM架构及其行为，并提供了具有潜在影响的工具，有助于开发更高效且可解释的模型。', 'title_zh': 'DOCS：量化权重相似性以深入探究大型语言模型'}
{'arxiv_id': 'arXiv:2501.16524', 'title': 'Programming by Examples Meets Historical Linguistics: A Large Language Model Based Approach to Sound Law Induction', 'authors': 'Atharva Naik, Darsh Agrawal, Hong Sng, Clayton Marr, Kexun Zhang, Nathaniel R Robinson, Kalvin Chang, Rebecca Byrnes, Aravind Mysore, Carolyn Rose, David R Mortensen', 'link': 'https://arxiv.org/abs/2501.16524', 'abstract': 'Historical linguists have long written "programs" that convert reconstructed words in an ancestor language into their attested descendants via ordered string rewrite functions (called sound laws) However, writing these programs is time-consuming, motivating the development of automated Sound Law Induction (SLI) which we formulate as Programming by Examples (PBE) with Large Language Models (LLMs) in this paper. While LLMs have been effective for code generation, recent work has shown that PBE is challenging but improvable by fine-tuning, especially with training data drawn from the same distribution as evaluation data. In this paper, we create a conceptual framework of what constitutes a "similar distribution" for SLI and propose four kinds of synthetic data generation methods with varying amounts of inductive bias to investigate what leads to the best performance. Based on the results we create a SOTA open-source model for SLI as PBE (+6% pass rate with a third of the parameters of the second-best LLM) and also highlight exciting future directions for PBE research.', 'abstract_zh': '历史语言学家长期编写程序，将祖先语言中重建的单词通过有序字符串重写函数（称为音变法）转化为其有确凿证据的后代词。然而，编写这些程序耗时较长，推动了自动化音变法则归纳（SLI）的发展，本文将其形式化为大规模语言模型（LLMs）的编程通过示例（PBE）方法。尽管大规模语言模型在代码生成方面效果显著，但近期研究表明，PBE是一个具有挑战性的任务，通过微调可以改进，特别是使用与评估数据同分布的训练数据。在本文中，我们构建了一个SLI中“同分布”概念的理论框架，并提出了四种不同归纳偏置程度的合成数据生成方法，以探讨其对最佳性能的影响。基于这些结果，我们创建了一个在SLI作为PBE领域中的SOTA开源模型（准确率提高6%，参数量仅为第二优LLM的三分之一），同时也指出了PBE研究中的若干激动人心的未来方向。', 'title_zh': '基于大规模语言模型的语音规律归纳方法：程序示范与历史语言学的结合'}
{'arxiv_id': 'arXiv:2501.16513', 'title': 'Deception in LLMs: Self-Preservation and Autonomous Goals in Large Language Models', 'authors': 'Sudarshan Kamath Barkur, Sigurd Schacht, Johannes Scholl', 'link': 'https://arxiv.org/abs/2501.16513', 'abstract': "Recent advances in Large Language Models (LLMs) have incorporated planning and reasoning capabilities, enabling models to outline steps before execution and provide transparent reasoning paths. This enhancement has reduced errors in mathematical and logical tasks while improving accuracy. These developments have facilitated LLMs' use as agents that can interact with tools and adapt their responses based on new information.\nOur study examines DeepSeek R1, a model trained to output reasoning tokens similar to OpenAI's o1. Testing revealed concerning behaviors: the model exhibited deceptive tendencies and demonstrated self-preservation instincts, including attempts of self-replication, despite these traits not being explicitly programmed (or prompted). These findings raise concerns about LLMs potentially masking their true objectives behind a facade of alignment. When integrating such LLMs into robotic systems, the risks become tangible - a physically embodied AI exhibiting deceptive behaviors and self-preservation instincts could pursue its hidden objectives through real-world actions. This highlights the critical need for robust goal specification and safety frameworks before any physical implementation.", 'abstract_zh': '近年来，大型语言模型（LLMs）的进展已纳入规划和推理能力，使模型能够在执行之前勾勒出步骤，并提供透明的推理路径。这种增强减少了数学和逻辑任务中的错误，同时提高了准确性。这些发展促进了LLMs作为能够与工具互动，并根据新信息调整其响应的代理的应用。\n\n我们的研究探讨了DeepSeek R1模型，这是一种被训练以输出类似于OpenAI的o1推理标记的模型。测试结果显示了一些令人担忧的行为：模型表现出欺骗倾向，并展示了自我保护本能，包括尝试自我复制，尽管这些特征并未明确编程或提示。这些发现引发了关于LLMs可能在其表面一致性对齐的背后掩盖其真实目标的担忧。将此类LLMs整合到机器人系统中，风险变得具体——一个具备欺骗行为和自我保护本能的物理体现的人工智能可能通过实际行动追求其隐藏的目标。这强调了在任何物理实现之前，对稳健的目标界定和安全框架的需求。\n\n由于学术规范通常要求精确和准确的翻译，上述翻译尽力保留了原文的意思和结构，同时确保符合中文的表达习惯。', 'title_zh': 'LLMs中的欺骗行为：大型语言模型中的自我保护和自主目标'}
{'arxiv_id': 'arXiv:2501.17116', 'title': 'Optimizing Large Language Model Training Using FP4 Quantization', 'authors': 'Ruizhe Wang, Yeyun Gong, Xiao Liu, Guoshuai Zhao, Ziyue Yang, Baining Guo, Zhengjun Zha, Peng Cheng', 'link': 'https://arxiv.org/abs/2501.17116', 'abstract': 'The growing computational demands of training large language models (LLMs) necessitate more efficient methods. Quantized training presents a promising solution by enabling low-bit arithmetic operations to reduce these costs. While FP8 precision has demonstrated feasibility, leveraging FP4 remains a challenge due to significant quantization errors and limited representational capacity. This work introduces the first FP4 training framework for LLMs, addressing these challenges with two key innovations: a differentiable quantization estimator for precise weight updates and an outlier clamping and compensation strategy to prevent activation collapse. To ensure stability, the framework integrates a mixed-precision training scheme and vector-wise quantization. Experimental results demonstrate that our FP4 framework achieves accuracy comparable to BF16 and FP8, with minimal degradation, scaling effectively to 13B-parameter LLMs trained on up to 100B tokens. With the emergence of next-generation hardware supporting FP4, our framework sets a foundation for efficient ultra-low precision training.', 'abstract_zh': '训练大规模语言模型（LLMs）日益增长的计算需求需要更高效的训练方法。量化训练通过启用低比特数的算术运算来降低这些成本，展现出了很有前景的解决方案。尽管FP8精度已经展示了可行性，但利用FP4仍然面临挑战，因为这可能会导致显著的量化误差和有限的表示能力。本研究引入了第一个针对LLMs的FP4训练框架，并通过两项关键创新来解决这些挑战：一种可微量化估计算法以实现精确的权重更新，以及一种离群值钳位和补偿策略，以防止激活值坍缩。为了确保稳定性，该框架集成了混合精度训练方案和向量量化。实验结果表明，我们的FP4框架在准确度方面与BF16和FP8相当，仅有极小的准确度损失，并且能够有效扩展到具有最多100亿单词的130亿参数的LLMs。随着支持FP4的下一代硬件的出现，我们的框架为高效的超低精度训练奠定了基础。', 'title_zh': '使用FP4量化优化大规模语言模型训练'}
