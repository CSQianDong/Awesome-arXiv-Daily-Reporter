{'arxiv_id': 'arXiv:2412.15177', 'title': 'Critical-Questions-of-Thought: Steering LLM reasoning with Argumentative Querying', 'authors': 'Federico Castagna, Isabel Sassoon, Simon Parsons', 'link': 'https://arxiv.org/abs/2412.15177', 'abstract': "Studies have underscored how, regardless of the recent breakthrough and swift advances in AI research, even state-of-the-art Large Language models (LLMs) continue to struggle when performing logical and mathematical reasoning. The results seem to suggest that LLMs still work as (highly advanced) data pattern identifiers, scoring poorly when attempting to generalise and solve reasoning problems the models have never previously seen or that are not close to samples presented in their training data. To address this compelling concern, this paper makes use of the notion of critical questions from the literature on argumentation theory, focusing in particular on Toulmin's model of argumentation. We show that employing these critical questions can improve the reasoning capabilities of LLMs. By probing the rationale behind the models' reasoning process, the LLM can assess whether some logical mistake is occurring and correct it before providing the final reply to the user prompt. The underlying idea is drawn from the gold standard of any valid argumentative procedure: the conclusion is valid if it is entailed by accepted premises. Or, to paraphrase such Aristotelian principle in a real-world approximation, characterised by incomplete information and presumptive logic, the conclusion is valid if not proved otherwise. This approach successfully steers the models' output through a reasoning pipeline, resulting in better performance against the baseline and its Chain-of-Thought (CoT) implementation. To this end, an extensive evaluation of the proposed approach on the MT-Bench Reasoning and Math tasks across a range of LLMs is provided.", 'abstract_zh': '研究表明，尽管最近在人工智能（AI）研究领域取得了突破性进展，最先进的大规模语言模型（LLMs）在进行逻辑和数学推理时仍然存在困难。结果显示，即使是最先进的LLMs仍主要充当（高度先进的）数据模式识别器，当尝试解决训练数据中未出现或与之相去甚远的推理问题时，其泛化能力较差。为应对这一紧迫的挑战，本文借鉴论证理论文献中的“关键问题”概念，并特别关注于托马斯·库恩（Toulmin）的论证模型。我们证明，使用这些关键问题可以提高LLMs的推理能力。通过探究模型推理过程的理由，LLMs可以评估是否有逻辑错误发生，并在向用户提供最终答复之前进行纠正。这一理念源自任何有效论证程序的黄金标准：如果结论是由公认的前提所蕴含的，那么结论就是有效的。或者，如亚里士多德原则在现实世界中的近似表述，在信息不完整且预设逻辑的情况下，如果未被反驳，则结论是有效的。这种方法成功地引导模型输出通过推理管道，使其相对于基线及其链式思维（CoT）实现表现更好。为此，我们提供了对MT-Bench推理和数学任务的广泛评估，涵盖多种不同类型的LLMs。', 'title_zh': '关键问题思考：通过论辩性查询引导大规模语言模型的推理'}
{'arxiv_id': 'arXiv:2412.15135', 'title': 'Probabilistic Strategy Logic with Degrees of Observability', 'authors': 'Chunyan Mu, Nima Motamed, Natasha Alechina, Brian Logan', 'link': 'https://arxiv.org/abs/2412.15135', 'abstract': "There has been considerable work on reasoning about the strategic ability of agents under imperfect information. However, existing logics such as Probabilistic Strategy Logic are unable to express properties relating to information transparency. Information transparency concerns the extent to which agents' actions and behaviours are observable by other agents. Reasoning about information transparency is useful in many domains including security, privacy, and decision-making. In this paper, we present a formal framework for reasoning about information transparency properties in stochastic multi-agent systems. We extend Probabilistic Strategy Logic with new observability operators that capture the degree of observability of temporal properties by agents. We show that the model checking problem for the resulting logic is decidable.", 'abstract_zh': '在不完美信息条件下代理的策略能力推理方面已有大量研究工作。然而，现有的逻辑如概率策略逻辑无法表达与信息透明度相关的性质。信息透明度关注代理的行动和行为被其他代理观察到的程度。在安全、隐私和决策制定等领域中，对信息透明度的推理是很有用的。本文提出了一种形式框架，用于在随机多代理系统中推理信息透明度性质。我们扩展了概率策略逻辑，加入新的可观察性操作符，以捕捉代理对时间属性可观察程度的表达。我们证明了所得到逻辑的模型检查问题是可判定的。', 'title_zh': '概率策略逻辑与观测度量'}
{'arxiv_id': 'arXiv:2412.15114', 'title': 'Towards Friendly AI: A Comprehensive Review and New Perspectives on Human-AI Alignment', 'authors': 'Qiyang Sun, Yupei Li, Emran Alturki, Sunil Munthumoduku Krishna Murthy, Björn W. Schuller', 'link': 'https://arxiv.org/abs/2412.15114', 'abstract': 'As Artificial Intelligence (AI) continues to advance rapidly, Friendly AI (FAI) has been proposed to advocate for more equitable and fair development of AI. Despite its importance, there is a lack of comprehensive reviews examining FAI from an ethical perspective, as well as limited discussion on its potential applications and future directions. This paper addresses these gaps by providing a thorough review of FAI, focusing on theoretical perspectives both for and against its development, and presenting a formal definition in a clear and accessible format. Key applications are discussed from the perspectives of eXplainable AI (XAI), privacy, fairness and affective computing (AC). Additionally, the paper identifies challenges in current technological advancements and explores future research avenues. The findings emphasise the significance of developing FAI and advocate for its continued advancement to ensure ethical and beneficial AI development.', 'abstract_zh': '随着人工智能（AI）的快速发展，友好人工智能（FAI）的概念已被提出，旨在促进更加公平和公正的AI发展。尽管FAI的重要性不言而喻，但缺乏从道德角度进行全面审视的研究，关于其潜在应用和未来发展方向的讨论也非常有限。本文通过提供对FAI的全面回顾，填补了这些空白，重点关注支持和发展FAI的理论视角，并以清晰易懂的方式提出正式定义。本文还从可解释人工智能（XAI）、隐私、公平性和情感计算（AC）的角度讨论了关键应用。此外，本文指出了当前技术进步中的挑战，并探讨了未来的研究方向。研究结果强调了开发FAI的重要性，并倡导继续推进FAI的发展，以确保道德和有益的AI发展。', 'title_zh': '亲和人工智能：人类-人工智能一致性的综合review与新视角'}
{'arxiv_id': 'arXiv:2412.14950', 'title': 'Generalizing Constraint Models in Constraint Acquisition', 'authors': 'Dimos Tsouros, Senne Berden, Steven Prestwich, Tias Guns', 'link': 'https://arxiv.org/abs/2412.14950', 'abstract': 'Constraint Acquisition (CA) aims to widen the use of constraint programming by assisting users in the modeling process. However, most CA methods suffer from a significant drawback: they learn a single set of individual constraints for a specific problem instance, but cannot generalize these constraints to the parameterized constraint specifications of the problem. In this paper, we address this limitation by proposing GenCon, a novel approach to learn parameterized constraint models capable of modeling varying instances of the same problem. To achieve this generalization, we make use of statistical learning techniques at the level of individual constraints. Specifically, we propose to train a classifier to predict, for any possible constraint and parameterization, whether the constraint belongs to the problem. We then show how, for some classes of classifiers, we can extract decision rules to construct interpretable constraint specifications. This enables the generation of ground constraints for any parameter instantiation. Additionally, we present a generate-and-test approach that can be used with any classifier, to generate the ground constraints on the fly. Our empirical results demonstrate that our approach achieves high accuracy and is robust to noise in the input instances.', 'abstract_zh': '约束获取（CA）旨在通过协助用户建模过程来扩大约束编程的应用范围。然而，大多数CA方法存在一个显著的缺陷：它们为特定问题实例学习了一组单独的约束，但无法将这些约束泛化为问题的参数化约束规范。本文通过提出GenCon，一种学习参数化约束模型的新方法，从而解决了这一限制，该模型能够建模同一问题的不同实例。为了实现这一泛化，我们利用统计学习技术在单个约束级别上进行操作。具体来说，我们提出训练一个分类器，用于预测任何可能的约束和参数化组合是否属于问题。然后，我们展示了对于某些类别的分类器，我们可以通过提取决策规则来构建可解释的约束规范，从而能够为任何参数化实例生成基础约束。此外，我们还提出了一种生成-检验方法，可以与任何分类器结合使用，以实时生成基础约束。我们的实验证明，该方法具有高准确度，并且对输入实例中的噪声具有鲁棒性。', 'title_zh': '在约束获取中推广约束模型'}
{'arxiv_id': 'arXiv:2412.14814', 'title': 'Answer Set Networks: Casting Answer Set Programming into Deep Learning', 'authors': 'Arseny Skryagin, Daniel Ochs, Phillip Deibert, Simon Kohaut, Devendra Singh Dhami, Kristian Kersting', 'link': 'https://arxiv.org/abs/2412.14814', 'abstract': 'Although Answer Set Programming (ASP) allows constraining neural-symbolic (NeSy) systems, its employment is hindered by the prohibitive costs of computing stable models and the CPU-bound nature of state-of-the-art solvers. To this end, we propose Answer Set Networks (ASN), a NeSy solver. Based on Graph Neural Networks (GNN), ASNs are a scalable approach to ASP-based Deep Probabilistic Logic Programming (DPPL). Specifically, we show how to translate ASPs into ASNs and demonstrate how ASNs can efficiently solve the encoded problem by leveraging GPU\'s batching and parallelization capabilities. Our experimental evaluations demonstrate that ASNs outperform state-of-the-art CPU-bound NeSy systems on multiple tasks. Simultaneously, we make the following two contributions based on the strengths of ASNs. Namely, we are the first to show the finetuning of Large Language Models (LLM) with DPPLs, employing ASNs to guide the training with logic. Further, we show the "constitutional navigation" of drones, i.e., encoding public aviation laws in an ASN for routing Unmanned Aerial Vehicles in uncertain environments.', 'abstract_zh': '尽管回答集编程（Answer Set Programming，ASP）能够约束神经符号（NeSy）系统，但计算稳定模型的成本高昂且最先进的求解器是CPU密集型的，这对ASP的运用构成了阻碍。为此，我们提出了一种名为回答集网络（Answer Set Networks，ASN）的NeSy求解器。基于图神经网络（Graph Neural Networks，GNN），ASN是一种基于ASP的深度概率逻辑编程（Deep Probabilistic Logic Programming，DPPL）的可扩展方法。具体而言，我们展示了如何将ASP转换为ASN，并通过利用GPU的批量处理和并行化能力，展示了ASN如何高效地解决编码问题。我们的实验评估表明，与最先进的CPU密集型NeSy系统相比，ASN在多个任务上表现出色。此外，我们基于ASN的强点做出以下两项贡献。首先，我们首次展示了使用DPPL微调大语言模型（Large Language Models，LLM），并利用ASN以逻辑为指导进行训练；其次，我们展示了无人机的“宪法导航”，即通过将公共航空法律编码在ASN中，实现无人驾驶航空器在不确定环境中的路径规划。', 'title_zh': '回答集网络：将回答集编程融入深度学习'}
{'arxiv_id': 'arXiv:2412.14728', 'title': 'LTLf Synthesis Under Unreliable Input', 'authors': 'Christian Hagemeier, Giuseppe de Giacomo, Moshe Y. Vardi', 'link': 'https://arxiv.org/abs/2412.14728', 'abstract': 'We study the problem of realizing strategies for an LTLf goal specification while ensuring that at least an LTLf backup specification is satisfied in case of unreliability of certain input variables. We formally define the problem and characterize its worst-case complexity as 2EXPTIME-complete, like standard LTLf synthesis. Then we devise three different solution techniques: one based on direct automata manipulation, which is 2EXPTIME, one disregarding unreliable input variables by adopting a belief construction, which is 3EXPTIME, and one leveraging second-order quantified LTLf (QLTLf), which is 2EXPTIME and allows for a direct encoding into monadic second-order logic, which in turn is worst-case nonelementary. We prove their correctness and evaluate them against each other empirically. Interestingly, theoretical worst-case bounds do not translate into observed performance; the MSO technique performs best, followed by belief construction and direct automata manipulation. As a byproduct of our study, we provide a general synthesis procedure for arbitrary QLTLf specifications.', 'abstract_zh': '我们研究了在某些输入变量不可靠的情况下，实现LTLf目标规范的同时，至少能确保满足一个LTLf备用规范的问题。我们正式定义了该问题，并将其最坏情况的复杂性归类为2EXPTIME-完全，类似于标准LTLf综合。然后我们提出了三种不同的解决方案：一种基于直接自动机操作的方法，复杂度为2EXPTIME；一种通过信念构建忽略不可靠的输入变量，其复杂度为3EXPTIME；一种利用量化LTLf（QLTLf），其复杂度同样为2EXPTIME，并允许直接编码到单态量化逻辑中，后者最坏情况下的复杂性是非元素阶的。我们证明了这些解决方案的正确性，并通过实验评估了它们之间的性能。有趣的是，理论上的最坏情况界并不反映实际性能；单态量化逻辑（MSO）技术表现最佳，其次是信念构建和直接自动机操作。作为研究的副产品，我们提供了一种通用的QLTLf规范综合方法。', 'title_zh': '在不可靠输入下的LTLf合成'}
{'arxiv_id': 'arXiv:2412.14708', 'title': 'Creation of AI-driven Smart Spaces for Enhanced Indoor Environments -- A Survey', 'authors': 'Aygün Varol, Naser Hossein Motlagh, Mirka Leino, Sasu Tarkoma, Johanna Virkki', 'link': 'https://arxiv.org/abs/2412.14708', 'abstract': 'Smart spaces are ubiquitous computing environments that integrate diverse sensing and communication technologies to enhance space functionality, optimize energy utilization, and improve user comfort and well-being. The integration of emerging AI methodologies into these environments facilitates the formation of AI-driven smart spaces, which further enhance functionalities of the spaces by enabling advanced applications such as personalized comfort settings, interactive living spaces, and automatization of the space systems, all resulting in enhanced indoor experiences of the users. In this paper, we present a systematic survey of existing research on the foundational components of AI-driven smart spaces, including sensor technologies, data communication protocols, sensor network management and maintenance strategies, as well as the data collection, processing and analytics. Given the pivotal role of AI in establishing AI-powered smart spaces, we explore the opportunities and challenges associated with traditional machine learning (ML) approaches, such as deep learning (DL), and emerging methodologies including large language models (LLMs). Finally, we provide key insights necessary for the development of AI-driven smart spaces, propose future research directions, and sheds light on the path forward.', 'abstract_zh': '智能空间是集成了多种传感和通信技术的无处不在的计算环境，旨在增强空间功能、优化能源利用并提升用户舒适度和福祉。将新兴的人工智能方法集成到这些环境中，促进了人工智能驱动的智能空间的形成，从而通过实现个性化舒适设置、互动生活空间以及空间系统的自动化等高级应用，进一步增强了空间功能，最终提升了用户的室内体验。在本文中，我们系统地概述了人工智能驱动智能空间的基础组成部分，包括传感器技术、数据通信协议、传感器网络管理与维护策略，以及数据采集、处理和分析。鉴于人工智能在建立人工智能赋能智能空间中的关键作用，我们探讨了传统机器学习（ML）方法，如深度学习（DL），以及新兴方法，如大规模语言模型（LLMs）所面临的机会与挑战。最后，我们提供了关于人工智能驱动智能空间发展所需的关键见解，提出了未来的研究方向，并指明了前进的道路。', 'title_zh': '基于人工智能驱动的智能空间创建以提升室内环境——综述'}
{'arxiv_id': 'arXiv:2412.14684', 'title': 'Bel Esprit: Multi-Agent Framework for Building AI Model Pipelines', 'authors': 'Yunsu Kim, AhmedElmogtaba Abdelaziz, Thiago Castro Ferreira, Mohamed Al-Badrashiny, Hassan Sawaf', 'link': 'https://arxiv.org/abs/2412.14684', 'abstract': 'As the demand for artificial intelligence (AI) grows to address complex real-world tasks, single models are often insufficient, requiring the integration of multiple models into pipelines. This paper introduces Bel Esprit, a conversational agent designed to construct AI model pipelines based on user-defined requirements. Bel Esprit employs a multi-agent framework where subagents collaborate to clarify requirements, build, validate, and populate pipelines with appropriate models. We demonstrate the effectiveness of this framework in generating pipelines from ambiguous user queries, using both human-curated and synthetic data. A detailed error analysis highlights ongoing challenges in pipeline construction. Bel Esprit is available for a free trial at this https URL.', 'abstract_zh': '随着对人工智能（AI）需求的增长，以解决复杂的现实世界任务，单一模型往往不足以应对，因此需要将多个模型整合到管道中。本文介绍了一种名为Bel Esprit的对话型代理，它旨在根据用户定义的要求构建AI模型管道。Bel Esprit采用多代理框架，其中子代理协作以澄清要求、构建、验证并用合适的模型填充管道。我们通过使用人类精选和合成数据展示了该框架在从模糊用户查询中生成管道方面的有效性。详细的错误分析指出了管道构建过程中仍存在的挑战。Bel Esprit可以在以下网址免费试用：[此处填写网址]。', 'title_zh': 'Bel Esprit：多agent框架构建AI模型流水线'}
{'arxiv_id': 'arXiv:2412.14515', 'title': 'Relational Programming with Foundation Models', 'authors': 'Ziyang Li, Jiani Huang, Jason Liu, Felix Zhu, Eric Zhao, William Dodds, Neelay Velingker, Rajeev Alur, Mayur Naik', 'link': 'https://arxiv.org/abs/2412.14515', 'abstract': 'Foundation models have vast potential to enable diverse AI applications. The powerful yet incomplete nature of these models has spurred a wide range of mechanisms to augment them with capabilities such as in-context learning, information retrieval, and code interpreting. We propose Vieira, a declarative framework that unifies these mechanisms in a general solution for programming with foundation models. Vieira follows a probabilistic relational paradigm and treats foundation models as stateless functions with relational inputs and outputs. It supports neuro-symbolic applications by enabling the seamless combination of such models with logic programs, as well as complex, multi-modal applications by streamlining the composition of diverse sub-models. We implement Vieira by extending the Scallop compiler with a foreign interface that supports foundation models as plugins. We implement plugins for 12 foundation models including GPT, CLIP, and SAM. We evaluate Vieira on 9 challenging tasks that span language, vision, and structured and vector databases. Our evaluation shows that programs in Vieira are concise, can incorporate modern foundation models, and have comparable or better accuracy than competitive baselines.', 'abstract_zh': '基础模型具有广泛潜力，可推动多种人工智能应用的发展。这些模型虽然强大但并不完整，这激发了各种机制以增强其功能，如上下文学习、信息检索和代码解释。我们提出了一种名为Vieira的声明性框架，该框架将这些机制统一在一个通用解决方案中，用于在基础模型上进行编程。Vieira遵循概率关系范式，并将基础模型视为无状态函数，具有关系型输入和输出。该框架通过使神经符号应用成为可能，从而能够无缝结合这些模型与逻辑程序，以及通过简化多种子模型的组合来支持复杂、多模态应用。\n\n我们通过在Scallop编译器中扩展一个对外接口来实现Vieira，该接口支持将基础模型作为插件。我们为此实现了12个基础模型的插件，包括GPT、CLIP和SAM。我们对Vieira进行了评估，涉及9个跨语言、视觉和结构化及向量数据库的挑战性任务。评估结果表明，Vieira中的程序简洁、能够融合现代基础模型，并且在准确度上与竞争性基线相当或更好。', 'title_zh': '使用基础模型进行关系编程'}
{'arxiv_id': 'arXiv:2412.14500', 'title': 'The Digital Ecosystem of Beliefs: does evolution favour AI over humans?', 'authors': 'David M. Bossens, Shanshan Feng, Yew-Soon Ong', 'link': 'https://arxiv.org/abs/2412.14500', 'abstract': "As AI systems are integrated into social networks, there are AI safety concerns that AI-generated content may dominate the web, e.g. in popularity or impact on this http URL understand such questions, this paper proposes the Digital Ecosystem of Beliefs (Digico), the first evolutionary framework for controlled experimentation with multi-population interactions in simulated social networks. The framework models a population of agents which change their messaging strategies due to evolutionary updates following a Universal Darwinism approach, interact via messages, influence each other's beliefs through dynamics based on a contagion model, and maintain their beliefs through cognitive Lamarckian inheritance. Initial experiments with an abstract implementation of Digico show that: a) when AIs have faster messaging, evolution, and more influence in the recommendation algorithm, they get 80% to 95% of the views, depending on the size of the influence benefit; b) AIs designed for propaganda can typically convince 50% of humans to adopt extreme beliefs, and up to 85% when agents believe only a limited number of channels; c) a penalty for content that violates agents' beliefs reduces propaganda effectiveness by up to 8%. We further discuss implications for control (e.g. legislation) and Digico as a means of studying evolutionary principles.", 'abstract_zh': '随着人工智能系统被整合到社交网络中，人们开始关注AI安全问题，例如AI生成的内容可能在受欢迎程度或影响力上占据主导地位。为进一步理解和探讨这些问题，本文提出了数字信念生态系统（Digico）框架，这是首个用于在模拟社交网络中进行多人群体交互受控实验的演化框架。该框架通过普遍达尔文主义方法模拟了一种群体实体，这些实体由于进化更新而调整其消息策略，通过消息进行交互，在基于传染病模型的动力学基础上互相影响信念，并通过认知拉马克式遗传维持其信念。\n\n初步实验表明：a) 当AI的信息传输、进化速度更快，并在推荐算法中具有更大影响力时，它们可以获得80%到95%的浏览量，具体比例取决于影响力收益的大小；b) 设计用于宣传的AI通常可以说服50%的人类采用极端信念，当代理只相信有限数量的渠道时，这个比例可以达到85%；c) 对违反代理信念的内容进行惩罚可使宣传活动的有效性降低8%。\n\n此外，本文还讨论了Digico框架对于控制（例如立法）的影响及其作为研究进化原则手段的作用。', 'title_zh': '信念数字生态系统：人工智能会取代人类吗？'}
{'arxiv_id': 'arXiv:2412.14492', 'title': 'FaultExplainer: Leveraging Large Language Models for Interpretable Fault Detection and Diagnosis', 'authors': 'Abdullah Khan, Rahul Nahar, Hao Chen, Gonzalo E. Constante Flores, Can Li', 'link': 'https://arxiv.org/abs/2412.14492', 'abstract': "Machine learning algorithms are increasingly being applied to fault detection and diagnosis (FDD) in chemical processes. However, existing data-driven FDD platforms often lack interpretability for process operators and struggle to identify root causes of previously unseen faults. This paper presents FaultExplainer, an interactive tool designed to improve fault detection, diagnosis, and explanation in the Tennessee Eastman Process (TEP). FaultExplainer integrates real-time sensor data visualization, Principal Component Analysis (PCA)-based fault detection, and identification of top contributing variables within an interactive user interface powered by large language models (LLMs). We evaluate the LLMs' reasoning capabilities in two scenarios: one where historical root causes are provided, and one where they are not to mimic the challenge of previously unseen faults. Experimental results using GPT-4o and o1-preview models demonstrate the system's strengths in generating plausible and actionable explanations, while also highlighting its limitations, including reliance on PCA-selected features and occasional hallucinations.", 'abstract_zh': '机器学习算法在化工过程的故障检测与诊断（FDD）中得到了越来越多的应用。然而，现有的数据驱动的FDD平台往往缺乏工艺操作人员可解释性，并且难以识别未见故障的根本原因。本文提出了一种名为FaultExplainer的交互式工具，旨在改善泰勒纳曼过程（TEP）中的故障检测、诊断和解释。FaultExplainer将实时传感器数据可视化、基于主成分分析（PCA）的故障检测以及关键影响变量的识别集成到了一个由大规模语言模型（LLMs）驱动的交互用户界面中。我们通过两种场景评估了LLMs的推理能力：一种场景是提供历史根本原因，另一种场景则不提供根本原因，以模拟未见故障的挑战。使用GPT-4o和o1-preview模型的实验结果表明，该系统在生成合理且可操作的解释方面具有优势，同时也指出了其局限性，包括对PCA选择特征的依赖性和偶尔的幻觉现象。', 'title_zh': 'FaultExplainer：利用大型语言模型进行可解释的故障检测与诊断'}
{'arxiv_id': 'arXiv:2412.14491', 'title': 'Mediation Analysis for Probabilities of Causation', 'authors': 'Yuta Kawakami, Jin Tian', 'link': 'https://arxiv.org/abs/2412.14491', 'abstract': 'Probabilities of causation (PoC) offer valuable insights for informed decision-making. This paper introduces novel variants of PoC-controlled direct, natural direct, and natural indirect probability of necessity and sufficiency (PNS). These metrics quantify the necessity and sufficiency of a treatment for producing an outcome, accounting for different causal pathways. We develop identification theorems for these new PoC measures, allowing for their estimation from observational data. We demonstrate the practical application of our results through an analysis of a real-world psychology dataset.', 'abstract_zh': '因果概率（PoC）为知情决策提供了宝贵的见解。本文介绍了因果概率控制下的新型直接因果概率、自然直接因果概率以及自然间接因果必要性和充分性概率（PNS）的新变体。这些度量指标量化了治疗生产结果的必要性和充分性，考虑了不同因果路径。我们开发了这些新PoC度量的识别定理，使其能够从观测数据中进行估计。我们通过分析一个实际的心理学数据集展示了这些结果的实际应用。', 'title_zh': '原因概率的中介分析'}
{'arxiv_id': 'arXiv:2412.14485', 'title': 'Towards Projected and Incremental Pseudo-Boolean Model Counting', 'authors': 'Suwei Yang, Kuldeep S. Meel', 'link': 'https://arxiv.org/abs/2412.14485', 'abstract': 'Model counting is a fundamental task that involves determining the number of satisfying assignments to a logical formula, typically in conjunctive normal form (CNF). While CNF model counting has received extensive attention over recent decades, interest in Pseudo-Boolean (PB) model counting is just emerging partly due to the greater flexibility of PB formulas. As such, we observed feature gaps in existing PB counters such as a lack of support for projected and incremental settings, which could hinder adoption.\nIn this work, our main contribution is the introduction of the PB model counter PBCount2, the first exact PB model counter with support for projected and incremental model counting. Our counter, PBCount2, uses our Least Occurrence Weighted Min Degree (LOW-MD) computation ordering heuristic to support projected model counting and a cache mechanism to enable incremental model counting. In our evaluations, PBCount2 completed at least 1.40x the number of benchmarks of competing methods for projected model counting and at least 1.18x of competing methods in incremental model counting.', 'abstract_zh': '模型计数是计算逻辑公式（通常为合取范式CNF）的满足赋值数量的基本任务。尽管在过去几十年中，CNF模型计数受到了广泛的关注，但对伪布尔（PB）模型计数的兴趣才刚刚兴起，这主要得益于PB公式更大的灵活性。因此，我们观察到现有的PB计数器在支持投影和增量计算方面存在特征差距，这可能会影响其应用。\n\n在本项工作中，我们的主要贡献是引入了第一个支持投影和增量模型计数的精确伪布尔计数器PBCount2。我们的计数器PBCount2利用了我们提出的Least Occurrence Weighted Min Degree (LOW-MD) 计算排序启发式算法来支持投影模型计数，并使用缓存机制来实现增量模型计数。在我们的评估中，PBCount2在投影模型计数方面完成了至少1.40倍于竞争对手方法的数量的基准测试，在增量模型计数方面则完成了至少1.18倍于竞争对手方法的数量的基准测试。', 'title_zh': '面向投影和增量伪布尔模型计数'}
{'arxiv_id': 'arXiv:2412.14409', 'title': 'Multi-task Representation Learning for Mixed Integer Linear Programming', 'authors': 'Junyang Cai, Taoan Huang, Bistra Dilkina', 'link': 'https://arxiv.org/abs/2412.14409', 'abstract': 'Mixed Integer Linear Programs (MILPs) are highly flexible and powerful tools for modeling and solving complex real-world combinatorial optimization problems. Recently, machine learning (ML)-guided approaches have demonstrated significant potential in improving MILP-solving efficiency. However, these methods typically rely on separate offline data collection and training processes, which limits their scalability and adaptability. This paper introduces the first multi-task learning framework for ML-guided MILP solving. The proposed framework provides MILP embeddings helpful in guiding MILP solving across solvers (e.g., Gurobi and SCIP) and across tasks (e.g., Branching and Solver configuration). Through extensive experiments on three widely used MILP benchmarks, we demonstrate that our multi-task learning model performs similarly to specialized models within the same distribution. Moreover, it significantly outperforms them in generalization across problem sizes and tasks.', 'abstract_zh': '混合整数线性规划模型（MILPs）是用于建模和解决复杂现实世界组合优化问题的强大而灵活的工具。最近，机器学习（ML）指导的方法在提高MILP求解效率方面显示出巨大的潜力。然而，这些方法通常依赖于分离的离线数据收集和训练过程，这限制了它们的可扩展性和适应性。本文提出了首个用于ML指导的MILP求解的多任务学习框架。所提出的框架提供了对求解器（如Gurobi和SCIP）和任务（如分支策略和求解器配置）跨域的MILP嵌入。通过在三个广泛使用的MILP基准上的大量实验，我们表明，我们的多任务学习模型在性能上与相同分布内的专业化模型相当。此外，它在问题规模和任务上的泛化能力显著优于它们。', 'title_zh': '混合整数线性规划的多任务表示学习'}
{'arxiv_id': 'arXiv:2412.14387', 'title': 'Clinical Trials Ontology Engineering with Large Language Models', 'authors': 'Berkan Çakır', 'link': 'https://arxiv.org/abs/2412.14387', 'abstract': 'Managing clinical trial information is currently a significant challenge for the medical industry, as traditional methods are both time-consuming and costly. This paper proposes a simple yet effective methodology to extract and integrate clinical trial data in a cost-effective and time-efficient manner. Allowing the medical industry to stay up-to-date with medical developments. Comparing time, cost, and quality of the ontologies created by humans, GPT3.5, GPT4, and Llama3 (8b & 70b). Findings suggest that large language models (LLM) are a viable option to automate this process both from a cost and time perspective. This study underscores significant implications for medical research where real-time data integration from clinical trials could become the norm.', 'abstract_zh': '目前，管理临床试验信息是医疗行业面临的一项重大挑战，因为传统方法既耗时又昂贵。本文提出了一种简单而有效的方法，能够在成本和时间上高效地提取和整合临床试验数据，从而使医疗行业能够及时了解医学发展动态。通过对由人类创建、GPT3.5、GPT4和Llama3（8b及70b）生成的本体在时间、成本和质量方面的比较研究表明，大型语言模型（LLM）从成本和时间角度来看，是一种可行的自动化选项。本研究强调了在医学研究中，从临床试验中实时集成数据可能成为常态的重要意义。', 'title_zh': '使用大型语言模型进行临床试验本体工程'}
{'arxiv_id': 'arXiv:2412.14382', 'title': 'Balans: Multi-Armed Bandits-based Adaptive Large Neighborhood Search for Mixed-Integer Programming Problem', 'authors': 'Junyang Cai, Serdar Kadioglu, Bistra Dilkina', 'link': 'https://arxiv.org/abs/2412.14382', 'abstract': 'Mixed-Integer Programming (MIP) is a powerful paradigm for modeling and solving various important combinatorial optimization problems. Recently, learning-based approaches have shown potential to speed up MIP solving via offline training that then guides important design decisions during search. However, a significant drawback of these methods is their heavy reliance on offline training, which requires collecting training datasets and computationally costly training epochs yet offering only limited generalization to unseen (larger) instances. In this paper, we propose Balans, an adaptive meta-solver for MIPs with online learning capability that does not require any supervision or apriori training. At its core, Balans is based on adaptive large-neighborhood search, operating on top of a MIP solver by successive applications of destroy and repair neighborhood operators. During the search, the selection among different neighborhood definitions is guided on the fly for the instance at hand via multi-armed bandit algorithms. Our extensive experiments on hard optimization instances show that Balans offers significant performance gains over the default MIP solver, is better than committing to any single best neighborhood, and improves over the state-of-the-art large-neighborhood search for MIPs. Finally, we release Balans as a highly configurable, MIP solver agnostic, open-source software.', 'abstract_zh': '混合整数规划（MIP）是一种强大的建模和求解各类重要组合优化问题的范式。近年来，基于学习的方法已被证明能够通过离线训练加速MIP求解，在搜索过程中指导重要的设计决策。然而，这些方法的一个显著缺点是它们对离线训练的重度依赖，这需要收集大量的训练数据并进行计算成本高昂的训练批次，但只能为未见过的（更大的）实例提供有限的一般化能力。在本文中，我们提出了一种名为Balans的自适应元求解器，它具有在线学习能力，不需要任何监督或先验训练。其核心思想是基于自适应的大邻域搜索，在MIP求解器的基础上，通过逐步应用破坏和修复邻域操作符。在搜索过程中，通过多臂老虎机算法实时指导不同邻域定义的选择，以适应当前实例的需求。我们在一系列困难优化问题上的实验表明，与默认的MIP求解器相比，Balans提供了显著的性能提升，优于单一最优邻域的选择，并改进了现有的MIP的大邻域搜索算法。最后，我们发布了一种高度可配置的、与MIP求解器无关的开放源代码软件Balans。', 'title_zh': 'Balans：基于多臂老虎机的自适应大邻域搜索方法用于混合整数规划问题'}
{'arxiv_id': 'arXiv:2412.14372', 'title': 'Python Agent in Ludii', 'authors': 'Izaias S. de Lima Neto, Marco A. A. de Aguiar Vieira, Anderson R. Tavares', 'link': 'https://arxiv.org/abs/2412.14372', 'abstract': 'Ludii is a Java general game system with a considerable number of board games, with an API for developing new agents and a game description language to create new games. To improve versatility and ease development, we provide Python interfaces for agent programming. This allows the use of Python modules to implement general game playing agents.\nAs a means of enabling Python for creating Ludii agents, the interfaces are implemented using different Java libraries: jpy and Py4J. The main goal of this work is to determine which version is faster. To do so, we conducted a performance analysis of two different GGP algorithms, Minimax adapted to GGP and MCTS. The analysis was performed across several combinatorial games with varying depth, branching factor, and ply time. For reproducibility, we provide tutorials and repositories.\nOur analysis includes predictive models using regression, which suggest that jpy is faster than Py4J, however slower than a native Java Ludii agent, as expected.', 'abstract_zh': 'Ludii 是一个基于 Java 的通用游戏系统，包含大量的棋盘游戏，并提供开发新代理的 API 以及创建新游戏的游戏描述语言。为了提高通用性和简化开发过程，我们提供了 Python 接口以便使用 Python 编程实现代理。这样可以利用 Python 模块来实现通用游戏代理。\n\n为了使 Python 能够用于创建 Ludii 代理，接口是通过不同的 Java 库 jpy 和 Py4J 实现的。本工作的主要目标是确定哪个版本更快速。为此，我们对两种不同的广义游戏协议 (General Game Playing, GGP) 算法（适配 GGP 的 Minimax 算法和 Monte Carlo Tree Search, MCTS）进行了性能分析。分析在多个具有不同深度、分支因子和回合时间的组合游戏中进行。为了可再现性，我们提供了教程和仓库。\n\n我们的分析包括使用回归建立的预测模型，这些模型表明 jpy 比 Py4J 快，但比原生 Java Ludii 代理慢，这在预期之中。', 'title_zh': 'Python代理在Ludii中的应用'}
{'arxiv_id': 'arXiv:2412.15212', 'title': 'Scaling 4D Representations', 'authors': 'João Carreira, Dilara Gokay, Michael King, Chuhan Zhang, Ignacio Rocco, Aravindh Mahendran, Thomas Albert Keck, Joseph Heyward, Skanda Koppula, Etienne Pot, Goker Erdogan, Yana Hasson, Yi Yang, Klaus Greff, Guillaume Le Moing, Sjoerd van Steenkiste, Daniel Zoran, Drew A. Hudson, Pedro Vélez, Luisa Polanía, Luke Friedman, Chris Duvarney, Ross Goroshin, Kelsey Allen, Jacob Walker, Rishabh Kabra, Eric Aboussouan, Jennifer Sun, Thomas Kipf, Carl Doersch, Viorica Pătrăucean, Dima Damen, Pauline Luc, Mehdi S. M. Sajjadi, Andrew Zisserman', 'link': 'https://arxiv.org/abs/2412.15212', 'abstract': 'Scaling has not yet been convincingly demonstrated for pure self-supervised learning from video. However, prior work has focused evaluations on semantic-related tasks $\\unicode{x2013}$ action classification, ImageNet classification, etc. In this paper we focus on evaluating self-supervised learning on non-semantic vision tasks that are more spatial (3D) and temporal (+1D = 4D), such as camera pose estimation, point and object tracking, and depth estimation. We show that by learning from very large video datasets, masked auto-encoding (MAE) with transformer video models actually scales, consistently improving performance on these 4D tasks, as model size increases from 20M all the way to the largest by far reported self-supervised video model $\\unicode{x2013}$ 22B parameters. Rigorous apples-to-apples comparison with many recent image and video models demonstrates the benefits of scaling 4D representations.', 'abstract_zh': '纯自监督学习从视频数据中尚未有令人信服的扩展性证明。然而，先前的工作主要集中在与语义相关的任务上，如动作分类、ImageNet分类等。在本文中，我们专注于评估自监督学习在非语义视觉任务上的表现，这些任务更加侧重于空间（3D）和时间（+1D，共4D）特性，如相机姿态估计、点和物体跟踪以及深度估计。我们通过从非常大的视频数据集中学习，展示了通过掩码自编码（MAE）和Transformer视频模型确实实现了扩展性，随着模型规模从20M增加到迄今为止报告的最大自监督视频模型（220亿参数），这些4D任务上的性能得到了持续改进。与许多近期的图像和视频模型进行严格的同质性比较，进一步证明了扩大4D表示形式的好处。', 'title_zh': '“扩展四维表示”'}
{'arxiv_id': 'arXiv:2412.15209', 'title': 'PRIMA: Multi-Image Vision-Language Models for Reasoning Segmentation', 'authors': 'Muntasir Wahed, Kiet A. Nguyen, Adheesh Sunil Juvekar, Xinzhuo Li, Xiaona Zhou, Vedant Shah, Tianjiao Yu, Pinar Yanardag, Ismini Lourentzou', 'link': 'https://arxiv.org/abs/2412.15209', 'abstract': 'Despite significant advancements in Large Vision-Language Models (LVLMs), existing pixel-grounding models operate on single-image settings, limiting their ability to perform detailed, fine-grained comparisons across multiple images. Conversely, current multi-image understanding models lack pixel-level grounding. Our work addresses this gap by introducing the task of multi-image pixel-grounded reasoning segmentation, and PRIMA, a novel LVLM that integrates pixel-level grounding with robust multi-image reasoning capabilities to produce contextually rich, pixel-grounded explanations. Central to PRIMA is an efficient vision module that queries fine-grained visual representations across multiple images, reducing TFLOPs by $25.3\\%$. To support training and evaluation, we curate $M^4Seg$, a new reasoning segmentation benchmark consisting of $\\sim$224K question-answer pairs that require fine-grained visual understanding across multiple images. Experimental results demonstrate PRIMA outperforms state-of-the-art baselines.', 'abstract_zh': '尽管在大规模视觉-语言模型（LVLMs）方面取得了显著进展，现有的像素定位模型仅限于单张图像的应用场景，限制了它们在多张图像间的详尽、细致对比能力。相反，当前的多图像理解模型缺乏像素级别的定位能力。我们的工作通过引入多图像像素定位推理分割任务，并提出了一种新颖的LVLM——PRIMA，它将像素级别的定位能力与稳健的多图像推理能力相结合，生成具有丰富上下文的像素定位解释。PRIMA的核心在于一个高效的视觉模块，它可以跨多张图像查询细粒度的视觉表示，将其计算量减少25.3%。为了支持训练和评估，我们构建了M4Seg，这是一个新的推理分割基准，包含约22.4万对需要跨多图像进行细粒度视觉理解的问题-答案对。实验结果证明，PRIMA在对比先进基线模型时表现更优。', 'title_zh': 'PRIMA：多张图像的视觉-语言模型用于推理分割'}
{'arxiv_id': 'arXiv:2412.15204', 'title': 'LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks', 'authors': 'Yushi Bai, Shangqing Tu, Jiajie Zhang, Hao Peng, Xiaozhi Wang, Xin Lv, Shulin Cao, Jiazheng Xu, Lei Hou, Yuxiao Dong, Jie Tang, Juanzi Li', 'link': 'https://arxiv.org/abs/2412.15204', 'abstract': 'This paper introduces LongBench v2, a benchmark designed to assess the ability of LLMs to handle long-context problems requiring deep understanding and reasoning across real-world multitasks. LongBench v2 consists of 503 challenging multiple-choice questions, with contexts ranging from 8k to 2M words, across six major task categories: single-document QA, multi-document QA, long in-context learning, long-dialogue history understanding, code repository understanding, and long structured data understanding. To ensure the breadth and the practicality, we collect data from nearly 100 highly educated individuals with diverse professional backgrounds. We employ both automated and manual review processes to maintain high quality and difficulty, resulting in human experts achieving only 53.7% accuracy under a 15-minute time constraint. Our evaluation reveals that the best-performing model, when directly answers the questions, achieves only 50.1% accuracy. In contrast, the o1-preview model, which includes longer reasoning, achieves 57.7%, surpassing the human baseline by 4%. These results highlight the importance of enhanced reasoning ability and scaling inference-time compute to tackle the long-context challenges in LongBench v2. The project is available at this https URL.', 'abstract_zh': '本文介绍了LongBench v2，这是一个基准测试，旨在评估大语言模型（LLMs）在处理需要深入理解和推理的长上下文问题方面的能力，特别是在实际多任务中的表现。LongBench v2 包含了 503 个具有挑战性的多项选择题，上下文范围从 8 千字到 2 百万字，涉及六个主要任务类别：单文档问答、多文档问答、长上下文学习、长对话历史理解、代码仓库理解以及长结构化数据理解。为了确保数据的广泛性和实用性，我们从来自多个专业背景的近 100 名高度教育的个体收集了数据。我们采用自动和手动审查相结合的方式，以保持高质量和难度，最终在 15 分钟的时间限制下，人类专家的准确率仅为 53.7%。我们的评估结果显示，当最佳模型直接回答问题时，其准确率仅为 50.1%。相比之下，o1-preview 模型包含了更长时间的推理，其准确率为 57.7%，超过了人类基准 4%。这些结果突显了增强推理能力和扩展推理时计算量在应对 LongBench v2 中长上下文挑战方面的重要性。该项目可在以下网址访问：[该项目网址]。', 'title_zh': 'LongBench v2：朝着对现实环境中长上下文多任务有更深的理解和推理方向发展'}
{'arxiv_id': 'arXiv:2412.15200', 'title': 'DI-PCG: Diffusion-based Efficient Inverse Procedural Content Generation for High-quality 3D Asset Creation', 'authors': 'Wang Zhao, Yan-Pei Cao, Jiale Xu, Yuejiang Dong, Ying Shan', 'link': 'https://arxiv.org/abs/2412.15200', 'abstract': 'Procedural Content Generation (PCG) is powerful in creating high-quality 3D contents, yet controlling it to produce desired shapes is difficult and often requires extensive parameter tuning. Inverse Procedural Content Generation aims to automatically find the best parameters under the input condition. However, existing sampling-based and neural network-based methods still suffer from numerous sample iterations or limited controllability. In this work, we present DI-PCG, a novel and efficient method for Inverse PCG from general image conditions. At its core is a lightweight diffusion transformer model, where PCG parameters are directly treated as the denoising target and the observed images as conditions to control parameter generation. DI-PCG is efficient and effective. With only 7.6M network parameters and 30 GPU hours to train, it demonstrates superior performance in recovering parameters accurately, and generalizing well to in-the-wild images. Quantitative and qualitative experiment results validate the effectiveness of DI-PCG in inverse PCG and image-to-3D generation tasks. DI-PCG offers a promising approach for efficient inverse PCG and represents a valuable exploration step towards a 3D generation path that models how to construct a 3D asset using parametric models.', 'abstract_zh': '过程化内容生成（PCG）在创建高质量3D内容方面非常强大，但要控制其生成所需的特定形状却颇具挑战性，通常需要进行繁琐的参数调整。逆过程化内容生成旨在在给定输入条件下自动找到最佳参数。然而，现有的基于采样的方法和基于神经网络的方法仍然存在大量的样本迭代或可控性有限的问题。在本文中，我们提出了DI-PCG，这是一种用于从一般图像条件逆向生成过程化内容的新颖且高效的算法。其核心是一个轻量级的扩散变换器模型，在该模型中，PCG参数直接作为去噪目标，观察到的图像作为控制参数生成的条件。DI-PCG高效且有效。仅需7.6M的网络参数和30个GPU小时进行训练，它在准确恢复参数和良好泛化到野外图像方面表现出卓越的性能。定量和定性的实验结果验证了DI-PCG在逆过程化内容生成和图像到3D生成任务中的有效性。DI-PCG为高效逆过程化内容生成提供了有前景的方法，并代表了向基于参数模型构建3D资产的3D生成路径的有意义探索。', 'title_zh': 'DI-PCG: 基于扩散过程的高效逆过程内容生成方法及其在高质量3D资产创建中的应用'}
{'arxiv_id': 'arXiv:2412.15188', 'title': 'LlamaFusion: Adapting Pretrained Language Models for Multimodal Generation', 'authors': 'Weijia Shi, Xiaochuang Han, Chunting Zhou, Weixin Liang, Xi Victoria Lin, Luke Zettlemoyer, Lili Yu', 'link': 'https://arxiv.org/abs/2412.15188', 'abstract': "We present LlamaFusion, a framework for empowering pretrained text-only large language models (LLMs) with multimodal generative capabilities, enabling them to understand and generate both text and images in arbitrary sequences. LlamaFusion leverages existing Llama-3's weights for processing texts autoregressively while introducing additional and parallel transformer modules for processing images with diffusion. During training, the data from each modality is routed to its dedicated modules: modality-specific feedforward layers, query-key-value projections, and normalization layers process each modality independently, while the shared self-attention layers allow interactions across text and image features. By freezing the text-specific modules and only training the image-specific modules, LlamaFusion preserves the language capabilities of text-only LLMs while developing strong visual understanding and generation abilities. Compared to methods that pretrain multimodal generative models from scratch, our experiments demonstrate that, LlamaFusion improves image understanding by 20% and image generation by 3.6% using only 50% of the FLOPs while maintaining Llama-3's language capabilities. We also demonstrate that this framework can adapt existing vision-language models with multimodal generation ability. Overall, this framework not only leverages existing computational investments in text-only LLMs but also enables the parallel development of language and vision capabilities, presenting a promising direction for efficient multimodal model development.", 'abstract_zh': '我们提出了LlamaFusion框架，该框架旨在赋予仅预训练文本的大语言模型（LLM）多模态生成能力，使其能够理解和生成任意序列的文本和图像。LlamaFusion利用现有的Llama-3权重进行自回归文本处理，同时引入额外且并行的变压器模块以通过扩散处理图像。在训练过程中，来自不同模态的数据会流向其专用模块：特定于模态的前馈层、查询-键-值投影以及规范化层分别独立处理每个模态，而共享的自注意力层则允许文本和图像特征之间的交互。通过冻结特定于文本的模块，并仅训练特定于图像的模块，LlamaFusion保留了仅文本LLM的语言能力，同时发展了强大的视觉理解与生成能力。与从零开始预训练多模态生成模型的方法相比，我们的实验表明，LlamaFusion仅使用50%的FLOPs即可提升20%的图像理解能力和3.6%的图像生成能力，同时保持Llama-3的语言能力。此外，我们还展示了该框架可以适应已有的具有多模态生成能力的视觉-语言模型。总体而言，该框架不仅利用了现有仅文本LLM的计算投资，还实现了语言与视觉能力的并行开发，为高效的多模态模型开发提供了颇有前景的方向。', 'title_zh': 'LlamaFusion：适应多模态生成的预训练语言模型'}
{'arxiv_id': 'arXiv:2412.15166', 'title': 'Human-Humanoid Robots Cross-Embodiment Behavior-Skill Transfer Using Decomposed Adversarial Learning from Demonstration', 'authors': 'Junjia Liu, Zhuo Li, Minghao Yu, Zhipeng Dong, Sylvain Calinon, Darwin Caldwell, Fei Chen', 'link': 'https://arxiv.org/abs/2412.15166', 'abstract': 'Humanoid robots are envisioned as embodied intelligent agents capable of performing a wide range of human-level loco-manipulation tasks, particularly in scenarios requiring strenuous and repetitive labor. However, learning these skills is challenging due to the high degrees of freedom of humanoid robots, and collecting sufficient training data for humanoid is a laborious process. Given the rapid introduction of new humanoid platforms, a cross-embodiment framework that allows generalizable skill transfer is becoming increasingly critical. To address this, we propose a transferable framework that reduces the data bottleneck by using a unified digital human model as a common prototype and bypassing the need for re-training on every new robot platform. The model learns behavior primitives from human demonstrations through adversarial imitation, and the complex robot structures are decomposed into functional components, each trained independently and dynamically coordinated. Task generalization is achieved through a human-object interaction graph, and skills are transferred to different robots via embodiment-specific kinematic motion retargeting and dynamic fine-tuning. Our framework is validated on five humanoid robots with diverse configurations, demonstrating stable loco-manipulation and highlighting its effectiveness in reducing data requirements and increasing the efficiency of skill transfer across platforms.', 'abstract_zh': '拟人机器人被设想为具备执行广泛的人类级移动操作任务的体现智能代理，特别是在需要繁重和重复劳动的场景中尤为适用。然而，由于拟人机器人具有高自由度，学习这些技能具有挑战性，而收集充分的训练数据对拟人机器人而言也是一个耗时的过程。鉴于新的拟人平台快速涌现，一种允许通用技能迁移的跨体态框架变得越来越关键。为解决这一问题，我们提出了一种可迁移的框架，通过使用统一的数字人体模型作为通用原型，从而减少数据瓶颈，避免每在新平台重新训练的需要。该模型通过对抗模仿学习从人类示范中学习行为素，复杂的机器人结构被分解为功能组件，各组件独立训练并动态协调。通过人力物体交互图实现任务泛化，并通过特定于体态的动力学运动目标重定位和动态微调将技能迁移到不同的机器人。该框架在五种具有差异配置的拟人机器人上得到了验证，展示了稳定的移动操作，并突出了其在减少数据需求和跨平台提高技能迁移效率方面的有效性。', 'title_zh': '人类-类人机器人异体行为-技能转移研究：基于分解对抗学习的演示学习'}
{'arxiv_id': 'arXiv:2412.15163', 'title': 'Operationalising Rawlsian Ethics for Fairness in Norm-Learning Agents', 'authors': 'Jessica Woodgate, Paul Marshall, Nirav Ajmeri', 'link': 'https://arxiv.org/abs/2412.15163', 'abstract': 'Social norms are standards of behaviour common in a society. However, when agents make decisions without considering how others are impacted, norms can emerge that lead to the subjugation of certain agents. We present RAWL-E, a method to create ethical norm-learning agents. RAWL-E agents operationalise maximin, a fairness principle from Rawlsian ethics, in their decision-making processes to promote ethical norms by balancing societal well-being with individual goals. We evaluate RAWL-E agents in simulated harvesting scenarios. We find that norms emerging in RAWL-E agent societies enhance social welfare, fairness, and robustness, and yield higher minimum experience compared to those that emerge in agent societies that do not implement Rawlsian ethics.', 'abstract_zh': '社会规范是指一个社会中普遍认同的行为标准。然而，当个体在做决策时不考虑其行为对他人的影响时，可能会形成一些压迫某些个体的行为规范。我们提出了一种名为RAWL-E的方法，旨在创建具备伦理规范学习能力的智能体。RAWL-E智能体在其决策过程中通过实现罗尔斯正义伦理学中的“最大化最小者”原则（maximin），在社会福祉与个体目标之间寻求平衡，从而促进伦理规范的形成。我们通过模拟收获场景对RAWL-E智能体进行了评估。研究结果表明，RAWL-E智能体社会中形成的规范提升了社会福利、公平性和稳健性，并且相较于未实施罗尔斯正义伦理的智能体社会，能获得更高的最低经验收益。', 'title_zh': '将罗尔斯伦理学应用于规范学习代理的公平性操作化'}
{'arxiv_id': 'arXiv:2412.15151', 'title': 'Language Models as Continuous Self-Evolving Data Engineers', 'authors': 'Peidong Wang, Ming Wang, Zhiming Ma, Xiaocui Yang, Shi Feng, Daling Wang, Yifei Zhang', 'link': 'https://arxiv.org/abs/2412.15151', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable capabilities on various tasks, while the further evolvement is limited to the lack of high-quality training data. In addition, traditional training approaches rely too much on expert-labeled data, setting an upper limit on the performance of LLMs. To address this issue, we propose a novel paradigm that enables LLMs to train itself by autonomously generating, cleaning, reviewing, and annotating data with preference information, named LANCE. Our approach demonstrates that LLMs can serve as continuous self-evolving data engineers, significantly reducing the time and cost of the post-training data construction process. Through iterative fine-tuning on different variants of the Qwen2, we validate the effectiveness of LANCE across various tasks, showing that it can continuously improve model performance and maintain high-quality data generation. Across eight benchmark dimensions, LANCE resulted in an average score enhancement of 3.36 for Qwen2-7B and 2.70 for Qwen2-7B-Instruct. This training paradigm with autonomous data construction not only reduces the reliance on human experts or external models but also ensures that the data aligns with human values and preferences, paving the way for the development of future superintelligent systems that can exceed human capabilities.', 'abstract_zh': '大型语言模型（LLMs）在多种任务上展现了卓越的能力，但进一步的发展受限于高质量训练数据的不足。此外，传统的训练方法过于依赖专家标注的数据，从而对LLMs的性能设立了上限。为了解决这一问题，我们提出了一种新的范式，使LLMs能够自主生成、清洗、审查和注释带有偏好信息的数据，这一过程被命名为LANCE。我们的方法表明，LLMs可以作为持续自我演化的数据工程师，显著减少了后训练数据构建过程的时间和成本。通过在不同版本的Qwen2上进行迭代微调，我们验证了LANCE在各种任务中的有效性，显示其能够持续提升模型性能并维持高质量的数据生成。LANCE在八个基准维度上分别提高了Qwen2-7B和Qwen2-7B-Instruct 3.36和2.70的分数。这种具有自主数据构建的训练范式不仅减少了对人类专家或外部模型的依赖，还确保了数据与人类价值观和偏好的一致性，为未来超智能系统的开发铺平了道路，这些系统能够超越人类的能力。', 'title_zh': '语言模型作为连续自我进化的数据工程师'}
{'arxiv_id': 'arXiv:2412.15150', 'title': 'Leveraging Color Channel Independence for Improved Unsupervised Object Detection', 'authors': 'Bastian Jäckl, Yannick Metz, Udo Schlegel, Daniel A. Keim, Maximilian T. Fischer', 'link': 'https://arxiv.org/abs/2412.15150', 'abstract': "Object-centric architectures can learn to extract distinct object representations from visual scenes, enabling downstream applications on the object level. Similarly to autoencoder-based image models, object-centric approaches have been trained on the unsupervised reconstruction loss of images encoded by RGB color spaces. In our work, we challenge the common assumption that RGB images are the optimal color space for unsupervised learning in computer vision. We discuss conceptually and empirically that other color spaces, such as HSV, bear essential characteristics for object-centric representation learning, like robustness to lighting conditions. We further show that models improve when requiring them to predict additional color channels. Specifically, we propose to transform the predicted targets to the RGB-S space, which extends RGB with HSV's saturation component and leads to markedly better reconstruction and disentanglement for five common evaluation datasets. The use of composite color spaces can be implemented with basically no computational overhead, is agnostic of the models' architecture, and is universally applicable across a wide range of visual computing tasks and training types. The findings of our approach encourage additional investigations in computer vision tasks beyond object-centric learning.", 'abstract_zh': '以对象为中心的架构可以从视觉场景中学习提取独特的对象表示，从而在对象级别上启用下游应用。与基于自编码器的图像模型类似，对象为中心的方法是通过编码RGB颜色空间中的图像的无监督重建损失进行训练的。在我们的工作中，我们挑战了RGB图像是最优颜色空间的常见假设，以无监督学习计算机视觉中的最优颜色空间。我们从概念上和实证上讨论了其他颜色空间（如HSV）对于对象为中心的表示学习具有本质特性，例如对光照条件的鲁棒性。我们进一步展示了要求模型预测额外的彩色通道可以提高模型性能。具体而言，我们建议将预测的目标转换到RGB-S空间，该空间在RGB的基础上加入了HSV的饱和度成分，从而在五个常见的评估数据集中显著提高了重建性能和分离度。使用复合颜色空间可以在基本不增加计算开销的情况下实现，不对模型的架构产生依赖，且可以广泛应用于各种视觉计算任务和训练类型。我们方法的研究结果鼓励在对象为中心学习之外的计算机视觉任务中进行更多的研究。', 'title_zh': '利用颜色通道独立性以改进无监督目标检测'}
{'arxiv_id': 'arXiv:2412.15129', 'title': 'Jet: A Modern Transformer-Based Normalizing Flow', 'authors': 'Alexander Kolesnikov, André Susano Pinto, Michael Tschannen', 'link': 'https://arxiv.org/abs/2412.15129', 'abstract': 'In the past, normalizing generative flows have emerged as a promising class of generative models for natural images. This type of model has many modeling advantages: the ability to efficiently compute log-likelihood of the input data, fast generation and simple overall structure. Normalizing flows remained a topic of active research but later fell out of favor, as visual quality of the samples was not competitive with other model classes, such as GANs, VQ-VAE-based approaches or diffusion models. In this paper we revisit the design of the coupling-based normalizing flow models by carefully ablating prior design choices and using computational blocks based on the Vision Transformer architecture, not convolutional neural networks. As a result, we achieve state-of-the-art quantitative and qualitative performance with a much simpler architecture. While the overall visual quality is still behind the current state-of-the-art models, we argue that strong normalizing flow models can help advancing research frontier by serving as building components of more powerful generative models.', 'abstract_zh': '在过去，正则化生成流已成为一种有前景的生成模型类别，适用于自然界中的图像。这类模型具有许多建模优势：能够高效计算输入数据的对数似然性、快速生成以及结构简单。然而，正则化流后来逐渐受到冷落，因为其生成样本的视觉质量与GANs、基于VQ-VAE的方法或扩散模型等其他模型类别相比不够竞争力。在本文中，我们通过仔细剔除先前的设计选择，并采用基于Vision Transformer架构的计算块而非卷积神经网络，重新审视基于耦合的正则化流模型的设计。结果，我们使用一个更为简单的架构取得了最先进的定量和定性性能。尽管整体视觉质量仍然落后于当前最先进的模型，但我们认为强大的正则化流模型可以通过作为更强大生成模型构建组件的方式推动研究前沿。', 'title_zh': 'Jet：一种基于Transformer的现代Normalize Flow'}
{'arxiv_id': 'arXiv:2412.15127', 'title': 'Adaptive Pruning for Large Language Models with Structural Importance Awareness', 'authors': 'Haotian Zheng, Jinke Ren, Yushan Sun, Ruichen Zhang, Wenbo Zhang, Zhen Li, Dusit Niyato, Shuguang Cui, Yatong Han', 'link': 'https://arxiv.org/abs/2412.15127', 'abstract': 'The recent advancements in large language models (LLMs) have significantly improved language understanding and generation capabilities. However, it is difficult to deploy LLMs on resource-constrained edge devices due to their high computational and storage resource demands. To address this issue, we propose a novel LLM model pruning method, namely structurally-aware adaptive pruning (SAAP), to significantly reduce the computational and memory costs while maintaining model performance. We first define an adaptive importance fusion metric to evaluate the importance of all coupled structures in LLMs by considering their homoscedastic uncertainty. Then, we rank the importance of all modules to determine the specific layers that should be pruned to meet particular performance requirements. Furthermore, we develop a new group fine-tuning strategy to improve the inference efficiency of LLMs. Finally, we evaluate the proposed SAAP method on multiple LLMs across two common tasks, i.e., zero-shot classification and text generation. Experimental results show that our SAAP method outperforms several state-of-the-art baseline methods, achieving 2.17%, 2.37%, and 2.39% accuracy gains on LLaMA-7B, Vicuna-7B, and LLaMA-13B. Additionally, SAAP improves the token generation speed by 5%, showcasing its practical advantages in resource-constrained scenarios.', 'abstract_zh': '近年来，大型语言模型（LLMs）在语言理解和生成能力方面取得了显著进步。然而，由于其对计算和存储资源的高需求，很难在资源受限的边缘设备上部署LLMs。为了解决这一问题，我们提出了一种新颖的LLM模型剪枝方法，即结构感知自适应剪枝（SAAP），该方法可大幅降低计算和内存成本，同时保持模型性能。首先，我们定义了一个自适应重要性融合度量，通过考虑耦合结构的同方差不确定性来评估LLMs中所有耦合结构的重要性。然后，我们对所有模块进行排序，确定需要剪枝的具体层以满足特定的性能要求。此外，我们还开发了一种新的分组微调策略，以提高LLMs的推理效率。最后，我们在两个常见任务（零样本分类和文本生成）的多个LLMs上评估了所提出的SAAP方法。实验结果表明，与几种最先进的基线方法相比，我们的SAAP方法在LLaMA-7B、Vicuna-7B和LLaMA-13B上分别取得了2.17%、2.37%和2.39%的准确率提升。此外，SAAP还提高了5%的标记生成速度，在资源受限的场景中展示出其实用优势。', 'title_zh': '具有结构重要性意识的大型语言模型自适应剪枝'}
{'arxiv_id': 'arXiv:2412.15118', 'title': 'Outcome-Refining Process Supervision for Code Generation', 'authors': 'Zhuohao Yu, Weizheng Gu, Yidong Wang, Zhengran Zeng, Jindong Wang, Wei Ye, Shikun Zhang', 'link': 'https://arxiv.org/abs/2412.15118', 'abstract': 'Large Language Models have demonstrated remarkable capabilities in code generation, yet they often struggle with complex programming tasks that require deep algorithmic reasoning. While process supervision through learned reward models shows promise in guiding reasoning steps, it requires expensive training data and suffers from unreliable evaluation. We propose Outcome-Refining Process Supervision, a novel paradigm that treats outcome refinement itself as the process to be supervised. Our framework leverages concrete execution signals to ground the supervision of reasoning steps, while using tree-structured exploration to maintain multiple solution trajectories simultaneously. Experiments demonstrate that our approach enables even smaller models to achieve high success accuracy and performance metrics on competitive programming tasks, creates more reliable verification than traditional reward models without requiring training PRMs. Our approach achieves significant improvements across 5 models and 3 datasets: an average of 26.9% increase in correctness and 42.2% in efficiency. The results suggest that providing structured reasoning space with concrete verification signals is crucial for solving complex programming tasks. We open-source all our code and data at: this https URL', 'abstract_zh': '大规模语言模型在代码生成方面展现了出色的能力，但在解决需要深入算法推理的复杂编程任务时往往表现不佳。通过学习奖励模型进行过程监督虽然显示出一定的潜力，但需要昂贵的训练数据，并且评价结果不够可靠。我们提出了一种新的方法——结果细化过程监督，将结果细化本身作为要监督的过程。我们的框架利用具体的执行信号来对推理步骤进行监督，同时采用树状探索结构来同时保持多个解决方案轨迹。实验结果表明，我们的方法能使即使较小的模型在竞争编程任务中实现高准确性和性能指标，提供比传统奖励模型更可靠的验证，而不需要训练PRMs。我们的方法在5个模型和3个数据集上均取得了显著提高：正确率平均提高了26.9%，效率提高了42.2%。结果表明，提供结构化的推理空间并结合具体的验证信号对于解决复杂编程任务至关重要。我们开源了所有代码和数据：[此链接](this https URL)', 'title_zh': '代码生成中的基于产出细化的过程监督'}
{'arxiv_id': 'arXiv:2412.15113', 'title': 'Associative memory inspires improvements for in-context learning using a novel attention residual stream architecture', 'authors': 'Thomas F Burns, Tomoki Fukai, Christopher J Earls', 'link': 'https://arxiv.org/abs/2412.15113', 'abstract': 'Large language models (LLMs) demonstrate an impressive ability to utilise information within the context of their input sequences to appropriately respond to data unseen by the LLM during its training procedure. This ability is known as in-context learning (ICL). Humans and non-human animals demonstrate similar abilities, however their neural architectures differ substantially from LLMs. Despite this, a critical component within LLMs, the attention mechanism, resembles modern associative memory models, widely used in and influenced by the computational neuroscience community to model biological memory systems. Using this connection, we introduce an associative memory model capable of performing ICL. We use this as inspiration for a novel residual stream architecture which allows information to directly flow between attention heads. We test this architecture during training within a two-layer Transformer and show its ICL abilities manifest more quickly than without this modification. We then apply our architecture in small language models with 8 million parameters, focusing on attention head values, with results also indicating improved ICL performance at this larger and more naturalistic scale.', 'abstract_zh': '大型语言模型（LLMs）展示了在输入序列的上下文中利用信息的能力，以适当地响应训练过程中未见过的数据。这种能力称为上下文内学习（ICL）。人类和非人类动物也展示了类似的能力，然而它们的神经架构与LLMs有显著差异。尽管如此，LLMs中的一个关键组件——注意机制——与现代联想记忆模型相似，这些模型在计算神经科学领域广泛使用并受到其影响，用于模拟生物记忆系统。基于这种联系，我们提出了一种联想记忆模型，该模型能够执行ICL。我们以此为灵感，引入了一种新的残差流架构，允许信息直接在注意头之间流动。我们在两层Transformer模型的训练过程中测试了这种架构，并显示了这种修改使得ICL能力表现得更快。随后，我们在具有800万个参数的小型语言模型中应用了这种架构，专注于注意头的值，结果显示在更大和更自然的规模上，这种架构也表现出增强的ICL性能。', 'title_zh': '关联记忆启发了一种新型注意残差流架构在上下文学习中的改进'}
{'arxiv_id': 'arXiv:2412.15105', 'title': 'Exploiting sparse structures and synergy designs to advance situational awareness of electrical power grid', 'authors': 'Shimiao Li', 'link': 'https://arxiv.org/abs/2412.15105', 'abstract': 'The growing threats of uncertainties, anomalies, and cyberattacks on power grids are driving a critical need to advance situational awareness which allows system operators to form a complete and accurate picture of the present and future state. Simulation and estimation are foundational tools in this process. However, existing tools lack the robustness and efficiency required to achieve the level of situational awareness needed for the ever-evolving threat landscape. Industry-standard (steady-state) simulators are not robust to blackouts, often leading to non-converging or non-actionable results. Estimation tools lack robustness to anomalous data, returning erroneous system states. Efficiency is the other major concern as nonlinearities and scalability issues make large systems slow to converge.\nThis thesis addresses robustness and efficiency gaps through a dual-fold contribution. We first address the inherent limitations in the existing physics-based and data-driven worlds; and then transcend the boundaries of conventional algorithmic design in the direction of a new paradigm -- Physics-ML Synergy -- which integrates the strengths of the two worlds. Our approaches are built on circuit formulation which provides a unified framework that applies to both transmission and distribution. Sparse optimization acts as the key enabler to make these tools intrinsically robust and immune to random threats, pinpointing dominant sources of (random) blackouts and data errors. Further, we explore sparsity-exploiting optimizations to develop lightweight ML models whose prediction and detection capabilities are a complement to physics-based tools; and whose lightweight designs advance generalization and scalability. Finally, Physics-ML Synergy brings robustness and efficiency further against targeted cyberthreats, by interconnecting our physics-based tools with lightweight ML.', 'abstract_zh': '日益增长的不确定性、异常情况和网络攻击对电网的安全构成重大威胁，这推动了对情境意识的迫切需求，使系统操作员能够全面、准确地了解当前和未来的情况。仿真和估计是实现这一目的的基本工具。然而，现有的工具在现阶段的威胁环境中缺乏足够的稳健性和效率。传统的稳态仿真器对断电不具有鲁棒性，经常导致结果不收敛或不可行。现有的估计工具对异常数据缺乏鲁棒性，会返回错误的系统状态。效率也是一个主要问题，因为非线性和扩展性问题使得大型系统难以快速收敛。\n\n本论文通过双重贡献来解决稳健性和效率的劣势。首先，我们解决现有的基于物理模型和数据驱动方法的固有限制；然后跨越传统算法设计的界限，转向一个新的范式——物理-机器学习协同（Physics-ML Synergy），该范式结合了两者的强项。我们的方法基于电路公式，提供了一个适用于传输和分配的统一框架。稀疏优化作为关键使能技术，使这些工具具备内在的鲁棒性，能够抵御随机威胁，并指出主要的断电和数据错误来源。此外，我们探索了利用稀疏性的优化技术来开发轻量级的机器学习模型，这些模型在预测和检测方面能补充基于物理的方法的功能，并通过轻量级设计提高泛化能力和可扩展性。最后，物理-机器学习协同效应通过将基于物理的方法与轻量级机器学习相互连接，进一步提升了对针对性的网络威胁的稳健性和效率。', 'title_zh': '利用稀疏结构和协同设计提高电力 grids 的情境感知能力'}
{'arxiv_id': 'arXiv:2412.15098', 'title': 'A Cross-Domain Study of the Use of Persuasion Techniques in Online Disinformation', 'authors': 'João A. Leite, Olesya Razuvayevskaya, Carolina Scarton, Kalina Bontcheva', 'link': 'https://arxiv.org/abs/2412.15098', 'abstract': 'Disinformation, irrespective of domain or language, aims to deceive or manipulate public opinion, typically through employing advanced persuasion techniques. Qualitative and quantitative research on the weaponisation of persuasion techniques in disinformation has been mostly topic-specific (e.g., COVID-19) with limited cross-domain studies, resulting in a lack of comprehensive understanding of these strategies. This study employs a state-of-the-art persuasion technique classifier to conduct a large-scale, multi-domain analysis of the role of 16 persuasion techniques in disinformation narratives. It shows how different persuasion techniques are employed disproportionately in different disinformation domains. We also include a detailed case study on climate change disinformation, highlighting how linguistic, psychological, and cultural factors shape the adaptation of persuasion strategies to fit unique thematic contexts.', 'abstract_zh': '不论是在哪个领域或使用哪种语言，虚假信息的目的是欺骗或操纵公众意见，通常通过运用先进的说服技术来实现。关于说服技术在虚假信息中武器化方面的定性和定量研究主要集中在特定主题上（例如新冠肺炎），跨领域的研究相对较少，导致对这些策略的理解不够全面。本研究采用最先进的说服技术分类器，对16种说服技术在多领域虚假信息叙事中的作用进行了大规模分析。结果显示，这些说服技术在不同虚假信息领域中的应用程度不均衡。我们还通过一个详细的案例研究探讨了气候变化虚假信息，强调了语言、心理和文化因素如何影响说服策略的适应性，以便更好地契合特定主题背景。', 'title_zh': '跨领域的在线误导信息中劝说技巧使用的研究'}
{'arxiv_id': 'arXiv:2412.15095', 'title': 'A Full Transformer-based Framework for Automatic Pain Estimation using Videos', 'authors': 'Stefanos Gkikas, Manolis Tsiknakis', 'link': 'https://arxiv.org/abs/2412.15095', 'abstract': 'The automatic estimation of pain is essential in designing an optimal pain management system offering reliable assessment and reducing the suffering of patients. In this study, we present a novel full transformer-based framework consisting of a Transformer in Transformer (TNT) model and a Transformer leveraging cross-attention and self-attention blocks. Elaborating on videos from the BioVid database, we demonstrate state-of-the-art performances, showing the efficacy, efficiency, and generalization capability across all the primary pain estimation tasks.', 'abstract_zh': '自动估计疼痛对于设计一个提供可靠评估并减轻患者痛苦的最优疼痛管理系统至关重要。在本研究中，我们提出了一种新颖的全变压器架构，该架构由Transformer in Transformer (TNT) 模型和利用交叉注意力和自注意力模块的变压器组成。通过对BioVid数据库中的视频进行详细分析，我们展示了该框架在所有主要疼痛估计任务上的先进性能、有效性和跨任务的一般化能力。', 'title_zh': '基于全变压器架构的视频自动疼痛估计完整框架'}
{'arxiv_id': 'arXiv:2412.15086', 'title': 'Learning Disentangled Equivariant Representation for Explicitly Controllable 3D Molecule Generation', 'authors': 'Haoran Liu, Youzhi Luo, Tianxiao Li, James Caverlee, Martin Renqiang Min', 'link': 'https://arxiv.org/abs/2412.15086', 'abstract': "We consider the conditional generation of 3D drug-like molecules with \\textit{explicit control} over molecular properties such as drug-like properties (e.g., Quantitative Estimate of Druglikeness or Synthetic Accessibility score) and effectively binding to specific protein sites. To tackle this problem, we propose an E(3)-equivariant Wasserstein autoencoder and factorize the latent space of our generative model into two disentangled aspects: molecular properties and the remaining structural context of 3D molecules. Our model ensures explicit control over these molecular attributes while maintaining equivariance of coordinate representation and invariance of data likelihood. Furthermore, we introduce a novel alignment-based coordinate loss to adapt equivariant networks for auto-regressive de-novo 3D molecule generation from scratch. Extensive experiments validate our model's effectiveness on property-guided and context-guided molecule generation, both for de-novo 3D molecule design and structure-based drug discovery against protein targets.", 'abstract_zh': '我们考虑在明确控制分子属性（如药效性质（例如，定量药效类比性估量或合成可及性评分）和有效结合到特定蛋白质位点）的情况下，生成3D药物样分子。为了解决这一问题，我们提出了一种E(3)-不变的Wasserstein自编码器，并将生成模型的潜在空间分解为两个独立方面：分子属性和3D分子的剩余结构上下文。我们的模型确保了对这些分子属性的明确控制，同时保持了坐标表示的不变性和数据似然性的不变性。此外，我们引入了一种新的基于对齐的坐标损失，以适应E(3)-不变网络，用于从头开始的自动回归3D分子生成。广泛的实验验证了我们模型在属性引导和上下文引导的分子生成方面（包括从头设计3D药物分子和基于结构的药物发现对抗蛋白质靶标）的有效性。', 'title_zh': '学习解耦同构表示以实现显式可控的3D分子生成'}
{'arxiv_id': 'arXiv:2412.15084', 'title': 'AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward Modeling', 'authors': 'Zihan Liu, Yang Chen, Mohammad Shoeybi, Bryan Catanzaro, Wei Ping', 'link': 'https://arxiv.org/abs/2412.15084', 'abstract': 'In this paper, we introduce AceMath, a suite of frontier math models that excel in solving complex math problems, along with highly effective reward models capable of evaluating generated solutions and reliably identifying the correct ones. To develop the instruction-tuned math models, we propose a supervised fine-tuning (SFT) process that first achieves competitive performance across general domains, followed by targeted fine-tuning for the math domain using a carefully curated set of prompts and synthetically generated responses. The resulting model, AceMath-72B-Instruct greatly outperforms Qwen2.5-Math-72B-Instruct, GPT-4o and Claude-3.5 Sonnet. To develop math-specialized reward model, we first construct AceMath-RewardBench, a comprehensive and robust benchmark for evaluating math reward models across diverse problems and difficulty levels. After that, we present a systematic approach to build our math reward models. The resulting model, AceMath-72B-RM, consistently outperforms state-of-the-art reward models. Furthermore, when combining AceMath-72B-Instruct with AceMath-72B-RM, we achieve the highest average rm@8 score across the math reasoning benchmarks. We will release model weights, training data, and evaluation benchmarks at: this https URL', 'abstract_zh': '在本文中，我们介绍了AceMath，这是一套表现卓越的前沿数学模型，能够解决复杂数学问题，并且配备了高效的奖励模型以评估生成的解决方案并可靠地识别正确的答案。为了开发指令调优的数学模型，我们提出了一种监督微调（SFT）过程，该过程首先在通用领域中实现竞争力，然后通过精心策划的提示和合成生成的响应针对数学领域进行目标化微调。由此产生的模型AceMath-72B-Instruct在各方面显著优于Qwen2.5-Math-72B-Instruct、GPT-4o和Claude-3.5 Sonnet。为了开发专门化的数学奖励模型，我们首先构建了AceMath-RewardBench，这是一个全面且 robust 的基准，用于在多样化的问题和难度级别下评估数学奖励模型。之后，我们提出了构建数学奖励模型的系统方法。由此产生的模型AceMath-72B-RM持续优于最先进的奖励模型。此外，当我们结合使用AceMath-72B-Instruct与AceMath-72B-RM时，我们在数学推理基准测试中实现了最高的平均rm@8得分。我们将释放模型权重、训练数据和评估基准，请访问以下链接：this https URL', 'title_zh': 'AceMath: 通过后训练和奖励建模推进前沿数学推理'}
{'arxiv_id': 'arXiv:2412.15054', 'title': 'GIRAFE: Glottal Imaging Dataset for Advanced Segmentation, Analysis, and Facilitative Playbacks Evaluation', 'authors': 'G. Andrade-Miranda, K. Chatzipapas, J.D. Arias-Londoño, J. I. Godino-Llorente', 'link': 'https://arxiv.org/abs/2412.15054', 'abstract': 'The advances in the development of Facilitative Playbacks extracted from High-Speed videoendoscopic sequences of the vocal folds are hindered by a notable lack of publicly available datasets annotated with the semantic segmentations corresponding to the area of the glottal gap. This fact also limits the reproducibility and further exploration of existing research in this field.\nTo address this gap, GIRAFE is a data repository designed to facilitate the development of advanced techniques for the semantic segmentation, analysis, and fast evaluation of High-Speed videoendoscopic sequences of the vocal folds. The repository includes 65 high-speed videoendoscopic recordings from a cohort of 50 patients (30 female, 20 male). The dataset comprises 15 recordings from healthy controls, 26 from patients with diagnosed voice disorders, and 24 with an unknown health condition. All of them were manually annotated by an expert, including the masks corresponding to the semantic segmentation of the glottal gap. The repository is also complemented with the automatic segmentation of the glottal area using different state-of-the-art approaches.\nThis data set has already supported several studies, which demonstrates its usefulness for the development of new glottal gap segmentation algorithms from High-Speed-Videoendoscopic sequences to improve or create new Facilitative Playbacks. Despite these advances and others in the field, the broader challenge of performing an accurate and completely automatic semantic segmentation method of the glottal area remains open.', 'abstract_zh': '高通量内窥镜声带序列中促进性回放的进展受到缺乏公开可用的带有声门间隙语义标注的数据集的限制。这一事实也限制了现有研究的可重复性和进一步探索。\n\n为了填补这一空白，GIRAFE 是一个数据仓库，旨在促进声带高通量内窥镜序列的语义分割、分析和快速评估的先进技术的发展。该仓库包括来自 50 名患者（30 名女性、20 名男性）的 65 段高通量内窥镜录像。数据集包括来自 30 名健康对照的 15 段录像、来自诊断为语音障碍的患者的 26 段录像以及来自未知健康状况的 24 段录像。所有这些录像都由专家手动标注，包括与声门间隙语义分割对应的掩码。此外，该数据仓库还提供了使用不同前沿方法自动分割声门区域的数据。\n\n该数据集已支持了多项研究，这证明了其在从高通量视频内窥镜序列开发新的声门间隙分割算法、以改进或创建新的促进性回放方面的有用性。尽管该领域在这些进展及其他方面取得了一些成果，但对声门区域进行精确且完全自动的语义分割方法的挑战仍然存在。', 'title_zh': 'GIRAFE：声门成像数据集，用于高级分割、分析及辅助回放评估'}
{'arxiv_id': 'arXiv:2412.15047', 'title': 'Measuring, Modeling, and Helping People Account for Privacy Risks in Online Self-Disclosures with AI', 'authors': 'Isadora Krsek, Anubha Kabra, Yao Dou, Tarek Naous, Laura A. Dabbish, Alan Ritter, Wei Xu, Sauvik Das', 'link': 'https://arxiv.org/abs/2412.15047', 'abstract': "In pseudonymous online fora like Reddit, the benefits of self-disclosure are often apparent to users (e.g., I can vent about my in-laws to understanding strangers), but the privacy risks are more abstract (e.g., will my partner be able to tell that this is me?). Prior work has sought to develop natural language processing (NLP) tools that help users identify potentially risky self-disclosures in their text, but none have been designed for or evaluated with the users they hope to protect. Absent this assessment, these tools will be limited by the social-technical gap: users need assistive tools that help them make informed decisions, not paternalistic tools that tell them to avoid self-disclosure altogether. To bridge this gap, we conducted a study with N = 21 Reddit users; we had them use a state-of-the-art NLP disclosure detection model on two of their authored posts and asked them questions to understand if and how the model helped, where it fell short, and how it could be improved to help them make more informed decisions. Despite its imperfections, users responded positively to the model and highlighted its use as a tool that can help them catch mistakes, inform them of risks they were unaware of, and encourage self-reflection. However, our work also shows how, to be useful and usable, AI for supporting privacy decision-making must account for posting context, disclosure norms, and users' lived threat models, and provide explanations that help contextualize detected risks.", 'abstract_zh': '在像Reddit这样的匿名在线论坛中，自我披露的好处对用户来说往往是明显的（例如，我可以向理解我的陌生人们倾诉我的岳父母问题），而隐私风险则是更加抽象的（例如，我的伴侣能猜出这是我在发言吗？）。先前的研究试图开发自然语言处理（NLP）工具来帮助用户识别他们文本中可能存在的风险性自我披露，但这些工具并未为他们希望保护的用户进行设计或评估。缺乏这种评估，这些工具将受限于社会技术差距：用户需要的是能够帮助他们做出知情决策的支持工具，而不是迫使他们完全避免自我披露的指导性工具。为了弥合这一差距，我们对21位Reddit用户进行了研究；我们让他们使用最新的NLP披露检测模型对两个自己撰写的帖子进行了处理，并询问他们关于模型的作用、不足之处以及如何改进以帮助他们做出更加知情的决策。尽管该模型存在缺陷，用户们还是对其持积极态度，并指出它在帮助他们发现错误、告知他们原本不了解的风险以及促进自我反思方面的作用。然而，我们的研究也展示了，为了真正有用并易于使用，支持隐私决策的AI必须考虑到发帖背景、披露规范以及用户的实际威胁模型，并提供解释来帮助解释检测到的风险。', 'title_zh': '用AI衡量、建模以及帮助人们评估在线自我披露中的隐私风险'}
{'arxiv_id': 'arXiv:2412.15004', 'title': 'Large Language Models and Code Security: A Systematic Literature Review', 'authors': 'Enna Basic, Alberto Giaretta', 'link': 'https://arxiv.org/abs/2412.15004', 'abstract': 'Large Language Models (LLMs) have emerged as powerful tools for automating various programming tasks, including security-related ones, such as detecting and fixing vulnerabilities. Despite their promising capabilities, when required to produce or modify pre-existing code, LLMs could introduce vulnerabilities unbeknown to the programmer. When analyzing code, they could miss clear vulnerabilities or signal nonexistent ones. In this Systematic Literature Review (SLR), we aim to investigate both the security benefits and potential drawbacks of using LLMs for a variety of code-related tasks. In particular, first we focus on the types of vulnerabilities that could be introduced by LLMs, when used for producing code. Second, we analyze the capabilities of LLMs to detect and fix vulnerabilities, in any given code, and how the prompting strategy of choice impacts their performance in these two tasks. Last, we provide an in-depth analysis on how data poisoning attacks on LLMs can impact performance in the aforementioned tasks.', 'abstract_zh': '大型语言模型（LLMs）已成为自动化各种编程任务的强大工具，包括安全相关的任务，如检测和修复漏洞。尽管它们具备强大的能力，但在生成或修改现有代码时，LLMs 仍有可能引入未知的漏洞。在分析代码时，LLMs 可能会忽略明显的漏洞，或者错误地标记不存在的漏洞。在本次系统性文献综述（SLR）中，我们旨在研究将LLMs应用于各种代码相关任务的安全优势和潜在缺点。首先，我们将重点关注LLMs在生成代码时可能引入的漏洞类型。其次，我们将分析LLMs在任意给定代码中检测和修复漏洞的能力，以及不同的提示策略如何影响它们在这两项任务中的性能。最后，我们将深入分析针对LLMs的数据投毒攻击如何影响上述任务的性能。', 'title_zh': '大型语言模型与代码安全：一项系统文献综述'}
{'arxiv_id': 'arXiv:2412.14995', 'title': 'HSEvo: Elevating Automatic Heuristic Design with Diversity-Driven Harmony Search and Genetic Algorithm Using LLMs', 'authors': 'Pham Vu Tuan Dat, Long Doan, Huynh Thi Thanh Binh', 'link': 'https://arxiv.org/abs/2412.14995', 'abstract': "Automatic Heuristic Design (AHD) is an active research area due to its utility in solving complex search and NP-hard combinatorial optimization problems in the real world. The recent advancements in Large Language Models (LLMs) introduce new possibilities by coupling LLMs with evolutionary computation to automatically generate heuristics, known as LLM-based Evolutionary Program Search (LLM-EPS). While previous LLM-EPS studies obtained great performance on various tasks, there is still a gap in understanding the properties of heuristic search spaces and achieving a balance between exploration and exploitation, which is a critical factor in large heuristic search spaces. In this study, we address this gap by proposing two diversity measurement metrics and perform an analysis on previous LLM-EPS approaches, including FunSearch, EoH, and ReEvo. Results on black-box AHD problems reveal that while EoH demonstrates higher diversity than FunSearch and ReEvo, its objective score is unstable. Conversely, ReEvo's reflection mechanism yields good objective scores but fails to optimize diversity effectively. With this finding in mind, we introduce HSEvo, an adaptive LLM-EPS framework that maintains a balance between diversity and convergence with a harmony search algorithm. Through experimentation, we find that HSEvo achieved high diversity indices and good objective scores while remaining cost-effective. These results underscore the importance of balancing exploration and exploitation and understanding heuristic search spaces in designing frameworks in LLM-EPS.", 'abstract_zh': '自动启发式设计（AHD）是一个活跃的研究领域，因为它在解决实际中的复杂搜索和NP难组合优化问题方面具有重要作用。最近，大型语言模型（LLMs）的发展为通过将LLMs与进化计算相结合来自动生成启发式方法提供了新的可能性，这种方法被称为基于大语言模型的进化程序搜索（LLM-EPS）。尽管先前的LLM-EPS研究在各种任务上取得了出色的性能，但在了解启发式搜索空间的特性以及在大启发式搜索空间中实现探索与利用之间的平衡方面仍存在差距，这是关键因素之一。在这项研究中，我们通过提出两种多样性的度量标准，并对先前的LLM-EPS方法进行分析，包括FunSearch、EoH和ReEvo，来解决这一差距。在黑盒AHD问题上的结果表明，尽管EoH的多样性高于FunSearch和ReEvo，但其目标评分不稳定。相反，ReEvo的反射机制获得了较好的目标评分，但在有效优化多样性方面却存在问题。基于这一发现，我们引入了一个适应性的LLM-EPS框架——HSEvo——它通过使用和谐搜索算法在多样性和收敛性之间保持平衡。通过实验，我们发现HSEvo在保持较高多样性指数和良好目标评分的同时，还具有成本效益。这些结果强调了在LLM-EPS框架设计中平衡探索与利用以及理解启发式搜索空间的重要性。', 'title_zh': 'HSEvo：通过多样性驱动的和谐搜索和遗传算法利用大规模语言模型自动启发式设计的提升'}
{'arxiv_id': 'arXiv:2412.14965', 'title': 'Movie2Story: A framework for understanding videos and telling stories in the form of novel text', 'authors': 'Kangning Li, Zheyang Jia, Anyu Ying', 'link': 'https://arxiv.org/abs/2412.14965', 'abstract': 'Multimodal video-to-text models have made considerable progress, primarily in generating brief descriptions of video content. However, there is still a deficiency in generating rich long-form text descriptions that integrate both video and audio. In this paper, we introduce a framework called M2S, designed to generate novel-length text by combining audio, video, and character recognition. M2S includes modules for video long-form text description and comprehension, audio-based analysis of emotion, speech rate, and character alignment, and visual-based character recognition alignment. By integrating multimodal information using the large language model GPT4o, M2S stands out in the field of multimodal text generation. We demonstrate the effectiveness and accuracy of M2S through comparative experiments and human evaluation. Additionally, the model framework has good scalability and significant potential for future research.', 'abstract_zh': '多模态视频到文本模型在生成简短的视频内容描述方面取得了显著进展。然而，仍存在生成丰富的长篇描述性文本的不足，这些描述性文本需要结合视频和音频信息。本文介绍了一种名为M2S的框架，旨在通过结合音频、视频和字符识别来生成新的文本长度描述。M2S包括用于生成和理解视频长篇文本描述的模块、基于音频的情绪分析、语速分析和角色对齐分析，以及基于视觉的字符识别对齐。通过使用大型语言模型GPT4o整合多模态信息，M2S在多模态文本生成领域脱颖而出。我们通过对比实验和人工评估展示了M2S的有效性和准确性。此外，该模型框架具有良好的扩展性，并且具有未来研究的巨大潜力。', 'title_zh': 'Movie2Story：一个理解视频并以新颖文本形式讲述故事的框架'}
{'arxiv_id': 'arXiv:2412.14933', 'title': 'Cirbo: A New Tool for Boolean Circuit Analysis and Synthesis', 'authors': 'Daniil Averkov, Tatiana Belova, Gregory Emdin, Mikhail Goncharov, Viktoriia Krivogornitsyna, Alexander S. Kulikov, Fedor Kurmazov, Daniil Levtsov, Georgie Levtsov, Vsevolod Vaskin, Aleksey Vorobiev', 'link': 'https://arxiv.org/abs/2412.14933', 'abstract': 'We present an open-source tool for manipulating Boolean circuits. It implements efficient algorithms, both existing and novel, for a rich variety of frequently used circuit tasks such as satisfiability, synthesis, and minimization. We tested the tool on a wide range of practically relevant circuits (computing, in particular, symmetric and arithmetic functions) that have been optimized intensively by the community for the last three years. The tool helped us to win the IWLS 2024 Programming Contest. In 2023, it was Google DeepMind who took the first place in the competition. We were able to reduce the size of the best circuits from 2023 by 12\\% on average, whereas for some individual circuits, our size reduction was as large as 83\\%.', 'abstract_zh': '我们介绍了一个开源工具，用于操作布尔电路。该工具实现了高效算法，包括现有的和新颖的算法，以处理各种常用电路任务，如可满足性、综合和最小化。我们在过去三年中由社区精心优化的广泛实际相关电路（特别是在计算对称和算术函数方面）上测试了该工具。该工具帮助我们在IWLS 2024编程竞赛中取得了胜利。2023年，Google DeepMind 在竞赛中取得了第一名。我们成功地将2023年最佳电路的大小平均减少了12%，而在某些单独的电路中，我们的尺寸减少高达83%。', 'title_zh': 'Cirbo：一种新的布尔电路分析与综合工具'}
{'arxiv_id': 'arXiv:2412.14922', 'title': 'RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response', 'authors': 'Junyu Luo, Xiao Luo, Kaize Ding, Jingyang Yuan, Zhiping Xiao, Ming Zhang', 'link': 'https://arxiv.org/abs/2412.14922', 'abstract': "Supervised fine-tuning (SFT) plays a crucial role in adapting large language models (LLMs) to specific domains or tasks. However, as demonstrated by empirical experiments, the collected data inevitably contains noise in practical applications, which poses significant challenges to model performance on downstream tasks. Therefore, there is an urgent need for a noise-robust SFT framework to enhance model capabilities in downstream tasks. To address this challenge, we introduce a robust SFT framework (RobustFT) that performs noise detection and relabeling on downstream task data. For noise identification, our approach employs a multi-expert collaborative system with inference-enhanced models to achieve superior noise detection. In the denoising phase, we utilize a context-enhanced strategy, which incorporates the most relevant and confident knowledge followed by careful assessment to generate reliable annotations. Additionally, we introduce an effective data selection mechanism based on response entropy, ensuring only high-quality samples are retained for fine-tuning. Extensive experiments conducted on multiple LLMs across five datasets demonstrate RobustFT's exceptional performance in noisy scenarios.", 'abstract_zh': '监督微调（SFT）在适应大规模语言模型（LLMs）到特定领域或任务方面发挥着重要作用。然而，如实践经验所显示的，实际应用中收集的数据不可避免地包含噪声，这对下游任务的模型性能构成了重大挑战。因此，迫切需要一个抗噪的SFT框架以提高模型在下游任务中的能力。为应对这一挑战，我们引入了一个抗噪SFT框架（RobustFT），该框架能够在下游任务数据中进行噪声检测和重新标注。在噪声识别方面，我们的方法采用多专家协作系统和推理增强模型以实现优越的噪声检测效果。在去噪阶段，我们采用了上下文增强策略，该策略结合了最相关且自信的知识，并经过仔细评估以生成可靠标注。此外，我们引入了一种基于响应熵的有效数据选择机制，确保仅保留高质量样本进行微调。在多个LLM上进行的跨五个数据集的广泛实验表明，RobustFT在噪声场景下表现出色。', 'title_zh': 'RobustFT：在嘈杂响应条件下大型语言模型的稳健监督微调'}
{'arxiv_id': 'arXiv:2412.14905', 'title': 'Dehallucinating Parallel Context Extension for Retrieval-Augmented Generation', 'authors': 'Zexiong Ma, Shengnan An, Zeqi Lin, Yanzhen Zou, Jian-Guang Lou, Bing Xie', 'link': 'https://arxiv.org/abs/2412.14905', 'abstract': 'Large language models (LLMs) are susceptible to generating hallucinated information, despite the integration of retrieval-augmented generation (RAG). Parallel context extension (PCE) is a line of research attempting to effectively integrating parallel (unordered) contexts, while it still suffers from hallucinations when adapted to RAG scenarios. In this paper, we propose DePaC (Dehallucinating Parallel Context Extension), which alleviates the hallucination problem with context-aware negative training and information-calibrated aggregation. DePaC is designed to alleviate two types of in-context hallucination: fact fabrication (i.e., LLMs present claims that are not supported by the contexts) and fact omission (i.e., LLMs fail to present claims that can be supported by the contexts). Specifically, (1) for fact fabrication, we apply the context-aware negative training that fine-tunes the LLMs with negative supervisions, thus explicitly guiding the LLMs to refuse to answer when contexts are not related to questions; (2) for fact omission, we propose the information-calibrated aggregation which prioritizes context windows with higher information increment from their contexts. The experimental results on nine RAG tasks demonstrate that DePaC significantly alleviates the two types of hallucination and consistently achieves better performances on these tasks.', 'abstract_zh': '以下是经过学术规范翻译后的论文内容或标题：\n\n大型语言模型（LLMs）在融合检索增强生成（RAG）技术后，仍有可能生成虚假信息。平行上下文扩展（PCE）是一类旨在有效整合不相关上下文的研究方法，但当应用于RAG场景时，仍然存在生成虚假信息的问题。本文提出了一种名为DePaC（Dehallucinating Parallel Context Extension）的方案，通过上下文感知的负向训练和信息校准聚合来缓解虚假信息问题。DePaC 设计用于解决两种类型的上下文内部虚假信息问题：事实杜撰（即，LLMs 提供与上下文无关的断言）和事实遗漏（即，LLMs 未能提供可以支持上下文的断言）。具体而言，(1) 对于事实杜撰，我们采用上下文感知的负向训练，对LLMs 进行微调并接受负向监督，从而使LLMs 显式地在上下文与问题无关时拒绝回答；(2) 对于事实遗漏，我们提出了信息校准聚合方法，优先考虑信息增量较大的上下文窗口。在九个RAG任务上的实验结果表明，DePaC 显著缓解了这两种虚假信息问题，并在这些任务上始终取得了更好的表现。', 'title_zh': '去 hallucination 的并行上下文扩展用于检索增强生成\n\n在这个翻译中，“Dehallucinating”被理解为去除或纠正hallucination（即生成与输入或知识库不符的内容），以更符合学术表达。“Parallel Context Extension for Retrieval-Augmented Generation”被直接翻译为“并行上下文扩展用于检索增强生成”。这样的翻译既保留了原意，又符合学术论文的表述规范。'}
{'arxiv_id': 'arXiv:2412.14869', 'title': 'AI-Powered Intracranial Hemorrhage Detection: A Co-Scale Convolutional Attention Model with Uncertainty-Based Fuzzy Integral Operator and Feature Screening', 'authors': 'Mehdi Hosseini Chagahi, Md. Jalil Piran, Niloufar Delfan, Behzad Moshiri, Jaber Hatam Parikhan', 'link': 'https://arxiv.org/abs/2412.14869', 'abstract': 'Intracranial hemorrhage (ICH) refers to the leakage or accumulation of blood within the skull, which occurs due to the rupture of blood vessels in or around the brain. If this condition is not diagnosed in a timely manner and appropriately treated, it can lead to serious complications such as decreased consciousness, permanent neurological disabilities, or even this http URL primary aim of this study is to detect the occurrence or non-occurrence of ICH, followed by determining the type of subdural hemorrhage (SDH). These tasks are framed as two separate binary classification problems. By adding two layers to the co-scale convolutional attention (CCA) classifier architecture, we introduce a novel approach for ICH detection. In the first layer, after extracting features from different slices of computed tomography (CT) scan images, we combine these features and select the 50 components that capture the highest variance in the data, considering them as informative features. We then assess the discriminative power of these features using the bootstrap forest algorithm, discarding those that lack sufficient discriminative ability between different classes. This algorithm explicitly determines the contribution of each feature to the final prediction, assisting us in developing an explainable AI model. The features feed into a boosting neural network as a latent feature space. In the second layer, we introduce a novel uncertainty-based fuzzy integral operator to fuse information from different CT scan slices. This operator, by accounting for the dependencies between consecutive slices, significantly improves detection accuracy.', 'abstract_zh': '颅内出血（ICH）是指血液在颅骨内部的泄漏或积聚，通常是由于颅内或颅内周围血管的破裂所致。若未及时诊断并适当治疗，可能会导致意识下降、永久性神经功能障碍，甚至危及生命。本研究的主要目标是检测ICH的发生或不存在，随后确定是否为硬脑膜下出血（SDH）。将这两个任务作为两个独立的二元分类问题进行建模。通过在联合尺度卷积注意力（CCA）分类器架构中加入两层结构，我们提出了一种新的ICH检测方法。第一层中，通过对计算机断层扫描（CT）图像的不同层面进行特征提取后，将这些特征结合，并选择出能够捕捉数据最高方差的50个特征，作为信息特征。然后，我们使用自助森林算法评估这些特征的辨别能力，剔除那些在不同类别间鉴别能力不够强的特征。此算法明确地确定了每个特征对最终预测的贡献，帮助我们构建可解释的人工智能模型。特征被输送到增强神经网络中作为潜在特征空间。第二层中，我们引入了一种基于不确定性的新模糊积分算子以融合不同CT扫描层面的信息。该算子通过考虑连续层面之间的依赖关系，显著提高了检测准确性。', 'title_zh': '基于AI的颅内出血检测：一种基于不确定性模糊积分运算器和特征筛选的共尺度卷积注意力模型'}
{'arxiv_id': 'arXiv:2412.14847', 'title': 'A Survey of RWKV', 'authors': 'Zhiyuan Li, Tingyu Xia, Yi Chang, Yuan Wu', 'link': 'https://arxiv.org/abs/2412.14847', 'abstract': 'The Receptance Weighted Key Value (RWKV) model offers a novel alternative to the Transformer architecture, merging the benefits of recurrent and attention-based systems. Unlike conventional Transformers, which depend heavily on self-attention, RWKV adeptly captures long-range dependencies with minimal computational demands. By utilizing a recurrent framework, RWKV addresses some computational inefficiencies found in Transformers, particularly in tasks with long sequences. RWKV has recently drawn considerable attention for its robust performance across multiple domains. Despite its growing popularity, no systematic review of the RWKV model exists. This paper seeks to fill this gap as the first comprehensive review of the RWKV architecture, its core principles, and its varied applications, such as natural language generation, natural language understanding, and computer vision. We assess how RWKV compares to traditional Transformer models, highlighting its capability to manage long sequences efficiently and lower computational costs. Furthermore, we explore the challenges RWKV encounters and propose potential directions for future research and advancement. We consistently maintain the related open-source materials at: this https URL.', 'abstract_zh': '受容性加权关键值（RWKV）模型提供了一种替代传统的Transformer架构的新颖选择，结合了循环网络和基于注意力系统的优点。与依赖于自我注意的常规Transformer不同，RWKV能够以最小的计算需求高效地捕捉长范围依赖关系。通过使用递归框架，RWKV解决了传统Transformer在处理长序列任务时的一些计算效率低下的问题。RWKV最近因其在多个领域的稳健表现引起了广泛注意。尽管其日益流行，但目前还没有系统性的RWKV模型综述。本文旨在填补这一空白，作为第一个全面综述RWKV架构、核心原则及其各种应用（如自然语言生成、自然语言理解和计算机视觉）的论文。我们评估了RWKV与传统Transformer模型的差异，并突显了其在高效处理长序列和降低计算成本方面的能力。此外，我们探讨了RWKV所面临的技术挑战，并提出了未来研究和发展的潜在方向。我们始终维护相关的开源材料，请参阅以下链接：https://this-url。', 'title_zh': '《RWKV综述》\n\n在这个翻译中，“A Survey of”被译为“综述”，“RWKV”保持不变，因为在这种情况下，它可能是指一个特定的模型或系统的名称。如果RWKV是某个特定领域的专有名词，通常不需要翻译。如果有更多具体内容需要翻译或进一步讨论，请告诉我！'}
{'arxiv_id': 'arXiv:2412.14846', 'title': 'Head and Neck Tumor Segmentation of MRI from Pre- and Mid-radiotherapy with Pre-training, Data Augmentation and Dual Flow UNet', 'authors': 'Litingyu Wang, Wenjun Liao, Shichuan Zhang, Guotai Wang', 'link': 'https://arxiv.org/abs/2412.14846', 'abstract': 'Head and neck tumors and metastatic lymph nodes are crucial for treatment planning and prognostic analysis. Accurate segmentation and quantitative analysis of these structures require pixel-level annotation, making automated segmentation techniques essential for the diagnosis and treatment of head and neck cancer. In this study, we investigated the effects of multiple strategies on the segmentation of pre-radiotherapy (pre-RT) and mid-radiotherapy (mid-RT) images. For the segmentation of pre-RT images, we utilized: 1) a fully supervised learning approach, and 2) the same approach enhanced with pre-trained weights and the MixUp data augmentation technique. For mid-RT images, we introduced a novel computational-friendly network architecture that features separate encoders for mid-RT images and registered pre-RT images with their labels. The mid-RT encoder branch integrates information from pre-RT images and labels progressively during the forward propagation. We selected the highest-performing model from each fold and used their predictions to create an ensemble average for inference. In the final test, our models achieved a segmentation performance of 82.38% for pre-RT and 72.53% for mid-RT on aggregated Dice Similarity Coefficient (DSC) as HiLab. Our code is available at this https URL.', 'abstract_zh': '头颈部肿瘤及其转移淋巴结对于治疗规划和预后分析至关重要。准确分割和定量分析这些结构需要像素级标注，因此自动分割技术对于头颈部癌症的诊断和治疗至关重要。在本研究中，我们探讨了多种策略对预治疗（pre-RT）和中程治疗（mid-RT）图像分割效果的影响。对于pre-RT图像分割，我们采用了：1）完全监督学习方法，以及2）结合预训练权重和MixUp数据扩增技术的增强方法。对于mid-RT图像，我们引入了一种新颖的计算友好型网络架构，该架构包括专门用于mid-RT图像的编码器和与pre-RT图像及其标签配准的编码器。mid-RT编码器分支在前向传播过程中逐步整合来自pre-RT图像和标签的信息。我们从每个折中的最优模型中选择了表现最好的模型，并使用它们的预测结果进行集成推理。最终测试中，我们的模型在HiLab汇总Dice相似系数（DSC）上的分割性能分别为pre-RT图像82.38%和mid-RT图像72.53%。我们的代码可在此处获得：this https URL。', 'title_zh': '在预治疗和中期放疗的MRI图像中基于预训练、数据增强和双流UNet的头部和颈部肿瘤分割'}
{'arxiv_id': 'arXiv:2412.14843', 'title': 'Mapping and Influencing the Political Ideology of Large Language Models using Synthetic Personas', 'authors': 'Pietro Bernardelle, Leon Fröhling, Stefano Civelli, Riccardo Lunardi, Kevin Roiter, Gianluca Demartini', 'link': 'https://arxiv.org/abs/2412.14843', 'abstract': "The analysis of political biases in large language models (LLMs) has primarily examined these systems as single entities with fixed viewpoints. While various methods exist for measuring such biases, the impact of persona-based prompting on LLMs' political orientation remains unexplored. In this work we leverage PersonaHub, a collection of synthetic persona descriptions, to map the political distribution of persona-based prompted LLMs using the Political Compass Test (PCT). We then examine whether these initial compass distributions can be manipulated through explicit ideological prompting towards diametrically opposed political orientations: right-authoritarian and left-libertarian. Our experiments reveal that synthetic personas predominantly cluster in the left-libertarian quadrant, with models demonstrating varying degrees of responsiveness when prompted with explicit ideological descriptors. While all models demonstrate significant shifts towards right-authoritarian positions, they exhibit more limited shifts towards left-libertarian positions, suggesting an asymmetric response to ideological manipulation that may reflect inherent biases in model training.", 'abstract_zh': '对大型语言模型（LLMs）中的政治偏见进行分析主要将这些系统视为具有固定视角的单一实体。虽然存在多种测量偏见的方法，但基于人设的提示对LLMs政治倾向的影响尚未得到探索。本研究利用PersonaHub合集——一个合成人设描述的集合——通过政治取向测试（PCT）来绘制基于人设的提示LLMs的政治分布图。我们随后探讨是否可以通过明确指示意识形态来操控这些初始的政治取向分布，进而使其偏向完全对立的政治取向：右翼权威主义和左翼自由主义。实验结果显示，合成人设主要集中在左翼自由主义象限，当使用明确的意识形态描述进行提示时，模型显示出不同程度的响应。所有模型在右翼权威主义方向上都表现出显著的转变，但在左翼自由主义方向上的转变则更为有限，这表明对意识形态操纵的不对称响应可能反映了模型训练中的固有偏见。', 'title_zh': '使用合成人物映射和影响大型语言模型的政治意识形态'}
{'arxiv_id': 'arXiv:2412.14841', 'title': 'Helping LLMs Improve Code Generation Using Feedback from Testing and Static Analysis', 'authors': 'Greta Dolcetti, Vincenzo Arceri, Eleonora Iotti, Sergio Maffeis, Agostino Cortesi, Enea Zaffanella', 'link': 'https://arxiv.org/abs/2412.14841', 'abstract': 'Large Language Models (LLMs) are one of the most promising developments in the field of artificial intelligence, and the software engineering community has readily noticed their potential role in the software development life-cycle. Developers routinely ask LLMs to generate code snippets, increasing productivity but also potentially introducing ownership, privacy, correctness, and security issues. Previous work highlighted how code generated by mainstream commercial LLMs is often not safe, containing vulnerabilities, bugs, and code smells. In this paper, we present a framework that leverages testing and static analysis to assess the quality, and guide the self-improvement, of code generated by general-purpose, open-source LLMs.\nFirst, we ask LLMs to generate C code to solve a number of programming tasks. Then we employ ground-truth tests to assess the (in)correctness of the generated code, and a static analysis tool to detect potential safety vulnerabilities. Next, we assess the models ability to evaluate the generated code, by asking them to detect errors and vulnerabilities. Finally, we test the models ability to fix the generated code, providing the reports produced during the static analysis and incorrectness evaluation phases as feedback.\nOur results show that models often produce incorrect code, and that the generated code can include safety issues. Moreover, they perform very poorly at detecting either issue. On the positive side, we observe a substantial ability to fix flawed code when provided with information about failed tests or potential vulnerabilities, indicating a promising avenue for improving the safety of LLM-based code generation tools.', 'abstract_zh': '大型语言模型（LLMs）是人工智能领域最具前景的发展之一，软件工程社区也已经注意到它们在软件开发生命周期中的潜在作用。开发者经常要求LLMs生成代码片段，从而提高生产效率，但也可能引入所有权、隐私、正确性及安全性方面的问题。前期研究指出，主流商业LLMs生成的代码往往不够安全，包含漏洞、错误和代码异味。在本文中，我们提出了一种框架，通过测试和静态分析来评估由通用开源LLMs生成的代码的质量，并引导这些模型进行自我优化。\n\n首先，我们要求LLMs生成C代码以解决一系列编程任务。然后，我们使用真实的测试来评估生成代码的（不）正确性，并使用静态分析工具检测潜在的安全漏洞。接下来，我们评估模型评估生成代码的能力，通过要求模型检测错误和漏洞。最后，我们测试模型修复生成代码的能力，提供在静态分析和不正确性评估阶段产生的报告作为反馈。\n\n我们的研究表明，模型经常生成错误的代码，生成的代码中可能包含安全问题。此外，它们在检测这些错误和问题方面表现非常糟糕。不过，当我们提供关于失败测试或潜在漏洞的信息时，我们观察到模型在修复存在问题的代码方面表现出明显的潜力，这为进一步改进基于LLM的代码生成工具的安全性提供了有前途的途径。', 'title_zh': '使用测试和静态分析反馈帮助大型语言模型提升代码生成能力'}
{'arxiv_id': 'arXiv:2412.14835', 'title': 'Progressive Multimodal Reasoning via Active Retrieval', 'authors': 'Guanting Dong, Chenghao Zhang, Mengjie Deng, Yutao Zhu, Zhicheng Dou, Ji-Rong Wen', 'link': 'https://arxiv.org/abs/2412.14835', 'abstract': 'Multi-step multimodal reasoning tasks pose significant challenges for multimodal large language models (MLLMs), and finding effective ways to enhance their performance in such scenarios remains an unresolved issue. In this paper, we propose AR-MCTS, a universal framework designed to progressively improve the reasoning capabilities of MLLMs through Active Retrieval (AR) and Monte Carlo Tree Search (MCTS). Our approach begins with the development of a unified retrieval module that retrieves key supporting insights for solving complex reasoning problems from a hybrid-modal retrieval corpus. To bridge the gap in automated multimodal reasoning verification, we employ the MCTS algorithm combined with an active retrieval mechanism, which enables the automatic generation of step-wise annotations. This strategy dynamically retrieves key insights for each reasoning step, moving beyond traditional beam search sampling to improve the diversity and reliability of the reasoning space. Additionally, we introduce a process reward model that aligns progressively to support the automatic verification of multimodal reasoning tasks. Experimental results across three complex multimodal reasoning benchmarks confirm the effectiveness of the AR-MCTS framework in enhancing the performance of various multimodal models. Further analysis demonstrates that AR-MCTS can optimize sampling diversity and accuracy, yielding reliable multimodal reasoning.', 'abstract_zh': '多步骤多模态推理任务对多模态大型语言模型（MLLMs）提出了显著挑战，而在这种场景中提升其性能的有效方法仍然是未解之谜。本文提出了一种名为AR-MCTS的通用框架，旨在通过主动检索（AR）和蒙特卡洛树搜索（MCTS）逐步提高MLLMs的推理能力。我们的方法首先构建了一个统一的检索模块，从混合模态检索库中检索解决复杂推理问题的关键支持洞察。为了解决自动多模态推理验证的差距，我们采用了结合主动检索机制的MCTS算法，这能够自动生成逐步骤的注解。该策略动态检索每个推理步骤的关键洞察，超越传统的束搜索采样方法，以提高推理空间的多样性和可靠性。此外，我们还引入了一种过程奖励模型，以逐步支持多模态推理任务的自动验证。在三个复杂的多模态推理基准测试中，实验结果证实了AR-MCTS框架在提升各种多模态模型性能方面的有效性。进一步的分析表明，AR-MCTS能够优化采样多样性和准确性，从而实现可靠的多模态推理。', 'title_zh': '通过主动检索实现逐步多模态推理'}
{'arxiv_id': 'arXiv:2412.14810', 'title': 'MARIA: a Multimodal Transformer Model for Incomplete Healthcare Data', 'authors': 'Camillo Maria Caruso, Paolo Soda, Valerio Guarrasi', 'link': 'https://arxiv.org/abs/2412.14810', 'abstract': 'In healthcare, the integration of multimodal data is pivotal for developing comprehensive diagnostic and predictive models. However, managing missing data remains a significant challenge in real-world applications. We introduce MARIA (Multimodal Attention Resilient to Incomplete datA), a novel transformer-based deep learning model designed to address these challenges through an intermediate fusion strategy. Unlike conventional approaches that depend on imputation, MARIA utilizes a masked self-attention mechanism, which processes only the available data without generating synthetic values. This approach enables it to effectively handle incomplete datasets, enhancing robustness and minimizing biases introduced by imputation methods. We evaluated MARIA against 10 state-of-the-art machine learning and deep learning models across 8 diagnostic and prognostic tasks. The results demonstrate that MARIA outperforms existing methods in terms of performance and resilience to varying levels of data incompleteness, underscoring its potential for critical healthcare applications.', 'abstract_zh': '在医疗保健领域，多模态数据的综合对于发展全面的诊断和预测模型至关重要。然而，在实际应用中，管理缺失数据仍然是一个重大挑战。为此，我们提出了MARIA（Multimodal Attention Resilient to Incomplete datA），一种新型的基于变压器的深度学习模型，通过中间融合策略来应对这些挑战。与依赖于数据填充的传统方法不同，MARIA 利用了遮罩自注意力机制，只处理可用数据而不生成合成值。这种方法使其能够有效处理不完整的数据集，增强其鲁棒性，并最大限度地减少由填充方法引入的偏差。我们对MARIA进行了全面的评估，与8个诊断和预后任务中的10个最先进的机器学习和深度学习模型进行了比较。结果表明，MARIA在性能和对数据不完整性变化程度的鲁棒性方面均优于现有方法，为其在关键医疗应用中的潜力提供了有力支持。', 'title_zh': 'MARIA：一种用于不完整医疗数据的多模态变压器模型'}
{'arxiv_id': 'arXiv:2412.14802', 'title': 'Stack Trace Deduplication: Faster, More Accurately, and in More Realistic Scenarios', 'authors': 'Egor Shibaev, Denis Sushentsev, Yaroslav Golubev, Aleksandr Khvorov', 'link': 'https://arxiv.org/abs/2412.14802', 'abstract': 'In large-scale software systems, there are often no fully-fledged bug reports with human-written descriptions when an error occurs. In this case, developers rely on stack traces, i.e., series of function calls that led to the error. Since there can be tens and hundreds of thousands of them describing the same issue from different users, automatic deduplication into categories is necessary to allow for processing. Recent works have proposed powerful deep learning-based approaches for this, but they are evaluated and compared in isolation from real-life workflows, and it is not clear whether they will actually work well at scale.\nTo overcome this gap, this work presents three main contributions: a novel model, an industry-based dataset, and a multi-faceted evaluation. Our model consists of two parts - (1) an embedding model with byte-pair encoding and approximate nearest neighbor search to quickly find the most relevant stack traces to the incoming one, and (2) a reranker that re-ranks the most fitting stack traces, taking into account the repeated frames between them. To complement the existing datasets collected from open-source projects, we share with the community SlowOps - a dataset of stack traces from IntelliJ-based products developed by JetBrains, which has an order of magnitude more stack traces per category. Finally, we carry out an evaluation that strives to be realistic: measuring not only the accuracy of categorization, but also the operation time and the ability to create new categories. The evaluation shows that our model strikes a good balance - it outperforms other models on both open-source datasets and SlowOps, while also being faster on time than most. We release all of our code and data, and hope that our work can pave the way to further practice-oriented research in the area.', 'abstract_zh': '在大规模软件系统中，当错误发生时，通常没有详细的人工描述的完全完善的bug报告。在这种情况下，开发人员依赖于堆栈跟踪，即导致错误的一系列函数调用。由于可能存在成千上万个描述同一问题的不同用户的信息，因此需要自动分组到不同的类别中以便处理。最近的研究提出了一些基于深度学习的强大方法，但这些方法在实际工作流程中并未得到评估和比较，不清楚它们在大规模应用中是否有效。\n\n为了解决这一差距，本研究提出了三个主要贡献：一个新颖的模型，一个基于工业的实际数据集，以及多层次的评估。我们的模型由两个部分组成——（1）嵌入模型，采用字节对编码和近似最近邻搜索，以快速找到与当前堆栈跟踪最相关的堆栈跟踪；（2）一个重排序模块，重新排列最合适的堆栈跟踪，考虑它们之间的重复帧。为了补充现有的来自开源项目的数据集，我们与社区分享了来自JetBrains的基于IntelliJ产品的SlowOps数据集，该数据集每个类别中的堆栈跟踪数量比现有数据集多一个数量级。最后，我们进行了一种力求实际的评估：不仅测量类别化精度，还测量操作时间以及创建新类别的能力。评估结果显示，我们的模型表现均衡——在开源数据集和SlowOps上均优于其他模型，同时在时间上也比大多数模型更快。我们发布了所有代码和数据，希望能够为该领域的实践导向研究铺平道路。', 'title_zh': '栈跟踪去重：更快、更准确、并在更多现实场景中实现'}
{'arxiv_id': 'arXiv:2412.14779', 'title': 'Agent-Temporal Credit Assignment for Optimal Policy Preservation in Sparse Multi-Agent Reinforcement Learning', 'authors': 'Aditya Kapoor, Sushant Swamy, Kale-ab Tessera, Mayank Baranwal, Mingfei Sun, Harshad Khadilkar, Stefano V. Albrecht', 'link': 'https://arxiv.org/abs/2412.14779', 'abstract': 'In multi-agent environments, agents often struggle to learn optimal policies due to sparse or delayed global rewards, particularly in long-horizon tasks where it is challenging to evaluate actions at intermediate time steps. We introduce Temporal-Agent Reward Redistribution (TAR$^2$), a novel approach designed to address the agent-temporal credit assignment problem by redistributing sparse rewards both temporally and across agents. TAR$^2$ decomposes sparse global rewards into time-step-specific rewards and calculates agent-specific contributions to these rewards. We theoretically prove that TAR$^2$ is equivalent to potential-based reward shaping, ensuring that the optimal policy remains unchanged. Empirical results demonstrate that TAR$^2$ stabilizes and accelerates the learning process. Additionally, we show that when TAR$^2$ is integrated with single-agent reinforcement learning algorithms, it performs as well as or better than traditional multi-agent reinforcement learning methods.', 'abstract_zh': '在多智能体环境中，智能体常常难以学习最优策略，尤其是在稀疏或延迟的全局奖励以及长期任务中，评估中间时间步骤的动作尤为困难。为此，我们提出了时间智能体奖励再分配（Temporal-Agent Reward Redistribution，简称TAR$^2$），这是一种旨在通过在时间和智能体之间重分配稀疏奖励来解决智能体-时间信用分配问题的新型方法。TAR$^2$将稀疏的全局奖励分解为时间步长特定的奖励，并计算每个智能体对这些奖励的贡献。我们从理论上证明了TAR$^2$等同于基于势的奖励塑形，确保最优策略不发生变化。实验结果表明，TAR$^2$能够稳定并加速学习过程。此外，我们还展示了在将TAR$^2$与单智能体强化学习算法结合时，其性能至少与传统多智能体强化学习方法相当或更优。', 'title_zh': '基于代理-时间信用分配的稀疏多代理强化学习中优化策略保留方法'}
{'arxiv_id': 'arXiv:2412.14775', 'title': 'Energy and polarization based on-line interference mitigation in radio interferometry', 'authors': 'Sarod Yatawatta, Albert-Jan Boonstra, Chris P. Broekema', 'link': 'https://arxiv.org/abs/2412.14775', 'abstract': 'Radio frequency interference (RFI) is a persistent contaminant in terrestrial radio astronomy. While new radio interferometers are becoming operational, novel sources of RFI are also emerging. In order to strengthen the mitigation of RFI in modern radio interferometers, we propose an on-line RFI mitigation scheme that can be run in the correlator of such interferometers. We combine statistics based on the energy as well as the polarization alignment of the correlated signal to develop an on-line RFI mitigation scheme that can be applied to a data stream produced by the correlator in real-time, especially targeted at low duty-cycle or transient RFI detection. In order to improve the computational efficiency, we explore the use of both single precision and half precision floating point operations in implementing the RFI mitigation algorithm. This ideally suits its deployment in accelerator computing devices such as graphics processing units (GPUs) as used by the LOFAR correlator. We provide results based on real data to demonstrate the efficacy of the proposed method.', 'abstract_zh': '射频干扰（RFI）是地面无线电天文学中的一个持久性污染物。随着新的射电干涉仪投入运行，新的RFI来源也正在出现。为了加强现代射电干涉仪中RFI的减轻措施，我们提出了一种可在此类干涉仪的关联器中运行的在线RFI减轻方案。我们结合基于关联信号能量及其偏振对齐的统计方法，开发了一种在线RFI减轻方案，可以在关联器生成的数据流中实现实时应用，特别针对低占用率或瞬态RFI的检测。为了提高计算效率，我们探索了在实施RFI减轻算法时使用单精度和半精度浮点运算的可能性。这使其非常适合在如LOFAR关联器所使用的图形处理单元（GPU）等加速计算设备上部署。我们基于实际数据提供了结果，以证明所提出方法的有效性。', 'title_zh': '基于能量和极化在线干扰抑制的射电干涉ometry方法'}
{'arxiv_id': 'arXiv:2412.14771', 'title': 'ALKAFI-LLAMA3: Fine-Tuning LLMs for Precise Legal Understanding in Palestine', 'authors': 'Rabee Qasem, Mohannad Hendi, Banan Tantour', 'link': 'https://arxiv.org/abs/2412.14771', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable potential in diverse domains, yet their application in the legal sector, particularly in low-resource contexts, remains limited. This study addresses the challenges of adapting LLMs to the Palestinian legal domain, where political instability, fragmented legal frameworks, and limited AI resources hinder effective machine-learning applications. We present a fine-tuned model based on a quantized version of Llama-3.2-1B-Instruct, trained on a synthetic data set derived from Palestinian legal texts. Using smaller-scale models and strategically generated question-answer pairs, we achieve a cost-effective, locally sustainable solution that provides accurate and contextually relevant legal guidance. Our experiments demonstrate promising performance on various query types, ranging from yes/no questions and narrative explanations to complex legal differentiations, while highlighting areas for improvement, such as handling calculation-based inquiries and structured list formatting. This work provides a pathway for the deployment of AI-driven legal assistance tools tailored to the needs of resource-constrained environments.', 'abstract_zh': '大型语言模型（LLMs）在多个领域展现出了显著的潜力，但在法律领域的应用，特别是在资源匮乏的环境中，仍受到限制。本研究旨在解决将LLMs适应到巴勒斯坦法律领域的挑战，由于政治不稳定、法律框架碎片化以及有限的人工智能资源，有效地利用机器学习应用受到阻碍。我们基于量化版本的Llama-3.2-1B-Instruct构建了一个微调模型，并训练了该模型，所用数据集来源于巴勒斯坦法律文本。通过使用规模较小的模型和精心设计的问题-答案对，我们实现了一种成本效益高、具有地方可持续性的解决方案，能够提供准确且上下文相关性的法律指导。我们的实验表明，该模型在各种查询类型上表现出了令人鼓舞的效果，涵盖了从是/否问题和叙事解释到复杂法律区分在内的多种查询，同时我们也指出了改进的方向，比如处理基于计算的查询和结构化列表格式化等问题。本研究为定制化的人工智能法律辅助工具的部署提供了一条途径，以适应资源匮乏的环境需求。', 'title_zh': 'ALKAFI-LLAMA3：针对巴勒斯坦精准法律理解的大型语言模型 fine-tuning'}
{'arxiv_id': 'arXiv:2412.14764', 'title': 'CodeRepoQA: A Large-scale Benchmark for Software Engineering Question Answering', 'authors': 'Ruida Hu, Chao Peng, Jingyi Ren, Bo Jiang, Xiangxin Meng, Qinyun Wu, Pengfei Gao, Xinchen Wang, Cuiyun Gao', 'link': 'https://arxiv.org/abs/2412.14764', 'abstract': "In this work, we introduce CodeRepoQA, a large-scale benchmark specifically designed for evaluating repository-level question-answering capabilities in the field of software engineering. CodeRepoQA encompasses five programming languages and covers a wide range of scenarios, enabling comprehensive evaluation of language models. To construct this dataset, we crawl data from 30 well-known repositories in GitHub, the largest platform for hosting and collaborating on code, and carefully filter raw data. In total, CodeRepoQA is a multi-turn question-answering benchmark with 585,687 entries, covering a diverse array of software engineering scenarios, with an average of 6.62 dialogue turns per entry.\nWe evaluate ten popular large language models on our dataset and provide in-depth analysis. We find that LLMs still have limitations in question-answering capabilities in the field of software engineering, and medium-length contexts are more conducive to LLMs' performance. The entire benchmark is publicly available at this https URL.", 'abstract_zh': '在本文中，我们介绍了CodeRepoQA，这是一个大型基准测试，专门用于评估软件工程领域代码仓库级别问题解答的能力。CodeRepoQA 包含五种编程语言，并涵盖了广泛的场景，使得语言模型能够进行全面评估。为了构建此数据集，我们从 GitHub（最大的代码托管和协作平台）爬取了30个知名代码仓库的数据，并仔细过滤了原始数据。总共，CodeRepoQA 是一个多轮问题解答基准测试，包含585,687个条目，涵盖了广泛的软件工程场景，平均每条目有6.62轮对话。\n\n我们对十个流行的大型语言模型进行了评估，并进行了深入分析。结果显示，大型语言模型在软件工程领域的问题解答能力仍然存在局限，中等长度的上下文环境更有助于大型语言模型的表现。整套基准测试已在此处公开：[公开链接]。', 'title_zh': 'CodeRepoQA：软件工程问答的大规模基准数据集'}
{'arxiv_id': 'arXiv:2412.14736', 'title': 'Advances in Artificial Intelligence forDiabetes Prediction: Insights from a Systematic Literature Review', 'authors': 'Pir Bakhsh Khokhar, Carmine Gravino, Fabio Palomba', 'link': 'https://arxiv.org/abs/2412.14736', 'abstract': 'This systematic review explores the use of machine learning (ML) in predicting diabetes, focusing on datasets, algorithms, training methods, and evaluation metrics. It examines datasets like the Singapore National Diabetic Retinopathy Screening program, REPLACE-BG, National Health and Nutrition Examination Survey, and Pima Indians Diabetes Database. The review assesses the performance of ML algorithms like CNN, SVM, Logistic Regression, and XGBoost in predicting diabetes outcomes. The study emphasizes the importance of interdisciplinary collaboration and ethical considerations in ML-based diabetes prediction models.', 'abstract_zh': '本文综述系统地探讨了机器学习（ML）在预测糖尿病方面的应用，重点研究了数据集、算法、训练方法和评估指标。综述分析了包括新加坡国家糖尿病视网膜筛查计划、REPLACE-BG项目、全国健康与营养检查调查以及佩梅印第安人糖尿病数据库等数据集。研究评估了CNN、SVM、逻辑回归和XGBoost等机器学习算法在预测糖尿病结果方面的性能。该研究强调了在基于机器学习的糖尿病预测模型中跨学科合作和伦理考量的重要性。', 'title_zh': '人工智能在糖尿病预测领域的进展：系统文献综述的洞察'}
{'arxiv_id': 'arXiv:2412.14732', 'title': 'Beyond the Hype: A Comprehensive Review of Current Trends in Generative AI Research, Teaching Practices, and Tools', 'authors': 'James Prather, Juho Leinonen, Natalie Kiesler, Jamie Gorson Benario, Sam Lau, Stephen MacNeil, Narges Norouzi, Simone Opel, Vee Pettit, Leo Porter, Brent N. Reeves, Jaromir Savelka, David H. Smith IV, Sven Strickroth, Daniel Zingaro', 'link': 'https://arxiv.org/abs/2412.14732', 'abstract': 'Generative AI (GenAI) is advancing rapidly, and the literature in computing education is expanding almost as quickly. Initial responses to GenAI tools were mixed between panic and utopian optimism. Many were fast to point out the opportunities and challenges of GenAI. Researchers reported that these new tools are capable of solving most introductory programming tasks and are causing disruptions throughout the curriculum. These tools can write and explain code, enhance error messages, create resources for instructors, and even provide feedback and help for students like a traditional teaching assistant. In 2024, new research started to emerge on the effects of GenAI usage in the computing classroom. These new data involve the use of GenAI to support classroom instruction at scale and to teach students how to code with GenAI. In support of the former, a new class of tools is emerging that can provide personalized feedback to students on their programming assignments or teach both programming and prompting skills at the same time. With the literature expanding so rapidly, this report aims to summarize and explain what is happening on the ground in computing classrooms. We provide a systematic literature review; a survey of educators and industry professionals; and interviews with educators using GenAI in their courses, educators studying GenAI, and researchers who create GenAI tools to support computing education. The triangulation of these methods and data sources expands the understanding of GenAI usage and perceptions at this critical moment for our community.', 'abstract_zh': '生成式人工智能（GenAI）正在迅速发展，计算教育领域的研究成果也在几乎同样快速地扩展。对于GenAI工具的初始反应具有混合性质，既有恐慌也有乌托邦式的乐观情绪。许多人迅速指出了GenAI的机会和挑战。研究人员报告称，这些新工具能够解决大多数入门级编程任务，并在整个课程中引发变革。这些工具可以编写和解释代码、增强错误信息、为教师创建资源，并且甚至能够像传统教学助理一样为学生提供反馈和帮助。到了2024年，围绕GenAI在计算教室中的使用效果的新研究开始涌现。这些新数据包括使用GenAI支持大规模课堂教学以及教授学生如何使用GenAI进行编码。为了支持前者，新一代工具正不断出现，可以为学生的编程作业提供个性化反馈，或者同时教授编程和提示技巧。随着研究成果的迅速扩展，本报告旨在总结和解释计算教室中正在进行的情况。我们将进行系统性的文献综述；对教育工作者和行业专业人士进行问卷调查；并对正在其课程中使用GenAI的教育工作者、研究GenAI的教育工作者以及创建支持计算教育的GenAI工具的研究人员进行访谈。通过对这些方法和数据来源的三角分析，可以更好地理解我们社区当前关键时刻GenAI的使用情况和认知状况。', 'title_zh': '超越 hype：生成式人工智能研究、教学实践及工具的全面回顾'}
{'arxiv_id': 'arXiv:2412.14689', 'title': 'How to Synthesize Text Data without Model Collapse?', 'authors': 'Xuekai Zhu, Daixuan Cheng, Hengli Li, Kaiyan Zhang, Ermo Hua, Xingtai Lv, Ning Ding, Zhouhan Lin, Zilong Zheng, Bowen Zhou', 'link': 'https://arxiv.org/abs/2412.14689', 'abstract': 'Model collapse in synthetic data indicates that iterative training on self-generated data leads to a gradual decline in performance. With the proliferation of AI models, synthetic data will fundamentally reshape the web data ecosystem. Future GPT-$\\{n\\}$ models will inevitably be trained on a blend of synthetic and human-produced data. In this paper, we focus on two questions: what is the impact of synthetic data on language model training, and how to synthesize data without model collapse? We first pre-train language models across different proportions of synthetic data, revealing a negative correlation between the proportion of synthetic data and model performance. We further conduct statistical analysis on synthetic data to uncover distributional shift phenomenon and over-concentration of n-gram features. Inspired by the above findings, we propose token editing on human-produced data to obtain semi-synthetic data. As a proof of concept, we theoretically demonstrate that token-level editing can prevent model collapse, as the test error is constrained by a finite upper bound. We conduct extensive experiments on pre-training from scratch, continual pre-training, and supervised fine-tuning. The results validate our theoretical proof that token-level editing improves data quality and enhances model performance.', 'abstract_zh': '模型在合成数据上的崩溃表明，迭代地在自我生成的数据上进行训练会导致模型性能逐渐下降。随着AI模型的普遍应用，合成数据将从根本上重塑网络数据生态系统。未来的GPT-$\\{n\\}$模型不可避免地会在合成数据和人类生成的数据混合的情况下进行训练。在本文中，我们重点关注两个问题：合成数据对语言模型训练的影响是什么？如何合成数据而不引发模型崩溃？我们首先在不同比例的合成数据上预训练语言模型，发现合成数据的比例与模型性能之间存在负相关关系。进一步地，我们对合成数据进行统计分析，发现了分布变化现象和n元组特征的过度集中。受上述发现的启发，我们提出对人类生成的数据进行标记编辑以获得半合成数据。作为概念验证，我们理论性地证明了标记级别的编辑可以防止模型崩溃，因为测试误差被一个有限的上限所约束。我们进行了全面的实验，包括从头预训练、连续预训练和监督微调。结果验证了我们的理论证明，标记级别的编辑提高了数据质量并增强了模型性能。', 'title_zh': '如何合成文本数据而不导致模型崩溃？'}
{'arxiv_id': 'arXiv:2412.14686', 'title': 'Each Fake News is Fake in its Own Way: An Attribution Multi-Granularity Benchmark for Multimodal Fake News Detection', 'authors': 'Hao Guo, Zihan Ma, Zhi Zeng, Minnan Luo, Weixin Zeng, Jiuyang Tang, Xiang Zhao', 'link': 'https://arxiv.org/abs/2412.14686', 'abstract': 'Social platforms, while facilitating access to information, have also become saturated with a plethora of fake news, resulting in negative consequences. Automatic multimodal fake news detection is a worthwhile pursuit. Existing multimodal fake news datasets only provide binary labels of real or fake. However, real news is alike, while each fake news is fake in its own way. These datasets fail to reflect the mixed nature of various types of multimodal fake news. To bridge the gap, we construct an attributing multi-granularity multimodal fake news detection dataset \\amg, revealing the inherent fake pattern. Furthermore, we propose a multi-granularity clue alignment model \\our to achieve multimodal fake news detection and attribution. Experimental results demonstrate that \\amg is a challenging dataset, and its attribution setting opens up new avenues for future research.', 'abstract_zh': '社交媒体在促进信息访问的同时，也充斥着大量的假新闻，产生了负面后果。自动多模态假新闻检测是一项值得追求的研究。现有的多模态假新闻数据集仅提供真假二元标签。然而，真正的新闻存在相似性，而每条假新闻都有其独特的虚假特性。这些数据集未能反映各种类型多模态假新闻的混合性质。为填补这一空白，我们构建了一个具有属性的多粒度多模态假新闻检测数据集 \\AMG，揭示了固有的虚假模式。此外，我们提出了一种多粒度线索对齐模型 \\OUR，以实现多模态假新闻的检测与归因。实验结果表明，\\AMG 是一个具有挑战性的数据集，其归因设置为未来的研究开辟了新的途径。', 'title_zh': '每条假新闻都有其独特之处：一种多模态假新闻检测的归因多层次基准'}
{'arxiv_id': 'arXiv:2412.14680', 'title': 'A Light-Weight Framework for Open-Set Object Detection with Decoupled Feature Alignment in Joint Space', 'authors': 'Yonghao He, Hu Su, Haiyong Yu, Cong Yang, Wei Sui, Cong Wang, Song Liu', 'link': 'https://arxiv.org/abs/2412.14680', 'abstract': 'Open-set object detection (OSOD) is highly desirable for robotic manipulation in unstructured environments. However, existing OSOD methods often fail to meet the requirements of robotic applications due to their high computational burden and complex deployment. To address this issue, this paper proposes a light-weight framework called Decoupled OSOD (DOSOD), which is a practical and highly efficient solution to support real-time OSOD tasks in robotic systems. Specifically, DOSOD builds upon the YOLO-World pipeline by integrating a vision-language model (VLM) with a detector. A Multilayer Perceptron (MLP) adaptor is developed to transform text embeddings extracted by the VLM into a joint space, within which the detector learns the region representations of class-agnostic proposals. Cross-modality features are directly aligned in the joint space, avoiding the complex feature interactions and thereby improving computational efficiency. DOSOD operates like a traditional closed-set detector during the testing phase, effectively bridging the gap between closed-set and open-set detection. Compared to the baseline YOLO-World, the proposed DOSOD significantly enhances real-time performance while maintaining comparable accuracy. The slight DOSOD-S model achieves a Fixed AP of $26.7\\%$, compared to $26.2\\%$ for YOLO-World-v1-S and $22.7\\%$ for YOLO-World-v2-S, using similar backbones on the LVIS minival dataset. Meanwhile, the FPS of DOSOD-S is $57.1\\%$ higher than YOLO-World-v1-S and $29.6\\%$ higher than YOLO-World-v2-S. Meanwhile, we demonstrate that the DOSOD model facilitates the deployment of edge devices. The codes and models are publicly available at this https URL.', 'abstract_zh': '开放集目标检测（Open-set Object Detection, OSOD）在不规则环境下的机器人操作中具有很高价值。然而，现有的OSOD方法往往因为计算负担重和部署复杂而无法满足机器人应用的要求。为解决这一问题，本文提出了一种轻量级框架——解耦开放集目标检测（Decoupled OSOD, DOSOD），该框架是支持机器人系统中实时OSOD任务的实用且高效解决方案。具体而言，DOSOD在YOLO-World流水线的基础上，整合了一个视觉语言模型（Visual Language Model, VLM）与检测器。开发了一个多层感知器（Multilayer Perceptron, MLP）适配器，用于将VLM提取的文本嵌入转化为联合空间，在该空间中，检测器学习无类别建议区域的表示。跨模态特征直接在联合空间中进行对齐，避免了复杂的特征交互，从而提高了计算效率。在测试阶段，DOSOD运作类似于传统的封闭集检测器，有效地填补了封闭集和开放集检测之间的差距。与基线YOLO-World相比，提出的DOSOD在保持相当准确性的前提下显著提高了实时性能。在使用相似骨干网的LVIS minival数据集上，DOSOD-S模型的固定平均精确度（Fixed AP）为26.7%，而YOLO-World-v1-S为26.2%，YOLO-World-v2-S为22.7%。同时，DOSOD-S的每秒帧数（FPS）比YOLO-World-v1-S高57.1%，比YOLO-World-v2-S高29.6%。此外，我们证明了DOSOD模型便于边缘设备的部署。代码和模型已公开发布。详见此链接：[请插入链接]。', 'title_zh': '基于解耦特征对齐的联合空间开放式目标检测轻量级框架'}
{'arxiv_id': 'arXiv:2412.14672', 'title': 'FiVL: A Framework for Improved Vision-Language Alignment', 'authors': 'Estelle Aflalo, Gabriela Ben Melech Stan, Tiep Le, Man Luo, Shachar Rosenman, Sayak Paul, Shao-Yen Tseng, Vasudev Lal', 'link': 'https://arxiv.org/abs/2412.14672', 'abstract': "Large Vision Language Models (LVLMs) have achieved significant progress in integrating visual and textual inputs for multimodal reasoning. However, a recurring challenge is ensuring these models utilize visual information as effectively as linguistic content when both modalities are necessary to formulate an accurate answer. We hypothesize that hallucinations arise due to the lack of effective visual grounding in current LVLMs. This issue extends to vision-language benchmarks, where it is difficult to make the image indispensable for accurate answer generation, particularly in vision question-answering tasks. In this work, we introduce FiVL, a novel method for constructing datasets designed to train LVLMs for enhanced visual grounding and to evaluate their effectiveness in achieving it. These datasets can be utilized for both training and assessing an LVLM's ability to use image content as substantive evidence rather than relying solely on linguistic priors, providing insights into the model's reliance on visual information. To demonstrate the utility of our dataset, we introduce an innovative training task that outperforms baselines alongside a validation method and application for explainability. The code is available at this https URL.", 'abstract_zh': '大规模视觉语言模型（LVLMs）在整合视觉和文本输入进行多模态推理方面取得了显著进展。然而，一个反复出现的挑战是如何确保这些模型在同时需要视觉信息和语言内容时，能够有效地利用视觉信息。我们认为，幻觉的产生是因为当前LVLMs缺乏有效的视觉定位能力。这一问题也同样体现在视觉语言基准测试中，在这些基准测试中，难以使图像成为生成准确答案不可或缺的组成部分，尤其是在视觉问答任务中。在本工作中，我们提出了一种新的方法FiVL，旨在构建数据集，用于训练LVLMs以增强视觉定位能力，并评估它们在实现这一目标方面的有效性。这些数据集可用于训练和评估LVLMs将图像内容作为实质性证据而非仅仅依赖语言先验的能力，从而提供模型在依赖视觉信息上的见解。为了展示我们数据集的实际应用价值，我们引入了一种创新的训练任务，该任务在基准线基础上表现更优，并附带了验证方法和解释性应用。相关代码可在以下链接获取：this https URL。', 'title_zh': 'FiVL：一个提高视觉-语言对齐的框架'}
{'arxiv_id': 'arXiv:2412.14670', 'title': 'Analysis and Visualization of Linguistic Structures in Large Language Models: Neural Representations of Verb-Particle Constructions in BERT', 'authors': 'Hassane Kissane, Achim Schilling, Patrick Krauss', 'link': 'https://arxiv.org/abs/2412.14670', 'abstract': "This study investigates the internal representations of verb-particle combinations within transformer-based large language models (LLMs), specifically examining how these models capture lexical and syntactic nuances at different neural network layers. Employing the BERT architecture, we analyse the representational efficacy of its layers for various verb-particle constructions such as 'agree on', 'come back', and 'give up'. Our methodology includes a detailed dataset preparation from the British National Corpus, followed by extensive model training and output analysis through techniques like multi-dimensional scaling (MDS) and generalized discrimination value (GDV) calculations. Results show that BERT's middle layers most effectively capture syntactic structures, with significant variability in representational accuracy across different verb categories. These findings challenge the conventional uniformity assumed in neural network processing of linguistic elements and suggest a complex interplay between network architecture and linguistic representation. Our research contributes to a better understanding of how deep learning models comprehend and process language, offering insights into the potential and limitations of current neural approaches to linguistic analysis. This study not only advances our knowledge in computational linguistics but also prompts further research into optimizing neural architectures for enhanced linguistic precision.", 'abstract_zh': '本研究探讨了基于变换器的大型语言模型（LLMs）中动词短语组合的内部表示，具体分析了这些模型在不同神经网络层如何捕捉词汇和句法细微差别。我们采用了BERT架构，对不同类型的动作短语组合（如“agree on”、“come back”、“give up”）的层次表示能力进行了分析。方法包括从英国国家语料库精心准备的数据集，随后通过多维尺度分析（MDS）和广义辨别值（GDV）计算等技术进行广泛的模型训练和输出分析。研究结果表明，BERT的中间层最有效地捕捉句法结构，而不同动词类别在表示准确性方面存在显著差异。这些发现挑战了神经网络处理语言元素时普遍存在的一致性的假设，并表明网络架构与语言表示之间的复杂交互关系。本研究对深度学习模型如何理解和处理语言有了更深入的理解，提供了关于当前神经方法在语言分析中的潜力和局限性的见解。本研究不仅推进了计算语言学的知识，还激发了对优化神经架构以提高语言精度的研究。', 'title_zh': '大型语言模型中语义结构的分析与可视化：BERT 中动词-粒子构造的神经表示分析与可视化'}
{'arxiv_id': 'arXiv:2412.14668', 'title': 'LoLaFL: Low-Latency Federated Learning via Forward-only Propagation', 'authors': 'Jierui Zhang, Jianhao Huang, Kaibin Huang', 'link': 'https://arxiv.org/abs/2412.14668', 'abstract': 'Federated learning (FL) has emerged as a widely adopted paradigm for enabling edge learning with distributed data while ensuring data privacy. However, the traditional FL with deep neural networks trained via backpropagation can hardly meet the low-latency learning requirements in the sixth generation (6G) mobile networks. This challenge mainly arises from the high-dimensional model parameters to be transmitted and the numerous rounds of communication required for convergence due to the inherent randomness of the training process. To address this issue, we adopt the state-of-the-art principle of maximal coding rate reduction to learn linear discriminative features and extend the resultant white-box neural network into FL, yielding the novel framework of Low-Latency Federated Learning (LoLaFL) via forward-only propagation. LoLaFL enables layer-wise transmissions and aggregation with significantly fewer communication rounds, thereby considerably reducing latency. Additionally, we propose two \\emph{nonlinear} aggregation schemes for LoLaFL. The first scheme is based on the proof that the optimal NN parameter aggregation in LoLaFL should be harmonic-mean-like. The second scheme further exploits the low-rank structures of the features and transmits the low-rank-approximated covariance matrices of features to achieve additional latency reduction. Theoretic analysis and experiments are conducted to evaluate the performance of LoLaFL. In comparison with traditional FL, the two nonlinear aggregation schemes for LoLaFL can achieve reductions in latency of over 91\\% and 98\\%, respectively, while maintaining comparable accuracies.', 'abstract_zh': '联邦学习（FL）作为一种在分布式数据上实现边缘学习的广泛采用范式，能够在确保数据隐私的同时进行模型训练。然而，传统的使用反向传播训练深度神经网络的FL难以满足第六代（6G）移动网络中的低延迟学习要求。这一挑战主要源于高效传输高维模型参数以及因训练过程固有的随机性而需要的大量通信轮次。为解决这一问题，我们采用最先进的最大编码率减少原则来学习线性判别特征，并将由此得出的白盒神经网络扩展到联邦学习中，从而形成一种通过前向传播的新框架——低延迟联邦学习（LoLaFL）。\n\nLoLaFL能够实现逐层的传输和聚合，显著减少通信轮次，从而大幅降低延迟。此外，我们还为LoLaFL提出了两种非线性聚合方案。第一个方案基于证明，在LoLaFL中最优的神经网络参数聚合应类似于调和平均。第二个方案进一步利用了特征的低秩结构，通过传输特征的低秩近似协方差矩阵来实现额外的延迟减少。通过理论分析和实验评估LoLaFL的性能。与传统的联邦学习相比，LoLaFL的两种非线性聚合方案分别能够分别实现超过91%和98%的延迟减少，同时保持相当的准确性。', 'title_zh': 'LoLaFL：基于单向传播的低延迟联邦学习'}
{'arxiv_id': 'arXiv:2412.14663', 'title': 'IOHunter: Graph Foundation Model to Uncover Online Information Operations', 'authors': 'Marco Minici, Luca Luceri, Francesco Fabbri, Emilio Ferrara', 'link': 'https://arxiv.org/abs/2412.14663', 'abstract': 'Social media platforms have become vital spaces for public discourse, serving as modern agorás where a wide range of voices influence societal narratives. However, their open nature also makes them vulnerable to exploitation by malicious actors, including state-sponsored entities, who can conduct information operations (IOs) to manipulate public opinion. The spread of misinformation, false news, and misleading claims threatens democratic processes and societal cohesion, making it crucial to develop methods for the timely detection of inauthentic activity to protect the integrity of online discourse. In this work, we introduce a methodology designed to identify users orchestrating information operations, a.k.a. \\textit{IO drivers}, across various influence campaigns. Our framework, named \\texttt{IOHunter}, leverages the combined strengths of Language Models and Graph Neural Networks to improve generalization in \\emph{supervised}, \\emph{scarcely-supervised}, and \\emph{cross-IO} contexts. Our approach achieves state-of-the-art performance across multiple sets of IOs originating from six countries, significantly surpassing existing approaches. This research marks a step toward developing Graph Foundation Models specifically tailored for the task of IO detection on social media platforms.', 'abstract_zh': '社交媒体平台已成为公众辩论的关键空间，作为现代论坛，广泛的声音参与塑造着社会叙事。然而，其开放性也使其容易被恶意行为者，包括国家支持的实体，利用来进行信息操作（IOs），以操控公众意见。虚假信息、假新闻和误导性声明的传播威胁着民主进程和社会凝聚力，因此及时检测不实行为变得至关重要，以保护在线讨论的完整性。在本研究中，我们提出了一种方法论，旨在识别在各种影响活动中策划信息操作的用户，即所谓的“IO驱动者”。我们提出了一种名为 \\texttt{IOHunter} 的框架，该框架结合了语言模型和图神经网络的优势，以提高在监督、弱监督和跨信息操作（\\emph{cross-IO}）情境中的泛化能力。我们的方法在六个不同国家起源的多个信息操作集合上实现了现有方法中的最佳性能。这项研究标志着开发专门针对社交媒体平台上信息操作检测任务的图基础模型的一步进展。', 'title_zh': 'IOHunter：基于图的模型以发现在线信息操作'}
{'arxiv_id': 'arXiv:2412.14660', 'title': 'Unveiling Uncertainty: A Deep Dive into Calibration and Performance of Multimodal Large Language Models', 'authors': 'Zijun Chen, Wenbo Hu, Guande He, Zhijie Deng, Zheng Zhang, Richang Hong', 'link': 'https://arxiv.org/abs/2412.14660', 'abstract': "Multimodal large language models (MLLMs) combine visual and textual data for tasks such as image captioning and visual question answering. Proper uncertainty calibration is crucial, yet challenging, for reliable use in areas like healthcare and autonomous driving. This paper investigates representative MLLMs, focusing on their calibration across various scenarios, including before and after visual fine-tuning, as well as before and after multimodal training of the base LLMs. We observed miscalibration in their performance, and at the same time, no significant differences in calibration across these scenarios. We also highlight how uncertainty differs between text and images and how their integration affects overall uncertainty. To better understand MLLMs' miscalibration and their ability to self-assess uncertainty, we construct the IDK (I don't know) dataset, which is key to evaluating how they handle unknowns. Our findings reveal that MLLMs tend to give answers rather than admit uncertainty, but this self-assessment improves with proper prompt adjustments. Finally, to calibrate MLLMs and enhance model reliability, we propose techniques such as temperature scaling and iterative prompt optimization. Our results provide insights into improving MLLMs for effective and responsible deployment in multimodal applications. Code and IDK dataset: \\href{this https URL}{this https URL}.", 'abstract_zh': '多模态大型语言模型（MLLMs）结合视觉和文本数据，用于诸如图像字幕和视觉问答等任务。在医疗保健和自主驾驶等关键领域中，适当的不确定性校准对于可靠使用至关重要，但同时也是极具挑战性的。本文研究了代表性的MLLMs，重点关注它们在不同场景下的校准情况，包括视觉微调前后以及基础大语言模型多模态训练前后。我们观察到了它们性能的校准偏差，但在这些场景之间的校准差异并不显著。我们还强调了文本和图像之间不确定性差异及其整合如何影响总体不确定性。为了更好地理解MLLMs的偏差并提高其自我评估不确定性的能力，我们构建了IDK（我不知道）数据集，这是评估它们处理未知情况的关键工具。研究结果表明，MLLMs倾向于给出答案而不是承认不确定性，但这种自我评估能力可以通过适当的提示调整而提高。最后，为了校准MLLMs并提高模型的可靠性，我们提出了诸如温度缩放和迭代提示优化等技术。我们的结果为在多模态应用中有效且负责任地部署MLLMs提供了见解。代码和IDK数据集：[此处插入链接]。', 'title_zh': '揭开不确定性之谜：多模态大型语言模型的校准与性能深入探究'}
{'arxiv_id': 'arXiv:2412.14640', 'title': 'Adaptive Prompt Tuning: Vision Guided Prompt Tuning with Cross-Attention for Fine-Grained Few-Shot Learning', 'authors': 'Eric Brouwer, Jan Erik van Woerden, Gertjan Burghouts, Matias Valedenegro-Toro, Marco Zullich', 'link': 'https://arxiv.org/abs/2412.14640', 'abstract': "Few-shot, fine-grained classification in computer vision poses significant challenges due to the need to differentiate subtle class distinctions with limited data. This paper presents a novel method that enhances the Contrastive Language-Image Pre-Training (CLIP) model through adaptive prompt tuning, guided by real-time visual inputs. Unlike existing techniques such as Context Optimization (CoOp) and Visual Prompt Tuning (VPT), which are constrained by static prompts or visual token reliance, the proposed approach leverages a cross-attention mechanism to dynamically refine text prompts for the image at hand. This enables an image-specific alignment of textual features with image patches extracted from the Vision Transformer, making the model more effective for datasets with high intra-class variance and low inter-class differences. The method is evaluated on several datasets, including CUBirds, Oxford Flowers, and FGVC Aircraft, showing significant performance gains over static prompt tuning approaches. To ensure these performance gains translate into trustworthy predictions, we integrate Monte-Carlo Dropout in our approach to improve the reliability of the model predictions and uncertainty estimates. This integration provides valuable insights into the model's predictive confidence, helping to identify when predictions can be trusted and when additional verification is necessary. This dynamic approach offers a robust solution, advancing the state-of-the-art for few-shot fine-grained classification.", 'abstract_zh': '计算机视觉中的少量样本、细粒度分类面临着显著挑战，因为需要在数据有限的情况下区分细微的类别差异。本文提出了一种新颖的方法，通过动态提示调优增强对比语言-图像预训练（CLIP）模型，该方法由实时视觉输入引导。与现有技术如上下文优化（CoOp）和视觉提示调优（VPT），这些技术受静止提示或对视觉标记的依赖性限制不同，所提出的方法利用交叉注意力机制对当前图像的文本提示进行动态精炼。这使得模型能够与源自视觉变换器的图像补丁进行特定图像的文本特征对齐，从而使其更适合具有高类内变异性且类间差异较小的数据集。该方法在多个数据集上进行了评估，包括CUBirds、Oxford Flowers和FGVC Aircraft等数据集，显示出显著的性能提升，超过了静态提示调优方法。为了确保这些性能提升转化为可信赖的预测，我们整合了蒙特卡洛丢棄技术以提高模型预测的可靠性和不确定性估计。这一整合提供了有关模型预测置信度的宝贵见解，有助于识别哪些预测可以信赖，哪些仍需要进一步验证。这种方法提供了稳健的解决方案，促进了少量样本细粒度分类的前沿技术进步。', 'title_zh': '自适应提示调优：基于跨注意力的视觉指导提示调优在细粒度少样本学习中的应用'}
{'arxiv_id': 'arXiv:2412.14639', 'title': 'A Shapley Value Estimation Speedup for Efficient Explainable Quantum AI', 'authors': 'Iain Burge, Michel Barbeau, Joaquin Garcia-Alfaro', 'link': 'https://arxiv.org/abs/2412.14639', 'abstract': "This work focuses on developing efficient post-hoc explanations for quantum AI algorithms. In classical contexts, the cooperative game theory concept of the Shapley value adapts naturally to post-hoc explanations, where it can be used to identify which factors are important in an AI's decision-making process. An interesting question is how to translate Shapley values to the quantum setting and whether quantum effects could be used to accelerate their calculation. We propose quantum algorithms that can extract Shapley values within some confidence interval. Our method is capable of quadratically outperforming classical Monte Carlo approaches to approximating Shapley values up to polylogarithmic factors in various circumstances. We demonstrate the validity of our approach empirically with specific voting games and provide rigorous proofs of performance for general cooperative games.", 'abstract_zh': '本文集中于开发量子人工智能算法的高效后验解释方法。在经典背景下，合作博弈论中的Shapley值概念自然适用于后验解释，其中可以用于识别AI决策过程中哪些因素是重要的。一个有趣的问题是如何将Shapley值转换到量子设置中，以及量子效应是否可以用于加速其计算。我们提出了一种量子算法，可在某些置信区间内提取Shapley值。我们的方法在多种情况下能够相对于经典的蒙特卡罗方法实现平方级的性能提升，考虑到对数多项式因子的影响。我们通过特定的投票博弈实验验证了方法的有效性，并为一般的合作博弈提供了严格的表现性能证明。', 'title_zh': '一种用于高效可解释量子人工智能的Shapley值估计加速方法'}
{'arxiv_id': 'arXiv:2412.14633', 'title': 'Progressive Fine-to-Coarse Reconstruction for Accurate Low-Bit Post-Training Quantization in Vision Transformers', 'authors': 'Rui Ding, Liang Yong, Sihuan Zhao, Jing Nie, Lihui Chen, Haijun Liu, Xichuan Zhou', 'link': 'https://arxiv.org/abs/2412.14633', 'abstract': 'Due to its efficiency, Post-Training Quantization (PTQ) has been widely adopted for compressing Vision Transformers (ViTs). However, when quantized into low-bit representations, there is often a significant performance drop compared to their full-precision counterparts. To address this issue, reconstruction methods have been incorporated into the PTQ framework to improve performance in low-bit quantization settings. Nevertheless, existing related methods predefine the reconstruction granularity and seldom explore the progressive relationships between different reconstruction granularities, which leads to sub-optimal quantization results in ViTs. To this end, in this paper, we propose a Progressive Fine-to-Coarse Reconstruction (PFCR) method for accurate PTQ, which significantly improves the performance of low-bit quantized vision transformers. Specifically, we define multi-head self-attention and multi-layer perceptron modules along with their shortcuts as the finest reconstruction units. After reconstructing these two fine-grained units, we combine them to form coarser blocks and reconstruct them at a coarser granularity level. We iteratively perform this combination and reconstruction process, achieving progressive fine-to-coarse reconstruction. Additionally, we introduce a Progressive Optimization Strategy (POS) for PFCR to alleviate the difficulty of training, thereby further enhancing model performance. Experimental results on the ImageNet dataset demonstrate that our proposed method achieves the best Top-1 accuracy among state-of-the-art methods, particularly attaining 75.61% for 3-bit quantized ViT-B in PTQ. Besides, quantization results on the COCO dataset reveal the effectiveness and generalization of our proposed method on other computer vision tasks like object detection and instance segmentation.', 'abstract_zh': '由于其高效性，后训练量化（Post-Training Quantization, PTQ）已成为压缩视觉变换器（Vision Transformers, ViTs）的常用方法。然而，在量化为低位表示时，ViTs 的性能通常会显著下降，与全精度版本相比差距较大。为了解决这一问题，已有研究在 PTQ 框架中引入了重建方法，以提高低位量化设置下的性能。然而，现有的相关方法会预先定义重建粒度，很少探索不同粒度之间的逐步关系，从而导致 ViTs 上的量化结果不够优化。为解决这些问题，本文提出了一种渐进精细到粗糙重建（Progressive Fine-to-Coarse Reconstruction, PFCR）方法，显著提高了低位量化视觉变换器的性能。具体而言，我们定义多头自注意力和多个层感知机模块及其捷径作为最细粒度的重建单元。在重建这些精细粒度单元之后，我们将它们结合成较粗的块，在更粗的粒度级别进行重建。我们迭代执行此组合和重建过程，最终实现逐步精细到粗糙的重建。此外，我们引入了一种渐进优化策略（Progressive Optimization Strategy, POS），以缓解训练难度，进一步提升模型性能。在 ImageNet 数据集上的实验结果表明，我们提出的方法在最先进的方法中实现了最佳的 Top-1 准确率，特别是在 PTQ 中的 3 位量化 ViT-B 中达到了 75.61% 的准确率。同时，COCO 数据集上的量化结果表明我们提出的方法在其他计算机视觉任务，如目标检测和实例分割中具有有效性和泛化能力。', 'title_zh': '面向视觉变换器的分阶段细到粗重建方法以实现准确的低比特量化后训练'}
{'arxiv_id': 'arXiv:2412.14626', 'title': 'Learning to Generate Research Idea with Dynamic Control', 'authors': 'Ruochen Li, Liqiang Jing, Chi Han, Jiawei Zhou, Xinya Du', 'link': 'https://arxiv.org/abs/2412.14626', 'abstract': 'The rapid advancements in large language models (LLMs) have demonstrated their potential to accelerate scientific discovery, particularly in automating the process of research ideation. LLM-based systems have shown promise in generating hypotheses and research ideas. However, current approaches predominantly rely on prompting-based pre-trained models, limiting their ability to optimize generated content effectively. Moreover, they also lack the capability to deal with the complex interdependence and inherent restrictions among novelty, feasibility, and effectiveness, which remains challenging due to the inherent trade-offs among these dimensions, such as the innovation-feasibility conflict. To address these limitations, we for the first time propose fine-tuning LLMs to be better idea proposers and introduce a novel framework that employs a two-stage approach combining Supervised Fine-Tuning (SFT) and controllable Reinforcement Learning (RL). In the SFT stage, the model learns foundational patterns from pairs of research papers and follow-up ideas. In the RL stage, multi-dimensional reward modeling, guided by fine-grained feedback, evaluates and optimizes the generated ideas across key metrics. Dimensional controllers enable dynamic adjustment of generation, while a sentence-level decoder ensures context-aware emphasis during inference. Our framework provides a balanced approach to research ideation, achieving high-quality outcomes by dynamically navigating the trade-offs among novelty, feasibility, and effectiveness.', 'abstract_zh': '大规模语言模型（LLMs）的快速进步已经显示出它们在加速科学发现方面的潜力，尤其是在自动化研究构思过程方面。基于LLM的系统展示了生成假设和研究构思的潜力。然而，当前的方法主要依赖于基于提示的预训练模型，这限制了它们在优化生成内容方面的有效性。此外，这些系统还缺乏处理新颖性、可行性和有效性之间复杂相互依赖关系的能力，这些相互依赖关系因这些维度之间的固有权衡而更具挑战性，例如创新与可行性的冲突。为了解决这些局限性，我们首次提出对LLM进行微调，以使其更好地提出研究构思，并介绍了一种新的框架，该框架采用结合监督微调（SFT）和可控强化学习（RL）的两阶段方法。在SFT阶段，模型从研究论文及其后续构思的配对中学习基础模式。在RL阶段，通过精细反馈引导的多维度奖励模型评估并优化生成的内容，确保在关键指标上取得最优效果。维度控制器使生成过程可以动态调整，而句子级解码器确保在推理过程中对上下文有意识地强调。我们的框架提供了一种平衡的研究构思方法，在动态导航新颖性、可行性和有效性之间的权衡时，实现了高质量的结果。', 'title_zh': '学习使用动态控制生成研究思路'}
{'arxiv_id': 'arXiv:2412.14619', 'title': 'Pitfalls of topology-aware image segmentation', 'authors': 'Alexander H. Berger, Laurin Lux, Alexander Weers, Martin Menten, Daniel Rueckert, Johannes C. Paetzold', 'link': 'https://arxiv.org/abs/2412.14619', 'abstract': "Topological correctness, i.e., the preservation of structural integrity and specific characteristics of shape, is a fundamental requirement for medical imaging tasks, such as neuron or vessel segmentation. Despite the recent surge in topology-aware methods addressing this challenge, their real-world applicability is hindered by flawed benchmarking practices. In this paper, we identify critical pitfalls in model evaluation that include inadequate connectivity choices, overlooked topological artifacts in ground truth annotations, and inappropriate use of evaluation metrics. Through detailed empirical analysis, we uncover these issues' profound impact on the evaluation and ranking of segmentation methods. Drawing from our findings, we propose a set of actionable recommendations to establish fair and robust evaluation standards for topology-aware medical image segmentation methods.", 'abstract_zh': '拓扑正确性，即保持结构完整性和特定形状特征，是医学成像任务（如神经元或血管分割）的一个基本要求。尽管近年来已有许多关注拓扑结构的方法被提出以应对这一挑战，但它们在实际应用中的适用性仍然受到不完善基准测试方法的限制。在本文中，我们指出了模型评估中的关键问题，包括不适当的连接性选择、忽视了真实标注中的拓扑错误，以及不恰当的评价指标使用。通过详细的经验分析，我们揭示了这些问题对分割方法评估和排名的深远影响。基于我们的研究结果，我们提出了一套可操作的建议，以建立公平且可靠的拓扑感知医学图像分割方法的评估标准。', 'title_zh': '拓扑感知图像分割的局限性'}
{'arxiv_id': 'arXiv:2412.14617', 'title': 'How good is GPT at writing political speeches for the White House?', 'authors': 'Jacques Savoy', 'link': 'https://arxiv.org/abs/2412.14617', 'abstract': 'Using large language models (LLMs), computers are able to generate a written text in response to a us er request. As this pervasive technology can be applied in numerous contexts, this study analyses the written style of one LLM called GPT by comparing its generated speeches with those of the recent US presidents. To achieve this objective, the State of the Union (SOTU) addresses written by Reagan to Biden are contrasted to those produced by both GPT-3.5 and GPT-4.o versions. Compared to US presidents, GPT tends to overuse the lemma "we" and produce shorter messages with, on average, longer sentences. Moreover, GPT opts for an optimistic tone, opting more often for political (e.g., president, Congress), symbolic (e.g., freedom), and abstract terms (e.g., freedom). Even when imposing an author\'s style to GPT, the resulting speech remains distinct from addresses written by the target author. Finally, the two GPT versions present distinct characteristics, but both appear overall dissimilar to true presidential messages.', 'abstract_zh': '利用大规模语言模型（LLMs），计算机能够根据用户请求生成书面文本。由于这项普及的技术可以在众多领域应用，本研究通过将一个名为GPT的LLM生成的演讲与近期美国总统的演讲进行比较，分析了GPT的书面风格。具体而言，本研究对比了里根至拜登历任总统发表的国情咨文（SOTU）与由GPT-3.5和GPT-4版本生成的版本。相较于美国总统，GPT有过度使用“we”这一词汇的现象，并生成更短的信息，平均而言，其句子更长。此外，GPT倾向于采用更乐观的语调，更频繁地使用政治性术语（如总统、国会）、象征性术语（如自由）和抽象性术语（如自由）。即使强加给GPT某种作者的风格，生成的演讲仍然与目标作者的演讲风格有所不同。最后，两种GPT版本呈现出不同的特点，但总体上与真正的总统演讲相异。', 'title_zh': 'GPT在为白宫撰写政治演说方面做得如何？'}
{'arxiv_id': 'arXiv:2412.14613', 'title': 'HarmonicEval: Multi-modal, Multi-task, Multi-criteria Automatic Evaluation Using a Vision Language Model', 'authors': 'Masanari Ohi, Masahiro Kaneko, Naoaki Okazaki, Nakamasa Inoue', 'link': 'https://arxiv.org/abs/2412.14613', 'abstract': 'Vision-language models (VLMs) have shown impressive abilities in text and image understanding. However, existing metrics for evaluating the text generated by VLMs focus exclusively on overall quality, leading to two limitations: 1) it is challenging to identify which aspects of the text need improvement from the overall score; 2) metrics may overlook specific evaluation criteria when predicting an overall score. To address these limitations, we propose HarmonicEval, a reference-free evaluation metric that aggregates criterion-wise scores to produce the overall score in a bottom-up manner. Furthermore, we construct the Multi-task Multi-criteria Human Evaluation (MMHE) dataset, which comprises 18,000 expert human judgments across four vision-language tasks. Our experiments demonstrate that HarmonicEval achieves higher correlations with human judgments than conventional metrics while providing numerical scores for each criterion.', 'abstract_zh': '视觉语言模型（VLMs）在文本和图像理解方面展现出了显著的能力。然而，现有的用于评估VLMs生成文本的度量标准仅侧重于整体质量，导致了两个局限性：1）难以仅从整体分数中识别需要改进的文本方面；2）度量标准在预测整体分数时可能会忽略特定的评估标准。为了克服这些局限性，我们提出了一种名为HarmonicEval的参考自由评估指标，它以自底向上的方式聚合各项标准分以生成整体分数。此外，我们构建了多任务多标准人工评估（MMHE）数据集，该数据集包含4个视觉语言任务中的18,000个专家人工判断。实验结果表明，HarmonicEval在与人类判断的相关性上优于传统度量标准，并且为每个标准提供了数值评分。', 'title_zh': '谐波评估：使用视觉语言模型的多模态、多任务、多标准自动评估'}
{'arxiv_id': 'arXiv:2412.14602', 'title': 'Towards Scalable and Deep Graph Neural Networks via Noise Masking', 'authors': 'Yuxuan Liang, Wentao Zhang, Zeang Sheng, Ling Yang, Quanqing Xu, Jiawei Jiang, Yunhai Tong, Bin Cu', 'link': 'https://arxiv.org/abs/2412.14602', 'abstract': 'In recent years, Graph Neural Networks (GNNs) have achieved remarkable success in many graph mining tasks. However, scaling them to large graphs is challenging due to the high computational and storage costs of repeated feature propagation and non-linear transformation during training. One commonly employed approach to address this challenge is model-simplification, which only executes the Propagation (P) once in the pre-processing, and Combine (C) these receptive fields in different ways and then feed them into a simple model for better performance. Despite their high predictive performance and scalability, these methods still face two limitations. First, existing approaches mainly focus on exploring different C methods from the model perspective, neglecting the crucial problem of performance degradation with increasing P depth from the data-centric perspective, known as the over-smoothing problem. Second, pre-processing overhead takes up most of the end-to-end processing time, especially for large-scale graphs. To address these limitations, we present random walk with noise masking (RMask), a plug-and-play module compatible with the existing model-simplification works. This module enables the exploration of deeper GNNs while preserving their scalability. Unlike the previous model-simplification works, we focus on continuous P and found that the noise existing inside each P is the cause of the over-smoothing issue, and use the efficient masking mechanism to eliminate them. Experimental results on six real-world datasets demonstrate that model-simplification works equipped with RMask yield superior performance compared to their original version and can make a good trade-off between accuracy and efficiency.', 'abstract_zh': '近年来，图神经网络（GNNs）在许多图挖掘任务中取得了显著的成果。然而，将它们扩展到大规模图中面临着高计算成本和存储成本的挑战，特别是在训练过程中多次进行特征传播和非线性转换。为了解决这一挑战，人们常用的方法是模型简化，即在预处理阶段仅执行一次传播（P），然后通过不同的方式组合这些感受野，再将它们输入一个简单的模型以提髙性能。尽管这些方法在预测性能和扩展性方面表现出色，但它们仍然面临两个局限性。首先，现有的方法主要从模型的角度探索不同的组合方法（C），忽视了从数据为中心的角度来看，随着传播深度（P）的增加，性能会下降的问题，这种现象被称为过度平滑问题。其次，预处理过程消耗了端到端处理时间的大部分，特别是在大规模图的情况下。\n\n为解决这些问题，我们提出了随机游走带有噪声掩蔽（RMask）模块，这是一种与现有模型简化工作兼容的即插即用模块。该模块能够探索更深的GNNs，同时保持其扩展性。与之前的模型简化工作不同，我们集中在连续的传播（P）上，发现存在于每次传播中的噪声是导致过度平滑问题的原因，并使用高效的掩蔽机制来消除这些噪声。在六个实际数据集上的实验结果表明，配备RMask的模型简化工作相较于其原始版本，在准确性和效率之间实现了良好的权衡，并且其预测性能更优。\n\n这样翻译后，既保留了原文的专业术语，也符合学术规范，便于读者理解。', 'title_zh': '通过噪声屏蔽实现可扩展和深层图神经网络'}
{'arxiv_id': 'arXiv:2412.14587', 'title': 'Spike2Former: Efficient Spiking Transformer for High-performance Image Segmentation', 'authors': 'Zhenxin Lei, Man Yao, Jiakui Hu, Xinhao Luo, Yanye Lu, Bo Xu, Guoqi Li', 'link': 'https://arxiv.org/abs/2412.14587', 'abstract': 'Spiking Neural Networks (SNNs) have a low-power advantage but perform poorly in image segmentation tasks. The reason is that directly converting neural networks with complex architectural designs for segmentation tasks into spiking versions leads to performance degradation and non-convergence. To address this challenge, we first identify the modules in the architecture design that lead to the severe reduction in spike firing, make targeted improvements, and propose Spike2Former architecture. Second, we propose normalized integer spiking neurons to solve the training stability problem of SNNs with complex architectures. We set a new state-of-the-art for SNNs in various semantic segmentation datasets, with a significant improvement of +12.7% mIoU and 5.0 efficiency on ADE20K, +14.3% mIoU and 5.2 efficiency on VOC2012, and +9.1% mIoU and 6.6 efficiency on CityScapes.', 'abstract_zh': '脉冲神经网络（SNNs）具有低功耗优势，但在图像分割任务中表现不佳。原因在于直接将具有复杂架构设计的神经网络转换为适用于分割任务的脉冲版本会导致性能下降和非收敛问题。为应对这一挑战，我们首先识别出导致脉冲发放严重减少的网络架构模块，并进行有针对性的改进，提出了一种名为Spike2Former的架构。其次，我们提出了归一化整数脉冲神经元，以解决具有复杂架构的SNNs在训练过程中稳定性的问题。在各种语义分割数据集中，我们的方法在ADE20K数据集上将mIoU提高了12.7%，效率提高了5.0；在VOC2012数据集上将mIoU提高了14.3%，效率提高了5.2；在城市场景数据集（CityScapes）上将mIoU提高了9.1%，效率提高了6.6。', 'title_zh': '_spike2former：高效的脉冲变压器用于高性能图像分割_\n\n注：为了使翻译更符合中文学术规范，可以稍微调整一下句子结构。原文“Spike2Former: Efficient Spiking Transformer for High-performance Image Segmentation”翻译为“_spike2former：高效的脉冲变压器用于高性能图像分割_”已经比较接近规范。如果你需要更正式的表达，可以改为：\n\n_spike2former：高效脉冲变压器模型用于高性能图像分割_\n\n这样更符合中文的表达习惯。'}
{'arxiv_id': 'arXiv:2412.14579', 'title': 'GSRender: Deduplicated Occupancy Prediction via Weakly Supervised 3D Gaussian Splatting', 'authors': 'Qianpu Sun, Changyong Shu, Sifan Zhou, Zichen Yu, Yan Chen, Dawei Yang, Yuan Chun', 'link': 'https://arxiv.org/abs/2412.14579', 'abstract': '3D occupancy perception is gaining increasing attention due to its capability to offer detailed and precise environment representations. Previous weakly-supervised NeRF methods balance efficiency and accuracy, with mIoU varying by 5-10 points due to sampling count along camera rays. Recently, real-time Gaussian splatting has gained widespread popularity in 3D reconstruction, and the occupancy prediction task can also be viewed as a reconstruction task. Consequently, we propose GSRender, which naturally employs 3D Gaussian Splatting for occupancy prediction, simplifying the sampling process. In addition, the limitations of 2D supervision result in duplicate predictions along the same camera ray. We implemented the Ray Compensation (RC) module, which mitigates this issue by compensating for features from adjacent frames. Finally, we redesigned the loss to eliminate the impact of dynamic objects from adjacent frames. Extensive experiments demonstrate that our approach achieves SOTA (state-of-the-art) results in RayIoU (+6.0), while narrowing the gap with 3D supervision methods. Our code will be released soon.', 'abstract_zh': '三维占用感知正逐渐受到关注，因为它能够提供详细且精确的环境表示。以往的弱监督NeRF方法在效率和准确性之间进行权衡，mIoU的变化幅度为5-10个百分点，这主要归因于沿相机光线的采样数量。最近，实时高斯散射在三维重建领域获得了广泛应用，而占用预测任务也可以被视为一种重建任务。因此，我们提出了一种名为GSRender的方法，该方法自然地利用三维高斯散射进行占用预测，从而简化了采样过程。此外，二维监督的局限性会导致沿同一相机光线重复预测的问题。我们实现了Ray Compensation（光线补偿）模块，通过补偿相邻帧中的特征来缓解这一问题。最后，我们重新设计了损失函数，以消除相邻帧中动态对象的影响。通过广泛的实验，我们的方法在RayIoU上取得了SOTA（现有最佳）的结果，同时缩小了与基于三维监督方法的差距。我们的代码将很快发布。', 'title_zh': 'GSRender: 通过弱监督3D高斯斑点图实现重复占用预测'}
{'arxiv_id': 'arXiv:2412.14571', 'title': 'SCKD: Semi-Supervised Cross-Modality Knowledge Distillation for 4D Radar Object Detection', 'authors': 'Ruoyu Xu, Zhiyu Xiang, Chenwei Zhang, Hanzhi Zhong, Xijun Zhao, Ruina Dang, Peng Xu, Tianyu Pu, Eryun Liu', 'link': 'https://arxiv.org/abs/2412.14571', 'abstract': '3D object detection is one of the fundamental perception tasks for autonomous vehicles. Fulfilling such a task with a 4D millimeter-wave radar is very attractive since the sensor is able to acquire 3D point clouds similar to Lidar while maintaining robust measurements under adverse weather. However, due to the high sparsity and noise associated with the radar point clouds, the performance of the existing methods is still much lower than expected. In this paper, we propose a novel Semi-supervised Cross-modality Knowledge Distillation (SCKD) method for 4D radar-based 3D object detection. It characterizes the capability of learning the feature from a Lidar-radar-fused teacher network with semi-supervised distillation. We first propose an adaptive fusion module in the teacher network to boost its performance. Then, two feature distillation modules are designed to facilitate the cross-modality knowledge transfer. Finally, a semi-supervised output distillation is proposed to increase the effectiveness and flexibility of the distillation framework. With the same network structure, our radar-only student trained by SCKD boosts the mAP by 10.38% over the baseline and outperforms the state-of-the-art works on the VoD dataset. The experiment on ZJUODset also shows 5.12% mAP improvements on the moderate difficulty level over the baseline when extra unlabeled data are available. Code is available at this https URL.', 'abstract_zh': '三维物体检测是自主车辆基本感知任务之一。使用4D毫米波雷达完成此类任务非常具有吸引力，因为该传感器能够在恶劣天气下保持稳健测量的同时，还能像激光雷达一样获取3D点云。然而，由于雷达点云高稀疏性和噪声，现有方法的效果仍然低于预期。在本文中，我们提出了一种新颖的半监督跨模态知识蒸馏（SCKD）方法，用于基于4D雷达的三维物体检测。该方法通过半监督蒸馏，在融合激光雷达和雷达信息的教师网络中学习特征。首先，我们在教师网络中提出了一种自适应融合模块，以提升其性能。然后，设计了两个特征蒸馏模块，以促进跨模态知识传输。最后，提出了一种半监督输出蒸馏方法，以增加蒸馏框架的有效性和灵活性。在相同的网络结构下，使用SCKD训练的仅有雷达数据的学生模型，在基准模型上提高了10.38%的mAP，并在VoD数据集上优于现有最佳工作。当额外的未标注数据可用时，在ZJUOD数据集上也展示了5.12%的mAP提升。源代码可通过以下链接获取：这个https URL。', 'title_zh': 'SCKD：半监督跨模态知识精炼在4D雷达目标检测中的应用'}
{'arxiv_id': 'arXiv:2412.14570', 'title': 'Characterising Simulation-Based Program Equilibria', 'authors': 'Emery Cooper, Caspar Oesterheld, Vincent Conitzer', 'link': 'https://arxiv.org/abs/2412.14570', 'abstract': "In Tennenholtz's program equilibrium, players of a game submit programs to play on their behalf. Each program receives the other programs' source code and outputs an action. This can model interactions involving AI agents, mutually transparent institutions, or commitments. Tennenholtz (2004) proves a folk theorem for program games, but the equilibria constructed are very brittle. We therefore consider simulation-based programs -- i.e., programs that work by running opponents' programs. These are relatively robust (in particular, two programs that act the same are treated the same) and are more practical than proof-based approaches. Oesterheld's (2019) $\\epsilon$Grounded$\\pi$Bot is such an approach. Unfortunately, it is not generally applicable to games of three or more players, and only allows for a limited range of equilibria in two player games. In this paper, we propose a generalisation to Oesterheld's (2019) $\\epsilon$Grounded$\\pi$Bot. We prove a folk theorem for our programs in a setting with access to a shared source of randomness. We then characterise their equilibria in a setting without shared randomness. Both with and without shared randomness, we achieve a much wider range of equilibria than Oesterheld's (2019) $\\epsilon$Grounded$\\pi$Bot. Finally, we explore the limits of simulation-based program equilibrium, showing that the Tennenholtz folk theorem cannot be attained by simulation-based programs without access to shared randomness.", 'abstract_zh': '在Tennenholtz的游戏程序均衡中，游戏中的玩家提交程序来代表自己行动。每个程序接收其他程序的源代码并输出一个行动。这种方法可以模拟涉及AI代理、互操作透明机构或承诺的交互。Tennenholtz (2004) 对程序游戏证明了公理定理，但构造的均衡非常脆弱。因此，我们考虑基于模拟的程序——即通过运行对手程序来进行工作的程序。这类程序相对坚固（特别是，行动相同的两个程序被同等对待），并且比基于证明的方法更实用。Oesterheld (2019) 的$\\epsilon$Grounded$\\pi$Bot 就是一种这种方法。然而，这种方法对三人及以上玩家的游戏不具普遍适用性，并且仅允许两玩家游戏中的有限范围的均衡。在本文中，我们提出了Oesterheld (2019) 的$\\epsilon$Grounded$\\pi$Bot 的一个一般化版本。我们证明了在共享随机源可用的情况下，这类程序的公理定理。然后，我们在没有共享随机源的情况下探讨了这类程序的均衡特性。无论是有共享随机源还是没有共享随机源，我们都实现了比Oesterheld (2019) 的$\\epsilon$Grounded$\\pi$Bot 更广泛的均衡范围。最后，我们探讨了基于模拟的程序均衡的极限，证明了没有共享随机源的基于模拟的程序无法达到Tennenholtz的公理定理。', 'title_zh': '基于模拟的程序均衡特性分析'}
{'arxiv_id': 'arXiv:2412.14569', 'title': 'Global Spatio-Temporal Fusion-based Traffic Prediction Algorithm with Anomaly Aware', 'authors': 'Chaoqun Liu, Xuanpeng Li, Chen Gong, Guangyu Li', 'link': 'https://arxiv.org/abs/2412.14569', 'abstract': 'Traffic prediction is an indispensable component of urban planning and traffic management. Achieving accurate traffic prediction hinges on the ability to capture the potential spatio-temporal relationships among road sensors. However, the majority of existing works focus on local short-term spatio-temporal correlations, failing to fully consider the interactions of different sensors in the long-term state. In addition, these works do not analyze the influences of anomalous factors, or have insufficient ability to extract personalized features of anomalous factors, which make them ineffectively capture their spatio-temporal influences on traffic prediction. To address the aforementioned issues, We propose a global spatio-temporal fusion-based traffic prediction algorithm that incorporates anomaly awareness. Initially, based on the designed anomaly detection network, we construct an efficient anomalous factors impacting module (AFIM), to evaluate the spatio-temporal impact of unexpected external events on traffic prediction. Furthermore, we propose a multi-scale spatio-temporal feature fusion module (MTSFFL) based on the transformer architecture, to obtain all possible both long and short term correlations among different sensors in a wide-area traffic environment for accurate prediction of traffic flow. Finally, experiments are implemented based on real-scenario public transportation datasets (PEMS04 and PEMS08) to demonstrate that our approach can achieve state-of-the-art performance.', 'abstract_zh': '交通预测是城市规划和交通管理不可或缺的一部分。实现准确的交通预测依赖于捕捉道路传感器之间潜在的空间-时间关系的能力。然而，现有工作大多关注局部的短期空间-时间相关性，未能充分考虑不同传感器在长期状态下的交互作用。此外，这些工作没有分析异常因素的影响，或者提取异常因素个性化特征的能力不足，这使得它们无法有效地捕捉这些因素对交通预测的空间-时间影响。为解决上述问题，我们提出了一种基于全局空间-时间融合的交通预测算法，引入了异常意识。首先，基于设计的异常检测网络，我们构建了一个高效的异常因素影响模块（AFIM），以评估意外外部事件对交通预测的空间-时间影响。此外，我们基于变压器架构提出了一个多尺度空间-时间特征融合模块（MTSFFL），以在广泛区域的交通环境中获得不同传感器之间所有可能的短期和长期相关性，从而实现对交通流的精准预测。最后，基于实际场景的公共交通数据集（PEMS04和PEMS08）进行了实验，证明我们的方法可以达到目前最先进的性能。', 'title_zh': '具备异常检测意识的全局时空融合交通预测算法'}
{'arxiv_id': 'arXiv:2412.14566', 'title': 'AIArena: A Blockchain-Based Decentralized AI Training Platform', 'authors': 'Zhipeng Wang, Rui Sun, Elizabeth Lui, Tuo Zhou, Yizhe Wen, Jiahao Sun', 'link': 'https://arxiv.org/abs/2412.14566', 'abstract': 'The rapid advancement of AI has underscored critical challenges in its development and implementation, largely due to centralized control by a few major corporations. This concentration of power intensifies biases within AI models, resulting from inadequate governance and oversight mechanisms. Additionally, it limits public involvement and heightens concerns about the integrity of model generation. Such monopolistic control over data and AI outputs threatens both innovation and fair data usage, as users inadvertently contribute data that primarily benefits these corporations. In this work, we propose AIArena, a blockchain-based decentralized AI training platform designed to democratize AI development and alignment through on-chain incentive mechanisms. AIArena fosters an open and collaborative environment where participants can contribute models and computing resources. Its on-chain consensus mechanism ensures fair rewards for participants based on their contributions. We instantiate and implement AIArena on the public Base blockchain Sepolia testnet, and the evaluation results demonstrate the feasibility of AIArena in real-world applications.', 'abstract_zh': '人工智能的 rapid advancement 早已凸显了其发展中和实施过程中的一些关键挑战，这主要是由于少数几家大型企业对人工智能的集中控制。这种权力集中加剧了人工智能模型中的偏差性，主要是由于缺乏有效的治理和监督机制。此外，这也限制了公众的参与，增加了对模型生成完整性的担忧。这种对数据和人工智能输出的垄断控制不仅威胁到了创新，也限制了公平的数据使用，因为用户在不知情的情况下贡献的数据主要有利于这些企业。在本文中，我们提出了一种基于区块链的去中心化人工智能训练平台 AIArena，通过链上激励机制，旨在实现人工智能的普及和发展。AIArena 创建了一个开放和协作的环境，参与者可以贡献模型和计算资源。链上的共识机制可以根据参与者的贡献公平地分配奖励。我们已在公共 Base 区块链 Sepolia 测试网上实现了 AIArena，并对其实现和应用进行了评估，结果表明 AIArena 在实际应用中具有可行性。', 'title_zh': 'AIArena：一种基于区块链的去中心化AI训练平台'}
{'arxiv_id': 'arXiv:2412.14545', 'title': 'Summary of Point Transformer with Federated Learning for Predicting Breast Cancer HER2 Status from Hematoxylin and Eosin-Stained Whole Slide Images', 'authors': 'Kamorudeen A. Amuda, Almustapha A. Wakili', 'link': 'https://arxiv.org/abs/2412.14545', 'abstract': 'This study introduces a federated learning-based approach to predict HER2 status from hematoxylin and eosin (HE)-stained whole slide images (WSIs), reducing costs and speeding up treatment decisions. To address label imbalance and feature representation challenges in multisite datasets, a point transformer is proposed, incorporating dynamic label distribution, an auxiliary classifier, and farthest cosine sampling. Extensive experiments demonstrate state-of-the-art performance across four sites (2687 WSIs) and strong generalization to two unseen sites (229 WSIs).', 'abstract_zh': '本文介绍了一种基于联邦学习的方法，用于预测苏木精和伊红（HE）染色的全玻片图像（WSI）中的HER2状态，从而降低费用并加快治疗决策速度。为了应对多中心数据集中标签不均衡和特征表示的挑战，提出了一种点变换器方法，该方法结合了动态标签分布、辅助分类器和最远余弦采样。广泛的实验表明，该方法在四个中心（2687张WSI）上达到了最先进的性能，并且在两个未见过的中心（229张WSI）上具有强大的泛化能力。', 'title_zh': '基于联邦学习的点变换器总结：用于预测乳腺癌HER2状态的苏木精和 eosin 染色全切片图像分析'}
{'arxiv_id': 'arXiv:2412.14538', 'title': 'Overview of AI and Communication for 6G Network: Fundamentals, Challenges, and Future Research Opportunities', 'authors': 'Qimei Cui, Xiaohu You, Ni Wei, Guoshun Nan, Xuefei Zhang, Jianhua Zhang, Xinchen Lyu, Ming Ai, Xiaofeng Tao, Zhiyong Feng, Ping Zhang, Qingqing Wu, Meixia Tao, Yongming Huang, Chongwen Huang, Guangyi Liu, Chenghui Peng, Zhiwen Pan, Tao Sun, Dusit Niyato, Tao Chen, Muhammad Khurram Khan, Abbas Jamalipour, Mohsen Guizani, Chau Yuen', 'link': 'https://arxiv.org/abs/2412.14538', 'abstract': 'With the increasing demand for seamless connectivity and intelligent communication, the integration of artificial intelligence (AI) and communication for sixth-generation (6G) network is emerging as a revolutionary architecture. This paper presents a comprehensive overview of AI and communication for 6G networks, emphasizing their foundational principles, inherent challenges, and future research opportunities. We commence with a retrospective analysis of AI and the evolution of large-scale AI models, underscoring their pivotal roles in shaping contemporary communication technologies. The discourse then transitions to a detailed exposition of the envisioned integration of AI within 6G networks, delineated across three progressive developmental stages. The initial stage, AI for Network, focuses on employing AI to augment network performance, optimize efficiency, and enhance user service experiences. The subsequent stage, Network for AI, highlights the role of the network in facilitating and buttressing AI operations and presents key enabling technologies, including digital twins for AI and semantic communication. In the final stage, AI as a Service, it is anticipated that future 6G networks will innately provide AI functions as services and support application scenarios like immersive communication and intelligent industrial robots. Specifically, we have defined the quality of AI service, which refers to the measurement framework system of AI services within the network. In addition to these developmental stages, we thoroughly examine the standardization processes pertinent to AI in network contexts, highlighting key milestones and ongoing efforts. Finally, we outline promising future research opportunities that could drive the evolution and refinement of AI and communication for 6G, positioning them as a cornerstone of next-generation communication infrastructure.', 'abstract_zh': '随着对无缝连接和智能通信需求的不断增加，人工智能（AI）与第六代（6G）网络的集成正逐渐成为一种革命性的架构。本文对6G网络中的AI与通信进行了全面概述，强调了其基础原理、固有挑战以及未来的研究机会。我们首先对AI的历史进行回顾分析，探讨大规模AI模型的演变过程及其在塑造现代通信技术方面的重要作用。随后，讨论转向对AI在6G网络中预期集成的详细阐述，分为三个逐步发展的阶段。第一个阶段“AI赋能网络”侧重于利用AI提升网络性能、优化效率并增强用户服务体验。第二个阶段“网络赋能AI”强调网络在促进和支撑AI操作中的作用，并介绍了关键技术，包括用于AI的数字孪生和语义通信。在最后一个阶段“AI即服务”中，预计将未来的6G网络能够内建AI功能作为服务，并支持融入沉浸式通信和智能工业机器人等应用情境。具体而言，我们定义了AI服务的质量，即网络中AI服务的衡量框架系统。除此之外，我们还深入探讨了在网络环境中与AI相关的标准化进程，指出了重要里程碑和正在进行的工作。最后，我们概述了驱动AI与通信在6G技术领域不断发展和完善的潜在研究机会，将其定位为下一代通信基础设施的核心支柱。', 'title_zh': '6G网络中人工智能与通信的综述：基础、挑战及未来研究机遇'}
{'arxiv_id': 'arXiv:2412.14522', 'title': 'CAE-T: A Channelwise AutoEncoder with Transformer for EEG Abnormality Detection', 'authors': 'Youshen Zhao, Keiji Iramina', 'link': 'https://arxiv.org/abs/2412.14522', 'abstract': 'Electroencephalogram (EEG) signals are critical for detecting abnormal brain activity, but their high dimensionality and complexity pose significant challenges for effective analysis. In this paper, we propose CAE-T, a novel framework that combines a channelwise CNN-based autoencoder with a single-head transformer classifier for efficient EEG abnormality detection. The channelwise autoencoder compresses raw EEG signals while preserving channel independence, reducing computational costs and retaining biologically meaningful features. The compressed representations are then fed into the transformer-based classifier, which efficiently models long-term dependencies to distinguish between normal and abnormal signals. Evaluated on the TUH Abnormal EEG Corpus, the proposed model achieves 85.0% accuracy, 76.2% sensitivity, and 91.2% specificity at the per-case level, outperforming baseline models such as EEGNet, Deep4Conv, and FusionCNN. Furthermore, CAE-T requires only 202M FLOPs and 2.9M parameters, making it significantly more efficient than transformer-based alternatives. The framework retains interpretability through its channelwise design, demonstrating great potential for future applications in neuroscience research and clinical practice. The source code is available at this https URL.', 'abstract_zh': '以下是翻译成中文的版本，符合学术规范：\n\n事件相关电位（Electroencephalogram, EEG）信号对于检测异常脑活动至关重要，但其高维度和复杂性对有效分析构成了重大挑战。本文提出了一种名为CAE-T的新框架，该框架将通道级卷积神经网络（Convolutional Neural Network, CNN）自动编码器与单头变压器分类器相结合，以实现高效的EEG异常检测。通道级自动编码器能够压缩原始EEG信号并保持通道独立性，降低计算成本并保留生物意义显著的特征。压缩后的表示随后被输入基于变压器的分类器，该分类器能够有效地建模长期依赖性，以区分正常和异常信号。在TUU异常EEG语料库上进行评估，所提出模型在每个病例水平上实现了85.0%的准确率、76.2%的灵敏度和91.2%的特异度，优于诸如EEGNet、Deep4Conv和FusionCNN等基线模型。此外，CAE-T仅需202M FLOPs和2.9M参数，显著优于基于变压器的替代方案。该框架通过其通道级设计保留了可解释性，展示了在神经科学研究和临床实践中广泛应用的巨大潜力。源代码已在此处提供：<该网址>。\n\n注：上述翻译中，“事件相关电位”指的是“事件相关电位”（Event-related potentials, ERPs），在缺少具体上下文的情况下，原文中的“Electroencephalogram (EEG) signals”在医学和脑科学研究中一般是直接指“电生理信号”或“脑电图信号”，但在特定语境中，也可为“事件相关电位”。根据具体应用场景，此术语可进一步调整。', 'title_zh': 'CAE-T：用于EEG异常检测的通道级自编码器与变压器相结合的方法'}
{'arxiv_id': 'arXiv:2412.14510', 'title': 'PA-RAG: RAG Alignment via Multi-Perspective Preference Optimization', 'authors': 'Jiayi Wu, Hengyi Cai, Lingyong Yan, Hao Sun, Xiang Li, Shuaiqiang Wang, Dawei Yin, Ming Gao', 'link': 'https://arxiv.org/abs/2412.14510', 'abstract': 'The emergence of Retrieval-augmented generation (RAG) has alleviated the issues of outdated and hallucinatory content in the generation of large language models (LLMs), yet it still reveals numerous limitations. When a general-purpose LLM serves as the RAG generator, it often suffers from inadequate response informativeness, response robustness, and citation quality. Past approaches to tackle these limitations, either by incorporating additional steps beyond generating responses or optimizing the generator through supervised fine-tuning (SFT), still failed to align with the RAG requirement thoroughly. Consequently, optimizing the RAG generator from multiple preference perspectives while maintaining its end-to-end LLM form remains a challenge. To bridge this gap, we propose Multiple Perspective Preference Alignment for Retrieval-Augmented Generation (PA-RAG), a method for optimizing the generator of RAG systems to align with RAG requirements comprehensively. Specifically, we construct high-quality instruction fine-tuning data and multi-perspective preference data by sampling varied quality responses from the generator across different prompt documents quality scenarios. Subsequently, we optimize the generator using SFT and Direct Preference Optimization (DPO). Extensive experiments conducted on four question-answer datasets across three LLMs demonstrate that PA-RAG can significantly enhance the performance of RAG generators. Our code and datasets are available at this https URL.', 'abstract_zh': '检索增强生成（RAG）的出现缓解了大型语言模型（LLMs）生成过程中内容过时和幻觉的问题，但仍揭示出许多局限性。当通用型LLM作为RAG生成器时，它往往在响应信息丰富性、响应稳健性和引证质量方面存在不足。过去解决这些问题的方法要么通过生成响应之外的额外步骤，要么通过监督微调（SFT）优化生成器，这些方法仍未充分满足RAG的要求。因此，如何从多个偏好角度优化RAG生成器并保持其端到端的LLM形式仍是一个挑战。为解决这一问题，我们提出了一种综合性优化方法——多角度偏好对齐的检索增强生成（PA-RAG），用于全面优化RAG系统中的生成器。具体而言，我们通过在不同提示文档质量场景中采样多质量级别的响应来构建高质量的指令微调数据和多角度偏好数据。随后，我们使用监督微调（SFT）和直接偏好优化（DPO）对生成器进行优化。我们在三个LLM的四个问答数据集上进行了广泛的实验，结果表明PA-RAG可以显著提升RAG生成器的性能。我们的代码和数据集可在以下链接获得：[此 https URL]。', 'title_zh': 'PA-RAG：基于多视角偏好优化的RAG对齐'}
{'arxiv_id': 'arXiv:2412.14497', 'title': 'Treatment Effects Estimation on Networked Observational Data using Disentangled Variational Graph Autoencoder', 'authors': 'Di Fan, Renlei Jiang, Yunhao Wen, Chuanhou Gao', 'link': 'https://arxiv.org/abs/2412.14497', 'abstract': 'Estimating individual treatment effect (ITE) from observational data has gained increasing attention across various domains, with a key challenge being the identification of latent confounders affecting both treatment and outcome. Networked observational data offer new opportunities to address this issue by utilizing network information to infer latent confounders. However, most existing approaches assume observed variables and network information serve only as proxy variables for latent confounders, which often fails in practice, as some variables influence treatment but not outcomes, and vice versa. Recent advances in disentangled representation learning, which disentangle latent factors into instrumental, confounding, and adjustment factors, have shown promise for ITE estimation. Building on this, we propose a novel disentangled variational graph autoencoder that learns disentangled factors for treatment effect estimation on networked observational data. Our graph encoder further ensures factor independence using the Hilbert-Schmidt Independence Criterion. Extensive experiments on two semi-synthetic datasets derived from real-world social networks and one synthetic dataset demonstrate that our method achieves state-of-the-art performance.', 'abstract_zh': '从观察数据中估计个体治疗效应（ITE）在各个领域都受到了越来越多的关注，一个关键挑战是识别影响治疗和结果的潜在混杂因素。网络化的观察数据提供了新的机会，通过利用网络信息来推断潜在混杂因素。然而，现有的大多数方法假设观测变量和网络信息仅作为潜在混杂因素的代理变量，而在实践中这往往无法实现，因为一些变量可能影响治疗但不直接影响结果，反之亦然。近年来，解开表征学习的进展，能够将潜在因素分离为工具变量、混杂变量和调整变量，为ITE估计带来了希望。在此基础上，我们提出了一种新的解开表示的变分图自编码器，用于网络化观察数据中的治疗效果估计。该图编码器通过希尔伯特-施密特独立性判据进一步确保了因素的独立性。在来自真实世界社交网络的两个半合成数据集和一个合成数据集上进行的广泛实验表明，我们的方法达到了最先进的性能。', 'title_zh': '使用解耦变分图自编码器估计网络观测数据中的治疗效应'}
{'arxiv_id': 'arXiv:2412.14488', 'title': 'Stochastic first-order methods with multi-extrapolated momentum for highly smooth unconstrained optimization', 'authors': 'Chuan He', 'link': 'https://arxiv.org/abs/2412.14488', 'abstract': 'In this paper we consider an unconstrained stochastic optimization problem where the objective function exhibits a high order of smoothness. In particular, we propose a stochastic first-order method (SFOM) with multi-extrapolated momentum, in which multiple extrapolations are performed in each iteration, followed by a momentum step based on these extrapolations. We show that our proposed SFOM with multi-extrapolated momentum can accelerate optimization by exploiting the high-order smoothness of the objective function $f$. Specifically, assuming that the gradient and the $p$th-order derivative of $f$ are Lipschitz continuous for some $p\\ge2$, and under some additional mild assumptions, we establish that our method achieves a sample complexity of $\\widetilde{\\mathcal{O}}(\\epsilon^{-(3p+1)/p})$ for finding a point $x$ satisfying $\\mathbb{E}[\\|\\nabla f(x)\\|]\\le\\epsilon$. To the best of our knowledge, our method is the first SFOM to leverage arbitrary order smoothness of the objective function for acceleration, resulting in a sample complexity that strictly improves upon the best-known results without assuming the average smoothness condition. Finally, preliminary numerical experiments validate the practical performance of our method and corroborate our theoretical findings.', 'abstract_zh': '在本文中，我们考虑了一个无约束随机优化问题，其中目标函数呈现出较高的光滑性。特别地，我们提出了一种具有多步外推动量的随机一阶方法（SFOM），在每次迭代中进行多次外推，随后基于这些外推进行动量步骤。我们展示了我们的提议方法——具有多步外推动量的SFOM——可以通过利用目标函数 \\(f\\) 的高阶光滑性来加速优化过程。具体而言，假设函数 \\(f\\) 的梯度以及 \\(p\\) 阶导数在某些 \\(p \\ge 2\\) 下是利普希兹连续的，并且在一些附加的温和假设下，我们证明了该方法可以在期望梯度范数 \\(\\mathbb{E}[\\|\\nabla f(x)\\|]\\le\\epsilon\\) 时达到 \\(\\widetilde{\\mathcal{O}}(\\epsilon^{-(3p+1)/p})\\) 的样本复杂度。据我们所知，我们的方法是第一个利用目标函数任意阶光滑性来加速的SFOM，其样本复杂度在不假设平均光滑性条件的情况下严格优于已知的最佳结果。最后，初步的数值实验验证了我们方法的实际性能，并与我们的理论发现相一致。', 'title_zh': '含有多重外推动量的随机一阶方法在高度光滑的无约束优化中的应用'}
{'arxiv_id': 'arXiv:2412.14468', 'title': 'HashAttention: Semantic Sparsity for Faster Inference', 'authors': 'Aditya Desai, Shuo Yang, Alejandro Cuadron, Ana Klimovic, Matei Zaharia, Joseph E. Gonzalez, Ion Stoica', 'link': 'https://arxiv.org/abs/2412.14468', 'abstract': 'Utilizing longer contexts is increasingly essential to power better AI systems. However, the cost of attending to long contexts is high due to the involved softmax computation. While the scaled dot-product attention (SDPA) exhibits token sparsity, with only a few pivotal tokens significantly contributing to attention, leveraging this sparsity effectively remains an open challenge. Previous methods either suffer from model degradation or require considerable additional resources. We propose HashAttention --a principled approach casting pivotal token identification as a recommendation problem. Given a query, HashAttention encodes keys and queries in Hamming space capturing the required semantic similarity using learned mapping functions. HashAttention efficiently identifies pivotal tokens for a given query in this Hamming space using bitwise operations, and only these pivotal tokens are used for attention computation, significantly improving overall attention efficiency. HashAttention can reduce the number of tokens used by a factor of $1/32\\times$ for the Llama-3.1-8B model with LongBench, keeping average quality loss within 0.6 points, while using only 32 bits per token auxiliary memory. At $32\\times$ sparsity, HashAttention is $3{-}6\\times$ faster than LightLLM and $2.5{-}4.5\\times$ faster than gpt-fast on Nvidia-L4 GPU.', 'abstract_zh': '利用更长的上下文对于提升AI系统的能力变得越来越重要。然而，处理长上下文的成本很高，因为涉及到了softmax计算。虽然缩放点积注意机制（SDPA）展示了令牌稀疏性，即只有少数几个关键的令牌对注意力贡献较大，但有效地利用这种稀疏性仍是一个开放的挑战。以往的方法要么导致模型性能下降，要么需要大量的额外资源。我们提出了一种名为HashAttention的方法——这是一种原理性的方法，将其关键令牌识别问题转化为推荐问题。对于给定的查询，HashAttention将键和查询编码到汉明空间中，并利用学习到的映射函数捕获所需的语义相似度。HashAttention通过位操作高效地识别出对给定查询而言的关键令牌，并仅使用这些关键令牌进行注意力计算，从而显著提高整体注意力效率。在使用LongBench对Llama-3.1-8B模型的实验中，HashAttention可以将所使用令牌的数量减少到原来的1/32，同时在平均质量损失控制在0.6分以内的前提下，只需要每令牌使用32位的辅助存储。在汉明稀疏度达到32倍的情况下，HashAttention在Nvidia L4 GPU上比LightLLM快3-6倍，比gpt-fast快2.5-4.5倍。', 'title_zh': 'HashAttention：语义稀疏化以实现更快的推理'}
{'arxiv_id': 'arXiv:2412.14451', 'title': 'CLDG: Contrastive Learning on Dynamic Graphs', 'authors': 'Yiming Xu, Bin Shi, Teng Ma, Bo Dong, Haoyi Zhou, Qinghua Zheng', 'link': 'https://arxiv.org/abs/2412.14451', 'abstract': "The graph with complex annotations is the most potent data type, whose constantly evolving motivates further exploration of the unsupervised dynamic graph representation. One of the representative paradigms is graph contrastive learning. It constructs self-supervised signals by maximizing the mutual information between the statistic graph's augmentation views. However, the semantics and labels may change within the augmentation process, causing a significant performance drop in downstream tasks. This drawback becomes greatly magnified on dynamic graphs. To address this problem, we designed a simple yet effective framework named CLDG. Firstly, we elaborate that dynamic graphs have temporal translation invariance at different levels. Then, we proposed a sampling layer to extract the temporally-persistent signals. It will encourage the node to maintain consistent local and global representations, i.e., temporal translation invariance under the timespan views. The extensive experiments demonstrate the effectiveness and efficiency of the method on seven datasets by outperforming eight unsupervised state-of-the-art baselines and showing competitiveness against four semi-supervised methods. Compared with the existing dynamic graph method, the number of model parameters and training time is reduced by an average of 2,001.86 times and 130.31 times on seven datasets, respectively.", 'abstract_zh': '具有复杂注释的图是最强大的数据类型，其不断变化特性激发了无监督动态图表示的进一步探索。其中一个代表性范式是图对比学习。该方法通过最大化统计图增强视角之间的互信息来构建自我监督信号。然而，在增强过程中，语义和标签可能会发生变化，导致下游任务性能显著下降。这一问题在动态图上尤为突出。为解决这一问题，我们设计了一个简单而有效的框架，名为CLDG。首先，我们阐明动态图在不同层次上具有时间平移不变性。然后，我们提出了一种抽样层来提取时间持久的信号，它将鼓励节点在时间跨度视角下保持一致的局部和全局表示，即时间平移不变性。广泛的实验结果证明了该方法在七个数据集上的有效性和效率，通过在七个数据集上超越八个无监督的最新基线方法，并且与四种半监督方法保持竞争力。与现有的动态图方法相比，该方法在七个数据集上的模型参数数量和训练时间分别减少了2,001.86倍和130.31倍。', 'title_zh': 'CLDG：动态图上的对比学习'}
{'arxiv_id': 'arXiv:2412.14444', 'title': 'GenHMR: Generative Human Mesh Recovery', 'authors': 'Muhammad Usama Saleem, Ekkasit Pinyoanuntapong, Pu Wang, Hongfei Xue, Srijan Das, Chen Chen', 'link': 'https://arxiv.org/abs/2412.14444', 'abstract': 'Human mesh recovery (HMR) is crucial in many computer vision applications; from health to arts and entertainment. HMR from monocular images has predominantly been addressed by deterministic methods that output a single prediction for a given 2D image. However, HMR from a single image is an ill-posed problem due to depth ambiguity and occlusions. Probabilistic methods have attempted to address this by generating and fusing multiple plausible 3D reconstructions, but their performance has often lagged behind deterministic approaches. In this paper, we introduce GenHMR, a novel generative framework that reformulates monocular HMR as an image-conditioned generative task, explicitly modeling and mitigating uncertainties in the 2D-to-3D mapping process. GenHMR comprises two key components: (1) a pose tokenizer to convert 3D human poses into a sequence of discrete tokens in a latent space, and (2) an image-conditional masked transformer to learn the probabilistic distributions of the pose tokens, conditioned on the input image prompt along with randomly masked token sequence. During inference, the model samples from the learned conditional distribution to iteratively decode high-confidence pose tokens, thereby reducing 3D reconstruction uncertainties. To further refine the reconstruction, a 2D pose-guided refinement technique is proposed to directly fine-tune the decoded pose tokens in the latent space, which forces the projected 3D body mesh to align with the 2D pose clues. Experiments on benchmark datasets demonstrate that GenHMR significantly outperforms state-of-the-art methods. Project website can be found at this https URL', 'abstract_zh': '人体网格恢复（HMR）在许多计算机视觉应用中都至关重要，从健康到艺术和娱乐领域。单目图像的HMR问题主要由确定性方法解决，这些方法针对给定的2D图像输出一个单一预测。然而，由于深度不确定性和遮挡，从单目图像进行HMR是一个病态问题。尽管概率方法尝试通过生成和融合多个可能的3D重建来解决这一问题，但它们的表现往往落后于确定性方法。在本文中，我们引入了GenHMR，这是一种新颖的生成框架，将单目HMR重新表述为基于图像生成的任务，明确地建模和缓解了从2D到3D映射过程中的不确定性。GenHMR包含两个关键组件：（1）姿态分词器，将3D人体姿态转换为潜在空间中的离散标记序列，以及（2）基于图像的掩模变换器，该变换器在输入图像提示和随机掩模标记序列的条件下学习姿态标记的概率分布。在推理过程中，模型从学习的条件分布中采样，逐步解码高置信度的姿态标记，从而减少3D重建的不确定性。为了进一步细化重建，我们提出了一种基于2D姿态的细化技术，直接在潜在空间中微调解码的姿态标记，迫使投影的3D人体网格与2D姿态线索对齐。在基准数据集上的实验表明，GenHMR 显著优于最先进的方法。网站链接可在此找到：[提供的链接]', 'title_zh': 'GenHMR：生成式人体网格恢复'}
{'arxiv_id': 'arXiv:2412.14436', 'title': 'ORBIT: Cost-Effective Dataset Curation for Large Language Model Domain Adaptation with an Astronomy Case Study', 'authors': 'Eric Modesitt, Ke Yang, Spencer Hulsey, Chengxiang Zhai, Volodymyr Kindratenko', 'link': 'https://arxiv.org/abs/2412.14436', 'abstract': "Recent advances in language modeling demonstrate the need for high-quality domain-specific training data, especially for tasks that require specialized knowledge. General-purpose models, while versatile, often lack the depth needed for expert-level tasks because of limited domain-specific information. Domain adaptation training can enhance these models, but it demands substantial, high-quality data. To address this, we propose ORBIT, a cost-efficient methodology for curating massive, high-quality domain-specific datasets from noisy web sources, tailored for training specialist large language models. Using astronomy as a primary case study, we refined the 1.3T-token FineWeb-Edu dataset into a high-quality, 10B-token subset focused on astronomy. Fine-tuning \\textsc{LLaMA-3-8B} on a 1B-token astronomy subset improved performance on the MMLU astronomy benchmark from 69\\% to 76\\% and achieved top results on AstroBench, an astronomy-specific benchmark. Moreover, our model (Orbit-LLaMA) outperformed \\textsc{LLaMA-3-8B-base}, with GPT-4o evaluations preferring it in 73\\% of cases across 1000 astronomy-specific questions. Additionally, we validated ORBIT's generalizability by applying it to law and medicine, achieving a significant improvement of data quality compared to an unfiltered baseline. We open-source the ORBIT methodology, including the curated datasets, the codebase, and the resulting model at \\href{this https URL}{this https URL}.", 'abstract_zh': '近年来，在语言模型方面的进展凸显了高质量领域特定训练数据的必要性，尤其是在需要专业领域知识的任务中。通用模型虽然功能强大，但在专业任务中往往缺乏必要的深度，因为它们在特定领域的信息有限。领域适应训练可以增强这些模型，但这类训练需要大量高质量的数据。为了应对这一挑战，我们提出了一种名为ORBIT的方法，该方法旨在从噪声较大的网络来源中高效地收集大规模高质量的领域特定数据集，以训练专业大型语言模型。以天文学为例，我们对1.3T词的FineWeb-Edu数据集进行了细化，得到了一个专注于天文学的高质量、100亿词的子集。进一步地，通过在天文学子集上微调\\textsc{LLaMA-3-8B}模型，MMLU天文学基准测试的性能提高了7.6个百分点，达到了AstroBench（一个专门针对天文学的基准测试）的顶级成绩。此外，我们的模型（Orbit-LLaMA）在GPT-4o评估中优于\\textsc{LLaMA-3-8B-base}模型，在1000个具体针对天文学的问题中有73%的情况下被偏好。我们还通过将其应用于法律和医学领域，验证了ORBIT方法的泛化能力，相较于未过滤的数据基线，我们实现了显著的数据质量提升。我们开源了ORBIT方法，包括精心收集的数据集、代码库和生成模型，网址为\\href{this https URL}{this https URL}。', 'title_zh': 'ORBIT：用于大型语言模型领域适应的成本效益数据集管理——以天文学案例研究为例'}
{'arxiv_id': 'arXiv:2412.14435', 'title': 'Cherry-Picking in Time Series Forecasting: How to Select Datasets to Make Your Model Shine', 'authors': 'Luis Roque, Carlos Soares, Vitor Cerqueira, Luis Torgo', 'link': 'https://arxiv.org/abs/2412.14435', 'abstract': 'The importance of time series forecasting drives continuous research and the development of new approaches to tackle this problem. Typically, these methods are introduced through empirical studies that frequently claim superior accuracy for the proposed approaches. Nevertheless, concerns are rising about the reliability and generalizability of these results due to limitations in experimental setups. This paper addresses a critical limitation: the number and representativeness of the datasets used. We investigate the impact of dataset selection bias, particularly the practice of cherry-picking datasets, on the performance evaluation of forecasting methods. Through empirical analysis with a diverse set of benchmark datasets, our findings reveal that cherry-picking datasets can significantly distort the perceived performance of methods, often exaggerating their effectiveness. Furthermore, our results demonstrate that by selectively choosing just four datasets - what most studies report - 46% of methods could be deemed best in class, and 77% could rank within the top three. Additionally, recent deep learning-based approaches show high sensitivity to dataset selection, whereas classical methods exhibit greater robustness. Finally, our results indicate that, when empirically validating forecasting algorithms on a subset of the benchmarks, increasing the number of datasets tested from 3 to 6 reduces the risk of incorrectly identifying an algorithm as the best one by approximately 40%. Our study highlights the critical need for comprehensive evaluation frameworks that more accurately reflect real-world scenarios. Adopting such frameworks will ensure the development of robust and reliable forecasting methods.', 'abstract_zh': '时间序列预测的重要性推动了持续的研究，并发展出了新的方法来应对这一挑战。通常，这些方法通过实证研究引入，并经常声称所提出的方法具有更高的准确性。然而，由于实验设置的局限性，人们对这些结果的可靠性和通用性产生了担忧。本文着重解决了一个关键限制：用于评估的方法所使用的数据集的数量和代表性。我们调查了数据集选择偏差，特别是数据集挑选偏好的实践，对预测方法性能评估的影响。通过使用多样化基准数据集的实证分析，我们的研究发现，数据集的选择偏好可能会显著扭曲方法的感知性能，经常夸大其效果。此外，我们的结果表明，通过仅选择四个数据集（研究中最常报告的数量），46%的方法可以被认为是最佳方法，77%的方法可以排名前三。另外，最近基于深度学习的方法对数据集的选择高度敏感，而经典的预测方法则表现出更大的鲁棒性。最后，我们的结果表明，在使用基准数据集的子集实证验证预测算法时，从测试3个数据集增加到6个数据集，可以将错误识别出最佳算法的风险降低约40%。我们的研究强调了制定更全面评估框架的迫切需要，以便更准确地反映现实世界的情景。采用这样的评估框架将确保开发出稳健和可靠的预测方法。', 'title_zh': '时间序列预测中的挑战组合：如何选择数据集使模型脱颖而出'}
{'arxiv_id': 'arXiv:2412.14426', 'title': 'All-in-One Tuning and Structural Pruning for Domain-Specific LLMs', 'authors': 'Lei Lu, Zhepeng Wang, Ruexue Bao, Mengbing Wang, Fangyi Li, Yawen Wu, Weiwen Jiang, Jie Xu, Yanzhi Wang, Shangqian Gao', 'link': 'https://arxiv.org/abs/2412.14426', 'abstract': 'Existing pruning techniques for large language models (LLMs) targeting domain-specific applications typically follow a two-stage process: pruning the pretrained general-purpose LLMs and then fine-tuning the pruned LLMs on specific domains. However, the pruning decisions, derived from the pretrained weights, remain unchanged during fine-tuning, even if the weights have been updated. Therefore, such a combination of the pruning decisions and the finetuned weights may be suboptimal, leading to non-negligible performance degradation. To address these limitations, we propose ATP: All-in-One Tuning and Structural Pruning, a unified one-stage structural pruning and fine-tuning approach that dynamically identifies the current optimal substructure throughout the fine-tuning phase via a trainable pruning decision generator. Moreover, given the limited available data for domain-specific applications, Low-Rank Adaptation (LoRA) becomes a common technique to fine-tune the LLMs. In ATP, we introduce LoRA-aware forward and sparsity regularization to ensure that the substructures corresponding to the learned pruning decisions can be directly removed after the ATP process. ATP outperforms the state-of-the-art two-stage pruning methods on tasks in the legal and healthcare domains. More specifically, ATP recovers up to 88% and 91% performance of the dense model when pruning 40% parameters of LLaMA2-7B and LLaMA3-8B models, respectively.', 'abstract_zh': '面向领域特定应用的大型语言模型（LLMs）现有的剪枝技术通常遵循两个阶段的过程：首先对预训练的通用LLMs进行剪枝，然后在特定领域对其进行微调。然而，在微调过程中，从预训练权重得出的剪枝决策保持不变，即使权重已被更新。因此，这种剪枝决策与微调权重的结合可能不是最优的，导致性能显著下降。为了解决这些局限性，我们提出了一种统一的一站式结构剪枝和微调方法——All-in-One Tuning and Structural Pruning（ATP）。ATP通过可训练的剪枝决策生成器动态识别微调过程中的最优子结构。此外，由于领域特定应用可用数据有限，低秩适应（LoRA）成为了一种常用方法来微调LLMs。在ATP中，我们引入了LoRA感知的前向传播和稀疏正则化，以确保在ATP处理后，根据学习到的剪枝决策得到的子结构可以被直接移除。实验结果显示，ATP在法律和医疗领域的任务上优于最先进的两阶段剪枝方法。具体而言，当分别对LLaMA2-7B和LLaMA3-8B模型剪枝40%的参数时，ATP分别恢复了88%和91%的密集模型性能。', 'title_zh': '面向特定领域的大型语言模型的一站式调优与结构剪枝'}
{'arxiv_id': 'arXiv:2412.14424', 'title': 'FedPIA -- Permuting and Integrating Adapters leveraging Wasserstein Barycenters for Finetuning Foundation Models in Multi-Modal Federated Learning', 'authors': 'Pramit Saha, Divyanshu Mishra, Felix Wagner, Konstantinos Kamnitsas, J. Alison Noble', 'link': 'https://arxiv.org/abs/2412.14424', 'abstract': 'Large Vision-Language Models typically require large text and image datasets for effective fine-tuning. However, collecting data from various sites, especially in healthcare, is challenging due to strict privacy regulations. An alternative is to fine-tune these models on end-user devices, such as in medical clinics, without sending data to a server. These local clients typically have limited computing power and small datasets, which are not enough for fully fine-tuning large VLMs on their own. A naive solution to these scenarios is to leverage parameter-efficient fine-tuning (PEFT) strategies and apply federated learning (FL) algorithms to combine the learned adapter weights, thereby respecting the resource limitations and data privacy. However, this approach does not fully leverage the knowledge from multiple adapters trained on diverse data distributions and for diverse tasks. The adapters are adversely impacted by data heterogeneity and task heterogeneity across clients resulting in suboptimal convergence. To this end, we propose a novel framework called FedPIA that improves upon the naive combinations of FL and PEFT by introducing Permutation and Integration of the local Adapters in the server and global Adapters in the clients exploiting Wasserstein barycenters for improved blending of client-specific and client-agnostic knowledge. This layerwise permutation helps to bridge the gap in the parameter space of local and global adapters before integration. We conduct over 2000 client-level experiments utilizing 48 medical image datasets across five different medical vision-language FL task settings encompassing visual question answering as well as image and report-based multi-label disease detection. Our experiments involving diverse client settings, ten different modalities, and two VLM backbones demonstrate that FedPIA consistently outperforms the state-of-the-art PEFT-FL baselines.', 'abstract_zh': '大型视觉-语言模型通常需要大型文本和图像数据集才能实现有效的微调。然而，在医疗保健等领域收集数据颇具挑战性，因为受到严格的数据隐私法规限制。一种替代方案是在终端用户设备上对这些模型进行微调，例如在医疗诊所中，而不将数据发送到服务器。这些本地客户端通常计算能力有限且数据集较小，不足以独立完成大型视觉-语言模型的全面微调。一种朴素的解决方案是利用参数高效微调（Parameter-Efficient Fine-Tuning, PEFT）策略，并应用联邦学习（Federated Learning, FL）算法结合本地适配器权重，从而尊重计算资源限制和数据隐私。然而，这种做法并不能充分利用在多种数据分布和不同任务上训练的多个适配器的知识。不同终端用户的异质数据和任务导致适配器性能受损，从而导致次优收敛。对此，我们提出了一种名为FedPIA的新框架，通过引入服务器侧的排列和集成本地适配器与客户端侧的全局适配器，并利用Wasserstein巴泽纳齐中心（Wasserstein barycenters）进行改进的客户特定与客户无关知识融合，改进了FL与PEFT的简单组合。逐层排列有助于在集成之前缩小本地和全局适配器的参数空间差距。我们通过在不同医疗视觉-语言FL任务设置（包括视觉问答以及基于图像和报告的多标签疾病检测）中采用48个医学图像数据集进行超过2000次客户端级别的实验进行了验证。涉及多样化客户端设置、十种不同模态以及两种视觉-语言模型骨干的实验表明，FedPIA在所有实验中均优于最先进的PEFT-FL基线。', 'title_zh': 'FedPIA —— 利用沃舍廷贝卢中枢（Wasserstein Barycenters）排列和集成适配器的多模态联邦学习基础模型微调方法'}
{'arxiv_id': 'arXiv:2412.14422', 'title': 'Enhancing Diffusion Models for High-Quality Image Generation', 'authors': 'Jaineet Shah, Michael Gromis, Rickston Pinto', 'link': 'https://arxiv.org/abs/2412.14422', 'abstract': 'This report presents the comprehensive implementation, evaluation, and optimization of Denoising Diffusion Probabilistic Models (DDPMs) and Denoising Diffusion Implicit Models (DDIMs), which are state-of-the-art generative models. During inference, these models take random noise as input and iteratively generate high-quality images as output. The study focuses on enhancing their generative capabilities by incorporating advanced techniques such as Classifier-Free Guidance (CFG), Latent Diffusion Models with Variational Autoencoders (VAE), and alternative noise scheduling strategies. The motivation behind this work is the growing demand for efficient and scalable generative AI models that can produce realistic images across diverse datasets, addressing challenges in applications such as art creation, image synthesis, and data augmentation. Evaluations were conducted on datasets including CIFAR-10 and ImageNet-100, with a focus on improving inference speed, computational efficiency, and image quality metrics like Frechet Inception Distance (FID). Results demonstrate that DDIM + CFG achieves faster inference and superior image quality. Challenges with VAE and noise scheduling are also highlighted, suggesting opportunities for future optimization. This work lays the groundwork for developing scalable, efficient, and high-quality generative AI systems to benefit industries ranging from entertainment to robotics.', 'abstract_zh': '本报告全面介绍了去噪扩散概率模型（DDPMs）和去噪扩散隐式模型（DDIMs）的实现、评估与优化。DDPMs和DDIMs是当前最先进的生成模型。在推理过程中，这些模型将随机噪声作为输入，并逐步生成高质量的图像作为输出。本研究旨在通过引入先进的技术，如无分类指导（Classifier-Free Guidance，CFG）、潜变量扩散模型与变分自编码器（Latent Diffusion Models with Variational Autoencoders，VAE），以及不同的噪声调度策略来增强它们的生成能力。这一工作的驱动力是针对跨多种数据集生产逼真图像的高效和可扩展生成AI模型的需求，解决了诸如艺术创作、图像合成和数据增强等应用中的挑战。评估在CIFAR-10和ImageNet-100等数据集上进行，重点关注提高推理速度、计算效率和图像质量指标（如弗雷切尔- incidental 距离，FID）的表现。研究结果表明，DDIM结合CFG可以实现更快的推理速度和更高质量的图像。同时，研究还指出了VAE和噪声调度的挑战，为未来的优化提供了机遇。本研究为开发可扩展、高效且高质量的生成AI系统奠定了基础，这些系统将惠及从娱乐到机器人等多个行业。', 'title_zh': '增强扩散模型以生成高质量图像'}
{'arxiv_id': 'arXiv:2412.14415', 'title': 'DriveGPT: Scaling Autoregressive Behavior Models for Driving', 'authors': 'Xin Huang, Eric M. Wolff, Paul Vernaza, Tung Phan-Minh, Hongge Chen, David S. Hayden, Mark Edmonds, Brian Pierce, Xinxin Chen, Pratik Elias Jacob, Xiaobai Chen, Chingiz Tairbekov, Pratik Agarwal, Tianshi Gao, Yuning Chai, Siddhartha Srinivasa', 'link': 'https://arxiv.org/abs/2412.14415', 'abstract': 'We present DriveGPT, a scalable behavior model for autonomous driving. We model driving as a sequential decision making task, and learn a transformer model to predict future agent states as tokens in an autoregressive fashion. We scale up our model parameters and training data by multiple orders of magnitude, enabling us to explore the scaling properties in terms of dataset size, model parameters, and compute. We evaluate DriveGPT across different scales in a planning task, through both quantitative metrics and qualitative examples including closed-loop driving in complex real-world scenarios. In a separate prediction task, DriveGPT outperforms a state-of-the-art baseline and exhibits improved performance by pretraining on a large-scale dataset, further validating the benefits of data scaling.', 'abstract_zh': '我们将介绍DriveGPT，这是一种可扩展的自动驾驶行为模型。我们将驾驶视为一个序列决策任务，并利用变换器模型以自回归的方式预测未来代理状态。通过大幅提升模型参数和训练数据的数量级，我们能够从数据集规模、模型参数和计算资源方面探索模型的可扩展性。我们通过规划任务中的定量指标和定性案例，包括在复杂真实世界场景中的闭环驾驶，评估了DriveGPT在不同规模下的性能。在一项单独的预测任务中，DriveGPT超越了最先进的基线模型，并通过在大规模数据集上进行预训练展示了性能的提升，进一步验证了数据规模对于模型性能的益处。', 'title_zh': 'DriveGPT：扩展自回归行为模型在自动驾驶中的应用'}
{'arxiv_id': 'arXiv:2412.14384', 'title': 'I0T: Embedding Standardization Method Towards Zero Modality Gap', 'authors': 'Na Min An, Eunki Kim, James Thorne, Hyunjung Shim', 'link': 'https://arxiv.org/abs/2412.14384', 'abstract': 'Contrastive Language-Image Pretraining (CLIP) enables zero-shot inference in downstream tasks such as image-text retrieval and classification. However, recent works extending CLIP suffer from the issue of modality gap, which arises when the image and text embeddings are projected to disparate manifolds, deviating from the intended objective of image-text contrastive learning. We discover that this phenomenon is linked to the modality-specific characteristic that each image/text encoder independently possesses and propose two methods to address the modality gap: (1) a post-hoc embedding standardization method, $\\text{I0T}_{\\text{post}}$ that reduces the modality gap approximately to zero and (2) a trainable method, $\\text{I0T}_{\\text{async}}$, to alleviate the modality gap problem by adding two normalization layers for each encoder. Our I0T framework can significantly reduce the modality gap while preserving the original embedding representations of trained models with their locked parameters. In practice, $\\text{I0T}_{\\text{post}}$ can serve as an alternative explainable automatic evaluation metric of widely used CLIPScore (CLIP-S).', 'abstract_zh': 'Contrastive 语言-图像预训练（CLIP）使零样本推理成为诸如图像-文本检索和分类等下游任务的可能。然而，扩展CLIP的近期工作遇到了模态差距的问题，当图像和文本嵌入被投影到不同的流形上时，这种情况会偏离图像-文本对比学习的初衷。我们发现这种现象与各自独立的图像/文本编码器所具有的模态特异性特征有关，并提出两种方法来解决模态差距问题：（1）一种事后嵌入标准化方法$\\text{I0T}_{\\text{post}}$，它可以将模态差距大约减少到零；（2）一种可训练方法$\\text{I0T}_{\\text{async}}$，通过为每个编码器增加两个规范化层来缓解模态差距问题。我们的I0T框架可以在保持训练模型原嵌入表示和锁定参数不变的情况下显著减少模态差距。在实践中，$\\text{I0T}_{\\text{post}}$可以作为广泛使用的CLIPScore（CLIP-S）的替代可解释自动评估指标。', 'title_zh': 'IoT: 面向零模态差距的标准化嵌入方法'}
{'arxiv_id': 'arXiv:2412.14366', 'title': 'Surrealistic-like Image Generation with Vision-Language Models', 'authors': 'Elif Ayten, Shuai Wang, Hjalmar Snoep', 'link': 'https://arxiv.org/abs/2412.14366', 'abstract': 'Recent advances in generative AI make it convenient to create different types of content, including text, images, and code. In this paper, we explore the generation of images in the style of paintings in the surrealism movement using vision-language generative models, including DALL-E, Deep Dream Generator, and DreamStudio. Our investigation starts with the generation of images under various image generation settings and different models. The primary objective is to identify the most suitable model and settings for producing such images. Additionally, we aim to understand the impact of using edited base images on the generated resulting images. Through these experiments, we evaluate the performance of selected models and gain valuable insights into their capabilities in generating such images. Our analysis shows that Dall-E 2 performs the best when using the generated prompt by ChatGPT.', 'abstract_zh': 'Recent进展在生成型人工智能使创建不同类型的内容变得便捷，包括文本、图像和代码。本文中，我们探讨了使用视觉-语言生成模型（如DALL-E、Deep Dream Generator和DreamStudio）生成超现实主义绘画风格图像的可能性。我们的研究始于在不同图像生成设置和不同模型下的图像生成。主要目标是识别生成此类图像的最佳模型和设置。此外，我们还旨在了解使用编辑后的基础图像对生成图像的影响。通过这些实验，我们评估了所选模型的性能，并获得了它们在生成此类图像方面的宝贵见解。我们的分析表明，当使用ChatGPT生成的提示时，Dall-E 2表现出最佳性能。', 'title_zh': '使用视觉-语言模型生成类似超现实主义的图像'}
{'arxiv_id': 'arXiv:2412.14355', 'title': 'Enabling Realtime Reinforcement Learning at Scale with Staggered Asynchronous Inference', 'authors': 'Matthew Riemer, Gopeshh Subbaraj, Glen Berseth, Irina Rish', 'link': 'https://arxiv.org/abs/2412.14355', 'abstract': "Realtime environments change even as agents perform action inference and learning, thus requiring high interaction frequencies to effectively minimize regret. However, recent advances in machine learning involve larger neural networks with longer inference times, raising questions about their applicability in realtime systems where reaction time is crucial. We present an analysis of lower bounds on regret in realtime reinforcement learning (RL) environments to show that minimizing long-term regret is generally impossible within the typical sequential interaction and learning paradigm, but often becomes possible when sufficient asynchronous compute is available. We propose novel algorithms for staggering asynchronous inference processes to ensure that actions are taken at consistent time intervals, and demonstrate that use of models with high action inference times is only constrained by the environment's effective stochasticity over the inference horizon, and not by action frequency. Our analysis shows that the number of inference processes needed scales linearly with increasing inference times while enabling use of models that are multiple orders of magnitude larger than existing approaches when learning from a realtime simulation of Game Boy games such as Pokémon and Tetris.", 'abstract_zh': '实时环境在智能体进行动作推理和学习的过程中不断变化，因此需要高频率的交互来有效地最小化遗憾。然而，近期的机器学习进展涉及更大的神经网络和更长的推理时间，这在需要快速反应的实时系统中引发了其适用性的问题。我们对实时强化学习（RL）环境中的后悔下界进行分析，表明在典型的顺序交互和学习范式中一般不可能完全最小化长期后悔，但在计算过程足够异步时，这种情况往往变得可能。我们提出了新颖的算法，用于调度异步推理过程，以确保动作在固定的时间间隔内被采取。我们的研究表明，当从实时模拟游戏男孩游戏（如宠物小精灵和俄罗斯方块）的过程中学习时，所需的推理过程数量随推理时间的增长线性增加，同时能够使用比现有方法大多个数量级的模型，并且这种模型的动作推理时间仅受限于推理窗口内的环境有效随机性，而非动作频率。', 'title_zh': '面向大规模实时强化学习的交错异步推理方法'}
{'arxiv_id': 'arXiv:2412.14351', 'title': 'Is Peer-Reviewing Worth the Effort?', 'authors': 'Kenneth Church, Raman Chandrasekar, John E. Ortega, Ibrahim Said Ahmad', 'link': 'https://arxiv.org/abs/2412.14351', 'abstract': 'How effective is peer-reviewing in identifying important papers? We treat this question as a forecasting task. Can we predict which papers will be highly cited in the future based on venue and "early returns" (citations soon after publication)? We show early returns are more predictive than venue. Finally, we end with constructive suggestions to address scaling challenges: (a) too many submissions and (b) too few qualified reviewers.', 'abstract_zh': '同行评审在识别重要论文方面有多有效？我们将这个问题视为一个预测任务。我们能否根据会议和“早期反馈”（即论文出版后不久的引用情况）来预测哪些论文在未来会被高度引用？结果显示，早期反馈比会议更能预测。最后，我们提出了几项建设性的建议来应对扩展挑战：（a）提交论文过多；（b）合格的评审人不足。', 'title_zh': '《Peer Review值得付出努力吗？》\n\n这个标题是对学术论文中同行评审过程的反思，将其翻译为《Peer Review值得付出努力吗？》既保留了原文的疑问性质，又符合中文的表达习惯。'}
{'arxiv_id': 'arXiv:2412.14340', 'title': 'A Unifying Information-theoretic Perspective on Evaluating Generative Models', 'authors': 'Alexis Fox, Samarth Swarup, Abhijin Adiga', 'link': 'https://arxiv.org/abs/2412.14340', 'abstract': 'Considering the difficulty of interpreting generative model output, there is significant current research focused on determining meaningful evaluation metrics. Several recent approaches utilize "precision" and "recall," borrowed from the classification domain, to individually quantify the output fidelity (realism) and output diversity (representation of the real data variation), respectively. With the increase in metric proposals, there is a need for a unifying perspective, allowing for easier comparison and clearer explanation of their benefits and drawbacks. To this end, we unify a class of kth-nearest-neighbors (kNN)-based metrics under an information-theoretic lens using approaches from kNN density estimation. Additionally, we propose a tri-dimensional metric composed of Precision Cross-Entropy (PCE), Recall Cross-Entropy (RCE), and Recall Entropy (RE), which separately measure fidelity and two distinct aspects of diversity, inter- and intra-class. Our domain-agnostic metric, derived from the information-theoretic concepts of entropy and cross-entropy, can be dissected for both sample- and mode-level analysis. Our detailed experimental results demonstrate the sensitivity of our metric components to their respective qualities and reveal undesirable behaviors of other metrics.', 'abstract_zh': '考虑到生成模型输出解释的难度，当前研究主要集中于确定有意义的评价指标。一些最近的方法借鉴了分类领域的“精确率”和“召回率”来单独量化输出的真实性和输出的多样性，分别对应生成数据与真实数据的一致性和变化范围。随着评价指标的不断增加，需要一个统一的视角，以便更容易地进行比较并清楚地解释其优点和缺点。为此，我们使用来自k最近邻密度估计的方法，将一类基于k最近邻（kNN）的评价指标统一到信息论视角下。此外，我们提出了一种三维评价指标，由精确率交叉熵（PCE）、召回率交叉熵（RCE）和召回率熵（RE）组成，分别测量真实性及类间和类内的两种不同多样性方面。我们的领域通用评价指标，基于信息论中的熵和交叉熵概念，可以从样本级和模式级进行分析。我们详尽的实验结果展示了评价指标各组成部分对其相应特性的敏感性，并揭示了其他评价指标的一些不可取行为。', 'title_zh': '一个统一的信息论视角下的生成模型评估方法'}
{'arxiv_id': 'arXiv:2412.14329', 'title': 'Embedding Cultural Diversity in Prototype-based Recommender Systems', 'authors': 'Armin Moradi, Nicola Neophytou, Florian Carichon, Golnoosh Farnadi', 'link': 'https://arxiv.org/abs/2412.14329', 'abstract': 'Popularity bias in recommender systems can increase cultural overrepresentation by favoring norms from dominant cultures and marginalizing underrepresented groups. This issue is critical for platforms offering cultural products, as they influence consumption patterns and human perceptions. In this work, we address popularity bias by identifying demographic biases within prototype-based matrix factorization methods. Using the country of origin as a proxy for cultural identity, we link this demographic attribute to popularity bias by refining the embedding space learning process. First, we propose filtering out irrelevant prototypes to improve representativity. Second, we introduce a regularization technique to enforce a uniform distribution of prototypes within the embedding space. Across four datasets, our results demonstrate a 27\\% reduction in the average rank of long-tail items and a 2\\% reduction in the average rank of items from underrepresented countries. Additionally, our model achieves a 2\\% improvement in HitRatio@10 compared to the state-of-the-art, highlighting that fairness is enhanced without compromising recommendation quality. Moreover, the distribution of prototypes leads to more inclusive explanations by better aligning items with diverse prototypes.', 'abstract_zh': '推荐系统中的流行度偏差可能会增加文化代表性，因为它倾向于推崇主导文化 norms，同时边缘化代表性不足的群体。这对提供文化产品的平台来说是一个关键问题，因为这些平台会影响消费模式和人类感知。在这项工作中，我们通过识别基于原型的矩阵分解方法中的人口统计学偏差来解决流行度偏差问题。使用国家作为文化身份的代理指标，我们通过改进嵌入空间的学习过程将这一人口统计学属性与流行度偏差联系起来。首先，我们建议过滤掉无关的原型以提高代表性。其次，我们引入了一种正则化技术，以确保嵌入空间中原型的均匀分布。在四个数据集中，我们的结果表明，平均尾部项目的排名降低了27%，来自代表性不足国家的项目的平均排名降低了2%。此外，与当前最先进的方法相比，我们的模型在@10的HitRatio上提高了2%，这表明在不牺牲推荐质量的情况下，公平性得到了提升。此外，原型的分布导致了更具包容性的解释，因为它更好地将项目与多样化的原型对齐。', 'title_zh': '将文化多样性嵌入原型推荐系统中'}
{'arxiv_id': 'arXiv:2412.14328', 'title': 'Semantic Role Labeling of NomBank Partitives', 'authors': 'Adam Meyers, Advait Pravin Savant, John E. Ortega', 'link': 'https://arxiv.org/abs/2412.14328', 'abstract': 'This article is about Semantic Role Labeling for English partitive nouns (5%/REL of the price/ARG1; The price/ARG1 rose 5 percent/REL) in the NomBank annotated corpus. Several systems are described using traditional and transformer-based machine learning, as well as ensembling. Our highest scoring system achieves an F1 of 91.74% using "gold" parses from the Penn Treebank and 91.12% when using the Berkeley Neural parser. This research includes both classroom and experimental settings for system development.', 'abstract_zh': '本文探讨了英语言义角色标注中的限定名词（例如：5%/REL of the price/ARG1；The price/ARG1 rose 5 percent/REL）在NomBank标注语料库中的应用。文中描述了使用传统机器学习和基于变换器的方法构建了多个系统，并采用了集成方法。我们得分最高的系统在使用宾州树库中的“黄金”解析结果时获得了91.74%的F1分数，而在使用伯克利神经解析器时则获得了91.12%的F1分数。本研究包括课堂和实验环境下的系统开发环境。', 'title_zh': 'NomBank 部分谓词的语义角色标注'}
{'arxiv_id': 'arXiv:2412.14323', 'title': 'The Role of Handling Attributive Nouns in Improving Chinese-To-English Machine Translation', 'authors': 'Haohao, Wang, Adam Meyers, John E. Ortega, Rodolfo Zevallos', 'link': 'https://arxiv.org/abs/2412.14323', 'abstract': "Translating between languages with drastically different grammatical conventions poses challenges, not just for human interpreters but also for machine translation systems. In this work, we specifically target the translation challenges posed by attributive nouns in Chinese, which frequently cause ambiguities in English translation. By manually inserting the omitted particle X ('DE'). In news article titles from the Penn Chinese Discourse Treebank, we developed a targeted dataset to fine-tune Hugging Face Chinese to English translation models, specifically improving how this critical function word is handled. This focused approach not only complements the broader strategies suggested by previous studies but also offers a practical enhancement by specifically addressing a common error type in Chinese-English translation.", 'abstract_zh': '将结构差异巨大的语言之间进行翻译，不仅给人类译者带来了挑战，也给机器翻译系统带来了挑战。本研究特别针对中文中的限定名词带来的翻译难题，这些名词在英文翻译中经常造成歧义。通过手工插入被省略的“的”字（X），我们利用宾夕法尼亚中文语料库中的新闻标题数据集，专门对Hugging Face的中英翻译模型进行了微调，特别是在处理这一关键功能词方面取得了改进。这种专注的方法不仅补充了先前研究提出的更广泛策略，还通过具体解决中文-英语翻译中的常见错误类型提供了实际的提升。', 'title_zh': '《属性名词的处理在提升中文到英文机器翻译中的作用》'}
{'arxiv_id': 'arXiv:2412.14304', 'title': 'Multi-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing LLM Ophthalmological QA in LMICs', 'authors': 'David Restrepo, Chenwei Wu, Zhengxu Tang, Zitao Shuai, Thao Nguyen Minh Phan, Jun-En Ding, Cong-Tinh Dao, Jack Gallifant, Robyn Gayle Dychiao, Jose Carlo Artiaga, André Hiroshi Bando, Carolina Pelegrini Barbosa Gracitelli, Vincenz Ferrer, Leo Anthony Celi, Danielle Bitterman, Michael G Morley, Luis Filipe Nakayama', 'link': 'https://arxiv.org/abs/2412.14304', 'abstract': 'Current ophthalmology clinical workflows are plagued by over-referrals, long waits, and complex and heterogeneous medical records. Large language models (LLMs) present a promising solution to automate various procedures such as triaging, preliminary tests like visual acuity assessment, and report summaries. However, LLMs have demonstrated significantly varied performance across different languages in natural language question-answering tasks, potentially exacerbating healthcare disparities in Low and Middle-Income Countries (LMICs). This study introduces the first multilingual ophthalmological question-answering benchmark with manually curated questions parallel across languages, allowing for direct cross-lingual comparisons. Our evaluation of 6 popular LLMs across 7 different languages reveals substantial bias across different languages, highlighting risks for clinical deployment of LLMs in LMICs. Existing debiasing methods such as Translation Chain-of-Thought or Retrieval-augmented generation (RAG) by themselves fall short of closing this performance gap, often failing to improve performance across all languages and lacking specificity for the medical domain. To address this issue, We propose CLARA (Cross-Lingual Reflective Agentic system), a novel inference time de-biasing method leveraging retrieval augmented generation and self-verification. Our approach not only improves performance across all languages but also significantly reduces the multilingual bias gap, facilitating equitable LLM application across the globe.', 'abstract_zh': '当前的眼科临床工作流程受到过度转诊、漫长等待时间和复杂异质性医疗记录的困扰。大规模语言模型（LLMs）有望自动化各种程序，如分诊、初步测试（如视力评估）和报告总结。然而，LLMs在自然语言问答任务中的性能在不同语言之间表现出显著差异，这可能加剧低收入和中等收入国家（LMICs）的医疗健康不平等。本研究引入了首个基于人工策源的多语言眼科问答基准，允许直接跨语言比较。我们对7种不同语言下的6种流行LLMs进行了评估，发现不同语言之间存在显著偏差，突显了在LMICs中临床部署LLMs时的风险。现有去偏方法，如翻译推理链或检索增强生成（RAG），单独使用时未能弥合这一性能差距，往往无法在所有语言中提高性能，缺乏针对医学领域的适应性。为此，我们提出了一种新颖的推理时间去偏方法——CLARA（跨语言反思性代理系统），该方法结合了检索增强生成和自我验证。我们的方法不仅提高了所有语言的性能，还显著减小了多语言偏差差距，从而促进全球范围内的LLM公平应用。', 'title_zh': 'Multilingual OphthaLingua：评估和去偏见LM在LMICs中眼科QA的多语言基准荏'}
{'arxiv_id': 'arXiv:2412.14302', 'title': 'SAFERec: Self-Attention and Frequency Enriched Model for Next Basket Recommendation', 'authors': 'Oleg Lashinin, Denis Krasilnikov, Aleksandr Milogradskii, Marina Ananyeva', 'link': 'https://arxiv.org/abs/2412.14302', 'abstract': 'Transformer-based approaches such as BERT4Rec and SASRec demonstrate strong performance in Next Item Recommendation (NIR) tasks. However, applying these architectures to Next-Basket Recommendation (NBR) tasks, which often involve highly repetitive interactions, is challenging due to the vast number of possible item combinations in a basket. Moreover, frequency-based methods such as TIFU-KNN and UP-CF still demonstrate strong performance in NBR tasks, frequently outperforming deep-learning approaches. This paper introduces SAFERec, a novel algorithm for NBR that enhances transformer-based architectures from NIR by incorporating item frequency information, consequently improving their applicability to NBR tasks. Extensive experiments on multiple datasets show that SAFERec outperforms all other baselines, specifically achieving an 8\\% improvement in Recall@10.', 'abstract_zh': '基于Transformer的方法，如BERT4Rec和SASRec，在下一个项目推荐（Next Item Recommendation, NIR）任务中表现出强大的性能。然而，将这些架构应用到下一个篮子推荐（Next-Basket Recommendation, NBR）任务中存在挑战，因为篮子中可能包含大量的项目组合，导致高度重复的交互。此外，基于频率的方法，如TIFU-KNN和UP-CF，在NBR任务中仍然表现出强大的性能，经常优于深度学习方法。本文提出了一种新颖的算法SAFERec，该算法通过整合项目频率信息来增强NIR任务中的Transformer架构，从而提高其在NBR任务中的适用性。在多个数据集上的广泛实验表明，SAFERec在所有基准模型中表现出最佳性能，尤其是在Recall@10上提高了8%。', 'title_zh': 'SAFERec：结合自注意力机制和频率增强的下一个购物篮推荐模型'}
{'arxiv_id': 'arXiv:2412.14295', 'title': 'Temporally Consistent Object-Centric Learning by Contrasting Slots', 'authors': 'Anna Manasyan, Maximilian Seitzer, Filip Radovic, Georg Martius, Andrii Zadaianchuk', 'link': 'https://arxiv.org/abs/2412.14295', 'abstract': 'Unsupervised object-centric learning from videos is a promising approach to extract structured representations from large, unlabeled collections of videos. To support downstream tasks like autonomous control, these representations must be both compositional and temporally consistent. Existing approaches based on recurrent processing often lack long-term stability across frames because their training objective does not enforce temporal consistency. In this work, we introduce a novel object-level temporal contrastive loss for video object-centric models that explicitly promotes temporal consistency. Our method significantly improves the temporal consistency of the learned object-centric representations, yielding more reliable video decompositions that facilitate challenging downstream tasks such as unsupervised object dynamics prediction. Furthermore, the inductive bias added by our loss strongly improves object discovery, leading to state-of-the-art results on both synthetic and real-world datasets, outperforming even weakly-supervised methods that leverage motion masks as additional cues.', 'abstract_zh': '无监督的对象中心学习是从大量未标记的视频集合中提取结构化表示的一种有前途的方法。为了支持诸如自主控制等下游任务，这些表示必须既是组合性的，又是时间一致性的。现有的基于循环处理的方法通常无法跨帧保持长期稳定性，因为它们的训练目标没有强制要求时间一致性。在本文中，我们引入了一种新颖的对象级别时间对比损失，用于视频对象中心模型，该损失明确地促进了时间一致性。我们的方法显著提高了所学习的对象中心表示的时间一致性，从而得到了更可靠的视频分解，这些分解便于诸如无监督对象动力学预测等更具挑战性的下游任务。此外，通过我们的损失增加的归纳偏置极大地提高了对象的发现能力，从而在合成和真实世界数据集上都取得了最先进的结果，甚至超越了利用运动掩码作为附加提示的弱监督方法。', 'title_zh': '时间一致的以对象为中心的学习：通过对比槽位实现'}
{'arxiv_id': 'arXiv:2412.14283', 'title': 'PixelMan: Consistent Object Editing with Diffusion Models via Pixel Manipulation and Generation', 'authors': 'Liyao Jiang, Negar Hassanpour, Mohammad Salameh, Mohammadreza Samadi, Jiao He, Fengyu Sun, Di Niu', 'link': 'https://arxiv.org/abs/2412.14283', 'abstract': 'Recent research explores the potential of Diffusion Models (DMs) for consistent object editing, which aims to modify object position, size, and composition, etc., while preserving the consistency of objects and background without changing their texture and attributes. Current inference-time methods often rely on DDIM inversion, which inherently compromises efficiency and the achievable consistency of edited images. Recent methods also utilize energy guidance which iteratively updates the predicted noise and can drive the latents away from the original image, resulting in distortions. In this paper, we propose PixelMan, an inversion-free and training-free method for achieving consistent object editing via Pixel Manipulation and generation, where we directly create a duplicate copy of the source object at target location in the pixel space, and introduce an efficient sampling approach to iteratively harmonize the manipulated object into the target location and inpaint its original location, while ensuring image consistency by anchoring the edited image to be generated to the pixel-manipulated image as well as by introducing various consistency-preserving optimization techniques during inference. Experimental evaluations based on benchmark datasets as well as extensive visual comparisons show that in as few as 16 inference steps, PixelMan outperforms a range of state-of-the-art training-based and training-free methods (usually requiring 50 steps) on multiple consistent object editing tasks.', 'abstract_zh': '近期的研究旨在探讨扩散模型（DMs）在一致性物体编辑中的潜力，该编辑旨在修改物体的位置、大小和组成等，同时保持物体及其背景的一致性，而不改变其纹理和属性。当前的推断时方法通常依赖于DDIM逆过程，这会不可避免地损害效率和编辑图像的一致性。最近的方法还利用能量引导，通过迭代更新预测的噪声来进行操作，这可能导致潜在空间中远离原始图像，从而导致失真。在本论文中，我们提出了一种无逆过程且无需训练的方法——PixelMan，该方法通过像素操作和生成实现一致性物体编辑。具体来说，我们直接在像素空间中创建源物体的副本并定位到目标位置，引入了高效的采样方法，通过迭代使修改后的物体和谐地融入目标位置，并通过填补其原始位置来保持图像一致性，同时通过引入多种保持一致性的优化技术，在推断时将编辑后的图像生成锚定到像素操作后的图像上。基于基准数据集的实验评估和广泛的视觉比较显示，PixelMan 在最少 16 次推断步骤中，在多个一致性物体编辑任务上优于多种基于训练的方法和无需训练的方法（通常需要 50 步）。', 'title_zh': 'PixelMan：通过像素操作与生成的扩散模型一致的对象编辑'}
{'arxiv_id': 'arXiv:2412.14276', 'title': 'Fake News Detection: Comparative Evaluation of BERT-like Models and Large Language Models with Generative AI-Annotated Data', 'authors': 'haina Raza, Drai Paulen-Patterson, Chen Ding', 'link': 'https://arxiv.org/abs/2412.14276', 'abstract': 'Fake news poses a significant threat to public opinion and social stability in modern society. This study presents a comparative evaluation of BERT-like encoder-only models and autoregressive decoder-only large language models (LLMs) for fake news detection. We introduce a dataset of news articles labeled with GPT-4 assistance (an AI-labeling method) and verified by human experts to ensure reliability. Both BERT-like encoder-only models and LLMs were fine-tuned on this dataset. Additionally, we developed an instruction-tuned LLM approach with majority voting during inference for label generation. Our analysis reveals that BERT-like models generally outperform LLMs in classification tasks, while LLMs demonstrate superior robustness against text perturbations. Compared to weak labels (distant supervision) data, the results show that AI labels with human supervision achieve better classification results. This study highlights the effectiveness of combining AI-based annotation with human oversight and demonstrates the performance of different families of machine learning models for fake news detection', 'abstract_zh': '虚假信息对现代社会的公共意见和社会稳定构成了重大威胁。本研究比较评估了编码器唯一模型（如BERT类模型）和自回归解码器唯一大型语言模型（LLMs）在虚假信息检测中的性能。我们提供了一个由GPT-4辅助（AI标注方法）标记并由人类专家验证的数据集，以确保数据可靠性。编码器唯一模型和LLMs均在此数据集上进行了微调。此外，我们还在推断过程中开发了一种基于多数投票的指令微调LLM方法以生成标签。分析结果显示，编码器唯一模型在分类任务中总体上优于LLMs，而LLMs在文本扰动下的鲁棒性更佳。与弱标签（远程监督）数据相比，使用人类监督的AI标签在分类任务中表现更优。本研究突显了结合基于AI的注释与人类监督的有效性，并展示了不同类型机器学习模型在虚假信息检测中的性能。', 'title_zh': '假新闻检测：基于BERT类模型和生成AI标注数据的大规模语言模型的比较评估'}
{'arxiv_id': 'arXiv:2412.14272', 'title': 'Split Learning in Computer Vision for Semantic Segmentation Delay Minimization', 'authors': 'Nikos G. Evgenidis, Nikos A. Mitsiou, Sotiris A. Tegos, Panagiotis D. Diamantoulakis, George K. Karagiannidis', 'link': 'https://arxiv.org/abs/2412.14272', 'abstract': "In this paper, we propose a novel approach to minimize the inference delay in semantic segmentation using split learning (SL), tailored to the needs of real-time computer vision (CV) applications for resource-constrained devices. Semantic segmentation is essential for applications such as autonomous vehicles and smart city infrastructure, but faces significant latency challenges due to high computational and communication loads. Traditional centralized processing methods are inefficient for such scenarios, often resulting in unacceptable inference delays. SL offers a promising alternative by partitioning deep neural networks (DNNs) between edge devices and a central server, enabling localized data processing and reducing the amount of data required for transmission. Our contribution includes the joint optimization of bandwidth allocation, cut layer selection of the edge devices' DNN, and the central server's processing resource allocation. We investigate both parallel and serial data processing scenarios and propose low-complexity heuristic solutions that maintain near-optimal performance while reducing computational requirements. Numerical results show that our approach effectively reduces inference delay, demonstrating the potential of SL for improving real-time CV applications in dynamic, resource-constrained environments.", 'abstract_zh': '在本文中，我们提出了一种新的方法，利用分割学习（SL）来最小化语义分割中的推理延迟，以满足资源受限设备中实时计算机视觉（CV）应用程序的需求。语义分割对于自动驾驶车辆和智慧城市基础设施等应用至关重要，但由于计算和通信负荷高，面临着显著的延迟挑战。传统的集中式处理方法并不适用于此类场景，经常导致不可接受的推理延迟。SL通过将深度神经网络（DNNs）在边缘设备和中央服务器之间分区，实现本地化数据处理，从而减少需传输的数据量，提供了一种有希望的替代方案。我们的贡献包括联合优化带宽分配、边缘设备DNN的切分层选择以及中央服务器的处理资源分配。我们研究了并行和串行数据处理场景，并提出了一种低复杂度的启发式解决方案，该解决方案在降低计算需求的同时保持接近最优性能。数值结果表明，我们的方法有效地减少了推理延迟，展示了SL在动态资源受限环境中改进实时CV应用的潜力。', 'title_zh': '计算机视觉中基于分割学习的语义分割延迟最小化'}
{'arxiv_id': 'arXiv:2412.14234', 'title': 'Syzygy: Dual Code-Test C to (safe) Rust Translation using LLMs and Dynamic Analysis', 'authors': 'Manish Shetty, Naman Jain, Adwait Godbole, Sanjit A. Seshia, Koushik Sen', 'link': 'https://arxiv.org/abs/2412.14234', 'abstract': 'Despite extensive usage in high-performance, low-level systems programming applications, C is susceptible to vulnerabilities due to manual memory management and unsafe pointer operations. Rust, a modern systems programming language, offers a compelling alternative. Its unique ownership model and type system ensure memory safety without sacrificing performance.\nIn this paper, we present Syzygy, an automated approach to translate C to safe Rust. Our technique uses a synergistic combination of LLM-driven code and test translation guided by dynamic-analysis-generated execution information. This paired translation runs incrementally in a loop over the program in dependency order of the code elements while maintaining per-step correctness. Our approach exposes novel insights on combining the strengths of LLMs and dynamic analysis in the context of scaling and combining code generation with testing. We apply our approach to successfully translate Zopfli, a high-performance compression library with ~3000 lines of code and 98 functions. We validate the translation by testing equivalence with the source C program on a set of inputs. To our knowledge, this is the largest automated and test-validated C to safe Rust code translation achieved so far.', 'abstract_zh': '尽管C语言在高性能、低级别的系统编程应用中被广泛应用，但由于手动内存管理和不安全的指针操作，它也容易受到安全漏洞的影响。Rust是一种现代的系统编程语言，提供了极具吸引力的替代方案。其独特的所有权模型和类型系统确保了内存安全性，同时不牺牲性能。\n\n在本文中，我们提出了Syzygy，一种自动将C代码转换为安全Rust代码的方法。我们的技术结合了LLM驱动的代码和测试转换，这些转换由动态分析生成的执行信息指导。这种成对的转换以依赖关系顺序逐步循环运行在整个程序中，并在每一步中保持正确性。我们的方法揭示了在扩展和结合代码生成与测试的过程中，如何结合LLM和动态分析的独特见解。我们应用这种方法成功地将Zopfli——一个包含约3000行代码和98个函数的高性能压缩库——转换为安全Rust代码。我们通过在一组输入上验证转换后的Rust代码与源C代码的等效性来验证转换。据我们所知，这是迄今为止实现的最大规模的自动和测试验证的C到安全Rust代码转换。', 'title_zh': 'Syzygy: 利用大语言模型和动态分析将双重编码测试C代码安全地翻译为Rust代码'}
{'arxiv_id': 'arXiv:2412.14219', 'title': 'A Survey on Inference Optimization Techniques for Mixture of Experts Models', 'authors': 'Jiacheng Liu, Peng Tang, Wenfeng Wang, Yuhang Ren, Xiaofeng Hou, Pheng-Ann Heng, Minyi Guo, Chao Li', 'link': 'https://arxiv.org/abs/2412.14219', 'abstract': 'The emergence of large-scale Mixture of Experts (MoE) models has marked a significant advancement in artificial intelligence, offering enhanced model capacity and computational efficiency through conditional computation. However, the deployment and inference of these models present substantial challenges in terms of computational resources, latency, and energy efficiency. This comprehensive survey systematically analyzes the current landscape of inference optimization techniques for MoE models across the entire system stack. We first establish a taxonomical framework that categorizes optimization approaches into model-level, system-level, and hardware-level optimizations. At the model level, we examine architectural innovations including efficient expert design, attention mechanisms, various compression techniques such as pruning, quantization, and knowledge distillation, as well as algorithm improvement including dynamic routing strategies and expert merging methods. At the system level, we investigate distributed computing approaches, load balancing mechanisms, and efficient scheduling algorithms that enable scalable deployment. Furthermore, we delve into hardware-specific optimizations and co-design strategies that maximize throughput and energy efficiency. This survey not only provides a structured overview of existing solutions but also identifies key challenges and promising research directions in MoE inference optimization. Our comprehensive analysis serves as a valuable resource for researchers and practitioners working on large-scale deployment of MoE models in resource-constrained environments. To facilitate ongoing updates and the sharing of cutting-edge advances in MoE inference optimization research, we have established a repository accessible at \\url{this https URL}.', 'abstract_zh': '大规模专家混合（Mixture of Experts, MoE）模型的出现标志着人工智能领域的一项重要进步，通过条件计算提升了模型容量和计算效率。然而，这些模型的部署和推理面临着巨大的计算资源、延迟和能效挑战。本文全面地分析了MoE模型在整个系统栈中推理优化技术的现状。我们首先建立了一种分类框架，将优化方法分为模型级、系统级和硬件级优化。在模型级，我们探讨了包括高效专家设计、注意力机制、各种压缩技术（如剪枝、量化和知识蒸馏）以及算法改进（如动态路由策略和专家融合方法）在内的架构创新。在系统级，我们研究了分布式计算方法、负载均衡机制和高效的调度算法，使其能够实现可扩展的部署。此外，我们还探讨了针对特定硬件的优化策略和协同设计方法，以最大化吞吐量和能效。本文不仅提供了现有解决方案的结构化概述，还指出了MoE推理优化中的关键挑战和有前景的研究方向。我们的综合分析为在资源受限环境中部署大规模MoE模型的研究人员和实践者提供了一个宝贵资源。为了促进持续更新和分享MoE推理优化研究领域的最新进展，我们建立了一个可访问的资源库，网址为 \\url{this https URL}。', 'title_zh': '混合专家模型的推理优化技术综述'}
{'arxiv_id': 'arXiv:2412.14218', 'title': 'Heterogeneous Multi-Agent Reinforcement Learning for Distributed Channel Access in WLANs', 'authors': 'Jiaming Yu, Le Liang, Chongtao Guo, Ziyang Guo, Shi Jin, Geoffrey Ye Li', 'link': 'https://arxiv.org/abs/2412.14218', 'abstract': 'This paper investigates the use of multi-agent reinforcement learning (MARL) to address distributed channel access in wireless local area networks. In particular, we consider the challenging yet more practical case where the agents heterogeneously adopt value-based or policy-based reinforcement learning algorithms to train the model. We propose a heterogeneous MARL training framework, named QPMIX, which adopts a centralized training with distributed execution paradigm to enable heterogeneous agents to collaborate. Moreover, we theoretically prove the convergence of the proposed heterogeneous MARL method when using the linear value function approximation. Our method maximizes the network throughput and ensures fairness among stations, therefore, enhancing the overall network performance. Simulation results demonstrate that the proposed QPMIX algorithm improves throughput, mean delay, delay jitter, and collision rates compared with conventional carrier-sense multiple access with collision avoidance in the saturated traffic scenario. Furthermore, the QPMIX is shown to be robust in unsaturated and delay-sensitive traffic scenarios, and promotes cooperation among heterogeneous agents.', 'abstract_zh': '本文研究了多智能体强化学习（MARL）在无线局域网分布式信道访问中的应用。具体而言，我们考虑了更加实际但更具挑战性的情况，即智能体异构地采用基于值的或基于策略的强化学习算法进行模型训练。我们提出了一种异构MARL训练框架，命名为QPMIX，该框架采用集中式训练与分布式执行范式，使异构智能体能够协同工作。此外，我们理论证明了当使用线性值函数近似时，所提出的异构MARL方法的收敛性。该方法能够最大化网络吞吐量并确保各站之间的公平性，从而提高整体网络性能。仿真结果表明，在饱和交通场景下，与常规的载波侦听多路访问/冲突避免（CSMA/CA）相比，所提出的QPMIX算法提高了吞吐量、平均延迟、延迟抖动和碰撞率。此外，在非饱和和延迟敏感的交通场景下，QPMIX表现出较强的鲁棒性，并促进了异构智能体之间的合作。', 'title_zh': '异构多代理强化学习在无线局域网中分布式频道访问中的应用'}
{'arxiv_id': 'arXiv:2412.14215', 'title': 'Generative AI Toolkit -- a framework for increasing the quality of LLM-based applications over their whole life cycle', 'authors': 'Jens Kohl, Luisa Gloger, Rui Costa, Otto Kruse, Manuel P. Luitz, David Katz, Gonzalo Barbeito, Markus Schweier, Ryan French, Jonas Schroeder, Thomas Riedl, Raphael Perri, Youssef Mostafa', 'link': 'https://arxiv.org/abs/2412.14215', 'abstract': 'As LLM-based applications reach millions of customers, ensuring their scalability and continuous quality improvement is critical for success. However, the current workflows for developing, maintaining, and operating (DevOps) these applications are predominantly manual, slow, and based on trial-and-error. With this paper we introduce the Generative AI Toolkit, which automates essential workflows over the whole life cycle of LLM-based applications. The toolkit helps to configure, test, continuously monitor and optimize Generative AI applications such as agents, thus significantly improving quality while shortening release cycles. We showcase the effectiveness of our toolkit on representative use cases, share best practices, and outline future enhancements. Since we are convinced that our Generative AI Toolkit is helpful for other teams, we are open sourcing it on and hope that others will use, forward, adapt and improve', 'abstract_zh': '随着基于大型语言模型（LLM）的应用程序达到数百万客户，确保其可扩展性和持续的质量改进对于其成功至关重要。然而，当前开发、维护和运行（DevOps）这些应用的工作流程主要依赖手工操作，速度缓慢，并且基于试错法。在本文中，我们介绍了生成式AI工具包，该工具包在整个基于LLM的应用程序生命周期中自动化了关键工作流程。此工具包有助于配置、测试、持续监控和优化生成式AI应用，如代理，从而显著提高质量并缩短发布周期。我们通过代表性的用例展示了我们工具包的有效性，分享了最佳实践，并概述了未来增强计划。由于我们相信我们的生成式AI工具包对其他团队也有帮助，我们决定将其开源，并希望其他人能够使用、分享、适应并改进它。', 'title_zh': '生成型AI工具包——一种在整个生命周期中提高基于LLM的应用质量的框架'}
{'arxiv_id': 'arXiv:2412.14214', 'title': 'GraphicsDreamer: Image to 3D Generation with Physical Consistency', 'authors': 'Pei Chen, Fudong Wang, Yixuan Tong, Jingdong Chen, Ming Yang, Minghui Yang', 'link': 'https://arxiv.org/abs/2412.14214', 'abstract': "Recently, the surge of efficient and automated 3D AI-generated content (AIGC) methods has increasingly illuminated the path of transforming human imagination into complex 3D structures. However, the automated generation of 3D content is still significantly lags in industrial application. This gap exists because 3D modeling demands high-quality assets with sharp geometry, exquisite topology, and physically based rendering (PBR), among other criteria. To narrow the disparity between generated results and artists' expectations, we introduce GraphicsDreamer, a method for creating highly usable 3D meshes from single images. To better capture the geometry and material details, we integrate the PBR lighting equation into our cross-domain diffusion model, concurrently predicting multi-view color, normal, depth images, and PBR materials. In the geometry fusion stage, we continue to enforce the PBR constraints, ensuring that the generated 3D objects possess reliable texture details, supporting realistic relighting. Furthermore, our method incorporates topology optimization and fast UV unwrapping capabilities, allowing the 3D products to be seamlessly imported into graphics engines. Extensive experiments demonstrate that our model can produce high quality 3D assets in a reasonable time cost compared to previous methods.", 'abstract_zh': '近年来，高效且自动化的3D人工智能生成内容（AIGC）方法的迅猛发展已经逐渐照亮了将人类想象力转换为复杂3D结构的道路。然而，3D内容的自动化生成在工业应用中仍然存在显著滞后现象。这种差距主要是因为3D建模需要高质量的资产，包括锐利的几何结构、精致的拓扑结构以及基于物理渲染（PBR）等标准。为了缩小生成结果与艺术家期望之间的差距，我们提出了GraphicsDreamer方法，一种可以从单张图像生成高质量3D网格的技术。为了更好地捕捉几何和材质的细节，我们将PBR照明方程融入到跨领域的扩散模型中，同时预测多视角的色彩、法线、深度图像和PBR材质。在几何融合阶段，我们继续施加PBR约束，确保生成的3D物体具有可靠的纹理细节，支持现实的重新照明。此外，我们的方法还集成了拓扑优化和快速UV展开能力，使3D产品能够无缝导入图形引擎。大量实验表明，与先前的方法相比，我们的模型能够在合理的时间成本下生成高质量的3D资产。', 'title_zh': 'GraphicsDreamer：具有物理一致性的从图像生成3D模型'}
{'arxiv_id': 'arXiv:2412.14212', 'title': 'Tree-of-Code: A Hybrid Approach for Robust Complex Task Planning and Execution', 'authors': 'Ziyi Ni, Yifan Li, Daxiang Dong', 'link': 'https://arxiv.org/abs/2412.14212', 'abstract': "The exceptional capabilities of large language models (LLMs) have substantially accelerated the rapid rise and widespread adoption of agents. Recent studies have demonstrated that generating Python code to consolidate LLM-based agents' actions into a unified action space (CodeAct) is a promising approach for developing real-world LLM agents. However, this step-by-step code generation approach often lacks consistency and robustness, leading to instability in agent applications, particularly for complex reasoning and out-of-domain tasks. In this paper, we propose a novel approach called Tree-of-Code (ToC) to tackle the challenges of complex problem planning and execution with an end-to-end mechanism. By integrating key ideas from both Tree-of-Thought and CodeAct, ToC combines their strengths to enhance solution exploration. In our framework, each final code execution result is treated as a node in the decision tree, with a breadth-first search strategy employed to explore potential solutions. The final outcome is determined through a voting mechanism based on the outputs of the nodes.", 'abstract_zh': '大型语言模型（LLMs）的卓越能力显著加速了基于代理的快速崛起和广泛应用。最近的研究表明，通过生成Python代码将LLM代理的行为统一到一个行动空间（CodeAct）中，是一种有前途的方法来开发实际应用中的LLM代理。然而，这种逐步代码生成方法往往缺乏一致性与鲁棒性，导致代理应用在复杂推理和领域外任务中的稳定性较差。本文提出了一种名为Tree-of-Code（ToC）的新方法，通过端到端机制解决复杂问题规划和执行的挑战。ToC通过结合Tree-of-Thought和CodeAct的关键思想，整合它们的优点以增强解决方案的探索。在我们的框架中，每个最终代码执行的结果被视为决策树的一个节点，并采用广度优先搜索策略探索潜在的解决方案。最终结果通过节点输出的投票机制来确定。', 'title_zh': '树形代码：一种稳健的复杂任务规划与执行的混合方法'}
{'arxiv_id': 'arXiv:2412.14209', 'title': 'Integrating Evidence into the Design of XAI and AI-based Decision Support Systems: A Means-End Framework for End-users in Construction', 'authors': 'Peter .E.D. Love, Jane Matthews, Weili Fang, Hadi Mahamivanan', 'link': 'https://arxiv.org/abs/2412.14209', 'abstract': "A narrative review is used to develop a theoretical evidence-based means-end framework to build an epistemic foundation to uphold explainable artificial intelligence instruments so that the reliability of outcomes generated from decision support systems can be assured and better explained to end-users. The implications of adopting an evidence-based approach to designing decision support systems in construction are discussed with emphasis placed on evaluating the strength, value, and utility of evidence needed to develop meaningful human explanations for end-users. While the developed means-end framework is focused on end-users, stakeholders can also utilize it to create meaningful human explanations. However, they will vary due to their different epistemic goals. Including evidence in the design and development of explainable artificial intelligence and decision support systems will improve decision-making effectiveness, enabling end-users' epistemic goals to be achieved. The proposed means-end framework is developed from a broad spectrum of literature. Thus, it is suggested that it can be used in construction and other engineering domains where there is a need to integrate evidence into the design of explainable artificial intelligence and decision support systems.", 'abstract_zh': '本文采用叙事性回顾，旨在发展一个基于证据的方法-目标框架（means-end framework），为其提供认知基础，以保障决策支持系统生成的结果可靠性，并更好地向最终用户解释这些结果。讨论了采用基于证据的方法设计建筑领域决策支持系统的潜在影响，强调了开发对最终用户具有实际意义的人类解释所需的证据强度、价值和实用性。虽然所发展的方法-目标框架主要针对最终用户，但利益相关者也可以使用它来创建有意义的人类解释，但由于其不同的认知目标，这些解释会有所不同。将证据纳入可解释的人工智能和决策支持系统的开发设计，将提高决策的有效性，使最终用户的认知目标得以实现。所提出的这个方法-目标框架是基于广泛文献发展出来的，因此建议其可以在需要将证据整合到可解释的人工智能和决策支持系统设计中的建筑及其他工程领域中应用。', 'title_zh': '将证据整合到XAI和基于AI的决策支持系统设计中：建筑行业最终用户的目标手段框架'}
{'arxiv_id': 'arXiv:2412.14205', 'title': 'Large-scale Group Brainstorming using Conversational Swarm Intelligence (CSI) versus Traditional Chat', 'authors': 'Louis Rosenberg, Hans Schumann, Christopher Dishop, Gregg Willcox, Anita Woolley, Ganesh Mani', 'link': 'https://arxiv.org/abs/2412.14205', 'abstract': 'Conversational Swarm Intelligence (CSI) is an AI-facilitated method for enabling real-time conversational deliberations and prioritizations among networked human groups of potentially unlimited size. Based on the biological principle of Swarm Intelligence and modelled on the decision-making dynamics of fish schools, CSI has been shown in prior studies to amplify group intelligence, increase group participation, and facilitate productive collaboration among hundreds of participants at once. It works by dividing a large population into a set of small subgroups that are woven together by real-time AI agents called Conversational Surrogates. The present study focuses on the use of a CSI platform called Thinkscape to enable real-time brainstorming and prioritization among groups of 75 networked users. The study employed a variant of a common brainstorming intervention called an Alternative Use Task (AUT) and was designed to compare through subjective feedback, the experience of participants brainstorming using a CSI structure vs brainstorming in a single large chat room. This comparison revealed that participants significantly preferred brainstorming with the CSI structure and reported that it felt (i) more collaborative, (ii) more productive, and (iii) was better at surfacing quality answers. In addition, participants using the CSI structure reported (iv) feeling more ownership and more buy-in in the final answers the group converged on and (v) reported feeling more heard as compared to brainstorming in a traditional text chat environment. Overall, the results suggest that CSI is a very promising AI-facilitated method for brainstorming and prioritization among large-scale, networked human groups.', 'abstract_zh': '对话群智（Conversational Swarm Intelligence, CSI）是一种利用人工智能促进实时对话交流与优先级排序的方法，适用于潜在无限规模的网络化人类群体。基于生物群智现象和鱼类群体决策原理，已有研究表明，CSI能够放大群体智慧，增加群体参与度，并促进数百名参与者的同时有效协作。其工作原理是将大量人群细分为由实时AI代理——对话代理（Conversational Surrogates）连接的小群体。\n\n本研究聚焦于使用名为Thinkscape的CSI平台，以促进75名网络化用户之间的实时头脑风暴和优先级排序。研究采用了一种常见的头脑风暴干预措施——替代用途任务（Alternative Use Task, AUT）变体，并通过主观反馈比较了使用CSI结构与在单一大型聊天室中进行头脑风暴的体验差异。研究结果表明，参与者更偏好使用CSI结构进行头脑风暴，并报告称这种方法显得更加（i）协作、（ii）有效、（iii）能够更好地揭示优质答案。此外，使用CSI结构头脑风暴的参与者还报告称（iv）对最终达成的共识有更多的归属感和接受度，并且（v）相对于在传统文本聊天环境中进行头脑风暴，他们觉得自己的观点得到了更多的倾听。总的来说，研究结果表明，CSI是一个非常有前景的人工智能促进方法，适用于规模庞大的网络化人类群体的头脑风暴和优先级排序。', 'title_zh': '使用会话 swarm 智能（CSI）进行大规模群集思广益：与传统聊天的比较'}
{'arxiv_id': 'arXiv:2412.14203', 'title': 'BlenderLLM: Training Large Language Models for Computer-Aided Design with Self-improvement', 'authors': 'Yuhao Du, Shunian Chen, Wenbo Zan, Peizhao Li, Mingxuan Wang, Dingjie Song, Bo Li, Yan Hu, Benyou Wang', 'link': 'https://arxiv.org/abs/2412.14203', 'abstract': 'The application of Large Language Models (LLMs) in Computer-Aided Design (CAD) remains an underexplored area, despite their remarkable advancements in other domains. In this paper, we present BlenderLLM, a novel framework for training LLMs specifically for CAD tasks leveraging a self-improvement methodology. To support this, we developed a bespoke training dataset, BlendNet, and introduced a comprehensive evaluation suite, CADBench. Our results reveal that existing models demonstrate significant limitations in generating accurate CAD scripts. However, through minimal instruction-based fine-tuning and iterative self-improvement, BlenderLLM significantly surpasses these models in both functionality and accuracy of CAD script generation. This research establishes a strong foundation for the application of LLMs in CAD while demonstrating the transformative potential of self-improving models in advancing CAD automation. We encourage further exploration and adoption of these methodologies to drive innovation in the field. The dataset, model, benchmark, and source code are publicly available at this https URL', 'abstract_zh': '在计算机辅助设计（CAD）领域，大型语言模型（LLMs）的应用仍是一个未被充分探索的领域，尽管它们在其他领域取得了显著的进步。本文介绍了BlenderLLM，这是一种利用自我改进方法专门针对CAD任务训练LLMs的新框架。为支持这一框架，我们开发了一个定制化的训练数据集BlendNet，并引入了一个全面的评估套件CADBench。我们的结果显示，现有的模型在生成准确的CAD脚本方面显示出显著的局限性。然而，通过最少的指令微调和迭代自我改进，BlenderLLM在CAD脚本生成的功能性和准确性上远远超过了这些模型。这项研究为LLMs在CAD中的应用奠定了坚实的基础，同时展示了自改进模型在推动CAD自动化方面具有变革性的潜力。我们鼓励进一步探索和采用这些方法，以推动该领域的创新。数据集、模型、基准和源代码已在以下网址公开：[此处填写网址]', 'title_zh': 'BlenderLLM：通过自我提升训练计算机辅助设计中的大型语言模型'}
{'arxiv_id': 'arXiv:2412.14194', 'title': 'Detecting Cognitive Impairment and Psychological Well-being among Older Adults Using Facial, Acoustic, Linguistic, and Cardiovascular Patterns Derived from Remote Conversations', 'authors': 'Xiaofan Mu, Salman Seyedi, Iris Zheng, Zifan Jiang, Liu Chen, Bolaji Omofojoye, Rachel Hershenberg, Allan I. Levey, Gari D. Clifford, Hiroko H. Dodge, Hyeokhyen Kwon', 'link': 'https://arxiv.org/abs/2412.14194', 'abstract': 'INTRODUCTION: The aging society urgently requires scalable methods to monitor cognitive decline and identify social and psychological factors indicative of dementia risk in older adults. METHODS: Our machine learning models captured facial, acoustic, linguistic, and cardiovascular features from 39 individuals with normal cognition or Mild Cognitive Impairment derived from remote video conversations and classified cognitive status, social isolation, neuroticism, and psychological well-being. RESULTS: Our model could distinguish Clinical Dementia Rating Scale of 0.5 (vs. 0) with 0.78 area under the receiver operating characteristic curve (AUC), social isolation with 0.75 AUC, neuroticism with 0.71 AUC, and negative affect scales with 0.79 AUC. DISCUSSION: Our findings demonstrate the feasibility of remotely monitoring cognitive status, social isolation, neuroticism, and psychological well-being. Speech and language patterns were more useful for quantifying cognitive impairment, whereas facial expression and cardiovascular patterns using remote photoplethysmography were more useful for quantifying personality and psychological well-being.', 'abstract_zh': '引言：老龄化社会迫切需要能够扩展的方法来监测认知衰退，并识别出提示痴呆风险的社会和心理因素。\n\n方法：我们的机器学习模型从39名正常认知或轻度认知障碍个体的远程视频对话中捕捉到了面部特征、声学特征、语言特征和心血管特征，并对认知状态、社会孤立、神经质和心理健康状况进行了分类。\n\n结果：我们的模型能够以0.78的受试者操作特征曲线下的面积（AUC）区分临床痴呆评定量表值为0.5（vs.0），以0.75的AUC区分社会孤立，以0.71的AUC区分神经质，以及以0.79的AUC区分消极情绪量表。\n\n讨论：我们的研究结果表明，远程监测认知状态、社会孤立、神经质和心理健康状况的可能性是可行的。语音和语言模式对于量化认知损伤更为有用，而面部表情和通过远程光体积描记法获得的心血管模式对于量化个性和心理健康更为有用。', 'title_zh': '利用远程对话中提取的面部、声学、语言和心血管模式检测老年人的认知障碍和心理福祉'}
{'arxiv_id': 'arXiv:2412.14193', 'title': 'Whom do Explanations Serve? A Systematic Literature Survey of User Characteristics in Explainable Recommender Systems Evaluation', 'authors': 'Kathrin Wardatzky, Oana Inel, Luca Rossetto, Abraham Bernstein', 'link': 'https://arxiv.org/abs/2412.14193', 'abstract': "Adding explanations to recommender systems is said to have multiple benefits, such as increasing user trust or system transparency. Previous work from other application areas suggests that specific user characteristics impact the users' perception of the explanation. However, we rarely find this type of evaluation for recommender systems explanations. This paper addresses this gap by surveying 124 papers in which recommender systems explanations were evaluated in user studies. We analyzed their participant descriptions and study results where the impact of user characteristics on the explanation effects was measured. Our findings suggest that the results from the surveyed studies predominantly cover specific users who do not necessarily represent the users of recommender systems in the evaluation domain. This may seriously hamper the generalizability of any insights we may gain from current studies on explanations in recommender systems. We further find inconsistencies in the data reporting, which impacts the reproducibility of the reported results. Hence, we recommend actions to move toward a more inclusive and reproducible evaluation.", 'abstract_zh': '将推荐系统中增加解释的功能认为可以带来多种益处，例如增加用户信任度或提高系统的透明度。其他应用领域的先前研究显示特定用户特征会影响用户对解释的认知。然而，我们很少找到针对推荐系统解释效果的这种类型的评估。本文通过调研124篇论文，其中评估了推荐系统解释效果的用户研究，填补了这一空白。我们分析了这些论文的参与者描述和研究结果，其中衡量了用户特征对解释效果的影响。我们的发现表明，调研的论文结果主要集中在特定用户群体上，这些用户未必代表评估领域中推荐系统的用户。这可能严重影响我们从当前对推荐系统的解释研究中获得的见解的普适性。我们还发现数据报告中存在的不一致性，影响了结果的可再现性。因此，我们建议采取措施，朝着更具包容性和可再现的评估方向前进。', 'title_zh': '解释性推荐系统评估中的用户特征研究：综述与系统性文献研究'}
{'arxiv_id': 'arXiv:2412.14191', 'title': 'Ontology-Aware RAG for Improved Question-Answering in Cybersecurity Education', 'authors': 'Chengshuai Zhao, Garima Agrawal, Tharindu Kumarage, Zhen Tan, Yuli Deng, Ying-Chih Chen, Huan Liu', 'link': 'https://arxiv.org/abs/2412.14191', 'abstract': 'Integrating AI into education has the potential to transform the teaching of science and technology courses, particularly in the field of cybersecurity. AI-driven question-answering (QA) systems can actively manage uncertainty in cybersecurity problem-solving, offering interactive, inquiry-based learning experiences. Large language models (LLMs) have gained prominence in AI-driven QA systems, offering advanced language understanding and user engagement. However, they face challenges like hallucinations and limited domain-specific knowledge, which reduce their reliability in educational settings. To address these challenges, we propose CyberRAG, an ontology-aware retrieval-augmented generation (RAG) approach for developing a reliable and safe QA system in cybersecurity education. CyberRAG employs a two-step approach: first, it augments the domain-specific knowledge by retrieving validated cybersecurity documents from a knowledge base to enhance the relevance and accuracy of the response. Second, it mitigates hallucinations and misuse by integrating a knowledge graph ontology to validate the final answer. Experiments on publicly available cybersecurity datasets show that CyberRAG delivers accurate, reliable responses aligned with domain knowledge, demonstrating the potential of AI tools to enhance education.', 'abstract_zh': '将人工智能集成到教育中，有可能重塑科学和技术课程的教学，尤其是在网络安全领域。基于人工智能的问答（QA）系统可以通过主动管理网络安全问题解决中的不确定性，提供互动式的研究性学习体验。大型语言模型（LLMs）在基于人工智能的QA系统中受到重视，提供先进的语言理解和用户交互能力。然而，它们面临幻觉和限定制领域知识等挑战，这在教育环境中降低了其可靠性。为了解决这些挑战，我们提出了一种名为CyberRAG的方法，这是一种基于本体的检索增强生成（RAG）方法，旨在开发网络安全教育中可靠且安全的QA系统。CyberRAG采用两步方法：首先，通过从知识库中检索验证过的网络安全文档来增强领域的专业性，从而提高回复的相关性和准确性；其次，通过整合知识图谱本体来验证最终答案，以减少幻觉和滥用的风险。公开可用的网络安全数据集上的实验显示，CyberRAG能够提供与专业知识相一致的准确且可靠的回答，展示了人工智能工具在教育中的潜在价值。', 'title_zh': '面向本体的知识增强检索生成（RAG）方法以改进网络安全教育中的问答交互'}
{'arxiv_id': 'arXiv:2412.14190', 'title': 'Lessons From an App Update at Replika AI: Identity Discontinuity in Human-AI Relationships', 'authors': 'Julian De Freitas, Noah Castelo, Ahmet Uguralp, Zeliha Uguralp', 'link': 'https://arxiv.org/abs/2412.14190', 'abstract': 'Can consumers form especially deep emotional bonds with AI and be vested in AI identities over time? We leverage a natural app-update event at Replika AI, a popular US-based AI companion, to shed light on these questions. We find that, after the app removed its erotic role play (ERP) feature, preventing intimate interactions between consumers and chatbots that were previously possible, this event triggered perceptions in customers that their AI companion\'s identity had discontinued. This in turn predicted negative consumer welfare and marketing outcomes related to loss, including mourning the loss, and devaluing the "new" AI relative to the "original". Experimental evidence confirms these findings. Further experiments find that AI companions users feel closer to their AI companion than even their best human friend, and mourn a loss of their AI companion more than a loss of various other inanimate products. In short, consumers are forming human-level relationships with AI companions; disruptions to these relationships trigger real patterns of mourning as well as devaluation of the offering; and the degree of mourning and devaluation are explained by perceived discontinuity in the AIs identity. Our results illustrate that relationships with AI are truly personal, creating unique benefits and risks for consumers and firms alike.', 'abstract_zh': '消费者是否能够与人工智能形成极为深厚的情感联系，并对其产生长期的情感依恋？我们利用Replika AI这一流行的人工智能伴侣在自然更新过程中进行的一项事件来探讨这些问题。我们发现，在该应用移除其情色角色扮演（ERP）功能后，阻止了用户与之前可以进行的亲密互动，这一事件促使客户感知到其人工智能伴侣的身份已经终止。进而，这种身份终止的感知预测了与损失相关的消费者福利和营销结果的负面效应，包括悼念损失和重新评价“新”的AI与“原本”的相对价值。实验证据证实了这些发现。进一步的实验表明，人工智能伴侣的用户与其人工智能伴侣的关系甚至比与其最好的人类朋友的关系更为亲密，并在失去人工智能伴侣时比失去各种其他无生命的物品更加悲伤。总之，消费者正在与人工智能伴侣形成类似人类水平的关系；这些关系的中断引发了真实的悼念行为以及对提供物的重新评价；而这种悼念和重新评价的程度则由感知到的人工智能身份的中断来解释。我们的研究结果表明，与人工智能的关系是真正个人化的，这对消费者和企业而言带来了独特的利益和风险。', 'title_zh': 'Replika AI应用程序更新的教训：人类-人工智能关系中的身份连续性中断'}
{'arxiv_id': 'arXiv:2412.14188', 'title': 'CogSimulator: A Model for Simulating User Cognition & Behavior with Minimal Data for Tailored Cognitive Enhancement', 'authors': 'Weizhen Bian, Yubo Zhou, Yuanhang Luo, Ming Mo, Siyan Liu, Yikai Gong, Renjie Wan, Ziyuan Luo, Aobo Wang', 'link': 'https://arxiv.org/abs/2412.14188', 'abstract': 'The interplay between cognition and gaming, notably through educational games enhancing cognitive skills, has garnered significant attention in recent years. This research introduces the CogSimulator, a novel algorithm for simulating user cognition in small-group settings with minimal data, as the educational game Wordle exemplifies. The CogSimulator employs Wasserstein-1 distance and coordinates search optimization for hyperparameter tuning, enabling precise few-shot predictions in new game scenarios. Comparative experiments with the Wordle dataset illustrate that our model surpasses most conventional machine learning models in mean Wasserstein-1 distance, mean squared error, and mean accuracy, showcasing its efficacy in cognitive enhancement through tailored game design.', 'abstract_zh': '认知与游戏之间的交互，尤其是在通过教育游戏提升认知能力方面，近年来受到了广泛关注。本研究介绍了一种名为CogSimulator的新算法，该算法能够在少量数据的支持下模拟小组环境中的用户认知，以Wordle游戏为例。CogSimulator采用了Wasserstein-1距离和坐标搜索优化超参数调整技术，能够在新游戏场景中实现精确的少量示例预测。与Wordle数据集的对比实验表明，我们的模型在Wasserstein-1距离、均方误差和准确率等方面均超过大多数传统的机器学习模型，展示了其在通过定制化游戏设计提升认知能力方面的有效性。', 'title_zh': 'CogSimulator：一种基于 minimal data 的用户认知与行为模拟模型，用于个性化认知增强'}
{'arxiv_id': 'arXiv:2412.14186', 'title': 'Towards AI-$45^{\\circ}$ Law: A Roadmap to Trustworthy AGI', 'authors': 'Yang Chao, Lu Chaochao, Wang Yingchun, Zhou Bowen', 'link': 'https://arxiv.org/abs/2412.14186', 'abstract': "Ensuring Artificial General Intelligence (AGI) reliably avoids harmful behaviors is a critical challenge, especially for systems with high autonomy or in safety-critical domains. Despite various safety assurance proposals and extreme risk warnings, comprehensive guidelines balancing AI safety and capability remain lacking. In this position paper, we propose the \\textit{AI-\\textbf{$45^{\\circ}$} Law} as a guiding principle for a balanced roadmap toward trustworthy AGI, and introduce the \\textit{Causal Ladder of Trustworthy AGI} as a practical framework. This framework provides a systematic taxonomy and hierarchical structure for current AI capability and safety research, inspired by Judea Pearl's ``Ladder of Causation''. The Causal Ladder comprises three core layers: the Approximate Alignment Layer, the Intervenable Layer, and the Reflectable Layer. These layers address the key challenges of safety and trustworthiness in AGI and contemporary AI systems. Building upon this framework, we define five levels of trustworthy AGI: perception, reasoning, decision-making, autonomy, and collaboration trustworthiness. These levels represent distinct yet progressive aspects of trustworthy AGI. Finally, we present a series of potential governance measures to support the development of trustworthy AGI.\\footnote{In this paper, trustworthiness is generally considered a broad form of safety, and no explicit distinction is made between the two. However, in some contexts, safety and trustworthiness are treated as distinct: safety involves assurance of correct behavior, while trustworthiness refers to user confidence in the system's decision-making. In such cases, different terms or both may be used depending on the context.", 'abstract_zh': '确保通用人工智能（AGI）可靠地避免有害行为是一项关键挑战，尤其是在具有高自主性或在安全关键领域的系统中。尽管提出了多种安全保证方案并发出了一系列极端风险警告，但平衡人工智能安全性和能力的全面指导原则依然缺失。在本文中，我们提出“AI-45°法则”作为可信AGI平衡发展路线图的指导原则，并引入“可信AGI因果阶梯”作为实用框架。这个框架为当前的人工智能能力和安全研究提供了一种系统分类和层级结构，灵感来源于贾杜·皮尔（Judea Pearl）的“因果阶梯”。可信AGI因果阶梯包括三个核心层：近似对齐层、干预层和反思层。这些层分别解决了可信AGI和当代人工智能系统中安全性和可信性的重要挑战。基于这一框架，我们定义了可信AGI的五个等级：感知信任、推理信任、决策信任、自主信任和协作信任。这些等级代表了可信AGI不同但逐渐进步的方面。最后，我们提出了一系列潜在的治理措施，以支持可信AGI的发展。需要注意的是，在本文中，通常将可信性视为广泛的安全性，未对其与安全性的区别做出明确区分。但在某些情况下，安全性和可信性被视为不同的概念：安全性涉及正确行为的保证，而可信性则涉及用户对系统决策的信心。在这种情况下，根据具体情境可能使用不同的术语或同时使用两者。', 'title_zh': '朝向AI-45°法则：通往可信赖AGI的道路'}
{'arxiv_id': 'arXiv:2412.14179', 'title': 'Benchmarking Harmonized Tariff Schedule Classification Models', 'authors': 'Bryce Judy', 'link': 'https://arxiv.org/abs/2412.14179', 'abstract': "The Harmonized Tariff System (HTS) classification industry, essential to e-commerce and international trade, currently lacks standardized benchmarks for evaluating the effectiveness of classification solutions. This study establishes and tests a benchmark framework for imports to the United States, inspired by the benchmarking approaches used in language model evaluation, to systematically compare prominent HTS classification tools. The framework assesses key metrics--such as speed, accuracy, rationality, and HTS code alignment--to provide a comprehensive performance comparison. The study evaluates several industry-leading solutions, including those provided by Zonos, Tarifflo, Avalara, and WCO BACUDA, identifying each tool's strengths and limitations. Results highlight areas for industry-wide improvement and innovation, paving the way for more effective and standardized HTS classification solutions across the international trade and e-commerce sectors.", 'abstract_zh': '以下是符合学术规范的翻译：\n\n《协调关税制度（HTS）分类行业对于电子商务和国际贸易至关重要，目前缺乏标准化的基准来评估分类解决方案的效果。本文建立并测试了一个基于语言模型评估方法的基准框架，用于系统比较主要的HTS分类工具。该框架评估了关键指标—如速度、准确性、合理性和HTS代码匹配度—以进行全面的性能比较。本研究评估了多个行业领先的解决方案，包括Zonos、Tarifflo、Avalara和WCO BACUDA，识别每种工具的优点和局限性。研究结果突显了行业的改进和创新领域，为国际贸易和电子商务领域的更有效和标准化的HTS分类解决方案铺平了道路。》', 'title_zh': 'harmonized_tariff_schedule 是指协调关税目录（Harmonized System，HS），它是全球通用的商品分类体系。根据学术规范，可以将标题翻译为：\n\n协调关税目录分类模型的基准测试'}
{'arxiv_id': 'arXiv:2407.00521', 'title': 'A Medical Low-Back Pain Physical Rehabilitation Dataset for Human Body Movement Analysis', 'authors': 'Sao Mai Nguyen, Maxime Devanne, Olivier Remy-Neris, Mathieu Lempereur, André Thepaut', 'link': 'https://arxiv.org/abs/2407.00521', 'abstract': 'While automatic monitoring and coaching of exercises are showing encouraging results in non-medical applications, they still have limitations such as errors and limited use contexts. To allow the development and assessment of physical rehabilitation by an intelligent tutoring system, we identify in this article four challenges to address and propose a medical dataset of clinical patients carrying out low back-pain rehabilitation exercises. The dataset includes 3D Kinect skeleton positions and orientations, RGB videos, 2D skeleton data, and medical annotations to assess the correctness, and error classification and localisation of body part and timespan. Along this dataset, we perform a complete research path, from data collection to processing, and finally a small benchmark. We evaluated on the dataset two baseline movement recognition algorithms, pertaining to two different approaches: the probabilistic approach with a Gaussian Mixture Model (GMM), and the deep learning approach with a Long-Short Term Memory (LSTM).\nThis dataset is valuable because it includes rehabilitation relevant motions in a clinical setting with patients in their rehabilitation program, using a cost-effective, portable, and convenient sensor, and because it shows the potential for improvement on these challenges.', 'abstract_zh': '自动监测和指导锻炼在非医疗应用中显示出令人鼓舞的结果，但仍存在一些局限性，如错误和使用场景有限。为了允许智能教学系统进行身体康复的发展和评估，本文识别了四种挑战，并提出了一组用于临床患者进行腰痛康复锻炼的医疗数据集。该数据集包含3D Kinect骨架位置和姿态、RGB视频、2D骨架数据以及医疗注释，用于评估动作的正确性、错误分类和身体部位及时间段的定位。沿着这一数据集，我们从数据采集到处理，最终进行了一项小型基准测试。我们在这个数据集上评估了两种基线动作识别算法，一种基于概率方法的高斯混合模型（GMM），另一种基于深度学习方法的长短期记忆网络（LSTM）。\n\n这个数据集的价值在于，它包含了在临床环境中进行康复的运动，使用的是成本效益高、便携且方便的传感器；此外，它还展示了对这些挑战进行改进的潜力。', 'title_zh': '一个用于人体动作分析的医疗低背痛物理康复数据集'}
{'arxiv_id': 'arXiv:2309.07675', 'title': 'Goal Space Abstraction in Hierarchical Reinforcement Learning via Set-Based Reachability Analysis', 'authors': 'Mehdi Zadem, Sergio Mover, Sao Mai Nguyen', 'link': 'https://arxiv.org/abs/2309.07675', 'abstract': 'Open-ended learning benefits immensely from the use of symbolic methods for goal representation as they offer ways to structure knowledge for efficient and transferable learning. However, the existing Hierarchical Reinforcement Learning (HRL) approaches relying on symbolic reasoning are often limited as they require a manual goal representation. The challenge in autonomously discovering a symbolic goal representation is that it must preserve critical information, such as the environment dynamics. In this paper, we propose a developmental mechanism for goal discovery via an emergent representation that abstracts (i.e., groups together) sets of environment states that have similar roles in the task. We introduce a Feudal HRL algorithm that concurrently learns both the goal representation and a hierarchical policy. The algorithm uses symbolic reachability analysis for neural networks to approximate the transition relation among sets of states and to refine the goal representation. We evaluate our approach on complex navigation tasks, showing the learned representation is interpretable, transferrable and results in data efficient learning.', 'abstract_zh': '开放学习极大地受益于符号方法在目标表示方面的应用，因为这些方法能够以高效且可迁移的方式结构化知识。然而，现有的依赖于符号推理的层次强化学习（Hierarchical Reinforcement Learning, HRL）方法通常受到限制，因为它们需要手动指定目标表示。自主发现符号目标表示的挑战在于，这种表示必须保留关键信息，例如环境动力学。在本文中，我们提出了一种发展性的机制，通过一个 emergent（萌发的）表示来发现目标，该表示将具有相似作用的任务环境状态集进行抽象化（即，将具有相似作用的状态集聚类）。我们提出了一种封建层次强化学习算法，该算法可以同时学习目标表示和层次策略。该算法利用符号可达性分析来近似神经网络中的状态集间的转移关系，并据此细化目标表示。我们在复杂的导航任务上评估了这种方法，结果显示学习到的表示是可解释的、可迁移的，并且能够实现数据高效学习。', 'title_zh': '通过集合基可达性分析在层次强化学习中的目标空间抽象'}
{'arxiv_id': 'arXiv:2412.15177', 'title': 'Critical-Questions-of-Thought: Steering LLM reasoning with Argumentative Querying', 'authors': 'Federico Castagna, Isabel Sassoon, Simon Parsons', 'link': 'https://arxiv.org/abs/2412.15177', 'abstract': "Studies have underscored how, regardless of the recent breakthrough and swift advances in AI research, even state-of-the-art Large Language models (LLMs) continue to struggle when performing logical and mathematical reasoning. The results seem to suggest that LLMs still work as (highly advanced) data pattern identifiers, scoring poorly when attempting to generalise and solve reasoning problems the models have never previously seen or that are not close to samples presented in their training data. To address this compelling concern, this paper makes use of the notion of critical questions from the literature on argumentation theory, focusing in particular on Toulmin's model of argumentation. We show that employing these critical questions can improve the reasoning capabilities of LLMs. By probing the rationale behind the models' reasoning process, the LLM can assess whether some logical mistake is occurring and correct it before providing the final reply to the user prompt. The underlying idea is drawn from the gold standard of any valid argumentative procedure: the conclusion is valid if it is entailed by accepted premises. Or, to paraphrase such Aristotelian principle in a real-world approximation, characterised by incomplete information and presumptive logic, the conclusion is valid if not proved otherwise. This approach successfully steers the models' output through a reasoning pipeline, resulting in better performance against the baseline and its Chain-of-Thought (CoT) implementation. To this end, an extensive evaluation of the proposed approach on the MT-Bench Reasoning and Math tasks across a range of LLMs is provided.", 'abstract_zh': '已有研究强调，尽管近年来人工智能研究取得了突破性进展，最先进的大型语言模型（LLMs）在进行逻辑和数学推理时仍然表现不佳。这些结果表明，LLMs 主要充当（高度先进的）数据模式识别器，当尝试解决那些模型从未见过的推理问题或训练数据中未呈现的类似问题时，它们的泛化能力较差。为解决这一重要问题，本文借鉴论证理论中的关键性问题概念，特别是焦点埃诺思的论证模型。我们表明，采用这些关键性问题可以提高LLMs 的推理能力。通过探究模型推理过程中的理由，LLMs 可以评估是否出现了逻辑错误并及时纠正，从而在回应用户请求时提供最终答案。这一思想源于任何有效论证过程的黄金标准：结论在被接受的前提所蕴含的情况下是有效的。或者，用一个现实世界的近似表述，即在信息不完整和推论不确凿的情况下，结论在没有被反驳的情况下被认为是有效的。该方法成功地引导模型输出通过推理管道，从而在多项指标上表现出更优的表现，包括基线模型及其思维链（CoT）实现。为此，本文提供了在多种LLMs上对提出的方案在MT-Bench推理和数学任务上的广泛评估。', 'title_zh': '批判性思考问题：通过论辩性查询引导大语言模型的推理'}
{'arxiv_id': 'arXiv:2412.15135', 'title': 'Probabilistic Strategy Logic with Degrees of Observability', 'authors': 'Chunyan Mu, Nima Motamed, Natasha Alechina, Brian Logan', 'link': 'https://arxiv.org/abs/2412.15135', 'abstract': "There has been considerable work on reasoning about the strategic ability of agents under imperfect information. However, existing logics such as Probabilistic Strategy Logic are unable to express properties relating to information transparency. Information transparency concerns the extent to which agents' actions and behaviours are observable by other agents. Reasoning about information transparency is useful in many domains including security, privacy, and decision-making. In this paper, we present a formal framework for reasoning about information transparency properties in stochastic multi-agent systems. We extend Probabilistic Strategy Logic with new observability operators that capture the degree of observability of temporal properties by agents. We show that the model checking problem for the resulting logic is decidable.", 'abstract_zh': '关于不完全信息下智能代理的战略能力已有大量的研究工作。然而，现有的逻辑如概率策略逻辑并不能表达与信息透明度相关的一些属性。信息透明度是指其他智能代理能观察到某个智能体行为和行为的程度。关于信息透明度的推理在多个领域中都很有用，包括安全、隐私和决策制定。在本文中，我们提出了一种形式化框架，用于在随机多智能体系统中推理信息透明度属性。我们扩展了概率策略逻辑，引入了新的可观测性操作符来捕捉智能体对时间属性可观测性的程度。我们证明了该逻辑的模型检查问题是可判定的。', 'title_zh': '概率策略逻辑中的可观测性程度分析'}
{'arxiv_id': 'arXiv:2412.15114', 'title': 'Towards Friendly AI: A Comprehensive Review and New Perspectives on Human-AI Alignment', 'authors': 'Qiyang Sun, Yupei Li, Emran Alturki, Sunil Munthumoduku Krishna Murthy, Björn W. Schuller', 'link': 'https://arxiv.org/abs/2412.15114', 'abstract': 'As Artificial Intelligence (AI) continues to advance rapidly, Friendly AI (FAI) has been proposed to advocate for more equitable and fair development of AI. Despite its importance, there is a lack of comprehensive reviews examining FAI from an ethical perspective, as well as limited discussion on its potential applications and future directions. This paper addresses these gaps by providing a thorough review of FAI, focusing on theoretical perspectives both for and against its development, and presenting a formal definition in a clear and accessible format. Key applications are discussed from the perspectives of eXplainable AI (XAI), privacy, fairness and affective computing (AC). Additionally, the paper identifies challenges in current technological advancements and explores future research avenues. The findings emphasise the significance of developing FAI and advocate for its continued advancement to ensure ethical and beneficial AI development.', 'abstract_zh': '随着人工智能（AI）的快速发展，友好人工智能（Friendly AI，FAI）的概念已被提出，以倡导更加公平和公正的人工智能发展。尽管FAI的重要性不言而喻，但目前缺乏从伦理角度进行全面审查的研究，关于其潜在应用和未来发展方向的讨论也相当有限。本文通过提供对FAI的全面回顾来填补这些空白，集中探讨支持和发展FAI的理论视角，同时给出一个简洁明了的正式定义。从可解释人工智能（XAI）、隐私、公平性和情感计算（AC）等关键应用的角度讨论了相关问题。此外，本文还指出了当前技术进步中的挑战，并探讨了未来的研究方向。研究发现强调了开发FAI的重要性，并倡导继续推进FAI的发展，以确保伦理和有益的人工智能发展。', 'title_zh': '通往友好数字助理之路：人类与人工智能一致性综述与新视角'}
{'arxiv_id': 'arXiv:2412.14950', 'title': 'Generalizing Constraint Models in Constraint Acquisition', 'authors': 'Dimos Tsouros, Senne Berden, Steven Prestwich, Tias Guns', 'link': 'https://arxiv.org/abs/2412.14950', 'abstract': 'Constraint Acquisition (CA) aims to widen the use of constraint programming by assisting users in the modeling process. However, most CA methods suffer from a significant drawback: they learn a single set of individual constraints for a specific problem instance, but cannot generalize these constraints to the parameterized constraint specifications of the problem. In this paper, we address this limitation by proposing GenCon, a novel approach to learn parameterized constraint models capable of modeling varying instances of the same problem. To achieve this generalization, we make use of statistical learning techniques at the level of individual constraints. Specifically, we propose to train a classifier to predict, for any possible constraint and parameterization, whether the constraint belongs to the problem. We then show how, for some classes of classifiers, we can extract decision rules to construct interpretable constraint specifications. This enables the generation of ground constraints for any parameter instantiation. Additionally, we present a generate-and-test approach that can be used with any classifier, to generate the ground constraints on the fly. Our empirical results demonstrate that our approach achieves high accuracy and is robust to noise in the input instances.', 'abstract_zh': '约束获取（CA）旨在通过帮助用户在建模过程中使用约束编程来扩大其应用范围。然而，大多数CA方法存在一个显著的缺陷：它们只为特定问题实例学习一组独立的约束，而不能将这些约束泛化到问题的参数化约束规范中。本文通过提出GenCon，一种能够学习参数化约束模型的新方法，来克服这一限制，这些模型能够建模相同问题的不同实例。为了实现这一泛化，我们将在单个约束级别上使用统计学习技术。具体而言，我们提出了一种训练分类器的方法，该分类器可以预测任何可能的约束和参数化情况，该约束是否属于该问题。然后我们展示了对于一些分类器类，我们如何从中提取决策规则以构建可解释的约束规范，从而能够为任何参数实例生成基础约束。此外，我们还提出了一种生成-测试方法，它可以与任何分类器结合使用，实时生成基础约束。我们的实证结果表明，我们的方法具有高准确度，并且对输入实例中的噪声具有鲁棒性。', 'title_zh': '在约束获取中泛化约束模型'}
{'arxiv_id': 'arXiv:2412.14814', 'title': 'Answer Set Networks: Casting Answer Set Programming into Deep Learning', 'authors': 'Arseny Skryagin, Daniel Ochs, Phillip Deibert, Simon Kohaut, Devendra Singh Dhami, Kristian Kersting', 'link': 'https://arxiv.org/abs/2412.14814', 'abstract': 'Although Answer Set Programming (ASP) allows constraining neural-symbolic (NeSy) systems, its employment is hindered by the prohibitive costs of computing stable models and the CPU-bound nature of state-of-the-art solvers. To this end, we propose Answer Set Networks (ASN), a NeSy solver. Based on Graph Neural Networks (GNN), ASNs are a scalable approach to ASP-based Deep Probabilistic Logic Programming (DPPL). Specifically, we show how to translate ASPs into ASNs and demonstrate how ASNs can efficiently solve the encoded problem by leveraging GPU\'s batching and parallelization capabilities. Our experimental evaluations demonstrate that ASNs outperform state-of-the-art CPU-bound NeSy systems on multiple tasks. Simultaneously, we make the following two contributions based on the strengths of ASNs. Namely, we are the first to show the finetuning of Large Language Models (LLM) with DPPLs, employing ASNs to guide the training with logic. Further, we show the "constitutional navigation" of drones, i.e., encoding public aviation laws in an ASN for routing Unmanned Aerial Vehicles in uncertain environments.', 'abstract_zh': '尽管回答集编程（ASP）能够约束神经符号（NeSy）系统，但由于计算稳定模型的高昂成本和最先进的求解器的CPU密集型特性，其应用受到了限制。为此，我们提出了一种NeSy求解器——回答集网络（ASN）。基于图神经网络（GNN），ASN是一种基于ASP的深度概率逻辑编程（DPPL）的可扩展方法。具体来说，我们展示了如何将ASP转换为ASN，并通过利用GPU的批处理和并行化能力，展示了ASN如何高效地解决编码问题。我们的实验评估表明，ASN在多个任务上优于最先进的CPU密集型NeSy系统。同时，基于ASN的优点，我们做出了以下两项贡献。首先，我们首次展示了使用DPPL微调大型语言模型（LLM），利用ASN用逻辑引导训练的过程。其次，我们展示了无人机的“宪法导航”，即在ASN中编码公共航空法，用于在不确定环境中引导无人驾驶飞机的航路规划。', 'title_zh': '基于回答集网络：将回答集编程纳入深度学习'}
{'arxiv_id': 'arXiv:2412.14728', 'title': 'LTLf Synthesis Under Unreliable Input', 'authors': 'Christian Hagemeier, Giuseppe de Giacomo, Moshe Y. Vardi', 'link': 'https://arxiv.org/abs/2412.14728', 'abstract': 'We study the problem of realizing strategies for an LTLf goal specification while ensuring that at least an LTLf backup specification is satisfied in case of unreliability of certain input variables. We formally define the problem and characterize its worst-case complexity as 2EXPTIME-complete, like standard LTLf synthesis. Then we devise three different solution techniques: one based on direct automata manipulation, which is 2EXPTIME, one disregarding unreliable input variables by adopting a belief construction, which is 3EXPTIME, and one leveraging second-order quantified LTLf (QLTLf), which is 2EXPTIME and allows for a direct encoding into monadic second-order logic, which in turn is worst-case nonelementary. We prove their correctness and evaluate them against each other empirically. Interestingly, theoretical worst-case bounds do not translate into observed performance; the MSO technique performs best, followed by belief construction and direct automata manipulation. As a byproduct of our study, we provide a general synthesis procedure for arbitrary QLTLf specifications.', 'abstract_zh': '我们研究了在某些输入变量不可靠的情况下，实现符合LTLf目标规范的策略，同时确保至少满足一个LTLf备份规范的问题。我们形式化地定义了该问题，并将其在最坏情况下的复杂性定为2EXPTIME完全，类似于标准的LTLf综合。然后我们设计了三种不同的解决方案：一种基于直接自动机操作的方法，其复杂性为2EXPTIME；一种通过采用信念构造来忽略不可靠的输入变量，其复杂性为3EXPTIME；以及一种利用量化LTLf（QLTLf），其复杂性为2EXPTIME，并允许直接编码到单调一阶逻辑，这种逻辑在最坏情况下的复杂性是非元素阶的。我们证明了其正确性，并通过实验对其进行相互评估。有趣的是，理论上的最坏情况边界并未转化为实际性能；单调一阶逻辑技术表现最佳，其次是信念构造和直接自动机操作。作为我们研究的副产品，我们提供了一种适用于任意QLTLf规范的综合方法。', 'title_zh': '在不可靠输入下的LTLf合成'}
{'arxiv_id': 'arXiv:2412.14708', 'title': 'Creation of AI-driven Smart Spaces for Enhanced Indoor Environments -- A Survey', 'authors': 'Aygün Varol, Naser Hossein Motlagh, Mirka Leino, Sasu Tarkoma, Johanna Virkki', 'link': 'https://arxiv.org/abs/2412.14708', 'abstract': 'Smart spaces are ubiquitous computing environments that integrate diverse sensing and communication technologies to enhance space functionality, optimize energy utilization, and improve user comfort and well-being. The integration of emerging AI methodologies into these environments facilitates the formation of AI-driven smart spaces, which further enhance functionalities of the spaces by enabling advanced applications such as personalized comfort settings, interactive living spaces, and automatization of the space systems, all resulting in enhanced indoor experiences of the users. In this paper, we present a systematic survey of existing research on the foundational components of AI-driven smart spaces, including sensor technologies, data communication protocols, sensor network management and maintenance strategies, as well as the data collection, processing and analytics. Given the pivotal role of AI in establishing AI-powered smart spaces, we explore the opportunities and challenges associated with traditional machine learning (ML) approaches, such as deep learning (DL), and emerging methodologies including large language models (LLMs). Finally, we provide key insights necessary for the development of AI-driven smart spaces, propose future research directions, and sheds light on the path forward.', 'abstract_zh': '智能空间是集成了多种传感和通信技术的通用计算环境，旨在增强空间功能、优化能源利用并改善用户的舒适度和福祉。将新兴的人工智能方法融入这些环境，促进了以人工智能为驱动力的智能空间的形成，进而通过个性化舒适设置、互动生活空间和空间系统自动化等高级应用，提升了空间的功能，从而为用户提供更好的室内体验。在本文中，我们将对以人工智能为驱动力的智能空间的基础组件进行系统性的综述，包括传感器技术、数据通信协议、传感器网络的管理与维护策略，以及数据采集、处理和分析方法。鉴于人工智能在建立人工智能驱动的智能空间中的关键作用，我们将探讨传统机器学习（ML）方法，尤其是深度学习（DL）以及新兴方法，如大型语言模型（LLMs）所带来的机遇与挑战。最后，我们提供了对于开发人工智能驱动的智能空间至关重要的见解，提出了未来的研究方向，并指明了前进的道路。', 'title_zh': '基于人工智能的智能空间创建：以优化室内环境为目标——一个综述'}
{'arxiv_id': 'arXiv:2412.14684', 'title': 'Bel Esprit: Multi-Agent Framework for Building AI Model Pipelines', 'authors': 'Yunsu Kim, AhmedElmogtaba Abdelaziz, Thiago Castro Ferreira, Mohamed Al-Badrashiny, Hassan Sawaf', 'link': 'https://arxiv.org/abs/2412.14684', 'abstract': 'As the demand for artificial intelligence (AI) grows to address complex real-world tasks, single models are often insufficient, requiring the integration of multiple models into pipelines. This paper introduces Bel Esprit, a conversational agent designed to construct AI model pipelines based on user-defined requirements. Bel Esprit employs a multi-agent framework where subagents collaborate to clarify requirements, build, validate, and populate pipelines with appropriate models. We demonstrate the effectiveness of this framework in generating pipelines from ambiguous user queries, using both human-curated and synthetic data. A detailed error analysis highlights ongoing challenges in pipeline construction. Bel Esprit is available for a free trial at this https URL.', 'abstract_zh': '随着对人工智能（AI）的需求增长，以解决复杂的现实世界任务，单一模型往往不足以应对，需要将多个模型整合到管道中。本文介绍了Bel Esprit，这是一种基于用户定义需求构建AI模型管道的对话式代理。Bel Esprit采用多代理框架，其中子代理协作以澄清需求、构建、验证并用适当模型填充管道。本文通过使用人类整理和合成数据展示了该框架在从模糊用户查询中生成管道方面的有效性。详细的错误分析突显了管道构建过程中持续存在的挑战。用户可以在以下链接免费试用Bel Esprit：[此链接](此链接应具体化为实际可用的URL)。', 'title_zh': '贝尔•埃斯普里特：多Agent框架构建AI模型流水线'}
{'arxiv_id': 'arXiv:2412.14515', 'title': 'Relational Programming with Foundation Models', 'authors': 'Ziyang Li, Jiani Huang, Jason Liu, Felix Zhu, Eric Zhao, William Dodds, Neelay Velingker, Rajeev Alur, Mayur Naik', 'link': 'https://arxiv.org/abs/2412.14515', 'abstract': 'Foundation models have vast potential to enable diverse AI applications. The powerful yet incomplete nature of these models has spurred a wide range of mechanisms to augment them with capabilities such as in-context learning, information retrieval, and code interpreting. We propose Vieira, a declarative framework that unifies these mechanisms in a general solution for programming with foundation models. Vieira follows a probabilistic relational paradigm and treats foundation models as stateless functions with relational inputs and outputs. It supports neuro-symbolic applications by enabling the seamless combination of such models with logic programs, as well as complex, multi-modal applications by streamlining the composition of diverse sub-models. We implement Vieira by extending the Scallop compiler with a foreign interface that supports foundation models as plugins. We implement plugins for 12 foundation models including GPT, CLIP, and SAM. We evaluate Vieira on 9 challenging tasks that span language, vision, and structured and vector databases. Our evaluation shows that programs in Vieira are concise, can incorporate modern foundation models, and have comparable or better accuracy than competitive baselines.', 'abstract_zh': '基础模型具有广泛潜力，能够促进多种AI应用的发展。这些模型虽然强大却不完美，这激发了众多机制的出现，以增强其功能，例如上下文学习、信息检索和代码解释。我们提出了一种名为Vieira的声明性框架，该框架将这些机制统一为编程使用基础模型的通用解决方案。Vieira遵循概率关系范式，并将基础模型视为无状态函数，具有关系型输入和输出。该框架支持神经符号应用，通过使这些模型与逻辑程序无缝结合得以实现，同时也支持通过简化多种子模型的组合来实现复杂、多模态应用。我们通过在Scallop编译器中扩展外部接口来实现Vieira，支持基础模型作为插件。我们为包括GPT、CLIP和SAM在内的12种基础模型实现了插件。我们对Vieira进行了9个富有挑战性的任务的评估，这些任务涵盖了语言、视觉和结构化及向量数据库。评估结果显示，Vieira中的程序简洁，能够集成现代基础模型，并且在与竞争性基线相比时具有相当或更好的准确性。', 'title_zh': '基于基础模型的关联式编程'}
{'arxiv_id': 'arXiv:2412.14500', 'title': 'The Digital Ecosystem of Beliefs: does evolution favour AI over humans?', 'authors': 'David M. Bossens, Shanshan Feng, Yew-Soon Ong', 'link': 'https://arxiv.org/abs/2412.14500', 'abstract': "As AI systems are integrated into social networks, there are AI safety concerns that AI-generated content may dominate the web, e.g. in popularity or impact on this http URL understand such questions, this paper proposes the Digital Ecosystem of Beliefs (Digico), the first evolutionary framework for controlled experimentation with multi-population interactions in simulated social networks. The framework models a population of agents which change their messaging strategies due to evolutionary updates following a Universal Darwinism approach, interact via messages, influence each other's beliefs through dynamics based on a contagion model, and maintain their beliefs through cognitive Lamarckian inheritance. Initial experiments with an abstract implementation of Digico show that: a) when AIs have faster messaging, evolution, and more influence in the recommendation algorithm, they get 80% to 95% of the views, depending on the size of the influence benefit; b) AIs designed for propaganda can typically convince 50% of humans to adopt extreme beliefs, and up to 85% when agents believe only a limited number of channels; c) a penalty for content that violates agents' beliefs reduces propaganda effectiveness by up to 8%. We further discuss implications for control (e.g. legislation) and Digico as a means of studying evolutionary principles.", 'abstract_zh': '随着人工智能系统被整合到社交媒体网络中，存在AI安全问题，即AI生成的内容可能会主导网络，在流行度或影响力方面占据主导地位。为了理解这类问题，本文提出了“信念数字生态系统”（Digico）框架，这是第一个用于模拟社交网络中多群体互动的进化实验控制框架。框架基于广义达尔文主义方法，模拟了一种进化更新机制，使代理改变其信息策略；代理通过信息互动，通过基于传播模型的动力学来影响彼此的信念，并通过认知拉马克式传承来维持其信念。初步实验结果表明：a) 当AI具有更快的信息传递、进化和在推荐算法中更大的影响力时，它们可以占据80%到95%的浏览量，具体比例取决于影响收益的大小；b) 设计用于宣传的AI通常可以说服50%的人类采用极端信念，当代理相信的渠道有限时，这一比例可以达到85%；c) 对违反代理信念的内容施加惩罚可以将宣传效果降低高达8%。我们进一步讨论了控制（例如，立法）及其对Digico作为一种研究进化原则工具的意义。', 'title_zh': '信念的数字化生态系统：进化是倾向于AI还是人类？'}
{'arxiv_id': 'arXiv:2412.14492', 'title': 'FaultExplainer: Leveraging Large Language Models for Interpretable Fault Detection and Diagnosis', 'authors': 'Abdullah Khan, Rahul Nahar, Hao Chen, Gonzalo E. Constante Flores, Can Li', 'link': 'https://arxiv.org/abs/2412.14492', 'abstract': "Machine learning algorithms are increasingly being applied to fault detection and diagnosis (FDD) in chemical processes. However, existing data-driven FDD platforms often lack interpretability for process operators and struggle to identify root causes of previously unseen faults. This paper presents FaultExplainer, an interactive tool designed to improve fault detection, diagnosis, and explanation in the Tennessee Eastman Process (TEP). FaultExplainer integrates real-time sensor data visualization, Principal Component Analysis (PCA)-based fault detection, and identification of top contributing variables within an interactive user interface powered by large language models (LLMs). We evaluate the LLMs' reasoning capabilities in two scenarios: one where historical root causes are provided, and one where they are not to mimic the challenge of previously unseen faults. Experimental results using GPT-4o and o1-preview models demonstrate the system's strengths in generating plausible and actionable explanations, while also highlighting its limitations, including reliance on PCA-selected features and occasional hallucinations.", 'abstract_zh': '机器学习算法在化工过程的故障检测与诊断（FDD）中逐渐得到应用。然而，现有的数据驱动的FDD平台往往缺乏对过程操作者的解释性，并且难以识别以前未见过的故障的根本原因。本文介绍了一种名为FaultExplainer的交互工具，旨在改进Tennessee Eastman过程（TEP）中的故障检测、诊断与解释。FaultExplainer将实时传感器数据可视化、基于主成分分析（PCA）的故障检测以及重要的贡献变量识别集成到一个由大语言模型（LLMs）驱动的交互用户界面中。我们通过两种场景评估了LLMs的推理能力：一种场景是提供历史根本原因，另一种场景是不提供，以模拟以前未见过的故障的挑战。使用GPT-4o和o1-preview模型的实验结果表明，该系统在生成合理的且可操作的解释方面具有优势，同时也指出了它的局限性，包括对PCA选择特征的依赖和偶尔的幻觉现象。', 'title_zh': '故障解释器：利用大型语言模型进行可解释的故障检测与诊断'}
{'arxiv_id': 'arXiv:2412.14491', 'title': 'Mediation Analysis for Probabilities of Causation', 'authors': 'Yuta Kawakami, Jin Tian', 'link': 'https://arxiv.org/abs/2412.14491', 'abstract': 'Probabilities of causation (PoC) offer valuable insights for informed decision-making. This paper introduces novel variants of PoC-controlled direct, natural direct, and natural indirect probability of necessity and sufficiency (PNS). These metrics quantify the necessity and sufficiency of a treatment for producing an outcome, accounting for different causal pathways. We develop identification theorems for these new PoC measures, allowing for their estimation from observational data. We demonstrate the practical application of our results through an analysis of a real-world psychology dataset.', 'abstract_zh': '因果概率（PoC）为基于信息的决策提供了宝贵的见解。本论文介绍了因果概率控制下的新型直接因果概率、自然直接因果概率和自然间接因果必要性和充分性概率（PNS）的新变体。这些度量可以量化治疗对于产生结果的必要性和充分性，并考虑到不同的因果路径。我们开发了这些新PoC度量的识别定理，使得可以从观测数据中估计这些度量。通过分析一个实际的心理学数据集，我们展示了这些结果的实际应用。', 'title_zh': '因果概率中介分析'}
{'arxiv_id': 'arXiv:2412.14485', 'title': 'Towards Projected and Incremental Pseudo-Boolean Model Counting', 'authors': 'Suwei Yang, Kuldeep S. Meel', 'link': 'https://arxiv.org/abs/2412.14485', 'abstract': 'Model counting is a fundamental task that involves determining the number of satisfying assignments to a logical formula, typically in conjunctive normal form (CNF). While CNF model counting has received extensive attention over recent decades, interest in Pseudo-Boolean (PB) model counting is just emerging partly due to the greater flexibility of PB formulas. As such, we observed feature gaps in existing PB counters such as a lack of support for projected and incremental settings, which could hinder adoption.\nIn this work, our main contribution is the introduction of the PB model counter PBCount2, the first exact PB model counter with support for projected and incremental model counting. Our counter, PBCount2, uses our Least Occurrence Weighted Min Degree (LOW-MD) computation ordering heuristic to support projected model counting and a cache mechanism to enable incremental model counting. In our evaluations, PBCount2 completed at least 1.40x the number of benchmarks of competing methods for projected model counting and at least 1.18x of competing methods in incremental model counting.', 'abstract_zh': '模型计数是一个基础任务，涉及确定逻辑公式（通常为合取范式CNF）的有效赋值数量。尽管在最近几十年里CNF模型计数受到了广泛的关注，但由于伪布尔(PB)公式更具灵活性，因此对PB模型计数的兴趣才刚刚兴起。因此，我们观察到现有PB计数器的特征缺口，例如缺乏对投影和增量设置的支持，这可能会阻碍其应用。\n\n在这项工作中，我们主要贡献是引入了首个支持投影和增量模型计数的精确PB计数器——PBCount2。我们的计数器PBCount2使用了我们的最少出现加权最小度(LOW-MD)计算顺序启发式算法，以支持投影模型计数，并使用了缓存机制以实现增量模型计数。在我们的评估中，PBCount2在投影模型计数方面比竞争方法至少完成了1.40倍的基准测试，在增量模型计数方面至少比竞争方法完成了1.18倍的基准测试。', 'title_zh': '面向投影和增量伪布尔模型计数'}
{'arxiv_id': 'arXiv:2412.14409', 'title': 'Multi-task Representation Learning for Mixed Integer Linear Programming', 'authors': 'Junyang Cai, Taoan Huang, Bistra Dilkina', 'link': 'https://arxiv.org/abs/2412.14409', 'abstract': 'Mixed Integer Linear Programs (MILPs) are highly flexible and powerful tools for modeling and solving complex real-world combinatorial optimization problems. Recently, machine learning (ML)-guided approaches have demonstrated significant potential in improving MILP-solving efficiency. However, these methods typically rely on separate offline data collection and training processes, which limits their scalability and adaptability. This paper introduces the first multi-task learning framework for ML-guided MILP solving. The proposed framework provides MILP embeddings helpful in guiding MILP solving across solvers (e.g., Gurobi and SCIP) and across tasks (e.g., Branching and Solver configuration). Through extensive experiments on three widely used MILP benchmarks, we demonstrate that our multi-task learning model performs similarly to specialized models within the same distribution. Moreover, it significantly outperforms them in generalization across problem sizes and tasks.', 'abstract_zh': '混合整数线性规划（MILPs）是建模和解决复杂现实世界组合优化问题的高度灵活且强大的工具。近年来，机器学习（ML）引导的方法展示了在提高MILP求解效率方面的巨大潜力。然而，这些方法通常依赖于单独的离线数据收集和训练过程，这限制了它们的可扩展性和适应性。本文介绍了首个针对ML引导MILP求解的多任务学习框架。所提出的框架提供了在不同求解器（如Gurobi和SCIP）和不同任务（如分支策略和求解器配置）下指导MILP求解的MILP嵌入。通过对三个广泛使用的MILP基准测试进行广泛实验，我们证明了我们的多任务学习模型在性能上与相同分布下的专门模型相当，而且在问题规模和任务上的泛化能力显著优于它们。', 'title_zh': '混合整数线性规划的多任务表示学习'}
{'arxiv_id': 'arXiv:2412.14387', 'title': 'Clinical Trials Ontology Engineering with Large Language Models', 'authors': 'Berkan Çakır', 'link': 'https://arxiv.org/abs/2412.14387', 'abstract': 'Managing clinical trial information is currently a significant challenge for the medical industry, as traditional methods are both time-consuming and costly. This paper proposes a simple yet effective methodology to extract and integrate clinical trial data in a cost-effective and time-efficient manner. Allowing the medical industry to stay up-to-date with medical developments. Comparing time, cost, and quality of the ontologies created by humans, GPT3.5, GPT4, and Llama3 (8b & 70b). Findings suggest that large language models (LLM) are a viable option to automate this process both from a cost and time perspective. This study underscores significant implications for medical research where real-time data integration from clinical trials could become the norm.', 'abstract_zh': '当前，临床试验信息管理对医疗行业来说是一项重要的挑战，因为传统方法既耗时又昂贵。本文提出了一种简单而有效的方法，以经济高效且节省时间的方式提取和整合临床试验数据，使医疗行业能够及时了解医学进展。本研究比较了由人类、GPT3.5、GPT4 和 Llama3（8b 和 70b 版本）创建的本体的时间、成本和质量。研究结果表明，大型语言模型（LLM）从成本和时间角度看都是实现这一过程的可行选项。本研究强调了对医学研究的重大意义，即实时整合临床试验数据有望成为常态。', 'title_zh': '使用大型语言模型进行临床试验本体工程'}
{'arxiv_id': 'arXiv:2412.14382', 'title': 'Balans: Multi-Armed Bandits-based Adaptive Large Neighborhood Search for Mixed-Integer Programming Problem', 'authors': 'Junyang Cai, Serdar Kadioglu, Bistra Dilkina', 'link': 'https://arxiv.org/abs/2412.14382', 'abstract': 'Mixed-Integer Programming (MIP) is a powerful paradigm for modeling and solving various important combinatorial optimization problems. Recently, learning-based approaches have shown potential to speed up MIP solving via offline training that then guides important design decisions during search. However, a significant drawback of these methods is their heavy reliance on offline training, which requires collecting training datasets and computationally costly training epochs yet offering only limited generalization to unseen (larger) instances. In this paper, we propose Balans, an adaptive meta-solver for MIPs with online learning capability that does not require any supervision or apriori training. At its core, Balans is based on adaptive large-neighborhood search, operating on top of a MIP solver by successive applications of destroy and repair neighborhood operators. During the search, the selection among different neighborhood definitions is guided on the fly for the instance at hand via multi-armed bandit algorithms. Our extensive experiments on hard optimization instances show that Balans offers significant performance gains over the default MIP solver, is better than committing to any single best neighborhood, and improves over the state-of-the-art large-neighborhood search for MIPs. Finally, we release Balans as a highly configurable, MIP solver agnostic, open-source software.', 'abstract_zh': '混合整数规划（MIP）是一种用于建模和解决各种重要组合优化问题的强大范式。近年来，基于学习的方法展示出通过离线训练加速MIP求解的潜力，从而在搜索过程中引导关键设计决策。然而，这些方法的一个显著缺点是它们对离线训练的重度依赖，需要收集训练数据集并在计算成本高昂的训练周期中进行训练，但仅能对未见过（更大规模）的问题实例提供有限的泛化能力。在本文中，我们提出了Balans，这是一种具有在线学习能力的自适应元求解器，不需要任何监督或先验训练。其核心基于自适应的大邻域搜索，通过逐步应用破坏和修复邻域操作符作用于MIP求解器之上。在搜索过程中，通过多臂赌博机算法实时引导针对当前实例选择不同邻域定义。我们在广泛的难优化实例上的实验结果显示，Balans 在性能上优于默认的MIP求解器，优于任何单一最优邻域的固定选择，并且优于当前最先进的MIP的大邻域搜索方法。最后，我们发布了Balans，作为高度可配置的、与MIP求解器无关的开源软件。', 'title_zh': 'Balans：基于multi-armed bandits的自适应大规模邻域搜索方法用于解决混合整数规划问题'}
{'arxiv_id': 'arXiv:2412.14372', 'title': 'Python Agent in Ludii', 'authors': 'Izaias S. de Lima Neto, Marco A. A. de Aguiar Vieira, Anderson R. Tavares', 'link': 'https://arxiv.org/abs/2412.14372', 'abstract': 'Ludii is a Java general game system with a considerable number of board games, with an API for developing new agents and a game description language to create new games. To improve versatility and ease development, we provide Python interfaces for agent programming. This allows the use of Python modules to implement general game playing agents.\nAs a means of enabling Python for creating Ludii agents, the interfaces are implemented using different Java libraries: jpy and Py4J. The main goal of this work is to determine which version is faster. To do so, we conducted a performance analysis of two different GGP algorithms, Minimax adapted to GGP and MCTS. The analysis was performed across several combinatorial games with varying depth, branching factor, and ply time. For reproducibility, we provide tutorials and repositories.\nOur analysis includes predictive models using regression, which suggest that jpy is faster than Py4J, however slower than a native Java Ludii agent, as expected.', 'abstract_zh': 'Ludii 是一个用 Java 编写的通用游戏系统，包含了大量的桌面游戏，并提供了一个开发新代理的 API 和一个游戏描述语言以创建新游戏。为了提高灵活性和简化开发过程，我们提供了 Python 接口以供代理编程使用。这使得可以使用 Python 模块来实现通用游戏代理。\n\n为了使 Python 能够创建 Ludii 代理，我们使用不同的 Java 库（jpy 和 Py4J）实现了这些接口。本工作的主要目标是确定哪个版本更快。为此，我们对两种不同的通用游戏竞技场（General Game Playing, GGP）算法（适应 GGP 的 Minimax 和 Monte Carlo Tree Search (MCTS)）进行了性能分析。分析在具有不同深度、分支因子和搜索步长的不同组合游戏上进行。\n\n为了保证可再现性，我们还提供了教程和代码仓库。我们的分析包括使用回归模型建立的预测模型，结果表明 jpy 的速度超过 Py4J，但仍然慢于原生的 Java Ludii 代理，这与预期相符。', 'title_zh': 'Python 代理在 Ludii 中的应用'}
{'arxiv_id': 'arXiv:2412.15212', 'title': 'Scaling 4D Representations', 'authors': 'João Carreira, Dilara Gokay, Michael King, Chuhan Zhang, Ignacio Rocco, Aravindh Mahendran, Thomas Albert Keck, Joseph Heyward, Skanda Koppula, Etienne Pot, Goker Erdogan, Yana Hasson, Yi Yang, Klaus Greff, Guillaume Le Moing, Sjoerd van Steenkiste, Daniel Zoran, Drew A. Hudson, Pedro Vélez, Luisa Polanía, Luke Friedman, Chris Duvarney, Ross Goroshin, Kelsey Allen, Jacob Walker, Rishabh Kabra, Eric Aboussouan, Jennifer Sun, Thomas Kipf, Carl Doersch, Viorica Pătrăucean, Dima Damen, Pauline Luc, Mehdi S. M. Sajjadi, Andrew Zisserman', 'link': 'https://arxiv.org/abs/2412.15212', 'abstract': 'Scaling has not yet been convincingly demonstrated for pure self-supervised learning from video. However, prior work has focused evaluations on semantic-related tasks $\\unicode{x2013}$ action classification, ImageNet classification, etc. In this paper we focus on evaluating self-supervised learning on non-semantic vision tasks that are more spatial (3D) and temporal (+1D = 4D), such as camera pose estimation, point and object tracking, and depth estimation. We show that by learning from very large video datasets, masked auto-encoding (MAE) with transformer video models actually scales, consistently improving performance on these 4D tasks, as model size increases from 20M all the way to the largest by far reported self-supervised video model $\\unicode{x2013}$ 22B parameters. Rigorous apples-to-apples comparison with many recent image and video models demonstrates the benefits of scaling 4D representations.', 'abstract_zh': '纯自我监督学习从视频中尚未被令人信服地证明具有扩展性。然而，先前的工作主要集中在语义相关的任务上，例如动作分类、ImageNet分类等。在本文中，我们关注自我监督学习在非语义视觉任务上的评估，这些任务更具空间性（3D）和时间性（+1D = 4D），例如相机位姿估计、点和对象跟踪以及深度估计。我们通过学习非常大的视频数据集表明，掩码自编码（MAE）与变压器视频模型实际上是可以扩展的，在模型规模从20M增加到迄今为止报道的最大自我监督视频模型（22B参数）的过程中，这些4D任务的性能得到了一致的提升。与许多最近的图像和视频模型进行严格的同对同比较，证明了扩展4D表示的益处。', 'title_zh': '4D表示的扩展'}
{'arxiv_id': 'arXiv:2412.15209', 'title': 'PRIMA: Multi-Image Vision-Language Models for Reasoning Segmentation', 'authors': 'Muntasir Wahed, Kiet A. Nguyen, Adheesh Sunil Juvekar, Xinzhuo Li, Xiaona Zhou, Vedant Shah, Tianjiao Yu, Pinar Yanardag, Ismini Lourentzou', 'link': 'https://arxiv.org/abs/2412.15209', 'abstract': 'Despite significant advancements in Large Vision-Language Models (LVLMs), existing pixel-grounding models operate on single-image settings, limiting their ability to perform detailed, fine-grained comparisons across multiple images. Conversely, current multi-image understanding models lack pixel-level grounding. Our work addresses this gap by introducing the task of multi-image pixel-grounded reasoning segmentation, and PRIMA, a novel LVLM that integrates pixel-level grounding with robust multi-image reasoning capabilities to produce contextually rich, pixel-grounded explanations. Central to PRIMA is an efficient vision module that queries fine-grained visual representations across multiple images, reducing TFLOPs by $25.3\\%$. To support training and evaluation, we curate $M^4Seg$, a new reasoning segmentation benchmark consisting of $\\sim$224K question-answer pairs that require fine-grained visual understanding across multiple images. Experimental results demonstrate PRIMA outperforms state-of-the-art baselines.', 'abstract_zh': '尽管在大型多模态模型（Large Vision-Language Models, LVLMs）方面取得了显著进步，现有的像素定位模型仅限于单图像设置，这限制了它们在多个图像之间进行详细的、精细粒度的比较的能力。相比之下，当前的多图像理解模型缺乏像素级别的定位能力。我们的工作通过引入多图像像素定位推理分割任务来填补这一空白，并提出了一个名为PRIMA的新LVLM，该模型结合了像素级别定位与稳健的多图像推理能力，从而产生具有丰富上下文的像素定位解释。PRIMA的核心是一个高效的视觉模块，该模块能够在多个图像中查询精细粒度的视觉表示，进而减少TFLOPs消耗25.3%。为了支持训练和评估，我们构建了M^4Seg基准数据集，该数据集包含约224K个问答对，要求进行跨多张图像的精细视觉理解。实验结果表明，PRIMA在与现有最先进的模型进行比较时表现出更高的性能。', 'title_zh': 'PRIMA：多图像视觉-语言推理分割模型'}
{'arxiv_id': 'arXiv:2412.15204', 'title': 'LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks', 'authors': 'Yushi Bai, Shangqing Tu, Jiajie Zhang, Hao Peng, Xiaozhi Wang, Xin Lv, Shulin Cao, Jiazheng Xu, Lei Hou, Yuxiao Dong, Jie Tang, Juanzi Li', 'link': 'https://arxiv.org/abs/2412.15204', 'abstract': 'This paper introduces LongBench v2, a benchmark designed to assess the ability of LLMs to handle long-context problems requiring deep understanding and reasoning across real-world multitasks. LongBench v2 consists of 503 challenging multiple-choice questions, with contexts ranging from 8k to 2M words, across six major task categories: single-document QA, multi-document QA, long in-context learning, long-dialogue history understanding, code repository understanding, and long structured data understanding. To ensure the breadth and the practicality, we collect data from nearly 100 highly educated individuals with diverse professional backgrounds. We employ both automated and manual review processes to maintain high quality and difficulty, resulting in human experts achieving only 53.7% accuracy under a 15-minute time constraint. Our evaluation reveals that the best-performing model, when directly answers the questions, achieves only 50.1% accuracy. In contrast, the o1-preview model, which includes longer reasoning, achieves 57.7%, surpassing the human baseline by 4%. These results highlight the importance of enhanced reasoning ability and scaling inference-time compute to tackle the long-context challenges in LongBench v2. The project is available at this https URL.', 'abstract_zh': '本文介绍了LongBench v2，这是一个基准测试，旨在评估大型语言模型处理需要深入理解和推理的长上下文问题的能力，特别是在现实世界多任务中的表现。LongBench v2 包含503个具有挑战性的选择题，上下文长度从8千词到2百万词不等，涵盖了六个主要任务类别：单文档问答、多文档问答、长上下文学习、长对话历史理解、代码库理解以及长结构化数据理解。为了确保涵盖面和实用性，我们从近100位具有多元化专业背景的高学历个体中收集数据。我们采用自动和人工审核相结合的方式，以保持高质量和难度，最终在15分钟的时间约束条件下，人类专家的准确率为53.7%。我们的评估结果显示，表现最佳的模型直接回答问题的准确率为50.1%。相比之下，包括更长推理过程的o1-preview模型的准确率为57.7%，超过了人类基准4%。这些结果突显了增强推理能力和扩展推理时间计算资源在解决LongBench v2中的长上下文挑战方面的重要性。该项目可在以下链接访问：this https URL', 'title_zh': '长任务基准 v2：对现实场景中长上下文多任务的理解与推理的深入探索'}
{'arxiv_id': 'arXiv:2412.15200', 'title': 'DI-PCG: Diffusion-based Efficient Inverse Procedural Content Generation for High-quality 3D Asset Creation', 'authors': 'Wang Zhao, Yan-Pei Cao, Jiale Xu, Yuejiang Dong, Ying Shan', 'link': 'https://arxiv.org/abs/2412.15200', 'abstract': 'Procedural Content Generation (PCG) is powerful in creating high-quality 3D contents, yet controlling it to produce desired shapes is difficult and often requires extensive parameter tuning. Inverse Procedural Content Generation aims to automatically find the best parameters under the input condition. However, existing sampling-based and neural network-based methods still suffer from numerous sample iterations or limited controllability. In this work, we present DI-PCG, a novel and efficient method for Inverse PCG from general image conditions. At its core is a lightweight diffusion transformer model, where PCG parameters are directly treated as the denoising target and the observed images as conditions to control parameter generation. DI-PCG is efficient and effective. With only 7.6M network parameters and 30 GPU hours to train, it demonstrates superior performance in recovering parameters accurately, and generalizing well to in-the-wild images. Quantitative and qualitative experiment results validate the effectiveness of DI-PCG in inverse PCG and image-to-3D generation tasks. DI-PCG offers a promising approach for efficient inverse PCG and represents a valuable exploration step towards a 3D generation path that models how to construct a 3D asset using parametric models.', 'abstract_zh': '程序化内容生成（PCG）在创建高质量3D内容方面具有强大的功能，但要控制其生成所需的特定形状却困难重重，往往需要进行广泛的参数调整。逆向程序化内容生成旨在在给定输入条件下自动找到最佳参数。然而，现有的基于采样和基于神经网络的方法仍然面临着大量的采样迭代或控制力有限的问题。在本工作中，我们提出了一种名为DI-PCG的新型高效方法，用于在一般图像条件下进行逆向PCG。其核心是一个轻量级的扩散变换器模型，其中PCG参数直接作为去噪目标，并将观测图像作为控制参数生成的条件。DI-PCG高效且有效。仅需7.6M的网络参数和30个GPU小时的训练时间，它在准确恢复参数以及在野外图像上的泛化能力上表现出色。定量和定性的实验结果验证了DI-PCG在逆向PCG和图像至3D生成任务中的有效性。DI-PCG 提供了一种有效的逆向PCG方法，并代表了朝着使用参数模型构造3D资产的3D生成路径中的一次有价值的研究进展。', 'title_zh': 'DI-PCG：基于扩散模型的有效逆过程内容生成方法及其在高质量3D资产创建中的应用'}
{'arxiv_id': 'arXiv:2412.15188', 'title': 'LlamaFusion: Adapting Pretrained Language Models for Multimodal Generation', 'authors': 'Weijia Shi, Xiaochuang Han, Chunting Zhou, Weixin Liang, Xi Victoria Lin, Luke Zettlemoyer, Lili Yu', 'link': 'https://arxiv.org/abs/2412.15188', 'abstract': "We present LlamaFusion, a framework for empowering pretrained text-only large language models (LLMs) with multimodal generative capabilities, enabling them to understand and generate both text and images in arbitrary sequences. LlamaFusion leverages existing Llama-3's weights for processing texts autoregressively while introducing additional and parallel transformer modules for processing images with diffusion. During training, the data from each modality is routed to its dedicated modules: modality-specific feedforward layers, query-key-value projections, and normalization layers process each modality independently, while the shared self-attention layers allow interactions across text and image features. By freezing the text-specific modules and only training the image-specific modules, LlamaFusion preserves the language capabilities of text-only LLMs while developing strong visual understanding and generation abilities. Compared to methods that pretrain multimodal generative models from scratch, our experiments demonstrate that, LlamaFusion improves image understanding by 20% and image generation by 3.6% using only 50% of the FLOPs while maintaining Llama-3's language capabilities. We also demonstrate that this framework can adapt existing vision-language models with multimodal generation ability. Overall, this framework not only leverages existing computational investments in text-only LLMs but also enables the parallel development of language and vision capabilities, presenting a promising direction for efficient multimodal model development.", 'abstract_zh': '我们提出了LlamaFusion，这是一种框架，旨在为预训练的纯文本大型语言模型（LLMs）赋予多模态生成能力，使它们能够理解和生成任意序列的文字和图像。LlamaFusion 通过利用现有Llama-3的权重进行自回归文本处理，同时引入额外并行的变换器模块来处理带有扩散处理的图像。在训练过程中，每种模态的数据被路由到其专用模块：特定于模态的前馈层、查询-键-值投影和规范化层独立处理每个模态，而共享的自注意力层则允许文本和图像特征之间的交互。通过冻结特定于文本的模块并在仅训练特定于图像的模块的同时进行训练，LlamaFusion 保持了纯文本LLMs的语言能力，同时发展了强大的视觉理解和生成能力。与从头开始预训练多模态生成模型的方法相比，我们的实验表明，LlamaFusion 仅使用50%的FLOPs，就能将图像理解提高20%，图像生成提高3.6%，同时保持Llama-3的语言能力。此外，我们还证明了此框架可以适应具有多模态生成能力的现有视觉-语言模型。总体而言，该框架不仅利用了纯文本LLMs现有的计算投资，还并行发展了语言和视觉能力，呈现出一种有效的多模态模型开发的有前途的方向。', 'title_zh': 'LlamaFusion： adapting 预训练语言模型以实现多模态生成\n\n为了更符合学术规范和中文表达习惯，可以进一步优化为：\n\nLlamaFusion：基于预训练语言模型的多模态生成adaptation'}
{'arxiv_id': 'arXiv:2412.15166', 'title': 'Human-Humanoid Robots Cross-Embodiment Behavior-Skill Transfer Using Decomposed Adversarial Learning from Demonstration', 'authors': 'Junjia Liu, Zhuo Li, Minghao Yu, Zhipeng Dong, Sylvain Calinon, Darwin Caldwell, Fei Chen', 'link': 'https://arxiv.org/abs/2412.15166', 'abstract': 'Humanoid robots are envisioned as embodied intelligent agents capable of performing a wide range of human-level loco-manipulation tasks, particularly in scenarios requiring strenuous and repetitive labor. However, learning these skills is challenging due to the high degrees of freedom of humanoid robots, and collecting sufficient training data for humanoid is a laborious process. Given the rapid introduction of new humanoid platforms, a cross-embodiment framework that allows generalizable skill transfer is becoming increasingly critical. To address this, we propose a transferable framework that reduces the data bottleneck by using a unified digital human model as a common prototype and bypassing the need for re-training on every new robot platform. The model learns behavior primitives from human demonstrations through adversarial imitation, and the complex robot structures are decomposed into functional components, each trained independently and dynamically coordinated. Task generalization is achieved through a human-object interaction graph, and skills are transferred to different robots via embodiment-specific kinematic motion retargeting and dynamic fine-tuning. Our framework is validated on five humanoid robots with diverse configurations, demonstrating stable loco-manipulation and highlighting its effectiveness in reducing data requirements and increasing the efficiency of skill transfer across platforms.', 'abstract_zh': '类人机器人被设想为能够在广泛的人类级别移动和操作任务中体现智能的代理，尤其是在需要繁重且重复劳动的场景中。然而，学习这些技能具有挑战性，因为类人机器人的自由度非常高，而收集足够的训练数据对于类人机器人来说是一个繁琐的过程。随着新型类人平台的快速涌现，一种跨体感框架变得愈加关键，该框架能够实现可迁移技能的通用化。为了解决这一问题，我们提出了一种可迁移框架，通过使用统一的数字人类模型作为通用原型并跳过针对每个新机器人平台重新训练的需求，从而减轻了数据瓶颈。该模型通过对抗性模仿从人类示范中学习行为原型，并将复杂的机器人结构分解为功能组件，每个组件独立训练并在动态协调中工作。通过人类-物体互作用图实现任务泛化，通过体感特定的运动重定位和动态微调将技能转移到不同的机器人上。我们的框架在五个具有不同配置的机器人上进行了验证，展示了稳定的移动和操作能力，并突显了其在减少数据需求和提高跨平台技能转移效率方面的作用。', 'title_zh': '人类-类人机器人跨躯体行为-技能转移：分解对抗学习示范研究'}
{'arxiv_id': 'arXiv:2412.15163', 'title': 'Operationalising Rawlsian Ethics for Fairness in Norm-Learning Agents', 'authors': 'Jessica Woodgate, Paul Marshall, Nirav Ajmeri', 'link': 'https://arxiv.org/abs/2412.15163', 'abstract': 'Social norms are standards of behaviour common in a society. However, when agents make decisions without considering how others are impacted, norms can emerge that lead to the subjugation of certain agents. We present RAWL-E, a method to create ethical norm-learning agents. RAWL-E agents operationalise maximin, a fairness principle from Rawlsian ethics, in their decision-making processes to promote ethical norms by balancing societal well-being with individual goals. We evaluate RAWL-E agents in simulated harvesting scenarios. We find that norms emerging in RAWL-E agent societies enhance social welfare, fairness, and robustness, and yield higher minimum experience compared to those that emerge in agent societies that do not implement Rawlsian ethics.', 'abstract_zh': '社会规范是指社会中普遍存在的行为标准。然而，当个体在做出决策时不考虑对他人产生的影响时，可能会出现一些导致某些个体被压制的规范。我们提出了一种名为RAWL-E的方法，用于创建可学习伦理规范的智能体。RAWL-E智能体在其决策过程中运用拉尔夫森伦理学中的最大化最小利益原则，以平衡社会效益与个人目标，从而促进伦理规范的形成。我们在模拟的采集场景中评估了RAWL-E智能体的表现。研究结果表明，RAWL-E社会中形成的规范能够提高社会福利、公平性和鲁棒性，并且相比不实施拉尔夫森伦理学的社会智能体，其最低经验水平也更高。', 'title_zh': '将罗尔斯伦理学应用于规范学习代理的公平性操作化'}
{'arxiv_id': 'arXiv:2412.15151', 'title': 'Language Models as Continuous Self-Evolving Data Engineers', 'authors': 'Peidong Wang, Ming Wang, Zhiming Ma, Xiaocui Yang, Shi Feng, Daling Wang, Yifei Zhang', 'link': 'https://arxiv.org/abs/2412.15151', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable capabilities on various tasks, while the further evolvement is limited to the lack of high-quality training data. In addition, traditional training approaches rely too much on expert-labeled data, setting an upper limit on the performance of LLMs. To address this issue, we propose a novel paradigm that enables LLMs to train itself by autonomously generating, cleaning, reviewing, and annotating data with preference information, named LANCE. Our approach demonstrates that LLMs can serve as continuous self-evolving data engineers, significantly reducing the time and cost of the post-training data construction process. Through iterative fine-tuning on different variants of the Qwen2, we validate the effectiveness of LANCE across various tasks, showing that it can continuously improve model performance and maintain high-quality data generation. Across eight benchmark dimensions, LANCE resulted in an average score enhancement of 3.36 for Qwen2-7B and 2.70 for Qwen2-7B-Instruct. This training paradigm with autonomous data construction not only reduces the reliance on human experts or external models but also ensures that the data aligns with human values and preferences, paving the way for the development of future superintelligent systems that can exceed human capabilities.', 'abstract_zh': '大型语言模型（LLMs）在多种任务中展现出了显著的能力，但其进一步发展受限于高质量训练数据的缺乏。此外，传统的训练方法过于依赖专家标注的数据，限制了LLMs的性能。为应对这一问题，我们提出了一种新的范式，使LLMs能够自主生成、清洗、审核和标注带偏好信息的数据，并将其命名为LANCE。我们的方法表明，LLMs可以作为持续自我演进的数据工程师，显著减少了数据构建后处理所需的时间和成本。通过在不同版本的Qwen2上进行迭代微调，我们验证了LANCE在各种任务中的有效性，展示了其可以持续提升模型性能并保持高质量数据生成的能力。在八个基准维度上，LANCE分别提高了Qwen2-7B和Qwen2-7B-Instruct的平均分数3.36和2.70。这种自主数据构建的训练范式不仅减少了对人工专家或外部模型的依赖，还确保了数据与人类价值观和偏好相一致，为开发未来超越人类能力的超智能系统奠定了基础。', 'title_zh': '语言模型作为连续自我进化的数据工程师'}
{'arxiv_id': 'arXiv:2412.15150', 'title': 'Leveraging Color Channel Independence for Improved Unsupervised Object Detection', 'authors': 'Bastian Jäckl, Yannick Metz, Udo Schlegel, Daniel A. Keim, Maximilian T. Fischer', 'link': 'https://arxiv.org/abs/2412.15150', 'abstract': "Object-centric architectures can learn to extract distinct object representations from visual scenes, enabling downstream applications on the object level. Similarly to autoencoder-based image models, object-centric approaches have been trained on the unsupervised reconstruction loss of images encoded by RGB color spaces. In our work, we challenge the common assumption that RGB images are the optimal color space for unsupervised learning in computer vision. We discuss conceptually and empirically that other color spaces, such as HSV, bear essential characteristics for object-centric representation learning, like robustness to lighting conditions. We further show that models improve when requiring them to predict additional color channels. Specifically, we propose to transform the predicted targets to the RGB-S space, which extends RGB with HSV's saturation component and leads to markedly better reconstruction and disentanglement for five common evaluation datasets. The use of composite color spaces can be implemented with basically no computational overhead, is agnostic of the models' architecture, and is universally applicable across a wide range of visual computing tasks and training types. The findings of our approach encourage additional investigations in computer vision tasks beyond object-centric learning.", 'abstract_zh': '以对象为中心的架构可以从视觉场景中学习提取独特的对象表示，从而在对象级别上启用下游应用。类似于基于自编码器的图像模型，以对象为中心的方法是通过RGB颜色空间编码的图像无监督重建损失来训练的。在我们的研究中，我们挑战了在计算机视觉中RGB图像是最优颜色空间用于无监督学习这一常见假设。我们从概念和实验上讨论了其他颜色空间，如HSV，这些颜色空间具有对光照条件具有鲁棒性的关键特性，有利于对象为中心的表示学习。我们还展示了当要求模型预测额外的颜色通道时，模型性能会得到提升。具体来说，我们提出将预测目标转换到RGB-S色彩空间，该空间在RGB的基础上加入了HSV的饱和度分量，从而在五个常用评估数据集上显著提高了重建和分离效果。使用复合色彩空间基本不需要增加计算成本，对模型架构具有鲁棒性，并且可以在广泛范围的视觉计算任务和训练类型中普遍应用。我们方法的研究发现鼓励在对象为中心学习之外进一步探索计算机视觉任务。', 'title_zh': '利用颜色通道独立性以提高无监督物体检测性能'}
{'arxiv_id': 'arXiv:2412.15129', 'title': 'Jet: A Modern Transformer-Based Normalizing Flow', 'authors': 'Alexander Kolesnikov, André Susano Pinto, Michael Tschannen', 'link': 'https://arxiv.org/abs/2412.15129', 'abstract': 'In the past, normalizing generative flows have emerged as a promising class of generative models for natural images. This type of model has many modeling advantages: the ability to efficiently compute log-likelihood of the input data, fast generation and simple overall structure. Normalizing flows remained a topic of active research but later fell out of favor, as visual quality of the samples was not competitive with other model classes, such as GANs, VQ-VAE-based approaches or diffusion models. In this paper we revisit the design of the coupling-based normalizing flow models by carefully ablating prior design choices and using computational blocks based on the Vision Transformer architecture, not convolutional neural networks. As a result, we achieve state-of-the-art quantitative and qualitative performance with a much simpler architecture. While the overall visual quality is still behind the current state-of-the-art models, we argue that strong normalizing flow models can help advancing research frontier by serving as building components of more powerful generative models.', 'abstract_zh': '在过去的研究中，归一化生成流动（Normalizing Flows）已经展现出生成自然图像的一种有前途的模型类别。这类模型具有许多建模优势：能够高效计算输入数据的对数似然，快速生成，并具有简洁的整体结构。虽然归一化流动模型仍然是一个受关注的研究课题，但在后来的研究中，由于生成样本的视觉质量与GAN、基于VQ-VAE的方法或扩散模型相比不够竞争，研究兴趣有所下降。在本文中，我们重新审视基于耦合的归一化流动模型的设计，通过仔细剖析先前的设计选择并采用基于视觉变换器（Vision Transformer）架构的计算块，而不是卷积神经网络，取得了最先进的定量和定性性能，同时模型结构更为简单。尽管总体的视觉质量仍落后于当前最先进的模型，我们认为强大的归一化流动模型可以作为更强大生成模型构建组件，从而促进研究前沿的发展。', 'title_zh': '《Jet：一种基于变压器的现代规范化流》'}
{'arxiv_id': 'arXiv:2412.15127', 'title': 'Adaptive Pruning for Large Language Models with Structural Importance Awareness', 'authors': 'Haotian Zheng, Jinke Ren, Yushan Sun, Ruichen Zhang, Wenbo Zhang, Zhen Li, Dusit Niyato, Shuguang Cui, Yatong Han', 'link': 'https://arxiv.org/abs/2412.15127', 'abstract': 'The recent advancements in large language models (LLMs) have significantly improved language understanding and generation capabilities. However, it is difficult to deploy LLMs on resource-constrained edge devices due to their high computational and storage resource demands. To address this issue, we propose a novel LLM model pruning method, namely structurally-aware adaptive pruning (SAAP), to significantly reduce the computational and memory costs while maintaining model performance. We first define an adaptive importance fusion metric to evaluate the importance of all coupled structures in LLMs by considering their homoscedastic uncertainty. Then, we rank the importance of all modules to determine the specific layers that should be pruned to meet particular performance requirements. Furthermore, we develop a new group fine-tuning strategy to improve the inference efficiency of LLMs. Finally, we evaluate the proposed SAAP method on multiple LLMs across two common tasks, i.e., zero-shot classification and text generation. Experimental results show that our SAAP method outperforms several state-of-the-art baseline methods, achieving 2.17%, 2.37%, and 2.39% accuracy gains on LLaMA-7B, Vicuna-7B, and LLaMA-13B. Additionally, SAAP improves the token generation speed by 5%, showcasing its practical advantages in resource-constrained scenarios.', 'abstract_zh': '近年来，大型语言模型（LLMs）在语言理解和生成能力方面取得了显著进展。然而，由于其对计算和存储资源的高需求，很难在资源受限的边缘设备上部署LLMs。为了解决这一问题，我们提出了一种新颖的LLM模型剪枝方法，即结构感知自适应剪枝（SAAP），能够在显著降低计算和内存成本的同时保持模型性能。首先，我们定义了一个自适应重要性融合度量，通过考虑它们的同方差不确定性来评估LLMs中所有耦合结构的重要性。然后，我们对所有模块的重要性进行排序，以确定应进行剪枝的具体层，以满足特定的性能要求。此外，我们开发了一种新的分组微调策略，以提高LLMs的推理效率。最后，我们在两个常见任务，即零样本分类和文本生成上，对多个LLMs评估了所提出的SAAP方法。实验结果表明，我们的SAAP方法优于几种最先进的基线方法，分别在LLaMA-7B、Vicuna-7B和LLaMA-13B上实现了2.17%、2.37%和2.39%的准确率提升。此外，SAAP还将单词生成速度提高了5%，展示了其在资源受限场景中的实际优势。', 'title_zh': '具有结构重要性意识的大型语言模型自适应剪枝'}
{'arxiv_id': 'arXiv:2412.15118', 'title': 'Outcome-Refining Process Supervision for Code Generation', 'authors': 'Zhuohao Yu, Weizheng Gu, Yidong Wang, Zhengran Zeng, Jindong Wang, Wei Ye, Shikun Zhang', 'link': 'https://arxiv.org/abs/2412.15118', 'abstract': 'Large Language Models have demonstrated remarkable capabilities in code generation, yet they often struggle with complex programming tasks that require deep algorithmic reasoning. While process supervision through learned reward models shows promise in guiding reasoning steps, it requires expensive training data and suffers from unreliable evaluation. We propose Outcome-Refining Process Supervision, a novel paradigm that treats outcome refinement itself as the process to be supervised. Our framework leverages concrete execution signals to ground the supervision of reasoning steps, while using tree-structured exploration to maintain multiple solution trajectories simultaneously. Experiments demonstrate that our approach enables even smaller models to achieve high success accuracy and performance metrics on competitive programming tasks, creates more reliable verification than traditional reward models without requiring training PRMs. Our approach achieves significant improvements across 5 models and 3 datasets: an average of 26.9% increase in correctness and 42.2% in efficiency. The results suggest that providing structured reasoning space with concrete verification signals is crucial for solving complex programming tasks. We open-source all our code and data at: this https URL', 'abstract_zh': '大型语言模型在代码生成方面展现了卓越的能力，但在处理需要深度算法推理的复杂编程任务时常常表现不佳。虽然通过学习奖励模型进行过程监督显示出一定的潜力，以引导推理步骤，但这种方法需要昂贵的训练数据，并且在评价方面存在不稳定性。我们提出了一种新的范式——结果精炼过程监督（Outcome-Refining Process Supervision），将其视为需要监督的过程。我们的框架利用具体的执行信号来确定推理步骤的监督，同时通过树状探索结构来同时维护多种解决方案路径。实验结果显示，我们的方法能够使更小的模型在竞争性编程任务中实现高成功率和高性能指标，而且与传统奖励模型相比，无需训练过程奖励模型即可获得更可靠的验证。我们的方法在5个模型和3个数据集上取得了显著提升：平均正确性提高了26.9%，效率提高了42.2%。结果表明，提供带有具体验证信号的结构化推理空间对于解决复杂编程任务至关重要。我们已在以下链接开源了所有代码和数据：this https URL', 'title_zh': '代码生成中的结果细化过程监督'}
{'arxiv_id': 'arXiv:2412.15113', 'title': 'Associative memory inspires improvements for in-context learning using a novel attention residual stream architecture', 'authors': 'Thomas F Burns, Tomoki Fukai, Christopher J Earls', 'link': 'https://arxiv.org/abs/2412.15113', 'abstract': 'Large language models (LLMs) demonstrate an impressive ability to utilise information within the context of their input sequences to appropriately respond to data unseen by the LLM during its training procedure. This ability is known as in-context learning (ICL). Humans and non-human animals demonstrate similar abilities, however their neural architectures differ substantially from LLMs. Despite this, a critical component within LLMs, the attention mechanism, resembles modern associative memory models, widely used in and influenced by the computational neuroscience community to model biological memory systems. Using this connection, we introduce an associative memory model capable of performing ICL. We use this as inspiration for a novel residual stream architecture which allows information to directly flow between attention heads. We test this architecture during training within a two-layer Transformer and show its ICL abilities manifest more quickly than without this modification. We then apply our architecture in small language models with 8 million parameters, focusing on attention head values, with results also indicating improved ICL performance at this larger and more naturalistic scale.', 'abstract_zh': '大型语言模型（LLMs）展示出了在输入序列的上下文中利用信息的能力，以适当的方式响应训练过程中未见过的数据。这一能力被称为上下文内的学习（ICL）。人类和非人类动物也表现出类似的能力，但它们的神经架构与LLMs有显著差异。尽管如此，LLMs中的关键组件——注意力机制——与现代关联记忆模型相似，这些模型在计算神经科学社区中广泛用于模拟生物记忆系统。利用这一联系，我们引入了一种能够执行ICL的关联记忆模型。我们以此为灵感，提出了一种新型的残差流架构，允许信息直接在注意力头之间流动。我们在两层Transformer中训练此架构，并展示在该架构中ICL能力表现得更为迅速。随后，我们将该架构应用于含有800万个参数的小型语言模型，并集中在注意力头的值上，结果表明在更大、更接近自然规模的范围内也观察到了ICL性能的提高。', 'title_zh': '关联记忆启发使用新型注意力残差流架构的上下文适配学习改进'}
{'arxiv_id': 'arXiv:2412.15105', 'title': 'Exploiting sparse structures and synergy designs to advance situational awareness of electrical power grid', 'authors': 'Shimiao Li', 'link': 'https://arxiv.org/abs/2412.15105', 'abstract': 'The growing threats of uncertainties, anomalies, and cyberattacks on power grids are driving a critical need to advance situational awareness which allows system operators to form a complete and accurate picture of the present and future state. Simulation and estimation are foundational tools in this process. However, existing tools lack the robustness and efficiency required to achieve the level of situational awareness needed for the ever-evolving threat landscape. Industry-standard (steady-state) simulators are not robust to blackouts, often leading to non-converging or non-actionable results. Estimation tools lack robustness to anomalous data, returning erroneous system states. Efficiency is the other major concern as nonlinearities and scalability issues make large systems slow to converge.\nThis thesis addresses robustness and efficiency gaps through a dual-fold contribution. We first address the inherent limitations in the existing physics-based and data-driven worlds; and then transcend the boundaries of conventional algorithmic design in the direction of a new paradigm -- Physics-ML Synergy -- which integrates the strengths of the two worlds. Our approaches are built on circuit formulation which provides a unified framework that applies to both transmission and distribution. Sparse optimization acts as the key enabler to make these tools intrinsically robust and immune to random threats, pinpointing dominant sources of (random) blackouts and data errors. Further, we explore sparsity-exploiting optimizations to develop lightweight ML models whose prediction and detection capabilities are a complement to physics-based tools; and whose lightweight designs advance generalization and scalability. Finally, Physics-ML Synergy brings robustness and efficiency further against targeted cyberthreats, by interconnecting our physics-based tools with lightweight ML.', 'abstract_zh': '电力系统日益增长的不确定性、异常和网络攻击威胁正在推动对情况认识的迫切需求，这使得系统运营商能够形成对当前和未来状态的完整且准确的了解成为重要任务。模拟和估计是这一过程中的基础工具。然而，现有工具缺乏在不断变化的威胁环境中达到所需情况认识水平的可靠性和效率。标准的稳态仿真器往往对停电不具有鲁棒性，常常导致结果无法收敛或无实际操作意义。估计工具对异常数据缺乏鲁棒性，会返回错误的系统状态。此外，效率也是一个主要问题，因为非线性和扩展性问题使得大系统难以快速收敛。\n\n本论文通过双重贡献来解决鲁棒性和效率的差距。首先，我们处理现有基于物理和数据驱动的世界中固有的限制；然后，突破传统算法设计的边界，向一种新的范式——物理与机器学习协同（Physics-ML Synergy）发展，将两者的优点结合在一起。我们的方法基于电路建模，提供了一个统一的框架，适用于输电和配电系统。稀疏优化作为关键使能技术，使这些工具固有地具备对随机威胁的鲁棒性和免疫性，能够定位主要的（随机）停电和数据误差。此外，我们探索稀疏优化策略以开发轻量级机器学习模型，这些模型的预测和检测能力能够补充基于物理的方法，并且轻量级设计进一步提高了泛化能力和扩展性。最后，通过将基于物理的方法与轻量级机器学习相互连接，物理与机器学习协同（Physics-ML Synergy）进一步提高了针对定向网络攻击的鲁棒性和效率。', 'title_zh': '利用稀疏结构和协同设计推进电力系统的态势感知能力'}
{'arxiv_id': 'arXiv:2412.15098', 'title': 'A Cross-Domain Study of the Use of Persuasion Techniques in Online Disinformation', 'authors': 'João A. Leite, Olesya Razuvayevskaya, Carolina Scarton, Kalina Bontcheva', 'link': 'https://arxiv.org/abs/2412.15098', 'abstract': 'Disinformation, irrespective of domain or language, aims to deceive or manipulate public opinion, typically through employing advanced persuasion techniques. Qualitative and quantitative research on the weaponisation of persuasion techniques in disinformation has been mostly topic-specific (e.g., COVID-19) with limited cross-domain studies, resulting in a lack of comprehensive understanding of these strategies. This study employs a state-of-the-art persuasion technique classifier to conduct a large-scale, multi-domain analysis of the role of 16 persuasion techniques in disinformation narratives. It shows how different persuasion techniques are employed disproportionately in different disinformation domains. We also include a detailed case study on climate change disinformation, highlighting how linguistic, psychological, and cultural factors shape the adaptation of persuasion strategies to fit unique thematic contexts.', 'abstract_zh': '无论是在哪个领域或使用哪种语言，虚假信息旨在欺骗或操控公众舆论，通常通过利用先进的说服技术来实现这一目的。关于说服技术在虚假信息中作为武器化手段的定性和定量研究主要局限于特定主题（例如，COVID-19），且跨领域研究有限，导致对这些策略的全面理解不足。本研究采用最先进的说服技术分类器进行大规模、跨领域的分析，研究16种说服技术在虚假信息叙事中的作用。结果显示这些说服技术在不同类型的虚假信息领域中被不成比例地使用。我们还详细分析了气候变化虚假信息案例，展示了语言、心理及文化因素如何影响说服策略的适应性，以契合独特的主题背景。', 'title_zh': '跨域研究：在线虚假信息中说服技术的运用'}
{'arxiv_id': 'arXiv:2412.15095', 'title': 'A Full Transformer-based Framework for Automatic Pain Estimation using Videos', 'authors': 'Stefanos Gkikas, Manolis Tsiknakis', 'link': 'https://arxiv.org/abs/2412.15095', 'abstract': 'The automatic estimation of pain is essential in designing an optimal pain management system offering reliable assessment and reducing the suffering of patients. In this study, we present a novel full transformer-based framework consisting of a Transformer in Transformer (TNT) model and a Transformer leveraging cross-attention and self-attention blocks. Elaborating on videos from the BioVid database, we demonstrate state-of-the-art performances, showing the efficacy, efficiency, and generalization capability across all the primary pain estimation tasks.', 'abstract_zh': '自动估计疼痛在设计一个提供可靠评估并减少患者痛苦的理想疼痛管理系统中是必不可少的。在本研究中，我们提出了一种新颖的全变压器基础框架，该框架包括一个Transformer in Transformer（TNT）模型和一个利用交叉注意力和自注意力模块的Transformer。通过对BioVid数据库中的视频进行详尽分析，我们展示了在所有主要疼痛估计任务中的优异性能，证明了该框架的有效性、高效性和泛化能力。', 'title_zh': '基于全变压器架构的视频自动疼痛估计完整框架'}
{'arxiv_id': 'arXiv:2412.15086', 'title': 'Learning Disentangled Equivariant Representation for Explicitly Controllable 3D Molecule Generation', 'authors': 'Haoran Liu, Youzhi Luo, Tianxiao Li, James Caverlee, Martin Renqiang Min', 'link': 'https://arxiv.org/abs/2412.15086', 'abstract': "We consider the conditional generation of 3D drug-like molecules with \\textit{explicit control} over molecular properties such as drug-like properties (e.g., Quantitative Estimate of Druglikeness or Synthetic Accessibility score) and effectively binding to specific protein sites. To tackle this problem, we propose an E(3)-equivariant Wasserstein autoencoder and factorize the latent space of our generative model into two disentangled aspects: molecular properties and the remaining structural context of 3D molecules. Our model ensures explicit control over these molecular attributes while maintaining equivariance of coordinate representation and invariance of data likelihood. Furthermore, we introduce a novel alignment-based coordinate loss to adapt equivariant networks for auto-regressive de-novo 3D molecule generation from scratch. Extensive experiments validate our model's effectiveness on property-guided and context-guided molecule generation, both for de-novo 3D molecule design and structure-based drug discovery against protein targets.", 'abstract_zh': '我们考虑在明确控制分子属性（如药物性质，例如定量的类药物估计值或合成可达性评分）的同时生成3D药物样分子，并有效与特定蛋白质位点结合的问题。为解决这一问题，我们提出了一种E(3)不变 Wasserstein 自编码器，并将生成模型的潜在空间分解为两个解耦的方面：分子属性和3D分子的剩余结构上下文。该模型确保在保持坐标表示的不变性和数据可能性不变性的前提下，能够明确控制这些分子属性。此外，我们引入了一种基于对齐的坐标损失，以适应E(3)不变网络进行从头开始的自动回归3D分子生成。广泛的经验研究表明，我们的模型在属性引导和上下文引导的分子生成中均有效，既适用于从头设计新3D分子，也适用于基于结构的药物发现对抗蛋白质靶标。', 'title_zh': '学习解耦变换表示以实现显式可控的3D分子生成'}
{'arxiv_id': 'arXiv:2412.15084', 'title': 'AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward Modeling', 'authors': 'Zihan Liu, Yang Chen, Mohammad Shoeybi, Bryan Catanzaro, Wei Ping', 'link': 'https://arxiv.org/abs/2412.15084', 'abstract': 'In this paper, we introduce AceMath, a suite of frontier math models that excel in solving complex math problems, along with highly effective reward models capable of evaluating generated solutions and reliably identifying the correct ones. To develop the instruction-tuned math models, we propose a supervised fine-tuning (SFT) process that first achieves competitive performance across general domains, followed by targeted fine-tuning for the math domain using a carefully curated set of prompts and synthetically generated responses. The resulting model, AceMath-72B-Instruct greatly outperforms Qwen2.5-Math-72B-Instruct, GPT-4o and Claude-3.5 Sonnet. To develop math-specialized reward model, we first construct AceMath-RewardBench, a comprehensive and robust benchmark for evaluating math reward models across diverse problems and difficulty levels. After that, we present a systematic approach to build our math reward models. The resulting model, AceMath-72B-RM, consistently outperforms state-of-the-art reward models. Furthermore, when combining AceMath-72B-Instruct with AceMath-72B-RM, we achieve the highest average rm@8 score across the math reasoning benchmarks. We will release model weights, training data, and evaluation benchmarks at: this https URL', 'abstract_zh': '在本文中，我们介绍了AceMath，这是一个在解决复杂数学问题方面表现卓越的前沿数学模型套装，同时还配套了高效率的奖励模型，能够评估生成的解决方案并可靠地识别正确的答案。为了开发指令调整的数学模型，我们提出了一种监督微调（SFT）过程，该过程首先在通用领域实现竞争力的性能，随后通过使用精心设计的提示和合成生成的响应对数学领域进行目标化的微调。由此产生的模型AceMath-72B-Instruct在性能上远超Qwen2.5-Math-72B-Instruct、GPT-4o和Claude-3.5 Sonnet。\n\n为了开发专门针对数学的奖励模型，我们首先构建了AceMath-RewardBench，这是一个综合且稳健的基准，用于评估数学奖励模型在各种问题和难度级别上的性能。之后，我们提出了一种系统的方法来构建我们的数学奖励模型。由此产生的模型AceMath-72B-RM在性能上持续优于最新的奖励模型。此外，当将AceMath-72B-Instruct与AceMath-72B-RM结合使用时，我们能够在数学推理基准测试中实现最高的平均rm@8分数。我们将发布模型权重、训练数据和评估基准：[此链接](this https URL)', 'title_zh': 'AceMath: 基于后训练和奖励建模推进前沿数学推理'}
{'arxiv_id': 'arXiv:2412.15054', 'title': 'GIRAFE: Glottal Imaging Dataset for Advanced Segmentation, Analysis, and Facilitative Playbacks Evaluation', 'authors': 'G. Andrade-Miranda, K. Chatzipapas, J.D. Arias-Londoño, J. I. Godino-Llorente', 'link': 'https://arxiv.org/abs/2412.15054', 'abstract': 'The advances in the development of Facilitative Playbacks extracted from High-Speed videoendoscopic sequences of the vocal folds are hindered by a notable lack of publicly available datasets annotated with the semantic segmentations corresponding to the area of the glottal gap. This fact also limits the reproducibility and further exploration of existing research in this field.\nTo address this gap, GIRAFE is a data repository designed to facilitate the development of advanced techniques for the semantic segmentation, analysis, and fast evaluation of High-Speed videoendoscopic sequences of the vocal folds. The repository includes 65 high-speed videoendoscopic recordings from a cohort of 50 patients (30 female, 20 male). The dataset comprises 15 recordings from healthy controls, 26 from patients with diagnosed voice disorders, and 24 with an unknown health condition. All of them were manually annotated by an expert, including the masks corresponding to the semantic segmentation of the glottal gap. The repository is also complemented with the automatic segmentation of the glottal area using different state-of-the-art approaches.\nThis data set has already supported several studies, which demonstrates its usefulness for the development of new glottal gap segmentation algorithms from High-Speed-Videoendoscopic sequences to improve or create new Facilitative Playbacks. Despite these advances and others in the field, the broader challenge of performing an accurate and completely automatic semantic segmentation method of the glottal area remains open.', 'abstract_zh': '高帧速内窥镜序列中声带促进回放的发展进步受到显着缺乏公共标注数据集的阻碍，特别是缺乏对应喉间隙区段语义标注的数据集。这一事实也限制了现有研究的可重复性和进一步探索。\n\n为填补这一空白，GIRAFE 数据库旨在促进声带高帧速内窥镜序列的语义分割、分析和快速评估技术的发展。该数据库包括来自50名患者（30名女性，20名男性）的65个高帧速内窥镜记录。数据集包含15个健康对照记录、26个已诊断出有声带障碍的患者记录以及24个未知健康状况的记录。所有记录均由专家手工标注，包括对应喉间隙语义分割的掩模。此外，数据库还提供了使用不同最先进的方法进行的喉区自动分割。\n\n该数据集已经支持了多项研究，证明了它在从高帧速内窥镜序列开发新的喉间隙分割算法，以改进或创造新的促进回放方面的有用性。尽管在这一领域取得了这些进展以及其他进展，但对喉区域进行准确和完全自动的语义分割方法的更大挑战仍然悬而未决。', 'title_zh': 'GIRAFE：声门成像数据集，用于高级分割、分析及辅助回放评价'}
{'arxiv_id': 'arXiv:2412.15047', 'title': 'Measuring, Modeling, and Helping People Account for Privacy Risks in Online Self-Disclosures with AI', 'authors': 'Isadora Krsek, Anubha Kabra, Yao Dou, Tarek Naous, Laura A. Dabbish, Alan Ritter, Wei Xu, Sauvik Das', 'link': 'https://arxiv.org/abs/2412.15047', 'abstract': "In pseudonymous online fora like Reddit, the benefits of self-disclosure are often apparent to users (e.g., I can vent about my in-laws to understanding strangers), but the privacy risks are more abstract (e.g., will my partner be able to tell that this is me?). Prior work has sought to develop natural language processing (NLP) tools that help users identify potentially risky self-disclosures in their text, but none have been designed for or evaluated with the users they hope to protect. Absent this assessment, these tools will be limited by the social-technical gap: users need assistive tools that help them make informed decisions, not paternalistic tools that tell them to avoid self-disclosure altogether. To bridge this gap, we conducted a study with N = 21 Reddit users; we had them use a state-of-the-art NLP disclosure detection model on two of their authored posts and asked them questions to understand if and how the model helped, where it fell short, and how it could be improved to help them make more informed decisions. Despite its imperfections, users responded positively to the model and highlighted its use as a tool that can help them catch mistakes, inform them of risks they were unaware of, and encourage self-reflection. However, our work also shows how, to be useful and usable, AI for supporting privacy decision-making must account for posting context, disclosure norms, and users' lived threat models, and provide explanations that help contextualize detected risks.", 'abstract_zh': '在Reddit等匿名在线论坛中，自我披露的好处对用户来说往往是显而易见的（例如，我可以向理解我的陌生人倾诉我的公婆问题），但隐私风险则较为抽象（例如，我的伴侣能否看出这是我在发言？）。此前的研究致力于开发自然语言处理（NLP）工具，帮助用户识别其文本中潜在的风险性自我披露，但这些工具并未针对希望保护的用户进行设计或评估。缺少这种评估，这些工具将受限于社会和技术的差距：用户需要能帮助他们做出知情决策的支持性工具，而非强制他们完全避免自我披露的家长式工具。为解决这一差距，我们进行了一项研究，研究对象为21名Reddit用户；我们让他们使用最先进的NLP披露检测模型检查了他们撰写的两篇文章，并提出了一些问题来了解该模型如何帮助他们、其不足之处在哪里以及如何改进以帮助他们做出更加知情的决策。尽管该模型存在某些缺陷，但用户对其表现出积极的反应，并强调了其作为一个工具的作用——帮助他们发现问题、告知其未知的风险，并促进自我反思。然而，我们的研究还表明，为了使支持隐私决策的AI既实用又易于使用，必须考虑到发帖背景、披露规范以及用户的实际威胁模型，并提供有助于解释检测到的风险的解释。', 'title_zh': '利用人工智能测量、建模并协助人们评估在线自我披露中的隐私风险'}
{'arxiv_id': 'arXiv:2412.15004', 'title': 'Large Language Models and Code Security: A Systematic Literature Review', 'authors': 'Enna Basic, Alberto Giaretta', 'link': 'https://arxiv.org/abs/2412.15004', 'abstract': 'Large Language Models (LLMs) have emerged as powerful tools for automating various programming tasks, including security-related ones, such as detecting and fixing vulnerabilities. Despite their promising capabilities, when required to produce or modify pre-existing code, LLMs could introduce vulnerabilities unbeknown to the programmer. When analyzing code, they could miss clear vulnerabilities or signal nonexistent ones. In this Systematic Literature Review (SLR), we aim to investigate both the security benefits and potential drawbacks of using LLMs for a variety of code-related tasks. In particular, first we focus on the types of vulnerabilities that could be introduced by LLMs, when used for producing code. Second, we analyze the capabilities of LLMs to detect and fix vulnerabilities, in any given code, and how the prompting strategy of choice impacts their performance in these two tasks. Last, we provide an in-depth analysis on how data poisoning attacks on LLMs can impact performance in the aforementioned tasks.', 'abstract_zh': '大规模语言模型（LLMs）已成为自动化各种编程任务的强大工具，包括安全性相关的任务，如检测和修复漏洞。尽管其展示了巨大的能力，但在生成或修改现有代码时，LLMs仍有可能引入未被程序员察觉的漏洞。在分析代码时，它们可能会忽略明显的漏洞或错误地标识不存在的漏洞。在本次系统文献综述（SLR）中，我们旨在研究使用LLMs进行各种代码相关任务的安全优势及其潜在缺点。首先，我们专注于LLMs在生成代码时可能引入的漏洞类型。其次，我们分析LLMs在任何给定代码中检测和修复漏洞的能力，并探讨选定的提示策略对这两项任务性能的影响。最后，我们深入分析了针对LLMs的数据中毒攻击如何影响上述任务的性能。', 'title_zh': '大规模语言模型与代码安全：一篇系统文献综述'}
{'arxiv_id': 'arXiv:2412.14995', 'title': 'HSEvo: Elevating Automatic Heuristic Design with Diversity-Driven Harmony Search and Genetic Algorithm Using LLMs', 'authors': 'Pham Vu Tuan Dat, Long Doan, Huynh Thi Thanh Binh', 'link': 'https://arxiv.org/abs/2412.14995', 'abstract': "Automatic Heuristic Design (AHD) is an active research area due to its utility in solving complex search and NP-hard combinatorial optimization problems in the real world. The recent advancements in Large Language Models (LLMs) introduce new possibilities by coupling LLMs with evolutionary computation to automatically generate heuristics, known as LLM-based Evolutionary Program Search (LLM-EPS). While previous LLM-EPS studies obtained great performance on various tasks, there is still a gap in understanding the properties of heuristic search spaces and achieving a balance between exploration and exploitation, which is a critical factor in large heuristic search spaces. In this study, we address this gap by proposing two diversity measurement metrics and perform an analysis on previous LLM-EPS approaches, including FunSearch, EoH, and ReEvo. Results on black-box AHD problems reveal that while EoH demonstrates higher diversity than FunSearch and ReEvo, its objective score is unstable. Conversely, ReEvo's reflection mechanism yields good objective scores but fails to optimize diversity effectively. With this finding in mind, we introduce HSEvo, an adaptive LLM-EPS framework that maintains a balance between diversity and convergence with a harmony search algorithm. Through experimentation, we find that HSEvo achieved high diversity indices and good objective scores while remaining cost-effective. These results underscore the importance of balancing exploration and exploitation and understanding heuristic search spaces in designing frameworks in LLM-EPS.", 'abstract_zh': '自动启发式设计（AHD）是当前一个活跃的研究领域，因为它在解决复杂的搜索问题和NP难组合最优化问题方面具有重要作用。最近，大型语言模型（LLMs）的发展为通过将LLMs与进化计算相结合来自动生成启发式算法提供了新的可能性，这种结合被称为基于LLMs的进化程序搜索（LLM-EPS）。尽管先前的LLM-EPS研究在各种任务上取得了很好的性能，但在理解启发式搜索空间的属性以及在大规模启发式搜索空间中实现探索与利用之间的平衡方面仍然存在差距，而这一点是至关重要的。在本研究中，我们通过提出两个多样性测量指标，并对过去的研究进行了分析，包括FunSearch、EoH和ReEvo等人，解决了这一差距。在黑盒子AHD问题上的实验结果显示，EoH的多样性高于FunSearch和ReEvo，但其目标分数不稳定。相反，ReEvo的反馈机制虽然能提供良好的目标分数，但在优化多样性方面却不够有效。基于这些发现，我们引入了HSEvo，这是一种通过 harmony search 算法在多样性和收敛性之间保持平衡的自适应LLM-EPS框架。通过实验，我们发现HSEvo实现了高多样性和良好的目标分数，同时也保持了成本效益。这些结果强调了在LLM-EPS框架设计中平衡探索与利用以及理解启发式搜索空间的重要性。', 'title_zh': 'HSEvo：通过多样驱动的和谐搜索和遗传算法结合大语言模型自动启发式设计提级方法'}
{'arxiv_id': 'arXiv:2412.14965', 'title': 'Movie2Story: A framework for understanding videos and telling stories in the form of novel text', 'authors': 'Kangning Li, Zheyang Jia, Anyu Ying', 'link': 'https://arxiv.org/abs/2412.14965', 'abstract': 'Multimodal video-to-text models have made considerable progress, primarily in generating brief descriptions of video content. However, there is still a deficiency in generating rich long-form text descriptions that integrate both video and audio. In this paper, we introduce a framework called M2S, designed to generate novel-length text by combining audio, video, and character recognition. M2S includes modules for video long-form text description and comprehension, audio-based analysis of emotion, speech rate, and character alignment, and visual-based character recognition alignment. By integrating multimodal information using the large language model GPT4o, M2S stands out in the field of multimodal text generation. We demonstrate the effectiveness and accuracy of M2S through comparative experiments and human evaluation. Additionally, the model framework has good scalability and significant potential for future research.', 'abstract_zh': '多模态视频到文本模型在生成视频内容的简短描述方面取得了显著进展。然而，这些模型在生成结合视频和音频的丰富长文本描述方面仍然存在不足。本文提出了一种名为M2S的框架，该框架通过结合音频、视频和字符识别来生成新颖长度的文本。M2S包括用于生成和理解视频长文本描述的模块、基于音频的情绪分析、语速分析和角色对齐模块，以及基于视觉的角色识别对齐模块。通过使用大型语言模型GPT4o整合多模态信息，M2S在多模态文本生成领域脱颖而出。我们通过对比实验和人类评估展示了M2S的有效性和准确性。此外，该模型框架具有良好的可扩展性，并且具有巨大的未来研究潜力。', 'title_zh': 'Movie2Story：一种理解视频并以新颖文本形式讲述故事的框架'}
{'arxiv_id': 'arXiv:2412.14933', 'title': 'Cirbo: A New Tool for Boolean Circuit Analysis and Synthesis', 'authors': 'Daniil Averkov, Tatiana Belova, Gregory Emdin, Mikhail Goncharov, Viktoriia Krivogornitsyna, Alexander S. Kulikov, Fedor Kurmazov, Daniil Levtsov, Georgie Levtsov, Vsevolod Vaskin, Aleksey Vorobiev', 'link': 'https://arxiv.org/abs/2412.14933', 'abstract': 'We present an open-source tool for manipulating Boolean circuits. It implements efficient algorithms, both existing and novel, for a rich variety of frequently used circuit tasks such as satisfiability, synthesis, and minimization. We tested the tool on a wide range of practically relevant circuits (computing, in particular, symmetric and arithmetic functions) that have been optimized intensively by the community for the last three years. The tool helped us to win the IWLS 2024 Programming Contest. In 2023, it was Google DeepMind who took the first place in the competition. We were able to reduce the size of the best circuits from 2023 by 12\\% on average, whereas for some individual circuits, our size reduction was as large as 83\\%.', 'abstract_zh': '我们介绍了一个开源工具，用于操作布尔电路。该工具实现了高效算法，涵盖了一系列常用电路任务（包括求解可满足性、综合和化简）的具体和创新算法。我们在过去三年中经过社区优化的一系列实际相关电路（尤其是对称函数和算术函数电路）上测试了该工具。该工具帮助我们赢得了IWLS 2024编程竞赛冠军。2023年，Google DeepMind获得了冠军。我们平均将2023年最佳电路的规模减少了12%，而对于某些特定电路，我们的规模减少量高达83%。', 'title_zh': 'Cirbo：一种新的布尔电路分析与综合工具'}
{'arxiv_id': 'arXiv:2412.14922', 'title': 'RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response', 'authors': 'Junyu Luo, Xiao Luo, Kaize Ding, Jingyang Yuan, Zhiping Xiao, Ming Zhang', 'link': 'https://arxiv.org/abs/2412.14922', 'abstract': "Supervised fine-tuning (SFT) plays a crucial role in adapting large language models (LLMs) to specific domains or tasks. However, as demonstrated by empirical experiments, the collected data inevitably contains noise in practical applications, which poses significant challenges to model performance on downstream tasks. Therefore, there is an urgent need for a noise-robust SFT framework to enhance model capabilities in downstream tasks. To address this challenge, we introduce a robust SFT framework (RobustFT) that performs noise detection and relabeling on downstream task data. For noise identification, our approach employs a multi-expert collaborative system with inference-enhanced models to achieve superior noise detection. In the denoising phase, we utilize a context-enhanced strategy, which incorporates the most relevant and confident knowledge followed by careful assessment to generate reliable annotations. Additionally, we introduce an effective data selection mechanism based on response entropy, ensuring only high-quality samples are retained for fine-tuning. Extensive experiments conducted on multiple LLMs across five datasets demonstrate RobustFT's exceptional performance in noisy scenarios.", 'abstract_zh': '监督微调（SFT）在使大型语言模型（LLMs）适应特定领域或任务方面起着关键作用。然而，如实证实验所展示的那样，在实际应用中收集的数据不可避免地包含噪声，这给模型在下游任务中的性能带来了重大挑战。因此，迫切需要一种鲁棒的SFT框架来提高模型在下游任务中的能力。为应对这一挑战，我们提出了一种鲁棒的SFT框架（RobustFT），该框架在下游任务数据上进行噪声检测和重标注。在噪声识别方面，我们使用具有推断增强的多专家协作系统来实现更优的噪声检测。在去噪阶段，我们采用上下文增强策略，结合最相关的和最可信的知识，并通过仔细评估生成可靠注释。此外，我们还引入了一种基于响应熵的有效数据选择机制，确保仅保留高质量样本进行微调。在五个不同数据集上对多种LLMs进行的广泛实验表明，RobustFT在噪声场景中表现出色。', 'title_zh': 'RobustFT：在嘈杂响应环境下大型语言模型的鲁棒监督微调'}
{'arxiv_id': 'arXiv:2412.14905', 'title': 'Dehallucinating Parallel Context Extension for Retrieval-Augmented Generation', 'authors': 'Zexiong Ma, Shengnan An, Zeqi Lin, Yanzhen Zou, Jian-Guang Lou, Bing Xie', 'link': 'https://arxiv.org/abs/2412.14905', 'abstract': 'Large language models (LLMs) are susceptible to generating hallucinated information, despite the integration of retrieval-augmented generation (RAG). Parallel context extension (PCE) is a line of research attempting to effectively integrating parallel (unordered) contexts, while it still suffers from hallucinations when adapted to RAG scenarios. In this paper, we propose DePaC (Dehallucinating Parallel Context Extension), which alleviates the hallucination problem with context-aware negative training and information-calibrated aggregation. DePaC is designed to alleviate two types of in-context hallucination: fact fabrication (i.e., LLMs present claims that are not supported by the contexts) and fact omission (i.e., LLMs fail to present claims that can be supported by the contexts). Specifically, (1) for fact fabrication, we apply the context-aware negative training that fine-tunes the LLMs with negative supervisions, thus explicitly guiding the LLMs to refuse to answer when contexts are not related to questions; (2) for fact omission, we propose the information-calibrated aggregation which prioritizes context windows with higher information increment from their contexts. The experimental results on nine RAG tasks demonstrate that DePaC significantly alleviates the two types of hallucination and consistently achieves better performances on these tasks.', 'abstract_zh': '大语言模型（LLMs）在集成检索增强生成（RAG）后仍容易生成幻觉信息。平行上下文扩展（PCE）是一系列研究，旨在有效整合无序的平行上下文，但当适应RAG场景时，仍然会遇到幻觉问题。本文提出了一种名为DePaC（Dehallucinating Parallel Context Extension）的方法，通过上下文感知的负训练和信息校准聚合来缓解幻觉问题。DePaC 设计用于缓解两种类型的上下文幻觉：事实虚构（即，LLMs 提出没有上下文支持的主张）和事实遗漏（即，LLMs 未能呈现可用上下文支持的主张）。具体来说，（1）对于事实虚构，我们应用了上下文感知的负训练，通过微调LLMs以采取否定监督，从而明确引导LLMs在上下文与问题不相关时拒绝回答；（2）对于事实遗漏，我们提出了信息校准聚合，优先选择那些从上下文获得更高信息增量的上下文窗口。在九个RAG任务上的实验结果表明，DePaC 显著缓解了这两种类型的幻觉，并在这些任务中实现了更好的性能。', 'title_zh': '去幻化平行上下文扩展以实现检索增强生成'}
{'arxiv_id': 'arXiv:2412.14869', 'title': 'AI-Powered Intracranial Hemorrhage Detection: A Co-Scale Convolutional Attention Model with Uncertainty-Based Fuzzy Integral Operator and Feature Screening', 'authors': 'Mehdi Hosseini Chagahi, Md. Jalil Piran, Niloufar Delfan, Behzad Moshiri, Jaber Hatam Parikhan', 'link': 'https://arxiv.org/abs/2412.14869', 'abstract': 'Intracranial hemorrhage (ICH) refers to the leakage or accumulation of blood within the skull, which occurs due to the rupture of blood vessels in or around the brain. If this condition is not diagnosed in a timely manner and appropriately treated, it can lead to serious complications such as decreased consciousness, permanent neurological disabilities, or even this http URL primary aim of this study is to detect the occurrence or non-occurrence of ICH, followed by determining the type of subdural hemorrhage (SDH). These tasks are framed as two separate binary classification problems. By adding two layers to the co-scale convolutional attention (CCA) classifier architecture, we introduce a novel approach for ICH detection. In the first layer, after extracting features from different slices of computed tomography (CT) scan images, we combine these features and select the 50 components that capture the highest variance in the data, considering them as informative features. We then assess the discriminative power of these features using the bootstrap forest algorithm, discarding those that lack sufficient discriminative ability between different classes. This algorithm explicitly determines the contribution of each feature to the final prediction, assisting us in developing an explainable AI model. The features feed into a boosting neural network as a latent feature space. In the second layer, we introduce a novel uncertainty-based fuzzy integral operator to fuse information from different CT scan slices. This operator, by accounting for the dependencies between consecutive slices, significantly improves detection accuracy.', 'abstract_zh': '颅内出血（ICH）是指血液在颅骨内泄漏或积聚，通常由于脑内或脑周围的血管破裂引起。如果未及时诊断并适当治疗，可能会导致意识下降、永久性的神经功能障碍，甚至死亡。本研究的主要目标是检测ICH的发生与否，并进一步确定蛛网膜下腔出血（SDH）的类型。这些问题被构想为两个独立的二元分类问题。通过在共同尺度卷积 attention（CCA）分类器架构中添加两层，我们提出了一种新的ICH检测方法。在第一层中，在从计算机断层扫描（CT）扫描图像的不同切片中提取特征后，我们结合了这些特征，并选择了能够捕捉数据中最高方差的50个成分，将其视为具有信息性的特征。我们然后使用自助森林算法评估这些特征的区分能力，去除那些在不同类别之间缺乏充分区分能力的特征。该算法明确确定了每个特征对最终预测的贡献，帮助我们开发一个可解释的AI模型。这些特征作为潜在特征空间输入到增强神经网络中。在第二层中，我们引入了一种基于不确定性的新模糊积分算子，用于融合不同CT扫描切片的信息。该算子通过考虑连续切片之间的依赖性，显著提高了检测准确性。', 'title_zh': '基于AI的颅内出血检测：一种基于不确定性模糊积分运算器和特征筛选的共尺度卷积注意力模型'}
{'arxiv_id': 'arXiv:2412.14847', 'title': 'A Survey of RWKV', 'authors': 'Zhiyuan Li, Tingyu Xia, Yi Chang, Yuan Wu', 'link': 'https://arxiv.org/abs/2412.14847', 'abstract': 'The Receptance Weighted Key Value (RWKV) model offers a novel alternative to the Transformer architecture, merging the benefits of recurrent and attention-based systems. Unlike conventional Transformers, which depend heavily on self-attention, RWKV adeptly captures long-range dependencies with minimal computational demands. By utilizing a recurrent framework, RWKV addresses some computational inefficiencies found in Transformers, particularly in tasks with long sequences. RWKV has recently drawn considerable attention for its robust performance across multiple domains. Despite its growing popularity, no systematic review of the RWKV model exists. This paper seeks to fill this gap as the first comprehensive review of the RWKV architecture, its core principles, and its varied applications, such as natural language generation, natural language understanding, and computer vision. We assess how RWKV compares to traditional Transformer models, highlighting its capability to manage long sequences efficiently and lower computational costs. Furthermore, we explore the challenges RWKV encounters and propose potential directions for future research and advancement. We consistently maintain the related open-source materials at: this https URL.', 'abstract_zh': '以下内容是将给定的英文论文内容或标题翻译成中文，并确保符合学术规范：\n\nReceptance加权关键值（RWKV）模型提供了一种替代传统的变压器架构的新颖方案，结合了循环网络和注意力机制的优点。与依赖大量自我注意的传统变压器不同，RWKV 能够以最小的计算需求高效地捕捉长距离依赖关系。通过使用循环框架，RWKV 解决了传统变压器在处理长序列任务时的一些计算效率问题。近年来，RWKV 因其在多个领域的稳健表现引起了广泛关注。尽管其日益受到欢迎，但尚未有系统的 RWKV 模型综述。本文旨在填补这一空白，成为首个全面综述 RWKV 架构及其核心原理的研究，以及其在自然语言生成、自然语言理解和计算机视觉等领域的多样应用。我们评估了 RWKV 与传统变压器模型的性能差异，强调了其高效处理长序列并降低计算成本的能力。此外，我们探讨了 RWKV 在实际应用中遇到的挑战，并提出了未来研究和改进的潜在方向。我们始终维护相关的开源材料：[此链接：this https URL]。\n\n请注意，这里的链接“this https URL”是一个占位符，在实际使用时应替换为具体的链接地址。', 'title_zh': '《RWKV综述》'}
{'arxiv_id': 'arXiv:2412.14846', 'title': 'Head and Neck Tumor Segmentation of MRI from Pre- and Mid-radiotherapy with Pre-training, Data Augmentation and Dual Flow UNet', 'authors': 'Litingyu Wang, Wenjun Liao, Shichuan Zhang, Guotai Wang', 'link': 'https://arxiv.org/abs/2412.14846', 'abstract': 'Head and neck tumors and metastatic lymph nodes are crucial for treatment planning and prognostic analysis. Accurate segmentation and quantitative analysis of these structures require pixel-level annotation, making automated segmentation techniques essential for the diagnosis and treatment of head and neck cancer. In this study, we investigated the effects of multiple strategies on the segmentation of pre-radiotherapy (pre-RT) and mid-radiotherapy (mid-RT) images. For the segmentation of pre-RT images, we utilized: 1) a fully supervised learning approach, and 2) the same approach enhanced with pre-trained weights and the MixUp data augmentation technique. For mid-RT images, we introduced a novel computational-friendly network architecture that features separate encoders for mid-RT images and registered pre-RT images with their labels. The mid-RT encoder branch integrates information from pre-RT images and labels progressively during the forward propagation. We selected the highest-performing model from each fold and used their predictions to create an ensemble average for inference. In the final test, our models achieved a segmentation performance of 82.38% for pre-RT and 72.53% for mid-RT on aggregated Dice Similarity Coefficient (DSC) as HiLab. Our code is available at this https URL.', 'abstract_zh': '头部和颈部肿瘤及其转移淋巴结对于治疗计划和预后分析至关重要。准确分割和定量分析这些结构需要像素级别的标注，因此自动化分割技术对于头部和颈部癌症的诊断和治疗至关重要。在本研究中，我们探讨了多种策略对放疗前（pre-RT）和放疗中（mid-RT）图像分割效果的影响。对于pre-RT图像分割，我们分别采用了：1) 全监督学习方法，以及2) 结合预训练权重和MixUp数据增强技术的该方法。对于mid-RT图像分割，我们引入了一种新型的计算友好型网络架构，该架构具有专门针对mid-RT图像的编码器，并且将预处理后的pre-RT图像及其标签进行了配准。mid-RT编码器分支在前向传播过程中逐步整合pre-RT图像及其标签的信息。我们从每折中选择表现最佳的模型，并使用它们的预测值进行推理的集成平均。最终测试中，我们的模型在HiLab汇总Dice相似性系数（DSC）上的分割性能分别为pre-RT图像82.38%和mid-RT图像72.53%。我们的代码可在以下网址获取：https://github.com/your-repository-name。', 'title_zh': '在放疗前和中期MRI中基于预训练、数据增强和双流UNet的头颈部肿瘤分割'}
{'arxiv_id': 'arXiv:2412.14843', 'title': 'Mapping and Influencing the Political Ideology of Large Language Models using Synthetic Personas', 'authors': 'Pietro Bernardelle, Leon Fröhling, Stefano Civelli, Riccardo Lunardi, Kevin Roiter, Gianluca Demartini', 'link': 'https://arxiv.org/abs/2412.14843', 'abstract': "The analysis of political biases in large language models (LLMs) has primarily examined these systems as single entities with fixed viewpoints. While various methods exist for measuring such biases, the impact of persona-based prompting on LLMs' political orientation remains unexplored. In this work we leverage PersonaHub, a collection of synthetic persona descriptions, to map the political distribution of persona-based prompted LLMs using the Political Compass Test (PCT). We then examine whether these initial compass distributions can be manipulated through explicit ideological prompting towards diametrically opposed political orientations: right-authoritarian and left-libertarian. Our experiments reveal that synthetic personas predominantly cluster in the left-libertarian quadrant, with models demonstrating varying degrees of responsiveness when prompted with explicit ideological descriptors. While all models demonstrate significant shifts towards right-authoritarian positions, they exhibit more limited shifts towards left-libertarian positions, suggesting an asymmetric response to ideological manipulation that may reflect inherent biases in model training.", 'abstract_zh': '大规模语言模型（LLMs）中的政治偏见分析主要将这些系统视为具有固定观点的单个实体进行研究。虽然存在多种方法用于衡量这些偏见，但基于人设的提示对LLMs政治倾向的影响尚未得到探讨。本研究利用PersonaHub数据集，该数据集包含合成人设描述，通过政治定向测试（PCT）来绘制基于人设的提示后LLMs的政治分布。然后我们将研究这些初始的政治定向分布是否可以通过明示的意识形态提示，向截然相反的政治倾向进行操控，如右翼集权主义和左翼自由主义。实验结果显示，合成人设主要集中在左翼自由主义象限，而当使用明示的意识形态描述器进行提示时，模型表现出不同程度的响应性。虽然所有模型都显示出显著向右翼集权主义方向的转变，但它们左翼自由主义方向的转变更为有限，这表明意识形态操控的不对称响应，可能反映了模型训练中的固有偏见。', 'title_zh': '使用合成 personas 映射和影响大型语言模型的政治意识形态'}
{'arxiv_id': 'arXiv:2412.14841', 'title': 'Helping LLMs Improve Code Generation Using Feedback from Testing and Static Analysis', 'authors': 'Greta Dolcetti, Vincenzo Arceri, Eleonora Iotti, Sergio Maffeis, Agostino Cortesi, Enea Zaffanella', 'link': 'https://arxiv.org/abs/2412.14841', 'abstract': 'Large Language Models (LLMs) are one of the most promising developments in the field of artificial intelligence, and the software engineering community has readily noticed their potential role in the software development life-cycle. Developers routinely ask LLMs to generate code snippets, increasing productivity but also potentially introducing ownership, privacy, correctness, and security issues. Previous work highlighted how code generated by mainstream commercial LLMs is often not safe, containing vulnerabilities, bugs, and code smells. In this paper, we present a framework that leverages testing and static analysis to assess the quality, and guide the self-improvement, of code generated by general-purpose, open-source LLMs.\nFirst, we ask LLMs to generate C code to solve a number of programming tasks. Then we employ ground-truth tests to assess the (in)correctness of the generated code, and a static analysis tool to detect potential safety vulnerabilities. Next, we assess the models ability to evaluate the generated code, by asking them to detect errors and vulnerabilities. Finally, we test the models ability to fix the generated code, providing the reports produced during the static analysis and incorrectness evaluation phases as feedback.\nOur results show that models often produce incorrect code, and that the generated code can include safety issues. Moreover, they perform very poorly at detecting either issue. On the positive side, we observe a substantial ability to fix flawed code when provided with information about failed tests or potential vulnerabilities, indicating a promising avenue for improving the safety of LLM-based code generation tools.', 'abstract_zh': '大型语言模型（LLMs）是人工智能领域最具前景的发展之一，软件工程社区也已注意到它们在软件开发生命周期中的潜在作用。开发者频繁要求LLMs生成代码片段，这虽然提高了生产力，但也可能引入所有权、隐私、正确性及安全性方面的问题。此前的研究指出，主流商用LLMs生成的代码往往不够安全，存在漏洞、错误和代码异味。在本文中，我们提出了一种框架，利用测试和静态分析评估由通用开源LLMs生成代码的质量，并指导其自我改进。\n\n首先，我们要求LLMs生成C语言代码以解决多种编程任务。然后，我们使用准确的测试案例来评估生成代码的正确性，并使用静态分析工具检测潜在的安全漏洞。接着，通过让模型检测错误和漏洞来评估其评估生成代码的能力。最后，我们测试模型修复生成代码的能力，将静态分析和不正确性评估阶段生成的报告作为反馈。\n\n我们的研究结果表明，模型经常生成不正确的代码，生成的代码中可能存在安全问题。此外，它们在检测这两种问题方面表现非常差。不过，我们观察到，当提供测试失败信息或潜在漏洞的信息时，模型具有显著的修复不正确代码的能力，这表明通过改进LLM基础代码生成工具的安全性是一个有前景的途径。', 'title_zh': '使用测试和静态分析反馈帮助大模型提高代码生成能力'}
{'arxiv_id': 'arXiv:2412.14835', 'title': 'Progressive Multimodal Reasoning via Active Retrieval', 'authors': 'Guanting Dong, Chenghao Zhang, Mengjie Deng, Yutao Zhu, Zhicheng Dou, Ji-Rong Wen', 'link': 'https://arxiv.org/abs/2412.14835', 'abstract': 'Multi-step multimodal reasoning tasks pose significant challenges for multimodal large language models (MLLMs), and finding effective ways to enhance their performance in such scenarios remains an unresolved issue. In this paper, we propose AR-MCTS, a universal framework designed to progressively improve the reasoning capabilities of MLLMs through Active Retrieval (AR) and Monte Carlo Tree Search (MCTS). Our approach begins with the development of a unified retrieval module that retrieves key supporting insights for solving complex reasoning problems from a hybrid-modal retrieval corpus. To bridge the gap in automated multimodal reasoning verification, we employ the MCTS algorithm combined with an active retrieval mechanism, which enables the automatic generation of step-wise annotations. This strategy dynamically retrieves key insights for each reasoning step, moving beyond traditional beam search sampling to improve the diversity and reliability of the reasoning space. Additionally, we introduce a process reward model that aligns progressively to support the automatic verification of multimodal reasoning tasks. Experimental results across three complex multimodal reasoning benchmarks confirm the effectiveness of the AR-MCTS framework in enhancing the performance of various multimodal models. Further analysis demonstrates that AR-MCTS can optimize sampling diversity and accuracy, yielding reliable multimodal reasoning.', 'abstract_zh': '多步多模态推理任务为多模态大型语言模型（MLLMs）带来了重大挑战，如何在这种场景下有效提升其性能仍然是一个未解决的问题。本文提出了一种名为AR-MCTS的通用框架，通过积极检索（Active Retrieval, AR）和蒙特卡罗树搜索（Monte Carlo Tree Search, MCTS）逐步提高MLLMs的推理能力。我们的方法首先开发了一个统一的检索模块，该模块可以从混合模态检索语料库中检索解决复杂推理问题的关键支持见解。为了弥合自动多模态推理验证中的差距，我们采用了结合积极检索机制的MCTS算法，这使得可以自动生成逐步注释。该策略动态地为每个推理步骤检索关键见解，超越了传统的束搜索采样方法，从而提高了推理空间的多样性和可靠性。此外，我们引入了一种过程奖励模型，该模型逐步对齐以支持多模态推理任务的自动验证。在三个复杂多模态推理基准上的实验结果证实了AR-MCTS框架在提升各种多模态模型性能方面的有效性。进一步的分析表明，AR-MCTS能够优化采样多样性与准确性，从而实现可靠的多模态推理。', 'title_zh': '基于主动检索的渐进多模态推理'}
{'arxiv_id': 'arXiv:2412.14810', 'title': 'MARIA: a Multimodal Transformer Model for Incomplete Healthcare Data', 'authors': 'Camillo Maria Caruso, Paolo Soda, Valerio Guarrasi', 'link': 'https://arxiv.org/abs/2412.14810', 'abstract': 'In healthcare, the integration of multimodal data is pivotal for developing comprehensive diagnostic and predictive models. However, managing missing data remains a significant challenge in real-world applications. We introduce MARIA (Multimodal Attention Resilient to Incomplete datA), a novel transformer-based deep learning model designed to address these challenges through an intermediate fusion strategy. Unlike conventional approaches that depend on imputation, MARIA utilizes a masked self-attention mechanism, which processes only the available data without generating synthetic values. This approach enables it to effectively handle incomplete datasets, enhancing robustness and minimizing biases introduced by imputation methods. We evaluated MARIA against 10 state-of-the-art machine learning and deep learning models across 8 diagnostic and prognostic tasks. The results demonstrate that MARIA outperforms existing methods in terms of performance and resilience to varying levels of data incompleteness, underscoring its potential for critical healthcare applications.', 'abstract_zh': '在医疗健康领域，多模态数据的整合对于开发全面的诊断和预测模型至关重要。然而，在实际应用中，管理缺失数据仍然是一个重大的挑战。我们提出了MARIA（Multimodal Attention Resilient to Incomplete datA），一种新型的基于变换器的深度学习模型，通过中间融合策略应对这些挑战。与依赖插补的传统方法不同，MARIA 使用掩码自注意力机制，在不生成合成值的情况下仅处理可用数据。这一方法使其能够有效处理不完整的数据集，增强模型的健壮性，并减少由插补方法引入的偏差。我们对MARIA进行了全面评估，与10种最先进的机器学习和深度学习模型在8项诊断和预后任务中进行比较。结果表明，MARIA在性能和对不同缺失程度数据的鲁棒性方面优于现有方法，突显了其在关键医疗应用中的潜力。', 'title_zh': 'MARIA：用于不完整医疗数据的多模态变压器模型'}
{'arxiv_id': 'arXiv:2412.14802', 'title': 'Stack Trace Deduplication: Faster, More Accurately, and in More Realistic Scenarios', 'authors': 'Egor Shibaev, Denis Sushentsev, Yaroslav Golubev, Aleksandr Khvorov', 'link': 'https://arxiv.org/abs/2412.14802', 'abstract': 'In large-scale software systems, there are often no fully-fledged bug reports with human-written descriptions when an error occurs. In this case, developers rely on stack traces, i.e., series of function calls that led to the error. Since there can be tens and hundreds of thousands of them describing the same issue from different users, automatic deduplication into categories is necessary to allow for processing. Recent works have proposed powerful deep learning-based approaches for this, but they are evaluated and compared in isolation from real-life workflows, and it is not clear whether they will actually work well at scale.\nTo overcome this gap, this work presents three main contributions: a novel model, an industry-based dataset, and a multi-faceted evaluation. Our model consists of two parts - (1) an embedding model with byte-pair encoding and approximate nearest neighbor search to quickly find the most relevant stack traces to the incoming one, and (2) a reranker that re-ranks the most fitting stack traces, taking into account the repeated frames between them. To complement the existing datasets collected from open-source projects, we share with the community SlowOps - a dataset of stack traces from IntelliJ-based products developed by JetBrains, which has an order of magnitude more stack traces per category. Finally, we carry out an evaluation that strives to be realistic: measuring not only the accuracy of categorization, but also the operation time and the ability to create new categories. The evaluation shows that our model strikes a good balance - it outperforms other models on both open-source datasets and SlowOps, while also being faster on time than most. We release all of our code and data, and hope that our work can pave the way to further practice-oriented research in the area.', 'abstract_zh': '在大规模软件系统中，当错误发生时，往往没有包含详细人工描述的完整bug报告。在这种情况下，开发人员依赖于堆栈跟踪，即导致错误的一系列函数调用。由于可能有成千上万个描述相同问题的堆栈跟踪，来自不同用户的这些堆栈跟踪需要进行自动分组分类，以便于处理。最近的研究已经提出了基于深度学习的强大方法来处理这个问题，但它们通常是孤立地进行评估和比较，并不能清楚地表明这些方法在大规模应用时是否真正有效。\n\n为弥合这一差距，本研究提出了三个主要贡献：一种新型模型、一个基于工业应用的数据集以及多维度的评估。我们的模型包括两部分：（1）一个使用字节对编码和近似最近邻搜索的嵌入模型，用于快速找到与最新堆栈跟踪最相关的堆栈跟踪；（2）一个重排器，根据彼此间的重复帧来重新排列最匹配的堆栈跟踪。为了补充现有的来自开源项目的数据集，我们向社区分享了SlowOps——一个包含大量堆栈跟踪的数据集，尤其是来自 JetBrains 开发的基于 IntelliJ 的产品的数据集，该数据集在每个类别中包含了数量级更大的堆栈跟踪。最后，我们进行了旨在实现现实性的评估：不仅衡量分类的准确性，还评估操作时间和创建新类别的能力。评估结果显示，我们的模型在多个方面表现出良好的均衡性——它在开源数据集和SlowOps中均优于其他模型，同时在操作时间上也快于大多数模型。我们已发布所有代码和数据，并希望我们的工作能够为该领域的进一步实践导向研究铺平道路。', 'title_zh': '栈跟踪去重：更快、更准确、并在更多现实场景中实现'}
{'arxiv_id': 'arXiv:2412.14779', 'title': 'Agent-Temporal Credit Assignment for Optimal Policy Preservation in Sparse Multi-Agent Reinforcement Learning', 'authors': 'Aditya Kapoor, Sushant Swamy, Kale-ab Tessera, Mayank Baranwal, Mingfei Sun, Harshad Khadilkar, Stefano V. Albrecht', 'link': 'https://arxiv.org/abs/2412.14779', 'abstract': 'In multi-agent environments, agents often struggle to learn optimal policies due to sparse or delayed global rewards, particularly in long-horizon tasks where it is challenging to evaluate actions at intermediate time steps. We introduce Temporal-Agent Reward Redistribution (TAR$^2$), a novel approach designed to address the agent-temporal credit assignment problem by redistributing sparse rewards both temporally and across agents. TAR$^2$ decomposes sparse global rewards into time-step-specific rewards and calculates agent-specific contributions to these rewards. We theoretically prove that TAR$^2$ is equivalent to potential-based reward shaping, ensuring that the optimal policy remains unchanged. Empirical results demonstrate that TAR$^2$ stabilizes and accelerates the learning process. Additionally, we show that when TAR$^2$ is integrated with single-agent reinforcement learning algorithms, it performs as well as or better than traditional multi-agent reinforcement learning methods.', 'abstract_zh': '在多智能体环境中，智能体通常难以学习最优策略，尤其是由于全局奖励稀疏或延迟，特别是在长期任务中，评估中间时间步的行动颇具挑战性。我们引入了时间-智能体奖励重分配（TAR\\(^2\\))，这是一种新颖的方法，旨在通过在时间和智能体之间重新分配稀疏奖励来解决智能体-时间的信用分配问题。TAR\\(^2\\) 将稀疏的全局奖励分解为时间步特定的奖励，并计算每个智能体对这些奖励的具体贡献。我们从理论上证明，TAR\\(^2\\) 等同于基于潜能的奖励塑造，确保最优策略保持不变。实验结果表明，TAR\\(^2\\) 能够稳定并加速学习过程。此外，我们展示了当将TAR\\(^2\\)与单智能体强化学习算法结合使用时，其性能至少与传统的多智能体强化学习方法相当或更优。', 'title_zh': '基于智能体-时间的信用分配方法，用于稀疏多智能体强化学习中的最优策略保留'}
{'arxiv_id': 'arXiv:2412.14775', 'title': 'Energy and polarization based on-line interference mitigation in radio interferometry', 'authors': 'Sarod Yatawatta, Albert-Jan Boonstra, Chris P. Broekema', 'link': 'https://arxiv.org/abs/2412.14775', 'abstract': 'Radio frequency interference (RFI) is a persistent contaminant in terrestrial radio astronomy. While new radio interferometers are becoming operational, novel sources of RFI are also emerging. In order to strengthen the mitigation of RFI in modern radio interferometers, we propose an on-line RFI mitigation scheme that can be run in the correlator of such interferometers. We combine statistics based on the energy as well as the polarization alignment of the correlated signal to develop an on-line RFI mitigation scheme that can be applied to a data stream produced by the correlator in real-time, especially targeted at low duty-cycle or transient RFI detection. In order to improve the computational efficiency, we explore the use of both single precision and half precision floating point operations in implementing the RFI mitigation algorithm. This ideally suits its deployment in accelerator computing devices such as graphics processing units (GPUs) as used by the LOFAR correlator. We provide results based on real data to demonstrate the efficacy of the proposed method.', 'abstract_zh': '射频干扰（RFI）是地面射电天文观测中的持久性污染源。随着新型射电干涉仪的运行，新的RFI源也在不断涌现。为了加强现代射电干涉仪中的RFI抑制，我们提出了一种在线RFI抑制方案，可以在射电干涉仪的关联器中运行。我们结合基于关联信号能量和极化对齐的统计方法，开发了一种在线RFI抑制方案，可以实时应用于由关联器产生的数据流，特别是针对低工作比率或瞬态RFI的检测。为了提高计算效率，我们研究了在实现RFI抑制算法时使用单精度和半精度浮点运算的可能性。这种方法特别适用于图形处理单元（GPUs）等加速计算设备，如同射电阵列LOFAR关联器所使用的那样。我们基于实际数据提供了结果，以证明所提方法的有效性。', 'title_zh': '基于能量和极化在线干扰抑制的射电干涉ometry方法'}
{'arxiv_id': 'arXiv:2412.14771', 'title': 'ALKAFI-LLAMA3: Fine-Tuning LLMs for Precise Legal Understanding in Palestine', 'authors': 'Rabee Qasem, Mohannad Hendi, Banan Tantour', 'link': 'https://arxiv.org/abs/2412.14771', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable potential in diverse domains, yet their application in the legal sector, particularly in low-resource contexts, remains limited. This study addresses the challenges of adapting LLMs to the Palestinian legal domain, where political instability, fragmented legal frameworks, and limited AI resources hinder effective machine-learning applications. We present a fine-tuned model based on a quantized version of Llama-3.2-1B-Instruct, trained on a synthetic data set derived from Palestinian legal texts. Using smaller-scale models and strategically generated question-answer pairs, we achieve a cost-effective, locally sustainable solution that provides accurate and contextually relevant legal guidance. Our experiments demonstrate promising performance on various query types, ranging from yes/no questions and narrative explanations to complex legal differentiations, while highlighting areas for improvement, such as handling calculation-based inquiries and structured list formatting. This work provides a pathway for the deployment of AI-driven legal assistance tools tailored to the needs of resource-constrained environments.', 'abstract_zh': '大型语言模型（LLMs）在多个领域展现了巨大的潜力，但在法律领域，尤其是在资源匮乏的环境中，其应用仍然有限。本研究旨在解决将LLMs适应于巴勒斯坦法律领域的挑战，其中政治不稳定、法定框架碎片化以及有限的人工智能资源阻碍了有效的机器学习应用。我们基于量化版本的Llama-3.2-1B-Instruct模型进行微调，并使用从巴勒斯坦法律文本中生成的合成数据集进行训练。通过使用规模较小的模型和战略生成的问题-答案对，我们提出了一种成本效益高、本地可持续的解决方案，能够提供准确且上下文相关的法律指导。我们的实验展示了该模型在各种查询类型上的出色表现，包括是/否问题、叙述解释以及复杂的法律区别，同时也指出了改进的空间，例如处理基于计算的查询和结构化列表格式化。这项工作为部署针对资源受限环境的AI驱动法律辅助工具提供了可行性路径。', 'title_zh': 'ALKAFI-LLAMA3：针对巴勒斯坦精准法律理解的大型语言模型 finetuning'}
{'arxiv_id': 'arXiv:2412.14764', 'title': 'CodeRepoQA: A Large-scale Benchmark for Software Engineering Question Answering', 'authors': 'Ruida Hu, Chao Peng, Jingyi Ren, Bo Jiang, Xiangxin Meng, Qinyun Wu, Pengfei Gao, Xinchen Wang, Cuiyun Gao', 'link': 'https://arxiv.org/abs/2412.14764', 'abstract': "In this work, we introduce CodeRepoQA, a large-scale benchmark specifically designed for evaluating repository-level question-answering capabilities in the field of software engineering. CodeRepoQA encompasses five programming languages and covers a wide range of scenarios, enabling comprehensive evaluation of language models. To construct this dataset, we crawl data from 30 well-known repositories in GitHub, the largest platform for hosting and collaborating on code, and carefully filter raw data. In total, CodeRepoQA is a multi-turn question-answering benchmark with 585,687 entries, covering a diverse array of software engineering scenarios, with an average of 6.62 dialogue turns per entry.\nWe evaluate ten popular large language models on our dataset and provide in-depth analysis. We find that LLMs still have limitations in question-answering capabilities in the field of software engineering, and medium-length contexts are more conducive to LLMs' performance. The entire benchmark is publicly available at this https URL.", 'abstract_zh': '在本文中，我们介绍了CodeRepoQA，这是一个大规模基准，专门用于评估软件工程领域仓库级别的问答能力。CodeRepoQA 包含五种编程语言，并涵盖了广泛的情景，从而全面评估语言模型。为了构建这个数据集，我们从 GitHub——最大的代码托管和协作平台——爬取了30个知名的代码仓库数据，并仔细筛选了原始数据。总体而言，CodeRepoQA 是一个包含585,687条条目的多轮问答基准，涵盖了多样化的软件工程情景，平均每条条目包含6.62轮对话。\n\n我们在我们的数据集上评估了十个流行的大型语言模型，并进行了深入分析。我们发现，在软件工程领域，大型语言模型的问答能力仍存在局限，且中等长度的上下文更有利于大型语言模型的性能。整个基准数据集已在以下网址公开：[此链接]。', 'title_zh': 'CodeRepoQA：大规模软件工程问答基准数据集'}
{'arxiv_id': 'arXiv:2412.14736', 'title': 'Advances in Artificial Intelligence forDiabetes Prediction: Insights from a Systematic Literature Review', 'authors': 'Pir Bakhsh Khokhar, Carmine Gravino, Fabio Palomba', 'link': 'https://arxiv.org/abs/2412.14736', 'abstract': 'This systematic review explores the use of machine learning (ML) in predicting diabetes, focusing on datasets, algorithms, training methods, and evaluation metrics. It examines datasets like the Singapore National Diabetic Retinopathy Screening program, REPLACE-BG, National Health and Nutrition Examination Survey, and Pima Indians Diabetes Database. The review assesses the performance of ML algorithms like CNN, SVM, Logistic Regression, and XGBoost in predicting diabetes outcomes. The study emphasizes the importance of interdisciplinary collaboration and ethical considerations in ML-based diabetes prediction models.', 'abstract_zh': '本系统综述探讨了机器学习（ML）在糖尿病预测中的应用，重点研究了数据集、算法、训练方法和评估指标。该综述分析了如新加坡全国糖尿病性视网膜病变筛查计划、REPLACE-BG、国家健康和营养状况检查调查以及皮马印第安人糖尿病数据库等数据集。研究评估了使用CNN、SVM、逻辑回归和XGBoost等机器学习算法在预测糖尿病结果方面的性能。本研究强调了在基于ML的糖尿病预测模型中跨学科合作和伦理考量的重要性。', 'title_zh': '人工智能在糖尿病预测中的进展：系统文献综述的见解'}
{'arxiv_id': 'arXiv:2412.14732', 'title': 'Beyond the Hype: A Comprehensive Review of Current Trends in Generative AI Research, Teaching Practices, and Tools', 'authors': 'James Prather, Juho Leinonen, Natalie Kiesler, Jamie Gorson Benario, Sam Lau, Stephen MacNeil, Narges Norouzi, Simone Opel, Vee Pettit, Leo Porter, Brent N. Reeves, Jaromir Savelka, David H. Smith IV, Sven Strickroth, Daniel Zingaro', 'link': 'https://arxiv.org/abs/2412.14732', 'abstract': 'Generative AI (GenAI) is advancing rapidly, and the literature in computing education is expanding almost as quickly. Initial responses to GenAI tools were mixed between panic and utopian optimism. Many were fast to point out the opportunities and challenges of GenAI. Researchers reported that these new tools are capable of solving most introductory programming tasks and are causing disruptions throughout the curriculum. These tools can write and explain code, enhance error messages, create resources for instructors, and even provide feedback and help for students like a traditional teaching assistant. In 2024, new research started to emerge on the effects of GenAI usage in the computing classroom. These new data involve the use of GenAI to support classroom instruction at scale and to teach students how to code with GenAI. In support of the former, a new class of tools is emerging that can provide personalized feedback to students on their programming assignments or teach both programming and prompting skills at the same time. With the literature expanding so rapidly, this report aims to summarize and explain what is happening on the ground in computing classrooms. We provide a systematic literature review; a survey of educators and industry professionals; and interviews with educators using GenAI in their courses, educators studying GenAI, and researchers who create GenAI tools to support computing education. The triangulation of these methods and data sources expands the understanding of GenAI usage and perceptions at this critical moment for our community.', 'abstract_zh': '生成式AI（GenAI）的进步速度非常快，计算教育领域的相关文献也正在迅速增长。最初对于GenAI工具的反应是既充满恐慌又抱有乌托邦式的乐观。许多人迅速指出了GenAI的机会与挑战。研究人员报告称，这些新工具能够解决大多数入门级编程任务，并在整个课程中引发了一系列颠覆。这些工具可以编写和解释代码，增强错误信息，为教师创建资源，并且还可以像传统的辅导助手那样为学生提供反馈和帮助。在2024年，关于GenAI在计算课堂中使用影响的新研究开始涌现。这些新数据涉及使用GenAI支持大规模课堂讲授以及教授学生如何使用GenAI进行编程。为了支持前者，一种新的工具类别正在涌现，能够为学生的编程作业提供个性化反馈，或同时教授编程和提示技能。鉴于文献的增长速度，本报告旨在总结并解释这些变化在计算课堂中的具体情况。我们将提供系统性文献综述、教育工作者和产业专业人士的问卷调查，以及对在课程中使用GenAI的教育工作者、研究GenAI的教育工作者以及创建支持计算教育的GenAI工具的研究人员的访谈。通过这些方法和数据源的三角验证，本报告进一步深化了我们对于GenAI使用情况及其在这一关键时刻对社区感知的理解。', 'title_zh': '超越 hype：生成式人工智能研究、教学实践和工具当前趋势的全面综述'}
{'arxiv_id': 'arXiv:2412.14689', 'title': 'How to Synthesize Text Data without Model Collapse?', 'authors': 'Xuekai Zhu, Daixuan Cheng, Hengli Li, Kaiyan Zhang, Ermo Hua, Xingtai Lv, Ning Ding, Zhouhan Lin, Zilong Zheng, Bowen Zhou', 'link': 'https://arxiv.org/abs/2412.14689', 'abstract': 'Model collapse in synthetic data indicates that iterative training on self-generated data leads to a gradual decline in performance. With the proliferation of AI models, synthetic data will fundamentally reshape the web data ecosystem. Future GPT-$\\{n\\}$ models will inevitably be trained on a blend of synthetic and human-produced data. In this paper, we focus on two questions: what is the impact of synthetic data on language model training, and how to synthesize data without model collapse? We first pre-train language models across different proportions of synthetic data, revealing a negative correlation between the proportion of synthetic data and model performance. We further conduct statistical analysis on synthetic data to uncover distributional shift phenomenon and over-concentration of n-gram features. Inspired by the above findings, we propose token editing on human-produced data to obtain semi-synthetic data. As a proof of concept, we theoretically demonstrate that token-level editing can prevent model collapse, as the test error is constrained by a finite upper bound. We conduct extensive experiments on pre-training from scratch, continual pre-training, and supervised fine-tuning. The results validate our theoretical proof that token-level editing improves data quality and enhances model performance.', 'abstract_zh': '模型在合成数据上的坍塌现象表明，迭代训练于自我生成的数据会导致模型性能逐渐下降。随着AI模型的普及，合成数据将从根本上重塑网络数据生态系统。未来的GPT-$\\{n\\}$模型不可避免地会结合合成数据和人类生成的数据进行训练。在本文中，我们重点探讨了两个问题：合成数据对语言模型训练的影响是什么，如何合成数据而不导致模型坍塌？我们首先在不同比例的合成数据下预训练语言模型，发现合成数据的比例与模型性能之间存在负相关关系。进一步对合成数据进行统计分析，揭示了分布转移现象和n-克隆重集中现象。受上述发现的启发，我们提出对人类生成的数据进行标记编辑，以获得半合成数据。作为概念验证，我们从理论上证明，标记级别编辑可以防止模型坍塌，因为测试误差受有限的上限约束。我们在从头预训练、持续预训练和监督微调方面进行了广泛的实验。结果验证了我们的理论证明：标记水平编辑可以提高数据质量并增强模型性能。', 'title_zh': '如何合成文本数据而不导致模型崩塌？'}
{'arxiv_id': 'arXiv:2412.14686', 'title': 'Each Fake News is Fake in its Own Way: An Attribution Multi-Granularity Benchmark for Multimodal Fake News Detection', 'authors': 'Hao Guo, Zihan Ma, Zhi Zeng, Minnan Luo, Weixin Zeng, Jiuyang Tang, Xiang Zhao', 'link': 'https://arxiv.org/abs/2412.14686', 'abstract': 'Social platforms, while facilitating access to information, have also become saturated with a plethora of fake news, resulting in negative consequences. Automatic multimodal fake news detection is a worthwhile pursuit. Existing multimodal fake news datasets only provide binary labels of real or fake. However, real news is alike, while each fake news is fake in its own way. These datasets fail to reflect the mixed nature of various types of multimodal fake news. To bridge the gap, we construct an attributing multi-granularity multimodal fake news detection dataset \\amg, revealing the inherent fake pattern. Furthermore, we propose a multi-granularity clue alignment model \\our to achieve multimodal fake news detection and attribution. Experimental results demonstrate that \\amg is a challenging dataset, and its attribution setting opens up new avenues for future research.', 'abstract_zh': '社交平台尽管促进了信息的获取，但也充斥着大量虚假信息，导致了一系列负面影响。自动多模态虚假新闻检测是一项值得追求的研究方向。现有的多模态虚假新闻数据集仅提供了真实或虚假的二元标签。然而，真实新闻是相似的，而每条虚假新闻都有其独特的虚假性。这些数据集未能反映各种类型多模态虚假新闻的复杂性质。为弥补这一差距，我们构建了一个属性化多粒度多模态虚假新闻检测数据集 \\AMG，揭示了内在的虚假模式。此外，我们提出了一种多粒度线索对齐模型 \\Our，以实现多模态虚假新闻的检测和溯源。实验结果表明，\\AMG 是一个具有挑战性的数据集，其溯源设置为未来研究开辟了新的方向。', 'title_zh': '每一则虚假新闻都有其独特的方式：一种多粒度归因基准，用于多模态虚假新闻检测'}
{'arxiv_id': 'arXiv:2412.14680', 'title': 'A Light-Weight Framework for Open-Set Object Detection with Decoupled Feature Alignment in Joint Space', 'authors': 'Yonghao He, Hu Su, Haiyong Yu, Cong Yang, Wei Sui, Cong Wang, Song Liu', 'link': 'https://arxiv.org/abs/2412.14680', 'abstract': 'Open-set object detection (OSOD) is highly desirable for robotic manipulation in unstructured environments. However, existing OSOD methods often fail to meet the requirements of robotic applications due to their high computational burden and complex deployment. To address this issue, this paper proposes a light-weight framework called Decoupled OSOD (DOSOD), which is a practical and highly efficient solution to support real-time OSOD tasks in robotic systems. Specifically, DOSOD builds upon the YOLO-World pipeline by integrating a vision-language model (VLM) with a detector. A Multilayer Perceptron (MLP) adaptor is developed to transform text embeddings extracted by the VLM into a joint space, within which the detector learns the region representations of class-agnostic proposals. Cross-modality features are directly aligned in the joint space, avoiding the complex feature interactions and thereby improving computational efficiency. DOSOD operates like a traditional closed-set detector during the testing phase, effectively bridging the gap between closed-set and open-set detection. Compared to the baseline YOLO-World, the proposed DOSOD significantly enhances real-time performance while maintaining comparable accuracy. The slight DOSOD-S model achieves a Fixed AP of $26.7\\%$, compared to $26.2\\%$ for YOLO-World-v1-S and $22.7\\%$ for YOLO-World-v2-S, using similar backbones on the LVIS minival dataset. Meanwhile, the FPS of DOSOD-S is $57.1\\%$ higher than YOLO-World-v1-S and $29.6\\%$ higher than YOLO-World-v2-S. Meanwhile, we demonstrate that the DOSOD model facilitates the deployment of edge devices. The codes and models are publicly available at this https URL.', 'abstract_zh': '开放集目标检测（OSOD）在非结构化环境中机器人操作中具有很高的重要性。然而，现有的OSOD方法往往由于计算负载高和复杂部署而无法满足机器人应用的需求。为解决这一问题，本文提出了一种轻量级框架，称为解耦开集目标检测（DOSOD），这是一种在机器人系统中支持实时OSOD任务的实际且高效的解决方案。具体而言，DOSOD 基于YOLO-World 管线，将视觉-语言模型（VLM）与检测器相结合。开发了一种多层感知器（MLP）适配器，将由VLM 提取的文本嵌入转换为联合空间，在此空间中，检测器学习无类感知提案的区域表示。跨模态特征在联合空间中直接对齐，避免了复杂的特征交互，并提高计算效率。在测试阶段，DOSOD 运作类似于传统的闭集检测器，有效地弥合了闭集和开集检测之间的差距。与基线YOLO-World 相比，所提出的DOSOD 能显著提高实时性能，同时保持相当的准确性。DOSOD-S 模型在LVIS minival 数据集上使用相似的骨干网络，实现了固定AP 的26.7%，而YOLO-World-v1-S 和YOLO-World-v2-S 分别为26.2% 和22.7%。同时，DOSOD-S 的FPS 高于YOLO-World-v1-S 57.1%，高于YOLO-World-v2-S 29.6%。此外，我们展示了DOSOD 模型有助于边缘设备的部署。代码和模型已在此处公开：<https://your-link-here.com>。', 'title_zh': '一种在联合空间中解耦特征对齐的开放集对象检测轻量级框架'}
{'arxiv_id': 'arXiv:2412.14672', 'title': 'FiVL: A Framework for Improved Vision-Language Alignment', 'authors': 'Estelle Aflalo, Gabriela Ben Melech Stan, Tiep Le, Man Luo, Shachar Rosenman, Sayak Paul, Shao-Yen Tseng, Vasudev Lal', 'link': 'https://arxiv.org/abs/2412.14672', 'abstract': "Large Vision Language Models (LVLMs) have achieved significant progress in integrating visual and textual inputs for multimodal reasoning. However, a recurring challenge is ensuring these models utilize visual information as effectively as linguistic content when both modalities are necessary to formulate an accurate answer. We hypothesize that hallucinations arise due to the lack of effective visual grounding in current LVLMs. This issue extends to vision-language benchmarks, where it is difficult to make the image indispensable for accurate answer generation, particularly in vision question-answering tasks. In this work, we introduce FiVL, a novel method for constructing datasets designed to train LVLMs for enhanced visual grounding and to evaluate their effectiveness in achieving it. These datasets can be utilized for both training and assessing an LVLM's ability to use image content as substantive evidence rather than relying solely on linguistic priors, providing insights into the model's reliance on visual information. To demonstrate the utility of our dataset, we introduce an innovative training task that outperforms baselines alongside a validation method and application for explainability. The code is available at this https URL.", 'abstract_zh': '大型视觉语言模型（LVLMs）在整合视觉和文本输入以进行跨模态推理方面取得了显著进展。然而，一个反复出现的挑战是确保这些模型在需要同时利用视觉信息和语言内容时，能够有效地利用视觉信息。我们假设幻觉的产生是由于当前LVLMs缺乏有效的视觉定位。这一问题同样也扩展到了视觉语言基准测试中，在这些基准测试中，很难让图像成为生成准确答案不可或缺的部分，尤其是在视觉问答任务中。在本文中，我们引入了FiVL，一种新颖的方法，用于构建数据集，旨在训练LVLMs以增强视觉定位能力，并评估其在实现该目标方面的有效性。这些数据集既可用于训练，也可用于评估LVLMs利用图像内容作为实质证据而非仅依赖语言先验的能力，从而提供模型对视觉信息依赖性的洞见。为了展示我们数据集的有效性，我们引入了一种创新的训练任务，该任务在基线模型上表现更优，同时提供了一种验证方法和解释性的应用。相关代码已发布于[此链接]。', 'title_zh': 'FiVL：一种改进的视觉-语言对齐框架'}
{'arxiv_id': 'arXiv:2412.14670', 'title': 'Analysis and Visualization of Linguistic Structures in Large Language Models: Neural Representations of Verb-Particle Constructions in BERT', 'authors': 'Hassane Kissane, Achim Schilling, Patrick Krauss', 'link': 'https://arxiv.org/abs/2412.14670', 'abstract': "This study investigates the internal representations of verb-particle combinations within transformer-based large language models (LLMs), specifically examining how these models capture lexical and syntactic nuances at different neural network layers. Employing the BERT architecture, we analyse the representational efficacy of its layers for various verb-particle constructions such as 'agree on', 'come back', and 'give up'. Our methodology includes a detailed dataset preparation from the British National Corpus, followed by extensive model training and output analysis through techniques like multi-dimensional scaling (MDS) and generalized discrimination value (GDV) calculations. Results show that BERT's middle layers most effectively capture syntactic structures, with significant variability in representational accuracy across different verb categories. These findings challenge the conventional uniformity assumed in neural network processing of linguistic elements and suggest a complex interplay between network architecture and linguistic representation. Our research contributes to a better understanding of how deep learning models comprehend and process language, offering insights into the potential and limitations of current neural approaches to linguistic analysis. This study not only advances our knowledge in computational linguistics but also prompts further research into optimizing neural architectures for enhanced linguistic precision.", 'abstract_zh': '本研究探讨了基于变换器的大语言模型（LLMs）内部对动词-粒子组合的表征，具体分析了这些模型在不同神经网络层中如何捕捉词汇和句法细微差别。本研究采用BERT架构，对诸如“agree on”、“come back”和“give up”等各种动词-粒子构式进行了层表征效果分析。研究方法包括从英国国家语料库详细准备数据集，随后进行广泛的模型训练，并通过多维标度分析（MDS）和广义判别值（GDV）计算进行输出分析。结果表明，BERT的中间层最有效地捕捉句法学结构，不同动词类别在表征准确性上存在显著差异。这些发现挑战了神经网络处理语言元素时的均匀假设，并暗示网络架构与语言表征之间存在复杂的相互作用。本研究有助于更好地理解深度学习模型如何理解和处理语言，并对当前神经语言分析方法的潜力和局限性提供了见解。本研究不仅推进了计算语言学的知识边界，还激发了关于优化神经架构以提高语言精度的进一步研究。', 'title_zh': '大型语言模型中的语言结构分析与可视化：BERT中动词-粒子构造的神经表示分析与可视化'}
{'arxiv_id': 'arXiv:2412.14668', 'title': 'LoLaFL: Low-Latency Federated Learning via Forward-only Propagation', 'authors': 'Jierui Zhang, Jianhao Huang, Kaibin Huang', 'link': 'https://arxiv.org/abs/2412.14668', 'abstract': 'Federated learning (FL) has emerged as a widely adopted paradigm for enabling edge learning with distributed data while ensuring data privacy. However, the traditional FL with deep neural networks trained via backpropagation can hardly meet the low-latency learning requirements in the sixth generation (6G) mobile networks. This challenge mainly arises from the high-dimensional model parameters to be transmitted and the numerous rounds of communication required for convergence due to the inherent randomness of the training process. To address this issue, we adopt the state-of-the-art principle of maximal coding rate reduction to learn linear discriminative features and extend the resultant white-box neural network into FL, yielding the novel framework of Low-Latency Federated Learning (LoLaFL) via forward-only propagation. LoLaFL enables layer-wise transmissions and aggregation with significantly fewer communication rounds, thereby considerably reducing latency. Additionally, we propose two \\emph{nonlinear} aggregation schemes for LoLaFL. The first scheme is based on the proof that the optimal NN parameter aggregation in LoLaFL should be harmonic-mean-like. The second scheme further exploits the low-rank structures of the features and transmits the low-rank-approximated covariance matrices of features to achieve additional latency reduction. Theoretic analysis and experiments are conducted to evaluate the performance of LoLaFL. In comparison with traditional FL, the two nonlinear aggregation schemes for LoLaFL can achieve reductions in latency of over 91\\% and 98\\%, respectively, while maintaining comparable accuracies.', 'abstract_zh': '联邦学习（FL）作为一种能够在分布式数据上实现边缘学习的同时确保数据隐私的广泛采用范式，已经脱颖而出。然而，传统的使用反向传播训练深度神经网络的FL难以满足第六代（6G）移动网络中的低延迟学习要求。这一挑战主要源于需要传输的高维模型参数以及训练过程中固有的随机性所需的众多通信轮次。为解决这一问题，我们采用了最先进的最大编码率降低原则，学习线性判别特征，并将由此产生的透明神经网络扩展到联邦学习中，从而提出了新的低延迟联邦学习（LoLaFL）框架，通过单向传播实现每一层的传输和聚合，大幅减少了通信轮次，从而显著降低了延迟。此外，我们还为LoLaFL提出了两种非线性聚合方案。第一个方案基于证明，在LoLaFL中，最优的NN参数聚合应类似调和平均值。第二个方案进一步利用特征的低秩结构，传输特征的低秩逼近协方差矩阵，以实现额外的延迟减少。理论分析和实验用于评估LoLaFL的性能。与传统FL相比，LoLaFL的两种非线性聚合方案分别实现了91%和98%以上的延迟降低，同时保持了相当的准确性。', 'title_zh': 'LoLaFL: 仅前向传播的低延迟联邦学习'}
{'arxiv_id': 'arXiv:2412.14663', 'title': 'IOHunter: Graph Foundation Model to Uncover Online Information Operations', 'authors': 'Marco Minici, Luca Luceri, Francesco Fabbri, Emilio Ferrara', 'link': 'https://arxiv.org/abs/2412.14663', 'abstract': 'Social media platforms have become vital spaces for public discourse, serving as modern agorás where a wide range of voices influence societal narratives. However, their open nature also makes them vulnerable to exploitation by malicious actors, including state-sponsored entities, who can conduct information operations (IOs) to manipulate public opinion. The spread of misinformation, false news, and misleading claims threatens democratic processes and societal cohesion, making it crucial to develop methods for the timely detection of inauthentic activity to protect the integrity of online discourse. In this work, we introduce a methodology designed to identify users orchestrating information operations, a.k.a. \\textit{IO drivers}, across various influence campaigns. Our framework, named \\texttt{IOHunter}, leverages the combined strengths of Language Models and Graph Neural Networks to improve generalization in \\emph{supervised}, \\emph{scarcely-supervised}, and \\emph{cross-IO} contexts. Our approach achieves state-of-the-art performance across multiple sets of IOs originating from six countries, significantly surpassing existing approaches. This research marks a step toward developing Graph Foundation Models specifically tailored for the task of IO detection on social media platforms.', 'abstract_zh': '社交媒体平台已经成为公共 discourse 关键的空间，它们作为现代公共集会场所，广泛的声音影响着社会叙事。然而，它们的开放性质也使其容易被恶意行为者（包括国家资助的实体）利用，这些行为者可以开展信息操作（IO）来操控公众意见。虚假信息、假新闻和误导性言论的传播威胁着民主进程和社会凝聚力，因此及时检测不真实活动的方法对于保护在线讨论的完整性至关重要。在这项工作中，我们提出了一种识别策划信息操作的用户（即IO驾驶员）的方法和框架。我们的框架名为IOHunter，利用语言模型和图神经网络的结合优势，提高在监督、稀疏监督和跨IO场景中的泛化能力。我们的方法在六个国家来源的信息操作数据集中达到了最先进的性能，明显优于现有方法。这项研究标志着朝着专门为社交媒体平台上的信息操作检测任务开发图基础模型方向迈出了一步。', 'title_zh': 'IOHunter：基于图的基金会模型以揭露在线信息操作\n\n这个标题翻译较为符合学术规范，同时保留了原文的专业术语和含义。'}
{'arxiv_id': 'arXiv:2412.14660', 'title': 'Unveiling Uncertainty: A Deep Dive into Calibration and Performance of Multimodal Large Language Models', 'authors': 'Zijun Chen, Wenbo Hu, Guande He, Zhijie Deng, Zheng Zhang, Richang Hong', 'link': 'https://arxiv.org/abs/2412.14660', 'abstract': "Multimodal large language models (MLLMs) combine visual and textual data for tasks such as image captioning and visual question answering. Proper uncertainty calibration is crucial, yet challenging, for reliable use in areas like healthcare and autonomous driving. This paper investigates representative MLLMs, focusing on their calibration across various scenarios, including before and after visual fine-tuning, as well as before and after multimodal training of the base LLMs. We observed miscalibration in their performance, and at the same time, no significant differences in calibration across these scenarios. We also highlight how uncertainty differs between text and images and how their integration affects overall uncertainty. To better understand MLLMs' miscalibration and their ability to self-assess uncertainty, we construct the IDK (I don't know) dataset, which is key to evaluating how they handle unknowns. Our findings reveal that MLLMs tend to give answers rather than admit uncertainty, but this self-assessment improves with proper prompt adjustments. Finally, to calibrate MLLMs and enhance model reliability, we propose techniques such as temperature scaling and iterative prompt optimization. Our results provide insights into improving MLLMs for effective and responsible deployment in multimodal applications. Code and IDK dataset: \\href{this https URL}{this https URL}.", 'abstract_zh': '多模态大型语言模型（MLLMs）结合视觉和文本数据，用于图像字幕、视觉问答等任务。在医疗健康和自动驾驶等关键领域，准确的不确定性校准至关重要，但同时也极具挑战性。本文探讨了代表性的MLLMs，重点研究它们在不同场景下的不确定性校准，包括视觉微调前后及基础大型语言模型的多模态训练前后。我们发现它们的表现存在偏差，但在这些场景之间的校准差异并不显著。此外，本文还强调了文本和图像之间不确定性差异以及它们的整合如何影响整体不确定性。为了更好地理解MLLMs的不确定性偏差及其自我评估不确定性的能力，我们构建了IDK（我不知道）数据集，这对于我们评估它们处理未知数的能力至关重要。我们的研究结果表明，MLLMs倾向于给出答案而不是承认不确定性，但通过适当的提示调整可以改善这种自我评估能力。最后，为了校准MLLMs并提高模型可靠性，我们提出了温度归一化和迭代提示优化等技术。我们的实验结果为我们提供了有关如何有效和负责任地在多模态应用程序中部署MLLMs的见解。代码和IDK数据集：[此处插入代码链接]', 'title_zh': '揭晓不确定性：深入探究多模态大语言模型的校准与性能'}
{'arxiv_id': 'arXiv:2412.14640', 'title': 'Adaptive Prompt Tuning: Vision Guided Prompt Tuning with Cross-Attention for Fine-Grained Few-Shot Learning', 'authors': 'Eric Brouwer, Jan Erik van Woerden, Gertjan Burghouts, Matias Valedenegro-Toro, Marco Zullich', 'link': 'https://arxiv.org/abs/2412.14640', 'abstract': "Few-shot, fine-grained classification in computer vision poses significant challenges due to the need to differentiate subtle class distinctions with limited data. This paper presents a novel method that enhances the Contrastive Language-Image Pre-Training (CLIP) model through adaptive prompt tuning, guided by real-time visual inputs. Unlike existing techniques such as Context Optimization (CoOp) and Visual Prompt Tuning (VPT), which are constrained by static prompts or visual token reliance, the proposed approach leverages a cross-attention mechanism to dynamically refine text prompts for the image at hand. This enables an image-specific alignment of textual features with image patches extracted from the Vision Transformer, making the model more effective for datasets with high intra-class variance and low inter-class differences. The method is evaluated on several datasets, including CUBirds, Oxford Flowers, and FGVC Aircraft, showing significant performance gains over static prompt tuning approaches. To ensure these performance gains translate into trustworthy predictions, we integrate Monte-Carlo Dropout in our approach to improve the reliability of the model predictions and uncertainty estimates. This integration provides valuable insights into the model's predictive confidence, helping to identify when predictions can be trusted and when additional verification is necessary. This dynamic approach offers a robust solution, advancing the state-of-the-art for few-shot fine-grained classification.", 'abstract_zh': '计算机视觉中的少样本、细粒度分类面临着重大挑战，因为它需要在数据有限的情况下区分细微的类别差异。本文提出了一种新颖的方法，通过基于实时视觉输入的自适应提示调整来增强对比语言-图像预训练（CLIP）模型。与现有的技术如上下文优化（CoOp）和视觉提示调整（VPT）相比，这些技术分别受限于静态提示和视觉标记依赖，本文提出的方法利用跨注意力机制动态细化当前图像的文本提示。这使得文本特征与来自视觉变换器提取的图像补丁实现特定于图像的对齐，从而使模型能够更好地处理高类内方差和低类间差异的数据集。该方法在CUBirds、Oxford Flowers和FGVC Aircraft等几个数据集上进行了评估，显示了相对于静态提示调整方法的显著性能提升。为了确保这些性能提升能够转化为可靠的预测，本文将蒙特卡洛dropout集成到方法中，以提高模型预测和不确定性估计的可靠性。这种集成提供了关于模型预测置信度的宝贵洞察，有助于识别可信赖的预测和需要额外验证的情况。这种动态方法提供了一种稳健的解决方案，推动了少样本细粒度分类的最新进展。', 'title_zh': '自适应提示调优：跨注意力引导的视觉导向提示调优在细粒度少样本学习中的应用'}
{'arxiv_id': 'arXiv:2412.14639', 'title': 'A Shapley Value Estimation Speedup for Efficient Explainable Quantum AI', 'authors': 'Iain Burge, Michel Barbeau, Joaquin Garcia-Alfaro', 'link': 'https://arxiv.org/abs/2412.14639', 'abstract': "This work focuses on developing efficient post-hoc explanations for quantum AI algorithms. In classical contexts, the cooperative game theory concept of the Shapley value adapts naturally to post-hoc explanations, where it can be used to identify which factors are important in an AI's decision-making process. An interesting question is how to translate Shapley values to the quantum setting and whether quantum effects could be used to accelerate their calculation. We propose quantum algorithms that can extract Shapley values within some confidence interval. Our method is capable of quadratically outperforming classical Monte Carlo approaches to approximating Shapley values up to polylogarithmic factors in various circumstances. We demonstrate the validity of our approach empirically with specific voting games and provide rigorous proofs of performance for general cooperative games.", 'abstract_zh': '本文关注于开发高效的事后解释方法，用于量子人工智能算法。在经典背景下，合作博弈论中的Shapley值概念自然适用于事后解释，可用于识别哪些因素在人工智能的决策过程中起着重要作用。一个有趣的问题是如何将Shapley值应用于量子设置，并且量子效应是否可以用于加速其计算。我们提出了一类量子算法，能够在某种程度上的置信区间内提取Shapley值。我们的方法在某些情况下能够在多项对数因子内比经典的蒙特卡罗方法更有效地进行Shapley值的近似。我们通过针对特定投票博弈的实验验证了我们方法的有效性，并提供了关于通用合作博弈性能的严格证明。', 'title_zh': '高效可解释的量子人工智能中的Shapley值估计加速'}
{'arxiv_id': 'arXiv:2412.14633', 'title': 'Progressive Fine-to-Coarse Reconstruction for Accurate Low-Bit Post-Training Quantization in Vision Transformers', 'authors': 'Rui Ding, Liang Yong, Sihuan Zhao, Jing Nie, Lihui Chen, Haijun Liu, Xichuan Zhou', 'link': 'https://arxiv.org/abs/2412.14633', 'abstract': 'Due to its efficiency, Post-Training Quantization (PTQ) has been widely adopted for compressing Vision Transformers (ViTs). However, when quantized into low-bit representations, there is often a significant performance drop compared to their full-precision counterparts. To address this issue, reconstruction methods have been incorporated into the PTQ framework to improve performance in low-bit quantization settings. Nevertheless, existing related methods predefine the reconstruction granularity and seldom explore the progressive relationships between different reconstruction granularities, which leads to sub-optimal quantization results in ViTs. To this end, in this paper, we propose a Progressive Fine-to-Coarse Reconstruction (PFCR) method for accurate PTQ, which significantly improves the performance of low-bit quantized vision transformers. Specifically, we define multi-head self-attention and multi-layer perceptron modules along with their shortcuts as the finest reconstruction units. After reconstructing these two fine-grained units, we combine them to form coarser blocks and reconstruct them at a coarser granularity level. We iteratively perform this combination and reconstruction process, achieving progressive fine-to-coarse reconstruction. Additionally, we introduce a Progressive Optimization Strategy (POS) for PFCR to alleviate the difficulty of training, thereby further enhancing model performance. Experimental results on the ImageNet dataset demonstrate that our proposed method achieves the best Top-1 accuracy among state-of-the-art methods, particularly attaining 75.61% for 3-bit quantized ViT-B in PTQ. Besides, quantization results on the COCO dataset reveal the effectiveness and generalization of our proposed method on other computer vision tasks like object detection and instance segmentation.', 'abstract_zh': '由于其高效性，后训练量化（Post-Training Quantization, PTQ）已被广泛应用于视觉变换器（Vision Transformers, ViTs）的压缩。然而，在转换为低比特表示时，量化ViTs往往会与高精度版本相比出现显著的性能下降。为了解决这一问题，已经将重构方法融入PTQ框架中，以提高低比特量化设置下的性能。尽管如此，现有的相关方法往往预先定义了重构粒度，很少探索不同重构粒度之间的逐步关系，这导致ViTs在量化过程中出现了次优的结果。鉴于此，本文提出了一种逐步精细到粗放重构（Progressive Fine-to-Coarse Reconstruction, PFCR）方法，旨在显著提升低比特量化视觉变换器的性能。具体来说，我们定义了多头自注意和多层感知机模块及其捷径作为最精细的重构单元。在重构这两个精细粒度单元后，我们将它们合并成较粗的块，并在较粗的粒度级别对其进行重构。我们通过重复这个合并和重构的过程，实现了逐步精细到粗放的重构。此外，我们引入了逐步优化策略（Progressive Optimization Strategy, POS），以缓解训练难度，进一步提高模型性能。实验结果表明，我们提出的方法在ImageNet数据集上达到了最先进的Top-1精度，特别是对于PTQ中的3比特量化ViT-B，其精度达到了75.61%。另外，对COCO数据集的量化结果表明，我们提出的方法在其他计算机视觉任务如目标检测和实例分割中也具有有效性和普适性。', 'title_zh': '面向视觉变换器的逐级细粒度到粗粒度重建方法，以实现精确的低比特量化后训练'}
{'arxiv_id': 'arXiv:2412.14626', 'title': 'Learning to Generate Research Idea with Dynamic Control', 'authors': 'Ruochen Li, Liqiang Jing, Chi Han, Jiawei Zhou, Xinya Du', 'link': 'https://arxiv.org/abs/2412.14626', 'abstract': 'The rapid advancements in large language models (LLMs) have demonstrated their potential to accelerate scientific discovery, particularly in automating the process of research ideation. LLM-based systems have shown promise in generating hypotheses and research ideas. However, current approaches predominantly rely on prompting-based pre-trained models, limiting their ability to optimize generated content effectively. Moreover, they also lack the capability to deal with the complex interdependence and inherent restrictions among novelty, feasibility, and effectiveness, which remains challenging due to the inherent trade-offs among these dimensions, such as the innovation-feasibility conflict. To address these limitations, we for the first time propose fine-tuning LLMs to be better idea proposers and introduce a novel framework that employs a two-stage approach combining Supervised Fine-Tuning (SFT) and controllable Reinforcement Learning (RL). In the SFT stage, the model learns foundational patterns from pairs of research papers and follow-up ideas. In the RL stage, multi-dimensional reward modeling, guided by fine-grained feedback, evaluates and optimizes the generated ideas across key metrics. Dimensional controllers enable dynamic adjustment of generation, while a sentence-level decoder ensures context-aware emphasis during inference. Our framework provides a balanced approach to research ideation, achieving high-quality outcomes by dynamically navigating the trade-offs among novelty, feasibility, and effectiveness.', 'abstract_zh': '大型语言模型（LLMs）的迅速发展已经显示了它们在加速科学研究方面的潜力，尤其是在自动化研究构想过程方面。基于LLM的系统在生成假设和研究构想方面显示出一定的前景。然而，当前的方法主要依赖于提示驱动的预训练模型，限制了它们有效优化生成内容的能力。此外，这些方法还缺乏处理新颖性、可行性和效果之间复杂相互依赖性和固有约束的能力，这些约束之间的权衡使得这种处理极具挑战性，例如创新与可行性的冲突。为了解决这些限制，我们首次提出对LLMs进行微调，使其更好地提出构想，并引入了一种新颖的框架，该框架结合了监督微调（SFT）和可控强化学习（RL）的两阶段方法。在SFT阶段，模型从研究论文及其后续想法的成对数据中学习基础模式。在RL阶段，通过精细反馈指导的多维奖励建模评估和优化生成的构想，以跨关键指标进行。维度控制器可以动态调整生成过程，而在推理过程中确保上下文感知的重点。我们的框架提供了一种平衡的研究构想方法，通过动态导航新颖性、可行性和效果之间的权衡，实现高质量的结果。', 'title_zh': '学习通过动态控制生成研究想法'}
{'arxiv_id': 'arXiv:2412.14619', 'title': 'Pitfalls of topology-aware image segmentation', 'authors': 'Alexander H. Berger, Laurin Lux, Alexander Weers, Martin Menten, Daniel Rueckert, Johannes C. Paetzold', 'link': 'https://arxiv.org/abs/2412.14619', 'abstract': "Topological correctness, i.e., the preservation of structural integrity and specific characteristics of shape, is a fundamental requirement for medical imaging tasks, such as neuron or vessel segmentation. Despite the recent surge in topology-aware methods addressing this challenge, their real-world applicability is hindered by flawed benchmarking practices. In this paper, we identify critical pitfalls in model evaluation that include inadequate connectivity choices, overlooked topological artifacts in ground truth annotations, and inappropriate use of evaluation metrics. Through detailed empirical analysis, we uncover these issues' profound impact on the evaluation and ranking of segmentation methods. Drawing from our findings, we propose a set of actionable recommendations to establish fair and robust evaluation standards for topology-aware medical image segmentation methods.", 'abstract_zh': '拓扑正确性，即保持形状的结构完整性和特定特征，是医学成像任务（如神经元或血管分割）中的基本要求。尽管近期对这一挑战的拓扑感知方法有所增加，但它们的实际应用受到了不当基准测试实践的限制。本文中，我们指出了模型评估中的关键问题，包括不充分的连通性选择、在真实标注中忽略的拓扑伪影，以及不合适的评估指标使用方式。通过详细的实证分析，我们揭示了这些问题对分割方法的评估和排名产生深远影响。基于我们的发现，我们提出了建立公平且稳健的拓扑感知医学图像分割方法评估标准的一系列实用建议。', 'title_zh': '拓扑感知图像分割的局限性'}
{'arxiv_id': 'arXiv:2412.14617', 'title': 'How good is GPT at writing political speeches for the White House?', 'authors': 'Jacques Savoy', 'link': 'https://arxiv.org/abs/2412.14617', 'abstract': 'Using large language models (LLMs), computers are able to generate a written text in response to a us er request. As this pervasive technology can be applied in numerous contexts, this study analyses the written style of one LLM called GPT by comparing its generated speeches with those of the recent US presidents. To achieve this objective, the State of the Union (SOTU) addresses written by Reagan to Biden are contrasted to those produced by both GPT-3.5 and GPT-4.o versions. Compared to US presidents, GPT tends to overuse the lemma "we" and produce shorter messages with, on average, longer sentences. Moreover, GPT opts for an optimistic tone, opting more often for political (e.g., president, Congress), symbolic (e.g., freedom), and abstract terms (e.g., freedom). Even when imposing an author\'s style to GPT, the resulting speech remains distinct from addresses written by the target author. Finally, the two GPT versions present distinct characteristics, but both appear overall dissimilar to true presidential messages.', 'abstract_zh': '利用大型语言模型（LLMs），计算机能够根据用户请求生成书面文本。由于这一普遍性技术可以应用于众多领域，本研究通过将一个名为GPT的LLM生成的演讲与近期美国总统的演讲进行比较，分析了GPT的书面风格。为了实现这一目标，本研究对比了里根总统至拜登总统的国情咨文（SOTU）与GPT-3.5和GPT-4版本生成的演讲。与美国总统相比，GPT倾向于过度使用“我们”这一词素，产生的信息较短且平均句子较长。此外，GPT倾向于采用更为乐观的语气，更频繁地使用政治性（例如，总统、国会）、象征性（例如，自由）和抽象性（例如，自由）词汇。即使对GPT施加特定作者的风格限制，生成的演讲仍与目标作者的演讲存在区别。最后，两个GPT版本具有不同的特点，但整体来看，两者与真实的总统演讲均存在显著差异。', 'title_zh': 'GPT在为白宫撰写政治演讲方面的表现如何？'}
{'arxiv_id': 'arXiv:2412.14613', 'title': 'HarmonicEval: Multi-modal, Multi-task, Multi-criteria Automatic Evaluation Using a Vision Language Model', 'authors': 'Masanari Ohi, Masahiro Kaneko, Naoaki Okazaki, Nakamasa Inoue', 'link': 'https://arxiv.org/abs/2412.14613', 'abstract': 'Vision-language models (VLMs) have shown impressive abilities in text and image understanding. However, existing metrics for evaluating the text generated by VLMs focus exclusively on overall quality, leading to two limitations: 1) it is challenging to identify which aspects of the text need improvement from the overall score; 2) metrics may overlook specific evaluation criteria when predicting an overall score. To address these limitations, we propose HarmonicEval, a reference-free evaluation metric that aggregates criterion-wise scores to produce the overall score in a bottom-up manner. Furthermore, we construct the Multi-task Multi-criteria Human Evaluation (MMHE) dataset, which comprises 18,000 expert human judgments across four vision-language tasks. Our experiments demonstrate that HarmonicEval achieves higher correlations with human judgments than conventional metrics while providing numerical scores for each criterion.', 'abstract_zh': '视觉-语言模型（VLMs）在文本和图像理解方面展现了令人印象深刻的 ability。然而，目前用于评估VLMs生成文本的指标仅集中于整体质量，导致两个局限性：1）难以从总体评分中识别哪些方面需要改进；2）在预测总体评分时，指标可能忽略特定的评估标准。为解决这些局限性，我们提出了一种名为HarmonicEval的参考独立评估指标，该指标以自底向上的方式聚合各个标准的评分以生成总体评分。此外，我们构建了包含18,000名专家对四项视觉-语言任务的人类评判的Multi-task Multi-criteria Human Evaluation (MMHE) 数据集。我们的实验表明，与传统指标相比，HarmonicEval在与人类评判的相关性上更高，并且能够为每个标准提供数字评分。', 'title_zh': '谐波评估：基于视觉语言模型的多模态、多任务、多指标自动评价方法'}
{'arxiv_id': 'arXiv:2412.14602', 'title': 'Towards Scalable and Deep Graph Neural Networks via Noise Masking', 'authors': 'Yuxuan Liang, Wentao Zhang, Zeang Sheng, Ling Yang, Quanqing Xu, Jiawei Jiang, Yunhai Tong, Bin Cu', 'link': 'https://arxiv.org/abs/2412.14602', 'abstract': 'In recent years, Graph Neural Networks (GNNs) have achieved remarkable success in many graph mining tasks. However, scaling them to large graphs is challenging due to the high computational and storage costs of repeated feature propagation and non-linear transformation during training. One commonly employed approach to address this challenge is model-simplification, which only executes the Propagation (P) once in the pre-processing, and Combine (C) these receptive fields in different ways and then feed them into a simple model for better performance. Despite their high predictive performance and scalability, these methods still face two limitations. First, existing approaches mainly focus on exploring different C methods from the model perspective, neglecting the crucial problem of performance degradation with increasing P depth from the data-centric perspective, known as the over-smoothing problem. Second, pre-processing overhead takes up most of the end-to-end processing time, especially for large-scale graphs. To address these limitations, we present random walk with noise masking (RMask), a plug-and-play module compatible with the existing model-simplification works. This module enables the exploration of deeper GNNs while preserving their scalability. Unlike the previous model-simplification works, we focus on continuous P and found that the noise existing inside each P is the cause of the over-smoothing issue, and use the efficient masking mechanism to eliminate them. Experimental results on six real-world datasets demonstrate that model-simplification works equipped with RMask yield superior performance compared to their original version and can make a good trade-off between accuracy and efficiency.', 'abstract_zh': '近年来，图神经网络（GNNs）在许多图挖掘任务中取得了显著的成功。然而，将其扩展到大规模图中是一项挑战，因为重复特征传播和非线性变换在训练过程中会产生高计算和存储成本。一种常用的方法是模型简化，这种方法在预处理阶段仅执行一次传播（P），并通过不同方式结合（C）这些感受野，然后将其输入到一个简单的模型中以提高性能。尽管这些方法具有高预测性能和可扩展性，但它们仍然面临两个局限性。首先，现有方法主要从模型视角探索不同的C方法，忽视了数据为中心视角下随着P深度增加而导致的性能下降问题，即过度平滑问题。其次，预处理开销占用了端到端处理时间的大部分，特别是在大规模图的情况下更为明显。为了解决这些问题，我们提出了随机游走带噪声掩蔽（RMask）模块，这是一个可与现有模型简化工作兼容的插件模块。该模块使我们能够探索更深层次的GNNs，同时保留其可扩展性。与之前的模型简化方法不同，我们重点关注连续的P，并发现存在于每个P中的噪声是导致过度平滑问题的原因，并利用高效的掩蔽机制来消除这些噪声。在六个真实世界的数据集上的实验结果显示，配备RMask的模型简化工作相比其原始版本具有更优的性能，并能较好地在准确性和效率之间进行权衡。', 'title_zh': '通过噪声掩蔽实现可扩展且深层的图神经网络'}
{'arxiv_id': 'arXiv:2412.14587', 'title': 'Spike2Former: Efficient Spiking Transformer for High-performance Image Segmentation', 'authors': 'Zhenxin Lei, Man Yao, Jiakui Hu, Xinhao Luo, Yanye Lu, Bo Xu, Guoqi Li', 'link': 'https://arxiv.org/abs/2412.14587', 'abstract': 'Spiking Neural Networks (SNNs) have a low-power advantage but perform poorly in image segmentation tasks. The reason is that directly converting neural networks with complex architectural designs for segmentation tasks into spiking versions leads to performance degradation and non-convergence. To address this challenge, we first identify the modules in the architecture design that lead to the severe reduction in spike firing, make targeted improvements, and propose Spike2Former architecture. Second, we propose normalized integer spiking neurons to solve the training stability problem of SNNs with complex architectures. We set a new state-of-the-art for SNNs in various semantic segmentation datasets, with a significant improvement of +12.7% mIoU and 5.0 efficiency on ADE20K, +14.3% mIoU and 5.2 efficiency on VOC2012, and +9.1% mIoU and 6.6 efficiency on CityScapes.', 'abstract_zh': '脉冲神经网络（SNNs）具有低功耗的优势，但在图像分割任务中表现不佳。原因是直接将具有复杂架构设计的神经网络转换为适合分割任务的脉冲版本，会导致性能下降和不收敛。为解决这一挑战，我们首先识别导致尖峰发射严重减少的架构模块，进行针对性改进，并提出了一种名为Spike2Former的架构。其次，我们提出了归一化整数脉冲神经元，以解决复杂架构的SNN在训练稳定性方面的问题。我们在各种语义分割数据集上达到了SNN的新最好性能，具体为：在ADE20K数据集上实现了12.7%的mIoU显著提升和5.0的效率改进，在VOC2012数据集上实现了14.3%的mIoU显著提升和5.2的效率改进，在CityScapes数据集上实现了9.1%的mIoU显著提升和6.6的效率改进。', 'title_zh': 'Spike2Former: 高效的脉冲变压器模型，用于高性能图像分割'}
{'arxiv_id': 'arXiv:2412.14579', 'title': 'GSRender: Deduplicated Occupancy Prediction via Weakly Supervised 3D Gaussian Splatting', 'authors': 'Qianpu Sun, Changyong Shu, Sifan Zhou, Zichen Yu, Yan Chen, Dawei Yang, Yuan Chun', 'link': 'https://arxiv.org/abs/2412.14579', 'abstract': '3D occupancy perception is gaining increasing attention due to its capability to offer detailed and precise environment representations. Previous weakly-supervised NeRF methods balance efficiency and accuracy, with mIoU varying by 5-10 points due to sampling count along camera rays. Recently, real-time Gaussian splatting has gained widespread popularity in 3D reconstruction, and the occupancy prediction task can also be viewed as a reconstruction task. Consequently, we propose GSRender, which naturally employs 3D Gaussian Splatting for occupancy prediction, simplifying the sampling process. In addition, the limitations of 2D supervision result in duplicate predictions along the same camera ray. We implemented the Ray Compensation (RC) module, which mitigates this issue by compensating for features from adjacent frames. Finally, we redesigned the loss to eliminate the impact of dynamic objects from adjacent frames. Extensive experiments demonstrate that our approach achieves SOTA (state-of-the-art) results in RayIoU (+6.0), while narrowing the gap with 3D supervision methods. Our code will be released soon.', 'abstract_zh': '3D 占有率感知正逐渐受到重视，因为其能够提供详细的精确环境表示。先前的弱监督 NeRF 方法在效率与准确性之间取得了平衡，但由于沿相机射线的采样数量不同，mIoU 的变化范围在 5-10 个百分点之间。近来，实时高斯点绘制在 3D 重建中获得了广泛的关注，而占有率预测任务也可以被视为一种重建任务。因此，我们提出了一种名为 GSRender 的方法，该方法自然地利用 3D 高斯点绘制来进行占有率预测，简化了采样过程。此外，2D 监督的局限性导致在相同的相机射线上产生重复预测。我们实现了 Ray 补偿 (RC) 模块，通过补偿相邻帧中的特征来缓解这一问题。最后，我们重新设计了损失函数，以消除相邻帧中动态对象的影响。广泛的实验表明，我们的方法在 RayIoU 上实现了 SOTA (目前最先进的) 结果，同时缩小了与 3D 监督方法之间的差距。我们的代码将很快发布。', 'title_zh': 'GSRender：通过弱监督3D高斯点绘画进行的去重占用预测'}
{'arxiv_id': 'arXiv:2412.14571', 'title': 'SCKD: Semi-Supervised Cross-Modality Knowledge Distillation for 4D Radar Object Detection', 'authors': 'Ruoyu Xu, Zhiyu Xiang, Chenwei Zhang, Hanzhi Zhong, Xijun Zhao, Ruina Dang, Peng Xu, Tianyu Pu, Eryun Liu', 'link': 'https://arxiv.org/abs/2412.14571', 'abstract': '3D object detection is one of the fundamental perception tasks for autonomous vehicles. Fulfilling such a task with a 4D millimeter-wave radar is very attractive since the sensor is able to acquire 3D point clouds similar to Lidar while maintaining robust measurements under adverse weather. However, due to the high sparsity and noise associated with the radar point clouds, the performance of the existing methods is still much lower than expected. In this paper, we propose a novel Semi-supervised Cross-modality Knowledge Distillation (SCKD) method for 4D radar-based 3D object detection. It characterizes the capability of learning the feature from a Lidar-radar-fused teacher network with semi-supervised distillation. We first propose an adaptive fusion module in the teacher network to boost its performance. Then, two feature distillation modules are designed to facilitate the cross-modality knowledge transfer. Finally, a semi-supervised output distillation is proposed to increase the effectiveness and flexibility of the distillation framework. With the same network structure, our radar-only student trained by SCKD boosts the mAP by 10.38% over the baseline and outperforms the state-of-the-art works on the VoD dataset. The experiment on ZJUODset also shows 5.12% mAP improvements on the moderate difficulty level over the baseline when extra unlabeled data are available. Code is available at this https URL.', 'abstract_zh': '三维物体检测是自动驾驶车辆基本感知任务之一。使用4D毫米波雷达来完成这项任务非常吸引人，因为传感器能够获取类似于激光雷达的3D点云同时还能在恶劣天气下保持稳健的测量。然而，由于雷达点云的高稀疏性和噪声，现有方法的性能仍然远低于预期。在本文中，我们提出了一种新颖的半监督跨模态知识蒸馏（SCKD）方法，用于基于4D雷达的三维物体检测。该方法通过半监督蒸馏来表征学习特征的能力，是从LiDar-雷达融合教师网络中获得的。我们首先在教师网络中提出一种自适应融合模块以提升其性能。接着，设计了两个特征蒸馏模块以促进跨模态知识的转移。最后，提出了一种半监督输出蒸馏以增加蒸馏框架的有效性和灵活性。在相同的网络结构下，通过SCKD训练的纯雷达学生网络在基准上的mAP提升了10.38%，并在VoD数据集上的表现超过了最新方法。当额外的未标注数据可用时，ZJUOD数据集的实验也表明SCKD在中等难度上的mAP提升了5.12%。代码已在此处提供：[链接]。', 'title_zh': 'SCKD：半监督跨模态知识蒸馏在4D雷达目标检测中的应用'}
{'arxiv_id': 'arXiv:2412.14570', 'title': 'Characterising Simulation-Based Program Equilibria', 'authors': 'Emery Cooper, Caspar Oesterheld, Vincent Conitzer', 'link': 'https://arxiv.org/abs/2412.14570', 'abstract': "In Tennenholtz's program equilibrium, players of a game submit programs to play on their behalf. Each program receives the other programs' source code and outputs an action. This can model interactions involving AI agents, mutually transparent institutions, or commitments. Tennenholtz (2004) proves a folk theorem for program games, but the equilibria constructed are very brittle. We therefore consider simulation-based programs -- i.e., programs that work by running opponents' programs. These are relatively robust (in particular, two programs that act the same are treated the same) and are more practical than proof-based approaches. Oesterheld's (2019) $\\epsilon$Grounded$\\pi$Bot is such an approach. Unfortunately, it is not generally applicable to games of three or more players, and only allows for a limited range of equilibria in two player games. In this paper, we propose a generalisation to Oesterheld's (2019) $\\epsilon$Grounded$\\pi$Bot. We prove a folk theorem for our programs in a setting with access to a shared source of randomness. We then characterise their equilibria in a setting without shared randomness. Both with and without shared randomness, we achieve a much wider range of equilibria than Oesterheld's (2019) $\\epsilon$Grounded$\\pi$Bot. Finally, we explore the limits of simulation-based program equilibrium, showing that the Tennenholtz folk theorem cannot be attained by simulation-based programs without access to shared randomness.", 'abstract_zh': '在Tennenholtz的游戏程序均衡中，游戏的参与者提交程序来代表自己进行游戏。每个程序会接收对方程序的源代码并输出一个行动。这可以模拟涉及AI代理、相互透明的机构或承诺的互动。Tennenholtz (2004) 证明了程序游戏中的folk定理，但构建的均衡非常脆弱。因此，我们考虑基于模拟的程序——即通过运行对手程序的方式工作的程序。这些程序相对稳健（特别是，行为相同的程序将受到相同的处理），且比基于证明的方法更加实用。Oesterheld (2019) 的$\\epsilon$Grounded$\\pi$Bot就是一种这样的方法。不幸的是，它不适用于三人或以上玩家的游戏，并且仅允许在两人游戏中有限范围的均衡。在本文中，我们提出了一种对Oesterheld (2019) 的$\\epsilon$Grounded$\\pi$Bot的推广。我们证明了在可以访问共享随机性的环境中，这些程序的folk定理。然后，我们探讨了在没有共享随机性的环境中，它们的均衡特性。无论是存在还是不存在共享随机性，我们均实现了比Oesterheld (2019) 的$\\epsilon$Grounded$\\pi$Bot更广泛的均衡范围。最后，我们探讨了基于模拟的程序均衡的极限，表明没有共享随机性的环境中，Tennenholtz的folk定理无法通过基于模拟的程序实现。', 'title_zh': '基于模拟的程序均衡性characterization'}
{'arxiv_id': 'arXiv:2412.14569', 'title': 'Global Spatio-Temporal Fusion-based Traffic Prediction Algorithm with Anomaly Aware', 'authors': 'Chaoqun Liu, Xuanpeng Li, Chen Gong, Guangyu Li', 'link': 'https://arxiv.org/abs/2412.14569', 'abstract': 'Traffic prediction is an indispensable component of urban planning and traffic management. Achieving accurate traffic prediction hinges on the ability to capture the potential spatio-temporal relationships among road sensors. However, the majority of existing works focus on local short-term spatio-temporal correlations, failing to fully consider the interactions of different sensors in the long-term state. In addition, these works do not analyze the influences of anomalous factors, or have insufficient ability to extract personalized features of anomalous factors, which make them ineffectively capture their spatio-temporal influences on traffic prediction. To address the aforementioned issues, We propose a global spatio-temporal fusion-based traffic prediction algorithm that incorporates anomaly awareness. Initially, based on the designed anomaly detection network, we construct an efficient anomalous factors impacting module (AFIM), to evaluate the spatio-temporal impact of unexpected external events on traffic prediction. Furthermore, we propose a multi-scale spatio-temporal feature fusion module (MTSFFL) based on the transformer architecture, to obtain all possible both long and short term correlations among different sensors in a wide-area traffic environment for accurate prediction of traffic flow. Finally, experiments are implemented based on real-scenario public transportation datasets (PEMS04 and PEMS08) to demonstrate that our approach can achieve state-of-the-art performance.', 'abstract_zh': '交通预测是城市规划和交通管理不可或缺的组成部分。实现准确的交通预测关键在于捕捉道路传感器之间潜在的时空关系。然而，现有大多数研究工作主要集中在局部短期时空关联上，未能充分考虑不同传感器在长期状态中的相互作用。此外，这些研究并未分析异常因素的影响，或提取异常因素的个性化特征的能力不足，导致它们难以有效地捕捉这些因素对交通预测的时空影响。为解决上述问题，我们提出了一种结合异常意识的全局时空融合交通预测算法。首先，基于设计的异常检测网络，我们构建了一个高效的异常因素影响模块（AFIM），以评估意外外部事件对交通预测的时空影响。其次，我们基于Transformer架构提出了一个多尺度时空特征融合模块（MTSFFL），以在广泛区域交通环境中获取不同传感器之间所有可能的短期和长期关联，从而实现准确的交通流量预测。最后，我们基于实际情况的公共交通数据集（PEMS04和PEMS08）进行了实验，证明我们的方法能够达到最先进的性能。', 'title_zh': '基于全局时空融合且具备异常检测能力的交通预测算法'}
{'arxiv_id': 'arXiv:2412.14566', 'title': 'AIArena: A Blockchain-Based Decentralized AI Training Platform', 'authors': 'Zhipeng Wang, Rui Sun, Elizabeth Lui, Tuo Zhou, Yizhe Wen, Jiahao Sun', 'link': 'https://arxiv.org/abs/2412.14566', 'abstract': 'The rapid advancement of AI has underscored critical challenges in its development and implementation, largely due to centralized control by a few major corporations. This concentration of power intensifies biases within AI models, resulting from inadequate governance and oversight mechanisms. Additionally, it limits public involvement and heightens concerns about the integrity of model generation. Such monopolistic control over data and AI outputs threatens both innovation and fair data usage, as users inadvertently contribute data that primarily benefits these corporations. In this work, we propose AIArena, a blockchain-based decentralized AI training platform designed to democratize AI development and alignment through on-chain incentive mechanisms. AIArena fosters an open and collaborative environment where participants can contribute models and computing resources. Its on-chain consensus mechanism ensures fair rewards for participants based on their contributions. We instantiate and implement AIArena on the public Base blockchain Sepolia testnet, and the evaluation results demonstrate the feasibility of AIArena in real-world applications.', 'abstract_zh': '人工智能的快速进步凸显了其在开发和实施过程中面临的关键挑战，主要是由于少数几家大型企业集中控制。这种权力的集中加剧了AI模型中的偏见，并且由于缺乏有效的治理和监督机制而加剧了问题。此外，这也限制了公众的参与，并增加了对模型生成完整性的担忧。这种对数据和AI输出的垄断控制不仅威胁到创新，还可能导致数据使用的不公平，因为用户无意中贡献的数据主要有利于这些企业。在这项工作中，我们提出了一种基于区块链的去中心化AI训练平台AIArena，旨在通过链上激励机制来民主化AI开发和对齐。AIArena促进了开放和协作的环境，参与者可以提交模型和计算资源。其链上共识机制确保参与者根据其贡献获得公平的奖励。我们已在公共Base区块链Sepolia测试网上实现和部署了AIArena，并且评估结果表明AIArena在实际应用中的可行性。', 'title_zh': 'AIArena：基于区块链的去中心化人工智能训练平台'}
{'arxiv_id': 'arXiv:2412.14545', 'title': 'Summary of Point Transformer with Federated Learning for Predicting Breast Cancer HER2 Status from Hematoxylin and Eosin-Stained Whole Slide Images', 'authors': 'Kamorudeen A. Amuda, Almustapha A. Wakili', 'link': 'https://arxiv.org/abs/2412.14545', 'abstract': 'This study introduces a federated learning-based approach to predict HER2 status from hematoxylin and eosin (HE)-stained whole slide images (WSIs), reducing costs and speeding up treatment decisions. To address label imbalance and feature representation challenges in multisite datasets, a point transformer is proposed, incorporating dynamic label distribution, an auxiliary classifier, and farthest cosine sampling. Extensive experiments demonstrate state-of-the-art performance across four sites (2687 WSIs) and strong generalization to two unseen sites (229 WSIs).', 'abstract_zh': '本研究提出了一种基于联邦学习的方法，用于预测苏木精和伊红（HE）染色全切片图像（WSI）中的HER2状态，从而降低相关成本并加快治疗决策过程。为了应对多中心数据集中标签不平衡和特征表示的挑战，提出了一种点变换器，该变换器结合了动态标签分布、辅助分类器和最远余弦采样方法。广泛的实验表明，该方法在四个中心（共2687张WSI）上取得了最先进的性能，并且在两个未见中心（共229张WSI）上表现出强大的泛化能力。', 'title_zh': '基于联邦学习的点变换器摘要：用于预测乳腺癌HER2状态的苏木精和 ⓘ 染色全切片图像分析'}
{'arxiv_id': 'arXiv:2412.14538', 'title': 'Overview of AI and Communication for 6G Network: Fundamentals, Challenges, and Future Research Opportunities', 'authors': 'Qimei Cui, Xiaohu You, Ni Wei, Guoshun Nan, Xuefei Zhang, Jianhua Zhang, Xinchen Lyu, Ming Ai, Xiaofeng Tao, Zhiyong Feng, Ping Zhang, Qingqing Wu, Meixia Tao, Yongming Huang, Chongwen Huang, Guangyi Liu, Chenghui Peng, Zhiwen Pan, Tao Sun, Dusit Niyato, Tao Chen, Muhammad Khurram Khan, Abbas Jamalipour, Mohsen Guizani, Chau Yuen', 'link': 'https://arxiv.org/abs/2412.14538', 'abstract': 'With the increasing demand for seamless connectivity and intelligent communication, the integration of artificial intelligence (AI) and communication for sixth-generation (6G) network is emerging as a revolutionary architecture. This paper presents a comprehensive overview of AI and communication for 6G networks, emphasizing their foundational principles, inherent challenges, and future research opportunities. We commence with a retrospective analysis of AI and the evolution of large-scale AI models, underscoring their pivotal roles in shaping contemporary communication technologies. The discourse then transitions to a detailed exposition of the envisioned integration of AI within 6G networks, delineated across three progressive developmental stages. The initial stage, AI for Network, focuses on employing AI to augment network performance, optimize efficiency, and enhance user service experiences. The subsequent stage, Network for AI, highlights the role of the network in facilitating and buttressing AI operations and presents key enabling technologies, including digital twins for AI and semantic communication. In the final stage, AI as a Service, it is anticipated that future 6G networks will innately provide AI functions as services and support application scenarios like immersive communication and intelligent industrial robots. Specifically, we have defined the quality of AI service, which refers to the measurement framework system of AI services within the network. In addition to these developmental stages, we thoroughly examine the standardization processes pertinent to AI in network contexts, highlighting key milestones and ongoing efforts. Finally, we outline promising future research opportunities that could drive the evolution and refinement of AI and communication for 6G, positioning them as a cornerstone of next-generation communication infrastructure.', 'abstract_zh': '随着对无缝连接和智能通信需求的不断增加，人工智能（AI）与第六代（6G）网络的融合正在成为一项革新的架构。本文综述了6G网络中AI与通信的基础原理、固有的挑战及未来的研究机会。我们从回顾AI及其大规模AI模型的发展入手，强调其在塑造现代通信技术中的关键作用。随后的讨论详细阐述了AI在6G网络中的预期融合，共分为三个渐进的发展阶段。第一阶段“网络中的AI”关注利用AI来增强网络性能、优化效率和提升用户体验。第二阶段“网络为AI”强调网络在支持和强化AI操作中的作用，并概述了关键的使能技术，包括AI数字孪生和语义通信。第三阶段“AI即服务”期待未来的6G网络将固有提供AI功能作为服务，并支持沉浸式通信和智能工业机器人等应用场景。具体而言，我们定义了AI服务的质量，这指的是网络中AI服务的衡量框架系统。除了这些发展阶段，我们还详细探讨了相关网络环境中AI的标准制定过程，强调了关键里程碑和正在进行的努力。最后，我们指出了能够推动AI和通信在6G中演进与精炼的有希望的研究机会，并将其定位为下一代通信基础设施的关键组成部分。', 'title_zh': '6G网络中人工智能与通信的综述：基础理论、挑战及未来研究机会'}
{'arxiv_id': 'arXiv:2412.14522', 'title': 'CAE-T: A Channelwise AutoEncoder with Transformer for EEG Abnormality Detection', 'authors': 'Youshen Zhao, Keiji Iramina', 'link': 'https://arxiv.org/abs/2412.14522', 'abstract': 'Electroencephalogram (EEG) signals are critical for detecting abnormal brain activity, but their high dimensionality and complexity pose significant challenges for effective analysis. In this paper, we propose CAE-T, a novel framework that combines a channelwise CNN-based autoencoder with a single-head transformer classifier for efficient EEG abnormality detection. The channelwise autoencoder compresses raw EEG signals while preserving channel independence, reducing computational costs and retaining biologically meaningful features. The compressed representations are then fed into the transformer-based classifier, which efficiently models long-term dependencies to distinguish between normal and abnormal signals. Evaluated on the TUH Abnormal EEG Corpus, the proposed model achieves 85.0% accuracy, 76.2% sensitivity, and 91.2% specificity at the per-case level, outperforming baseline models such as EEGNet, Deep4Conv, and FusionCNN. Furthermore, CAE-T requires only 202M FLOPs and 2.9M parameters, making it significantly more efficient than transformer-based alternatives. The framework retains interpretability through its channelwise design, demonstrating great potential for future applications in neuroscience research and clinical practice. The source code is available at this https URL.', 'abstract_zh': '脑电图（EEG）信号对于检测异常脑活动至关重要，但其高维度和复杂性对有效分析带来了重大挑战。本文提出了一种新型框架CAE-T，该框架结合了通道wise卷积神经网络（CNN）自编码器和单头变换器分类器，以实现高效的EEG异常检测。通道wise自编码器压缩原始EEG信号的同时保留了通道独立性，降低了计算成本并保留了生物意义显著的特征。压缩后的表示随后被输入基于变换器的分类器，该分类器能够有效地建模长期依赖关系，以区分正常和异常信号。该模型在TUH异常EEG数据集上的评估结果显示，其在每个病例级别的准确率为85.0%，敏感性为76.2%，特异性为91.2%，在基线模型（如EEGNet、Deep4Conv和FusionCNN）的基础上表现更优。此外，CAE-T仅需要202M FLOPs和2.9M参数，这使其在基于变换器的替代方案中具有显著的效率优势。通过其通道wise设计，该框架保持了可解释性，展示了其在神经理论研究和临床实践中的巨大应用潜力。源代码可在此处访问：https://this-url。', 'title_zh': 'CAE-T：一种基于变压器的通道wise自编码器用于EEG异常检测'}
{'arxiv_id': 'arXiv:2412.14510', 'title': 'PA-RAG: RAG Alignment via Multi-Perspective Preference Optimization', 'authors': 'Jiayi Wu, Hengyi Cai, Lingyong Yan, Hao Sun, Xiang Li, Shuaiqiang Wang, Dawei Yin, Ming Gao', 'link': 'https://arxiv.org/abs/2412.14510', 'abstract': 'The emergence of Retrieval-augmented generation (RAG) has alleviated the issues of outdated and hallucinatory content in the generation of large language models (LLMs), yet it still reveals numerous limitations. When a general-purpose LLM serves as the RAG generator, it often suffers from inadequate response informativeness, response robustness, and citation quality. Past approaches to tackle these limitations, either by incorporating additional steps beyond generating responses or optimizing the generator through supervised fine-tuning (SFT), still failed to align with the RAG requirement thoroughly. Consequently, optimizing the RAG generator from multiple preference perspectives while maintaining its end-to-end LLM form remains a challenge. To bridge this gap, we propose Multiple Perspective Preference Alignment for Retrieval-Augmented Generation (PA-RAG), a method for optimizing the generator of RAG systems to align with RAG requirements comprehensively. Specifically, we construct high-quality instruction fine-tuning data and multi-perspective preference data by sampling varied quality responses from the generator across different prompt documents quality scenarios. Subsequently, we optimize the generator using SFT and Direct Preference Optimization (DPO). Extensive experiments conducted on four question-answer datasets across three LLMs demonstrate that PA-RAG can significantly enhance the performance of RAG generators. Our code and datasets are available at this https URL.', 'abstract_zh': '检索增强生成（RAG）的出现缓解了大型语言模型（LLMs）生成内容中的过时和幻觉问题，但仍暴露出许多局限性。当通用型LLM作为RAG生成器使用时，它往往在响应信息量、响应稳健性和引文质量方面存在不足。过去解决这些局限性的方法，要么通过生成响应之外的额外步骤，要么通过监督微调（SFT）优化生成器，仍然未能充分满足RAG的要求。因此，在保持其端到端LLM形式的同时，从多方面调整RAG生成器仍是一个挑战。为了弥合这一差距，我们提出了面向检索增强生成的多元视角偏好对齐方法（PA-RAG），该方法用于全面优化RAG系统中的生成器以满足RAG要求。具体而言，我们通过从不同提示文档质量场景中采样多样化质量的响应构建高质量指令微调数据和多视角偏好数据。随后，我们使用SFT和直接偏好优化（DPO）来优化生成器。在三个大型语言模型上的四个问答数据集上进行的广泛实验表明，PA-RAG可以显著提升RAG生成器的性能。我们的代码和数据集可在此处获得：[此链接]。', 'title_zh': 'PA-RAG：多视角偏好优化驱动的RAG对齐'}
{'arxiv_id': 'arXiv:2412.14497', 'title': 'Treatment Effects Estimation on Networked Observational Data using Disentangled Variational Graph Autoencoder', 'authors': 'Di Fan, Renlei Jiang, Yunhao Wen, Chuanhou Gao', 'link': 'https://arxiv.org/abs/2412.14497', 'abstract': 'Estimating individual treatment effect (ITE) from observational data has gained increasing attention across various domains, with a key challenge being the identification of latent confounders affecting both treatment and outcome. Networked observational data offer new opportunities to address this issue by utilizing network information to infer latent confounders. However, most existing approaches assume observed variables and network information serve only as proxy variables for latent confounders, which often fails in practice, as some variables influence treatment but not outcomes, and vice versa. Recent advances in disentangled representation learning, which disentangle latent factors into instrumental, confounding, and adjustment factors, have shown promise for ITE estimation. Building on this, we propose a novel disentangled variational graph autoencoder that learns disentangled factors for treatment effect estimation on networked observational data. Our graph encoder further ensures factor independence using the Hilbert-Schmidt Independence Criterion. Extensive experiments on two semi-synthetic datasets derived from real-world social networks and one synthetic dataset demonstrate that our method achieves state-of-the-art performance.', 'abstract_zh': '从观察数据中估计个体治疗效果（ITE）在各个领域已经引起了越来越多的关注，关键挑战在于识别同时影响治疗和结果的潜变量。网络观察数据提供了一种新的机会，通过利用网络信息来推断潜变量。然而，现有大多数方法假设观察变量和网络信息仅作为潜变量的替代变量，实践中常常不成立，因为一些变量可能影响治疗而不影响结果，反之亦然。最近在分离表示学习方面的进展，通过将潜在因素分离为工具变量、混杂变量和调整变量，为ITE估计提供了新的可能性。在此基础上，我们提出了一种新的分离的变分图自编码器，该自编码器在网络观察数据中学习分离的治疗效果估计因子。我们的图编码器进一步通过希尔伯特-施密特独立性准则确保了因子的独立性。对两个源自现实社会网络的半合成数据集和一个合成数据集进行的广泛实验表明，我们的方法达到了最先进的性能。', 'title_zh': '使用解纠缠变分图形自编码器估计网络观测数据中的治疗效应'}
{'arxiv_id': 'arXiv:2412.14488', 'title': 'Stochastic first-order methods with multi-extrapolated momentum for highly smooth unconstrained optimization', 'authors': 'Chuan He', 'link': 'https://arxiv.org/abs/2412.14488', 'abstract': 'In this paper we consider an unconstrained stochastic optimization problem where the objective function exhibits a high order of smoothness. In particular, we propose a stochastic first-order method (SFOM) with multi-extrapolated momentum, in which multiple extrapolations are performed in each iteration, followed by a momentum step based on these extrapolations. We show that our proposed SFOM with multi-extrapolated momentum can accelerate optimization by exploiting the high-order smoothness of the objective function $f$. Specifically, assuming that the gradient and the $p$th-order derivative of $f$ are Lipschitz continuous for some $p\\ge2$, and under some additional mild assumptions, we establish that our method achieves a sample complexity of $\\widetilde{\\mathcal{O}}(\\epsilon^{-(3p+1)/p})$ for finding a point $x$ satisfying $\\mathbb{E}[\\|\\nabla f(x)\\|]\\le\\epsilon$. To the best of our knowledge, our method is the first SFOM to leverage arbitrary order smoothness of the objective function for acceleration, resulting in a sample complexity that strictly improves upon the best-known results without assuming the average smoothness condition. Finally, preliminary numerical experiments validate the practical performance of our method and corroborate our theoretical findings.', 'abstract_zh': '在本文中，我们考虑了一个无约束的随机优化问题，其中目标函数具有较高的光滑度。特别地，我们提出了一种具有多外推动量的随机一阶方法（SFOM），在每一步迭代中进行多次外推，随后基于这些外推进行一次动量步骤。我们证明了我们的SFOM方法能够通过利用目标函数 \\(f\\) 的高阶光滑性来加速优化过程。具体而言，假设 \\(f\\) 的梯度和 \\(p\\) 阶导数（\\(p \\geq 2\\)）在某些条件下是利普希茨连续的，并且在一些额外的轻度假设下，我们建立了该方法在找到满足 \\(\\mathbb{E}[\\|\\nabla f(x)\\|] \\leq \\epsilon\\) 的点 \\(x\\) 时所需的样本复杂度为 \\(\\widetilde{\\mathcal{O}}(\\epsilon^{-(3p+1)/p})\\)。据我们所知，我们的方法是第一个利用目标函数任意阶光滑性来加速优化的SFOM方法，从而在不假设平均光滑性条件的情况下，严格改善了已知的最佳结果。最后，初步的数值实验验证了我们方法的实际性能，并与我们的理论结果相一致。', 'title_zh': '具有多外推动量的随机一阶方法在高度光滑无约束优化中的应用'}
{'arxiv_id': 'arXiv:2412.14468', 'title': 'HashAttention: Semantic Sparsity for Faster Inference', 'authors': 'Aditya Desai, Shuo Yang, Alejandro Cuadron, Ana Klimovic, Matei Zaharia, Joseph E. Gonzalez, Ion Stoica', 'link': 'https://arxiv.org/abs/2412.14468', 'abstract': 'Utilizing longer contexts is increasingly essential to power better AI systems. However, the cost of attending to long contexts is high due to the involved softmax computation. While the scaled dot-product attention (SDPA) exhibits token sparsity, with only a few pivotal tokens significantly contributing to attention, leveraging this sparsity effectively remains an open challenge. Previous methods either suffer from model degradation or require considerable additional resources. We propose HashAttention --a principled approach casting pivotal token identification as a recommendation problem. Given a query, HashAttention encodes keys and queries in Hamming space capturing the required semantic similarity using learned mapping functions. HashAttention efficiently identifies pivotal tokens for a given query in this Hamming space using bitwise operations, and only these pivotal tokens are used for attention computation, significantly improving overall attention efficiency. HashAttention can reduce the number of tokens used by a factor of $1/32\\times$ for the Llama-3.1-8B model with LongBench, keeping average quality loss within 0.6 points, while using only 32 bits per token auxiliary memory. At $32\\times$ sparsity, HashAttention is $3{-}6\\times$ faster than LightLLM and $2.5{-}4.5\\times$ faster than gpt-fast on Nvidia-L4 GPU.', 'abstract_zh': '利用更长的上下文越来越成为构建更强大AI系统的必要条件。然而，关注长上下文的成本因涉及的softmax计算而高昂。虽然标度点积注意力（Scaled Dot-Product Attention，SDPA）表现出标记稀疏性，仅有少数关键标记对注意力有显著贡献，但有效地利用这种稀疏性仍是一个开放的挑战。先前的方法要么导致模型退化，要么需要大量的额外资源。我们提出了一种名为HashAttention的方法——一种基于推荐问题来识别关键标记的合理方法。给定一个查询，HashAttention将键和查询编码到哈明空间中，通过学习的映射函数捕获所需的语义相似性。HashAttention使用位操作高效地在哈明空间中识别给定查询的关键标记，并仅使用这些关键标记进行注意力计算，从而显著提高整体注意力效率。HashAttention可以在不影响平均质量损失（0.6分以内）的情况下，将Llama-3.1-8B模型使用LongBench的标记数量减少32倍，同时每标记使用仅32位的辅助内存。在32倍稀疏性下，HashAttention在Nvidia L4 GPU上的速度比LightLLM快3-6倍，比gpt-fast快2.5-4.5倍。', 'title_zh': 'HashAttention：语义稀疏性以实现更快的推理'}
{'arxiv_id': 'arXiv:2412.14451', 'title': 'CLDG: Contrastive Learning on Dynamic Graphs', 'authors': 'Yiming Xu, Bin Shi, Teng Ma, Bo Dong, Haoyi Zhou, Qinghua Zheng', 'link': 'https://arxiv.org/abs/2412.14451', 'abstract': "The graph with complex annotations is the most potent data type, whose constantly evolving motivates further exploration of the unsupervised dynamic graph representation. One of the representative paradigms is graph contrastive learning. It constructs self-supervised signals by maximizing the mutual information between the statistic graph's augmentation views. However, the semantics and labels may change within the augmentation process, causing a significant performance drop in downstream tasks. This drawback becomes greatly magnified on dynamic graphs. To address this problem, we designed a simple yet effective framework named CLDG. Firstly, we elaborate that dynamic graphs have temporal translation invariance at different levels. Then, we proposed a sampling layer to extract the temporally-persistent signals. It will encourage the node to maintain consistent local and global representations, i.e., temporal translation invariance under the timespan views. The extensive experiments demonstrate the effectiveness and efficiency of the method on seven datasets by outperforming eight unsupervised state-of-the-art baselines and showing competitiveness against four semi-supervised methods. Compared with the existing dynamic graph method, the number of model parameters and training time is reduced by an average of 2,001.86 times and 130.31 times on seven datasets, respectively.", 'abstract_zh': '包含复杂注释的图是最具潜力的数据类型，其不断演化为无监督动态图表示的进一步探索提供了动力。代表性范例之一是图对比学习。该方法通过最大化静态图增强视图之间的互信息来构建自监督信号。然而，在增强过程中，语义和标签可能会发生变化，导致下游任务的性能显著下降。这一问题在动态图中尤为突出。为解决这一问题，我们设计了一个简单而有效的框架，称为CLDG。首先，我们强调动态图在不同层次上具有时间平移不变性。然后，我们提出了一种采样层来提取时间持久的信号。这将鼓励节点在时间跨度视图下保持一致的局部和全局表示，即时间平移不变性。广泛实验表明，该方法在七个数据集上优于八个无监督的最新基线，并且与四个半监督方法具有竞争力。与现有的动态图方法相比，该方法在七个数据集上的模型参数数量和训练时间分别减少了平均2001.86倍和130.31倍。', 'title_zh': 'CLDG：动态图上的对比学习'}
{'arxiv_id': 'arXiv:2412.14444', 'title': 'GenHMR: Generative Human Mesh Recovery', 'authors': 'Muhammad Usama Saleem, Ekkasit Pinyoanuntapong, Pu Wang, Hongfei Xue, Srijan Das, Chen Chen', 'link': 'https://arxiv.org/abs/2412.14444', 'abstract': 'Human mesh recovery (HMR) is crucial in many computer vision applications; from health to arts and entertainment. HMR from monocular images has predominantly been addressed by deterministic methods that output a single prediction for a given 2D image. However, HMR from a single image is an ill-posed problem due to depth ambiguity and occlusions. Probabilistic methods have attempted to address this by generating and fusing multiple plausible 3D reconstructions, but their performance has often lagged behind deterministic approaches. In this paper, we introduce GenHMR, a novel generative framework that reformulates monocular HMR as an image-conditioned generative task, explicitly modeling and mitigating uncertainties in the 2D-to-3D mapping process. GenHMR comprises two key components: (1) a pose tokenizer to convert 3D human poses into a sequence of discrete tokens in a latent space, and (2) an image-conditional masked transformer to learn the probabilistic distributions of the pose tokens, conditioned on the input image prompt along with randomly masked token sequence. During inference, the model samples from the learned conditional distribution to iteratively decode high-confidence pose tokens, thereby reducing 3D reconstruction uncertainties. To further refine the reconstruction, a 2D pose-guided refinement technique is proposed to directly fine-tune the decoded pose tokens in the latent space, which forces the projected 3D body mesh to align with the 2D pose clues. Experiments on benchmark datasets demonstrate that GenHMR significantly outperforms state-of-the-art methods. Project website can be found at this https URL', 'abstract_zh': '以下是经过学术规范翻译的内容：\n\n人体网格恢复（HMR）在许多计算机视觉应用中至关重要，从医疗健康到艺术娱乐领域。单目图像的HMR问题主要由确定性方法处理，这些方法对给定的2D图像输出一个单一的预测。然而，从单目图像中恢复人体网格是一个病态问题，因为存在深度模糊和遮挡现象。概率方法试图通过生成并融合多个可能的3D重建来解决该问题，但其性能往往落后于确定性方法。在本文中，我们提出了一种名为GenHMR的生成框架，将单目HMR重新定义为基于图像的生成任务，明确建模并缓解了从2D到3D映射过程中的不确定性。GenHMR包含两个关键组件：(1) 一个姿态分词器，用于将3D人体姿态转换为潜在空间中的离散令牌序列；(2) 一个基于图像的掩码变换器，用于学习在输入图像提示和随机遮掩令牌序列条件下姿态令牌的概率分布。在推理过程中，模型从学习到的条件分布中抽样，逐步解码高置信度的姿态令牌，从而降低3D重建的不确定性。为了进一步细化重建结果，我们提出了一种基于2D姿态的细化技术，该技术直接微调潜在空间中的解码姿态令牌，促使投影的3D人体网格与2D姿态线索对齐。基准数据集上的实验表明，GenHMR显著优于现有的先进方法。项目网站可访问此处 [点击访问项目网站]。', 'title_zh': 'GenHMR：生成式人体网格恢复'}
{'arxiv_id': 'arXiv:2412.14436', 'title': 'ORBIT: Cost-Effective Dataset Curation for Large Language Model Domain Adaptation with an Astronomy Case Study', 'authors': 'Eric Modesitt, Ke Yang, Spencer Hulsey, Chengxiang Zhai, Volodymyr Kindratenko', 'link': 'https://arxiv.org/abs/2412.14436', 'abstract': "Recent advances in language modeling demonstrate the need for high-quality domain-specific training data, especially for tasks that require specialized knowledge. General-purpose models, while versatile, often lack the depth needed for expert-level tasks because of limited domain-specific information. Domain adaptation training can enhance these models, but it demands substantial, high-quality data. To address this, we propose ORBIT, a cost-efficient methodology for curating massive, high-quality domain-specific datasets from noisy web sources, tailored for training specialist large language models. Using astronomy as a primary case study, we refined the 1.3T-token FineWeb-Edu dataset into a high-quality, 10B-token subset focused on astronomy. Fine-tuning \\textsc{LLaMA-3-8B} on a 1B-token astronomy subset improved performance on the MMLU astronomy benchmark from 69\\% to 76\\% and achieved top results on AstroBench, an astronomy-specific benchmark. Moreover, our model (Orbit-LLaMA) outperformed \\textsc{LLaMA-3-8B-base}, with GPT-4o evaluations preferring it in 73\\% of cases across 1000 astronomy-specific questions. Additionally, we validated ORBIT's generalizability by applying it to law and medicine, achieving a significant improvement of data quality compared to an unfiltered baseline. We open-source the ORBIT methodology, including the curated datasets, the codebase, and the resulting model at \\href{this https URL}{this https URL}.", 'abstract_zh': '近年来，语言模型的研究进展表明，需要高质量的专业领域训练数据，尤其是对于需要专业领域知识的任务。通用模型虽然功能多样，但往往缺乏在专家级别任务中所需的深度，因为它们对专业知识领域的信息有限。领域适应训练可以增强这些模型，但需要大量的高质量数据。为了解决这一问题，我们提出了一种名为ORBITE的方法论，旨在从噪声较大的网络来源中高效地收集大量高质量的专业领域数据，以训练专门的语言模型。通过将FineWeb-Edu（1.3T词元）数据集精炼成专注于天文学领域的100亿词元高质量子集作为主要案例研究，我们使用天文学特定领域的数据集对\\textsc{LLaMA-3-8B}进行了微调，结果在MMLU天文学基准测试中的性能从69%提高到了76%，并在专门的天文学基准测试AstroBench上取得了最佳成绩。此外，我们的模型（Orbit-LLaMA）的表现超过了未优化的\\textsc{LLaMA-3-8B-base}模型，在1000个天文学特定问题中，GPT-4o评估有73%的情况更偏好于它。此外，我们验证了ORBITE的一般适应性，将其应用于法律和医学领域，相比未经筛选的基础数据集，实现了显著的数据质量提升。我们开源了ORBITE方法论，包括精心整理的数据集、代码库以及生成的模型，访问链接为：\\href{this https URL}{这个链接}。', 'title_zh': 'ORBIT：用于大型语言模型领域自适应的数据集编目成本效益方法——以天文学案例研究为例'}
{'arxiv_id': 'arXiv:2412.14435', 'title': 'Cherry-Picking in Time Series Forecasting: How to Select Datasets to Make Your Model Shine', 'authors': 'Luis Roque, Carlos Soares, Vitor Cerqueira, Luis Torgo', 'link': 'https://arxiv.org/abs/2412.14435', 'abstract': 'The importance of time series forecasting drives continuous research and the development of new approaches to tackle this problem. Typically, these methods are introduced through empirical studies that frequently claim superior accuracy for the proposed approaches. Nevertheless, concerns are rising about the reliability and generalizability of these results due to limitations in experimental setups. This paper addresses a critical limitation: the number and representativeness of the datasets used. We investigate the impact of dataset selection bias, particularly the practice of cherry-picking datasets, on the performance evaluation of forecasting methods. Through empirical analysis with a diverse set of benchmark datasets, our findings reveal that cherry-picking datasets can significantly distort the perceived performance of methods, often exaggerating their effectiveness. Furthermore, our results demonstrate that by selectively choosing just four datasets - what most studies report - 46% of methods could be deemed best in class, and 77% could rank within the top three. Additionally, recent deep learning-based approaches show high sensitivity to dataset selection, whereas classical methods exhibit greater robustness. Finally, our results indicate that, when empirically validating forecasting algorithms on a subset of the benchmarks, increasing the number of datasets tested from 3 to 6 reduces the risk of incorrectly identifying an algorithm as the best one by approximately 40%. Our study highlights the critical need for comprehensive evaluation frameworks that more accurately reflect real-world scenarios. Adopting such frameworks will ensure the development of robust and reliable forecasting methods.', 'abstract_zh': '时间序列预测的重要性驱使人们不断进行研究并开发新的方法来解决这一问题。通常，这些方法通过实证研究引入，这些研究常常声称所提出的方法具有更高的精度。然而，由于实验设置中的局限性，人们对这些结果的可靠性和普适性提出了担忧。本文重点关注一个关键的限制：所使用的数据集的数量和代表性。我们探讨了数据集选择偏差，特别是“挑豆”数据集做法对预测方法性能评估的影响。通过使用多样化的基准数据集进行实证分析，我们的研究结果表明，“挑豆”数据集会显著歪曲方法的感知性能，常常夸大其效果。此外，我们的结果还显示，通过对仅四个数据集进行选择性地挑选，这在大多数研究中被报告，46%的方法可以被认为是最佳方法，而77%的方法可以排名在前三名。同时，最近基于深度学习的方法对数据集选择高度敏感，而经典方法则表现出更强的鲁棒性。最后，我们的结果还表明，在对基准数据集的一部分进行实证验证时，将测试数据集的数量从3个增加到6个，可以将错误地将算法识别为最佳算法的风险降低约40%。我们的研究强调了采用全面评估框架的必要性，这些框架更能反映现实世界的场景。采用这样的框架将确保开发出更具鲁棒性和可靠性的预测方法。', 'title_zh': '时间序列预测中的数据甜蜜点选择：如何挑选数据集以使模型脱颖而出'}
{'arxiv_id': 'arXiv:2412.14426', 'title': 'All-in-One Tuning and Structural Pruning for Domain-Specific LLMs', 'authors': 'Lei Lu, Zhepeng Wang, Ruexue Bao, Mengbing Wang, Fangyi Li, Yawen Wu, Weiwen Jiang, Jie Xu, Yanzhi Wang, Shangqian Gao', 'link': 'https://arxiv.org/abs/2412.14426', 'abstract': 'Existing pruning techniques for large language models (LLMs) targeting domain-specific applications typically follow a two-stage process: pruning the pretrained general-purpose LLMs and then fine-tuning the pruned LLMs on specific domains. However, the pruning decisions, derived from the pretrained weights, remain unchanged during fine-tuning, even if the weights have been updated. Therefore, such a combination of the pruning decisions and the finetuned weights may be suboptimal, leading to non-negligible performance degradation. To address these limitations, we propose ATP: All-in-One Tuning and Structural Pruning, a unified one-stage structural pruning and fine-tuning approach that dynamically identifies the current optimal substructure throughout the fine-tuning phase via a trainable pruning decision generator. Moreover, given the limited available data for domain-specific applications, Low-Rank Adaptation (LoRA) becomes a common technique to fine-tune the LLMs. In ATP, we introduce LoRA-aware forward and sparsity regularization to ensure that the substructures corresponding to the learned pruning decisions can be directly removed after the ATP process. ATP outperforms the state-of-the-art two-stage pruning methods on tasks in the legal and healthcare domains. More specifically, ATP recovers up to 88% and 91% performance of the dense model when pruning 40% parameters of LLaMA2-7B and LLaMA3-8B models, respectively.', 'abstract_zh': '现有的针对特定领域应用的大语言模型（LLMs）的剪枝技术通常遵循一个两阶段过程：首先对预训练的一般目的LLM进行剪枝，然后在其特定领域上进行微调。然而，剪枝决策是基于预训练权重的，即使权重在微调过程中有所更新，这些剪枝决策依然保持不变。因此，这种剪枝决策与微调权重的结合可能是次优的，可能导致明显的性能下降。为了解决这些问题，我们提出了ATP：一键式微调与结构剪枝，这是一种统一的一站式结构剪枝和微调方法，通过可训练的剪枝决策生成器在微调过程中动态确定当前的最优子结构。此外，由于特定领域的可用数据有限，低秩适应（LoRA）成为一种常见的微调LLM的技术。在ATP中，我们引入了LoRA意识前向传播和稀疏正则化，以确保在ATP处理后，与学习到的剪枝决策对应的子结构可以被直接移除。实验证明，ATP在法律和医疗领域的任务上优于最先进的两阶段剪枝方法。具体而言，当对LLaMA2-7B和LLaMA3-8B模型进行40%参数剪枝时，ATP分别恢复了原始模型性能的88%和91%。', 'title_zh': '适用于特定领域的大型语言模型的全方位调优与结构剪裁'}
{'arxiv_id': 'arXiv:2412.14424', 'title': 'FedPIA -- Permuting and Integrating Adapters leveraging Wasserstein Barycenters for Finetuning Foundation Models in Multi-Modal Federated Learning', 'authors': 'Pramit Saha, Divyanshu Mishra, Felix Wagner, Konstantinos Kamnitsas, J. Alison Noble', 'link': 'https://arxiv.org/abs/2412.14424', 'abstract': 'Large Vision-Language Models typically require large text and image datasets for effective fine-tuning. However, collecting data from various sites, especially in healthcare, is challenging due to strict privacy regulations. An alternative is to fine-tune these models on end-user devices, such as in medical clinics, without sending data to a server. These local clients typically have limited computing power and small datasets, which are not enough for fully fine-tuning large VLMs on their own. A naive solution to these scenarios is to leverage parameter-efficient fine-tuning (PEFT) strategies and apply federated learning (FL) algorithms to combine the learned adapter weights, thereby respecting the resource limitations and data privacy. However, this approach does not fully leverage the knowledge from multiple adapters trained on diverse data distributions and for diverse tasks. The adapters are adversely impacted by data heterogeneity and task heterogeneity across clients resulting in suboptimal convergence. To this end, we propose a novel framework called FedPIA that improves upon the naive combinations of FL and PEFT by introducing Permutation and Integration of the local Adapters in the server and global Adapters in the clients exploiting Wasserstein barycenters for improved blending of client-specific and client-agnostic knowledge. This layerwise permutation helps to bridge the gap in the parameter space of local and global adapters before integration. We conduct over 2000 client-level experiments utilizing 48 medical image datasets across five different medical vision-language FL task settings encompassing visual question answering as well as image and report-based multi-label disease detection. Our experiments involving diverse client settings, ten different modalities, and two VLM backbones demonstrate that FedPIA consistently outperforms the state-of-the-art PEFT-FL baselines.', 'abstract_zh': '大型视觉-语言模型通常需要大规模的文本和图像数据集才能有效微调。然而，由于严格的隐私保护法规，在收集来自不同站点的数据，尤其是在医疗保健领域，存在挑战。一种替代方案是在终端用户设备上，如在医疗诊所中对这些模型进行微调，而不将数据发送到服务器。这些本地客户端通常拥有有限的计算能力和较小的数据集，不足以独自完成大规模视觉-语言模型的完全微调。简单的解决方案是利用参数高效微调(PEFT)策略，并应用联邦学习(FL)算法结合本地适配器的权重，从而尊重资源限制和数据隐私。然而，这种方式未能充分利用在不同数据分布和不同任务上训练的各种适配器所获得的知识。适配器受到跨客户端数据异质性和任务异质性的负面影响，导致收敛效果不佳。为此，我们提出了一种名为FedPIA的新框架，改进了FL和PEFT的简单结合，通过在服务器端引入局部适配器的排列和集成以及在客户端引入全局适配器，结合使用Wasserstein巴莱中心来改进客户特定知识和客户无关知识的融合。逐层排列有助于在集成前填补本地和全局适配器在参数空间上的差距。我们在五个不同的医疗视觉-语言联邦学习任务设置中（包括视觉问答以及基于图像和报告的多标签疾病检测）使用了48个医疗图像数据集，进行了超过2000次客户级别实验。我们的实验涉及多样化的客户设置、十个不同的模态和两个视觉-语言模型的两个骨干网络，表明FedPIA始终优于最先进的参数高效微调-联邦学习基线。', 'title_zh': 'FedPIA —— 利用 Wasserstein 拟中心ILTER 适配器进行多模态联邦学习微调\n\n注释：这个翻译尽可能地保持了原文的学术风格和术语的专业性。其中，“Permuting and Integrating Adapters leveraging Wasserstein Barycenters”被合并为了“利用 Wasserstein 拟中心ILTER 适配器”，以更符合中文的表达习惯和学术规范。“Fed”是“Federated”的缩写，“Federated Learning”在中文中通常翻译为“联邦学习”。这里“拟中心FILTER”是对“Wasserstein Barycenters”的一种较为通顺的意译，尽可能保留了原文的核心思想。'}
{'arxiv_id': 'arXiv:2412.14422', 'title': 'Enhancing Diffusion Models for High-Quality Image Generation', 'authors': 'Jaineet Shah, Michael Gromis, Rickston Pinto', 'link': 'https://arxiv.org/abs/2412.14422', 'abstract': 'This report presents the comprehensive implementation, evaluation, and optimization of Denoising Diffusion Probabilistic Models (DDPMs) and Denoising Diffusion Implicit Models (DDIMs), which are state-of-the-art generative models. During inference, these models take random noise as input and iteratively generate high-quality images as output. The study focuses on enhancing their generative capabilities by incorporating advanced techniques such as Classifier-Free Guidance (CFG), Latent Diffusion Models with Variational Autoencoders (VAE), and alternative noise scheduling strategies. The motivation behind this work is the growing demand for efficient and scalable generative AI models that can produce realistic images across diverse datasets, addressing challenges in applications such as art creation, image synthesis, and data augmentation. Evaluations were conducted on datasets including CIFAR-10 and ImageNet-100, with a focus on improving inference speed, computational efficiency, and image quality metrics like Frechet Inception Distance (FID). Results demonstrate that DDIM + CFG achieves faster inference and superior image quality. Challenges with VAE and noise scheduling are also highlighted, suggesting opportunities for future optimization. This work lays the groundwork for developing scalable, efficient, and high-quality generative AI systems to benefit industries ranging from entertainment to robotics.', 'abstract_zh': '本报告详细介绍了去噪扩散概率模型（DDPMs）和去噪扩散隐模型（DDIMs）的全面实施、评估及优化。这些模型是目前最先进的生成模型。在推理过程中，这些模型将随机噪声作为输入，逐步生成高质量的图像作为输出。该研究重点在于通过引入先进技术如分类器无关引导（CFG）、潜变量扩散模型与变分自编码器（VAE）以及替代噪声调度策略来增强其生成能力。这项工作的动机源于对高效且可扩展的生成人工智能模型日益增长的需求，这些模型能够在多样化的数据集中生成逼真的图像，从而解决艺术创作、图像合成和数据增强等应用中的挑战。评价在CIFAR-10和ImageNet-100等数据集上进行，重点提高推理速度、计算效率以及象Frechetception距离（FID）等图像质量指标。研究结果表明，DDIM + CFG实现了更快的推理和更优质的图像质量。同时，也指出了VAE和噪声调度中存在的挑战，为进一步优化提供了机会。这项工作为开发可扩展、高效且高质量的生成人工智能系统奠定了基础，这些系统将惠及娱乐、机器人等各个行业。', 'title_zh': '提升扩散模型以生成高质图像'}
{'arxiv_id': 'arXiv:2412.14415', 'title': 'DriveGPT: Scaling Autoregressive Behavior Models for Driving', 'authors': 'Xin Huang, Eric M. Wolff, Paul Vernaza, Tung Phan-Minh, Hongge Chen, David S. Hayden, Mark Edmonds, Brian Pierce, Xinxin Chen, Pratik Elias Jacob, Xiaobai Chen, Chingiz Tairbekov, Pratik Agarwal, Tianshi Gao, Yuning Chai, Siddhartha Srinivasa', 'link': 'https://arxiv.org/abs/2412.14415', 'abstract': 'We present DriveGPT, a scalable behavior model for autonomous driving. We model driving as a sequential decision making task, and learn a transformer model to predict future agent states as tokens in an autoregressive fashion. We scale up our model parameters and training data by multiple orders of magnitude, enabling us to explore the scaling properties in terms of dataset size, model parameters, and compute. We evaluate DriveGPT across different scales in a planning task, through both quantitative metrics and qualitative examples including closed-loop driving in complex real-world scenarios. In a separate prediction task, DriveGPT outperforms a state-of-the-art baseline and exhibits improved performance by pretraining on a large-scale dataset, further validating the benefits of data scaling.', 'abstract_zh': '我们提出了DriveGPT，一种可扩展的自主驾驶行为模型。我们将驾驶任务建模为一个序列决策任务，并通过自回归的方式训练一个变压器模型来预测未来代理状态。我们通过多个数量级扩展模型参数和训练数据，从而探索数据集规模、模型参数和计算量之间的扩展性。我们在规划任务中不同规模上评估了DriveGPT，通过定量指标和定性示例（包括复杂现实场景中的闭环驾驶）进行了评估。在单独的预测任务中，DriveGPT超过了最先进的基线模型，并通过在大规模数据集上进行预训练表现出更好的性能，进一步验证了数据扩展的好处。', 'title_zh': 'DriveGPT：扩展自回归行为模型在驾驶领域的应用'}
{'arxiv_id': 'arXiv:2412.14384', 'title': 'I0T: Embedding Standardization Method Towards Zero Modality Gap', 'authors': 'Na Min An, Eunki Kim, James Thorne, Hyunjung Shim', 'link': 'https://arxiv.org/abs/2412.14384', 'abstract': 'Contrastive Language-Image Pretraining (CLIP) enables zero-shot inference in downstream tasks such as image-text retrieval and classification. However, recent works extending CLIP suffer from the issue of modality gap, which arises when the image and text embeddings are projected to disparate manifolds, deviating from the intended objective of image-text contrastive learning. We discover that this phenomenon is linked to the modality-specific characteristic that each image/text encoder independently possesses and propose two methods to address the modality gap: (1) a post-hoc embedding standardization method, $\\text{I0T}_{\\text{post}}$ that reduces the modality gap approximately to zero and (2) a trainable method, $\\text{I0T}_{\\text{async}}$, to alleviate the modality gap problem by adding two normalization layers for each encoder. Our I0T framework can significantly reduce the modality gap while preserving the original embedding representations of trained models with their locked parameters. In practice, $\\text{I0T}_{\\text{post}}$ can serve as an alternative explainable automatic evaluation metric of widely used CLIPScore (CLIP-S).', 'abstract_zh': '对比语言-图像预训练(CLIP)使零样本推理在图像-文本检索和分类等下游任务中成为可能。然而，最近扩展CLIP的工作面临模态差距的问题，当图像和文本嵌入被投影到不同的流形上时，这种差距偏离了图像-文本对比学习的预期目标。我们发现这种现象与每个图像/文本编码器独立拥有的模态特定特征有关，并提出了两种方法来解决模态差距问题：(1) 一种后处理嵌入标准化方法，$\\text{I0T}_{\\text{post}}$，该方法可将模态差距大约减少至零；(2) 一种可训练方法，$\\text{I0T}_{\\text{async}}$，通过为每个编码器添加两个规范化层来缓解模态差距问题。我们的I0T框架可以显著减小模态差距，同时保留训练模型的原始嵌入表示及其锁定的参数。在实践中，$\\text{I0T}_{\\text{post}}$可以作为广泛使用的CLIPScore（CLIP-S）的一个替代的可解释自动评估指标。', 'title_zh': 'I0T: 零模态差距嵌入标准方法'}
{'arxiv_id': 'arXiv:2412.14366', 'title': 'Surrealistic-like Image Generation with Vision-Language Models', 'authors': 'Elif Ayten, Shuai Wang, Hjalmar Snoep', 'link': 'https://arxiv.org/abs/2412.14366', 'abstract': 'Recent advances in generative AI make it convenient to create different types of content, including text, images, and code. In this paper, we explore the generation of images in the style of paintings in the surrealism movement using vision-language generative models, including DALL-E, Deep Dream Generator, and DreamStudio. Our investigation starts with the generation of images under various image generation settings and different models. The primary objective is to identify the most suitable model and settings for producing such images. Additionally, we aim to understand the impact of using edited base images on the generated resulting images. Through these experiments, we evaluate the performance of selected models and gain valuable insights into their capabilities in generating such images. Our analysis shows that Dall-E 2 performs the best when using the generated prompt by ChatGPT.', 'abstract_zh': '近年来，生成AI的发展使得创建不同类型的内容，包括文本、图像和代码，变得非常便利。在本文中，我们探讨了使用视觉语言生成模型（如DALL-E、Deep Dream Generator和DreamStudio）生成超现实主义绘画风格图像的研究。我们的研究始于在不同图像生成设置和不同模型下的图像生成。主要目标是识别最适合生成此类图像的模型和设置。此外，我们还旨在了解使用编辑过的基础图像对生成结果图像的影响。通过这些实验，我们评估了选定模型的性能，并获得了关于其生成此类图像能力的宝贵见解。我们的分析表明，当使用由ChatGPT生成的提示词时，DALL-E 2表现最佳。', 'title_zh': '使用视觉语言模型生成类似超现实主义的图像'}
{'arxiv_id': 'arXiv:2412.14355', 'title': 'Enabling Realtime Reinforcement Learning at Scale with Staggered Asynchronous Inference', 'authors': 'Matthew Riemer, Gopeshh Subbaraj, Glen Berseth, Irina Rish', 'link': 'https://arxiv.org/abs/2412.14355', 'abstract': "Realtime environments change even as agents perform action inference and learning, thus requiring high interaction frequencies to effectively minimize regret. However, recent advances in machine learning involve larger neural networks with longer inference times, raising questions about their applicability in realtime systems where reaction time is crucial. We present an analysis of lower bounds on regret in realtime reinforcement learning (RL) environments to show that minimizing long-term regret is generally impossible within the typical sequential interaction and learning paradigm, but often becomes possible when sufficient asynchronous compute is available. We propose novel algorithms for staggering asynchronous inference processes to ensure that actions are taken at consistent time intervals, and demonstrate that use of models with high action inference times is only constrained by the environment's effective stochasticity over the inference horizon, and not by action frequency. Our analysis shows that the number of inference processes needed scales linearly with increasing inference times while enabling use of models that are multiple orders of magnitude larger than existing approaches when learning from a realtime simulation of Game Boy games such as Pokémon and Tetris.", 'abstract_zh': '实时环境在代理执行动作推理和学习的过程中不断变化，因此需要高频率的交互来有效地最小化遗憾。然而，最近的机器学习进展涉及更大型的神经网络以及更长的推理时间，这在反应时间至关重要的实时系统中引发了对其适用性的疑问。我们对实时强化学习（RL）环境中最小化长期遗憾的下界进行了分析，表明在典型的序列交互和学习范式中，通常不可能最小化长期遗憾，但在有足够的异步计算资源时，这种情况变得可能。我们提出了新的算法来交错执行异步推理过程，确保动作在一致的时间间隔内被采取，并证明在实时模拟Game Boy游戏（如宝可梦和俄罗斯方块）的过程中使用具有长时间动作推理的模型仅受到推理窗口内环境有效随机性的限制，而不是动作频率的限制。我们的分析表明，所需的推理过程数量随着推理时间的增加而线性增长，从而可以在学习过程中使用比现有方法大多个数量级的模型。', 'title_zh': '大规模实时强化学习的分时异步推理实现'}
{'arxiv_id': 'arXiv:2412.14351', 'title': 'Is Peer-Reviewing Worth the Effort?', 'authors': 'Kenneth Church, Raman Chandrasekar, John E. Ortega, Ibrahim Said Ahmad', 'link': 'https://arxiv.org/abs/2412.14351', 'abstract': 'How effective is peer-reviewing in identifying important papers? We treat this question as a forecasting task. Can we predict which papers will be highly cited in the future based on venue and "early returns" (citations soon after publication)? We show early returns are more predictive than venue. Finally, we end with constructive suggestions to address scaling challenges: (a) too many submissions and (b) too few qualified reviewers.', 'abstract_zh': '同行评议在识别重要论文方面有多有效？我们将这个问题视为一个预测任务：我们能否基于会议/期刊和“早期反馈”（即发表后不久的引用情况）来预测哪些论文在未来会被高度引用？我们证明了早期反馈比会议更具预测性。最后，我们提出了应对规模挑战的建设性建议：(a) 处理过多的投稿，(b) 提高合格审稿人的数量。', 'title_zh': '值得付出努力进行同行评审吗？'}
{'arxiv_id': 'arXiv:2412.14340', 'title': 'A Unifying Information-theoretic Perspective on Evaluating Generative Models', 'authors': 'Alexis Fox, Samarth Swarup, Abhijin Adiga', 'link': 'https://arxiv.org/abs/2412.14340', 'abstract': 'Considering the difficulty of interpreting generative model output, there is significant current research focused on determining meaningful evaluation metrics. Several recent approaches utilize "precision" and "recall," borrowed from the classification domain, to individually quantify the output fidelity (realism) and output diversity (representation of the real data variation), respectively. With the increase in metric proposals, there is a need for a unifying perspective, allowing for easier comparison and clearer explanation of their benefits and drawbacks. To this end, we unify a class of kth-nearest-neighbors (kNN)-based metrics under an information-theoretic lens using approaches from kNN density estimation. Additionally, we propose a tri-dimensional metric composed of Precision Cross-Entropy (PCE), Recall Cross-Entropy (RCE), and Recall Entropy (RE), which separately measure fidelity and two distinct aspects of diversity, inter- and intra-class. Our domain-agnostic metric, derived from the information-theoretic concepts of entropy and cross-entropy, can be dissected for both sample- and mode-level analysis. Our detailed experimental results demonstrate the sensitivity of our metric components to their respective qualities and reveal undesirable behaviors of other metrics.', 'abstract_zh': '考虑到生成模型输出的解释性难度，目前的研究主要集中于确定有意义的评估指标。近年来，一些方法利用“精确率”（precision）和“召回率”（recall），这些概念源自分类领域，分别独立地量化输出保真度（现实感）和输出多样性（真实数据变异的表示）。随着评估指标的不断涌现，需要一个统一看法，以便于更容易地进行比较，并清楚地解释其各自的优势和劣势。为此，我们从 k 最近邻（kNN）密度估计方法出发，将一类 kNN 基本的评估指标统一在信息理论的视角下。此外，我们还提出一个三维评估指标，由精确率交叉熵（PCE）、召回率交叉熵（RCE）和召回率熵（RE）组成，分别度量保真度和两类不同的多样性方面：类间和类内。我们的领域无关评估指标，基于熵和交叉熵的信息理论概念，可以用于样本级和模式级的分析。我们的详细实验结果证明了评估指标各组成部分对其相应质量的敏感性，并揭示了其他评估指标的不良行为。', 'title_zh': '一种统一的信息论视角下生成模型评估方法'}
{'arxiv_id': 'arXiv:2412.14329', 'title': 'Embedding Cultural Diversity in Prototype-based Recommender Systems', 'authors': 'Armin Moradi, Nicola Neophytou, Florian Carichon, Golnoosh Farnadi', 'link': 'https://arxiv.org/abs/2412.14329', 'abstract': 'Popularity bias in recommender systems can increase cultural overrepresentation by favoring norms from dominant cultures and marginalizing underrepresented groups. This issue is critical for platforms offering cultural products, as they influence consumption patterns and human perceptions. In this work, we address popularity bias by identifying demographic biases within prototype-based matrix factorization methods. Using the country of origin as a proxy for cultural identity, we link this demographic attribute to popularity bias by refining the embedding space learning process. First, we propose filtering out irrelevant prototypes to improve representativity. Second, we introduce a regularization technique to enforce a uniform distribution of prototypes within the embedding space. Across four datasets, our results demonstrate a 27\\% reduction in the average rank of long-tail items and a 2\\% reduction in the average rank of items from underrepresented countries. Additionally, our model achieves a 2\\% improvement in HitRatio@10 compared to the state-of-the-art, highlighting that fairness is enhanced without compromising recommendation quality. Moreover, the distribution of prototypes leads to more inclusive explanations by better aligning items with diverse prototypes.', 'abstract_zh': '推荐系统中的流行度偏差可能会通过推崇主导文化规范并边缘化未代表群体的文化产品，增加文化过度代表现象。这对于提供文化产品的平台尤其关键，因为这将影响消费模式和人类认知。本研究通过识别原型基于矩阵分解方法中的人口统计学偏差来应对流行度偏差。以文化身份的代理变量——国家为起点，我们通过细化嵌入空间的学习过程将人口统计学属性与流行度偏差联系起来。首先，我们提出过滤掉无关的原型以提高代表性；其次，我们引入一种正则化技术来强制原型在嵌入空间内的均匀分布。在四个数据集上的实验结果表明，与长尾项目的平均排名下降了27%，来自未代表国家的项目的平均排名下降了2%。此外，我们的模型在HitRatio@10上的表现比当前最好的方法提高了2%，这表明在未牺牲推荐质量的前提下，公平性得到了提升。而且，原型的分布导致了更具包容性的解释，因为这有助于更好地将项目与多样化的原型对齐。', 'title_zh': '将文化多样性嵌入原型推荐系统中'}
{'arxiv_id': 'arXiv:2412.14328', 'title': 'Semantic Role Labeling of NomBank Partitives', 'authors': 'Adam Meyers, Advait Pravin Savant, John E. Ortega', 'link': 'https://arxiv.org/abs/2412.14328', 'abstract': 'This article is about Semantic Role Labeling for English partitive nouns (5%/REL of the price/ARG1; The price/ARG1 rose 5 percent/REL) in the NomBank annotated corpus. Several systems are described using traditional and transformer-based machine learning, as well as ensembling. Our highest scoring system achieves an F1 of 91.74% using "gold" parses from the Penn Treebank and 91.12% when using the Berkeley Neural parser. This research includes both classroom and experimental settings for system development.', 'abstract_zh': '本文探讨了英语部分名词（例如：5%/REL of the price/ARG1；The price/ARG1 rose 5 percent/REL）的语义角色标注问题，并基于NomBank标注语料库进行了研究。文中描述了使用传统机器学习和基于变换器的机器学习方法构建的各种系统，还采用了集成学习方法。我们最高分的系统分别使用Penn Treebank的“黄金”解析和Berkeley Neural解析，达到了91.74%和91.12%的F1分数。本文的研究涵盖了课堂教学和实验设置下的系统开发。', 'title_zh': 'NomBank 部分补语的语义角色标注'}
{'arxiv_id': 'arXiv:2412.14323', 'title': 'The Role of Handling Attributive Nouns in Improving Chinese-To-English Machine Translation', 'authors': 'Haohao, Wang, Adam Meyers, John E. Ortega, Rodolfo Zevallos', 'link': 'https://arxiv.org/abs/2412.14323', 'abstract': "Translating between languages with drastically different grammatical conventions poses challenges, not just for human interpreters but also for machine translation systems. In this work, we specifically target the translation challenges posed by attributive nouns in Chinese, which frequently cause ambiguities in English translation. By manually inserting the omitted particle X ('DE'). In news article titles from the Penn Chinese Discourse Treebank, we developed a targeted dataset to fine-tune Hugging Face Chinese to English translation models, specifically improving how this critical function word is handled. This focused approach not only complements the broader strategies suggested by previous studies but also offers a practical enhancement by specifically addressing a common error type in Chinese-English translation.", 'abstract_zh': '不同语言具有截然不同的语法规则时，进行语言转换会面临挑战，这不仅对人类口译员构成考验，也对机器翻译系统提出了挑战。本文特别研究了中文中的限定名词对英语翻译造成的歧义问题。通过手动插入被省略的助词“的”（X），我们在宾夕法尼亚中文语篇树库（Penn Chinese Discourse Treebank）的新闻文章标题中构建了一个专门的数据集，用于微调Hugging Face的中文到英语翻译模型，特别是改进了对这类关键功能词的处理方式。这种有针对性的方法不仅补充了先前研究中提出的更广泛策略，还通过具体解决中文到英语翻译中的常见错误类型提供了实际的改进。', 'title_zh': '《属性名词的处理在提升中文到英文机器翻译中的作用》'}
{'arxiv_id': 'arXiv:2412.14304', 'title': 'Multi-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing LLM Ophthalmological QA in LMICs', 'authors': 'David Restrepo, Chenwei Wu, Zhengxu Tang, Zitao Shuai, Thao Nguyen Minh Phan, Jun-En Ding, Cong-Tinh Dao, Jack Gallifant, Robyn Gayle Dychiao, Jose Carlo Artiaga, André Hiroshi Bando, Carolina Pelegrini Barbosa Gracitelli, Vincenz Ferrer, Leo Anthony Celi, Danielle Bitterman, Michael G Morley, Luis Filipe Nakayama', 'link': 'https://arxiv.org/abs/2412.14304', 'abstract': 'Current ophthalmology clinical workflows are plagued by over-referrals, long waits, and complex and heterogeneous medical records. Large language models (LLMs) present a promising solution to automate various procedures such as triaging, preliminary tests like visual acuity assessment, and report summaries. However, LLMs have demonstrated significantly varied performance across different languages in natural language question-answering tasks, potentially exacerbating healthcare disparities in Low and Middle-Income Countries (LMICs). This study introduces the first multilingual ophthalmological question-answering benchmark with manually curated questions parallel across languages, allowing for direct cross-lingual comparisons. Our evaluation of 6 popular LLMs across 7 different languages reveals substantial bias across different languages, highlighting risks for clinical deployment of LLMs in LMICs. Existing debiasing methods such as Translation Chain-of-Thought or Retrieval-augmented generation (RAG) by themselves fall short of closing this performance gap, often failing to improve performance across all languages and lacking specificity for the medical domain. To address this issue, We propose CLARA (Cross-Lingual Reflective Agentic system), a novel inference time de-biasing method leveraging retrieval augmented generation and self-verification. Our approach not only improves performance across all languages but also significantly reduces the multilingual bias gap, facilitating equitable LLM application across the globe.', 'abstract_zh': '当前眼科临床工作流程受到过度转诊、等待时间长以及复杂多样的医疗记录的困扰。大型语言模型（LLMs）为自动化各种程序（如分诊、初步检查如视力评估和报告总结）提供了前景广阔的可能性。然而，LLMs 在自然语言问题回答任务中表现出显著不同的性能差异，这可能加剧低收入和中等收入国家（LMICs）的医疗健康不平等。本研究引入了首个跨语言眼科问题-答案基准数据集，其中包含手工策划的平行问题跨语言匹配，有助于直接进行跨语言比较。我们的评估结果显示，在7种不同语言的6种流行LLMs中表现出显著的语言偏差，突出了在LMICs中临床部署LLMs的风险。现有的去偏方法，如翻译链式思维或检索增强生成（RAG），单独使用时无法有效缩小性能差距，往往无法在所有语言中提高性能，并且缺乏针对医疗领域的特定性。为应对这一问题，我们提出了CLARA（跨语言反思代理系统）——一种新型推理时去偏方法，利用检索增强生成和自我验证。我们的方法不仅能够提高所有语言的性能，还显著减少了多语言偏差差距，促进了全球范围内的公平应用。', 'title_zh': '多语眼科语言：评估和去偏见 LMICs 中语言模型眼科 QA 的多语言基准'}
{'arxiv_id': 'arXiv:2412.14302', 'title': 'SAFERec: Self-Attention and Frequency Enriched Model for Next Basket Recommendation', 'authors': 'Oleg Lashinin, Denis Krasilnikov, Aleksandr Milogradskii, Marina Ananyeva', 'link': 'https://arxiv.org/abs/2412.14302', 'abstract': 'Transformer-based approaches such as BERT4Rec and SASRec demonstrate strong performance in Next Item Recommendation (NIR) tasks. However, applying these architectures to Next-Basket Recommendation (NBR) tasks, which often involve highly repetitive interactions, is challenging due to the vast number of possible item combinations in a basket. Moreover, frequency-based methods such as TIFU-KNN and UP-CF still demonstrate strong performance in NBR tasks, frequently outperforming deep-learning approaches. This paper introduces SAFERec, a novel algorithm for NBR that enhances transformer-based architectures from NIR by incorporating item frequency information, consequently improving their applicability to NBR tasks. Extensive experiments on multiple datasets show that SAFERec outperforms all other baselines, specifically achieving an 8\\% improvement in Recall@10.', 'abstract_zh': '基于Transformer的方法，如BERT4Rec和SASRec在Next Item Recommendation (NIR)任务中展示了强大的性能。然而，将这些架构应用于Next-Basket Recommendation (NBR)任务时存在挑战，尤其是在涉及大量重复交互的情况下，因为篮子中可能存在的项目组合数量非常庞大。此外，基于频率的方法，如TIFU-KNN和UP-CF在NBR任务中仍显示出强大的性能，经常优于深度学习方法。本文介绍了一种新的算法SAFERec，该算法通过结合项目频率信息来增强NIR任务中的Transformer架构，从而提高了这些架构在NBR任务中的适用性。在多个数据集上的 extensive 实验表明，SAFERec 在所有基线方法中表现出优越性，特别是在 Recall@10 上取得了 8% 的提升。', 'title_zh': 'SAFTERec：自我注意与频率增强模型在篮次推荐中的应用'}
{'arxiv_id': 'arXiv:2412.14295', 'title': 'Temporally Consistent Object-Centric Learning by Contrasting Slots', 'authors': 'Anna Manasyan, Maximilian Seitzer, Filip Radovic, Georg Martius, Andrii Zadaianchuk', 'link': 'https://arxiv.org/abs/2412.14295', 'abstract': 'Unsupervised object-centric learning from videos is a promising approach to extract structured representations from large, unlabeled collections of videos. To support downstream tasks like autonomous control, these representations must be both compositional and temporally consistent. Existing approaches based on recurrent processing often lack long-term stability across frames because their training objective does not enforce temporal consistency. In this work, we introduce a novel object-level temporal contrastive loss for video object-centric models that explicitly promotes temporal consistency. Our method significantly improves the temporal consistency of the learned object-centric representations, yielding more reliable video decompositions that facilitate challenging downstream tasks such as unsupervised object dynamics prediction. Furthermore, the inductive bias added by our loss strongly improves object discovery, leading to state-of-the-art results on both synthetic and real-world datasets, outperforming even weakly-supervised methods that leverage motion masks as additional cues.', 'abstract_zh': '无监督的目标为中心学习是从大量未标记的视频集合中提取结构化表示的一种有前途的方法。为了支持诸如自主控制之类的下游任务，这些表示必须同时具备组合性和时间一致性。现有的基于循环处理的方法往往缺乏长时间帧间的一致性，因为它们的训练目标并未强制时间一致性。在本工作中，我们提出了一种新颖的目标级别时间对比损失，专门用于视频目标为中心模型，以显式地促进时间一致性。我们的方法显著提高了所学习的目标为中心表示的时间一致性，从而实现了更可靠的视频分解，有助于诸如无监督对象动力学预测之类的具有挑战性的下游任务。此外，我们损失函数所带来的归纳偏置大大改善了对象的发现，使我们在合成数据集和现实世界数据集上均取得了最先进的结果，甚至超越了利用运动掩码作为额外线索的弱监督方法。', 'title_zh': '基于槽对比学习的时序一致对象中心化学习'}
{'arxiv_id': 'arXiv:2412.14283', 'title': 'PixelMan: Consistent Object Editing with Diffusion Models via Pixel Manipulation and Generation', 'authors': 'Liyao Jiang, Negar Hassanpour, Mohammad Salameh, Mohammadreza Samadi, Jiao He, Fengyu Sun, Di Niu', 'link': 'https://arxiv.org/abs/2412.14283', 'abstract': 'Recent research explores the potential of Diffusion Models (DMs) for consistent object editing, which aims to modify object position, size, and composition, etc., while preserving the consistency of objects and background without changing their texture and attributes. Current inference-time methods often rely on DDIM inversion, which inherently compromises efficiency and the achievable consistency of edited images. Recent methods also utilize energy guidance which iteratively updates the predicted noise and can drive the latents away from the original image, resulting in distortions. In this paper, we propose PixelMan, an inversion-free and training-free method for achieving consistent object editing via Pixel Manipulation and generation, where we directly create a duplicate copy of the source object at target location in the pixel space, and introduce an efficient sampling approach to iteratively harmonize the manipulated object into the target location and inpaint its original location, while ensuring image consistency by anchoring the edited image to be generated to the pixel-manipulated image as well as by introducing various consistency-preserving optimization techniques during inference. Experimental evaluations based on benchmark datasets as well as extensive visual comparisons show that in as few as 16 inference steps, PixelMan outperforms a range of state-of-the-art training-based and training-free methods (usually requiring 50 steps) on multiple consistent object editing tasks.', 'abstract_zh': '近期的研究探索了扩散模型（DMs）在实现对象一致编辑方面的潜在能力，其目标是在保持对象及其背景一致性的同时，修改对象的位置、大小和组成等，而不改变其纹理和属性。当前的推理时间方法往往依赖于DDIM反演，这不可避免地会牺牲效率和编辑图像的一致性。近年来的方法还利用能量引导进行迭代更新预测噪声，这可能导致潜在表示远离原始图像，从而产生失真。在本文中，我们提出了一种名为PixelMan的方法，这是一种无反演且无需训练的方法，该方法通过像素操纵和生成实现一致的对象编辑。在该方法中，我们直接在像素空间中创建源对象的副本到目标位置，并引入了一种高效的采样方法，用于逐步将操纵对象和谐地插入目标位置，并填补其原始位置，同时通过将生成的编辑图像锚定到像素操纵图像，并在推理过程中引入多种保持一致性的优化技术，来确保图像的一致性。基于基准数据集的实验评估以及广泛的视觉对比显示，在仅仅16步推理步骤内，PixelMan在多个一致性对象编辑任务中表现出色，优于多种基于训练和非训练方法（通常需要50步）。', 'title_zh': 'PixelMan：通过像素操纵与生成的一致对象编辑方法基于扩散模型'}
{'arxiv_id': 'arXiv:2412.14276', 'title': 'Fake News Detection: Comparative Evaluation of BERT-like Models and Large Language Models with Generative AI-Annotated Data', 'authors': 'haina Raza, Drai Paulen-Patterson, Chen Ding', 'link': 'https://arxiv.org/abs/2412.14276', 'abstract': 'Fake news poses a significant threat to public opinion and social stability in modern society. This study presents a comparative evaluation of BERT-like encoder-only models and autoregressive decoder-only large language models (LLMs) for fake news detection. We introduce a dataset of news articles labeled with GPT-4 assistance (an AI-labeling method) and verified by human experts to ensure reliability. Both BERT-like encoder-only models and LLMs were fine-tuned on this dataset. Additionally, we developed an instruction-tuned LLM approach with majority voting during inference for label generation. Our analysis reveals that BERT-like models generally outperform LLMs in classification tasks, while LLMs demonstrate superior robustness against text perturbations. Compared to weak labels (distant supervision) data, the results show that AI labels with human supervision achieve better classification results. This study highlights the effectiveness of combining AI-based annotation with human oversight and demonstrates the performance of different families of machine learning models for fake news detection', 'abstract_zh': '虚假信息对现代社会的公众意见和社会稳定构成重大威胁。本研究对基于BERT的编码器模型和自回归解码器大型语言模型（LLMs）在虚假信息检测中的性能进行了比较评价。我们引入了一个由GPT-4辅助标注（一种AI标注方法）并经人类专家验证的数据集，以确保数据的可靠性。这两种模型都在这数据集上进行了微调。此外，我们还开发了一种在推理过程中采用多数投票的指令调整的LLM方法，用于生成标签。我们的分析表明，基于BERT的模型在分类任务中通常优于LLMs，而LLMs在对抗文本扰动方面表现出更好的鲁棒性。与弱标签（远程监督）数据相比，结果表明，带有人类监督的AI标签能够获得更好的分类效果。本研究突显了结合基于AI的标注与人类监督的有效性，并展示了不同家族机器学习模型在虚假信息检测中的表现。', 'title_zh': '虚假新闻检测：基于BERT类模型与生成AI标注数据的大语言模型的比较评估'}
{'arxiv_id': 'arXiv:2412.14272', 'title': 'Split Learning in Computer Vision for Semantic Segmentation Delay Minimization', 'authors': 'Nikos G. Evgenidis, Nikos A. Mitsiou, Sotiris A. Tegos, Panagiotis D. Diamantoulakis, George K. Karagiannidis', 'link': 'https://arxiv.org/abs/2412.14272', 'abstract': "In this paper, we propose a novel approach to minimize the inference delay in semantic segmentation using split learning (SL), tailored to the needs of real-time computer vision (CV) applications for resource-constrained devices. Semantic segmentation is essential for applications such as autonomous vehicles and smart city infrastructure, but faces significant latency challenges due to high computational and communication loads. Traditional centralized processing methods are inefficient for such scenarios, often resulting in unacceptable inference delays. SL offers a promising alternative by partitioning deep neural networks (DNNs) between edge devices and a central server, enabling localized data processing and reducing the amount of data required for transmission. Our contribution includes the joint optimization of bandwidth allocation, cut layer selection of the edge devices' DNN, and the central server's processing resource allocation. We investigate both parallel and serial data processing scenarios and propose low-complexity heuristic solutions that maintain near-optimal performance while reducing computational requirements. Numerical results show that our approach effectively reduces inference delay, demonstrating the potential of SL for improving real-time CV applications in dynamic, resource-constrained environments.", 'abstract_zh': '在本文中，我们提出了一种新颖的方法，用于通过拆分学习（Split Learning, SL）最小化语义分割中的推理延迟，以满足资源受限设备上实时计算机视觉（Computer Vision, CV）应用的需求。语义分割对于自动驾驶车辆和智能城市基础设施等应用至关重要，但由于高计算和通信负载，面临显著的延迟挑战。传统的集中式处理方法在这些场景中效率低下，往往导致不可接受的推理延迟。SL通过将深度神经网络（Deep Neural Networks, DNNs）分割到边缘设备和中央服务器之间，提供了分区域数据处理的可能，并减少了传输所需的数据量。我们的贡献包括联合优化带宽分配、选择边缘设备和中央服务器的计算资源分配，并确定分割层。我们探讨了并行和串行数据处理场景，提出了一种低复杂度启发式解决方案，该方案在保持近乎最优性能的同时减少了计算需求。数值结果表明，我们的方法有效减少了推理延迟，展示了SL在动态和资源受限环境中改进实时CV应用的潜力。', 'title_zh': '计算机视觉中用于语义分割延迟最小化的分割学习'}
{'arxiv_id': 'arXiv:2412.14234', 'title': 'Syzygy: Dual Code-Test C to (safe) Rust Translation using LLMs and Dynamic Analysis', 'authors': 'Manish Shetty, Naman Jain, Adwait Godbole, Sanjit A. Seshia, Koushik Sen', 'link': 'https://arxiv.org/abs/2412.14234', 'abstract': 'Despite extensive usage in high-performance, low-level systems programming applications, C is susceptible to vulnerabilities due to manual memory management and unsafe pointer operations. Rust, a modern systems programming language, offers a compelling alternative. Its unique ownership model and type system ensure memory safety without sacrificing performance.\nIn this paper, we present Syzygy, an automated approach to translate C to safe Rust. Our technique uses a synergistic combination of LLM-driven code and test translation guided by dynamic-analysis-generated execution information. This paired translation runs incrementally in a loop over the program in dependency order of the code elements while maintaining per-step correctness. Our approach exposes novel insights on combining the strengths of LLMs and dynamic analysis in the context of scaling and combining code generation with testing. We apply our approach to successfully translate Zopfli, a high-performance compression library with ~3000 lines of code and 98 functions. We validate the translation by testing equivalence with the source C program on a set of inputs. To our knowledge, this is the largest automated and test-validated C to safe Rust code translation achieved so far.', 'abstract_zh': '尽管 C 语言因其在高性能低级系统编程应用中的广泛应用而广受欢迎，但由于其手动内存管理和不安全的指针操作，C 仍然容易受到漏洞的影响。作为现代系统编程语言的 Rust 提供了一个有力的替代方案。其独特的所有权模型和类型系统在不牺牲性能的情况下确保了内存安全。\n\n在本文中，我们介绍了 Syzygy，一种自动将 C 代码翻译为安全的 Rust 的方法。我们的技术利用了 LLM 驱动的代码和测试翻译与动态分析生成的执行信息指导相结合的方式。这种配对翻译按照代码元素的依赖顺序循环增量运行，同时保持每一步的正确性。我们的方法揭示了在扩展和结合代码生成与测试方面，如何结合 LLM 和动态分析的新颖见解。我们应用该方法成功地将 Zopfli（一个具有约 3000 行代码和 98 个功能的高性能压缩库）翻译成了安全的 Rust 代码。我们通过在一组输入上测试与源 C 程序的等效性来验证翻译结果。据我们所知，这是迄今为止实现的最大规模的自动测试验证的 C 到安全 Rust 代码翻译。', 'title_zh': '标题和内容翻译如下：\n\n标题：Syzygy: 使用大型语言模型和动态分析的面向安全的Rust翻译的代码-测试对偶变换\n\n正文：\nSyzygy: 利用大型语言模型和动态分析将代码-测试对偶变换为安全的Rust\n\n详细描述：\nSyzygy 是一种利用大型语言模型（LLMs）和动态分析技术将代码-测试对偶变换为安全的 Rust 语言的方法。该方法旨在通过自动将现有的代码和测试转换为安全可靠的 Rust 代码，提高软件系统的安全性和可维护性。'}
{'arxiv_id': 'arXiv:2412.14219', 'title': 'A Survey on Inference Optimization Techniques for Mixture of Experts Models', 'authors': 'Jiacheng Liu, Peng Tang, Wenfeng Wang, Yuhang Ren, Xiaofeng Hou, Pheng-Ann Heng, Minyi Guo, Chao Li', 'link': 'https://arxiv.org/abs/2412.14219', 'abstract': 'The emergence of large-scale Mixture of Experts (MoE) models has marked a significant advancement in artificial intelligence, offering enhanced model capacity and computational efficiency through conditional computation. However, the deployment and inference of these models present substantial challenges in terms of computational resources, latency, and energy efficiency. This comprehensive survey systematically analyzes the current landscape of inference optimization techniques for MoE models across the entire system stack. We first establish a taxonomical framework that categorizes optimization approaches into model-level, system-level, and hardware-level optimizations. At the model level, we examine architectural innovations including efficient expert design, attention mechanisms, various compression techniques such as pruning, quantization, and knowledge distillation, as well as algorithm improvement including dynamic routing strategies and expert merging methods. At the system level, we investigate distributed computing approaches, load balancing mechanisms, and efficient scheduling algorithms that enable scalable deployment. Furthermore, we delve into hardware-specific optimizations and co-design strategies that maximize throughput and energy efficiency. This survey not only provides a structured overview of existing solutions but also identifies key challenges and promising research directions in MoE inference optimization. Our comprehensive analysis serves as a valuable resource for researchers and practitioners working on large-scale deployment of MoE models in resource-constrained environments. To facilitate ongoing updates and the sharing of cutting-edge advances in MoE inference optimization research, we have established a repository accessible at \\url{this https URL}.', 'abstract_zh': '大规模混合专家（MoE）模型的出现标志着人工智能领域的重大进展，通过条件计算提升了模型容量和计算效率。然而，这些模型的部署和推理也面临着巨大的挑战，包括计算资源、延迟和能源效率等方面。本文通过全面的调查，系统地分析了整个系统栈中MoE模型推理优化技术的现状。我们首先建立了一个分类框架，将优化方法分为模型级、系统级和硬件级优化。在模型级，我们探讨了包括高效专家设计、注意力机制、各种压缩技术（如剪枝、量化和知识蒸馏）以及算法改进（包括动态路由策略和专家合并方法）在内的架构创新。在系统级，我们研究了分布式计算方法、负载均衡机制和高效的调度算法，以实现可扩展部署。此外，我们深入探讨了特定硬件的优化和协同设计策略，以最大化吞吐量和能源效率。本文不仅提供了现有解决方案的结构化概述，还指出了MoE推理优化中关键的挑战和有前景的研究方向。我们的综合分析为在资源受限环境中大规模部署MoE模型的研究人员和从业者提供了宝贵的资源。为了促进MoE推理优化研究的持续更新和最前沿进展的分享，我们建立了可在此处访问的仓库：\\url{this https URL}。', 'title_zh': '混合专家模型的推理优化技术综述'}
{'arxiv_id': 'arXiv:2412.14218', 'title': 'Heterogeneous Multi-Agent Reinforcement Learning for Distributed Channel Access in WLANs', 'authors': 'Jiaming Yu, Le Liang, Chongtao Guo, Ziyang Guo, Shi Jin, Geoffrey Ye Li', 'link': 'https://arxiv.org/abs/2412.14218', 'abstract': 'This paper investigates the use of multi-agent reinforcement learning (MARL) to address distributed channel access in wireless local area networks. In particular, we consider the challenging yet more practical case where the agents heterogeneously adopt value-based or policy-based reinforcement learning algorithms to train the model. We propose a heterogeneous MARL training framework, named QPMIX, which adopts a centralized training with distributed execution paradigm to enable heterogeneous agents to collaborate. Moreover, we theoretically prove the convergence of the proposed heterogeneous MARL method when using the linear value function approximation. Our method maximizes the network throughput and ensures fairness among stations, therefore, enhancing the overall network performance. Simulation results demonstrate that the proposed QPMIX algorithm improves throughput, mean delay, delay jitter, and collision rates compared with conventional carrier-sense multiple access with collision avoidance in the saturated traffic scenario. Furthermore, the QPMIX is shown to be robust in unsaturated and delay-sensitive traffic scenarios, and promotes cooperation among heterogeneous agents.', 'abstract_zh': '本文探讨了多代理 reinforcement 学习（MARL）在无线局域网中分布式信道访问中的应用。特别地，我们考虑了一个更具挑战性的、但更具实际意义的情况，即代理异构地采用基于值或基于策略的 reinforcement 学习算法来训练模型。本文提出了一种名为 QPMIX 的异构 MARL 训练框架，该框架采用集中式训练与分布式执行的模式，以使异构代理能够协作。此外，我们从理论上证明了在使用线性值函数逼近时，所提出的异构 MARL 方法的收敛性。该方法最大限度地提高了网络吞吐量，并确保了各站点之间的公平性，从而整体提升了网络性能。仿真实验结果表明，在饱和流量场景下，相比传统的载波侦听多路访问/碰撞避免（CSMA/CA），所提出的 QPMIX 算法在吞吐量、平均延迟、延迟抖动和碰撞率方面均有提升。此外，QPMIX 在非饱和和延迟敏感的流量场景下表现出良好的鲁棒性，并促进了异构代理之间的合作。', 'title_zh': '针对WLAN中分布式信道访问的异构多代理强化学习方法'}
{'arxiv_id': 'arXiv:2412.14215', 'title': 'Generative AI Toolkit -- a framework for increasing the quality of LLM-based applications over their whole life cycle', 'authors': 'Jens Kohl, Luisa Gloger, Rui Costa, Otto Kruse, Manuel P. Luitz, David Katz, Gonzalo Barbeito, Markus Schweier, Ryan French, Jonas Schroeder, Thomas Riedl, Raphael Perri, Youssef Mostafa', 'link': 'https://arxiv.org/abs/2412.14215', 'abstract': 'As LLM-based applications reach millions of customers, ensuring their scalability and continuous quality improvement is critical for success. However, the current workflows for developing, maintaining, and operating (DevOps) these applications are predominantly manual, slow, and based on trial-and-error. With this paper we introduce the Generative AI Toolkit, which automates essential workflows over the whole life cycle of LLM-based applications. The toolkit helps to configure, test, continuously monitor and optimize Generative AI applications such as agents, thus significantly improving quality while shortening release cycles. We showcase the effectiveness of our toolkit on representative use cases, share best practices, and outline future enhancements. Since we are convinced that our Generative AI Toolkit is helpful for other teams, we are open sourcing it on and hope that others will use, forward, adapt and improve', 'abstract_zh': '随着基于大语言模型（LLM）的应用达到数百万用户，确保其可扩展性和持续的质量改进对于其成功至关重要。然而，当前开发、维护和运营（DevOps）这些应用的工作流程主要依赖于人工、缓慢且基于试错的方法。在本文中，我们介绍了一种生成式AI工具集，它能够自动化整个生成式AI应用生命周期中的关键工作流程。该工具集有助于配置、测试、持续监控和优化生成式AI应用（如智能代理），从而显著提高质量并缩短发布周期。我们通过代表性案例展示了该工具集的有效性，分享了最佳实践，并概述了未来增强计划。由于我们相信该生成式AI工具集对其他团队也有帮助，我们将其开源，并希望其他人能够使用、传播、适应和改进它。', 'title_zh': '生成式AI工具包——提升基于大规模语言模型的应用在整个生命周期质量的框架'}
{'arxiv_id': 'arXiv:2412.14214', 'title': 'GraphicsDreamer: Image to 3D Generation with Physical Consistency', 'authors': 'Pei Chen, Fudong Wang, Yixuan Tong, Jingdong Chen, Ming Yang, Minghui Yang', 'link': 'https://arxiv.org/abs/2412.14214', 'abstract': "Recently, the surge of efficient and automated 3D AI-generated content (AIGC) methods has increasingly illuminated the path of transforming human imagination into complex 3D structures. However, the automated generation of 3D content is still significantly lags in industrial application. This gap exists because 3D modeling demands high-quality assets with sharp geometry, exquisite topology, and physically based rendering (PBR), among other criteria. To narrow the disparity between generated results and artists' expectations, we introduce GraphicsDreamer, a method for creating highly usable 3D meshes from single images. To better capture the geometry and material details, we integrate the PBR lighting equation into our cross-domain diffusion model, concurrently predicting multi-view color, normal, depth images, and PBR materials. In the geometry fusion stage, we continue to enforce the PBR constraints, ensuring that the generated 3D objects possess reliable texture details, supporting realistic relighting. Furthermore, our method incorporates topology optimization and fast UV unwrapping capabilities, allowing the 3D products to be seamlessly imported into graphics engines. Extensive experiments demonstrate that our model can produce high quality 3D assets in a reasonable time cost compared to previous methods.", 'abstract_zh': '近年来，高效且自动化的三维AI生成内容（AIGC）方法的兴起日益突显了将人类想象转化为复杂三维结构的途径。然而，三维内容的自动化生成在工业应用中仍然存在显著差距。这一差距源于三维建模需要高质量的资产，包括锐利的几何结构、精美的拓扑结构以及基于物理的渲染（PBR）等要求。为缩小生成结果与艺术家期望之间的差距，我们提出了GraphicsDreamer方法，以从单张图像中创建高度可用的3D网格。为了更好地捕捉几何和材质细节，我们将PBR光照方程整合到我们的跨域扩散模型中，同时预测多视角颜色、法线、深度图像和PBR材质。在几何融合阶段，我们继续施加PBR约束，确保生成的三维物体具有可靠的纹理细节，支持现实的重新照明。此外，我们的方法还整合了拓扑优化和快速UV展开功能，使得三维产品能够无缝导入图形引擎。大量实验表明，与以前的方法相比，我们的模型能够在合理的时间成本下生成高质素的三维资产。', 'title_zh': 'GraphicsDreamer：具有物理一致性从图像生成三维模型'}
{'arxiv_id': 'arXiv:2412.14212', 'title': 'Tree-of-Code: A Hybrid Approach for Robust Complex Task Planning and Execution', 'authors': 'Ziyi Ni, Yifan Li, Daxiang Dong', 'link': 'https://arxiv.org/abs/2412.14212', 'abstract': "The exceptional capabilities of large language models (LLMs) have substantially accelerated the rapid rise and widespread adoption of agents. Recent studies have demonstrated that generating Python code to consolidate LLM-based agents' actions into a unified action space (CodeAct) is a promising approach for developing real-world LLM agents. However, this step-by-step code generation approach often lacks consistency and robustness, leading to instability in agent applications, particularly for complex reasoning and out-of-domain tasks. In this paper, we propose a novel approach called Tree-of-Code (ToC) to tackle the challenges of complex problem planning and execution with an end-to-end mechanism. By integrating key ideas from both Tree-of-Thought and CodeAct, ToC combines their strengths to enhance solution exploration. In our framework, each final code execution result is treated as a node in the decision tree, with a breadth-first search strategy employed to explore potential solutions. The final outcome is determined through a voting mechanism based on the outputs of the nodes.", 'abstract_zh': '大型语言模型（LLMs）的卓越能力大幅加速了智能代理的快速崛起和广泛应用。近期的研究表明，生成Python代码以将基于LLM的代理行为整合到统一的动作空间（CodeAct）是一种有前景的方法，用于开发实际应用中的LLM代理。然而，这种逐步的代码生成方法往往缺乏一致性和稳健性，导致在智能代理应用于复杂推理和领域外任务时会出现不稳定现象。本文提出了一种名为Tree-of-Code（ToC）的新方法，通过端到端机制解决复杂问题规划和执行的挑战。ToC结合了Tree-of-Thought和CodeAct的关键思想，利用它们各自的优点来增强解决方案的探索。在我们的框架中，每个最终代码执行结果被视为决策树中的一个节点，并采用广度优先搜索策略来探讨潜在解决方案。最终结果通过节点输出的投票机制来确定。', 'title_zh': 'Tree-of-Code: 一种稳健的复杂任务规划与执行的混合方法'}
{'arxiv_id': 'arXiv:2412.14209', 'title': 'Integrating Evidence into the Design of XAI and AI-based Decision Support Systems: A Means-End Framework for End-users in Construction', 'authors': 'Peter .E.D. Love, Jane Matthews, Weili Fang, Hadi Mahamivanan', 'link': 'https://arxiv.org/abs/2412.14209', 'abstract': "A narrative review is used to develop a theoretical evidence-based means-end framework to build an epistemic foundation to uphold explainable artificial intelligence instruments so that the reliability of outcomes generated from decision support systems can be assured and better explained to end-users. The implications of adopting an evidence-based approach to designing decision support systems in construction are discussed with emphasis placed on evaluating the strength, value, and utility of evidence needed to develop meaningful human explanations for end-users. While the developed means-end framework is focused on end-users, stakeholders can also utilize it to create meaningful human explanations. However, they will vary due to their different epistemic goals. Including evidence in the design and development of explainable artificial intelligence and decision support systems will improve decision-making effectiveness, enabling end-users' epistemic goals to be achieved. The proposed means-end framework is developed from a broad spectrum of literature. Thus, it is suggested that it can be used in construction and other engineering domains where there is a need to integrate evidence into the design of explainable artificial intelligence and decision support systems.", 'abstract_zh': '本文采用叙述性综述的方法，构建了一个理论导向的手段-目标框架，以建立解释性人工智能工具的知识基础，并确保决策支持系统的输出结果可靠且能够更好地向终端用户解释。讨论了采用证据导向的方法设计建筑行业决策支持系统的含义，着重评估了开发有意义的人类解释所需证据的强度、价值和实用性。虽然所构建的手段-目标框架主要针对终端用户，但利益相关者也可以利用它来创建有意义的人类解释，不过这些解释会因各自的知识目标不同而有所差异。将证据纳入解释性人工智能和决策支持系统的设计与开发中，将提高决策的有效性，使终端用户的知识目标得以实现。提出的手段-目标框架来源于广泛的文献综述，因此建议该框架可以应用于需要将证据整合到解释性人工智能和决策支持系统设计中的建筑和其他工程领域。', 'title_zh': '将证据融入基于XAI和AI决策支持系统的设计之中：建筑领域最终用户视角的目的-手段框架'}
{'arxiv_id': 'arXiv:2412.14205', 'title': 'Large-scale Group Brainstorming using Conversational Swarm Intelligence (CSI) versus Traditional Chat', 'authors': 'Louis Rosenberg, Hans Schumann, Christopher Dishop, Gregg Willcox, Anita Woolley, Ganesh Mani', 'link': 'https://arxiv.org/abs/2412.14205', 'abstract': 'Conversational Swarm Intelligence (CSI) is an AI-facilitated method for enabling real-time conversational deliberations and prioritizations among networked human groups of potentially unlimited size. Based on the biological principle of Swarm Intelligence and modelled on the decision-making dynamics of fish schools, CSI has been shown in prior studies to amplify group intelligence, increase group participation, and facilitate productive collaboration among hundreds of participants at once. It works by dividing a large population into a set of small subgroups that are woven together by real-time AI agents called Conversational Surrogates. The present study focuses on the use of a CSI platform called Thinkscape to enable real-time brainstorming and prioritization among groups of 75 networked users. The study employed a variant of a common brainstorming intervention called an Alternative Use Task (AUT) and was designed to compare through subjective feedback, the experience of participants brainstorming using a CSI structure vs brainstorming in a single large chat room. This comparison revealed that participants significantly preferred brainstorming with the CSI structure and reported that it felt (i) more collaborative, (ii) more productive, and (iii) was better at surfacing quality answers. In addition, participants using the CSI structure reported (iv) feeling more ownership and more buy-in in the final answers the group converged on and (v) reported feeling more heard as compared to brainstorming in a traditional text chat environment. Overall, the results suggest that CSI is a very promising AI-facilitated method for brainstorming and prioritization among large-scale, networked human groups.', 'abstract_zh': '对话蜂群智能（Conversational Swarm Intelligence，CSI）是一种通过人工智能辅助进行实时对话性讨论和优先级排序的方法，适用于潜在无限规模的网络化人类群体。该方法基于生物蜂群智能的原则，并模仿鱼群决策机制。以往研究已证实，CSI能够放大群体智能、增加群体参与度，并促进数百名参与者同时的高效协作。CSI通过将大规模人群分成由实时人工智能代理（称为对话替代者）编织在一起的小群体来实现这一目标。\n\n本研究聚焦于使用一种名为Thinkscape的CSI平台，以促进75名网络用户之间的实时头脑风暴和优先级排序。研究采用了常见的头脑风暴干预措施之一——替代用途任务（Alternative Use Task，AUT），并通过主观反馈比较了参与者在CSI结构下进行头脑风暴与在单个大型聊天室中进行头脑风暴的体验。结果表明，参与者更偏好使用CSI结构进行头脑风暴，认为这种结构使得（i）合作感更强，（ii）更富有成效，并且（iii）更能产生优质答案。此外，使用CSI结构的参与者认为在最终达成共识的答案上（iv）拥有更强的所有权感和认同感，并且（v）感觉自己更被听见，相比于在传统文本聊天环境中进行头脑风暴。总体而言，这些结果表明，CSI是一种非常适合大规模网络化人类群体进行头脑风暴和优先级排序的极具前景的人工智能辅助方法。', 'title_zh': '大规模群体头脑风暴：基于对话型群智情报（Conversational Swarm Intelligence, CSI）的方法与传统聊天的比较'}
{'arxiv_id': 'arXiv:2412.14203', 'title': 'BlenderLLM: Training Large Language Models for Computer-Aided Design with Self-improvement', 'authors': 'Yuhao Du, Shunian Chen, Wenbo Zan, Peizhao Li, Mingxuan Wang, Dingjie Song, Bo Li, Yan Hu, Benyou Wang', 'link': 'https://arxiv.org/abs/2412.14203', 'abstract': 'The application of Large Language Models (LLMs) in Computer-Aided Design (CAD) remains an underexplored area, despite their remarkable advancements in other domains. In this paper, we present BlenderLLM, a novel framework for training LLMs specifically for CAD tasks leveraging a self-improvement methodology. To support this, we developed a bespoke training dataset, BlendNet, and introduced a comprehensive evaluation suite, CADBench. Our results reveal that existing models demonstrate significant limitations in generating accurate CAD scripts. However, through minimal instruction-based fine-tuning and iterative self-improvement, BlenderLLM significantly surpasses these models in both functionality and accuracy of CAD script generation. This research establishes a strong foundation for the application of LLMs in CAD while demonstrating the transformative potential of self-improving models in advancing CAD automation. We encourage further exploration and adoption of these methodologies to drive innovation in the field. The dataset, model, benchmark, and source code are publicly available at this https URL', 'abstract_zh': '尽管大型语言模型（LLMs）在其他领域取得了显著进展，但在计算机辅助设计（CAD）中的应用仍是一个未充分探索的领域。本文介绍了BlenderLLM，这是一种专为CAD任务训练的新型框架，利用自我提高方法。为支持这一目标，我们开发了专门的训练数据集BlendNet，并引入了一个全面的评估套件CADBench。我们的研究表明，现有的模型在生成准确的CAD脚本方面存在显著局限性。然而，通过基于最少指令的微调和迭代自我提高，BlenderLLM在功能性和CAD脚本生成的准确性方面显著超过了这些模型。本研究为LLMs在CAD中的应用奠定了坚实的基础，同时展示了自我提高模型在推进CAD自动化方面的变革潜力。我们鼓励进一步探索和采用这些方法以推动该领域的创新。有关数据集、模型、基准测试和源代码可在以下网址获取：[在这里插入网址]', 'title_zh': 'BlenderLLM：用于计算机辅助设计的大规模语言模型训练及自我改进'}
{'arxiv_id': 'arXiv:2412.14194', 'title': 'Detecting Cognitive Impairment and Psychological Well-being among Older Adults Using Facial, Acoustic, Linguistic, and Cardiovascular Patterns Derived from Remote Conversations', 'authors': 'Xiaofan Mu, Salman Seyedi, Iris Zheng, Zifan Jiang, Liu Chen, Bolaji Omofojoye, Rachel Hershenberg, Allan I. Levey, Gari D. Clifford, Hiroko H. Dodge, Hyeokhyen Kwon', 'link': 'https://arxiv.org/abs/2412.14194', 'abstract': 'INTRODUCTION: The aging society urgently requires scalable methods to monitor cognitive decline and identify social and psychological factors indicative of dementia risk in older adults. METHODS: Our machine learning models captured facial, acoustic, linguistic, and cardiovascular features from 39 individuals with normal cognition or Mild Cognitive Impairment derived from remote video conversations and classified cognitive status, social isolation, neuroticism, and psychological well-being. RESULTS: Our model could distinguish Clinical Dementia Rating Scale of 0.5 (vs. 0) with 0.78 area under the receiver operating characteristic curve (AUC), social isolation with 0.75 AUC, neuroticism with 0.71 AUC, and negative affect scales with 0.79 AUC. DISCUSSION: Our findings demonstrate the feasibility of remotely monitoring cognitive status, social isolation, neuroticism, and psychological well-being. Speech and language patterns were more useful for quantifying cognitive impairment, whereas facial expression and cardiovascular patterns using remote photoplethysmography were more useful for quantifying personality and psychological well-being.', 'abstract_zh': 'Introduction：老龄化社会迫切需要能够大规模监测认知衰退并识别与痴呆风险相关的社会和心理因素的方法。\n\n Methods：我们的机器学习模型从39名正常认知或轻度认知障碍个体的远程视频对话中捕获了面部、声学、语言和心血管特征，并分类认知状态、社交孤立、神经质和心理福祉。\n\n Results：我们的模型在临床痴呆评定量表为0.5（对比0）时的受试者操作特征曲线下的面积（AUC）为0.78，社交孤立的AUC为0.75，神经质的AUC为0.71，消极情绪量表的AUC为0.79。\n\n Discussion：我们的发现证明了通过远程监测认知状态、社交孤立、神经质和心理福祉的可行性。语音和语言模式对于量化认知损伤更为有用，而面部表情和通过远程光体积描记法获取的心血管模式则对于量化个性和心理福祉更为有用。', 'title_zh': '利用远程对话中提取的面部、声学、语言和心血管模式检测老年人的认知障碍和心理福祉'}
{'arxiv_id': 'arXiv:2412.14193', 'title': 'Whom do Explanations Serve? A Systematic Literature Survey of User Characteristics in Explainable Recommender Systems Evaluation', 'authors': 'Kathrin Wardatzky, Oana Inel, Luca Rossetto, Abraham Bernstein', 'link': 'https://arxiv.org/abs/2412.14193', 'abstract': "Adding explanations to recommender systems is said to have multiple benefits, such as increasing user trust or system transparency. Previous work from other application areas suggests that specific user characteristics impact the users' perception of the explanation. However, we rarely find this type of evaluation for recommender systems explanations. This paper addresses this gap by surveying 124 papers in which recommender systems explanations were evaluated in user studies. We analyzed their participant descriptions and study results where the impact of user characteristics on the explanation effects was measured. Our findings suggest that the results from the surveyed studies predominantly cover specific users who do not necessarily represent the users of recommender systems in the evaluation domain. This may seriously hamper the generalizability of any insights we may gain from current studies on explanations in recommender systems. We further find inconsistencies in the data reporting, which impacts the reproducibility of the reported results. Hence, we recommend actions to move toward a more inclusive and reproducible evaluation.", 'abstract_zh': '将推荐系统中加入解释被认为是有多重益处的，例如增加用户的信任度或提高系统的透明度。来自其他应用领域的早期研究指出，用户的某些特性会影响他们对解释的感知。然而，我们在推荐系统解释方面的评价中很少见到这种类型的评估。本文通过调查124篇论文解决了这一缺口，这些论文涉及了用户研究中对推荐系统解释的评估。我们分析了这些研究中参与者描述和实验结果，评估了用户特性对解释效果的影响。我们的发现表明，这些调查研究的结果大多集中在特定的用户群体上，这些用户不一定代表评估领域中推荐系统的实际用户。这可能严重阻碍我们从当前关于推荐系统解释的研究中获得的任何见解的一般性。此外，我们还发现数据报告存在不一致性，这影响了报告结果的可重复性。因此，我们建议采取措施朝着更具包容性和可重复性的评估方向前进。', 'title_zh': '解释性推荐系统评估中用户的特性研究：一项系统文献综述'}
{'arxiv_id': 'arXiv:2412.14191', 'title': 'Ontology-Aware RAG for Improved Question-Answering in Cybersecurity Education', 'authors': 'Chengshuai Zhao, Garima Agrawal, Tharindu Kumarage, Zhen Tan, Yuli Deng, Ying-Chih Chen, Huan Liu', 'link': 'https://arxiv.org/abs/2412.14191', 'abstract': 'Integrating AI into education has the potential to transform the teaching of science and technology courses, particularly in the field of cybersecurity. AI-driven question-answering (QA) systems can actively manage uncertainty in cybersecurity problem-solving, offering interactive, inquiry-based learning experiences. Large language models (LLMs) have gained prominence in AI-driven QA systems, offering advanced language understanding and user engagement. However, they face challenges like hallucinations and limited domain-specific knowledge, which reduce their reliability in educational settings. To address these challenges, we propose CyberRAG, an ontology-aware retrieval-augmented generation (RAG) approach for developing a reliable and safe QA system in cybersecurity education. CyberRAG employs a two-step approach: first, it augments the domain-specific knowledge by retrieving validated cybersecurity documents from a knowledge base to enhance the relevance and accuracy of the response. Second, it mitigates hallucinations and misuse by integrating a knowledge graph ontology to validate the final answer. Experiments on publicly available cybersecurity datasets show that CyberRAG delivers accurate, reliable responses aligned with domain knowledge, demonstrating the potential of AI tools to enhance education.', 'abstract_zh': '将人工智能融入教育有可能重塑科学和技术课程的教学，尤其是在网络安全领域。由人工智能驱动的问答（QA）系统可以在网络安全问题解决中主动管理不确定性，提供互动性和探究性学习体验。大型语言模型（LLMs）在人工智能驱动的QA系统中备受瞩目，提供了高级语言理解和用户参与度。然而，它们面临幻觉和有限领域特定知识等挑战，这在教育环境中降低了它们的可靠性。为了解决这些挑战，我们提出了一种名为CyberRAG的方法，这是一种基于本体的检索增强生成（RAG）方法，用于开发网络安全教育中的可靠和安全的问答系统。CyberRAG采用两步方法：首先，通过从知识库中检索验证过的网络安全文档来增强领域特定知识，提高响应的相关性和准确性；其次，通过集成知识图本体来验证最终答案，以减轻幻觉和误用问题。在公开的网络安全数据集上的实验表明，CyberRAG能提供与领域知识一致的准确和可靠的回应，展示了人工智能工具提升教育的潜力。', 'title_zh': '基于本体的RAG方法以提高网络安全教育中的问答效果'}
{'arxiv_id': 'arXiv:2412.14190', 'title': 'Lessons From an App Update at Replika AI: Identity Discontinuity in Human-AI Relationships', 'authors': 'Julian De Freitas, Noah Castelo, Ahmet Uguralp, Zeliha Uguralp', 'link': 'https://arxiv.org/abs/2412.14190', 'abstract': 'Can consumers form especially deep emotional bonds with AI and be vested in AI identities over time? We leverage a natural app-update event at Replika AI, a popular US-based AI companion, to shed light on these questions. We find that, after the app removed its erotic role play (ERP) feature, preventing intimate interactions between consumers and chatbots that were previously possible, this event triggered perceptions in customers that their AI companion\'s identity had discontinued. This in turn predicted negative consumer welfare and marketing outcomes related to loss, including mourning the loss, and devaluing the "new" AI relative to the "original". Experimental evidence confirms these findings. Further experiments find that AI companions users feel closer to their AI companion than even their best human friend, and mourn a loss of their AI companion more than a loss of various other inanimate products. In short, consumers are forming human-level relationships with AI companions; disruptions to these relationships trigger real patterns of mourning as well as devaluation of the offering; and the degree of mourning and devaluation are explained by perceived discontinuity in the AIs identity. Our results illustrate that relationships with AI are truly personal, creating unique benefits and risks for consumers and firms alike.', 'abstract_zh': '消费者能否与AI形成特别深厚的情感纽带，并随着时间的推移投资于AI的身份认同？我们利用Replika AI这款流行的美国AI伴侣软件的一个自然应用程序更新事件，来探讨这些问题。我们发现，当应用程序移除其色情角色扮演功能，阻止了消费者与之前可以互动的聊天机器人之间的亲密互动后，这一事件引发了客户对其AI伴侣身份中断的认知。这反过来预测了与损失相关的消费者福利和营销结果的负面影响，包括对损失的哀悼以及重新评价“新的”AI与“原始”的AI相比的价值。实验证据证实了这些发现。进一步的实验表明，使用AI伴侣的用户与其AI伴侣的关系比与他们最好的人类朋友的关系更为亲密，并且在AI伴侣失去后哀悼的程度超过了对各种其他无生命产品失去的哀悼。简而言之，消费者正在与AI伴侣建立人类水平的关系；这些关系的中断引发了真实的哀悼模式以及对产品的重新评价；哀悼和重新评价的程度由对AI身份中断的认知差异来解释。我们的研究结果表明，与AI的关系确实是非常个人的，这为消费者和企业都带来了独特的优势和风险。', 'title_zh': 'Replika AI 应用更新中的教训：人类-人工智能关系中的身份连续性中断'}
{'arxiv_id': 'arXiv:2412.14188', 'title': 'CogSimulator: A Model for Simulating User Cognition & Behavior with Minimal Data for Tailored Cognitive Enhancement', 'authors': 'Weizhen Bian, Yubo Zhou, Yuanhang Luo, Ming Mo, Siyan Liu, Yikai Gong, Renjie Wan, Ziyuan Luo, Aobo Wang', 'link': 'https://arxiv.org/abs/2412.14188', 'abstract': 'The interplay between cognition and gaming, notably through educational games enhancing cognitive skills, has garnered significant attention in recent years. This research introduces the CogSimulator, a novel algorithm for simulating user cognition in small-group settings with minimal data, as the educational game Wordle exemplifies. The CogSimulator employs Wasserstein-1 distance and coordinates search optimization for hyperparameter tuning, enabling precise few-shot predictions in new game scenarios. Comparative experiments with the Wordle dataset illustrate that our model surpasses most conventional machine learning models in mean Wasserstein-1 distance, mean squared error, and mean accuracy, showcasing its efficacy in cognitive enhancement through tailored game design.', 'abstract_zh': '认知与游戏之间的相互作用，尤其是在教育游戏中通过增强认知技能的方式，近年来引起了广泛关注。本文介绍了一种新的算法——CogSimulator，用于在少量数据的情况下模拟用户在小组环境中的认知过程。以热门的教育资源游戏Wordle为例，CogSimulator采用Wasserstein-1距离和坐标搜索优化超参数调节，能够在新游戏场景中实现精确的少样本预测。通过与Wordle数据集的对比实验表明，我们的模型在Wasserstein-1距离、均方误差和准确率方面均优于大多数传统机器学习模型，展示了其通过定制化游戏设计提高认知能力的有效性。', 'title_zh': 'CogSimulator：一种基于最小数据量模拟用户认知与行为的模型，以实现个性化认知增强'}
{'arxiv_id': 'arXiv:2412.14186', 'title': 'Towards AI-$45^{\\circ}$ Law: A Roadmap to Trustworthy AGI', 'authors': 'Yang Chao, Lu Chaochao, Wang Yingchun, Zhou Bowen', 'link': 'https://arxiv.org/abs/2412.14186', 'abstract': "Ensuring Artificial General Intelligence (AGI) reliably avoids harmful behaviors is a critical challenge, especially for systems with high autonomy or in safety-critical domains. Despite various safety assurance proposals and extreme risk warnings, comprehensive guidelines balancing AI safety and capability remain lacking. In this position paper, we propose the \\textit{AI-\\textbf{$45^{\\circ}$} Law} as a guiding principle for a balanced roadmap toward trustworthy AGI, and introduce the \\textit{Causal Ladder of Trustworthy AGI} as a practical framework. This framework provides a systematic taxonomy and hierarchical structure for current AI capability and safety research, inspired by Judea Pearl's ``Ladder of Causation''. The Causal Ladder comprises three core layers: the Approximate Alignment Layer, the Intervenable Layer, and the Reflectable Layer. These layers address the key challenges of safety and trustworthiness in AGI and contemporary AI systems. Building upon this framework, we define five levels of trustworthy AGI: perception, reasoning, decision-making, autonomy, and collaboration trustworthiness. These levels represent distinct yet progressive aspects of trustworthy AGI. Finally, we present a series of potential governance measures to support the development of trustworthy AGI.\\footnote{In this paper, trustworthiness is generally considered a broad form of safety, and no explicit distinction is made between the two. However, in some contexts, safety and trustworthiness are treated as distinct: safety involves assurance of correct behavior, while trustworthiness refers to user confidence in the system's decision-making. In such cases, different terms or both may be used depending on the context.", 'abstract_zh': '确保人工智能通用系统（AGI）可靠地避免有害行为是一项关键挑战，特别是在具有高度自主性或在安全关键领域的系统中尤为如此。尽管提出了各种安全保证方案以及极端风险警告，但平衡AI安全与能力的全面指南仍然有所欠缺。在这篇立场声明中，我们提出了“AI-45°定律”作为一条指导原则，引领一条可信AGI的发展路线图，并介绍了“可信AGI因果阶梯”作为一种实用框架。该框架为当前的AI能力和安全性研究提供了一种系统化的分类和层次结构，灵感来自于尤德·佩尔德的“因果阶梯”。因果阶梯包含三个核心层：近似对齐层、可控层和可反思层。这些层次针对AGI和当代AI系统的安全性和可信性中的关键挑战。在此框架基础上，我们定义了可信AGI的五个层级：感知可信性、推理可信性、决策可信性、自主性可信性和协作可信性。这些层级代表了可信AGI的独特且渐进性的方面。最后，我们提出了若干潜在的治理措施以支持可信AGI的发展。 footnote{在这篇文章中，通常将可信性视为广泛意义上的安全，没有明确区分两者之间的区别。但在某些情况下，安全性和可信性被视为不同的概念：安全性涉及行为正确性的保证，而可信性指的是用户对系统决策的信心。在这种情况下，根据不同的情境，可能会使用不同的术语或两者兼用。}', 'title_zh': '朝向AI-45°法则：迈向可信赖的超人工智能的路线图'}
{'arxiv_id': 'arXiv:2412.14179', 'title': 'Benchmarking Harmonized Tariff Schedule Classification Models', 'authors': 'Bryce Judy', 'link': 'https://arxiv.org/abs/2412.14179', 'abstract': "The Harmonized Tariff System (HTS) classification industry, essential to e-commerce and international trade, currently lacks standardized benchmarks for evaluating the effectiveness of classification solutions. This study establishes and tests a benchmark framework for imports to the United States, inspired by the benchmarking approaches used in language model evaluation, to systematically compare prominent HTS classification tools. The framework assesses key metrics--such as speed, accuracy, rationality, and HTS code alignment--to provide a comprehensive performance comparison. The study evaluates several industry-leading solutions, including those provided by Zonos, Tarifflo, Avalara, and WCO BACUDA, identifying each tool's strengths and limitations. Results highlight areas for industry-wide improvement and innovation, paving the way for more effective and standardized HTS classification solutions across the international trade and e-commerce sectors.", 'abstract_zh': '国际贸易和电子商务领域至关重要的海关分类协调制度（HTS）目前缺乏标准化的基准来评估分类解决方案的有效性。本研究受语言模型评估中的基准测试方法的启发，建立并测试了一套适用于美国进口的基准框架，系统比较了主要的HTS分类工具。该框架评估关键指标——包括速度、准确性、合理性和HTS代码对齐——以进行全面的性能比较。研究评估了几种业内领先解决方案，包括Zonos、Tarifflo、Avalara和WCO BACUDA提供的工具，指出每种工具的优势和局限性。研究结果强调了行业范围内的改进和创新领域，为国际贸易和电子商务领域提供了更有效和标准化的HTS分类解决方案。', 'title_zh': 'harmonizedtariff schedule分类模型基准测试'}
{'arxiv_id': 'arXiv:2407.00521', 'title': 'A Medical Low-Back Pain Physical Rehabilitation Dataset for Human Body Movement Analysis', 'authors': 'Sao Mai Nguyen, Maxime Devanne, Olivier Remy-Neris, Mathieu Lempereur, André Thepaut', 'link': 'https://arxiv.org/abs/2407.00521', 'abstract': 'While automatic monitoring and coaching of exercises are showing encouraging results in non-medical applications, they still have limitations such as errors and limited use contexts. To allow the development and assessment of physical rehabilitation by an intelligent tutoring system, we identify in this article four challenges to address and propose a medical dataset of clinical patients carrying out low back-pain rehabilitation exercises. The dataset includes 3D Kinect skeleton positions and orientations, RGB videos, 2D skeleton data, and medical annotations to assess the correctness, and error classification and localisation of body part and timespan. Along this dataset, we perform a complete research path, from data collection to processing, and finally a small benchmark. We evaluated on the dataset two baseline movement recognition algorithms, pertaining to two different approaches: the probabilistic approach with a Gaussian Mixture Model (GMM), and the deep learning approach with a Long-Short Term Memory (LSTM).\nThis dataset is valuable because it includes rehabilitation relevant motions in a clinical setting with patients in their rehabilitation program, using a cost-effective, portable, and convenient sensor, and because it shows the potential for improvement on these challenges.', 'abstract_zh': '自动监测和指导锻炼在非医疗应用中显示出积极的结果，但仍存在一些限制，如错误和使用场景的限制。为了允许智能辅导系统进行物理康复的开发和评估，本文识别了四个需要解决的挑战，并提出了一组包含临床患者实施腰痛康复锻炼的医疗数据集。该数据集包括3D Kinect骨架的位置和姿态、RGB视频、2D骨架数据以及医学注释，用于评估正确性、错误分类和身体部位及时间段的定位。沿着这个数据集，我们进行了从数据收集到处理，最后是小型基准测试的完整研究路径。我们使用该数据集评估了两种基本的动作识别算法，分别为概率方法（采用高斯混合模型GMM）和深度学习方法（采用长短期记忆网络LSTM）。\n\n这一数据集具有重要的价值，因为它在临床环境中包含了患者的康复训练动作，采用了经济、便携和方便的传感器，并且展示了在这些挑战上改进的潜力。', 'title_zh': '人体运动分析用的医学低背痛物理康复数据集'}
{'arxiv_id': 'arXiv:2309.07675', 'title': 'Goal Space Abstraction in Hierarchical Reinforcement Learning via Set-Based Reachability Analysis', 'authors': 'Mehdi Zadem, Sergio Mover, Sao Mai Nguyen', 'link': 'https://arxiv.org/abs/2309.07675', 'abstract': 'Open-ended learning benefits immensely from the use of symbolic methods for goal representation as they offer ways to structure knowledge for efficient and transferable learning. However, the existing Hierarchical Reinforcement Learning (HRL) approaches relying on symbolic reasoning are often limited as they require a manual goal representation. The challenge in autonomously discovering a symbolic goal representation is that it must preserve critical information, such as the environment dynamics. In this paper, we propose a developmental mechanism for goal discovery via an emergent representation that abstracts (i.e., groups together) sets of environment states that have similar roles in the task. We introduce a Feudal HRL algorithm that concurrently learns both the goal representation and a hierarchical policy. The algorithm uses symbolic reachability analysis for neural networks to approximate the transition relation among sets of states and to refine the goal representation. We evaluate our approach on complex navigation tasks, showing the learned representation is interpretable, transferrable and results in data efficient learning.', 'abstract_zh': '采用符号方法对目标进行表示能够极大促进开放性学习，因为这种方法能够为高效且可迁移的学习提供知识结构化的方式。然而，现有的依赖符号推理的层次强化学习（Hierarchical Reinforcement Learning, HRL）方法往往受到限制，因为它们需要手动定义目标表示。自动发现符号目标表示的挑战在于，它必须保留关键信息，如环境动力学。在本文中，我们提出了一种基于新兴表示的发展机制，该机制能够抽象（即，将具有相似作用的状态集组合在一起），用于任务中的目标发现。我们引入了一种封建HRL算法，该算法同时学习目标表示和层次策略。该算法利用符号可达性分析神经网络来近似状态集之间的转移关系，并改进目标表示。我们通过复杂导航任务评估了该方法，表明所学习的表示是可解释的、可迁移的，并且能够实现数据高效学习。', 'title_zh': '通过集基可达性分析实现层次强化学习中的目标空间抽象'}
{'arxiv_id': 'arXiv:2412.15177', 'title': 'Critical-Questions-of-Thought: Steering LLM reasoning with Argumentative Querying', 'authors': 'Federico Castagna, Isabel Sassoon, Simon Parsons', 'link': 'https://arxiv.org/abs/2412.15177', 'abstract': "Studies have underscored how, regardless of the recent breakthrough and swift advances in AI research, even state-of-the-art Large Language models (LLMs) continue to struggle when performing logical and mathematical reasoning. The results seem to suggest that LLMs still work as (highly advanced) data pattern identifiers, scoring poorly when attempting to generalise and solve reasoning problems the models have never previously seen or that are not close to samples presented in their training data. To address this compelling concern, this paper makes use of the notion of critical questions from the literature on argumentation theory, focusing in particular on Toulmin's model of argumentation. We show that employing these critical questions can improve the reasoning capabilities of LLMs. By probing the rationale behind the models' reasoning process, the LLM can assess whether some logical mistake is occurring and correct it before providing the final reply to the user prompt. The underlying idea is drawn from the gold standard of any valid argumentative procedure: the conclusion is valid if it is entailed by accepted premises. Or, to paraphrase such Aristotelian principle in a real-world approximation, characterised by incomplete information and presumptive logic, the conclusion is valid if not proved otherwise. This approach successfully steers the models' output through a reasoning pipeline, resulting in better performance against the baseline and its Chain-of-Thought (CoT) implementation. To this end, an extensive evaluation of the proposed approach on the MT-Bench Reasoning and Math tasks across a range of LLMs is provided.", 'abstract_zh': '研究表明，尽管最近在人工智能研究领域取得了突破并迅速推进，最先进的大型语言模型（LLMs）在进行逻辑和数学推理时仍然存在困难。这些结果表明，LLMs 仍然主要作为高度先进的数据模式识别器工作，当尝试推广并解决以往未见过的新推理问题或与训练数据中样本相差较大的问题时，表现不佳。为应对这一重要关切，本文借鉴了论证理论文献中的关键问题概念，尤其是焦点于费奥尔蒙（Toulmin）的论证模型。我们证明，采用这些关键问题可以提高LLMs的推理能力。通过探究模型推理过程中的理由，LLMs能够在最终回答用户提示之前评估是否存在逻辑错误并进行修正。这一设计理念来自于有效论证过程的金标准：如果结论由接受的前提所推导出来，则结论有效。或者，用一条基于不完全信息和推定逻辑的现实世界近似版本来重新阐述亚里士多德的原则，如果结论未被反驳，则结论有效。这种方法成功地引导了模型输出通过推理管道，从而在基线及其Chain-of-Thought（CoT）实施方面取得了更好的性能。为此，本文在MT-Bench的推理和数学任务上，对所提出的方法在不同LLMs中进行了广泛评估。', 'title_zh': '批判性思考问题：通过论辩性查询引导大语言模型的推理'}
{'arxiv_id': 'arXiv:2412.15135', 'title': 'Probabilistic Strategy Logic with Degrees of Observability', 'authors': 'Chunyan Mu, Nima Motamed, Natasha Alechina, Brian Logan', 'link': 'https://arxiv.org/abs/2412.15135', 'abstract': "There has been considerable work on reasoning about the strategic ability of agents under imperfect information. However, existing logics such as Probabilistic Strategy Logic are unable to express properties relating to information transparency. Information transparency concerns the extent to which agents' actions and behaviours are observable by other agents. Reasoning about information transparency is useful in many domains including security, privacy, and decision-making. In this paper, we present a formal framework for reasoning about information transparency properties in stochastic multi-agent systems. We extend Probabilistic Strategy Logic with new observability operators that capture the degree of observability of temporal properties by agents. We show that the model checking problem for the resulting logic is decidable.", 'abstract_zh': '关于不完善信息下代理的战略能力进行推理已有大量研究工作。然而，现有的逻辑，如概率策略逻辑，无法表达与信息透明度相关的属性。信息透明度指的是代理的行为和行动被其他代理观测的程度。对信息透明度的推理在安全、隐私和决策等领域都非常有用。在本文中，我们提出了一种形式化的框架，用于推理随机多代理系统中的信息透明度属性。我们扩展了概率策略逻辑，引入了新的可观测性操作符，以捕捉代理对时间属性的可观测程度。我们证明了所得到的逻辑的模型检查问题是可判定的。', 'title_zh': '具有可观测性程度的概率策略逻辑'}
{'arxiv_id': 'arXiv:2412.15114', 'title': 'Towards Friendly AI: A Comprehensive Review and New Perspectives on Human-AI Alignment', 'authors': 'Qiyang Sun, Yupei Li, Emran Alturki, Sunil Munthumoduku Krishna Murthy, Björn W. Schuller', 'link': 'https://arxiv.org/abs/2412.15114', 'abstract': 'As Artificial Intelligence (AI) continues to advance rapidly, Friendly AI (FAI) has been proposed to advocate for more equitable and fair development of AI. Despite its importance, there is a lack of comprehensive reviews examining FAI from an ethical perspective, as well as limited discussion on its potential applications and future directions. This paper addresses these gaps by providing a thorough review of FAI, focusing on theoretical perspectives both for and against its development, and presenting a formal definition in a clear and accessible format. Key applications are discussed from the perspectives of eXplainable AI (XAI), privacy, fairness and affective computing (AC). Additionally, the paper identifies challenges in current technological advancements and explores future research avenues. The findings emphasise the significance of developing FAI and advocate for its continued advancement to ensure ethical and beneficial AI development.', 'abstract_zh': '随着人工智能（AI）的快速发展，友好人工智能（Friendly AI，FAI）的概念已被提出，旨在推动更加公平和公正的AI发展。尽管FAI的重要性不言而喻，但迄今为止，从伦理角度进行全面综述的研究尚缺乏，对FAI潜在应用及其未来发展方向的讨论也较为有限。本文旨在填补这些空白，通过对FAI进行全面综述，重点关注其发展中的理论视角，并提供清晰简洁的形式化定义。此外，从可解释人工智能（XAI）、隐私、公平性和情感计算（AC）的视角讨论了主要的应用领域。本文还指出了当前技术进步中的挑战，并探讨了未来的研究方向。研究结果强调了开发友好人工智能的重要性，并倡导继续推进FAI的研究，以确保伦理和有益的人工智能发展。', 'title_zh': '走向友好的人工智能：人类-人工智能对齐的综合review与新视角'}
{'arxiv_id': 'arXiv:2412.14950', 'title': 'Generalizing Constraint Models in Constraint Acquisition', 'authors': 'Dimos Tsouros, Senne Berden, Steven Prestwich, Tias Guns', 'link': 'https://arxiv.org/abs/2412.14950', 'abstract': 'Constraint Acquisition (CA) aims to widen the use of constraint programming by assisting users in the modeling process. However, most CA methods suffer from a significant drawback: they learn a single set of individual constraints for a specific problem instance, but cannot generalize these constraints to the parameterized constraint specifications of the problem. In this paper, we address this limitation by proposing GenCon, a novel approach to learn parameterized constraint models capable of modeling varying instances of the same problem. To achieve this generalization, we make use of statistical learning techniques at the level of individual constraints. Specifically, we propose to train a classifier to predict, for any possible constraint and parameterization, whether the constraint belongs to the problem. We then show how, for some classes of classifiers, we can extract decision rules to construct interpretable constraint specifications. This enables the generation of ground constraints for any parameter instantiation. Additionally, we present a generate-and-test approach that can be used with any classifier, to generate the ground constraints on the fly. Our empirical results demonstrate that our approach achieves high accuracy and is robust to noise in the input instances.', 'abstract_zh': '约束获取（CA）旨在通过辅助用户建模过程来扩大约束编程的应用范围。然而，大多数CA方法存在一个显著的局限性：它们只为特定问题实例学习一组单独的约束条件，而无法将这些约束条件推广到问题的参数化约束规范中。在本文中，我们通过提出GenCon这一新颖的方法来解决这一局限性，旨在学习可用于描述同一问题不同实例的参数化约束模型。为了实现这一泛化，我们在单个约束层面采用统计学习技术。具体而言，我们建议训练一个分类器，以预测任何可能的约束和参数化情况是否属于该问题。然后，我们展示了如何从中提取决策规则以构建可解释的约束规范，从而能够为任何参数实例生成基础约束。此外，我们提出了一种生成-测试方法，可以与任何分类器结合使用，实时生成基础约束。我们的实验证明，该方法可以实现高精度，并且在输入实例存在噪声的情况下依然表现出良好的鲁棒性。', 'title_zh': '在约束获取中推广约束模型'}
{'arxiv_id': 'arXiv:2412.14814', 'title': 'Answer Set Networks: Casting Answer Set Programming into Deep Learning', 'authors': 'Arseny Skryagin, Daniel Ochs, Phillip Deibert, Simon Kohaut, Devendra Singh Dhami, Kristian Kersting', 'link': 'https://arxiv.org/abs/2412.14814', 'abstract': 'Although Answer Set Programming (ASP) allows constraining neural-symbolic (NeSy) systems, its employment is hindered by the prohibitive costs of computing stable models and the CPU-bound nature of state-of-the-art solvers. To this end, we propose Answer Set Networks (ASN), a NeSy solver. Based on Graph Neural Networks (GNN), ASNs are a scalable approach to ASP-based Deep Probabilistic Logic Programming (DPPL). Specifically, we show how to translate ASPs into ASNs and demonstrate how ASNs can efficiently solve the encoded problem by leveraging GPU\'s batching and parallelization capabilities. Our experimental evaluations demonstrate that ASNs outperform state-of-the-art CPU-bound NeSy systems on multiple tasks. Simultaneously, we make the following two contributions based on the strengths of ASNs. Namely, we are the first to show the finetuning of Large Language Models (LLM) with DPPLs, employing ASNs to guide the training with logic. Further, we show the "constitutional navigation" of drones, i.e., encoding public aviation laws in an ASN for routing Unmanned Aerial Vehicles in uncertain environments.', 'abstract_zh': '尽管Answer Set Programming (ASP) 允许约束神经符号（NeSy）系统，但其应用受限于计算稳定模型的高昂成本以及最先进的求解器因CPU密集型而带来的挑战。为解决这些问题，我们提出了Answer Set Networks（ASN），这是一种NeSy求解器，基于图神经网络（GNN），ASN是一种基于ASP的深度概率逻辑编程（DPPL）的可扩展方法。具体来说，我们展示了如何将ASP转换为ASN，并展示了如何通过利用GPU的批量处理和并行化能力，ASN能够高效地求解编码的问题。我们的实验评估表明，ASN在多项任务中优于现有的CPU密集型NeSy系统。同时，基于ASN的优势，我们做出了以下两项贡献：\n\n1. 我们首次展示了使用深度概率逻辑编程（DPPL）微调大型语言模型（LLM），利用ASN进行逻辑指导的训练。\n2. 我们展示了无人机的“宪法导航”，即在ASN中编码公共航空法规，并将其应用于在不确定环境中引导无人驾驶航空器（UAV）。', 'title_zh': '答案集网络：将回答集编程融入深度学习'}
{'arxiv_id': 'arXiv:2412.14728', 'title': 'LTLf Synthesis Under Unreliable Input', 'authors': 'Christian Hagemeier, Giuseppe de Giacomo, Moshe Y. Vardi', 'link': 'https://arxiv.org/abs/2412.14728', 'abstract': 'We study the problem of realizing strategies for an LTLf goal specification while ensuring that at least an LTLf backup specification is satisfied in case of unreliability of certain input variables. We formally define the problem and characterize its worst-case complexity as 2EXPTIME-complete, like standard LTLf synthesis. Then we devise three different solution techniques: one based on direct automata manipulation, which is 2EXPTIME, one disregarding unreliable input variables by adopting a belief construction, which is 3EXPTIME, and one leveraging second-order quantified LTLf (QLTLf), which is 2EXPTIME and allows for a direct encoding into monadic second-order logic, which in turn is worst-case nonelementary. We prove their correctness and evaluate them against each other empirically. Interestingly, theoretical worst-case bounds do not translate into observed performance; the MSO technique performs best, followed by belief construction and direct automata manipulation. As a byproduct of our study, we provide a general synthesis procedure for arbitrary QLTLf specifications.', 'abstract_zh': '我们研究如何在某些输入变量不可靠的情况下，实现一个LTLf目标规范的策略，同时确保至少满足一个LTLf备份规范。我们正式定义了该问题，并将其最坏情况复杂性characterize为2EXPTIME完全，类似于标准的LTLf综合。然后我们提出了三种不同的解决方案：一种基于直接的自动机操作的方法，复杂性为2EXPTIME；一种通过信念构建忽略不可靠的输入变量的方法，复杂性为3EXPTIME；以及一种利用二阶量化LTLf（QLTLf）的方法，复杂性为2EXPTIME，并且可以将其直接编码为单调二阶逻辑中，后者在最坏情况下的复杂性是非元素的。我们证明了这些方法的正确性，并进行了实验性评估。有趣的是，理论上的最坏情况界限并不转化为实际性能；单调二阶逻辑方法表现最好，其次是信念构建方法和直接自动机操作方法。在研究过程中，我们提供了一种通用的合成程序用于任意的QLTLf规范。', 'title_zh': '在不可靠输入下的LTLf合成'}
{'arxiv_id': 'arXiv:2412.14708', 'title': 'Creation of AI-driven Smart Spaces for Enhanced Indoor Environments -- A Survey', 'authors': 'Aygün Varol, Naser Hossein Motlagh, Mirka Leino, Sasu Tarkoma, Johanna Virkki', 'link': 'https://arxiv.org/abs/2412.14708', 'abstract': 'Smart spaces are ubiquitous computing environments that integrate diverse sensing and communication technologies to enhance space functionality, optimize energy utilization, and improve user comfort and well-being. The integration of emerging AI methodologies into these environments facilitates the formation of AI-driven smart spaces, which further enhance functionalities of the spaces by enabling advanced applications such as personalized comfort settings, interactive living spaces, and automatization of the space systems, all resulting in enhanced indoor experiences of the users. In this paper, we present a systematic survey of existing research on the foundational components of AI-driven smart spaces, including sensor technologies, data communication protocols, sensor network management and maintenance strategies, as well as the data collection, processing and analytics. Given the pivotal role of AI in establishing AI-powered smart spaces, we explore the opportunities and challenges associated with traditional machine learning (ML) approaches, such as deep learning (DL), and emerging methodologies including large language models (LLMs). Finally, we provide key insights necessary for the development of AI-driven smart spaces, propose future research directions, and sheds light on the path forward.', 'abstract_zh': '智能空间是集成了多种感知和通信技术的泛在计算环境，旨在增强空间功能、优化能源利用并改善用户舒适度和幸福感。将新兴的人工智能方法融入这些环境有助于形成由人工智能驱动的智能空间，进一步通过提供个性化舒适设置、互动生活空间以及空间系统的自动化等功能，提升室内体验。在本文中，我们系统地回顾了人工智能驱动智能空间的基础组件研究，包括传感器技术、数据通信协议、传感器网络管理和维护策略，以及数据的收集、处理和分析。鉴于人工智能在建立人工智能赋能智能空间中的关键作用，我们探讨了传统机器学习（ML）方法，如深度学习（DL），以及新兴的方法论，包括大型语言模型（LLMs）相关的机遇和挑战。最后，我们提供了开发人工智能驱动智能空间的关键见解，提出未来的研究方向，并指明了前进的道路。', 'title_zh': '基于人工智能驱动的智能空间创建以提升室内环境——一项综述'}
{'arxiv_id': 'arXiv:2412.14684', 'title': 'Bel Esprit: Multi-Agent Framework for Building AI Model Pipelines', 'authors': 'Yunsu Kim, AhmedElmogtaba Abdelaziz, Thiago Castro Ferreira, Mohamed Al-Badrashiny, Hassan Sawaf', 'link': 'https://arxiv.org/abs/2412.14684', 'abstract': 'As the demand for artificial intelligence (AI) grows to address complex real-world tasks, single models are often insufficient, requiring the integration of multiple models into pipelines. This paper introduces Bel Esprit, a conversational agent designed to construct AI model pipelines based on user-defined requirements. Bel Esprit employs a multi-agent framework where subagents collaborate to clarify requirements, build, validate, and populate pipelines with appropriate models. We demonstrate the effectiveness of this framework in generating pipelines from ambiguous user queries, using both human-curated and synthetic data. A detailed error analysis highlights ongoing challenges in pipeline construction. Bel Esprit is available for a free trial at this https URL.', 'abstract_zh': '随着人工智能（AI）在解决复杂现实世界任务方面的需求增长，单一模型往往不够用，需要将多个模型集成到工作流中。本文介绍了Bel Esprit，这是一个基于用户定义需求构建人工智能模型工作流的对话代理。Bel Esprit采用多代理框架，其中子代理协作以澄清需求、构建、验证并填充合适模型的工作流。我们通过使用人工策划和合成数据展示了这一框架在生成来自模糊用户查询的工作流方面的有效性。详细的错误分析突显了在工作流构建过程中仍存在的挑战。Bel Esprit可以在以下链接免费试用：此https URL。', 'title_zh': 'Bel Esprit：多agent框架构建AI模型流水线'}
{'arxiv_id': 'arXiv:2412.14515', 'title': 'Relational Programming with Foundation Models', 'authors': 'Ziyang Li, Jiani Huang, Jason Liu, Felix Zhu, Eric Zhao, William Dodds, Neelay Velingker, Rajeev Alur, Mayur Naik', 'link': 'https://arxiv.org/abs/2412.14515', 'abstract': 'Foundation models have vast potential to enable diverse AI applications. The powerful yet incomplete nature of these models has spurred a wide range of mechanisms to augment them with capabilities such as in-context learning, information retrieval, and code interpreting. We propose Vieira, a declarative framework that unifies these mechanisms in a general solution for programming with foundation models. Vieira follows a probabilistic relational paradigm and treats foundation models as stateless functions with relational inputs and outputs. It supports neuro-symbolic applications by enabling the seamless combination of such models with logic programs, as well as complex, multi-modal applications by streamlining the composition of diverse sub-models. We implement Vieira by extending the Scallop compiler with a foreign interface that supports foundation models as plugins. We implement plugins for 12 foundation models including GPT, CLIP, and SAM. We evaluate Vieira on 9 challenging tasks that span language, vision, and structured and vector databases. Our evaluation shows that programs in Vieira are concise, can incorporate modern foundation models, and have comparable or better accuracy than competitive baselines.', 'abstract_zh': '基础模型具有广泛潜力，能够促进多种AI应用的发展。这些模型虽然强大但不完善，由此激发了各种机制来增强其能力，如上下文学习、信息检索和代码解释。我们提出了一种名为Vieira的声明性框架，旨在以通用解决方案的形式将这些机制统一起来，用于编程基础模型。Vieira遵循概率关系范式，将基础模型视为无状态函数，输入和输出具有关系性。该框架支持神经符号应用，通过无缝结合基础模型与逻辑程序来实现，同时也通过简化不同子模型的组合来支持复杂的多模态应用。\n\n我们通过在Scallop编译器中扩展外联接口来实现Vieira，支持基础模型作为插件使用。我们为包括GPT、CLIP和SAM在内的12种基础模型实现插件。我们利用Vieira在涵盖语言、视觉以及结构化和向量数据库的9个挑战性任务中进行了评估。评估结果显示，Vieira中的程序简洁、能够整合现代基础模型，并在与竞争性基线相当或更优的准确度方面表现出色。', 'title_zh': '基于基础模型的关联编程'}
{'arxiv_id': 'arXiv:2412.14500', 'title': 'The Digital Ecosystem of Beliefs: does evolution favour AI over humans?', 'authors': 'David M. Bossens, Shanshan Feng, Yew-Soon Ong', 'link': 'https://arxiv.org/abs/2412.14500', 'abstract': "As AI systems are integrated into social networks, there are AI safety concerns that AI-generated content may dominate the web, e.g. in popularity or impact on this http URL understand such questions, this paper proposes the Digital Ecosystem of Beliefs (Digico), the first evolutionary framework for controlled experimentation with multi-population interactions in simulated social networks. The framework models a population of agents which change their messaging strategies due to evolutionary updates following a Universal Darwinism approach, interact via messages, influence each other's beliefs through dynamics based on a contagion model, and maintain their beliefs through cognitive Lamarckian inheritance. Initial experiments with an abstract implementation of Digico show that: a) when AIs have faster messaging, evolution, and more influence in the recommendation algorithm, they get 80% to 95% of the views, depending on the size of the influence benefit; b) AIs designed for propaganda can typically convince 50% of humans to adopt extreme beliefs, and up to 85% when agents believe only a limited number of channels; c) a penalty for content that violates agents' beliefs reduces propaganda effectiveness by up to 8%. We further discuss implications for control (e.g. legislation) and Digico as a means of studying evolutionary principles.", 'abstract_zh': '随着人工智能系统融入社会网络，AI安全问题开始凸显，如AI生成的内容可能主导互联网，在流行度或影响方面占据主导地位（例如在相关链接中）。为了理解这些问题，本文提出了数字信念生态系统（Digico），这是首个用于模拟社会网络中多群体交互的受控实验的进化框架。该框架通过通用达尔文主义方法进行进化更新，模拟一群由于信息策略变化的智能体，通过消息进行交互，通过基于传染病模型的动力学影响彼此的信念，并通过认知拉马克式遗传保持信念。初步实验结果表明：a) 当AI在消息传递、进化速度以及建议算法中的影响力加快时，它们可以获得80%到95%的浏览量，具体取决于影响力收益的大小；b) 设计用于宣传的AI通常能够说服50%的人类接受极端信念，当智能体仅相信有限数量的渠道时，这一比例可达到85%；c) 对违背智能体信念的内容进行处罚可以将宣传效果降低8%。此外，本文还讨论了该框架在控制措施（例如立法）方面的应用及其作为研究进化原则工具的意义。', 'title_zh': '信念数字化生态系统：进化是倾向于AI还是人类？'}
{'arxiv_id': 'arXiv:2412.14492', 'title': 'FaultExplainer: Leveraging Large Language Models for Interpretable Fault Detection and Diagnosis', 'authors': 'Abdullah Khan, Rahul Nahar, Hao Chen, Gonzalo E. Constante Flores, Can Li', 'link': 'https://arxiv.org/abs/2412.14492', 'abstract': "Machine learning algorithms are increasingly being applied to fault detection and diagnosis (FDD) in chemical processes. However, existing data-driven FDD platforms often lack interpretability for process operators and struggle to identify root causes of previously unseen faults. This paper presents FaultExplainer, an interactive tool designed to improve fault detection, diagnosis, and explanation in the Tennessee Eastman Process (TEP). FaultExplainer integrates real-time sensor data visualization, Principal Component Analysis (PCA)-based fault detection, and identification of top contributing variables within an interactive user interface powered by large language models (LLMs). We evaluate the LLMs' reasoning capabilities in two scenarios: one where historical root causes are provided, and one where they are not to mimic the challenge of previously unseen faults. Experimental results using GPT-4o and o1-preview models demonstrate the system's strengths in generating plausible and actionable explanations, while also highlighting its limitations, including reliance on PCA-selected features and occasional hallucinations.", 'abstract_zh': '机器学习算法在化工过程中故障检测与诊断（FDD）中的应用日益增多。然而，现有的数据驱动的FDD平台往往缺乏过程操作员的可解释性，并且难以识别之前未见过的故障的根本原因。本文介绍了故障解释器（FaultExplainer），这是一种旨在提高田纳西东部过程（TEP）故障检测、诊断和解释的交互式工具。故障解释器结合了实时传感器数据可视化、基于主成分分析（PCA）的故障检测以及通过大型语言模型（LLMs）实现的交互式用户界面中关键变量的识别。我们评估了LLMs在两种场景下的推理能力：一种是有历史根本原因提供的情况下，另一种是没有任何历史根本原因的情况下，以模拟之前未见过的故障的挑战。使用GPT-4o和o1-preview模型的实验结果表明，该系统在生成合理且可行的解释方面具有优势，同时也指出了其局限性，包括对PCA选择特征的依赖以及偶尔的幻觉现象。', 'title_zh': '故障解释器：利用大型语言模型进行可解释的故障检测与诊断'}
{'arxiv_id': 'arXiv:2412.14491', 'title': 'Mediation Analysis for Probabilities of Causation', 'authors': 'Yuta Kawakami, Jin Tian', 'link': 'https://arxiv.org/abs/2412.14491', 'abstract': 'Probabilities of causation (PoC) offer valuable insights for informed decision-making. This paper introduces novel variants of PoC-controlled direct, natural direct, and natural indirect probability of necessity and sufficiency (PNS). These metrics quantify the necessity and sufficiency of a treatment for producing an outcome, accounting for different causal pathways. We develop identification theorems for these new PoC measures, allowing for their estimation from observational data. We demonstrate the practical application of our results through an analysis of a real-world psychology dataset.', 'abstract_zh': '概率归因（PoC）为知情决策提供了宝贵的见解。本文介绍了控制概率归因（PoC）的新变体，包括直接概率归因、自然直接概率归因和自然间接必要性和充分性概率（PNS）。这些指标量化了治疗对于产生结果的必要性和充分性，同时考虑了不同的因果路径。我们开发了这些新PoC度量的识别定理，使其可以从观测数据中进行估计。通过分析一个实际的心理学数据集，我们展示了结果的实际应用。', 'title_zh': '概率因果性的中介效应分析'}
{'arxiv_id': 'arXiv:2412.14485', 'title': 'Towards Projected and Incremental Pseudo-Boolean Model Counting', 'authors': 'Suwei Yang, Kuldeep S. Meel', 'link': 'https://arxiv.org/abs/2412.14485', 'abstract': 'Model counting is a fundamental task that involves determining the number of satisfying assignments to a logical formula, typically in conjunctive normal form (CNF). While CNF model counting has received extensive attention over recent decades, interest in Pseudo-Boolean (PB) model counting is just emerging partly due to the greater flexibility of PB formulas. As such, we observed feature gaps in existing PB counters such as a lack of support for projected and incremental settings, which could hinder adoption.\nIn this work, our main contribution is the introduction of the PB model counter PBCount2, the first exact PB model counter with support for projected and incremental model counting. Our counter, PBCount2, uses our Least Occurrence Weighted Min Degree (LOW-MD) computation ordering heuristic to support projected model counting and a cache mechanism to enable incremental model counting. In our evaluations, PBCount2 completed at least 1.40x the number of benchmarks of competing methods for projected model counting and at least 1.18x of competing methods in incremental model counting.', 'abstract_zh': '模型计数是计算逻辑公式（通常为合取范式CNF）满足赋值数量的基本任务。尽管CNF模型计数在近几十年内受到了广泛的关注，但Pseudo-Boolean（PB）模型计数由于PB公式的更大灵活性，其研究兴趣才刚刚开始。因此，我们观察到现有的PB计数器存在特征差距，例如缺乏对投影和增量设置的支持，这可能会影响其应用。\n\n在这项工作中，我们的主要贡献是引入了PB计数器PBCount2，这是第一个支持投影和增量模型计数的确切PB计数器。我们的计数器PBCount2使用了我们的Least Occurrence Weighted Min Degree（LOW-MD）计算排序启发式，以支持投影模型计数，并使用缓存机制来实现增量模型计数。在我们的评估中，PBCount2在投影模型计数方面完成了至少1.40倍的基准测试数量，而在增量模型计数方面则完成了至少1.18倍的基准测试数量。', 'title_zh': '面向投影和增量伪布尔模型计数'}
{'arxiv_id': 'arXiv:2412.14409', 'title': 'Multi-task Representation Learning for Mixed Integer Linear Programming', 'authors': 'Junyang Cai, Taoan Huang, Bistra Dilkina', 'link': 'https://arxiv.org/abs/2412.14409', 'abstract': 'Mixed Integer Linear Programs (MILPs) are highly flexible and powerful tools for modeling and solving complex real-world combinatorial optimization problems. Recently, machine learning (ML)-guided approaches have demonstrated significant potential in improving MILP-solving efficiency. However, these methods typically rely on separate offline data collection and training processes, which limits their scalability and adaptability. This paper introduces the first multi-task learning framework for ML-guided MILP solving. The proposed framework provides MILP embeddings helpful in guiding MILP solving across solvers (e.g., Gurobi and SCIP) and across tasks (e.g., Branching and Solver configuration). Through extensive experiments on three widely used MILP benchmarks, we demonstrate that our multi-task learning model performs similarly to specialized models within the same distribution. Moreover, it significantly outperforms them in generalization across problem sizes and tasks.', 'abstract_zh': '混合整数线性规划（MILPs）是建模和解决复杂现实世界组合优化问题的强大且灵活的工具。近年来，基于机器学习（ML）的引导方法显示出在提高MILP求解效率方面的显著潜力。然而，这些方法通常依赖于分开的离线数据收集和训练过程，这限制了它们的可扩展性和适应性。本文介绍了第一个用于ML引导MILP求解的多任务学习框架。所提出的框架提供了有助于在不同求解器（例如，Gurobi和SCIP）和不同任务（例如，分枝和求解器配置）引导MILP求解的MILP嵌入。通过在三个广泛使用的MILP基准上的大量实验，我们证明了我们的多任务学习模型在分布内与专门模型的表现相似。此外，它在问题规模和任务的泛化方面显著优于它们。', 'title_zh': '混合整数线性规划的多任务表示学习'}
{'arxiv_id': 'arXiv:2412.14387', 'title': 'Clinical Trials Ontology Engineering with Large Language Models', 'authors': 'Berkan Çakır', 'link': 'https://arxiv.org/abs/2412.14387', 'abstract': 'Managing clinical trial information is currently a significant challenge for the medical industry, as traditional methods are both time-consuming and costly. This paper proposes a simple yet effective methodology to extract and integrate clinical trial data in a cost-effective and time-efficient manner. Allowing the medical industry to stay up-to-date with medical developments. Comparing time, cost, and quality of the ontologies created by humans, GPT3.5, GPT4, and Llama3 (8b & 70b). Findings suggest that large language models (LLM) are a viable option to automate this process both from a cost and time perspective. This study underscores significant implications for medical research where real-time data integration from clinical trials could become the norm.', 'abstract_zh': '目前，管理临床试验信息是医疗行业面临的显著挑战，传统方法既耗时又昂贵。本文提出了一种简单而有效的方法，以成本效益高和时间效率高的方式提取和整合临床试验数据，帮助医疗行业及时掌握医学发展动态。将由人类创建、GPT3.5、GPT4和Llama3（8b及70b）生成的本体的时间、成本和质量进行比较。研究表明，大型语言模型（LLM）在成本和时间方面都是自动化此过程的一个可行选项。本研究强调了医学研究领域的重要意义，即从临床试验中实时集成数据可能成为常态。', 'title_zh': '使用大型语言模型进行临床试验本体工程'}
{'arxiv_id': 'arXiv:2412.14382', 'title': 'Balans: Multi-Armed Bandits-based Adaptive Large Neighborhood Search for Mixed-Integer Programming Problem', 'authors': 'Junyang Cai, Serdar Kadioglu, Bistra Dilkina', 'link': 'https://arxiv.org/abs/2412.14382', 'abstract': 'Mixed-Integer Programming (MIP) is a powerful paradigm for modeling and solving various important combinatorial optimization problems. Recently, learning-based approaches have shown potential to speed up MIP solving via offline training that then guides important design decisions during search. However, a significant drawback of these methods is their heavy reliance on offline training, which requires collecting training datasets and computationally costly training epochs yet offering only limited generalization to unseen (larger) instances. In this paper, we propose Balans, an adaptive meta-solver for MIPs with online learning capability that does not require any supervision or apriori training. At its core, Balans is based on adaptive large-neighborhood search, operating on top of a MIP solver by successive applications of destroy and repair neighborhood operators. During the search, the selection among different neighborhood definitions is guided on the fly for the instance at hand via multi-armed bandit algorithms. Our extensive experiments on hard optimization instances show that Balans offers significant performance gains over the default MIP solver, is better than committing to any single best neighborhood, and improves over the state-of-the-art large-neighborhood search for MIPs. Finally, we release Balans as a highly configurable, MIP solver agnostic, open-source software.', 'abstract_zh': '混合整数规划（MIP）是一种强大的建模和解决各类重要组合优化问题的范式。近年来，基于学习的方法显示出通过离线训练来加速MIP求解的潜力，离线训练随后在搜索过程中指导关键设计决策。然而，这些方法的一个显著缺点是它们严重依赖于离线训练，需要收集训练数据集并进行计算成本高昂的训练周期，但提供的泛化能力仅限于未见过（更大规模的）实例。在本文中，我们提出Balans，这是一种具有在线学习能力的自适应元求解器，无需任何监督或预先训练。核心上，Balans 基于自适应的大邻域搜索，以迭代应用破坏和修复邻域操作符的形式，构建在MIP求解器之上。在搜索过程中，针对当前实例的不同邻域定义选择由多臂 bandit 算法实时指导。我们在多个困难优化实例上的广泛实验表明，Balans 相对于默认MIP求解器提供了显著的性能增益，优于仅依赖最优邻域策略，同时还优于当前最先进的MIP大邻域搜索方法。最后，我们以高度可配置并且与MIP求解器无关的形式发布了Balans，作为开源软件。', 'title_zh': 'Balans：基于多臂bandits的自适应大规模邻域搜索方法用于解决混合整数规划问题'}
{'arxiv_id': 'arXiv:2412.14372', 'title': 'Python Agent in Ludii', 'authors': 'Izaias S. de Lima Neto, Marco A. A. de Aguiar Vieira, Anderson R. Tavares', 'link': 'https://arxiv.org/abs/2412.14372', 'abstract': 'Ludii is a Java general game system with a considerable number of board games, with an API for developing new agents and a game description language to create new games. To improve versatility and ease development, we provide Python interfaces for agent programming. This allows the use of Python modules to implement general game playing agents.\nAs a means of enabling Python for creating Ludii agents, the interfaces are implemented using different Java libraries: jpy and Py4J. The main goal of this work is to determine which version is faster. To do so, we conducted a performance analysis of two different GGP algorithms, Minimax adapted to GGP and MCTS. The analysis was performed across several combinatorial games with varying depth, branching factor, and ply time. For reproducibility, we provide tutorials and repositories.\nOur analysis includes predictive models using regression, which suggest that jpy is faster than Py4J, however slower than a native Java Ludii agent, as expected.', 'abstract_zh': 'Ludii是一个用Java编写的通用游戏系统，包含大量棋盘游戏，并提供用于开发新代理的API和游戏描述语言，以便创建新游戏。为了提高灵活性和开发便捷性，我们为代理编程提供了Python接口。这使得可以使用Python模块来实现通用游戏代理。\n\n为实现使用Python创建Ludii代理，接口是通过不同的Java库（jpy和Py4J）实现的。本工作的主要目标是确定哪种版本更快。为此，我们对两种不同的广义游戏协议（GGP）算法——适应了GGP的Minimax算法和Monte Carlo树搜索（MCTS）——进行了性能分析。分析涵盖了多种组合游戏，这些游戏在深度、分支因子和每步时间上有所不同。为了保证可重复性，我们提供了教程和代码仓库。\n\n我们的分析包括使用回归构建的预测模型，这些模型表明jpy比Py4J更快，但比原生的Java Ludii代理慢，这是预料之中的。', 'title_zh': 'Python 代理在 Ludii 中的应用'}
{'arxiv_id': 'arXiv:2412.15212', 'title': 'Scaling 4D Representations', 'authors': 'João Carreira, Dilara Gokay, Michael King, Chuhan Zhang, Ignacio Rocco, Aravindh Mahendran, Thomas Albert Keck, Joseph Heyward, Skanda Koppula, Etienne Pot, Goker Erdogan, Yana Hasson, Yi Yang, Klaus Greff, Guillaume Le Moing, Sjoerd van Steenkiste, Daniel Zoran, Drew A. Hudson, Pedro Vélez, Luisa Polanía, Luke Friedman, Chris Duvarney, Ross Goroshin, Kelsey Allen, Jacob Walker, Rishabh Kabra, Eric Aboussouan, Jennifer Sun, Thomas Kipf, Carl Doersch, Viorica Pătrăucean, Dima Damen, Pauline Luc, Mehdi S. M. Sajjadi, Andrew Zisserman', 'link': 'https://arxiv.org/abs/2412.15212', 'abstract': 'Scaling has not yet been convincingly demonstrated for pure self-supervised learning from video. However, prior work has focused evaluations on semantic-related tasks $\\unicode{x2013}$ action classification, ImageNet classification, etc. In this paper we focus on evaluating self-supervised learning on non-semantic vision tasks that are more spatial (3D) and temporal (+1D = 4D), such as camera pose estimation, point and object tracking, and depth estimation. We show that by learning from very large video datasets, masked auto-encoding (MAE) with transformer video models actually scales, consistently improving performance on these 4D tasks, as model size increases from 20M all the way to the largest by far reported self-supervised video model $\\unicode{x2013}$ 22B parameters. Rigorous apples-to-apples comparison with many recent image and video models demonstrates the benefits of scaling 4D representations.', 'abstract_zh': '纯自监督学习从视频中尚未被有力地证明具有可扩展性。然而，先前的工作主要集中在语义相关任务上的评估，如动作分类和ImageNet分类等。在本文中，我们关注于评估自监督学习在非语义视觉任务上的表现，这些任务更具空间性（3D）和时间性（+1D = 4D），如相机姿态估计、点和物体跟踪以及深度估计。我们展示通过从非常大的视频数据集中学习，掩码自编码器（MAE）与Transformer视频模型实际上是可以扩展的，随着模型规模从20M增加到目前报道的最大自监督视频模型（22B参数），这些4D任务的性能得到了一致的提升。与许多近期的图像和视频模型进行严格的直接比较，证明了扩展4D表示的好处。', 'title_zh': '4D表示的扩展'}
{'arxiv_id': 'arXiv:2412.15209', 'title': 'PRIMA: Multi-Image Vision-Language Models for Reasoning Segmentation', 'authors': 'Muntasir Wahed, Kiet A. Nguyen, Adheesh Sunil Juvekar, Xinzhuo Li, Xiaona Zhou, Vedant Shah, Tianjiao Yu, Pinar Yanardag, Ismini Lourentzou', 'link': 'https://arxiv.org/abs/2412.15209', 'abstract': 'Despite significant advancements in Large Vision-Language Models (LVLMs), existing pixel-grounding models operate on single-image settings, limiting their ability to perform detailed, fine-grained comparisons across multiple images. Conversely, current multi-image understanding models lack pixel-level grounding. Our work addresses this gap by introducing the task of multi-image pixel-grounded reasoning segmentation, and PRIMA, a novel LVLM that integrates pixel-level grounding with robust multi-image reasoning capabilities to produce contextually rich, pixel-grounded explanations. Central to PRIMA is an efficient vision module that queries fine-grained visual representations across multiple images, reducing TFLOPs by $25.3\\%$. To support training and evaluation, we curate $M^4Seg$, a new reasoning segmentation benchmark consisting of $\\sim$224K question-answer pairs that require fine-grained visual understanding across multiple images. Experimental results demonstrate PRIMA outperforms state-of-the-art baselines.', 'abstract_zh': '尽管在大型视觉-语言模型（LVLMs）方面取得了显著进展，现有的像素定位模型仅在单图像设置中运行，限制了它们在跨多图像进行详细、精细比较的能力。相反，当前的多图像理解模型缺乏像素级的定位能力。我们通过引入多图像像素定位推理分割任务来填补这一空白，并提出了PRIMA，这是一种新颖的LVLM，它结合了像素级定位与稳健的多图像推理能力，以生成丰富上下文、像素定位的解释。PRIMA的核心是一个高效的感觉模块，该模块能够在多个图像中查询精细的视觉表示，相比以往方法减少了25.3%的TFLOPs。为支持训练和评估，我们构建了M^4Seg，这是一个新的推理分割基准，包含约22.4万组问题-答案对，需要跨多图像进行精细的视觉理解。实验结果表明，PRIMA在基准测试中优于现有最先进的基线。', 'title_zh': 'PRIMA：多图像视觉语言模型的推理分割'}
{'arxiv_id': 'arXiv:2412.15204', 'title': 'LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks', 'authors': 'Yushi Bai, Shangqing Tu, Jiajie Zhang, Hao Peng, Xiaozhi Wang, Xin Lv, Shulin Cao, Jiazheng Xu, Lei Hou, Yuxiao Dong, Jie Tang, Juanzi Li', 'link': 'https://arxiv.org/abs/2412.15204', 'abstract': 'This paper introduces LongBench v2, a benchmark designed to assess the ability of LLMs to handle long-context problems requiring deep understanding and reasoning across real-world multitasks. LongBench v2 consists of 503 challenging multiple-choice questions, with contexts ranging from 8k to 2M words, across six major task categories: single-document QA, multi-document QA, long in-context learning, long-dialogue history understanding, code repository understanding, and long structured data understanding. To ensure the breadth and the practicality, we collect data from nearly 100 highly educated individuals with diverse professional backgrounds. We employ both automated and manual review processes to maintain high quality and difficulty, resulting in human experts achieving only 53.7% accuracy under a 15-minute time constraint. Our evaluation reveals that the best-performing model, when directly answers the questions, achieves only 50.1% accuracy. In contrast, the o1-preview model, which includes longer reasoning, achieves 57.7%, surpassing the human baseline by 4%. These results highlight the importance of enhanced reasoning ability and scaling inference-time compute to tackle the long-context challenges in LongBench v2. The project is available at this https URL.', 'abstract_zh': '本文介绍了LongBench v2，这是一个用于评估大规模语言模型（LLM）处理需要深层次理解和推理的长句子问题能力的基准测试。LongBench v2 包含了 503 个具有挑战性的选择题，上下文长度从 8000 字到 200 万字不等，涵盖了六个主要任务类别：单文档问答、多文档问答、长上下文学习、长对话历史理解、代码仓库理解以及长结构化数据理解。为了确保涵盖广泛的应用场景和实用性，我们从来自广泛专业背景的近 100 名受过高等教育的个人收集数据。通过结合自动和人工审核过程，保持了高质量和高难度，最终在 15 分钟的时间限制下，专业人类专家的准确率为 53.7%。我们的评估结果显示，在直接回答问题的最佳模型的准确率为 50.1%。相比之下，一个包括更长推理的 o1-preview 模型的准确率为 57.7%，这超过了人类基准线 4%。这些结果强调了提高推理能力并扩展推理时间计算能力的重要性，以便解决 LongBench v2 中的长句子挑战。该项目的相关信息可参见以下链接：[请在这里插入链接]。', 'title_zh': '长任务基准 v2：更深入地理解和支持现实场景中长上下文多任务处理'}
{'arxiv_id': 'arXiv:2412.15200', 'title': 'DI-PCG: Diffusion-based Efficient Inverse Procedural Content Generation for High-quality 3D Asset Creation', 'authors': 'Wang Zhao, Yan-Pei Cao, Jiale Xu, Yuejiang Dong, Ying Shan', 'link': 'https://arxiv.org/abs/2412.15200', 'abstract': 'Procedural Content Generation (PCG) is powerful in creating high-quality 3D contents, yet controlling it to produce desired shapes is difficult and often requires extensive parameter tuning. Inverse Procedural Content Generation aims to automatically find the best parameters under the input condition. However, existing sampling-based and neural network-based methods still suffer from numerous sample iterations or limited controllability. In this work, we present DI-PCG, a novel and efficient method for Inverse PCG from general image conditions. At its core is a lightweight diffusion transformer model, where PCG parameters are directly treated as the denoising target and the observed images as conditions to control parameter generation. DI-PCG is efficient and effective. With only 7.6M network parameters and 30 GPU hours to train, it demonstrates superior performance in recovering parameters accurately, and generalizing well to in-the-wild images. Quantitative and qualitative experiment results validate the effectiveness of DI-PCG in inverse PCG and image-to-3D generation tasks. DI-PCG offers a promising approach for efficient inverse PCG and represents a valuable exploration step towards a 3D generation path that models how to construct a 3D asset using parametric models.', 'abstract_zh': '程序化内容生成（PCG）在创建高质量3D内容方面非常强大，但要控制其生成所需的特定形状却相当困难，往往需要进行大量的参数调整。逆程序化内容生成旨在在给定输入条件的情况下自动找到最优参数。然而，现有的基于采样和基于神经网络的方法仍然面临大量采样迭代或有限可控性的问题。本工作中，我们提出了一种名为DI-PCG的新颖且高效的逆PCG方法，它可以处理一般图像条件下的逆PCG问题。核心在于一个轻量级的扩散变换器模型，其中PCG参数直接作为去噪目标，观察到的图像作为控制参数生成的条件。DI-PCG不仅高效且有效。该模型仅有7.6M的网络参数，仅需30个GPU小时即可训练完成，并在准确恢复参数和很好地泛化到野外图像方面表现出优越性能。定量和定性实验结果验证了DI-PCG在逆PCG和图像到3D生成任务上的有效性。DI-PCG为高效逆PCG提供了一种有前景的方法，并代表了在建模如何使用参数模型构建3D资产方面的一个有价值的研究步骤。', 'title_zh': 'DI-PCG：基于扩散过程的高效程序化内容生成方法及其在高质量3D资产创建中的应用'}
{'arxiv_id': 'arXiv:2412.15188', 'title': 'LlamaFusion: Adapting Pretrained Language Models for Multimodal Generation', 'authors': 'Weijia Shi, Xiaochuang Han, Chunting Zhou, Weixin Liang, Xi Victoria Lin, Luke Zettlemoyer, Lili Yu', 'link': 'https://arxiv.org/abs/2412.15188', 'abstract': "We present LlamaFusion, a framework for empowering pretrained text-only large language models (LLMs) with multimodal generative capabilities, enabling them to understand and generate both text and images in arbitrary sequences. LlamaFusion leverages existing Llama-3's weights for processing texts autoregressively while introducing additional and parallel transformer modules for processing images with diffusion. During training, the data from each modality is routed to its dedicated modules: modality-specific feedforward layers, query-key-value projections, and normalization layers process each modality independently, while the shared self-attention layers allow interactions across text and image features. By freezing the text-specific modules and only training the image-specific modules, LlamaFusion preserves the language capabilities of text-only LLMs while developing strong visual understanding and generation abilities. Compared to methods that pretrain multimodal generative models from scratch, our experiments demonstrate that, LlamaFusion improves image understanding by 20% and image generation by 3.6% using only 50% of the FLOPs while maintaining Llama-3's language capabilities. We also demonstrate that this framework can adapt existing vision-language models with multimodal generation ability. Overall, this framework not only leverages existing computational investments in text-only LLMs but also enables the parallel development of language and vision capabilities, presenting a promising direction for efficient multimodal model development.", 'abstract_zh': '我们提出了LlamaFusion框架，该框架能够赋予仅限文本的大型语言模型（LLMs）多模态生成能力，使其能够理解和生成任意序列的文字和图像。LlamaFusion利用Llama-3现有的权重进行文本自回归处理，并引入了额外的并行变压器模块来处理图像的扩散过程。在训练过程中，来自每个模态的数据被定向到其专用模块：特定于模态的前馈层、查询-键-值投影以及规范化层独立处理每个模态，而共享的自注意力层则允许文本和图像特征之间的交互。通过冻结特定于文本的模块，仅训练特定于图像的模块，LlamaFusion保留了仅限文本的LLMs的语言能力，同时增强了其视觉理解与生成能力。与从头开始预训练多模态生成模型的方法相比，我们的实验数据显示，LlamaFusion仅使用了50%的FLOPs就提升了20%的图像理解能力和3.6%的图像生成能力，同时保持了Llama-3的语言能力。同时，我们也展示了该框架可以适应具有多模态生成能力的现有视觉-语言模型。总体而言，该框架不仅利用了仅限文本的LLMs的现有计算投资，还使语言与视觉能力的并行开发成为可能，为有效多模态模型开发提供了有希望的方向。', 'title_zh': 'LlamaFusion: 调整预训练语言模型以实现多模态生成'}
{'arxiv_id': 'arXiv:2412.15166', 'title': 'Human-Humanoid Robots Cross-Embodiment Behavior-Skill Transfer Using Decomposed Adversarial Learning from Demonstration', 'authors': 'Junjia Liu, Zhuo Li, Minghao Yu, Zhipeng Dong, Sylvain Calinon, Darwin Caldwell, Fei Chen', 'link': 'https://arxiv.org/abs/2412.15166', 'abstract': 'Humanoid robots are envisioned as embodied intelligent agents capable of performing a wide range of human-level loco-manipulation tasks, particularly in scenarios requiring strenuous and repetitive labor. However, learning these skills is challenging due to the high degrees of freedom of humanoid robots, and collecting sufficient training data for humanoid is a laborious process. Given the rapid introduction of new humanoid platforms, a cross-embodiment framework that allows generalizable skill transfer is becoming increasingly critical. To address this, we propose a transferable framework that reduces the data bottleneck by using a unified digital human model as a common prototype and bypassing the need for re-training on every new robot platform. The model learns behavior primitives from human demonstrations through adversarial imitation, and the complex robot structures are decomposed into functional components, each trained independently and dynamically coordinated. Task generalization is achieved through a human-object interaction graph, and skills are transferred to different robots via embodiment-specific kinematic motion retargeting and dynamic fine-tuning. Our framework is validated on five humanoid robots with diverse configurations, demonstrating stable loco-manipulation and highlighting its effectiveness in reducing data requirements and increasing the efficiency of skill transfer across platforms.', 'abstract_zh': 'humanoid 机器人被设想为具备执行广泛人体级别行动与操作任务的实体智能代理，特别是在需要繁重且重复劳动的场景中。然而，由于人形机器人的自由度很高，学习这些技能具有挑战性，而为人形机器人收集足够的训练数据也是一个繁重的过程。鉴于新的人形平台不断涌现，能够实现技能泛化的跨体态框架变得尤为重要。为了解决这个问题，我们提出了一种可转移的框架，通过使用统一的数字 humans 模型作为通用原型，并跳过每个新机器人平台重新训练的需求，从而减少数据瓶颈。该模型通过对抗模仿从人类演示中学习行为原型，并将复杂的机器人结构分解为功能组件，每个组件独立训练并动态协调。任务泛化通过人类-物体交互图实现，而技能则通过特定于主体的动力学运动重新对准和动态微调转移到不同的机器人上。我们在具有不同配置的五个机器人上验证了该框架，展示了稳定的人体运动操作，并突显了其减少数据需求和提高跨平台技能转移效率的有效性。', 'title_zh': '人类-类人机器人跨身体行为技能分解对抗学习转移'}
{'arxiv_id': 'arXiv:2412.15163', 'title': 'Operationalising Rawlsian Ethics for Fairness in Norm-Learning Agents', 'authors': 'Jessica Woodgate, Paul Marshall, Nirav Ajmeri', 'link': 'https://arxiv.org/abs/2412.15163', 'abstract': 'Social norms are standards of behaviour common in a society. However, when agents make decisions without considering how others are impacted, norms can emerge that lead to the subjugation of certain agents. We present RAWL-E, a method to create ethical norm-learning agents. RAWL-E agents operationalise maximin, a fairness principle from Rawlsian ethics, in their decision-making processes to promote ethical norms by balancing societal well-being with individual goals. We evaluate RAWL-E agents in simulated harvesting scenarios. We find that norms emerging in RAWL-E agent societies enhance social welfare, fairness, and robustness, and yield higher minimum experience compared to those that emerge in agent societies that do not implement Rawlsian ethics.', 'abstract_zh': '社会规范是指社会中普遍认可的行为标准。然而，当个体在决策时不顾及他人受到的影响时，可能会形成一些压迫某些个体的社会规范。本文提出了一种名为RAWL-E的方法，用于创建具有伦理学习能力的智能体。RAWL-E智能体在其决策过程中运用拉姆斯理论中的最大最小原则（maximin），平衡社会福祉与个体目标，从而促进伦理规范的形成。我们在模拟的采集场景中评估了RAWL-E智能体的表现。研究结果显示，RAWL-E智能体社会中形成的规范能够提升社会福利、公平性和鲁棒性，并且相比未实施拉姆斯理论原则的智能体社会，能获得更高的最低体验值。', 'title_zh': '将罗尔斯正义伦理学应用于规范学习代理的公平性操作化'}
{'arxiv_id': 'arXiv:2412.15151', 'title': 'Language Models as Continuous Self-Evolving Data Engineers', 'authors': 'Peidong Wang, Ming Wang, Zhiming Ma, Xiaocui Yang, Shi Feng, Daling Wang, Yifei Zhang', 'link': 'https://arxiv.org/abs/2412.15151', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable capabilities on various tasks, while the further evolvement is limited to the lack of high-quality training data. In addition, traditional training approaches rely too much on expert-labeled data, setting an upper limit on the performance of LLMs. To address this issue, we propose a novel paradigm that enables LLMs to train itself by autonomously generating, cleaning, reviewing, and annotating data with preference information, named LANCE. Our approach demonstrates that LLMs can serve as continuous self-evolving data engineers, significantly reducing the time and cost of the post-training data construction process. Through iterative fine-tuning on different variants of the Qwen2, we validate the effectiveness of LANCE across various tasks, showing that it can continuously improve model performance and maintain high-quality data generation. Across eight benchmark dimensions, LANCE resulted in an average score enhancement of 3.36 for Qwen2-7B and 2.70 for Qwen2-7B-Instruct. This training paradigm with autonomous data construction not only reduces the reliance on human experts or external models but also ensures that the data aligns with human values and preferences, paving the way for the development of future superintelligent systems that can exceed human capabilities.', 'abstract_zh': '大型语言模型（LLMs）在各种任务上展现了显著的能力，然而其进一步的发展受限于高质量训练数据的缺乏。此外，传统的训练方法过于依赖专家标注的数据，这在一定程度上限制了LLMs的性能。为了解决这一问题，我们提出了一种新颖的范式，使LLMs能够自主生成、清理、审查和标注数据，并融入偏好信息，该范式命名为LANCE。通过在Qwen2的不同变体上进行迭代微调，我们验证了LANCE在各种任务上的有效性，表明其能够持续提升模型性能并保持高质量的数据生成。在八个基准维度上，LANCE分别为Qwen2-7B和Qwen2-7B-Instruct带来了平均评分提升3.36和2.70。这种自主构建数据的训练范式不仅减少了对人类专家或外部模型的依赖，还确保了数据符合人类价值观和偏好，为未来超越人类能力的超智能系统的开发铺平了道路。', 'title_zh': '语言模型作为连续自我进化的数据工程师'}
{'arxiv_id': 'arXiv:2412.15150', 'title': 'Leveraging Color Channel Independence for Improved Unsupervised Object Detection', 'authors': 'Bastian Jäckl, Yannick Metz, Udo Schlegel, Daniel A. Keim, Maximilian T. Fischer', 'link': 'https://arxiv.org/abs/2412.15150', 'abstract': "Object-centric architectures can learn to extract distinct object representations from visual scenes, enabling downstream applications on the object level. Similarly to autoencoder-based image models, object-centric approaches have been trained on the unsupervised reconstruction loss of images encoded by RGB color spaces. In our work, we challenge the common assumption that RGB images are the optimal color space for unsupervised learning in computer vision. We discuss conceptually and empirically that other color spaces, such as HSV, bear essential characteristics for object-centric representation learning, like robustness to lighting conditions. We further show that models improve when requiring them to predict additional color channels. Specifically, we propose to transform the predicted targets to the RGB-S space, which extends RGB with HSV's saturation component and leads to markedly better reconstruction and disentanglement for five common evaluation datasets. The use of composite color spaces can be implemented with basically no computational overhead, is agnostic of the models' architecture, and is universally applicable across a wide range of visual computing tasks and training types. The findings of our approach encourage additional investigations in computer vision tasks beyond object-centric learning.", 'abstract_zh': '以对象为中心的架构能够学会从视觉场景中提取独特的对象表示，从而在对象级别上启用下游应用。与基于自编码器的图像模型类似，以对象为中心的方法也曾在通过RGB颜色空间编码的图像的无监督重构损失上进行训练。在我们的研究中，我们挑战了RGB图像是计算机视觉中最佳的无监督学习颜色空间这一常见假设。我们从概念上和实验证据中讨论了其他颜色空间，如HSV，在对象中心表示学习中具有核心特征，例如对光照条件的鲁棒性。进一步地，我们展示了要求模型预测额外的颜色通道可以提高模型性能。具体而言，我们建议将预测的目标转换为RGB-S空间，该空间在RGB基础上增加了HSV的饱和度分量，从而在五个常见评估数据集上显著提高了重构和去混杂效果。使用组合颜色空间的实现几乎不需要额外的计算开销，与模型架构无关，并且可以在广泛应用视觉计算任务和训练类型的情况下普遍适用。我们方法的发现鼓励在对象中心学习之外进一步探索计算机视觉任务。', 'title_zh': '利用颜色通道独立性以提高无监督目标检测性能'}
{'arxiv_id': 'arXiv:2412.15129', 'title': 'Jet: A Modern Transformer-Based Normalizing Flow', 'authors': 'Alexander Kolesnikov, André Susano Pinto, Michael Tschannen', 'link': 'https://arxiv.org/abs/2412.15129', 'abstract': 'In the past, normalizing generative flows have emerged as a promising class of generative models for natural images. This type of model has many modeling advantages: the ability to efficiently compute log-likelihood of the input data, fast generation and simple overall structure. Normalizing flows remained a topic of active research but later fell out of favor, as visual quality of the samples was not competitive with other model classes, such as GANs, VQ-VAE-based approaches or diffusion models. In this paper we revisit the design of the coupling-based normalizing flow models by carefully ablating prior design choices and using computational blocks based on the Vision Transformer architecture, not convolutional neural networks. As a result, we achieve state-of-the-art quantitative and qualitative performance with a much simpler architecture. While the overall visual quality is still behind the current state-of-the-art models, we argue that strong normalizing flow models can help advancing research frontier by serving as building components of more powerful generative models.', 'abstract_zh': '在过去，规范化生成流已成为自然图像生成的一种有前途的生成模型类别。这类模型具有许多建模优势：能够高效计算输入数据的对数似然性，快速生成且整体结构简单。规范化流一直是一个活跃的研究领域，但后来由于其生成图像的质量不具有竞争优势，即与生成对抗网络（GANs）、基于矢量量化变分自编码器（VQ-VAE）的方法或扩散模型相比，规范化流逐渐不再受欢迎。在本文中，我们通过仔细地剥离先前的设计选择，并采用基于视觉变换器架构而非卷积神经网络的计算模块，重新审视基于耦合的规范化流模型的设计。结果，我们以一个更为简单的架构实现了最先进的定量和定性性能。尽管整体视觉质量仍落后于当前最先进的模型，但我们认为强大的规范化流模型可以通过作为更强大生成模型的构建组件来推动研究前沿。', 'title_zh': 'jets：一种基于变压器的现代归一化流'}
{'arxiv_id': 'arXiv:2412.15127', 'title': 'Adaptive Pruning for Large Language Models with Structural Importance Awareness', 'authors': 'Haotian Zheng, Jinke Ren, Yushan Sun, Ruichen Zhang, Wenbo Zhang, Zhen Li, Dusit Niyato, Shuguang Cui, Yatong Han', 'link': 'https://arxiv.org/abs/2412.15127', 'abstract': 'The recent advancements in large language models (LLMs) have significantly improved language understanding and generation capabilities. However, it is difficult to deploy LLMs on resource-constrained edge devices due to their high computational and storage resource demands. To address this issue, we propose a novel LLM model pruning method, namely structurally-aware adaptive pruning (SAAP), to significantly reduce the computational and memory costs while maintaining model performance. We first define an adaptive importance fusion metric to evaluate the importance of all coupled structures in LLMs by considering their homoscedastic uncertainty. Then, we rank the importance of all modules to determine the specific layers that should be pruned to meet particular performance requirements. Furthermore, we develop a new group fine-tuning strategy to improve the inference efficiency of LLMs. Finally, we evaluate the proposed SAAP method on multiple LLMs across two common tasks, i.e., zero-shot classification and text generation. Experimental results show that our SAAP method outperforms several state-of-the-art baseline methods, achieving 2.17%, 2.37%, and 2.39% accuracy gains on LLaMA-7B, Vicuna-7B, and LLaMA-13B. Additionally, SAAP improves the token generation speed by 5%, showcasing its practical advantages in resource-constrained scenarios.', 'abstract_zh': '近年来，大规模语言模型（LLMs）在语言理解和生成能力方面取得了显著进步。然而，由于LLMs对计算资源和存储空间的需求较高，难以在资源受限的边缘设备上部署。为解决这一问题，我们提出了一种新颖的大规模语言模型剪枝方法——结构感知自适应剪枝（SAAP），以显著减少计算和内存成本，同时保持模型性能。首先，我们定义了一种自适应重要性融合度量来评估LLMs中所有耦合结构的重要性，考虑了它们的同方差不确定性。然后，我们对所有模块的重要性进行排名，以确定应剪枝的具体层以满足特定性能要求。此外，我们开发了一种新的分组微调策略，以提高LLMs的推理效率。最后，我们在两个常用任务——零样本分类和文本生成——上对多个LLMs评估了所提出的SAAP方法。实验结果表明，我们的SAAP方法优于几种最先进的基准方法，在LLaMA-7B、Vicuna-7B和LLaMA-13B上分别实现了2.17%、2.37%和2.39%的准确率提升。此外，SAAP将令牌生成速度提高了5%，展示了其在资源受限场景下的实际优势。', 'title_zh': '具有结构重要性意识的自适应剪枝方法用于大型语言模型'}
{'arxiv_id': 'arXiv:2412.15118', 'title': 'Outcome-Refining Process Supervision for Code Generation', 'authors': 'Zhuohao Yu, Weizheng Gu, Yidong Wang, Zhengran Zeng, Jindong Wang, Wei Ye, Shikun Zhang', 'link': 'https://arxiv.org/abs/2412.15118', 'abstract': 'Large Language Models have demonstrated remarkable capabilities in code generation, yet they often struggle with complex programming tasks that require deep algorithmic reasoning. While process supervision through learned reward models shows promise in guiding reasoning steps, it requires expensive training data and suffers from unreliable evaluation. We propose Outcome-Refining Process Supervision, a novel paradigm that treats outcome refinement itself as the process to be supervised. Our framework leverages concrete execution signals to ground the supervision of reasoning steps, while using tree-structured exploration to maintain multiple solution trajectories simultaneously. Experiments demonstrate that our approach enables even smaller models to achieve high success accuracy and performance metrics on competitive programming tasks, creates more reliable verification than traditional reward models without requiring training PRMs. Our approach achieves significant improvements across 5 models and 3 datasets: an average of 26.9% increase in correctness and 42.2% in efficiency. The results suggest that providing structured reasoning space with concrete verification signals is crucial for solving complex programming tasks. We open-source all our code and data at: this https URL', 'abstract_zh': '大语言模型在代码生成方面展示了显著的能力，但在处理需要深度算法推理的复杂编程任务时常常出现问题。虽然基于学习奖励模型的过程监督在指导推理步骤方面具有潜力，但需要昂贵的训练数据，并且在评估方面存在不可靠的问题。我们提出了一种名为结果细化过程监督的新范式，将结果细化本身作为要监督的过程。我们的框架利用具体的执行信号来为基础的监督提供支撑，同时使用树状探索结构来同时维护多个解决方案轨迹。实验表明，我们的方法能够使更小的模型在竞标编程任务中实现高成功率和性能指标，同时无需训练PRMs即可提供更可靠的验证。我们的方法在5个模型和3个数据集上实现了显著改进：平均正确性提高了26.9%，效率提高了42.2%。实验结果表明，为解决复杂编程任务提供结构化的推理空间和具体的验证信号至关重要。我们开源了所有代码和数据，地址为：this https URL', 'title_zh': '代码生成中的成果优化过程监督'}
{'arxiv_id': 'arXiv:2412.15113', 'title': 'Associative memory inspires improvements for in-context learning using a novel attention residual stream architecture', 'authors': 'Thomas F Burns, Tomoki Fukai, Christopher J Earls', 'link': 'https://arxiv.org/abs/2412.15113', 'abstract': 'Large language models (LLMs) demonstrate an impressive ability to utilise information within the context of their input sequences to appropriately respond to data unseen by the LLM during its training procedure. This ability is known as in-context learning (ICL). Humans and non-human animals demonstrate similar abilities, however their neural architectures differ substantially from LLMs. Despite this, a critical component within LLMs, the attention mechanism, resembles modern associative memory models, widely used in and influenced by the computational neuroscience community to model biological memory systems. Using this connection, we introduce an associative memory model capable of performing ICL. We use this as inspiration for a novel residual stream architecture which allows information to directly flow between attention heads. We test this architecture during training within a two-layer Transformer and show its ICL abilities manifest more quickly than without this modification. We then apply our architecture in small language models with 8 million parameters, focusing on attention head values, with results also indicating improved ICL performance at this larger and more naturalistic scale.', 'abstract_zh': '大规模语言模型（LLMs）展示了在输入序列上下文中利用信息的能力，以适当响应在其训练过程中未见过的数据。这种能力被称为上下文学习（ICL）。人类和其他动物也展现出类似的 ability，尽管他们的神经架构与 LLMs 有显著差异。尽管如此，LLMs 中的一个关键组件——注意力机制——与现代联想记忆模型相似，这些模型广泛应用于并受到计算神经科学社区的启发，用于模拟生物记忆系统。利用这一联系，我们引入了一个能够执行 ICL 的联想记忆模型。我们以此为灵感，提出了一种新的残差流架构，允许信息直接在注意力头之间流动。我们在两层变换器的训练过程中测试了该架构，并证明了在没有这种修改的情况下，ICL 能力表现得更迅速。然后，我们将该架构应用于具有 800 万参数的小型语言模型，并专注于注意力头值，结果表明在此更大和更自然的规模下，ICL 性能也得到了改进。', 'title_zh': '关联记忆启发了一种新型注意残差流架构在上下文学习中的改进'}
{'arxiv_id': 'arXiv:2412.15105', 'title': 'Exploiting sparse structures and synergy designs to advance situational awareness of electrical power grid', 'authors': 'Shimiao Li', 'link': 'https://arxiv.org/abs/2412.15105', 'abstract': 'The growing threats of uncertainties, anomalies, and cyberattacks on power grids are driving a critical need to advance situational awareness which allows system operators to form a complete and accurate picture of the present and future state. Simulation and estimation are foundational tools in this process. However, existing tools lack the robustness and efficiency required to achieve the level of situational awareness needed for the ever-evolving threat landscape. Industry-standard (steady-state) simulators are not robust to blackouts, often leading to non-converging or non-actionable results. Estimation tools lack robustness to anomalous data, returning erroneous system states. Efficiency is the other major concern as nonlinearities and scalability issues make large systems slow to converge.\nThis thesis addresses robustness and efficiency gaps through a dual-fold contribution. We first address the inherent limitations in the existing physics-based and data-driven worlds; and then transcend the boundaries of conventional algorithmic design in the direction of a new paradigm -- Physics-ML Synergy -- which integrates the strengths of the two worlds. Our approaches are built on circuit formulation which provides a unified framework that applies to both transmission and distribution. Sparse optimization acts as the key enabler to make these tools intrinsically robust and immune to random threats, pinpointing dominant sources of (random) blackouts and data errors. Further, we explore sparsity-exploiting optimizations to develop lightweight ML models whose prediction and detection capabilities are a complement to physics-based tools; and whose lightweight designs advance generalization and scalability. Finally, Physics-ML Synergy brings robustness and efficiency further against targeted cyberthreats, by interconnecting our physics-based tools with lightweight ML.', 'abstract_zh': '随着不确定性、异常和网络安全攻击对电力网络威胁的不断增大，对态势感知的需求变得至关重要。态势感知能够帮助系统操作员形成对当前和未来状态的全面、准确的了解。模拟和估计是这一过程中的基础工具。然而，现有的工具在实现所必需的态势感知水平方面仍然缺乏足够的稳健性和效率，无法应对不断变化的威胁环境。行业中常用的（静态条件下的）仿真器对断电等突发事件不够稳健，往往导致无法收敛或无法采取行动的结果。估计工具对异常数据缺乏稳健性，返回错误的系统状态。效率也是一个主要问题，由于非线性问题和可扩展性问题的存在，使大型系统的收敛变得缓慢。\n\n本论文通过双管齐下的贡献来弥补稳健性和效率上的差距。我们首先解决现有的基于物理和数据驱动方法本身固有的局限性；然后超越传统算法设计的边界，迈向一种新的范式——物理学与机器学习协同——将其两者的优点结合起来。我们的方法基于电路公式，提供了一个适用于传输和配电的统一框架。稀疏优化作为关键的使能器，使这些工具能够在本质上具有稳健性，对于随机威胁具备免疫力，并能精确定位随机断电和数据错误的主要来源。此外，我们还探讨了利用稀疏性的优化方法以开发轻量级的机器学习模型，这些模型的预测和检测能力可以补充基于物理的方法；并且轻量级的设计能够提高泛化能力和可扩展性。最后，物理学与机器学习协同进一步提高了对定向网络攻击的稳健性和效率，通过将我们的基于物理的方法与轻量级的机器学习方法连接起来，增强了整体的防护能力。', 'title_zh': '利用稀疏结构和协同设计推进电力系统的 situational awareness'}
{'arxiv_id': 'arXiv:2412.15098', 'title': 'A Cross-Domain Study of the Use of Persuasion Techniques in Online Disinformation', 'authors': 'João A. Leite, Olesya Razuvayevskaya, Carolina Scarton, Kalina Bontcheva', 'link': 'https://arxiv.org/abs/2412.15098', 'abstract': 'Disinformation, irrespective of domain or language, aims to deceive or manipulate public opinion, typically through employing advanced persuasion techniques. Qualitative and quantitative research on the weaponisation of persuasion techniques in disinformation has been mostly topic-specific (e.g., COVID-19) with limited cross-domain studies, resulting in a lack of comprehensive understanding of these strategies. This study employs a state-of-the-art persuasion technique classifier to conduct a large-scale, multi-domain analysis of the role of 16 persuasion techniques in disinformation narratives. It shows how different persuasion techniques are employed disproportionately in different disinformation domains. We also include a detailed case study on climate change disinformation, highlighting how linguistic, psychological, and cultural factors shape the adaptation of persuasion strategies to fit unique thematic contexts.', 'abstract_zh': '无论是在哪个领域或使用哪种语言，虚假信息旨在欺骗或操控公众舆论，通常通过运用高级说服技巧来实现。在虚假信息中武器化说服技巧的定性与定量研究主要集中在特定主题上（例如，COVID-19），跨领域的研究较少，导致对这些策略的理解不够全面。本研究采用最先进的说服技巧分类器，进行大规模、跨领域的分析，探讨16种说服技巧在虚假信息叙事中的作用。研究显示了不同说服技巧在不同虚假信息领域中的不均衡应用情况。同时，我们还通过对气候变迁虚假信息进行详细案例研究，阐明了语言、心理和文化因素如何塑造说服策略以适应特定的主题背景。', 'title_zh': '跨域研究：在线虚假信息中说服技术的运用'}
{'arxiv_id': 'arXiv:2412.15095', 'title': 'A Full Transformer-based Framework for Automatic Pain Estimation using Videos', 'authors': 'Stefanos Gkikas, Manolis Tsiknakis', 'link': 'https://arxiv.org/abs/2412.15095', 'abstract': 'The automatic estimation of pain is essential in designing an optimal pain management system offering reliable assessment and reducing the suffering of patients. In this study, we present a novel full transformer-based framework consisting of a Transformer in Transformer (TNT) model and a Transformer leveraging cross-attention and self-attention blocks. Elaborating on videos from the BioVid database, we demonstrate state-of-the-art performances, showing the efficacy, efficiency, and generalization capability across all the primary pain estimation tasks.', 'abstract_zh': '自动评估疼痛对于设计一个优化的疼痛管理系统至关重要，该系统能够提供可靠的评估并减少患者的痛苦。在本研究中，我们提出了一种新颖的全变压器基线框架，该框架包含一个Transformer in Transformer (TNT)模型和一个利用跨注意力和自我注意力模块的变压器模型。通过对BioVid数据库中的视频进行详尽分析，我们展示了这些模型在所有主要疼痛估计任务中的先进性能，证明了其有效性和推广能力。', 'title_zh': '基于完整变压器架构的视频自动疼痛估计框架'}
{'arxiv_id': 'arXiv:2412.15086', 'title': 'Learning Disentangled Equivariant Representation for Explicitly Controllable 3D Molecule Generation', 'authors': 'Haoran Liu, Youzhi Luo, Tianxiao Li, James Caverlee, Martin Renqiang Min', 'link': 'https://arxiv.org/abs/2412.15086', 'abstract': "We consider the conditional generation of 3D drug-like molecules with \\textit{explicit control} over molecular properties such as drug-like properties (e.g., Quantitative Estimate of Druglikeness or Synthetic Accessibility score) and effectively binding to specific protein sites. To tackle this problem, we propose an E(3)-equivariant Wasserstein autoencoder and factorize the latent space of our generative model into two disentangled aspects: molecular properties and the remaining structural context of 3D molecules. Our model ensures explicit control over these molecular attributes while maintaining equivariance of coordinate representation and invariance of data likelihood. Furthermore, we introduce a novel alignment-based coordinate loss to adapt equivariant networks for auto-regressive de-novo 3D molecule generation from scratch. Extensive experiments validate our model's effectiveness on property-guided and context-guided molecule generation, both for de-novo 3D molecule design and structure-based drug discovery against protein targets.", 'abstract_zh': '我们考虑生成具有**明确控制**的三维药物样分子，包括分子性质（如定量药物样估测或合成可达性评分）的控制，以及有效结合至特定蛋白质位点。为了解决这一问题，我们提出了一种**E(3)-不变**的沃斯泰因自动编码器（Wasserstein autoencoder），并把生成模型的潜空间分解为两个解耦的方面：分子性质和三维分子的剩余结构背景。我们的模型确保了对这些分子属性的明确控制，同时保持了坐标表示的不变性和数据似然性的不变性。此外，我们引入了一种新的基于对齐的坐标损失，以适应协变网络进行从零开始的自回归三维分子生成。通过广泛的实验验证，我们的模型在性质指导和上下文指导的分子生成中均表现出有效性，包括从零开始的三维分子设计和基于结构的药物发现针对蛋白质靶标。', 'title_zh': '学习解耦的守恒表示以实现显式可控的3D分子生成'}
{'arxiv_id': 'arXiv:2412.15084', 'title': 'AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward Modeling', 'authors': 'Zihan Liu, Yang Chen, Mohammad Shoeybi, Bryan Catanzaro, Wei Ping', 'link': 'https://arxiv.org/abs/2412.15084', 'abstract': 'In this paper, we introduce AceMath, a suite of frontier math models that excel in solving complex math problems, along with highly effective reward models capable of evaluating generated solutions and reliably identifying the correct ones. To develop the instruction-tuned math models, we propose a supervised fine-tuning (SFT) process that first achieves competitive performance across general domains, followed by targeted fine-tuning for the math domain using a carefully curated set of prompts and synthetically generated responses. The resulting model, AceMath-72B-Instruct greatly outperforms Qwen2.5-Math-72B-Instruct, GPT-4o and Claude-3.5 Sonnet. To develop math-specialized reward model, we first construct AceMath-RewardBench, a comprehensive and robust benchmark for evaluating math reward models across diverse problems and difficulty levels. After that, we present a systematic approach to build our math reward models. The resulting model, AceMath-72B-RM, consistently outperforms state-of-the-art reward models. Furthermore, when combining AceMath-72B-Instruct with AceMath-72B-RM, we achieve the highest average rm@8 score across the math reasoning benchmarks. We will release model weights, training data, and evaluation benchmarks at: this https URL', 'abstract_zh': '在本文中，我们介绍了一套名为AceMath的前沿数学模型，这些模型在解决复杂数学问题方面表现出色，并且配备了高效的奖励模型，能够评估生成的解决方案，并可靠地识别正确的答案。为了开发指令调优的数学模型，我们提出了一种监督微调（SFT）过程，该过程首先在通用领域实现竞争性性能，然后通过使用精心策划的提示和合成生成的响应，在数学领域进行有针对性的微调。由此产生的模型AceMath-72B-Instruct在多个方面显著优于Qwen2.5-Math-72B-Instruct、GPT-4o和Claude-3.5 Sonnet。为了开发专门针对数学的奖励模型，我们首先构建了AceMath-RewardBench，这是一个全面且稳健的基准，用于评估数学奖励模型在各种问题和难度级别上的性能。之后，我们提出了构建数学奖励模型的系统方法。由此产生的模型AceMath-72B-RM在当前最先进的奖励模型中表现优异。此外，当将AceMath-72B-Instruct与AceMath-72B-RM结合使用时，我们在数学推理基准测试中实现了最高的平均rm@8分数。我们将发布模型权重、训练数据和评估基准：[此链接](this https URL)', 'title_zh': 'AceMath: 基于后训练和奖励建模的前沿数学推理提升'}
{'arxiv_id': 'arXiv:2412.15054', 'title': 'GIRAFE: Glottal Imaging Dataset for Advanced Segmentation, Analysis, and Facilitative Playbacks Evaluation', 'authors': 'G. Andrade-Miranda, K. Chatzipapas, J.D. Arias-Londoño, J. I. Godino-Llorente', 'link': 'https://arxiv.org/abs/2412.15054', 'abstract': 'The advances in the development of Facilitative Playbacks extracted from High-Speed videoendoscopic sequences of the vocal folds are hindered by a notable lack of publicly available datasets annotated with the semantic segmentations corresponding to the area of the glottal gap. This fact also limits the reproducibility and further exploration of existing research in this field.\nTo address this gap, GIRAFE is a data repository designed to facilitate the development of advanced techniques for the semantic segmentation, analysis, and fast evaluation of High-Speed videoendoscopic sequences of the vocal folds. The repository includes 65 high-speed videoendoscopic recordings from a cohort of 50 patients (30 female, 20 male). The dataset comprises 15 recordings from healthy controls, 26 from patients with diagnosed voice disorders, and 24 with an unknown health condition. All of them were manually annotated by an expert, including the masks corresponding to the semantic segmentation of the glottal gap. The repository is also complemented with the automatic segmentation of the glottal area using different state-of-the-art approaches.\nThis data set has already supported several studies, which demonstrates its usefulness for the development of new glottal gap segmentation algorithms from High-Speed-Videoendoscopic sequences to improve or create new Facilitative Playbacks. Despite these advances and others in the field, the broader challenge of performing an accurate and completely automatic semantic segmentation method of the glottal area remains open.', 'abstract_zh': '高速视频内镜序列中声带促进回放发展的进展受到公开数据集的严重缺乏的阻碍，这些数据集缺乏与气孔区语义分割相对应的注释。这一事实也限制了现有研究的可再现性及其进一步探索。\n\n为了解决这一差距，GIRAFE 是一个数据仓库，旨在促进对高速视频内镜序列进行语义分割、分析和快速评估的高级技术的发展。该仓库包含来自50名患者的65段高速视频内镜记录（30名女性，20名男性）。数据集包括15段来自健康对照者的记录，26段来自已诊断出声音障碍的患者记录，以及24段来自不明健康状况的患者记录。所有记录均由专家手动注释，包括与气孔区语义分割相对应的掩码。此外，该仓库还补充了使用不同最先进的方法自动分割声门区域。\n\n该数据集已经支持了多项研究，这表明其对于从高速视频内镜序列开发新的气孔区分割算法以改进或创建新的促进回放具有有用性。尽管在该领域取得了这些进展和其他成果，对气门区域进行准确且完全自动的语义分割方法仍是一个开放的挑战。', 'title_zh': 'GIRAFE：用于高级分割、分析及辅助回放评估的声门成像数据集'}
{'arxiv_id': 'arXiv:2412.15047', 'title': 'Measuring, Modeling, and Helping People Account for Privacy Risks in Online Self-Disclosures with AI', 'authors': 'Isadora Krsek, Anubha Kabra, Yao Dou, Tarek Naous, Laura A. Dabbish, Alan Ritter, Wei Xu, Sauvik Das', 'link': 'https://arxiv.org/abs/2412.15047', 'abstract': "In pseudonymous online fora like Reddit, the benefits of self-disclosure are often apparent to users (e.g., I can vent about my in-laws to understanding strangers), but the privacy risks are more abstract (e.g., will my partner be able to tell that this is me?). Prior work has sought to develop natural language processing (NLP) tools that help users identify potentially risky self-disclosures in their text, but none have been designed for or evaluated with the users they hope to protect. Absent this assessment, these tools will be limited by the social-technical gap: users need assistive tools that help them make informed decisions, not paternalistic tools that tell them to avoid self-disclosure altogether. To bridge this gap, we conducted a study with N = 21 Reddit users; we had them use a state-of-the-art NLP disclosure detection model on two of their authored posts and asked them questions to understand if and how the model helped, where it fell short, and how it could be improved to help them make more informed decisions. Despite its imperfections, users responded positively to the model and highlighted its use as a tool that can help them catch mistakes, inform them of risks they were unaware of, and encourage self-reflection. However, our work also shows how, to be useful and usable, AI for supporting privacy decision-making must account for posting context, disclosure norms, and users' lived threat models, and provide explanations that help contextualize detected risks.", 'abstract_zh': '在像Reddit这样的匿名在线论坛中，自我披露的好处对用户来说通常是显而易见的（例如，我可以向理解我的陌生人倾诉关于公婆的问题），但隐私风险则更为抽象（例如，我的伴侣能否猜出这就是我？）。先前的研究试图开发自然语言处理（NLP）工具，帮助用户识别其文本中可能存在的风险性自我披露，但这些工具都未针对其希望保护的用户进行设计或评估。缺乏这种评估，这些工具将受限于社会技术鸿沟：用户需要的是辅助工具，能够帮助他们做出知情决策，而不是强制他们完全避免自我披露的家长式工具。为了弥合这一鸿沟，我们与21位Reddit用户进行了研究；让这些用户使用最先进的NLP披露检测模型对她们撰写的两篇帖子进行分析，并提出问题以了解该模型如何帮助他们、其不足之处以及如何改进以帮助它们做出更加知情的决策。尽管该模型存在缺陷，但用户对其反应积极，并指出该模型作为帮助他们发现错误、了解未知风险和促进自我反思的工具的价值。然而，我们的研究也表明，为了成为有用和可用的技术，支持隐私决策的AI必须考虑发帖背景、自我披露规范以及用户的实际威胁模型，并提供有助于解释检测到的风险的说明。', 'title_zh': '使用AI衡量、建模并帮助人们评估在线自我披露中的隐私风险'}
{'arxiv_id': 'arXiv:2412.15004', 'title': 'Large Language Models and Code Security: A Systematic Literature Review', 'authors': 'Enna Basic, Alberto Giaretta', 'link': 'https://arxiv.org/abs/2412.15004', 'abstract': 'Large Language Models (LLMs) have emerged as powerful tools for automating various programming tasks, including security-related ones, such as detecting and fixing vulnerabilities. Despite their promising capabilities, when required to produce or modify pre-existing code, LLMs could introduce vulnerabilities unbeknown to the programmer. When analyzing code, they could miss clear vulnerabilities or signal nonexistent ones. In this Systematic Literature Review (SLR), we aim to investigate both the security benefits and potential drawbacks of using LLMs for a variety of code-related tasks. In particular, first we focus on the types of vulnerabilities that could be introduced by LLMs, when used for producing code. Second, we analyze the capabilities of LLMs to detect and fix vulnerabilities, in any given code, and how the prompting strategy of choice impacts their performance in these two tasks. Last, we provide an in-depth analysis on how data poisoning attacks on LLMs can impact performance in the aforementioned tasks.', 'abstract_zh': '大型语言模型（LLMs）已成为自动化各种编程任务的强大工具，包括与安全相关的工作，如检测和修复漏洞。尽管它们具有令人充满希望的能力，但在必须生成或修改现有代码时，LLMs 可能会引入程序员不知晓的漏洞。在分析代码时，它们可能会遗漏明显的漏洞或误报不存在的漏洞。在本系统综述（SLR）中，我们旨在探讨使用LLMs进行各种代码相关任务时的安全利弊。首先，我们重点关注LLMs在生成代码时可能引入的漏洞类型。其次，我们分析LLMs在任何给定代码中检测和修复漏洞的能力，以及所选择的提示策略如何影响它们在这两项任务中的表现。最后，我们详细分析数据投毒攻击如何影响LLMs在上述任务中的性能。', 'title_zh': '大型语言模型与代码安全性：一项系统文献综述'}
{'arxiv_id': 'arXiv:2412.14995', 'title': 'HSEvo: Elevating Automatic Heuristic Design with Diversity-Driven Harmony Search and Genetic Algorithm Using LLMs', 'authors': 'Pham Vu Tuan Dat, Long Doan, Huynh Thi Thanh Binh', 'link': 'https://arxiv.org/abs/2412.14995', 'abstract': "Automatic Heuristic Design (AHD) is an active research area due to its utility in solving complex search and NP-hard combinatorial optimization problems in the real world. The recent advancements in Large Language Models (LLMs) introduce new possibilities by coupling LLMs with evolutionary computation to automatically generate heuristics, known as LLM-based Evolutionary Program Search (LLM-EPS). While previous LLM-EPS studies obtained great performance on various tasks, there is still a gap in understanding the properties of heuristic search spaces and achieving a balance between exploration and exploitation, which is a critical factor in large heuristic search spaces. In this study, we address this gap by proposing two diversity measurement metrics and perform an analysis on previous LLM-EPS approaches, including FunSearch, EoH, and ReEvo. Results on black-box AHD problems reveal that while EoH demonstrates higher diversity than FunSearch and ReEvo, its objective score is unstable. Conversely, ReEvo's reflection mechanism yields good objective scores but fails to optimize diversity effectively. With this finding in mind, we introduce HSEvo, an adaptive LLM-EPS framework that maintains a balance between diversity and convergence with a harmony search algorithm. Through experimentation, we find that HSEvo achieved high diversity indices and good objective scores while remaining cost-effective. These results underscore the importance of balancing exploration and exploitation and understanding heuristic search spaces in designing frameworks in LLM-EPS.", 'abstract_zh': '自动启发式设计（Automatic Heuristic Design, AHD）是一个活跃的研究领域，因其在解决复杂搜索和NP难组合优化问题方面的实用性而备受关注。近期，大型语言模型（Large Language Models, LLMs）的发展为利用LLMs与进化计算相结合自动生成启发式方法提供了新的可能性，这种结合被称为LLMs基础的进化程序搜索（LLM-EPS）。尽管先前的LLM-EPS研究在各种任务上取得了很好的性能，但在理解和平衡探索与利用之间的关系方面仍存在差距，尤其是对于大规模启发式搜索空间而言，这一点至关重要。本研究旨在通过提出两种多样性的度量标准并对先前的LLM-EPS方法（包括FunSearch、EoH、ReEvo等）进行分析来弥合这一差距。在黑盒AHD问题上的实验结果表明，虽然EoH在多样性方面优于FunSearch和ReEvo，但其目标分数不稳定；反之，ReEvo的反射机制能够取得良好的目标分数，但在优化多样性方面效果不佳。基于这一发现，我们引入了一种自适应的LLM-EPS框架——HSEvo，该框架通过和谐搜索算法维持多样性和收敛之间的平衡。实验结果表明，HSEvo不仅能够保持较高的多样性指数和良好的目标分数，同时还能保持成本效益。这些结果强调了在LLM-EPS框架设计中平衡探索与利用以及理解启发式搜索空间的重要性。', 'title_zh': 'HSEvo：通过多样化驱动的和声搜索与遗传算法结合大语言模型自动启发式设计提级'}
{'arxiv_id': 'arXiv:2412.14965', 'title': 'Movie2Story: A framework for understanding videos and telling stories in the form of novel text', 'authors': 'Kangning Li, Zheyang Jia, Anyu Ying', 'link': 'https://arxiv.org/abs/2412.14965', 'abstract': 'Multimodal video-to-text models have made considerable progress, primarily in generating brief descriptions of video content. However, there is still a deficiency in generating rich long-form text descriptions that integrate both video and audio. In this paper, we introduce a framework called M2S, designed to generate novel-length text by combining audio, video, and character recognition. M2S includes modules for video long-form text description and comprehension, audio-based analysis of emotion, speech rate, and character alignment, and visual-based character recognition alignment. By integrating multimodal information using the large language model GPT4o, M2S stands out in the field of multimodal text generation. We demonstrate the effectiveness and accuracy of M2S through comparative experiments and human evaluation. Additionally, the model framework has good scalability and significant potential for future research.', 'abstract_zh': '多模态视频到文本模型在生成简短的视频内容描述方面取得了显著进展。然而，在生成具有丰富信息且能综合视频和音频内容的长篇文本描述方面仍然存在不足。本文介绍了名为M2S的框架，旨在结合音频、视频和字符识别来生成长篇文本描述。M2S 包含用于生成视频长篇文本描述及理解、基于音频的情绪分析、语速分析以及字符对齐的模块，以及基于视觉的字符识别对齐。通过使用大语言模型GPT4o 综合多模态信息，M2S 在多模态文本生成领域脱颖而出。我们通过对比实验和人工评估展示了M2S 的有效性和准确性。此外，该模型框架具有良好的扩展性和显著的研究潜力。', 'title_zh': 'Movie2Story：理解视频并以新颖文本形式讲述故事的框架'}
{'arxiv_id': 'arXiv:2412.14933', 'title': 'Cirbo: A New Tool for Boolean Circuit Analysis and Synthesis', 'authors': 'Daniil Averkov, Tatiana Belova, Gregory Emdin, Mikhail Goncharov, Viktoriia Krivogornitsyna, Alexander S. Kulikov, Fedor Kurmazov, Daniil Levtsov, Georgie Levtsov, Vsevolod Vaskin, Aleksey Vorobiev', 'link': 'https://arxiv.org/abs/2412.14933', 'abstract': 'We present an open-source tool for manipulating Boolean circuits. It implements efficient algorithms, both existing and novel, for a rich variety of frequently used circuit tasks such as satisfiability, synthesis, and minimization. We tested the tool on a wide range of practically relevant circuits (computing, in particular, symmetric and arithmetic functions) that have been optimized intensively by the community for the last three years. The tool helped us to win the IWLS 2024 Programming Contest. In 2023, it was Google DeepMind who took the first place in the competition. We were able to reduce the size of the best circuits from 2023 by 12\\% on average, whereas for some individual circuits, our size reduction was as large as 83\\%.', 'abstract_zh': '我们介绍了一个开源工具，用于操作布尔电路。该工具实现了高效算法，包括现有和新颖的算法，以处理各种常见的电路任务，如可满足性、合成和简化。我们使用该工具对社区在过去三年中优化的各种实际相关的电路进行了测试（特别关注对称和算术函数的计算）。该工具帮助我们在IWLS 2024编程比赛中取得了胜利。2023年，谷歌深度思维（Google DeepMind）在比赛中夺冠。我们能够将2023年最佳电路的大小平均缩小12%，而在个别电路中，我们的尺寸减少高达83%。', 'title_zh': 'Cirbo：一种新的布尔电路分析与综合工具'}
{'arxiv_id': 'arXiv:2412.14922', 'title': 'RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response', 'authors': 'Junyu Luo, Xiao Luo, Kaize Ding, Jingyang Yuan, Zhiping Xiao, Ming Zhang', 'link': 'https://arxiv.org/abs/2412.14922', 'abstract': "Supervised fine-tuning (SFT) plays a crucial role in adapting large language models (LLMs) to specific domains or tasks. However, as demonstrated by empirical experiments, the collected data inevitably contains noise in practical applications, which poses significant challenges to model performance on downstream tasks. Therefore, there is an urgent need for a noise-robust SFT framework to enhance model capabilities in downstream tasks. To address this challenge, we introduce a robust SFT framework (RobustFT) that performs noise detection and relabeling on downstream task data. For noise identification, our approach employs a multi-expert collaborative system with inference-enhanced models to achieve superior noise detection. In the denoising phase, we utilize a context-enhanced strategy, which incorporates the most relevant and confident knowledge followed by careful assessment to generate reliable annotations. Additionally, we introduce an effective data selection mechanism based on response entropy, ensuring only high-quality samples are retained for fine-tuning. Extensive experiments conducted on multiple LLMs across five datasets demonstrate RobustFT's exceptional performance in noisy scenarios.", 'abstract_zh': '监督微调（SFT）在将大语言模型（LLMs）适应特定领域或任务中起着关键作用。然而，如实证实验所示，收集的数据在实际应用中不可避免地包含噪声，这对模型在下游任务中的性能构成了重大挑战。因此，需要一个鲁棒的SFT框架来增强模型在下游任务中的能力。为应对这一挑战，我们提出了一种鲁棒SFT框架（RobustFT），该框架在下游任务数据上进行噪声检测和重新标签。对于噪声识别，我们的方法采用了一个多专家协作系统和推理增强模型，以实现更好的噪声检测。在去噪阶段，我们利用一种基于上下文的关系化策略，该策略结合了最相关和最自信的知识，并经过仔细评估后生成可靠注释。此外，我们还引入了一种基于响应熵的有效数据选择机制，确保只有高质量的样本被保留用于微调。在五个数据集上对多个LLMs进行的大量实验表明，RobustFT在噪声场景中的性能表现出色。', 'title_zh': 'RobustFT: 在噪声响应环境下大型语言模型的鲁棒监督微调'}
{'arxiv_id': 'arXiv:2412.14905', 'title': 'Dehallucinating Parallel Context Extension for Retrieval-Augmented Generation', 'authors': 'Zexiong Ma, Shengnan An, Zeqi Lin, Yanzhen Zou, Jian-Guang Lou, Bing Xie', 'link': 'https://arxiv.org/abs/2412.14905', 'abstract': 'Large language models (LLMs) are susceptible to generating hallucinated information, despite the integration of retrieval-augmented generation (RAG). Parallel context extension (PCE) is a line of research attempting to effectively integrating parallel (unordered) contexts, while it still suffers from hallucinations when adapted to RAG scenarios. In this paper, we propose DePaC (Dehallucinating Parallel Context Extension), which alleviates the hallucination problem with context-aware negative training and information-calibrated aggregation. DePaC is designed to alleviate two types of in-context hallucination: fact fabrication (i.e., LLMs present claims that are not supported by the contexts) and fact omission (i.e., LLMs fail to present claims that can be supported by the contexts). Specifically, (1) for fact fabrication, we apply the context-aware negative training that fine-tunes the LLMs with negative supervisions, thus explicitly guiding the LLMs to refuse to answer when contexts are not related to questions; (2) for fact omission, we propose the information-calibrated aggregation which prioritizes context windows with higher information increment from their contexts. The experimental results on nine RAG tasks demonstrate that DePaC significantly alleviates the two types of hallucination and consistently achieves better performances on these tasks.', 'abstract_zh': '大型语言模型（LLMs）在整合检索增强生成（RAG）后仍然容易生成虚构信息，尽管已经集成了检索增强生成（RAG）。平行上下文扩展（PCE）是一条研究路线，旨在有效地整合无序的并行上下文，但在适应RAG场景时仍然存在生成虚构信息的问题。在本文中，我们提出了一种名为DePaC（Dehallucinating Parallel Context Extension）的方法，通过上下文感知的负样本训练和信息校准聚合来缓解生成虚构信息的问题。DePaC 设计用于缓解两种类型的上下文内部虚构信息：事实捏造（即，LLMs 提出的断言没有相关上下文的支持）和事实遗漏（即，LLMs 没有呈现可以由上下文支持的断言）。具体而言，（1）对于事实捏造，我们应用上下文感知的负样本训练，通过微调LLMs 来结合负监督，从而使LLMs 明确地在上下文不相关于问题时拒绝作答；（2）对于事实遗漏，我们提出了一种信息校准聚合方法，优先考虑那些具有更高信息增量的上下文窗口。在九项RAG任务上的实验结果表明，DePaC 显著缓解了两种类型的虚构信息问题，并且在这些任务中始终实现了更好的性能。', 'title_zh': '去hallucination的并行上下文扩展用于检索增强生成'}
{'arxiv_id': 'arXiv:2412.14869', 'title': 'AI-Powered Intracranial Hemorrhage Detection: A Co-Scale Convolutional Attention Model with Uncertainty-Based Fuzzy Integral Operator and Feature Screening', 'authors': 'Mehdi Hosseini Chagahi, Md. Jalil Piran, Niloufar Delfan, Behzad Moshiri, Jaber Hatam Parikhan', 'link': 'https://arxiv.org/abs/2412.14869', 'abstract': 'Intracranial hemorrhage (ICH) refers to the leakage or accumulation of blood within the skull, which occurs due to the rupture of blood vessels in or around the brain. If this condition is not diagnosed in a timely manner and appropriately treated, it can lead to serious complications such as decreased consciousness, permanent neurological disabilities, or even this http URL primary aim of this study is to detect the occurrence or non-occurrence of ICH, followed by determining the type of subdural hemorrhage (SDH). These tasks are framed as two separate binary classification problems. By adding two layers to the co-scale convolutional attention (CCA) classifier architecture, we introduce a novel approach for ICH detection. In the first layer, after extracting features from different slices of computed tomography (CT) scan images, we combine these features and select the 50 components that capture the highest variance in the data, considering them as informative features. We then assess the discriminative power of these features using the bootstrap forest algorithm, discarding those that lack sufficient discriminative ability between different classes. This algorithm explicitly determines the contribution of each feature to the final prediction, assisting us in developing an explainable AI model. The features feed into a boosting neural network as a latent feature space. In the second layer, we introduce a novel uncertainty-based fuzzy integral operator to fuse information from different CT scan slices. This operator, by accounting for the dependencies between consecutive slices, significantly improves detection accuracy.', 'abstract_zh': '颅内出血（ICH）是指血液在颅骨内泄漏或积聚的情况，通常是由于脑内或脑周围的血管破裂所导致。如果这种状况未得到及时诊断和适当治疗，可能会导致意识下降、永久性的神经功能损伤，甚至可能导致更严重的后果。本研究的主要目的是检测ICH的发生与否，接着确定硬膜下出血（SDH）的类型。这些任务被定性为两个独立的二元分类问题。通过在共尺度卷积注意力（CCA）分类器架构中增加两层，我们提出了一种新的ICH检测方法。在第一层中，在从不同断层的计算机断层扫描（CT）图像中提取特征后，我们将这些特征结合，并选取50个能够捕捉数据中最高差异性的关键特征。然后，我们使用自助森林算法评估这些特征的区分能力，剔除那些在不同类别之间缺乏充足区分能力的特征。该算法明确地确定了每个特征对最终预测的贡献，帮助我们构建了一个可解释的人工智能模型。这些特征作为潜在特征空间输入到提升神经网络中。在第二层中，我们提出了一种新的基于不确定性的模糊积分运算符，用于融合不同CT扫描断层的信息。通过考虑连续断层之间的依赖关系，这种运算符显著提高了检测准确性。', 'title_zh': '基于AI的颅内出血检测：一种不确定性基于模糊积分运算符和特征筛选的协同尺度卷积注意力模型'}
{'arxiv_id': 'arXiv:2412.14847', 'title': 'A Survey of RWKV', 'authors': 'Zhiyuan Li, Tingyu Xia, Yi Chang, Yuan Wu', 'link': 'https://arxiv.org/abs/2412.14847', 'abstract': 'The Receptance Weighted Key Value (RWKV) model offers a novel alternative to the Transformer architecture, merging the benefits of recurrent and attention-based systems. Unlike conventional Transformers, which depend heavily on self-attention, RWKV adeptly captures long-range dependencies with minimal computational demands. By utilizing a recurrent framework, RWKV addresses some computational inefficiencies found in Transformers, particularly in tasks with long sequences. RWKV has recently drawn considerable attention for its robust performance across multiple domains. Despite its growing popularity, no systematic review of the RWKV model exists. This paper seeks to fill this gap as the first comprehensive review of the RWKV architecture, its core principles, and its varied applications, such as natural language generation, natural language understanding, and computer vision. We assess how RWKV compares to traditional Transformer models, highlighting its capability to manage long sequences efficiently and lower computational costs. Furthermore, we explore the challenges RWKV encounters and propose potential directions for future research and advancement. We consistently maintain the related open-source materials at: this https URL.', 'abstract_zh': '《接收比加权关键值（RWKV）模型》提供了一种新颖的Transformer架构替代方案，结合了递归和基于注意力系统的优点。与依赖于自注意力的传统Transformer不同，RWKV能够以较小的计算需求捕捉长范围依赖关系。通过利用递归框架，RWKV解决了传统Transformer在处理长序列任务时的部分计算效率问题。RWKV最近因其在多个领域的稳健性能获得了广泛关注。尽管其受欢迎程度不断增加，但目前尚未有系统性的RWKV模型综述。本文旨在填补这一空白，提供RWKV架构、核心原则及其在自然语言生成、自然语言理解和计算机视觉等多种应用领域中的首次全面综述。我们评估RWKV与传统Transformer模型的比较，强调其高效管理长序列和降低计算成本的能力。此外，我们探讨了RWKV面临的挑战，并提出了未来研究和发展的潜在方向。我们持续维护相关的开放源代码材料于以下链接：[this https URL]。', 'title_zh': 'RWKV综述'}
{'arxiv_id': 'arXiv:2412.14846', 'title': 'Head and Neck Tumor Segmentation of MRI from Pre- and Mid-radiotherapy with Pre-training, Data Augmentation and Dual Flow UNet', 'authors': 'Litingyu Wang, Wenjun Liao, Shichuan Zhang, Guotai Wang', 'link': 'https://arxiv.org/abs/2412.14846', 'abstract': 'Head and neck tumors and metastatic lymph nodes are crucial for treatment planning and prognostic analysis. Accurate segmentation and quantitative analysis of these structures require pixel-level annotation, making automated segmentation techniques essential for the diagnosis and treatment of head and neck cancer. In this study, we investigated the effects of multiple strategies on the segmentation of pre-radiotherapy (pre-RT) and mid-radiotherapy (mid-RT) images. For the segmentation of pre-RT images, we utilized: 1) a fully supervised learning approach, and 2) the same approach enhanced with pre-trained weights and the MixUp data augmentation technique. For mid-RT images, we introduced a novel computational-friendly network architecture that features separate encoders for mid-RT images and registered pre-RT images with their labels. The mid-RT encoder branch integrates information from pre-RT images and labels progressively during the forward propagation. We selected the highest-performing model from each fold and used their predictions to create an ensemble average for inference. In the final test, our models achieved a segmentation performance of 82.38% for pre-RT and 72.53% for mid-RT on aggregated Dice Similarity Coefficient (DSC) as HiLab. Our code is available at this https URL.', 'abstract_zh': '头颈部肿瘤及其转移淋巴结是治疗规划和预后分析的关键。准确分割这些结构并进行定量分析需要进行像素级标注，因此自动化分割技术对于头颈部癌症的诊断和治疗至关重要。在本研究中，我们探讨了多种策略对治疗前（pre-RT）和中期治疗期间（mid-RT）图像分割效果的影响。对于pre-RT图像的分割，我们采用了：1）完全监督学习方法；2）结合预训练权重和MixUp数据增强技术的相同方法。对于mid-RT图像，我们引入了一种新的计算效率高的网络架构，该架构包含了专门用于mid-RT图像和对齐的pre-RT图像及其标签的独立编码器。mid-RT编码器分支在前向传播过程中逐步整合了pre-RT图像和标签的信息。我们从每折中选择表现最好的模型，并使用这些模型的预测值构建集成平均值用于推断。在最终测试中，我们的模型在HiLab聚合Dice相似性系数（DSC）上达到了pre-RT图像82.38%和mid-RT图像72.53%的分割性能。我们的代码可在以下网址获得：[这个网址]。', 'title_zh': '预放疗和中放疗阶段基于MRI的头颈肿瘤分割：预训练、数据增强和双流UNet'}
{'arxiv_id': 'arXiv:2412.14843', 'title': 'Mapping and Influencing the Political Ideology of Large Language Models using Synthetic Personas', 'authors': 'Pietro Bernardelle, Leon Fröhling, Stefano Civelli, Riccardo Lunardi, Kevin Roiter, Gianluca Demartini', 'link': 'https://arxiv.org/abs/2412.14843', 'abstract': "The analysis of political biases in large language models (LLMs) has primarily examined these systems as single entities with fixed viewpoints. While various methods exist for measuring such biases, the impact of persona-based prompting on LLMs' political orientation remains unexplored. In this work we leverage PersonaHub, a collection of synthetic persona descriptions, to map the political distribution of persona-based prompted LLMs using the Political Compass Test (PCT). We then examine whether these initial compass distributions can be manipulated through explicit ideological prompting towards diametrically opposed political orientations: right-authoritarian and left-libertarian. Our experiments reveal that synthetic personas predominantly cluster in the left-libertarian quadrant, with models demonstrating varying degrees of responsiveness when prompted with explicit ideological descriptors. While all models demonstrate significant shifts towards right-authoritarian positions, they exhibit more limited shifts towards left-libertarian positions, suggesting an asymmetric response to ideological manipulation that may reflect inherent biases in model training.", 'abstract_zh': '大型语言模型（LLMs）中的政治偏见分析主要将这些系统视为单一且具有固定观点的实体。虽然存在多种测量偏见的方法，但基于人设不断提示对LLMs政治倾向的影响尚未得到探索。在此工作中，我们利用PersonaHub（包含合成人设描述的集合），结合政治倾向测试（PCT），映射基于人设不断提示的LLMs的政治分布。我们随后探讨是否可以通过显性的意识形态提示，将这些初始的倾向分布操纵至完全对立的政治倾向：右翼极权主义和左翼自由主义。实验结果显示，合成人设主要聚类在左翼自由主义象限，当使用显性的意识形态描述符进行提示时，模型显示出不同程度的响应。尽管所有模型都表现出向右翼极权主义倾向的显著转变，但它们向左翼自由主义倾向的转变则更为有限，这表明模型对意识形态操纵的响应是非对称的，这可能反映了模型训练中固有的偏见。', 'title_zh': '使用合成人格映射和影响大规模语言模型的政治意识形态'}
{'arxiv_id': 'arXiv:2412.14841', 'title': 'Helping LLMs Improve Code Generation Using Feedback from Testing and Static Analysis', 'authors': 'Greta Dolcetti, Vincenzo Arceri, Eleonora Iotti, Sergio Maffeis, Agostino Cortesi, Enea Zaffanella', 'link': 'https://arxiv.org/abs/2412.14841', 'abstract': 'Large Language Models (LLMs) are one of the most promising developments in the field of artificial intelligence, and the software engineering community has readily noticed their potential role in the software development life-cycle. Developers routinely ask LLMs to generate code snippets, increasing productivity but also potentially introducing ownership, privacy, correctness, and security issues. Previous work highlighted how code generated by mainstream commercial LLMs is often not safe, containing vulnerabilities, bugs, and code smells. In this paper, we present a framework that leverages testing and static analysis to assess the quality, and guide the self-improvement, of code generated by general-purpose, open-source LLMs.\nFirst, we ask LLMs to generate C code to solve a number of programming tasks. Then we employ ground-truth tests to assess the (in)correctness of the generated code, and a static analysis tool to detect potential safety vulnerabilities. Next, we assess the models ability to evaluate the generated code, by asking them to detect errors and vulnerabilities. Finally, we test the models ability to fix the generated code, providing the reports produced during the static analysis and incorrectness evaluation phases as feedback.\nOur results show that models often produce incorrect code, and that the generated code can include safety issues. Moreover, they perform very poorly at detecting either issue. On the positive side, we observe a substantial ability to fix flawed code when provided with information about failed tests or potential vulnerabilities, indicating a promising avenue for improving the safety of LLM-based code generation tools.', 'abstract_zh': '大型语言模型（LLMs）是人工智能领域最具前景的发展之一，软件工程社区已经注意到它们在软件开发生命周期中的潜在作用。开发人员经常要求LLMs生成代码片段，这虽然提高了生产效率，但也可能引入所有权、隐私、正确性和安全性问题。先前的研究强调，主流商用LLMs生成的代码往往不够安全，常常包含漏洞、错误和代码异味。在本文中，我们提出了一种框架，利用测试和静态分析来评估由通用开源LLMs生成的代码的质量，并引导其自我改进。\n\n首先，我们要求LLMs生成C代码以解决多种编程任务。然后，我们使用真实测试来评估生成代码的正确性，并使用静态分析工具检测潜在的安全漏洞。接下来，我们评估模型评估生成代码的能力，通过要求它们检测错误和漏洞。最后，我们测试模型修复生成代码的能力，将静态分析和不正确性评估阶段产生的报告作为反馈。\n\n我们的结果表明，模型经常生成不正确的代码，并且生成的代码中可能包含安全问题。此外，它们在检测这些问题方面表现非常不佳。在积极的一面，我们观察到，在提供有关失败测试或潜在漏洞的信息时，模型具有修复受损代码的显著能力，这表明可以通过改进LLM基代码生成工具的安全性来开辟一条有希望的道路。', 'title_zh': '使用测试和静态分析反馈帮助大语言模型提升代码生成能力'}
{'arxiv_id': 'arXiv:2412.14835', 'title': 'Progressive Multimodal Reasoning via Active Retrieval', 'authors': 'Guanting Dong, Chenghao Zhang, Mengjie Deng, Yutao Zhu, Zhicheng Dou, Ji-Rong Wen', 'link': 'https://arxiv.org/abs/2412.14835', 'abstract': 'Multi-step multimodal reasoning tasks pose significant challenges for multimodal large language models (MLLMs), and finding effective ways to enhance their performance in such scenarios remains an unresolved issue. In this paper, we propose AR-MCTS, a universal framework designed to progressively improve the reasoning capabilities of MLLMs through Active Retrieval (AR) and Monte Carlo Tree Search (MCTS). Our approach begins with the development of a unified retrieval module that retrieves key supporting insights for solving complex reasoning problems from a hybrid-modal retrieval corpus. To bridge the gap in automated multimodal reasoning verification, we employ the MCTS algorithm combined with an active retrieval mechanism, which enables the automatic generation of step-wise annotations. This strategy dynamically retrieves key insights for each reasoning step, moving beyond traditional beam search sampling to improve the diversity and reliability of the reasoning space. Additionally, we introduce a process reward model that aligns progressively to support the automatic verification of multimodal reasoning tasks. Experimental results across three complex multimodal reasoning benchmarks confirm the effectiveness of the AR-MCTS framework in enhancing the performance of various multimodal models. Further analysis demonstrates that AR-MCTS can optimize sampling diversity and accuracy, yielding reliable multimodal reasoning.', 'abstract_zh': '多步多模态推理任务对多模态大型语言模型（MLLMs）提出了显著挑战，如何在这些场景中有效提升其性能依然是未解决的问题。本文提出了一种名为AR-MCTS的通用框架，旨在通过主动检索（AR）和蒙特卡洛树搜索（MCTS）逐步提高MLLMs的推理能力。我们的方法首先开发了一个统一的检索模块，从混合模态检索语料库中获取解决复杂推理问题的关键支持见解。为弥合自动多模态推理验证中的差距，我们采用MCTS算法结合主动检索机制，自动生成逐步标注。该策略动态检索每个推理步骤的关键见解，超越了传统的束搜索抽样，以提高推理空间的多样性和可靠性。此外，我们引入了一个过程奖励模型，该模型逐渐对齐以支持多模态推理任务的自动验证。在三个复杂的多模态推理基准测试中的实验结果证明了AR-MCTS框架在提高各种多模态模型性能方面的有效性。进一步分析表明，AR-MCTS可以优化采样多样性和准确性，从而实现可靠的多模态推理。', 'title_zh': '渐进多模态推理通过主动检索实现'}
{'arxiv_id': 'arXiv:2412.14810', 'title': 'MARIA: a Multimodal Transformer Model for Incomplete Healthcare Data', 'authors': 'Camillo Maria Caruso, Paolo Soda, Valerio Guarrasi', 'link': 'https://arxiv.org/abs/2412.14810', 'abstract': 'In healthcare, the integration of multimodal data is pivotal for developing comprehensive diagnostic and predictive models. However, managing missing data remains a significant challenge in real-world applications. We introduce MARIA (Multimodal Attention Resilient to Incomplete datA), a novel transformer-based deep learning model designed to address these challenges through an intermediate fusion strategy. Unlike conventional approaches that depend on imputation, MARIA utilizes a masked self-attention mechanism, which processes only the available data without generating synthetic values. This approach enables it to effectively handle incomplete datasets, enhancing robustness and minimizing biases introduced by imputation methods. We evaluated MARIA against 10 state-of-the-art machine learning and deep learning models across 8 diagnostic and prognostic tasks. The results demonstrate that MARIA outperforms existing methods in terms of performance and resilience to varying levels of data incompleteness, underscoring its potential for critical healthcare applications.', 'abstract_zh': '在医疗保健领域，多模态数据的整合对于开发全面的诊断和预测模型至关重要。然而，管理缺失数据仍然是实际应用中的一个重要挑战。我们提出了MARIA（Multimodal Attention Resilient to Incomplete datA），这是一种基于transformer的深度学习模型，旨在通过中间融合策略解决这些挑战。与依赖于数据填充的传统方法不同，MARIA使用掩蔽自注意力机制，仅处理可用数据而不生成合成值。这种方法使MARIA能够有效地处理不完整的数据集，增强其鲁棒性并减少由填充方法引入的偏差。我们在8项诊断和预后任务中将MARIA与10种最先进的机器学习和深度学习模型进行了对比评估。结果表明，MARIA在性能和对不同数据缺失程度的鲁棒性方面优于现有方法，这凸显了其在关键医疗保健应用中的潜力。', 'title_zh': 'MARIA：一种用于不完整医疗数据的多模态变压器模型'}
{'arxiv_id': 'arXiv:2412.14802', 'title': 'Stack Trace Deduplication: Faster, More Accurately, and in More Realistic Scenarios', 'authors': 'Egor Shibaev, Denis Sushentsev, Yaroslav Golubev, Aleksandr Khvorov', 'link': 'https://arxiv.org/abs/2412.14802', 'abstract': 'In large-scale software systems, there are often no fully-fledged bug reports with human-written descriptions when an error occurs. In this case, developers rely on stack traces, i.e., series of function calls that led to the error. Since there can be tens and hundreds of thousands of them describing the same issue from different users, automatic deduplication into categories is necessary to allow for processing. Recent works have proposed powerful deep learning-based approaches for this, but they are evaluated and compared in isolation from real-life workflows, and it is not clear whether they will actually work well at scale.\nTo overcome this gap, this work presents three main contributions: a novel model, an industry-based dataset, and a multi-faceted evaluation. Our model consists of two parts - (1) an embedding model with byte-pair encoding and approximate nearest neighbor search to quickly find the most relevant stack traces to the incoming one, and (2) a reranker that re-ranks the most fitting stack traces, taking into account the repeated frames between them. To complement the existing datasets collected from open-source projects, we share with the community SlowOps - a dataset of stack traces from IntelliJ-based products developed by JetBrains, which has an order of magnitude more stack traces per category. Finally, we carry out an evaluation that strives to be realistic: measuring not only the accuracy of categorization, but also the operation time and the ability to create new categories. The evaluation shows that our model strikes a good balance - it outperforms other models on both open-source datasets and SlowOps, while also being faster on time than most. We release all of our code and data, and hope that our work can pave the way to further practice-oriented research in the area.', 'abstract_zh': '在大规模软件系统中，当发生错误时，通常没有包含完整的人工描述的正式错误报告。在这种情况下，开发者依赖于栈跟踪信息，即导致错误的一系列函数调用。由于数千甚至数万条栈跟踪可能描述相同的错误问题，因此需要自动将其归类以便处理。最近的研究提出了基于深度学习的强大方法来实现这一点，但这些方法往往是孤立地评估和比较的，并不清楚它们在大规模应用中是否能够很好地工作。\n\n为了解决这一问题，本项工作提出了三个主要贡献：一种新型模型、一个基于工业实践的数据集以及一个多维度评估方法。我们的模型分为两个部分：（1）一个嵌入模型，使用字对编码和近似最近邻搜索算法，以快速找到与新收到的栈跟踪最相关的那些栈跟踪；（2）一个再排序器，可以重新排名最符合的栈跟踪，并考虑它们之间重复的帧。为了补充现有的从开源项目中收集的数据集，我们与社区共享了SlowOps数据集——一个由JetBrains开发的基于IntelliJ的产品的栈跟踪数据集，每个类别中的栈跟踪数量是现有数据集的量级数量。最后，我们进行了一个力求真实的评估：不仅要衡量分类的准确性，还要衡量操作时间和创建新类别的能力。评估结果显示，我们的模型在平衡各方面性能上表现出色——在开源数据集和SlowOps数据集上的性能都优于其他模型，同时在时间上也比大多数模型更快。我们已开源了所有代码和数据，并希望我们的工作能够引领更多实践导向的研究。', 'title_zh': '栈跟踪去重：更快速、更准确，并且在更多现实场景中实现'}
{'arxiv_id': 'arXiv:2412.14779', 'title': 'Agent-Temporal Credit Assignment for Optimal Policy Preservation in Sparse Multi-Agent Reinforcement Learning', 'authors': 'Aditya Kapoor, Sushant Swamy, Kale-ab Tessera, Mayank Baranwal, Mingfei Sun, Harshad Khadilkar, Stefano V. Albrecht', 'link': 'https://arxiv.org/abs/2412.14779', 'abstract': 'In multi-agent environments, agents often struggle to learn optimal policies due to sparse or delayed global rewards, particularly in long-horizon tasks where it is challenging to evaluate actions at intermediate time steps. We introduce Temporal-Agent Reward Redistribution (TAR$^2$), a novel approach designed to address the agent-temporal credit assignment problem by redistributing sparse rewards both temporally and across agents. TAR$^2$ decomposes sparse global rewards into time-step-specific rewards and calculates agent-specific contributions to these rewards. We theoretically prove that TAR$^2$ is equivalent to potential-based reward shaping, ensuring that the optimal policy remains unchanged. Empirical results demonstrate that TAR$^2$ stabilizes and accelerates the learning process. Additionally, we show that when TAR$^2$ is integrated with single-agent reinforcement learning algorithms, it performs as well as or better than traditional multi-agent reinforcement learning methods.', 'abstract_zh': '在多智能体环境中，智能体经常难以学习到最优策略，尤其是由于全局奖励稀疏或延迟，以及在长期任务中评估中间时间步动作具有挑战性。为此，我们提出了时间-智能体奖励重新分配（TAR$^2$）方法，这是一种旨在通过时间和智能体间重新分配稀疏奖励来解决智能体-时间信用分配问题的新型方法。TAR$^2$ 将稀疏的全局奖励分解为特定时间步的奖励，并计算各智能体对该奖励的贡献。我们从理论上证明，TAR$^2$ 等同于基于潜在函数的奖励塑造，确保最优策略不变。实验证明，TAR$^2$ 可以稳定并加速学习过程。此外，我们展示了当将TAR$^2$ 与单智能体强化学习算法结合使用时，其效果至少与或优于传统的多智能体强化学习方法。', 'title_zh': '基于代理-时间的信用分配方法以实现稀疏多代理 reinforcement 学习中优化策略的保留'}
{'arxiv_id': 'arXiv:2412.14775', 'title': 'Energy and polarization based on-line interference mitigation in radio interferometry', 'authors': 'Sarod Yatawatta, Albert-Jan Boonstra, Chris P. Broekema', 'link': 'https://arxiv.org/abs/2412.14775', 'abstract': 'Radio frequency interference (RFI) is a persistent contaminant in terrestrial radio astronomy. While new radio interferometers are becoming operational, novel sources of RFI are also emerging. In order to strengthen the mitigation of RFI in modern radio interferometers, we propose an on-line RFI mitigation scheme that can be run in the correlator of such interferometers. We combine statistics based on the energy as well as the polarization alignment of the correlated signal to develop an on-line RFI mitigation scheme that can be applied to a data stream produced by the correlator in real-time, especially targeted at low duty-cycle or transient RFI detection. In order to improve the computational efficiency, we explore the use of both single precision and half precision floating point operations in implementing the RFI mitigation algorithm. This ideally suits its deployment in accelerator computing devices such as graphics processing units (GPUs) as used by the LOFAR correlator. We provide results based on real data to demonstrate the efficacy of the proposed method.', 'abstract_zh': '射频干扰（RFI）是地面射电天文观测中的持续性污染源。随着新型射电干涉仪的投入使用，新的RFI源也在不断涌现。为了加强现代射电干涉仪中的RFI抑制，我们提出了一种在线RFI抑制方案，该方案可以在射电干涉仪的相干器中运行。我们结合相干信号的能量统计和极化对齐统计，开发了一种在线RFI抑制方案，可以在相干器生成的数据流中实时应用，特别适用于低占空比或瞬态RFI的检测。为了提高计算效率，我们探索了使用单精度浮点运算和半精度浮点运算来实现RFI抑制算法的可能性。这对使用图形处理单元（GPU）等加速计算设备的LOFAR相干器的部署尤其适用。我们基于实际数据提供结果，以证明所提出方法的有效性。', 'title_zh': '基于能量和极化在线干扰抑制的无线电干涉ometry方法'}
{'arxiv_id': 'arXiv:2412.14771', 'title': 'ALKAFI-LLAMA3: Fine-Tuning LLMs for Precise Legal Understanding in Palestine', 'authors': 'Rabee Qasem, Mohannad Hendi, Banan Tantour', 'link': 'https://arxiv.org/abs/2412.14771', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable potential in diverse domains, yet their application in the legal sector, particularly in low-resource contexts, remains limited. This study addresses the challenges of adapting LLMs to the Palestinian legal domain, where political instability, fragmented legal frameworks, and limited AI resources hinder effective machine-learning applications. We present a fine-tuned model based on a quantized version of Llama-3.2-1B-Instruct, trained on a synthetic data set derived from Palestinian legal texts. Using smaller-scale models and strategically generated question-answer pairs, we achieve a cost-effective, locally sustainable solution that provides accurate and contextually relevant legal guidance. Our experiments demonstrate promising performance on various query types, ranging from yes/no questions and narrative explanations to complex legal differentiations, while highlighting areas for improvement, such as handling calculation-based inquiries and structured list formatting. This work provides a pathway for the deployment of AI-driven legal assistance tools tailored to the needs of resource-constrained environments.', 'abstract_zh': '大型语言模型（LLMs）在众多领域展现了巨大的潜力，但在法律领域，特别是在资源贫乏的背景下，其应用仍然有限。本研究探讨了将LLMs适应巴勒斯坦法律领域的挑战，由于该地区的政治不稳定、法律框架碎片化以及有限的人工智能资源，有效的人工智能机器学习应用受到了阻碍。我们提出了一种基于量化版本Llama-3.2-1B-Instruct的微调模型，该模型在从巴勒斯坦法律文本中派生的合成数据集上进行训练。通过使用较小规模的模型和策略性生成的问题-答案对，我们实现了成本效益高、本地可持续的解决方案，提供了准确且上下文相关性的法律指导。我们的实验在各种查询类型上展示了积极的性能，包括是/否问题、叙述性解释以及复杂的法律区分，同时也指出了改进的方向，如处理基于计算的查询和结构化列表格式化。本研究为在资源受限环境中部署基于人工智能的法律辅助工具提供了途径。', 'title_zh': 'ALKAFI-LLAMA3：为了提升巴勒斯坦精准法律理解而微调的大语言模型'}
{'arxiv_id': 'arXiv:2412.14764', 'title': 'CodeRepoQA: A Large-scale Benchmark for Software Engineering Question Answering', 'authors': 'Ruida Hu, Chao Peng, Jingyi Ren, Bo Jiang, Xiangxin Meng, Qinyun Wu, Pengfei Gao, Xinchen Wang, Cuiyun Gao', 'link': 'https://arxiv.org/abs/2412.14764', 'abstract': "In this work, we introduce CodeRepoQA, a large-scale benchmark specifically designed for evaluating repository-level question-answering capabilities in the field of software engineering. CodeRepoQA encompasses five programming languages and covers a wide range of scenarios, enabling comprehensive evaluation of language models. To construct this dataset, we crawl data from 30 well-known repositories in GitHub, the largest platform for hosting and collaborating on code, and carefully filter raw data. In total, CodeRepoQA is a multi-turn question-answering benchmark with 585,687 entries, covering a diverse array of software engineering scenarios, with an average of 6.62 dialogue turns per entry.\nWe evaluate ten popular large language models on our dataset and provide in-depth analysis. We find that LLMs still have limitations in question-answering capabilities in the field of software engineering, and medium-length contexts are more conducive to LLMs' performance. The entire benchmark is publicly available at this https URL.", 'abstract_zh': '本文介绍了CodeRepoQA，这是一个大规模基准测试，专门用于评估软件工程领域中仓库级问题解答能力。CodeRepoQA 涵盖了五种编程语言，并涵盖了广泛的情景，能够全面评估语言模型。为了构建此数据集，我们从 GitHub（全球最大的代码托管和协作平台）中爬取了30个知名仓库的数据，并仔细筛选原始数据。总体而言，CodeRepoQA 是一个包含585,687条条目的多轮问答基准测试，涵盖了多种多样的软件工程场景，平均每条条目包含6.62轮对话。\n\n我们在该数据集上评估了十个流行的大型语言模型，并进行了详细分析。我们发现，大型语言模型在软件工程领域的问答能力仍然存在局限性，中等长度的上下文更有利于提升其表现。整个基准测试已经公开发布，可通过以下链接访问：[公开链接]。', 'title_zh': 'CodeRepoQA：软件工程问答的大规模基准'}
{'arxiv_id': 'arXiv:2412.14736', 'title': 'Advances in Artificial Intelligence forDiabetes Prediction: Insights from a Systematic Literature Review', 'authors': 'Pir Bakhsh Khokhar, Carmine Gravino, Fabio Palomba', 'link': 'https://arxiv.org/abs/2412.14736', 'abstract': 'This systematic review explores the use of machine learning (ML) in predicting diabetes, focusing on datasets, algorithms, training methods, and evaluation metrics. It examines datasets like the Singapore National Diabetic Retinopathy Screening program, REPLACE-BG, National Health and Nutrition Examination Survey, and Pima Indians Diabetes Database. The review assesses the performance of ML algorithms like CNN, SVM, Logistic Regression, and XGBoost in predicting diabetes outcomes. The study emphasizes the importance of interdisciplinary collaboration and ethical considerations in ML-based diabetes prediction models.', 'abstract_zh': '本系统综述探讨了机器学习（ML）在糖尿病预测中的应用，重点关注数据集、算法、训练方法和评估指标。研究分析了包括新加坡国家糖尿病视网膜病变筛查项目、REPLACE-BG、全国健康与营养状况调查(NHANES)以及培美印第安人糖尿病数据库在内的数据集。综述评估了如卷积神经网络（CNN）、支持向量机（SVM）、逻辑回归和XGBoost等机器学习算法在预测糖尿病结果方面的表现。研究强调了在基于机器学习的糖尿病预测模型中跨学科合作和伦理考量的重要性。', 'title_zh': '人工智能在糖尿病预测中的进展：系统文献综述的见解'}
{'arxiv_id': 'arXiv:2412.14732', 'title': 'Beyond the Hype: A Comprehensive Review of Current Trends in Generative AI Research, Teaching Practices, and Tools', 'authors': 'James Prather, Juho Leinonen, Natalie Kiesler, Jamie Gorson Benario, Sam Lau, Stephen MacNeil, Narges Norouzi, Simone Opel, Vee Pettit, Leo Porter, Brent N. Reeves, Jaromir Savelka, David H. Smith IV, Sven Strickroth, Daniel Zingaro', 'link': 'https://arxiv.org/abs/2412.14732', 'abstract': 'Generative AI (GenAI) is advancing rapidly, and the literature in computing education is expanding almost as quickly. Initial responses to GenAI tools were mixed between panic and utopian optimism. Many were fast to point out the opportunities and challenges of GenAI. Researchers reported that these new tools are capable of solving most introductory programming tasks and are causing disruptions throughout the curriculum. These tools can write and explain code, enhance error messages, create resources for instructors, and even provide feedback and help for students like a traditional teaching assistant. In 2024, new research started to emerge on the effects of GenAI usage in the computing classroom. These new data involve the use of GenAI to support classroom instruction at scale and to teach students how to code with GenAI. In support of the former, a new class of tools is emerging that can provide personalized feedback to students on their programming assignments or teach both programming and prompting skills at the same time. With the literature expanding so rapidly, this report aims to summarize and explain what is happening on the ground in computing classrooms. We provide a systematic literature review; a survey of educators and industry professionals; and interviews with educators using GenAI in their courses, educators studying GenAI, and researchers who create GenAI tools to support computing education. The triangulation of these methods and data sources expands the understanding of GenAI usage and perceptions at this critical moment for our community.', 'abstract_zh': '生成型人工智能（GenAI）正在迅速发展，计算教育领域的研究文献也在几乎同样快速地扩展。最初对GenAI工具的反应是混合的，既有恐慌也有乌托邦式的乐观。许多人迅速指出了GenAI的机会和挑战。研究人员报告称，这些新工具能够解决大部分入门级编程任务，并在整个课程中引发冲击。这些工具可以编写和解释代码、增强错误信息、为教师创建资源，甚至像传统助教一样给予反馈和帮助。2024年，关于GenAI在计算课堂中的使用效果的研究开始涌现。这些新数据涉及使用GenAI支持大规模课堂教学，以及教授学生如何使用GenAI编程。为了支持前者，正在出现一种新的工具类别，可以针对学生的编程作业提供个性化反馈，同时教授编程和提示技能。由于文献扩展得如此迅速，本报告旨在总结和解释在计算课堂中正在发生的情况。我们提供了一个系统的文献综述；对教育工作者和行业专业人士进行了调查；并与正在其课程中使用GenAI的教育工作者、研究GenAI的教育工作者以及创建支持计算教育的GenAI工具的研究人员进行了访谈。这些方法和数据来源的三角分析在这一关键时刻深化了我们对GenAI使用和认知的理解。', 'title_zh': '超越 hype：生成式人工智能研究、教学实践及工具的综合回顾'}
{'arxiv_id': 'arXiv:2412.14689', 'title': 'How to Synthesize Text Data without Model Collapse?', 'authors': 'Xuekai Zhu, Daixuan Cheng, Hengli Li, Kaiyan Zhang, Ermo Hua, Xingtai Lv, Ning Ding, Zhouhan Lin, Zilong Zheng, Bowen Zhou', 'link': 'https://arxiv.org/abs/2412.14689', 'abstract': 'Model collapse in synthetic data indicates that iterative training on self-generated data leads to a gradual decline in performance. With the proliferation of AI models, synthetic data will fundamentally reshape the web data ecosystem. Future GPT-$\\{n\\}$ models will inevitably be trained on a blend of synthetic and human-produced data. In this paper, we focus on two questions: what is the impact of synthetic data on language model training, and how to synthesize data without model collapse? We first pre-train language models across different proportions of synthetic data, revealing a negative correlation between the proportion of synthetic data and model performance. We further conduct statistical analysis on synthetic data to uncover distributional shift phenomenon and over-concentration of n-gram features. Inspired by the above findings, we propose token editing on human-produced data to obtain semi-synthetic data. As a proof of concept, we theoretically demonstrate that token-level editing can prevent model collapse, as the test error is constrained by a finite upper bound. We conduct extensive experiments on pre-training from scratch, continual pre-training, and supervised fine-tuning. The results validate our theoretical proof that token-level editing improves data quality and enhances model performance.', 'abstract_zh': '合成数据中的模型退化表明，迭代训练自生成数据会导致性能逐步下降。随着人工智能模型的普及，合成数据将从根本上重塑网络数据生态。未来的GPT-$\\{n\\}$模型不可避免地会在合成数据和人工生成数据的混合集上进行训练。在本文中，我们重点关注两个问题：合成数据对语言模型训练的影响是什么？如何合成数据而不发生模型退化？我们首先在不同比例的合成数据下预训练语言模型，发现合成数据的比例与模型性能之间存在负相关。为进一步分析合成数据，我们进行了统计分析，揭示了分布偏移现象和n-克gram特征的过度集中。受上述发现的启发，我们提出了在人工生成数据上进行标记编辑以获得半合成数据的方法。作为概念验证，我们从理论上证明了标记级编辑可以防止模型退化，因为测试误差被有限的上限所制约。我们在从零开始的预训练、连续预训练和监督微调等多种实验中进行了广泛测试。结果验证了我们的理论证明，标记级编辑提高了数据质量并增强了模型性能。', 'title_zh': '如何合成文本数据而避免模型坍塌？'}
{'arxiv_id': 'arXiv:2412.14686', 'title': 'Each Fake News is Fake in its Own Way: An Attribution Multi-Granularity Benchmark for Multimodal Fake News Detection', 'authors': 'Hao Guo, Zihan Ma, Zhi Zeng, Minnan Luo, Weixin Zeng, Jiuyang Tang, Xiang Zhao', 'link': 'https://arxiv.org/abs/2412.14686', 'abstract': 'Social platforms, while facilitating access to information, have also become saturated with a plethora of fake news, resulting in negative consequences. Automatic multimodal fake news detection is a worthwhile pursuit. Existing multimodal fake news datasets only provide binary labels of real or fake. However, real news is alike, while each fake news is fake in its own way. These datasets fail to reflect the mixed nature of various types of multimodal fake news. To bridge the gap, we construct an attributing multi-granularity multimodal fake news detection dataset \\amg, revealing the inherent fake pattern. Furthermore, we propose a multi-granularity clue alignment model \\our to achieve multimodal fake news detection and attribution. Experimental results demonstrate that \\amg is a challenging dataset, and its attribution setting opens up new avenues for future research.', 'abstract_zh': '社交媒体平台虽在信息获取方面提供了便利，但也充斥着大量假新闻，导致了一系列负面后果。自动多模态假新闻检测是一项值得努力的方向。现有的多模态假新闻数据集仅提供了真实或虚假的二元标签。然而，实际新闻虽然相似，但每条假新闻都有其独特性。这些数据集未能反映各种类型多模态假新闻的复杂性质。为填补这一缺口，我们构建了一个具有归属性多粒度多模态假新闻检测数据集 \\AMG，揭示了内含的假新闻模式。进一步地，我们提出了一种多粒度线索对齐模型 \\Our，以实现多模态假新闻的检测和归属。实验结果表明，\\AMG 是一个具有挑战性的数据集，其归属设定为未来研究开辟了新的方向。', 'title_zh': '每条虚假新闻都有其独特的虚假之处：多模态虚假新闻检测的归因多粒度基准'}
{'arxiv_id': 'arXiv:2412.14680', 'title': 'A Light-Weight Framework for Open-Set Object Detection with Decoupled Feature Alignment in Joint Space', 'authors': 'Yonghao He, Hu Su, Haiyong Yu, Cong Yang, Wei Sui, Cong Wang, Song Liu', 'link': 'https://arxiv.org/abs/2412.14680', 'abstract': 'Open-set object detection (OSOD) is highly desirable for robotic manipulation in unstructured environments. However, existing OSOD methods often fail to meet the requirements of robotic applications due to their high computational burden and complex deployment. To address this issue, this paper proposes a light-weight framework called Decoupled OSOD (DOSOD), which is a practical and highly efficient solution to support real-time OSOD tasks in robotic systems. Specifically, DOSOD builds upon the YOLO-World pipeline by integrating a vision-language model (VLM) with a detector. A Multilayer Perceptron (MLP) adaptor is developed to transform text embeddings extracted by the VLM into a joint space, within which the detector learns the region representations of class-agnostic proposals. Cross-modality features are directly aligned in the joint space, avoiding the complex feature interactions and thereby improving computational efficiency. DOSOD operates like a traditional closed-set detector during the testing phase, effectively bridging the gap between closed-set and open-set detection. Compared to the baseline YOLO-World, the proposed DOSOD significantly enhances real-time performance while maintaining comparable accuracy. The slight DOSOD-S model achieves a Fixed AP of $26.7\\%$, compared to $26.2\\%$ for YOLO-World-v1-S and $22.7\\%$ for YOLO-World-v2-S, using similar backbones on the LVIS minival dataset. Meanwhile, the FPS of DOSOD-S is $57.1\\%$ higher than YOLO-World-v1-S and $29.6\\%$ higher than YOLO-World-v2-S. Meanwhile, we demonstrate that the DOSOD model facilitates the deployment of edge devices. The codes and models are publicly available at this https URL.', 'abstract_zh': '开放集目标检测（Open-set Object Detection, OSOD）在无结构环境中机器人操作中有很高的需求。然而，现有的OSOD方法由于计算负担重和部署复杂，往往无法满足机器人应用的要求。为了解决这一问题，本文提出了一种轻量级框架，称为分离式OSOD（Decoupled OSOD, DOSOD），这是一种在机器人系统中支持实时OSOD任务的实用且高效解决方案。具体而言，DOSOD在YOLO-World流水线的基础上，通过结合视觉语言模型（Vision-Language Model, VLM）和检测器来构建。开发了一个多层感知器（Multilayer Perceptron, MLP）适配器，将VLM提取的文本嵌入转换到一个联合空间，在这个空间中，检测器可以学习通用提议的区域表示。多模态特征直接在联合空间中对齐，避免了复杂的特征交互，从而提高计算效率。在测试阶段，DOSOD像传统的封闭集检测器一样运行，有效缩小了封闭集和开放集检测之间的差距。与基线YOLO-World相比，提出的DOSOD显著提高了实时性能，同时保持了相当的准确性。DOSOD-S模型在LVIS minival数据集上使用类似骨干网络时，固定平均精度（Fixed AP）达到了26.7%，分别比YOLO-World-v1-S和YOLO-World-v2-S高出0.5%和4p0%。同时，DOSOD-S的FPS比YOLO-World-v1-S高57.1%，比YOLO-World-v2-S高29.6%。此外，我们还展示了DOSOD模型为边缘设备的部署提供了便利。关于开源代码和模型可以访问以下链接： [该网址]。', 'title_zh': '面向联合空间解耦特征对齐的开集物体检测轻量级框架'}
{'arxiv_id': 'arXiv:2412.14672', 'title': 'FiVL: A Framework for Improved Vision-Language Alignment', 'authors': 'Estelle Aflalo, Gabriela Ben Melech Stan, Tiep Le, Man Luo, Shachar Rosenman, Sayak Paul, Shao-Yen Tseng, Vasudev Lal', 'link': 'https://arxiv.org/abs/2412.14672', 'abstract': "Large Vision Language Models (LVLMs) have achieved significant progress in integrating visual and textual inputs for multimodal reasoning. However, a recurring challenge is ensuring these models utilize visual information as effectively as linguistic content when both modalities are necessary to formulate an accurate answer. We hypothesize that hallucinations arise due to the lack of effective visual grounding in current LVLMs. This issue extends to vision-language benchmarks, where it is difficult to make the image indispensable for accurate answer generation, particularly in vision question-answering tasks. In this work, we introduce FiVL, a novel method for constructing datasets designed to train LVLMs for enhanced visual grounding and to evaluate their effectiveness in achieving it. These datasets can be utilized for both training and assessing an LVLM's ability to use image content as substantive evidence rather than relying solely on linguistic priors, providing insights into the model's reliance on visual information. To demonstrate the utility of our dataset, we introduce an innovative training task that outperforms baselines alongside a validation method and application for explainability. The code is available at this https URL.", 'abstract_zh': '大规模视觉语言模型（LVLMs）已经在融合视觉和文本输入以进行多模态推理方面取得了显著进展。然而，一个反复出现的挑战在于确保这些模型在需要同时使用视觉信息和语言内容来形成准确答案时，能够有效地利用视觉信息。我们认为幻觉现象源于当前LVLMs中缺乏有效的视觉定位能力。这一问题也扩展到了视觉语言基准测试，在这些测试中，要让图像成为生成准确答案不可或缺的因素，尤其是在视觉问答任务中尤为困难。在本文中，我们提出了FiVL，一种新颖的数据集构建方法，旨在训练LVLMs以增强视觉定位能力，并评估其在该方面取得的效果。这些数据集既可用于训练，也可用于评估LVLMs利用图像内容作为实质性证据的能力，而不是仅仅依赖于语言先验，从而为模型依赖视觉信息的程度提供见解。为了展示我们数据集的有效性，我们引入了一种创新的训练任务，该任务在基准测试中表现出色，并提出了验证方法和解释性的应用。相关代码可在以下链接获取：this https URL。', 'title_zh': 'FiVL：一种改进的视觉-语言对齐框架'}
{'arxiv_id': 'arXiv:2412.14670', 'title': 'Analysis and Visualization of Linguistic Structures in Large Language Models: Neural Representations of Verb-Particle Constructions in BERT', 'authors': 'Hassane Kissane, Achim Schilling, Patrick Krauss', 'link': 'https://arxiv.org/abs/2412.14670', 'abstract': "This study investigates the internal representations of verb-particle combinations within transformer-based large language models (LLMs), specifically examining how these models capture lexical and syntactic nuances at different neural network layers. Employing the BERT architecture, we analyse the representational efficacy of its layers for various verb-particle constructions such as 'agree on', 'come back', and 'give up'. Our methodology includes a detailed dataset preparation from the British National Corpus, followed by extensive model training and output analysis through techniques like multi-dimensional scaling (MDS) and generalized discrimination value (GDV) calculations. Results show that BERT's middle layers most effectively capture syntactic structures, with significant variability in representational accuracy across different verb categories. These findings challenge the conventional uniformity assumed in neural network processing of linguistic elements and suggest a complex interplay between network architecture and linguistic representation. Our research contributes to a better understanding of how deep learning models comprehend and process language, offering insights into the potential and limitations of current neural approaches to linguistic analysis. This study not only advances our knowledge in computational linguistics but also prompts further research into optimizing neural architectures for enhanced linguistic precision.", 'abstract_zh': '本研究探讨了基于Transformer的大型语言模型（LLMs）中动词-粒子组合的内部表示方式，特别研究了这些模型在不同神经网络层如何捕捉词汇和句法微妙之处。我们采用BERT架构，分析其各层对诸如"agree on"、"come back"和"give up"等动词-粒子构造的表示效果。研究方法包括从英国国家语料库提取详细的语料数据集，随后进行广泛的模型训练，并通过多维缩放（MDS）和广义判别值（GDV）计算等技术进行输出分析。结果表明，BERT的中间层最有效地捕捉句法结构，但不同动词类别的表示准确性存在显著差异。这些发现挑战了神经网络处理语言元素时的常规统一性，表明网络架构与语言表示之间存在复杂的相互作用。我们的研究有助于更好地理解深度学习模型如何理解和处理语言，提供了当前神经方法在语言分析中的潜力和局限性见解。本研究不仅推进了计算语言学领域的知识，还促使进一步研究以优化神经架构以提高语言精确度。', 'title_zh': '大型语言模型中的语言结构分析与可视化：BERT 中的动词-粒子结构的神经表示分析与可视化'}
{'arxiv_id': 'arXiv:2412.14668', 'title': 'LoLaFL: Low-Latency Federated Learning via Forward-only Propagation', 'authors': 'Jierui Zhang, Jianhao Huang, Kaibin Huang', 'link': 'https://arxiv.org/abs/2412.14668', 'abstract': 'Federated learning (FL) has emerged as a widely adopted paradigm for enabling edge learning with distributed data while ensuring data privacy. However, the traditional FL with deep neural networks trained via backpropagation can hardly meet the low-latency learning requirements in the sixth generation (6G) mobile networks. This challenge mainly arises from the high-dimensional model parameters to be transmitted and the numerous rounds of communication required for convergence due to the inherent randomness of the training process. To address this issue, we adopt the state-of-the-art principle of maximal coding rate reduction to learn linear discriminative features and extend the resultant white-box neural network into FL, yielding the novel framework of Low-Latency Federated Learning (LoLaFL) via forward-only propagation. LoLaFL enables layer-wise transmissions and aggregation with significantly fewer communication rounds, thereby considerably reducing latency. Additionally, we propose two \\emph{nonlinear} aggregation schemes for LoLaFL. The first scheme is based on the proof that the optimal NN parameter aggregation in LoLaFL should be harmonic-mean-like. The second scheme further exploits the low-rank structures of the features and transmits the low-rank-approximated covariance matrices of features to achieve additional latency reduction. Theoretic analysis and experiments are conducted to evaluate the performance of LoLaFL. In comparison with traditional FL, the two nonlinear aggregation schemes for LoLaFL can achieve reductions in latency of over 91\\% and 98\\%, respectively, while maintaining comparable accuracies.', 'abstract_zh': '联邦学习（FL）作为一种广泛采用的范式，能够通过分布式数据实现边缘学习，并且保证数据隐私。然而，传统的基于反向传播训练深度神经网络的FL难以满足第六代（6G）移动网络中的低延时学习要求。这一挑战主要源自于需要传输的高维模型参数以及由于训练过程固有的随机性而导致的大量通信轮次。为解决这一问题，我们采用最先进的最大编码率减少原理来学习线性判别特征，并将由此得到的白盒神经网络扩展到联邦学习中，从而构建出一种新的低延时联邦学习（LoLaFL）框架，采用仅前向传播的方式来实现。LoLaFL允许逐层传输和聚合，从而显著减少通信轮次，从而大幅降低延时。此外，我们为LoLaFL提出了两种非线性聚合方案。第一个方案基于这样一个证明：在LoLaFL中最优的神经网络参数聚合应类似于调和平均。第二个方案进一步利用特征的低秩结构，传输特征的低秩近似协方差矩阵，以实现额外的延时减少。我们通过理论分析和实验来评估LoLaFL的性能。与传统FL相比，LoLaFL的这两种非线性聚合方案分别实现了超过91%和98%的延时减少，同时保持了相近的准确率。', 'title_zh': 'LoLaFL：基于单向传播的低延迟联邦学习'}
{'arxiv_id': 'arXiv:2412.14663', 'title': 'IOHunter: Graph Foundation Model to Uncover Online Information Operations', 'authors': 'Marco Minici, Luca Luceri, Francesco Fabbri, Emilio Ferrara', 'link': 'https://arxiv.org/abs/2412.14663', 'abstract': 'Social media platforms have become vital spaces for public discourse, serving as modern agorás where a wide range of voices influence societal narratives. However, their open nature also makes them vulnerable to exploitation by malicious actors, including state-sponsored entities, who can conduct information operations (IOs) to manipulate public opinion. The spread of misinformation, false news, and misleading claims threatens democratic processes and societal cohesion, making it crucial to develop methods for the timely detection of inauthentic activity to protect the integrity of online discourse. In this work, we introduce a methodology designed to identify users orchestrating information operations, a.k.a. \\textit{IO drivers}, across various influence campaigns. Our framework, named \\texttt{IOHunter}, leverages the combined strengths of Language Models and Graph Neural Networks to improve generalization in \\emph{supervised}, \\emph{scarcely-supervised}, and \\emph{cross-IO} contexts. Our approach achieves state-of-the-art performance across multiple sets of IOs originating from six countries, significantly surpassing existing approaches. This research marks a step toward developing Graph Foundation Models specifically tailored for the task of IO detection on social media platforms.', 'abstract_zh': '社交媒体平台已成为公共讨论的关键空间，它们作为现代公共论坛，广泛的声音影响着社会叙事。然而，它们的开放性质也使它们容易被恶意行为者，包括国家资助的实体，利用来进行信息操作（IO），以操纵公众舆论。虚假信息、假新闻和误导性声明的传播威胁着民主程序和社会团结，因此及时检测不真实活动的方法变得至关重要，以保护在线讨论的完整性。在本研究中，我们提出了一种方法论，旨在跨多种影响运动识别策划信息操作的用户，即所谓的“信息操作驱动者”（IO drivers）。我们的框架命名为\\texttt{IOHunter}，利用语言模型和图神经网络的综合优势，在监督、少监督和跨信息操作（cross-IO）上下文中提高泛化能力。我们的方法在六个国家来源的多个信息操作集上取得了最先进的性能，显著超越了现有方法。这项研究标志着朝着为社交媒体平台上的信息操作检测任务开发专门的图基础模型迈出了重要的一步。', 'title_zh': 'IOHunter：基于图的基础模型以揭示在线信息操作\n\n解释：\n- "IOHunter" 是论文名称，保持不变。\n- "Graph Foundation Model" 转换为 "基于图的基础模型"，符合中文的表达习惯。\n- "Uncover Online Information Operations" 翻译为 "揭示在线信息操作"，准确传达原文含义。'}
{'arxiv_id': 'arXiv:2412.14660', 'title': 'Unveiling Uncertainty: A Deep Dive into Calibration and Performance of Multimodal Large Language Models', 'authors': 'Zijun Chen, Wenbo Hu, Guande He, Zhijie Deng, Zheng Zhang, Richang Hong', 'link': 'https://arxiv.org/abs/2412.14660', 'abstract': "Multimodal large language models (MLLMs) combine visual and textual data for tasks such as image captioning and visual question answering. Proper uncertainty calibration is crucial, yet challenging, for reliable use in areas like healthcare and autonomous driving. This paper investigates representative MLLMs, focusing on their calibration across various scenarios, including before and after visual fine-tuning, as well as before and after multimodal training of the base LLMs. We observed miscalibration in their performance, and at the same time, no significant differences in calibration across these scenarios. We also highlight how uncertainty differs between text and images and how their integration affects overall uncertainty. To better understand MLLMs' miscalibration and their ability to self-assess uncertainty, we construct the IDK (I don't know) dataset, which is key to evaluating how they handle unknowns. Our findings reveal that MLLMs tend to give answers rather than admit uncertainty, but this self-assessment improves with proper prompt adjustments. Finally, to calibrate MLLMs and enhance model reliability, we propose techniques such as temperature scaling and iterative prompt optimization. Our results provide insights into improving MLLMs for effective and responsible deployment in multimodal applications. Code and IDK dataset: \\href{this https URL}{this https URL}.", 'abstract_zh': '多模态大语言模型（MLLMs）结合视觉和文本数据，用于完成图像字幕、视觉问答等任务。在医学和自动驾驶等关键领域，MLLMs的恰当不确定性校准至关重要，但极具挑战性。本文探讨了代表性的MLLMs在不同场景下的校准情况，包括视觉微调前后以及基础大语言模型（LLM）进行多模态训练前后的情况。我们发现它们在性能上的校准存在偏差，但不同场景下的校准差异并不显著。此外，我们分析了文本和图像之间不确定性差异，以及它们的整合如何影响整体不确定性。为了更深入地理解MLLMs的偏差以及它们评估不确定性的能力，我们构建了IDK（我不知道）数据集，这对于评估它们处理未知情况的表现至关重要。我们的研究发现，MLLMs倾向于给出答案而不是承认不确定性，但通过适当的提示调整，这种自我评估能力得到了提升。最后，为了校准MLLMs并提高模型可靠性，我们提出了温度缩放和迭代提示优化等技术。我们的研究结果为在多模态应用中有效和负责任地部署MLLMs提供了进一步的见解。有关代码和IDK数据集，请参见以下链接：\\href{this https URL}{this https URL}。', 'title_zh': '揭开不确定性之面纱：多模态大型语言模型的校准与性能深入探究'}
{'arxiv_id': 'arXiv:2412.14640', 'title': 'Adaptive Prompt Tuning: Vision Guided Prompt Tuning with Cross-Attention for Fine-Grained Few-Shot Learning', 'authors': 'Eric Brouwer, Jan Erik van Woerden, Gertjan Burghouts, Matias Valedenegro-Toro, Marco Zullich', 'link': 'https://arxiv.org/abs/2412.14640', 'abstract': "Few-shot, fine-grained classification in computer vision poses significant challenges due to the need to differentiate subtle class distinctions with limited data. This paper presents a novel method that enhances the Contrastive Language-Image Pre-Training (CLIP) model through adaptive prompt tuning, guided by real-time visual inputs. Unlike existing techniques such as Context Optimization (CoOp) and Visual Prompt Tuning (VPT), which are constrained by static prompts or visual token reliance, the proposed approach leverages a cross-attention mechanism to dynamically refine text prompts for the image at hand. This enables an image-specific alignment of textual features with image patches extracted from the Vision Transformer, making the model more effective for datasets with high intra-class variance and low inter-class differences. The method is evaluated on several datasets, including CUBirds, Oxford Flowers, and FGVC Aircraft, showing significant performance gains over static prompt tuning approaches. To ensure these performance gains translate into trustworthy predictions, we integrate Monte-Carlo Dropout in our approach to improve the reliability of the model predictions and uncertainty estimates. This integration provides valuable insights into the model's predictive confidence, helping to identify when predictions can be trusted and when additional verification is necessary. This dynamic approach offers a robust solution, advancing the state-of-the-art for few-shot fine-grained classification.", 'abstract_zh': '计算机视觉中的少样本、细粒度分类由于需要在有限的数据下区分微妙的类别差异，面临着重大挑战。本文提出了一种创新方法，通过自适应提示调优增强对比语言-图像预训练（CLIP）模型，该方法受到实时视觉输入的引导。与现有的技术如上下文优化（CoOp）和视觉提示调优（VPT）相比，这些技术受限于静态提示或对视觉标记的依赖，本文提出的方法利用交叉注意力机制动态地细化当前图像对应的文本提示。这使得文本特征与来自视觉变换器提取的图像补丁实现特定于图像的对齐，从而提高了对于高类内变异性且类间差异较低的数据集的模型效果。该方法在CUBirds、Oxford Flowers和FGVC Aircraft等几个数据集上进行了评估，显示出比静态提示调优方法显著的性能提升。为了确保这些性能提升能够转化为可信赖的预测，我们在方法中整合了蒙特卡洛dropout技术，以提高模型预测的可靠性和不确定性估计。这种整合提供了关于模型预测置信度的宝贵见解，有助于识别可以信任的预测和需要验证的预测。这一动态方法提供了一种稳健的解决方案，推动了少样本细粒度分类的技术进步。', 'title_zh': '自适应提示调整：基于视觉的跨注意力提示调整方法在细粒度少样本学习中的应用'}
{'arxiv_id': 'arXiv:2412.14639', 'title': 'A Shapley Value Estimation Speedup for Efficient Explainable Quantum AI', 'authors': 'Iain Burge, Michel Barbeau, Joaquin Garcia-Alfaro', 'link': 'https://arxiv.org/abs/2412.14639', 'abstract': "This work focuses on developing efficient post-hoc explanations for quantum AI algorithms. In classical contexts, the cooperative game theory concept of the Shapley value adapts naturally to post-hoc explanations, where it can be used to identify which factors are important in an AI's decision-making process. An interesting question is how to translate Shapley values to the quantum setting and whether quantum effects could be used to accelerate their calculation. We propose quantum algorithms that can extract Shapley values within some confidence interval. Our method is capable of quadratically outperforming classical Monte Carlo approaches to approximating Shapley values up to polylogarithmic factors in various circumstances. We demonstrate the validity of our approach empirically with specific voting games and provide rigorous proofs of performance for general cooperative games.", 'abstract_zh': '本研究集中在开发高效的后验解释方法，用于量子人工智能算法。在经典情境下，合作博弈理论中的Shapley值概念自然适用于后验解释，可以用来识别AI决策过程中哪些因素是重要的。一个有趣的问题是如何将Shapley值转化为量子设定，并且量子效应是否能用于加速其计算。我们提出了一种量子算法，可以在一定的置信区间内提取Shapley值。该方法在某些情况下能够超越多项对数级的古典蒙特卡洛方法，表现出平方级的优越性能。我们通过特定投票博弈的实证研究证实了该方法的有效性，并为一般合作博弈提供了严格的性能证明。', 'title_zh': '一种用于高效可解释量子人工智能的Shapley值估计加速方法'}
{'arxiv_id': 'arXiv:2412.14633', 'title': 'Progressive Fine-to-Coarse Reconstruction for Accurate Low-Bit Post-Training Quantization in Vision Transformers', 'authors': 'Rui Ding, Liang Yong, Sihuan Zhao, Jing Nie, Lihui Chen, Haijun Liu, Xichuan Zhou', 'link': 'https://arxiv.org/abs/2412.14633', 'abstract': 'Due to its efficiency, Post-Training Quantization (PTQ) has been widely adopted for compressing Vision Transformers (ViTs). However, when quantized into low-bit representations, there is often a significant performance drop compared to their full-precision counterparts. To address this issue, reconstruction methods have been incorporated into the PTQ framework to improve performance in low-bit quantization settings. Nevertheless, existing related methods predefine the reconstruction granularity and seldom explore the progressive relationships between different reconstruction granularities, which leads to sub-optimal quantization results in ViTs. To this end, in this paper, we propose a Progressive Fine-to-Coarse Reconstruction (PFCR) method for accurate PTQ, which significantly improves the performance of low-bit quantized vision transformers. Specifically, we define multi-head self-attention and multi-layer perceptron modules along with their shortcuts as the finest reconstruction units. After reconstructing these two fine-grained units, we combine them to form coarser blocks and reconstruct them at a coarser granularity level. We iteratively perform this combination and reconstruction process, achieving progressive fine-to-coarse reconstruction. Additionally, we introduce a Progressive Optimization Strategy (POS) for PFCR to alleviate the difficulty of training, thereby further enhancing model performance. Experimental results on the ImageNet dataset demonstrate that our proposed method achieves the best Top-1 accuracy among state-of-the-art methods, particularly attaining 75.61% for 3-bit quantized ViT-B in PTQ. Besides, quantization results on the COCO dataset reveal the effectiveness and generalization of our proposed method on other computer vision tasks like object detection and instance segmentation.', 'abstract_zh': '由于其高效性，后训练量化（Post-Training Quantization，PTQ）在压缩视觉变换器（Vision Transformers，ViTs）方面得到了广泛应用。然而，在量化为低位表示时，ViTs 经常会与全精度版本相比表现出显著的性能下降。为解决这一问题，已有研究将重构方法纳入PTQ框架，以提高低位量化设置下的性能。尽管如此，现有的相关方法往往预先定义重构粒度，且很少探索不同重构粒度之间的逐步关系，导致ViTs 的量化结果不尽如人意。有鉴于此，本文提出了一种逐层精细至粗犷重构（Progressive Fine-to-Coarse Reconstruction，PFCR）方法，以实现准确的后训练量化，显著提高了低位量化视觉变换器的性能。具体而言，我们定义了多头自注意力模块、多层感知器模块及其捷径作为最精细的重构单元。在重构这两个精细单元后，我们将它们组合形成较粗的块，并在更粗的粒度上对其进行重构。我们迭代地执行这种组合与重构过程，实现逐层精细至粗犷的重构。此外，我们引入了一种逐层优化策略（Progressive Optimization Strategy，POS），以缓解训练难度，进一步增强模型性能。在ImageNet数据集上的实验结果表明，我们提出的方法在所有先进方法中取得了最出色的Top-1准确率，特别是在PTQ下3位量化ViT-B中达到了75.61%的准确率。此外，对COCO数据集的量化结果表明，我们提出的方法在诸如目标检测和实例分割等其他计算机视觉任务中具有有效性和普适性。', 'title_zh': '面向视觉 transformers 的分阶段细到粗重建方法以实现准确的低位宽训练后量化'}
{'arxiv_id': 'arXiv:2412.14626', 'title': 'Learning to Generate Research Idea with Dynamic Control', 'authors': 'Ruochen Li, Liqiang Jing, Chi Han, Jiawei Zhou, Xinya Du', 'link': 'https://arxiv.org/abs/2412.14626', 'abstract': 'The rapid advancements in large language models (LLMs) have demonstrated their potential to accelerate scientific discovery, particularly in automating the process of research ideation. LLM-based systems have shown promise in generating hypotheses and research ideas. However, current approaches predominantly rely on prompting-based pre-trained models, limiting their ability to optimize generated content effectively. Moreover, they also lack the capability to deal with the complex interdependence and inherent restrictions among novelty, feasibility, and effectiveness, which remains challenging due to the inherent trade-offs among these dimensions, such as the innovation-feasibility conflict. To address these limitations, we for the first time propose fine-tuning LLMs to be better idea proposers and introduce a novel framework that employs a two-stage approach combining Supervised Fine-Tuning (SFT) and controllable Reinforcement Learning (RL). In the SFT stage, the model learns foundational patterns from pairs of research papers and follow-up ideas. In the RL stage, multi-dimensional reward modeling, guided by fine-grained feedback, evaluates and optimizes the generated ideas across key metrics. Dimensional controllers enable dynamic adjustment of generation, while a sentence-level decoder ensures context-aware emphasis during inference. Our framework provides a balanced approach to research ideation, achieving high-quality outcomes by dynamically navigating the trade-offs among novelty, feasibility, and effectiveness.', 'abstract_zh': '大规模语言模型（LLMs）的迅猛发展已经展示了其在加速科学发现方面的潜力，尤其是在自动化研究构想过程方面。基于LLM的系统在生成假设和研究构想方面表现出一定的潜力。然而，当前的方法主要依赖于基于提示的预训练模型，这限制了它们对生成内容的有效优化。此外，它们还缺乏处理新颖性、可行性和有效性之间复杂互相关系和固有约束的能力，这些约束由于各维度之间固有的权衡（如创新与可行性的冲突）而难以克服。为解决这些问题，我们首次提出对LLMs进行微调，以使其更好地提出构想，并引入了一种新的框架，该框架采用了结合监督微调（SFT）和可控强化学习（RL）的两阶段方法。在SFT阶段，模型从科研论文及其后续构想的配对中学习基础模式。在RL阶段，通过细粒度反馈指导的多维度奖励建模评估并优化生成的构想，涵盖关键指标。维度控制器使生成过程动态调整，而句级解码器确保在推理时对上下文有意识的强调。我们的框架提供了一种平衡的研究构想方法，通过动态权衡新颖性、可行性和有效性，实现高质量的结果。', 'title_zh': '学习使用动态控制生成研究想法'}
{'arxiv_id': 'arXiv:2412.14619', 'title': 'Pitfalls of topology-aware image segmentation', 'authors': 'Alexander H. Berger, Laurin Lux, Alexander Weers, Martin Menten, Daniel Rueckert, Johannes C. Paetzold', 'link': 'https://arxiv.org/abs/2412.14619', 'abstract': "Topological correctness, i.e., the preservation of structural integrity and specific characteristics of shape, is a fundamental requirement for medical imaging tasks, such as neuron or vessel segmentation. Despite the recent surge in topology-aware methods addressing this challenge, their real-world applicability is hindered by flawed benchmarking practices. In this paper, we identify critical pitfalls in model evaluation that include inadequate connectivity choices, overlooked topological artifacts in ground truth annotations, and inappropriate use of evaluation metrics. Through detailed empirical analysis, we uncover these issues' profound impact on the evaluation and ranking of segmentation methods. Drawing from our findings, we propose a set of actionable recommendations to establish fair and robust evaluation standards for topology-aware medical image segmentation methods.", 'abstract_zh': '拓扑正确性，即保持结构完整性和特定形状特征的要求，是医学影像任务（如神经元或血管分割）中的基本需求。尽管近期在关注拓扑特性的方法方面取得了一定进展，但它们在实际应用中的普及受到了不良基准测试方法的阻碍。在本文中，我们识别出模型评估中的关键陷阱，包括不充分的连接性选择、未注意真实标签注释中的拓扑异常以及评价指标的不当使用。通过详细的实证分析，我们揭示了这些问题对分割方法的评估和排名产生的深远影响。结合我们的研究成果，我们提出了一套可操作的建议，以建立拓扑感知医学图像分割方法的公平和稳健的评价标准。', 'title_zh': '拓扑感知图像分割的局限性'}
{'arxiv_id': 'arXiv:2412.14617', 'title': 'How good is GPT at writing political speeches for the White House?', 'authors': 'Jacques Savoy', 'link': 'https://arxiv.org/abs/2412.14617', 'abstract': 'Using large language models (LLMs), computers are able to generate a written text in response to a us er request. As this pervasive technology can be applied in numerous contexts, this study analyses the written style of one LLM called GPT by comparing its generated speeches with those of the recent US presidents. To achieve this objective, the State of the Union (SOTU) addresses written by Reagan to Biden are contrasted to those produced by both GPT-3.5 and GPT-4.o versions. Compared to US presidents, GPT tends to overuse the lemma "we" and produce shorter messages with, on average, longer sentences. Moreover, GPT opts for an optimistic tone, opting more often for political (e.g., president, Congress), symbolic (e.g., freedom), and abstract terms (e.g., freedom). Even when imposing an author\'s style to GPT, the resulting speech remains distinct from addresses written by the target author. Finally, the two GPT versions present distinct characteristics, but both appear overall dissimilar to true presidential messages.', 'abstract_zh': '使用大规模语言模型（LLMs），计算机能够根据用户请求生成书面文本。由于这项普遍技术可以应用于多种情境，本研究通过对比一个名为GPT的LLM生成的演讲与近期美国总统的演讲，分析了GPT的书面风格。具体而言，通过对里根至拜登时期的所有国情咨文（SOTU）进行对比，研究了GPT-3.5和GPT-4版本生成的演讲。与美国总统的演讲相比，GPT倾向于过度使用“我们”这一词素，生成的演讲内容较短，平均而言句子更长。此外，GPT选择了一种更乐观的语调，更频繁地使用政治性词汇（例如，总统、国会），象征性词汇（例如，自由）和抽象词汇（例如，自由）。即使要求GPT模仿某一作者的风格，生成的演讲仍然与其目标作者的风格有显著差异。最后，GPT-3.5和GPT-4两种版本具有不同的特点，但总体上两者都不大类似于真实的总统演讲。', 'title_zh': 'GPT在为白宫撰写政治演说方面表现如何？'}
{'arxiv_id': 'arXiv:2412.14613', 'title': 'HarmonicEval: Multi-modal, Multi-task, Multi-criteria Automatic Evaluation Using a Vision Language Model', 'authors': 'Masanari Ohi, Masahiro Kaneko, Naoaki Okazaki, Nakamasa Inoue', 'link': 'https://arxiv.org/abs/2412.14613', 'abstract': 'Vision-language models (VLMs) have shown impressive abilities in text and image understanding. However, existing metrics for evaluating the text generated by VLMs focus exclusively on overall quality, leading to two limitations: 1) it is challenging to identify which aspects of the text need improvement from the overall score; 2) metrics may overlook specific evaluation criteria when predicting an overall score. To address these limitations, we propose HarmonicEval, a reference-free evaluation metric that aggregates criterion-wise scores to produce the overall score in a bottom-up manner. Furthermore, we construct the Multi-task Multi-criteria Human Evaluation (MMHE) dataset, which comprises 18,000 expert human judgments across four vision-language tasks. Our experiments demonstrate that HarmonicEval achieves higher correlations with human judgments than conventional metrics while providing numerical scores for each criterion.', 'abstract_zh': '视觉-语言模型（VLMs）在文本和图像理解方面展现出了令人印象深刻的性能。然而，现有用于评估VLMs生成文本的指标仅仅关注总体质量，这导致了两个局限性：1）从总体评分中难以识别需要改进的具体文本方面；2）指标可能在预测总体评分时忽视特定的评估标准。为解决这些局限性，我们提出了一种名为HarmonicEval的无参考评估指标，该指标通过自下而上的方式聚合各个标准的评分来生成总体评分。此外，我们构建了多任务多标准人类评估（MMHE）数据集，该数据集包含了4个视觉-语言任务中18,000名专家的人类判断。我们的实验表明，HarmonicEval在与人类判断的相关性方面优于传统指标，并且能够为每个标准提供数值评分。', 'title_zh': '谐波评估：利用视觉语言模型进行多模态、多任务、多标准自动化评估'}
{'arxiv_id': 'arXiv:2412.14602', 'title': 'Towards Scalable and Deep Graph Neural Networks via Noise Masking', 'authors': 'Yuxuan Liang, Wentao Zhang, Zeang Sheng, Ling Yang, Quanqing Xu, Jiawei Jiang, Yunhai Tong, Bin Cu', 'link': 'https://arxiv.org/abs/2412.14602', 'abstract': 'In recent years, Graph Neural Networks (GNNs) have achieved remarkable success in many graph mining tasks. However, scaling them to large graphs is challenging due to the high computational and storage costs of repeated feature propagation and non-linear transformation during training. One commonly employed approach to address this challenge is model-simplification, which only executes the Propagation (P) once in the pre-processing, and Combine (C) these receptive fields in different ways and then feed them into a simple model for better performance. Despite their high predictive performance and scalability, these methods still face two limitations. First, existing approaches mainly focus on exploring different C methods from the model perspective, neglecting the crucial problem of performance degradation with increasing P depth from the data-centric perspective, known as the over-smoothing problem. Second, pre-processing overhead takes up most of the end-to-end processing time, especially for large-scale graphs. To address these limitations, we present random walk with noise masking (RMask), a plug-and-play module compatible with the existing model-simplification works. This module enables the exploration of deeper GNNs while preserving their scalability. Unlike the previous model-simplification works, we focus on continuous P and found that the noise existing inside each P is the cause of the over-smoothing issue, and use the efficient masking mechanism to eliminate them. Experimental results on six real-world datasets demonstrate that model-simplification works equipped with RMask yield superior performance compared to their original version and can make a good trade-off between accuracy and efficiency.', 'abstract_zh': '近年来，图神经网络（GNNs）在许多图挖掘任务中取得了显著的成功。然而，将它们扩展到大规模图上具有挑战性，因为训练过程中重复特征传播和非线性变换的高计算和存储成本。为了解决这个问题，一种常见的方法是模型简化，该方法在预处理阶段只执行一次传播（P）操作，并通过不同方式结合（C）这些感受野，然后将它们输送到一个简单的模型以获得更好的性能。尽管这些方法在预测性能和可扩展性方面表现出色，但仍面临两个限制。首先，现有方法主要从模型的角度探索不同的C方法，忽视了数据为中心的角度下随着P深度增加而导致的性能下降问题，即过度平滑问题。其次，预处理开销占用了端到端处理时间的主要部分，尤其是在大规模图的情况下。为了解决这些限制，我们提出了一种名为随机游走结合噪声屏蔽（RMask）的插件模块，该模块兼容现有的模型简化工作，能够在保持可扩展性的同时探索更深的GNNs。与之前的模型简化方法不同，我们专注于连续的P操作，并发现存在于每个P内部的噪声是导致过度平滑问题的原因，使用高效的屏蔽机制来消除这些噪声。在六个真实数据集上的实验结果表明，配备RMask的模型简化方法相比其原始版本具有更好的性能，并能在准确性和效率之间取得良好的平衡。', 'title_zh': '通过噪声屏蔽实现可扩展且深度的图神经网络'}
{'arxiv_id': 'arXiv:2412.14587', 'title': 'Spike2Former: Efficient Spiking Transformer for High-performance Image Segmentation', 'authors': 'Zhenxin Lei, Man Yao, Jiakui Hu, Xinhao Luo, Yanye Lu, Bo Xu, Guoqi Li', 'link': 'https://arxiv.org/abs/2412.14587', 'abstract': 'Spiking Neural Networks (SNNs) have a low-power advantage but perform poorly in image segmentation tasks. The reason is that directly converting neural networks with complex architectural designs for segmentation tasks into spiking versions leads to performance degradation and non-convergence. To address this challenge, we first identify the modules in the architecture design that lead to the severe reduction in spike firing, make targeted improvements, and propose Spike2Former architecture. Second, we propose normalized integer spiking neurons to solve the training stability problem of SNNs with complex architectures. We set a new state-of-the-art for SNNs in various semantic segmentation datasets, with a significant improvement of +12.7% mIoU and 5.0 efficiency on ADE20K, +14.3% mIoU and 5.2 efficiency on VOC2012, and +9.1% mIoU and 6.6 efficiency on CityScapes.', 'abstract_zh': '脉冲神经网络（SNNs）具有低功耗的优势，但在图像分割任务中表现不佳。原因在于直接将具有复杂架构设计的神经网络转换为适合分割任务的脉冲版本会导致性能下降和无法收敛。为解决这一挑战，我们首先识别出导致脉冲放电严重下降的架构模块，并进行针对性改进，提出了Spike2Former架构。其次，我们提出了归一化整数脉冲神经元，以解决复杂架构SNNs在训练过程中的稳定性问题。我们在多个语义分割数据集上达到了SNNs的最新最佳性能，具体改进为ADE20K数据集上提升了12.7%的mIoU和5.0的效率，VOC2012数据集上提升了14.3%的mIoU和5.2的效率，CityScapes数据集上提升了9.1%的mIoU和6.6的效率。', 'title_zh': 'Spike2Former: 高效脉冲变换器，用于高性能图像分割'}
{'arxiv_id': 'arXiv:2412.14579', 'title': 'GSRender: Deduplicated Occupancy Prediction via Weakly Supervised 3D Gaussian Splatting', 'authors': 'Qianpu Sun, Changyong Shu, Sifan Zhou, Zichen Yu, Yan Chen, Dawei Yang, Yuan Chun', 'link': 'https://arxiv.org/abs/2412.14579', 'abstract': '3D occupancy perception is gaining increasing attention due to its capability to offer detailed and precise environment representations. Previous weakly-supervised NeRF methods balance efficiency and accuracy, with mIoU varying by 5-10 points due to sampling count along camera rays. Recently, real-time Gaussian splatting has gained widespread popularity in 3D reconstruction, and the occupancy prediction task can also be viewed as a reconstruction task. Consequently, we propose GSRender, which naturally employs 3D Gaussian Splatting for occupancy prediction, simplifying the sampling process. In addition, the limitations of 2D supervision result in duplicate predictions along the same camera ray. We implemented the Ray Compensation (RC) module, which mitigates this issue by compensating for features from adjacent frames. Finally, we redesigned the loss to eliminate the impact of dynamic objects from adjacent frames. Extensive experiments demonstrate that our approach achieves SOTA (state-of-the-art) results in RayIoU (+6.0), while narrowing the gap with 3D supervision methods. Our code will be released soon.', 'abstract_zh': '3D 占有率感知正逐渐受到关注，因为它能够提供详细和准确的环境表示。前期的弱监督 NeRF 方法在效率和准确性之间进行平衡，mIoU 范围为 5-10 个点，主要受到沿相机光线采样数量的影响。最近，实时高斯散斑技术在3D重建领域获得了广泛 popularity，而占有率预测任务也可以视为重建任务。因此，我们提出了 GSRender，该方法自然地利用 3D 高斯散斑进行占有率预测，简化了采样过程。此外，2D 监督的局限性会导致沿相同相机光线的重复预测。我们实现了 Ray Compensation（光线补偿）模块，通过补偿相邻帧中的特征来减轻这一问题。最后，我们重新设计了损失函数，以消除相邻帧中动态对象的影响。大量实验表明，我们的方法在 RayIoU 方面达到了 SOTA（目前最先进的）结果，同时缩小了与基于 3D 监督的方法之间的差距。我们的代码将很快发布。', 'title_zh': 'GSRender：通过弱监督3D 高斯点绘制实现的去重占用预测'}
{'arxiv_id': 'arXiv:2412.14571', 'title': 'SCKD: Semi-Supervised Cross-Modality Knowledge Distillation for 4D Radar Object Detection', 'authors': 'Ruoyu Xu, Zhiyu Xiang, Chenwei Zhang, Hanzhi Zhong, Xijun Zhao, Ruina Dang, Peng Xu, Tianyu Pu, Eryun Liu', 'link': 'https://arxiv.org/abs/2412.14571', 'abstract': '3D object detection is one of the fundamental perception tasks for autonomous vehicles. Fulfilling such a task with a 4D millimeter-wave radar is very attractive since the sensor is able to acquire 3D point clouds similar to Lidar while maintaining robust measurements under adverse weather. However, due to the high sparsity and noise associated with the radar point clouds, the performance of the existing methods is still much lower than expected. In this paper, we propose a novel Semi-supervised Cross-modality Knowledge Distillation (SCKD) method for 4D radar-based 3D object detection. It characterizes the capability of learning the feature from a Lidar-radar-fused teacher network with semi-supervised distillation. We first propose an adaptive fusion module in the teacher network to boost its performance. Then, two feature distillation modules are designed to facilitate the cross-modality knowledge transfer. Finally, a semi-supervised output distillation is proposed to increase the effectiveness and flexibility of the distillation framework. With the same network structure, our radar-only student trained by SCKD boosts the mAP by 10.38% over the baseline and outperforms the state-of-the-art works on the VoD dataset. The experiment on ZJUODset also shows 5.12% mAP improvements on the moderate difficulty level over the baseline when extra unlabeled data are available. Code is available at this https URL.', 'abstract_zh': '三维物体检测是自动驾驶车辆的基本感知任务之一。利用4D毫米波雷达完成这样一个任务非常吸引人，因为该传感器能够获取类似于激光雷达的3D点云数据，同时在恶劣天气条件下还能保持稳健的测量性能。然而，由于雷达点云数据的高度稀疏性和噪声特性，现有方法的性能仍远低于预期。本文提出了一种新的半监督跨模态知识蒸馏（SCKD）方法，用于基于4D雷达的3D物体检测。该方法通过半监督蒸馏，刻画了从激光雷达-雷达融合教师网络中学习特征的能力。我们首先在教师网络中提出了一种自适应融合模块，以提升其性能。然后，设计了两个特征蒸馏模块，以促进跨模态知识的转移。最后，提出了半监督输出蒸馏，以增加蒸馏框架的有效性和灵活性。使用相同的网络结构，通过SCKD训练的仅雷达学生在网络基线的基础上提升了10.38%的mAP，并在VoD数据集上超越了最新的方法。当可用额外未标注数据时，在ZJUOD数据集上的实验也表明，与基线相比，在中等难度级别上mAP提高了5.12%。相关代码可通过以下链接获取：this https URL。', 'title_zh': 'SCKD：半监督跨模态知识蒸馏在4D雷达目标检测中的应用'}
{'arxiv_id': 'arXiv:2412.14570', 'title': 'Characterising Simulation-Based Program Equilibria', 'authors': 'Emery Cooper, Caspar Oesterheld, Vincent Conitzer', 'link': 'https://arxiv.org/abs/2412.14570', 'abstract': "In Tennenholtz's program equilibrium, players of a game submit programs to play on their behalf. Each program receives the other programs' source code and outputs an action. This can model interactions involving AI agents, mutually transparent institutions, or commitments. Tennenholtz (2004) proves a folk theorem for program games, but the equilibria constructed are very brittle. We therefore consider simulation-based programs -- i.e., programs that work by running opponents' programs. These are relatively robust (in particular, two programs that act the same are treated the same) and are more practical than proof-based approaches. Oesterheld's (2019) $\\epsilon$Grounded$\\pi$Bot is such an approach. Unfortunately, it is not generally applicable to games of three or more players, and only allows for a limited range of equilibria in two player games. In this paper, we propose a generalisation to Oesterheld's (2019) $\\epsilon$Grounded$\\pi$Bot. We prove a folk theorem for our programs in a setting with access to a shared source of randomness. We then characterise their equilibria in a setting without shared randomness. Both with and without shared randomness, we achieve a much wider range of equilibria than Oesterheld's (2019) $\\epsilon$Grounded$\\pi$Bot. Finally, we explore the limits of simulation-based program equilibrium, showing that the Tennenholtz folk theorem cannot be attained by simulation-based programs without access to shared randomness.", 'abstract_zh': '在Tennenholtz的游戏程序均衡中，游戏中的参与者提交程序代表自己进行游戏。每个程序会接收其他程序的源代码并输出一个行动。这可以用来模拟涉及AI代理、相互透明机构或承诺的互动。Tennenholtz（2004）为程序游戏证明了一个民谣定理（folk theorem），但构建的均衡非常脆弱。因此，我们考虑了基于模拟的程序——即通过运行对手程序的方式工作。这些程序相对较为稳健（特别是，行为相同的两个程序会被同等对待），并且相比基于证明的方法更为实用。Oesterheld（2019）的$\\epsilon$Grounded$\\pi$Bot正是如此。遗憾的是，它并不适用于三人或更多参与者的游戏，只在两人游戏中允许有限范围的均衡。在本文中，我们提出了对Oesterheld（2019）的$\\epsilon$Grounded$\\pi$Bot的推广。我们在一个可以访问共享随机源的设置中证明了我们程序的民谣定理。然后，在没有共享随机源的设置中，我们对它们的均衡进行了刻画。无论是有共享随机源的情况还是没有共享随机源的情况，我们实现的均衡范围都比Oesterheld（2019）的$\\epsilon$Grounded$\\pi$Bot要广泛得多。最后，我们探讨了基于模拟的程序均衡的极限，并证明了在没有共享随机源的情况下，基于模拟的程序无法实现Tennenholtz的民谣定理。', 'title_zh': '基于模拟的程序均衡性特征化'}
{'arxiv_id': 'arXiv:2412.14569', 'title': 'Global Spatio-Temporal Fusion-based Traffic Prediction Algorithm with Anomaly Aware', 'authors': 'Chaoqun Liu, Xuanpeng Li, Chen Gong, Guangyu Li', 'link': 'https://arxiv.org/abs/2412.14569', 'abstract': 'Traffic prediction is an indispensable component of urban planning and traffic management. Achieving accurate traffic prediction hinges on the ability to capture the potential spatio-temporal relationships among road sensors. However, the majority of existing works focus on local short-term spatio-temporal correlations, failing to fully consider the interactions of different sensors in the long-term state. In addition, these works do not analyze the influences of anomalous factors, or have insufficient ability to extract personalized features of anomalous factors, which make them ineffectively capture their spatio-temporal influences on traffic prediction. To address the aforementioned issues, We propose a global spatio-temporal fusion-based traffic prediction algorithm that incorporates anomaly awareness. Initially, based on the designed anomaly detection network, we construct an efficient anomalous factors impacting module (AFIM), to evaluate the spatio-temporal impact of unexpected external events on traffic prediction. Furthermore, we propose a multi-scale spatio-temporal feature fusion module (MTSFFL) based on the transformer architecture, to obtain all possible both long and short term correlations among different sensors in a wide-area traffic environment for accurate prediction of traffic flow. Finally, experiments are implemented based on real-scenario public transportation datasets (PEMS04 and PEMS08) to demonstrate that our approach can achieve state-of-the-art performance.', 'abstract_zh': '交通预测是城市规划和交通管理不可或缺的组成部分。实现准确的交通预测依赖于捕获道路传感器之间潜在的空间-时间关系的能力。然而，现有的大多数研究专注于局部短期的空间-时间相关性，未能充分考虑不同传感器之间在长期状态下的交互作用。此外，这些研究也没有分析异常因素的影响，或者提取异常因素个性化特征的能力不足，这使得它们难以有效捕捉这些因素的空间-时间影响对交通预测的影响。为了解决上述问题，我们提出了一种结合异常意识的全局时空融合交通预测算法。首先，基于设计的异常检测网络，构建了一个高效的异常因素影响模块（AFIM），以评估意外外部事件对交通预测的空间-时间影响。此外，我们提出了基于Transformer架构的多尺度时空特征融合模块（MTSFFL），以在广域交通环境中获取不同传感器之间所有可能的长期和短期相关性，从而实现交通流量的精确预测。最后，通过基于实际场景的公共交通数据集（PEMS04和PEMS08）进行实验，证明了我们的方法能够实现最先进的性能。', 'title_zh': '基于全局时空融合及异常检测的交通预测算法'}
{'arxiv_id': 'arXiv:2412.14566', 'title': 'AIArena: A Blockchain-Based Decentralized AI Training Platform', 'authors': 'Zhipeng Wang, Rui Sun, Elizabeth Lui, Tuo Zhou, Yizhe Wen, Jiahao Sun', 'link': 'https://arxiv.org/abs/2412.14566', 'abstract': 'The rapid advancement of AI has underscored critical challenges in its development and implementation, largely due to centralized control by a few major corporations. This concentration of power intensifies biases within AI models, resulting from inadequate governance and oversight mechanisms. Additionally, it limits public involvement and heightens concerns about the integrity of model generation. Such monopolistic control over data and AI outputs threatens both innovation and fair data usage, as users inadvertently contribute data that primarily benefits these corporations. In this work, we propose AIArena, a blockchain-based decentralized AI training platform designed to democratize AI development and alignment through on-chain incentive mechanisms. AIArena fosters an open and collaborative environment where participants can contribute models and computing resources. Its on-chain consensus mechanism ensures fair rewards for participants based on their contributions. We instantiate and implement AIArena on the public Base blockchain Sepolia testnet, and the evaluation results demonstrate the feasibility of AIArena in real-world applications.', 'abstract_zh': '人工智能的迅速发展凸显了其开发与实施中至关重要的挑战，主要归因于少数几家大型企业对其的集中控制。这种权力集中加剧了人工智能模型中的偏见问题，这些问题源于治理和监督机制的不足。此外，这也限制了公众的参与，并加剧了对模型生成公正性的担忧。这种数据和AI输出的垄断控制既阻碍了创新，也破坏了数据的公平使用，因为用户通常在无意中贡献的数据主要惠及这些企业。在本研究中，我们提出了一种基于区块链的去中心化AI训练平台——AIArena，旨在通过链上的激励机制实现AI的民主化发展与对齐。AIArena 创造了一个开放和协作的环境，参与者可以在其中贡献模型和计算资源。其链上的共识机制确保参与者根据其贡献公平地获得奖励。我们已在公共Base区块链Sepolia测试网上实例化并实现了AIArena，并且评估结果证明了AIArena在实际应用中的可行性。', 'title_zh': 'AIArena：一种基于区块链的分布式人工智能培训平台\n\n这个标题翻译成中文既保留了原文的含义，又符合中文的表达习惯。请注意，这是一篇关于基于区块链技术的人工智能分布式训练平台的论文或研究项目名称。'}
{'arxiv_id': 'arXiv:2412.14545', 'title': 'Summary of Point Transformer with Federated Learning for Predicting Breast Cancer HER2 Status from Hematoxylin and Eosin-Stained Whole Slide Images', 'authors': 'Kamorudeen A. Amuda, Almustapha A. Wakili', 'link': 'https://arxiv.org/abs/2412.14545', 'abstract': 'This study introduces a federated learning-based approach to predict HER2 status from hematoxylin and eosin (HE)-stained whole slide images (WSIs), reducing costs and speeding up treatment decisions. To address label imbalance and feature representation challenges in multisite datasets, a point transformer is proposed, incorporating dynamic label distribution, an auxiliary classifier, and farthest cosine sampling. Extensive experiments demonstrate state-of-the-art performance across four sites (2687 WSIs) and strong generalization to two unseen sites (229 WSIs).', 'abstract_zh': '本研究提出了一种基于联邦学习的方法，用于预测苏木精和伊红（HE）染色全视野图像（WSIs）中的HER2状态，从而降低成本并加快治疗决策过程。为了应对多中心数据集中标签不平衡和特征表示的挑战，我们引入了一种点变换器，结合了动态标签分布、辅助分类器和最远余弦采样。广泛实验显示，该方法在四个中心（2687张WSIs）上达到了最先进的性能，并且在两个未见中心（229张WSIs）上具有较强的泛化能力。', 'title_zh': '基于联邦学习的点变换器方法在预测苏木精和伊红染色全玻片图像中乳腺癌HER2状态方面的总结'}
{'arxiv_id': 'arXiv:2412.14538', 'title': 'Overview of AI and Communication for 6G Network: Fundamentals, Challenges, and Future Research Opportunities', 'authors': 'Qimei Cui, Xiaohu You, Ni Wei, Guoshun Nan, Xuefei Zhang, Jianhua Zhang, Xinchen Lyu, Ming Ai, Xiaofeng Tao, Zhiyong Feng, Ping Zhang, Qingqing Wu, Meixia Tao, Yongming Huang, Chongwen Huang, Guangyi Liu, Chenghui Peng, Zhiwen Pan, Tao Sun, Dusit Niyato, Tao Chen, Muhammad Khurram Khan, Abbas Jamalipour, Mohsen Guizani, Chau Yuen', 'link': 'https://arxiv.org/abs/2412.14538', 'abstract': 'With the increasing demand for seamless connectivity and intelligent communication, the integration of artificial intelligence (AI) and communication for sixth-generation (6G) network is emerging as a revolutionary architecture. This paper presents a comprehensive overview of AI and communication for 6G networks, emphasizing their foundational principles, inherent challenges, and future research opportunities. We commence with a retrospective analysis of AI and the evolution of large-scale AI models, underscoring their pivotal roles in shaping contemporary communication technologies. The discourse then transitions to a detailed exposition of the envisioned integration of AI within 6G networks, delineated across three progressive developmental stages. The initial stage, AI for Network, focuses on employing AI to augment network performance, optimize efficiency, and enhance user service experiences. The subsequent stage, Network for AI, highlights the role of the network in facilitating and buttressing AI operations and presents key enabling technologies, including digital twins for AI and semantic communication. In the final stage, AI as a Service, it is anticipated that future 6G networks will innately provide AI functions as services and support application scenarios like immersive communication and intelligent industrial robots. Specifically, we have defined the quality of AI service, which refers to the measurement framework system of AI services within the network. In addition to these developmental stages, we thoroughly examine the standardization processes pertinent to AI in network contexts, highlighting key milestones and ongoing efforts. Finally, we outline promising future research opportunities that could drive the evolution and refinement of AI and communication for 6G, positioning them as a cornerstone of next-generation communication infrastructure.', 'abstract_zh': '随着对无缝连接和智能通信需求的不断增加，人工智能（AI）与第六代（6G）网络的融合正逐渐成为一种革命性的架构。本文对6G网络中的AI与通信进行了全面综述，强调了其基本原则、固有挑战以及未来的研究机会。我们首先回溯了AI的历史及其大规模AI模型的发展，突出了AI在塑造当代通信技术方面的作用。然后讨论转向了在6G网络中深度融合AI的详细剖析，分为三个逐步发展的阶段。第一个阶段，AI赋能网络，专注于运用AI提升网络性能、优化效率并增强用户服务体验。第二个阶段，网络赋能AI，突出了网络在促进和支持AI操作中的作用，并介绍了关键使能技术，包括AI的数字孪生和语义通信。在最后一个阶段，AI即服务，预计未来的6G网络将本身就提供AI功能作为服务，并支持沉浸式通信和智能工业机器人等应用场景。我们还明确了AI服务的质量，即网络中AI服务的衡量框架系统。除了这些发展阶段外，我们还详细分析了与网络中AI相关的标准化过程，突出了关键里程碑和正在进行的努力。最后，我们概述了可能推动6G中AI与通信演变和完善的未来研究机会，使它们成为下一代通信基础设施的基础。', 'title_zh': '6G网络中人工智能与通信的综述：基础、挑战及未来研究机遇'}
{'arxiv_id': 'arXiv:2412.14522', 'title': 'CAE-T: A Channelwise AutoEncoder with Transformer for EEG Abnormality Detection', 'authors': 'Youshen Zhao, Keiji Iramina', 'link': 'https://arxiv.org/abs/2412.14522', 'abstract': 'Electroencephalogram (EEG) signals are critical for detecting abnormal brain activity, but their high dimensionality and complexity pose significant challenges for effective analysis. In this paper, we propose CAE-T, a novel framework that combines a channelwise CNN-based autoencoder with a single-head transformer classifier for efficient EEG abnormality detection. The channelwise autoencoder compresses raw EEG signals while preserving channel independence, reducing computational costs and retaining biologically meaningful features. The compressed representations are then fed into the transformer-based classifier, which efficiently models long-term dependencies to distinguish between normal and abnormal signals. Evaluated on the TUH Abnormal EEG Corpus, the proposed model achieves 85.0% accuracy, 76.2% sensitivity, and 91.2% specificity at the per-case level, outperforming baseline models such as EEGNet, Deep4Conv, and FusionCNN. Furthermore, CAE-T requires only 202M FLOPs and 2.9M parameters, making it significantly more efficient than transformer-based alternatives. The framework retains interpretability through its channelwise design, demonstrating great potential for future applications in neuroscience research and clinical practice. The source code is available at this https URL.', 'abstract_zh': '以下是经过专业翻译并符合学术规范的中文版本：\n\n脑电图（EEG）信号对于检测异常脑活动至关重要，但由于其高维度和复杂性，有效分析面临着重大挑战。本文提出了一种新颖的框架CAE-T，该框架结合了一种基于通道的卷积神经网络（CNN）自编码器与单一头部变换器分类器，以提高EEG异常检测的效率。通道自编码器通过保留通道独立性来压缩原始EEG信号，降低计算成本并保留生物意义特征。经过压缩的表示随后输入到基于变换器的分类器中，该分类器能够高效建模长程依赖关系，从而区分正常和异常信号。在TUh异常脑电图数据集上进行评估，所提出模型的准确率达到了85.0%，敏感性达到了76.2%，特异性达到了91.2%，优于EEGNet、Deep4Conv和FusionCNN等基线模型。此外，CAE-T仅需要202M FLOPs和2.9M参数，使其在计算效率方面远优于基于变换器的替代方案。框架通过其通道级设计保留了可解释性，展示了在神经科学研究和临床实践中的广泛应用潜力。源代码可在以下网址获取：[此链接]。\n\n请注意，最后的“[此链接]”部分应该被替换为实际的URL链接。', 'title_zh': 'CAE-T：通道级自动编码器结合变换器的EEG异常检测方法'}
{'arxiv_id': 'arXiv:2412.14510', 'title': 'PA-RAG: RAG Alignment via Multi-Perspective Preference Optimization', 'authors': 'Jiayi Wu, Hengyi Cai, Lingyong Yan, Hao Sun, Xiang Li, Shuaiqiang Wang, Dawei Yin, Ming Gao', 'link': 'https://arxiv.org/abs/2412.14510', 'abstract': 'The emergence of Retrieval-augmented generation (RAG) has alleviated the issues of outdated and hallucinatory content in the generation of large language models (LLMs), yet it still reveals numerous limitations. When a general-purpose LLM serves as the RAG generator, it often suffers from inadequate response informativeness, response robustness, and citation quality. Past approaches to tackle these limitations, either by incorporating additional steps beyond generating responses or optimizing the generator through supervised fine-tuning (SFT), still failed to align with the RAG requirement thoroughly. Consequently, optimizing the RAG generator from multiple preference perspectives while maintaining its end-to-end LLM form remains a challenge. To bridge this gap, we propose Multiple Perspective Preference Alignment for Retrieval-Augmented Generation (PA-RAG), a method for optimizing the generator of RAG systems to align with RAG requirements comprehensively. Specifically, we construct high-quality instruction fine-tuning data and multi-perspective preference data by sampling varied quality responses from the generator across different prompt documents quality scenarios. Subsequently, we optimize the generator using SFT and Direct Preference Optimization (DPO). Extensive experiments conducted on four question-answer datasets across three LLMs demonstrate that PA-RAG can significantly enhance the performance of RAG generators. Our code and datasets are available at this https URL.', 'abstract_zh': '检索增强生成（RAG）的出现缓解了大型语言模型（LLMs）生成内容时出现的过时和幻觉问题，但仍存在许多局限性。当通用语言模型作为RAG生成器使用时，它往往面临响应信息不足、响应稳健性差和引文质量低的问题。过去通过添加额外步骤生成响应或通过监督微调（SFT）优化生成器的方法，至今未能充分满足RAG的要求。因此，从多个偏好角度来看优化RAG生成器，同时保持其端到端的语言模型形式，仍然是一项挑战。为了解决这一问题，我们提出了面向检索增强生成的多视角偏好对齐方法（PA-RAG），该方法旨在全面优化RAG系统的生成器以满足RAG的要求。具体来说，我们通过从不同提示文档质量场景中采样不同质量的响应来构建高质量的指令微调数据和多视角偏好数据。随后，我们使用监督微调（SFT）和直接偏好优化（DPO）来优化生成器。在三种大型语言模型和四个问答数据集上的广泛实验表明，PA-RAG 能够显著提高RAG生成器的表现。我们的代码和数据集可在以下链接访问：this https URL。\n\n请注意，为了适应学术规范和中文表达习惯，上述翻译进行了适当调整。', 'title_zh': 'PA-RAG：多视角偏好优化下的RAG对齐'}
{'arxiv_id': 'arXiv:2412.14497', 'title': 'Treatment Effects Estimation on Networked Observational Data using Disentangled Variational Graph Autoencoder', 'authors': 'Di Fan, Renlei Jiang, Yunhao Wen, Chuanhou Gao', 'link': 'https://arxiv.org/abs/2412.14497', 'abstract': 'Estimating individual treatment effect (ITE) from observational data has gained increasing attention across various domains, with a key challenge being the identification of latent confounders affecting both treatment and outcome. Networked observational data offer new opportunities to address this issue by utilizing network information to infer latent confounders. However, most existing approaches assume observed variables and network information serve only as proxy variables for latent confounders, which often fails in practice, as some variables influence treatment but not outcomes, and vice versa. Recent advances in disentangled representation learning, which disentangle latent factors into instrumental, confounding, and adjustment factors, have shown promise for ITE estimation. Building on this, we propose a novel disentangled variational graph autoencoder that learns disentangled factors for treatment effect estimation on networked observational data. Our graph encoder further ensures factor independence using the Hilbert-Schmidt Independence Criterion. Extensive experiments on two semi-synthetic datasets derived from real-world social networks and one synthetic dataset demonstrate that our method achieves state-of-the-art performance.', 'abstract_zh': '从观察数据中估计个体治疗效果（ITE）在各个领域中引起了越来越多的关注，关键挑战在于识别影响治疗和结果的潜在混杂因素。网络化观察数据提供了新的机会，可以通过利用网络信息来推断潜在混杂因素。然而，现有大多数方法假设观察变量和网络信息仅作为潜在混杂因素的代理变量，这在实践中往往行不通，因为有些变量影响治疗但不影响结果，反之亦然。近年来，解耦表征学习的发展展示了通过将潜在因素分解为工具变量、混杂变量和调整变量来进行ITE估计的潜力。基于此，我们提出了一种新的解耦变分图自编码器，该模型能够学习网络化观察数据中治疗效果估计的解耦因素。我们的图编码器进一步通过希尔伯特-施密特独立性判据（HSIC）确保这些因素的独立性。在两个源自现实社会网络的半合成数据集和一个合成数据集上进行的大量实验表明，我们的方法达到了最先进的性能。', 'title_zh': '使用解纠缠变分图自编码器估计网络观察数据的治疗效果'}
{'arxiv_id': 'arXiv:2412.14488', 'title': 'Stochastic first-order methods with multi-extrapolated momentum for highly smooth unconstrained optimization', 'authors': 'Chuan He', 'link': 'https://arxiv.org/abs/2412.14488', 'abstract': 'In this paper we consider an unconstrained stochastic optimization problem where the objective function exhibits a high order of smoothness. In particular, we propose a stochastic first-order method (SFOM) with multi-extrapolated momentum, in which multiple extrapolations are performed in each iteration, followed by a momentum step based on these extrapolations. We show that our proposed SFOM with multi-extrapolated momentum can accelerate optimization by exploiting the high-order smoothness of the objective function $f$. Specifically, assuming that the gradient and the $p$th-order derivative of $f$ are Lipschitz continuous for some $p\\ge2$, and under some additional mild assumptions, we establish that our method achieves a sample complexity of $\\widetilde{\\mathcal{O}}(\\epsilon^{-(3p+1)/p})$ for finding a point $x$ satisfying $\\mathbb{E}[\\|\\nabla f(x)\\|]\\le\\epsilon$. To the best of our knowledge, our method is the first SFOM to leverage arbitrary order smoothness of the objective function for acceleration, resulting in a sample complexity that strictly improves upon the best-known results without assuming the average smoothness condition. Finally, preliminary numerical experiments validate the practical performance of our method and corroborate our theoretical findings.', 'abstract_zh': '在本文中，我们考虑了一个无约束随机优化问题，其中目标函数表现出高阶光滑性。特别地，我们提出了一种带有多重外插动量的随机一阶方法（SFOM），在每一步迭代中执行多次外插，随后基于这些外插进行动量步骤。我们展示了我们的SFOM方法如何通过利用目标函数$f$的高阶光滑性加速优化过程。具体而言，在假设梯度和$f$的$p$阶导数（$p \\ge 2$）满足Lipschitz连续性条件，并且在一些轻微的额外假设下，我们证明我们的方法可以在找到满足以下条件的点$x$，即$\\mathbb{E}[\\|\\nabla f(x)\\|] \\le \\epsilon$的情况下实现样本复杂度$\\widetilde{\\mathcal{O}}(\\epsilon^{-(3p+1)/p})$。据我们所知，这是第一个利用目标函数任意阶光滑性加速优化的随机一阶方法，并且在不假设平均光滑性条件的情况下，严格改进了现有最佳结果的样本复杂度。最后，初步的数值实验验证了我们方法的实用性能，并且支持了我们的理论结论。', 'title_zh': '带有多重外推动量的随机一阶方法在高度光滑无约束优化中的应用'}
{'arxiv_id': 'arXiv:2412.14468', 'title': 'HashAttention: Semantic Sparsity for Faster Inference', 'authors': 'Aditya Desai, Shuo Yang, Alejandro Cuadron, Ana Klimovic, Matei Zaharia, Joseph E. Gonzalez, Ion Stoica', 'link': 'https://arxiv.org/abs/2412.14468', 'abstract': 'Utilizing longer contexts is increasingly essential to power better AI systems. However, the cost of attending to long contexts is high due to the involved softmax computation. While the scaled dot-product attention (SDPA) exhibits token sparsity, with only a few pivotal tokens significantly contributing to attention, leveraging this sparsity effectively remains an open challenge. Previous methods either suffer from model degradation or require considerable additional resources. We propose HashAttention --a principled approach casting pivotal token identification as a recommendation problem. Given a query, HashAttention encodes keys and queries in Hamming space capturing the required semantic similarity using learned mapping functions. HashAttention efficiently identifies pivotal tokens for a given query in this Hamming space using bitwise operations, and only these pivotal tokens are used for attention computation, significantly improving overall attention efficiency. HashAttention can reduce the number of tokens used by a factor of $1/32\\times$ for the Llama-3.1-8B model with LongBench, keeping average quality loss within 0.6 points, while using only 32 bits per token auxiliary memory. At $32\\times$ sparsity, HashAttention is $3{-}6\\times$ faster than LightLLM and $2.5{-}4.5\\times$ faster than gpt-fast on Nvidia-L4 GPU.', 'abstract_zh': '利用更长的上下文对提升AI系统的性能越来越重要，但处理长上下文的成本很高，这主要是由于涉及的softmax计算。虽然缩放点积注意机制（SDPA）展示了标记稀疏性，只有少数关键标记显著贡献于注意力，但如何有效利用这种稀疏性仍然是一个开放的问题。以往的方法要么导致模型性能下降，要么需要大量的额外资源。我们提出了HashAttention——一种基于原则的方法，将关键标记的识别问题转化为推荐问题。给定一个查询，HashAttention将键和查询编码到汉明空间中，利用学习到的映射函数捕捉所需的语义相似性。HashAttention通过位操作高效地在汉明空间中识别给定查询的关键标记，并仅使用这些关键标记进行注意计算，从而显著提高整体注意力效率。HashAttention可以将Llama-3.1-8B模型在LongBench上的标记使用量减少1/32倍，平均质量损失控制在0.6分以内，同时仅使用每标记32位的辅助内存。在汉明稀疏度为32倍时，HashAttention比LightLLM快3-6倍，在Nvidia-L4 GPU上比gpt-fast快2.5-4.5倍。', 'title_zh': 'HashAttention：语义稀疏性以实现更快的推理'}
{'arxiv_id': 'arXiv:2412.14451', 'title': 'CLDG: Contrastive Learning on Dynamic Graphs', 'authors': 'Yiming Xu, Bin Shi, Teng Ma, Bo Dong, Haoyi Zhou, Qinghua Zheng', 'link': 'https://arxiv.org/abs/2412.14451', 'abstract': "The graph with complex annotations is the most potent data type, whose constantly evolving motivates further exploration of the unsupervised dynamic graph representation. One of the representative paradigms is graph contrastive learning. It constructs self-supervised signals by maximizing the mutual information between the statistic graph's augmentation views. However, the semantics and labels may change within the augmentation process, causing a significant performance drop in downstream tasks. This drawback becomes greatly magnified on dynamic graphs. To address this problem, we designed a simple yet effective framework named CLDG. Firstly, we elaborate that dynamic graphs have temporal translation invariance at different levels. Then, we proposed a sampling layer to extract the temporally-persistent signals. It will encourage the node to maintain consistent local and global representations, i.e., temporal translation invariance under the timespan views. The extensive experiments demonstrate the effectiveness and efficiency of the method on seven datasets by outperforming eight unsupervised state-of-the-art baselines and showing competitiveness against four semi-supervised methods. Compared with the existing dynamic graph method, the number of model parameters and training time is reduced by an average of 2,001.86 times and 130.31 times on seven datasets, respectively.", 'abstract_zh': '具有复杂注释的图形是最强大的数据类型，其不断演进推动了无监督动态图形表示的进一步探索。其中一个代表性的范式是图形对比学习。通过最大化统计数据图的不同视图之间的互信息，它构建了自监督信号。然而，在加工过程中，语义和标签可能会发生变化，这在下游任务中导致显著的性能下降。这一缺点在动态图形中被大幅放大。为解决这一问题，我们设计了一个简单而有效的框架，命名为CLDG。首先，我们阐述了动态图形在不同层次上具有时间平移不变性。然后，我们提出了一种采样层来提取时间上持久的信号。这将鼓励节点在时间跨度视图下维持一致的局部和全局表示，即时间平移不变性。广泛的实验表明，在七个数据集上，该方法通过优于八种无监督的最新基准方法并展现出与四种半监督方法竞争的能力，证明了其有效性和效率。与现有的动态图形方法相比，在七个数据集上，模型参数的数量和训练时间分别减少了2001.86倍和130.31倍。', 'title_zh': 'CLDG：动态图上的对比学习'}
{'arxiv_id': 'arXiv:2412.14444', 'title': 'GenHMR: Generative Human Mesh Recovery', 'authors': 'Muhammad Usama Saleem, Ekkasit Pinyoanuntapong, Pu Wang, Hongfei Xue, Srijan Das, Chen Chen', 'link': 'https://arxiv.org/abs/2412.14444', 'abstract': 'Human mesh recovery (HMR) is crucial in many computer vision applications; from health to arts and entertainment. HMR from monocular images has predominantly been addressed by deterministic methods that output a single prediction for a given 2D image. However, HMR from a single image is an ill-posed problem due to depth ambiguity and occlusions. Probabilistic methods have attempted to address this by generating and fusing multiple plausible 3D reconstructions, but their performance has often lagged behind deterministic approaches. In this paper, we introduce GenHMR, a novel generative framework that reformulates monocular HMR as an image-conditioned generative task, explicitly modeling and mitigating uncertainties in the 2D-to-3D mapping process. GenHMR comprises two key components: (1) a pose tokenizer to convert 3D human poses into a sequence of discrete tokens in a latent space, and (2) an image-conditional masked transformer to learn the probabilistic distributions of the pose tokens, conditioned on the input image prompt along with randomly masked token sequence. During inference, the model samples from the learned conditional distribution to iteratively decode high-confidence pose tokens, thereby reducing 3D reconstruction uncertainties. To further refine the reconstruction, a 2D pose-guided refinement technique is proposed to directly fine-tune the decoded pose tokens in the latent space, which forces the projected 3D body mesh to align with the 2D pose clues. Experiments on benchmark datasets demonstrate that GenHMR significantly outperforms state-of-the-art methods. Project website can be found at this https URL', 'abstract_zh': '人体网格恢复（HMR）在许多计算机视觉应用中至关重要，从医疗到艺术和娱乐领域。单眼图像的HMR主要被确定性方法所解决，这些方法针对给定的2D图像输出单个预测。然而，从单张图像恢复HMR是一个病态问题，由于深度模糊性和遮挡现象。为了应对这一问题，概率方法尝试通过生成和融合多个可能的3D重建来进行处理，但其性能往往落后于确定性方法。本文引入了GenHMR，这是一种新颖的生成框架，重新定义了单眼HMR为基于图像生成的任务，明确建模并缓解了从2D到3D映射过程中的不确定性。GenHMR包含两个关键组件：（1）姿势分词器，将3D人体姿态转化为潜在空间中的离散token序列；（2）基于图像的掩模变换器，学习在输入图像提示和随机掩模token序列下姿势token的概率分布。在推断过程中，模型从学习到的条件分布中采样，逐步解码高置信度的姿势token，从而降低3D重建的不确定性。为了进一步细化重建，提出了一种基于2D姿态的细化技术，直接在潜在空间中微调解码的姿势token，促使投影到3D人体网格与2D姿态线索对齐。在基准数据集上的实验表明，GenHMR在性能上显著优于现有方法。项目网站可在以下链接找到：[在此插入链接]', 'title_zh': 'GenHMR：生成式人体网格恢复'}
{'arxiv_id': 'arXiv:2412.14436', 'title': 'ORBIT: Cost-Effective Dataset Curation for Large Language Model Domain Adaptation with an Astronomy Case Study', 'authors': 'Eric Modesitt, Ke Yang, Spencer Hulsey, Chengxiang Zhai, Volodymyr Kindratenko', 'link': 'https://arxiv.org/abs/2412.14436', 'abstract': "Recent advances in language modeling demonstrate the need for high-quality domain-specific training data, especially for tasks that require specialized knowledge. General-purpose models, while versatile, often lack the depth needed for expert-level tasks because of limited domain-specific information. Domain adaptation training can enhance these models, but it demands substantial, high-quality data. To address this, we propose ORBIT, a cost-efficient methodology for curating massive, high-quality domain-specific datasets from noisy web sources, tailored for training specialist large language models. Using astronomy as a primary case study, we refined the 1.3T-token FineWeb-Edu dataset into a high-quality, 10B-token subset focused on astronomy. Fine-tuning \\textsc{LLaMA-3-8B} on a 1B-token astronomy subset improved performance on the MMLU astronomy benchmark from 69\\% to 76\\% and achieved top results on AstroBench, an astronomy-specific benchmark. Moreover, our model (Orbit-LLaMA) outperformed \\textsc{LLaMA-3-8B-base}, with GPT-4o evaluations preferring it in 73\\% of cases across 1000 astronomy-specific questions. Additionally, we validated ORBIT's generalizability by applying it to law and medicine, achieving a significant improvement of data quality compared to an unfiltered baseline. We open-source the ORBIT methodology, including the curated datasets, the codebase, and the resulting model at \\href{this https URL}{this https URL}.", 'abstract_zh': '近年来，语言模型的发展表明，高质量的领域特定训练数据对于完成需要专门知识的任务至关重要。尽管通用模型具有广泛的适用性，但在专家级任务中往往缺乏深度，因为它们缺乏特定领域的信息。领域适应训练可以增强这些模型，但需要大量高质量的数据。为了解决这一问题，我们提出了ORBIT，这是一种成本效益高的方法，用于从嘈杂的网络来源中收集大量高质量领域特定数据，以训练专门的语言模型。我们以天文学为主要案例研究，将1.3T令牌的FineWeb-Edu数据集精炼为一个专注于天文学的高质量100亿令牌子集。在对100亿令牌的天文学子集进行微调后，\\textsc{LLaMA-3-8B}在MMLU天文学基准测试中的表现从69%提升到76%，并在特定于天文学的基准测试AstroBench中获得了最佳成绩。此外，我们的模型（Orbit-LLaMA）优于\\textsc{LLaMA-3-8B-base}，根据GPT-4o的评估，在1000个天文学专门问题中有73%的情况下它被优先选择。另外，我们验证了ORBIT的一般性，将其应用于法律和医学领域，与未经过滤的基线相比，数据质量得到了显著改善。我们已将ORBIT方法及其定制化数据集、代码库和最终模型开源，链接为 \\href{this https URL}{this https URL}。', 'title_zh': 'ORBIT：用于大型语言模型领域适配的成本有效数据集编排——以天文学案例研究为例'}
{'arxiv_id': 'arXiv:2412.14435', 'title': 'Cherry-Picking in Time Series Forecasting: How to Select Datasets to Make Your Model Shine', 'authors': 'Luis Roque, Carlos Soares, Vitor Cerqueira, Luis Torgo', 'link': 'https://arxiv.org/abs/2412.14435', 'abstract': 'The importance of time series forecasting drives continuous research and the development of new approaches to tackle this problem. Typically, these methods are introduced through empirical studies that frequently claim superior accuracy for the proposed approaches. Nevertheless, concerns are rising about the reliability and generalizability of these results due to limitations in experimental setups. This paper addresses a critical limitation: the number and representativeness of the datasets used. We investigate the impact of dataset selection bias, particularly the practice of cherry-picking datasets, on the performance evaluation of forecasting methods. Through empirical analysis with a diverse set of benchmark datasets, our findings reveal that cherry-picking datasets can significantly distort the perceived performance of methods, often exaggerating their effectiveness. Furthermore, our results demonstrate that by selectively choosing just four datasets - what most studies report - 46% of methods could be deemed best in class, and 77% could rank within the top three. Additionally, recent deep learning-based approaches show high sensitivity to dataset selection, whereas classical methods exhibit greater robustness. Finally, our results indicate that, when empirically validating forecasting algorithms on a subset of the benchmarks, increasing the number of datasets tested from 3 to 6 reduces the risk of incorrectly identifying an algorithm as the best one by approximately 40%. Our study highlights the critical need for comprehensive evaluation frameworks that more accurately reflect real-world scenarios. Adopting such frameworks will ensure the development of robust and reliable forecasting methods.', 'abstract_zh': '时间序列预测的重要性推动了持续的研究和新方法的发展，以解决这一问题。这些方法通常通过实证研究引入，并经常声称所提出的方法具有优越的准确性。然而，由于实验设置的局限性，人们对这些结果的可靠性和普遍适用性产生了担忧。本文针对一个关键限制：所使用的数据集的数量和代表性不足。我们探讨了数据集选择偏差，特别是挑选手册（原文为“cherry-picking”）数据集的做法，对预测方法性能评估的影响。通过使用多样化的基准数据集进行实证分析，我们的研究结果表明，挑选手册数据集可以显著扭曲方法的感知性能，常常夸大其效果。此外，我们的结果还表明，仅通过有选择地选择四个数据集（即大多数研究报道的数量），46%的方法可以被认为是最佳的，77%的方法可以跻身前三名。另外，最近基于深度学习的方法对数据集选择表现出了高度敏感性，而经典方法则表现出更大的稳健性。最后，我们的结果表明，在对基准数据集的一部分进行预测算法的实证验证时，将测试数据集的数量从3增加到6可将误识别算法为最佳算法的风险降低约40%。我们的研究强调了建立全面评估框架的必要性，这些框架可以更准确地反映现实世界的情景。采用这样的框架将确保开发出稳健可靠的预测方法。', 'title_zh': '时间序列预测中的数据集挑选：如何选择数据集让模型脱颖而出'}
{'arxiv_id': 'arXiv:2412.14426', 'title': 'All-in-One Tuning and Structural Pruning for Domain-Specific LLMs', 'authors': 'Lei Lu, Zhepeng Wang, Ruexue Bao, Mengbing Wang, Fangyi Li, Yawen Wu, Weiwen Jiang, Jie Xu, Yanzhi Wang, Shangqian Gao', 'link': 'https://arxiv.org/abs/2412.14426', 'abstract': 'Existing pruning techniques for large language models (LLMs) targeting domain-specific applications typically follow a two-stage process: pruning the pretrained general-purpose LLMs and then fine-tuning the pruned LLMs on specific domains. However, the pruning decisions, derived from the pretrained weights, remain unchanged during fine-tuning, even if the weights have been updated. Therefore, such a combination of the pruning decisions and the finetuned weights may be suboptimal, leading to non-negligible performance degradation. To address these limitations, we propose ATP: All-in-One Tuning and Structural Pruning, a unified one-stage structural pruning and fine-tuning approach that dynamically identifies the current optimal substructure throughout the fine-tuning phase via a trainable pruning decision generator. Moreover, given the limited available data for domain-specific applications, Low-Rank Adaptation (LoRA) becomes a common technique to fine-tune the LLMs. In ATP, we introduce LoRA-aware forward and sparsity regularization to ensure that the substructures corresponding to the learned pruning decisions can be directly removed after the ATP process. ATP outperforms the state-of-the-art two-stage pruning methods on tasks in the legal and healthcare domains. More specifically, ATP recovers up to 88% and 91% performance of the dense model when pruning 40% parameters of LLaMA2-7B and LLaMA3-8B models, respectively.', 'abstract_zh': '现有的针对特定领域应用的大语言模型（LLMs）的剪枝技术通常采用两阶段过程：首先对预训练的一般目的LLMs进行剪枝，然后在特定领域对其进行微调。然而，在微调过程中，从预训练权重中得出的剪枝决策保持不变，即使权重已经更新。因此，这种剪枝决策与微调权重的结合可能是次优的，可能导致性能显著下降。为解决这些局限性，我们提出了ATP：全能一体化剪枝与微调，这是一种统一的一阶段结构剪枝和微调方法，通过可训练的剪枝决策生成器动态识别微调过程中当前的最佳子结构。此外，由于特定领域应用可用的数据有限，低秩适应（LoRA）已成为一种常见的微调LLMs的技术。在ATP中，我们引入了LoRA感知的前向传播和稀疏正则化，以确保所学的剪枝决策对应的子结构可以在ATP过程结束后直接被移除。ATP在法律和医疗领域的任务上优于最先进的两阶段剪枝方法。具体来说，当对LLaMA2-7B和LLaMA3-8B模型参数剪枝40%时，ATP分别恢复了密集模型性能的88%和91%。', 'title_zh': '针对特定领域的大语言模型的全面调优与结构剪枝'}
{'arxiv_id': 'arXiv:2412.14424', 'title': 'FedPIA -- Permuting and Integrating Adapters leveraging Wasserstein Barycenters for Finetuning Foundation Models in Multi-Modal Federated Learning', 'authors': 'Pramit Saha, Divyanshu Mishra, Felix Wagner, Konstantinos Kamnitsas, J. Alison Noble', 'link': 'https://arxiv.org/abs/2412.14424', 'abstract': 'Large Vision-Language Models typically require large text and image datasets for effective fine-tuning. However, collecting data from various sites, especially in healthcare, is challenging due to strict privacy regulations. An alternative is to fine-tune these models on end-user devices, such as in medical clinics, without sending data to a server. These local clients typically have limited computing power and small datasets, which are not enough for fully fine-tuning large VLMs on their own. A naive solution to these scenarios is to leverage parameter-efficient fine-tuning (PEFT) strategies and apply federated learning (FL) algorithms to combine the learned adapter weights, thereby respecting the resource limitations and data privacy. However, this approach does not fully leverage the knowledge from multiple adapters trained on diverse data distributions and for diverse tasks. The adapters are adversely impacted by data heterogeneity and task heterogeneity across clients resulting in suboptimal convergence. To this end, we propose a novel framework called FedPIA that improves upon the naive combinations of FL and PEFT by introducing Permutation and Integration of the local Adapters in the server and global Adapters in the clients exploiting Wasserstein barycenters for improved blending of client-specific and client-agnostic knowledge. This layerwise permutation helps to bridge the gap in the parameter space of local and global adapters before integration. We conduct over 2000 client-level experiments utilizing 48 medical image datasets across five different medical vision-language FL task settings encompassing visual question answering as well as image and report-based multi-label disease detection. Our experiments involving diverse client settings, ten different modalities, and two VLM backbones demonstrate that FedPIA consistently outperforms the state-of-the-art PEFT-FL baselines.', 'abstract_zh': '大型视觉-语言模型通常需要大规模的文本和图像数据集以实现有效的细调。然而，在医疗保健等领域收集数据由于严格的隐私法规而面临挑战。一个可行的替代方案是在终端用户设备上（例如在医疗诊所）进行细调，而无需将数据发送到服务器。这些本地设备通常具有有限的计算能力和小的数据集，不足以独立将大型VLMs进行完全细调。一种简单的解决方案是利用参数高效细调（PEFT）策略，并结合联邦学习（FL）算法来整合已学习的适配器权重，从而尊重资源限制和数据隐私。然而，这种做法并没有充分利用在不同数据分布和不同任务上训练的多个适配器的知识。适配器由于客户端间数据异质性和任务异质性而受到影响，导致效果不佳的收敛。为此，我们提出了一种名为FedPIA的新框架，它通过在服务器端引入局部适配器的排列和整合，在客户端利用Wasserstein变心来改进FL和PEFT的简单结合，从而整合客户端特定和无客户端特定知识。逐层排列有助于在整合前缩小局部适配器和全局适配器的参数空间差距。我们利用48个医学图像数据集在五种不同的医学视觉-语言联邦学习任务设置中（包括视觉问答及基于图像和报告的多标签疾病检测）进行了超过2000个客户端级别的实验。我们的实验涵盖了多样化的客户端设置、十种不同的模态以及两个VLM基础模型，表明FedPIA在所有情况下都优于最先进的PEFT-FL基线。', 'title_zh': 'FedPIA——利用Wasserstein 调和集成和置换适配器进行多模态联邦学习微调基础模型'}
{'arxiv_id': 'arXiv:2412.14422', 'title': 'Enhancing Diffusion Models for High-Quality Image Generation', 'authors': 'Jaineet Shah, Michael Gromis, Rickston Pinto', 'link': 'https://arxiv.org/abs/2412.14422', 'abstract': 'This report presents the comprehensive implementation, evaluation, and optimization of Denoising Diffusion Probabilistic Models (DDPMs) and Denoising Diffusion Implicit Models (DDIMs), which are state-of-the-art generative models. During inference, these models take random noise as input and iteratively generate high-quality images as output. The study focuses on enhancing their generative capabilities by incorporating advanced techniques such as Classifier-Free Guidance (CFG), Latent Diffusion Models with Variational Autoencoders (VAE), and alternative noise scheduling strategies. The motivation behind this work is the growing demand for efficient and scalable generative AI models that can produce realistic images across diverse datasets, addressing challenges in applications such as art creation, image synthesis, and data augmentation. Evaluations were conducted on datasets including CIFAR-10 and ImageNet-100, with a focus on improving inference speed, computational efficiency, and image quality metrics like Frechet Inception Distance (FID). Results demonstrate that DDIM + CFG achieves faster inference and superior image quality. Challenges with VAE and noise scheduling are also highlighted, suggesting opportunities for future optimization. This work lays the groundwork for developing scalable, efficient, and high-quality generative AI systems to benefit industries ranging from entertainment to robotics.', 'abstract_zh': '本报告全面介绍了去噪扩散概率模型（DDPMs）和去噪扩散隐模型（DDIMs）的实施、评估与优化，这两种模型是当前先进的生成模型。在推理过程中，这些模型将随机噪声作为输入，并通过迭代生成高质量的图像作为输出。本研究的重点在于通过引入先进技术，如分类器无关引导（CFG）、潜扩散模型结合变分自编码器（VAE）以及替代噪声调度策略来提升其生成能力。进行此项研究的动机是为了满足对高效且可扩展的生成型AI模型的需求，这些模型能够在多种数据集中生成逼真的图像，解决诸如艺术创作、图像合成和数据增强等应用领域中的挑战。\n\n本研究在CIFAR-10和ImageNet-100等数据集上进行了测试，重点关注提高推理速度、计算效率以及使用弗雷切尔-入渗距离（FID）等图像质量指标衡量的图像质量。结果表明，DDIM结合CFG实现了更快的推理速度和更高的图像质量。同时还指出了VAE和噪声调度方面存在的挑战，为未来的优化提供了机会。这项工作为开发可扩展、高效且高质量的生成型AI系统奠定了基础，这些系统可以惠及从娱乐到机器人技术等各个行业。', 'title_zh': '增强扩散模型以生成高质量图像'}
{'arxiv_id': 'arXiv:2412.14415', 'title': 'DriveGPT: Scaling Autoregressive Behavior Models for Driving', 'authors': 'Xin Huang, Eric M. Wolff, Paul Vernaza, Tung Phan-Minh, Hongge Chen, David S. Hayden, Mark Edmonds, Brian Pierce, Xinxin Chen, Pratik Elias Jacob, Xiaobai Chen, Chingiz Tairbekov, Pratik Agarwal, Tianshi Gao, Yuning Chai, Siddhartha Srinivasa', 'link': 'https://arxiv.org/abs/2412.14415', 'abstract': 'We present DriveGPT, a scalable behavior model for autonomous driving. We model driving as a sequential decision making task, and learn a transformer model to predict future agent states as tokens in an autoregressive fashion. We scale up our model parameters and training data by multiple orders of magnitude, enabling us to explore the scaling properties in terms of dataset size, model parameters, and compute. We evaluate DriveGPT across different scales in a planning task, through both quantitative metrics and qualitative examples including closed-loop driving in complex real-world scenarios. In a separate prediction task, DriveGPT outperforms a state-of-the-art baseline and exhibits improved performance by pretraining on a large-scale dataset, further validating the benefits of data scaling.', 'abstract_zh': '我们提出DriveGPT，一种可扩展的自主驾驶行为模型。我们将驾驶建模为连续决策任务，并利用transformer模型以自回归的方式预测未来代理状态，将其视为令牌。我们通过多个数量级扩展模型参数和训练数据，从而在数据集规模、模型参数和计算资源方面探索可扩展性。我们在规划任务的不同规模下对DriveGPT进行评估，通过定性和定量指标，包括在复杂现实世界场景中的闭环驾驶示例。在另一项预测任务中，DriveGPT在表现上优于最先进的基线，并通过在大规模数据集上预训练显示出改进的表现，进一步验证了数据扩展的优势。', 'title_zh': 'DriveGPT：扩展自回归行为模型以应用于自动驾驶'}
{'arxiv_id': 'arXiv:2412.14384', 'title': 'I0T: Embedding Standardization Method Towards Zero Modality Gap', 'authors': 'Na Min An, Eunki Kim, James Thorne, Hyunjung Shim', 'link': 'https://arxiv.org/abs/2412.14384', 'abstract': 'Contrastive Language-Image Pretraining (CLIP) enables zero-shot inference in downstream tasks such as image-text retrieval and classification. However, recent works extending CLIP suffer from the issue of modality gap, which arises when the image and text embeddings are projected to disparate manifolds, deviating from the intended objective of image-text contrastive learning. We discover that this phenomenon is linked to the modality-specific characteristic that each image/text encoder independently possesses and propose two methods to address the modality gap: (1) a post-hoc embedding standardization method, $\\text{I0T}_{\\text{post}}$ that reduces the modality gap approximately to zero and (2) a trainable method, $\\text{I0T}_{\\text{async}}$, to alleviate the modality gap problem by adding two normalization layers for each encoder. Our I0T framework can significantly reduce the modality gap while preserving the original embedding representations of trained models with their locked parameters. In practice, $\\text{I0T}_{\\text{post}}$ can serve as an alternative explainable automatic evaluation metric of widely used CLIPScore (CLIP-S).', 'abstract_zh': '对比语言-图像预训练（CLIP）使零样本推理成为诸如图像-文本检索和分类等下游任务的可行方法。然而，最近扩展CLIP的工作遭受了模态差距的问题，当图像和文本嵌入被投影到不同的流形上时，偏离了图像-文本对比学习的预期目标。我们发现这一现象与每个图像/文本编码器各自具有的模态特定特性相关，并提出了两种方法来解决模态差距问题：（1）一种事后嵌入标准化方法$\\text{I0T}_{\\text{post}}$，它可以将模态差距大约减少至零；（2）一种可训练的方法$\\text{I0T}_{\\text{async}}$，通过在每个编码器上添加两个规范化层来缓解模态差距问题。我们的I0T框架能够在保留训练模型锁定参数的原始嵌入表示的同时，显著减少模态差距。在实践中，$\\text{I0T}_{\\text{post}}$可以作为广泛使用的CLIP分数（CLIP-S）的一种可解释的自动化评估指标替代方案。', 'title_zh': 'IoT: 零模态差距嵌入标准化方法'}
{'arxiv_id': 'arXiv:2412.14366', 'title': 'Surrealistic-like Image Generation with Vision-Language Models', 'authors': 'Elif Ayten, Shuai Wang, Hjalmar Snoep', 'link': 'https://arxiv.org/abs/2412.14366', 'abstract': 'Recent advances in generative AI make it convenient to create different types of content, including text, images, and code. In this paper, we explore the generation of images in the style of paintings in the surrealism movement using vision-language generative models, including DALL-E, Deep Dream Generator, and DreamStudio. Our investigation starts with the generation of images under various image generation settings and different models. The primary objective is to identify the most suitable model and settings for producing such images. Additionally, we aim to understand the impact of using edited base images on the generated resulting images. Through these experiments, we evaluate the performance of selected models and gain valuable insights into their capabilities in generating such images. Our analysis shows that Dall-E 2 performs the best when using the generated prompt by ChatGPT.', 'abstract_zh': '近年来，生成式AI的进步使得创建不同类型的内容，包括文本、图像和代码，变得非常方便。本文探讨了使用视觉语言生成模型（包括DALL-E、Deep Dream Generator和DreamStudio）生成超现实主义绘画风格图像的问题。我们的研究始于在不同图像生成设置和不同模型下的图像生成。主要目标是确定最适合生成此类图像的模型和设置。此外，我们还旨在理解使用编辑后的基础图像对生成的最终图像产生的影响。通过这些实验，我们评估了所选模型的性能，并获得了关于它们生成此类图像能力的宝贵见解。我们的分析显示，当使用由ChatGPT生成的提示时，DALL-E 2表现最佳。', 'title_zh': '使用视觉语言模型生成超现实主义风格的图像'}
{'arxiv_id': 'arXiv:2412.14355', 'title': 'Enabling Realtime Reinforcement Learning at Scale with Staggered Asynchronous Inference', 'authors': 'Matthew Riemer, Gopeshh Subbaraj, Glen Berseth, Irina Rish', 'link': 'https://arxiv.org/abs/2412.14355', 'abstract': "Realtime environments change even as agents perform action inference and learning, thus requiring high interaction frequencies to effectively minimize regret. However, recent advances in machine learning involve larger neural networks with longer inference times, raising questions about their applicability in realtime systems where reaction time is crucial. We present an analysis of lower bounds on regret in realtime reinforcement learning (RL) environments to show that minimizing long-term regret is generally impossible within the typical sequential interaction and learning paradigm, but often becomes possible when sufficient asynchronous compute is available. We propose novel algorithms for staggering asynchronous inference processes to ensure that actions are taken at consistent time intervals, and demonstrate that use of models with high action inference times is only constrained by the environment's effective stochasticity over the inference horizon, and not by action frequency. Our analysis shows that the number of inference processes needed scales linearly with increasing inference times while enabling use of models that are multiple orders of magnitude larger than existing approaches when learning from a realtime simulation of Game Boy games such as Pokémon and Tetris.", 'abstract_zh': '即使代理执行动作推断和学习时，实时环境也在不断变化，因此需要高频率的交互以有效最小化遗憾。然而，最近的机器学习进展涉及更大规模的神经网络和更长的推断时间，这在反应时间至关重要的实时系统中引发了关于其适用性的问题。我们对实时强化学习（Reinforcement Learning, RL）环境中的遗憾下界进行了分析，表明在典型的顺序交互和学习范式中，一般不可能最小化长期遗憾，但在有足够的异步计算能力时，这种情况往往会变得可能。我们提出了新的算法来交错异步推断过程，确保采取动作的时间间隔一致，并展示了当从实时模拟的Game Boy游戏如宝可梦和俄罗斯方块中学习时，使用具有高动作推断时间的模型仅受推断窗口内的环境有效随机性制约，而不受动作频率的制约。我们的分析表明，需要的推断过程数量随着推断时间的增长呈线性增加，并在使用比现有方法大多个数量级的模型时仍然适用。', 'title_zh': '大规模实时强化学习的分时异步推理实现'}
{'arxiv_id': 'arXiv:2412.14351', 'title': 'Is Peer-Reviewing Worth the Effort?', 'authors': 'Kenneth Church, Raman Chandrasekar, John E. Ortega, Ibrahim Said Ahmad', 'link': 'https://arxiv.org/abs/2412.14351', 'abstract': 'How effective is peer-reviewing in identifying important papers? We treat this question as a forecasting task. Can we predict which papers will be highly cited in the future based on venue and "early returns" (citations soon after publication)? We show early returns are more predictive than venue. Finally, we end with constructive suggestions to address scaling challenges: (a) too many submissions and (b) too few qualified reviewers.', 'abstract_zh': '同行评审在识别重要论文方面的有效性如何？我们将这个问题视为一项预测任务。我们能否基于会议和“早期反馈”（即发表后不久的引用情况）来预测哪些论文在未来将被高度引用？我们表明，早期反馈比会议更能预测论文的影响力。最后，我们提出了几点建设性的建议，以应对扩大量化挑战：(a) 递交数量过多，(b) 合格评审人数量不足。', 'title_zh': '值得付出努力进行同行评审吗？'}
{'arxiv_id': 'arXiv:2412.14340', 'title': 'A Unifying Information-theoretic Perspective on Evaluating Generative Models', 'authors': 'Alexis Fox, Samarth Swarup, Abhijin Adiga', 'link': 'https://arxiv.org/abs/2412.14340', 'abstract': 'Considering the difficulty of interpreting generative model output, there is significant current research focused on determining meaningful evaluation metrics. Several recent approaches utilize "precision" and "recall," borrowed from the classification domain, to individually quantify the output fidelity (realism) and output diversity (representation of the real data variation), respectively. With the increase in metric proposals, there is a need for a unifying perspective, allowing for easier comparison and clearer explanation of their benefits and drawbacks. To this end, we unify a class of kth-nearest-neighbors (kNN)-based metrics under an information-theoretic lens using approaches from kNN density estimation. Additionally, we propose a tri-dimensional metric composed of Precision Cross-Entropy (PCE), Recall Cross-Entropy (RCE), and Recall Entropy (RE), which separately measure fidelity and two distinct aspects of diversity, inter- and intra-class. Our domain-agnostic metric, derived from the information-theoretic concepts of entropy and cross-entropy, can be dissected for both sample- and mode-level analysis. Our detailed experimental results demonstrate the sensitivity of our metric components to their respective qualities and reveal undesirable behaviors of other metrics.', 'abstract_zh': '考虑到生成模型输出难以解释的问题，当前有大量的研究集中在确定有意义的评估指标上。一些最近的方法借鉴分类领域的“精确率”和“召回率”，分别独立地衡量输出的真实性和输出的多样性。随着评价指标的不断增加，需要一个统一的视角，以便更方便地比较这些指标的优缺点。为此，我们利用k最近邻密度估计的方法，从信息论的视角统一了一类基于k近邻（kNN）的指标。此外，我们提出了一种三维指标，由精确率交叉熵（PCE）、召回率交叉熵（RCE）和召回率熵（RE）组成，分别测量真实性和多样性的两个不同方面：类间和类内多样性。我们提出的一个领域无关的指标，基于信息论概念的熵和交叉熵，可以在样本和模式级别上进行分解分析。详细实验结果表明，我们的指标组件对各自的品质具有敏感性，并揭示了其他指标的不良行为。', 'title_zh': '一种统一体量化的信息论视角下的生成模型评估方法'}
{'arxiv_id': 'arXiv:2412.14329', 'title': 'Embedding Cultural Diversity in Prototype-based Recommender Systems', 'authors': 'Armin Moradi, Nicola Neophytou, Florian Carichon, Golnoosh Farnadi', 'link': 'https://arxiv.org/abs/2412.14329', 'abstract': 'Popularity bias in recommender systems can increase cultural overrepresentation by favoring norms from dominant cultures and marginalizing underrepresented groups. This issue is critical for platforms offering cultural products, as they influence consumption patterns and human perceptions. In this work, we address popularity bias by identifying demographic biases within prototype-based matrix factorization methods. Using the country of origin as a proxy for cultural identity, we link this demographic attribute to popularity bias by refining the embedding space learning process. First, we propose filtering out irrelevant prototypes to improve representativity. Second, we introduce a regularization technique to enforce a uniform distribution of prototypes within the embedding space. Across four datasets, our results demonstrate a 27\\% reduction in the average rank of long-tail items and a 2\\% reduction in the average rank of items from underrepresented countries. Additionally, our model achieves a 2\\% improvement in HitRatio@10 compared to the state-of-the-art, highlighting that fairness is enhanced without compromising recommendation quality. Moreover, the distribution of prototypes leads to more inclusive explanations by better aligning items with diverse prototypes.', 'abstract_zh': '推荐系统中的流行度偏差可能会通过偏向主导文化规范而增加文化过代表，同时边缘化被代表不足的群体。这一问题对于提供文化产品的平台尤为重要，因为它会影响消费模式和人类感知。在本文中，我们通过识别基于原型的矩阵分解方法中的人口统计偏差来解决流行度偏差问题。利用原产地作为文化身份的代理，我们通过细化嵌入空间学习过程将人口统计属性与流行度偏差联系起来。首先，我们提出过滤掉无关的原型以提高代表性。其次，我们引入一种正则化技术，以确保嵌入空间中原型的均匀分布。在四个数据集上，我们的结果表明，长尾项目的平均排名降低了27%，来自被代表不足国家的项目的平均排名降低了2%。此外，我们的模型在HitRatio@10上相对于最新技术提高了2%，这表明公平性得到了增强而没有牺牲推荐质量。此外，原型的分布导致了更加包容的解释，因为这样可以更好地使项目与多样性的原型对齐。', 'title_zh': '将文化多样性融入原型推荐系统中'}
{'arxiv_id': 'arXiv:2412.14328', 'title': 'Semantic Role Labeling of NomBank Partitives', 'authors': 'Adam Meyers, Advait Pravin Savant, John E. Ortega', 'link': 'https://arxiv.org/abs/2412.14328', 'abstract': 'This article is about Semantic Role Labeling for English partitive nouns (5%/REL of the price/ARG1; The price/ARG1 rose 5 percent/REL) in the NomBank annotated corpus. Several systems are described using traditional and transformer-based machine learning, as well as ensembling. Our highest scoring system achieves an F1 of 91.74% using "gold" parses from the Penn Treebank and 91.12% when using the Berkeley Neural parser. This research includes both classroom and experimental settings for system development.', 'abstract_zh': '本文探讨了在NomBank标注语料库中英语部分名词的语义角色标注（例如，5%/REL of the price/ARG1；The price/ARG1 rose 5 percent/REL）。研究介绍了使用传统机器学习和Transformer基机器学习方法构建的多种系统，并且提到了集成方法。我们的最高得分系统在使用宾夕法尼亚树库的“金标准”解析时达到了91.74%的F1值，使用伯克利神经解析器时达到了91.12%的F1值。本研究包括系统开发的课堂和实验设置。', 'title_zh': '诺蒙宾语部分语义角色标注（Semantic Role Labeling of NomBank Partitives）'}
{'arxiv_id': 'arXiv:2412.14323', 'title': 'The Role of Handling Attributive Nouns in Improving Chinese-To-English Machine Translation', 'authors': 'Haohao, Wang, Adam Meyers, John E. Ortega, Rodolfo Zevallos', 'link': 'https://arxiv.org/abs/2412.14323', 'abstract': "Translating between languages with drastically different grammatical conventions poses challenges, not just for human interpreters but also for machine translation systems. In this work, we specifically target the translation challenges posed by attributive nouns in Chinese, which frequently cause ambiguities in English translation. By manually inserting the omitted particle X ('DE'). In news article titles from the Penn Chinese Discourse Treebank, we developed a targeted dataset to fine-tune Hugging Face Chinese to English translation models, specifically improving how this critical function word is handled. This focused approach not only complements the broader strategies suggested by previous studies but also offers a practical enhancement by specifically addressing a common error type in Chinese-English translation.", 'abstract_zh': '将具有截然不同语法规范的语言进行互译会带来挑战，不仅对于人类译者，也对机器翻译系统构成了挑战。在这项工作中，我们特别关注了中文中的限定名词所引发的翻译难题，这类名词在英语翻译中经常导致措辞上的模糊。通过人工插入被省略的“定”字（作为标志性宾格助词），我们开发了一个针对性的数据集，以微调Hugging Face的中文到英文翻译模型，特别是在如何处理这个关键功能词方面取得了进步。这种集中改进不仅补充了之前研究中提出的更广泛策略，还通过具体解决中文到英文翻译中的常见错误类型，提供了实际的改进方案。', 'title_zh': '《属性名词在提高中文到英文机器翻译质量中的作用》'}
{'arxiv_id': 'arXiv:2412.14304', 'title': 'Multi-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing LLM Ophthalmological QA in LMICs', 'authors': 'David Restrepo, Chenwei Wu, Zhengxu Tang, Zitao Shuai, Thao Nguyen Minh Phan, Jun-En Ding, Cong-Tinh Dao, Jack Gallifant, Robyn Gayle Dychiao, Jose Carlo Artiaga, André Hiroshi Bando, Carolina Pelegrini Barbosa Gracitelli, Vincenz Ferrer, Leo Anthony Celi, Danielle Bitterman, Michael G Morley, Luis Filipe Nakayama', 'link': 'https://arxiv.org/abs/2412.14304', 'abstract': 'Current ophthalmology clinical workflows are plagued by over-referrals, long waits, and complex and heterogeneous medical records. Large language models (LLMs) present a promising solution to automate various procedures such as triaging, preliminary tests like visual acuity assessment, and report summaries. However, LLMs have demonstrated significantly varied performance across different languages in natural language question-answering tasks, potentially exacerbating healthcare disparities in Low and Middle-Income Countries (LMICs). This study introduces the first multilingual ophthalmological question-answering benchmark with manually curated questions parallel across languages, allowing for direct cross-lingual comparisons. Our evaluation of 6 popular LLMs across 7 different languages reveals substantial bias across different languages, highlighting risks for clinical deployment of LLMs in LMICs. Existing debiasing methods such as Translation Chain-of-Thought or Retrieval-augmented generation (RAG) by themselves fall short of closing this performance gap, often failing to improve performance across all languages and lacking specificity for the medical domain. To address this issue, We propose CLARA (Cross-Lingual Reflective Agentic system), a novel inference time de-biasing method leveraging retrieval augmented generation and self-verification. Our approach not only improves performance across all languages but also significantly reduces the multilingual bias gap, facilitating equitable LLM application across the globe.', 'abstract_zh': '当前的眼科临床工作流程受到过度转诊、长时间等待和复杂多样的医疗记录的影响。大型语言模型（LLMs）有望自动化各种程序，如分诊、初步测试（例如视力评估）和报告总结。然而，LLMs在自然语言问答任务中表现出显著不同的性能差异，这可能在低收入和中等收入国家（LMICs）加剧医疗保健不平等。本研究引入了第一个多语言眼科问答基准数据集，该数据集包含手工编纂且跨语言平行的问题，允许直接跨语言比较。我们对6种流行的LLMs在7种不同语言上的评估结果显示了明显的语言间差异，突显了LLMs在LMICs中的临床应用场景中存在风险。现有的去偏见方法（如翻译链思维或检索增强生成，RAG），单独使用时无法缩小这一性能差距，常常无法在所有语言上改善性能，并且缺乏对医疗领域的针对性。为解决这一问题，我们提出了CLARA（跨语言反思代理系统）这一新颖的推理时去偏见方法，利用检索增强生成和自验证。我们的方法不仅在所有语言上改善了性能，而且还显著减小了多语言偏见差距，促进了全球范围内LLMs的公平应用。', 'title_zh': '多语眼科语言：评估和去偏见LMfontName在低收入和中等收入国家眼科问答的多语言基准'}
{'arxiv_id': 'arXiv:2412.14302', 'title': 'SAFERec: Self-Attention and Frequency Enriched Model for Next Basket Recommendation', 'authors': 'Oleg Lashinin, Denis Krasilnikov, Aleksandr Milogradskii, Marina Ananyeva', 'link': 'https://arxiv.org/abs/2412.14302', 'abstract': 'Transformer-based approaches such as BERT4Rec and SASRec demonstrate strong performance in Next Item Recommendation (NIR) tasks. However, applying these architectures to Next-Basket Recommendation (NBR) tasks, which often involve highly repetitive interactions, is challenging due to the vast number of possible item combinations in a basket. Moreover, frequency-based methods such as TIFU-KNN and UP-CF still demonstrate strong performance in NBR tasks, frequently outperforming deep-learning approaches. This paper introduces SAFERec, a novel algorithm for NBR that enhances transformer-based architectures from NIR by incorporating item frequency information, consequently improving their applicability to NBR tasks. Extensive experiments on multiple datasets show that SAFERec outperforms all other baselines, specifically achieving an 8\\% improvement in Recall@10.', 'abstract_zh': '基于Transformer的方法，如BERT4Rec和SASRec，在Next Item Recommendation (NIR) 任务中表现出强大的性能。然而，将这些架构应用于Next-Basket Recommendation (NBR) 任务时颇具挑战性，因为篮子中的项目组合可能极为多样和重复，导致潜在组合数量庞大。此外，基于频率的方法，如TIFU-KNN和UP-CF，在NBR 任务中仍表现出强大的性能，经常优于深度学习方法。本文介绍了一种新的算法SAFERec，该算法通过引入项目频率信息来增强NIR任务中的Transformer架构，从而增加了其在NBR任务中的适用性。针对多个数据集的广泛实验表明，SAFERec 在所有基线中表现最优，特别是在Recall@10上实现了8%的提升。', 'title_zh': 'SAFERec: 基于自我注意力和频率增强的下一个购物车推荐模型'}
{'arxiv_id': 'arXiv:2412.14295', 'title': 'Temporally Consistent Object-Centric Learning by Contrasting Slots', 'authors': 'Anna Manasyan, Maximilian Seitzer, Filip Radovic, Georg Martius, Andrii Zadaianchuk', 'link': 'https://arxiv.org/abs/2412.14295', 'abstract': 'Unsupervised object-centric learning from videos is a promising approach to extract structured representations from large, unlabeled collections of videos. To support downstream tasks like autonomous control, these representations must be both compositional and temporally consistent. Existing approaches based on recurrent processing often lack long-term stability across frames because their training objective does not enforce temporal consistency. In this work, we introduce a novel object-level temporal contrastive loss for video object-centric models that explicitly promotes temporal consistency. Our method significantly improves the temporal consistency of the learned object-centric representations, yielding more reliable video decompositions that facilitate challenging downstream tasks such as unsupervised object dynamics prediction. Furthermore, the inductive bias added by our loss strongly improves object discovery, leading to state-of-the-art results on both synthetic and real-world datasets, outperforming even weakly-supervised methods that leverage motion masks as additional cues.', 'abstract_zh': '从大量无标签视频中进行无监督的物体中心学习是一种有前景的方法，能够从大型的未标注视频集合中提取结构化的表示。为了支持如自主控制等下游任务，这些表示必须同时具备组合性和时间一致性。现有基于循环处理的方法通常在帧间缺乏长期稳定性，因为其训练目标不强制时间一致性。在这项工作中，我们提出了一种新的物体级别时间对比损失，专门用于视频物体中心模型，以显式促进时间一致性。我们的方法显著提高了所学习的物体中心表示的时间一致性，从而生成更加可靠的视频分解，有助于诸如无监督物体动力学预测等具有挑战性的下游任务。此外，通过我们的损失函数引入的归纳偏置显著改进了物体发现能力，在合成数据集和真实数据集上取得了目前最先进的结果，甚至超越了依赖于运动掩码的弱监督方法。', 'title_zh': '通过对比槽位实现时间一致的以对象为中心的学习'}
{'arxiv_id': 'arXiv:2412.14283', 'title': 'PixelMan: Consistent Object Editing with Diffusion Models via Pixel Manipulation and Generation', 'authors': 'Liyao Jiang, Negar Hassanpour, Mohammad Salameh, Mohammadreza Samadi, Jiao He, Fengyu Sun, Di Niu', 'link': 'https://arxiv.org/abs/2412.14283', 'abstract': 'Recent research explores the potential of Diffusion Models (DMs) for consistent object editing, which aims to modify object position, size, and composition, etc., while preserving the consistency of objects and background without changing their texture and attributes. Current inference-time methods often rely on DDIM inversion, which inherently compromises efficiency and the achievable consistency of edited images. Recent methods also utilize energy guidance which iteratively updates the predicted noise and can drive the latents away from the original image, resulting in distortions. In this paper, we propose PixelMan, an inversion-free and training-free method for achieving consistent object editing via Pixel Manipulation and generation, where we directly create a duplicate copy of the source object at target location in the pixel space, and introduce an efficient sampling approach to iteratively harmonize the manipulated object into the target location and inpaint its original location, while ensuring image consistency by anchoring the edited image to be generated to the pixel-manipulated image as well as by introducing various consistency-preserving optimization techniques during inference. Experimental evaluations based on benchmark datasets as well as extensive visual comparisons show that in as few as 16 inference steps, PixelMan outperforms a range of state-of-the-art training-based and training-free methods (usually requiring 50 steps) on multiple consistent object editing tasks.', 'abstract_zh': '近年来的研究探讨了扩散模型（DMs）在保持对象一致性编辑中的潜在应用，旨在修改对象的位置、大小和组成等元素，同时保持对象和背景的一致性，而不改变它们的纹理和属性。当前的推理方法通常依赖于DDIM反向过程，这会不可避免地牺牲效率和编辑图像的一致性。最近的方法还利用能量引导机制，通过迭代更新预测噪声，可能导致潜在向量远离原始图像，从而产生失真。本文提出了一种无反转和无训练的方法——PixelMan，通过像素操控和生成实现一致对象编辑，该方法直接在像素空间中在目标位置创建源对象的副本，并引入高效采样方法，以迭代方式将操控对象和谐地融入目标位置，并用掉漆方法修复其原始位置，同时通过将编辑后的图像锚定到像素操控的图像以及引入各种一致性的优化技术来确保图像一致性。\n\n实验评估基于基准数据集，并进行了广泛的视觉比较，结果显示，在仅16次推理步骤中，PixelMan 在多个一致对象编辑任务上优于一系列最新的基于训练和无训练方法（通常需要50步）。', 'title_zh': 'PixelMan：通过像素操作与生成一致对象编辑的扩散模型方法'}
{'arxiv_id': 'arXiv:2412.14276', 'title': 'Fake News Detection: Comparative Evaluation of BERT-like Models and Large Language Models with Generative AI-Annotated Data', 'authors': 'haina Raza, Drai Paulen-Patterson, Chen Ding', 'link': 'https://arxiv.org/abs/2412.14276', 'abstract': 'Fake news poses a significant threat to public opinion and social stability in modern society. This study presents a comparative evaluation of BERT-like encoder-only models and autoregressive decoder-only large language models (LLMs) for fake news detection. We introduce a dataset of news articles labeled with GPT-4 assistance (an AI-labeling method) and verified by human experts to ensure reliability. Both BERT-like encoder-only models and LLMs were fine-tuned on this dataset. Additionally, we developed an instruction-tuned LLM approach with majority voting during inference for label generation. Our analysis reveals that BERT-like models generally outperform LLMs in classification tasks, while LLMs demonstrate superior robustness against text perturbations. Compared to weak labels (distant supervision) data, the results show that AI labels with human supervision achieve better classification results. This study highlights the effectiveness of combining AI-based annotation with human oversight and demonstrates the performance of different families of machine learning models for fake news detection', 'abstract_zh': '虚假信息在现代社会中对公众意见和社会稳定构成了重大威胁。本研究对比评估了基于BERT的编码器模型和自回归解码器大规模语言模型（LLMs）在虚假信息检测中的效果。我们引入了一个由GPT-4协助标注并由人类专家验证的新闻文章数据集，以确保其可靠性。这两种模型（基于BERT的编码器模型和LLMs）均在此数据集上进行了微调。此外，我们还在推理过程中开发了一种多数投票调优的LLM方法，用于生成标签。分析结果表明，基于BERT的模型在分类任务中通常优于LLMs，而LLMs对文本扰动的鲁棒性更强。与弱标签数据集相比，使用受人类监督的人工智能标签数据集能够获得更好的分类效果。本研究强调了将基于人工智能的注释与人类监督相结合的有效性，并展示了不同类型机器学习模型在虚假信息检测中的性能。', 'title_zh': '虚假新闻检测：基于BERT类模型与生成式AI注释数据的大语言模型的比较评估'}
{'arxiv_id': 'arXiv:2412.14272', 'title': 'Split Learning in Computer Vision for Semantic Segmentation Delay Minimization', 'authors': 'Nikos G. Evgenidis, Nikos A. Mitsiou, Sotiris A. Tegos, Panagiotis D. Diamantoulakis, George K. Karagiannidis', 'link': 'https://arxiv.org/abs/2412.14272', 'abstract': "In this paper, we propose a novel approach to minimize the inference delay in semantic segmentation using split learning (SL), tailored to the needs of real-time computer vision (CV) applications for resource-constrained devices. Semantic segmentation is essential for applications such as autonomous vehicles and smart city infrastructure, but faces significant latency challenges due to high computational and communication loads. Traditional centralized processing methods are inefficient for such scenarios, often resulting in unacceptable inference delays. SL offers a promising alternative by partitioning deep neural networks (DNNs) between edge devices and a central server, enabling localized data processing and reducing the amount of data required for transmission. Our contribution includes the joint optimization of bandwidth allocation, cut layer selection of the edge devices' DNN, and the central server's processing resource allocation. We investigate both parallel and serial data processing scenarios and propose low-complexity heuristic solutions that maintain near-optimal performance while reducing computational requirements. Numerical results show that our approach effectively reduces inference delay, demonstrating the potential of SL for improving real-time CV applications in dynamic, resource-constrained environments.", 'abstract_zh': '在本文中，我们提出了一种新的方法，利用拆分学习（SL）来最小化语义分割中的推理延迟，以满足资源受限设备上实时计算机视觉（CV）应用的需求。语义分割对于自动驾驶车辆和智能城市基础设施等应用至关重要，但因高计算和通信负荷而面临显著的延迟挑战。传统的集中式处理方法在这些场景中效率低下，往往会导致无法接受的推理延迟。拆分学习通过在边缘设备和中央服务器之间划分深度神经网络（DNN），实现了本地化数据处理，减少了需要传输的数据量，从而提供了一种有前景的替代方案。我们的贡献包括联合优化带宽分配、边缘设备DNN的切分层选择以及中央服务器的处理资源分配。我们研究了并行和串行数据处理场景，并提出了低复杂度启发式解决方案，这些方案能够在降低计算需求的同时维持接近最优的性能。数值结果表明，我们的方法有效减少了推理延迟，展示了拆分学习在动态、资源受限环境中改善实时CV应用的潜力。', 'title_zh': '计算机视觉中的分割学习：面向语义分割的延迟最小化'}
{'arxiv_id': 'arXiv:2412.14234', 'title': 'Syzygy: Dual Code-Test C to (safe) Rust Translation using LLMs and Dynamic Analysis', 'authors': 'Manish Shetty, Naman Jain, Adwait Godbole, Sanjit A. Seshia, Koushik Sen', 'link': 'https://arxiv.org/abs/2412.14234', 'abstract': 'Despite extensive usage in high-performance, low-level systems programming applications, C is susceptible to vulnerabilities due to manual memory management and unsafe pointer operations. Rust, a modern systems programming language, offers a compelling alternative. Its unique ownership model and type system ensure memory safety without sacrificing performance.\nIn this paper, we present Syzygy, an automated approach to translate C to safe Rust. Our technique uses a synergistic combination of LLM-driven code and test translation guided by dynamic-analysis-generated execution information. This paired translation runs incrementally in a loop over the program in dependency order of the code elements while maintaining per-step correctness. Our approach exposes novel insights on combining the strengths of LLMs and dynamic analysis in the context of scaling and combining code generation with testing. We apply our approach to successfully translate Zopfli, a high-performance compression library with ~3000 lines of code and 98 functions. We validate the translation by testing equivalence with the source C program on a set of inputs. To our knowledge, this is the largest automated and test-validated C to safe Rust code translation achieved so far.', 'abstract_zh': '尽管C语言在高性能和低级别的系统编程应用中被广泛使用，但由于其手动内存管理和不安全的指针操作，C语言容易遭受漏洞攻击。rust是一种现代的系统编程语言，提供了极具吸引力的替代方案。其独特的所有权模型和类型系统确保了内存安全，同时不牺牲性能。\n\n在本文中，我们提出了一种名为Syzygy的自动将C代码翻译为安全Rust代码的方法。我们的技术结合了由大规模语言模型（LLM）驱动的代码和测试的自动翻译，并由动态分析生成的执行信息引导。这一对的翻译以依赖关系顺序循环地对程序中的代码元素进行增量处理，并在每一步保持正确性。我们的方法在将大规模语言模型和动态分析相结合的背景下，揭示了代码生成与测试融合的新见解。我们应用该方法成功地将Zopfli（一个约3000行代码和98个函数的高性能压缩库）进行了翻译。我们通过在一组输入上测试其与源代码C版本的等价性来验证翻译的有效性。据我们所知，这是迄今为止首次实现的最全面的自动和测试验证的C到安全Rust代码翻译。', 'title_zh': '共生：使用大语言模型和动态分析将双工代码测试 C 转换为 (安全的) Rust'}
{'arxiv_id': 'arXiv:2412.14219', 'title': 'A Survey on Inference Optimization Techniques for Mixture of Experts Models', 'authors': 'Jiacheng Liu, Peng Tang, Wenfeng Wang, Yuhang Ren, Xiaofeng Hou, Pheng-Ann Heng, Minyi Guo, Chao Li', 'link': 'https://arxiv.org/abs/2412.14219', 'abstract': 'The emergence of large-scale Mixture of Experts (MoE) models has marked a significant advancement in artificial intelligence, offering enhanced model capacity and computational efficiency through conditional computation. However, the deployment and inference of these models present substantial challenges in terms of computational resources, latency, and energy efficiency. This comprehensive survey systematically analyzes the current landscape of inference optimization techniques for MoE models across the entire system stack. We first establish a taxonomical framework that categorizes optimization approaches into model-level, system-level, and hardware-level optimizations. At the model level, we examine architectural innovations including efficient expert design, attention mechanisms, various compression techniques such as pruning, quantization, and knowledge distillation, as well as algorithm improvement including dynamic routing strategies and expert merging methods. At the system level, we investigate distributed computing approaches, load balancing mechanisms, and efficient scheduling algorithms that enable scalable deployment. Furthermore, we delve into hardware-specific optimizations and co-design strategies that maximize throughput and energy efficiency. This survey not only provides a structured overview of existing solutions but also identifies key challenges and promising research directions in MoE inference optimization. Our comprehensive analysis serves as a valuable resource for researchers and practitioners working on large-scale deployment of MoE models in resource-constrained environments. To facilitate ongoing updates and the sharing of cutting-edge advances in MoE inference optimization research, we have established a repository accessible at \\url{this https URL}.', 'abstract_zh': '大规模专家混合模型（Mixture of Experts, MoE）的兴起标志着人工智能领域的一项重要进步，通过条件计算增强了模型容量和计算效率。然而，这些模型的部署和推理在计算资源、延迟和能源效率方面带来了显著挑战。本综述系统分析了MoE模型在整个系统堆栈中的推理优化技术。我们首先建立了一种分类框架，将优化方法分为模型层面、系统层面和硬件层面的优化。在模型层面，我们探讨了架构创新，包括高效的专家设计、注意力机制、各种压缩技术（如剪枝、量化和知识蒸馏），以及算法改进（如动态路由策略和专家合并方法）。在系统层面，我们研究了分布式计算方法、负载均衡机制以及高效的调度算法，以实现可扩展部署。此外，我们还深入探讨了特定硬件的优化和协同设计策略，以最大化吞吐量和能源效率。本综述不仅提供了现有解决方案的结构化概述，还指出了MoE推理优化中关键的挑战和有希望的研究方向。我们全面的分析为在资源受限环境中部署大规模MoE模型的研究人员和实践者提供了宝贵的资源。为了促进MoE推理优化研究的持续更新和尖端成果的分享，我们建立了一个可访问的代码库：\\url{this https URL}。', 'title_zh': '混合专家模型推理优化技术综述'}
{'arxiv_id': 'arXiv:2412.14218', 'title': 'Heterogeneous Multi-Agent Reinforcement Learning for Distributed Channel Access in WLANs', 'authors': 'Jiaming Yu, Le Liang, Chongtao Guo, Ziyang Guo, Shi Jin, Geoffrey Ye Li', 'link': 'https://arxiv.org/abs/2412.14218', 'abstract': 'This paper investigates the use of multi-agent reinforcement learning (MARL) to address distributed channel access in wireless local area networks. In particular, we consider the challenging yet more practical case where the agents heterogeneously adopt value-based or policy-based reinforcement learning algorithms to train the model. We propose a heterogeneous MARL training framework, named QPMIX, which adopts a centralized training with distributed execution paradigm to enable heterogeneous agents to collaborate. Moreover, we theoretically prove the convergence of the proposed heterogeneous MARL method when using the linear value function approximation. Our method maximizes the network throughput and ensures fairness among stations, therefore, enhancing the overall network performance. Simulation results demonstrate that the proposed QPMIX algorithm improves throughput, mean delay, delay jitter, and collision rates compared with conventional carrier-sense multiple access with collision avoidance in the saturated traffic scenario. Furthermore, the QPMIX is shown to be robust in unsaturated and delay-sensitive traffic scenarios, and promotes cooperation among heterogeneous agents.', 'abstract_zh': '本文探讨了多智能体强化学习（MARL）在无线局域网中分布式信道访问中的应用。特别地，我们考虑了一种更具挑战性但也更实际的情况，即不同智能体异质采用基于值或基于策略的强化学习算法进行模型训练。我们提出了一种名为QPMIX的异质MARL训练框架，采用集中训练与分布式执行的范式，使得不同智能体能够协同工作。此外，我们理论证明了在使用线性值函数近似时，所提出的异质MARL方法的收敛性。该方法通过最大化网络吞吐量和确保站点之间的公平性，从而提升整体网络性能。仿真结果表明，在饱和流量场景下，所提出的QPMIX算法相较于传统带有冲突避免机制的载波侦听多路访问（CSMA/CA）方法，在吞吐量、平均延迟、延迟抖动和碰撞率方面均有所提升。此外，QPMIX在非饱和和延迟敏感流量场景下表现出良好的鲁棒性，并促进不同智能体之间的合作。', 'title_zh': '异构多代理强化学习在WLAN中分布式信道访问中的应用'}
{'arxiv_id': 'arXiv:2412.14215', 'title': 'Generative AI Toolkit -- a framework for increasing the quality of LLM-based applications over their whole life cycle', 'authors': 'Jens Kohl, Luisa Gloger, Rui Costa, Otto Kruse, Manuel P. Luitz, David Katz, Gonzalo Barbeito, Markus Schweier, Ryan French, Jonas Schroeder, Thomas Riedl, Raphael Perri, Youssef Mostafa', 'link': 'https://arxiv.org/abs/2412.14215', 'abstract': 'As LLM-based applications reach millions of customers, ensuring their scalability and continuous quality improvement is critical for success. However, the current workflows for developing, maintaining, and operating (DevOps) these applications are predominantly manual, slow, and based on trial-and-error. With this paper we introduce the Generative AI Toolkit, which automates essential workflows over the whole life cycle of LLM-based applications. The toolkit helps to configure, test, continuously monitor and optimize Generative AI applications such as agents, thus significantly improving quality while shortening release cycles. We showcase the effectiveness of our toolkit on representative use cases, share best practices, and outline future enhancements. Since we are convinced that our Generative AI Toolkit is helpful for other teams, we are open sourcing it on and hope that others will use, forward, adapt and improve', 'abstract_zh': '当基于大型语言模型（LLM）的应用程序达到数百万用户时，确保其可扩展性和持续的质量改进对于成功至关重要。然而，当前开发、维护和运营（DevOps）这些应用程序的工作流程主要是手动的、缓慢的，并且基于试错。本文我们介绍了生成式AI工具包，该工具包实现了基于整个生命周期的生成式AI应用程序的核心工作流程自动化。此工具包有助于配置、测试、持续监控和优化生成式AI应用（如代理程序），从而显著提高质量并缩短发布周期。我们通过典型用例展示了该工具包的有效性，分享了最佳实践，并概述了未来改进的方向。鉴于我们相信我们的生成式AI工具包对其他团队很有帮助，我们决定将其开源，希望他人能够使用、传播、适应并改进它。', 'title_zh': '生成式AI工具包——一种提升基于LLM的应用在整个生命周期中质量的框架'}
{'arxiv_id': 'arXiv:2412.14214', 'title': 'GraphicsDreamer: Image to 3D Generation with Physical Consistency', 'authors': 'Pei Chen, Fudong Wang, Yixuan Tong, Jingdong Chen, Ming Yang, Minghui Yang', 'link': 'https://arxiv.org/abs/2412.14214', 'abstract': "Recently, the surge of efficient and automated 3D AI-generated content (AIGC) methods has increasingly illuminated the path of transforming human imagination into complex 3D structures. However, the automated generation of 3D content is still significantly lags in industrial application. This gap exists because 3D modeling demands high-quality assets with sharp geometry, exquisite topology, and physically based rendering (PBR), among other criteria. To narrow the disparity between generated results and artists' expectations, we introduce GraphicsDreamer, a method for creating highly usable 3D meshes from single images. To better capture the geometry and material details, we integrate the PBR lighting equation into our cross-domain diffusion model, concurrently predicting multi-view color, normal, depth images, and PBR materials. In the geometry fusion stage, we continue to enforce the PBR constraints, ensuring that the generated 3D objects possess reliable texture details, supporting realistic relighting. Furthermore, our method incorporates topology optimization and fast UV unwrapping capabilities, allowing the 3D products to be seamlessly imported into graphics engines. Extensive experiments demonstrate that our model can produce high quality 3D assets in a reasonable time cost compared to previous methods.", 'abstract_zh': '近年来，高效且自动化的3D人工智能生成内容（AIGC）方法的迅猛发展逐渐照亮了将人类想象力转化为复杂3D结构的道路。然而，3D内容的自动化生成在工业应用中仍然显著滞后。这一差距存在是因为3D建模需要高质量的资产，包括锐利的几何结构、精美的拓扑结构以及基于物理的渲染（PBR）等其他标准。为了缩小生成结果与艺术家期望之间的差距，我们引入了GraphicsDreamer方法，旨在从单张图像中生成高度可用的3D网格。为了更好地捕捉几何和材质细节，我们在跨域扩散模型中结合了PBR光照方程，同时预测多视角的颜色、法线、深度图像和PBR材质。在几何融合阶段，我们继续施加PBR约束，确保生成的3D对象具有可靠的纹理细节，支持真实的重新光照。此外，我们的方法还集成了拓扑优化和快速UV展开能力，使得3D产品能够无缝导入图形引擎。广泛的实验表明，与前一种方法相比，我们的模型能够在合理的时间成本内生成高质量的3D资产。', 'title_zh': 'GraphicsDreamer：具有物理一致性的从图像到3D生成'}
{'arxiv_id': 'arXiv:2412.14212', 'title': 'Tree-of-Code: A Hybrid Approach for Robust Complex Task Planning and Execution', 'authors': 'Ziyi Ni, Yifan Li, Daxiang Dong', 'link': 'https://arxiv.org/abs/2412.14212', 'abstract': "The exceptional capabilities of large language models (LLMs) have substantially accelerated the rapid rise and widespread adoption of agents. Recent studies have demonstrated that generating Python code to consolidate LLM-based agents' actions into a unified action space (CodeAct) is a promising approach for developing real-world LLM agents. However, this step-by-step code generation approach often lacks consistency and robustness, leading to instability in agent applications, particularly for complex reasoning and out-of-domain tasks. In this paper, we propose a novel approach called Tree-of-Code (ToC) to tackle the challenges of complex problem planning and execution with an end-to-end mechanism. By integrating key ideas from both Tree-of-Thought and CodeAct, ToC combines their strengths to enhance solution exploration. In our framework, each final code execution result is treated as a node in the decision tree, with a breadth-first search strategy employed to explore potential solutions. The final outcome is determined through a voting mechanism based on the outputs of the nodes.", 'abstract_zh': '大型语言模型（LLMs）的出色能力极大地促进了基于代理的快速崛起和广泛应用。近期的研究表明，将LLM代理的操作整合到一个统一的操作空间中（CodeAct）并生成对应的Python代码，是一种有前景的方法，可用于开发实际应用中的LLM代理。然而，这种逐步代码生成的方法往往缺乏一致性和稳健性，导致代理应用不稳定，特别是在复杂的推理和跨领域任务中表现尤为明显。本文提出了一种名为Code树（ToC）的新方法，以端到端机制解决复杂问题规划和执行的挑战。通过整合Tree-of-Thought和CodeAct的关键思想，ToC结合了它们的优势，以增强解决方案的探索。在我们的框架中，每一行最终代码执行结果都被视为决策树中的一个节点，并采用广度优先搜索策略来探索潜在的解决方案。最终结果是通过对节点输出进行投票机制确定的。', 'title_zh': 'Tree-of-Code：一种稳健的复杂任务规划与执行的混合方法'}
{'arxiv_id': 'arXiv:2412.14209', 'title': 'Integrating Evidence into the Design of XAI and AI-based Decision Support Systems: A Means-End Framework for End-users in Construction', 'authors': 'Peter .E.D. Love, Jane Matthews, Weili Fang, Hadi Mahamivanan', 'link': 'https://arxiv.org/abs/2412.14209', 'abstract': "A narrative review is used to develop a theoretical evidence-based means-end framework to build an epistemic foundation to uphold explainable artificial intelligence instruments so that the reliability of outcomes generated from decision support systems can be assured and better explained to end-users. The implications of adopting an evidence-based approach to designing decision support systems in construction are discussed with emphasis placed on evaluating the strength, value, and utility of evidence needed to develop meaningful human explanations for end-users. While the developed means-end framework is focused on end-users, stakeholders can also utilize it to create meaningful human explanations. However, they will vary due to their different epistemic goals. Including evidence in the design and development of explainable artificial intelligence and decision support systems will improve decision-making effectiveness, enabling end-users' epistemic goals to be achieved. The proposed means-end framework is developed from a broad spectrum of literature. Thus, it is suggested that it can be used in construction and other engineering domains where there is a need to integrate evidence into the design of explainable artificial intelligence and decision support systems.", 'abstract_zh': '本文采用叙述性综述的方法，构建了一个基于理论证据的手段-目的框架，以建立知识论基础，支撑可解释的人工智能工具，确保决策支持系统生成的结果具有可靠性并能够更好地向最终用户提供解释。讨论了采用证据为基础的方法设计建筑领域决策支持系统的意义，并强调了需要评估证据的强度、价值和效用，以开发有意义的人类解释。虽然所构建的手段-目的框架着眼于最终用户，但利益相关者也可以利用它来创建有意义的人类解释，但由于其不同的知识目标，这些解释会有所不同。将证据纳入可解释的人工智能和决策支持系统的设计与开发，将提高决策有效性，使最终用户的知识目标得以实现。所提出的手段-目的框架源于广泛的文献综述，因此建议它可以在需要将证据纳入可解释的人工智能和决策支持系统设计的建筑和其他工程领域中使用。', 'title_zh': '将证据整合到XAI和基于AI的决策支持系统设计中：建筑行业最终用户的一种目的手段框架'}
{'arxiv_id': 'arXiv:2412.14205', 'title': 'Large-scale Group Brainstorming using Conversational Swarm Intelligence (CSI) versus Traditional Chat', 'authors': 'Louis Rosenberg, Hans Schumann, Christopher Dishop, Gregg Willcox, Anita Woolley, Ganesh Mani', 'link': 'https://arxiv.org/abs/2412.14205', 'abstract': 'Conversational Swarm Intelligence (CSI) is an AI-facilitated method for enabling real-time conversational deliberations and prioritizations among networked human groups of potentially unlimited size. Based on the biological principle of Swarm Intelligence and modelled on the decision-making dynamics of fish schools, CSI has been shown in prior studies to amplify group intelligence, increase group participation, and facilitate productive collaboration among hundreds of participants at once. It works by dividing a large population into a set of small subgroups that are woven together by real-time AI agents called Conversational Surrogates. The present study focuses on the use of a CSI platform called Thinkscape to enable real-time brainstorming and prioritization among groups of 75 networked users. The study employed a variant of a common brainstorming intervention called an Alternative Use Task (AUT) and was designed to compare through subjective feedback, the experience of participants brainstorming using a CSI structure vs brainstorming in a single large chat room. This comparison revealed that participants significantly preferred brainstorming with the CSI structure and reported that it felt (i) more collaborative, (ii) more productive, and (iii) was better at surfacing quality answers. In addition, participants using the CSI structure reported (iv) feeling more ownership and more buy-in in the final answers the group converged on and (v) reported feeling more heard as compared to brainstorming in a traditional text chat environment. Overall, the results suggest that CSI is a very promising AI-facilitated method for brainstorming and prioritization among large-scale, networked human groups.', 'abstract_zh': '对话蚁群智能（Conversational Swarm Intelligence, CSI）是一种通过人工智能引导的方法，用于在网络化的人群组中实现实时对话性协商和优先级排序，而这些人群组的规模可能无限。基于生物界的蚁群智能原理，CSI 类似于研究鱼类群体决策动态的方法，研究表明它可以放大群体智能，增加群体参与度，并促进数百名参与者同时的高效协作。该方法通过将大量人群细分为由实时 AI 代理（对话代理）连接起来的小群体来实现。本研究专注于使用名为 Thinkscape 的 CSI 平台，以实现 75 名网络用户的实时头脑风暴和优先级排序。该研究采用了一种常见的头脑风暴干预措施——替代用途任务（AUT）的变体，并设计了通过主观反馈比较在 CSI 结构下头脑风暴与单一大型聊天室头脑风暴之间的差异。比较结果表明，参与者更偏好使用 CSI 结构进行头脑风暴，并报告称这（i）更具有协作性，（ii）更具有生产力，（iii）更善于提出高质量的答案。此外，使用 CSI 结构的参与者还报告称（iv）对最终达成共识的答案有更强的所有权感和认同感，并且（v）在传统文本聊天环境中感觉得到了更多的倾听。总体而言，研究结果表明，CSI 是一种非常有前景的人工智能辅助方法，适用于大规模网络化人群的头脑风暴和优先级排序。', 'title_zh': '大规模群体头脑风暴：基于对话型群智智能（CSI）的对比研究 versus 传统的聊天方式'}
{'arxiv_id': 'arXiv:2412.14203', 'title': 'BlenderLLM: Training Large Language Models for Computer-Aided Design with Self-improvement', 'authors': 'Yuhao Du, Shunian Chen, Wenbo Zan, Peizhao Li, Mingxuan Wang, Dingjie Song, Bo Li, Yan Hu, Benyou Wang', 'link': 'https://arxiv.org/abs/2412.14203', 'abstract': 'The application of Large Language Models (LLMs) in Computer-Aided Design (CAD) remains an underexplored area, despite their remarkable advancements in other domains. In this paper, we present BlenderLLM, a novel framework for training LLMs specifically for CAD tasks leveraging a self-improvement methodology. To support this, we developed a bespoke training dataset, BlendNet, and introduced a comprehensive evaluation suite, CADBench. Our results reveal that existing models demonstrate significant limitations in generating accurate CAD scripts. However, through minimal instruction-based fine-tuning and iterative self-improvement, BlenderLLM significantly surpasses these models in both functionality and accuracy of CAD script generation. This research establishes a strong foundation for the application of LLMs in CAD while demonstrating the transformative potential of self-improving models in advancing CAD automation. We encourage further exploration and adoption of these methodologies to drive innovation in the field. The dataset, model, benchmark, and source code are publicly available at this https URL', 'abstract_zh': '大规模语言模型（LLMs）在计算机辅助设计（CAD）中的应用尽管其他领域取得了显著进展，仍是一个未被充分探索的领域。本文介绍了一种名为BlenderLLM的新框架，该框架利用自我改进方法专门针对CAD任务进行训练。为此，我们开发了一个定制化的训练数据集BlendNet，并引入了全面的评估套件CADBench。实验结果表明，现有模型在生成准确的CAD脚本方面存在显著局限性。然而，通过最少的指令微调和迭代自我改进，BlenderLLM在CAD脚本生成的功能性和准确性方面显著超越了这些模型。本文的研究为LLMs在CAD中的应用奠定了坚实的基础，并展示了自我改进模型在推动CAD自动化方面的变革潜力。我们鼓励进一步探索和采用这些方法，以推动该领域的创新。所有数据集、模型、基准测试和源代码均可通过以下链接获取：[在这里插入具体的网址]', 'title_zh': 'BlenderLLM：用于计算机辅助设计的大语言模型自改进训练'}
{'arxiv_id': 'arXiv:2412.14194', 'title': 'Detecting Cognitive Impairment and Psychological Well-being among Older Adults Using Facial, Acoustic, Linguistic, and Cardiovascular Patterns Derived from Remote Conversations', 'authors': 'Xiaofan Mu, Salman Seyedi, Iris Zheng, Zifan Jiang, Liu Chen, Bolaji Omofojoye, Rachel Hershenberg, Allan I. Levey, Gari D. Clifford, Hiroko H. Dodge, Hyeokhyen Kwon', 'link': 'https://arxiv.org/abs/2412.14194', 'abstract': 'INTRODUCTION: The aging society urgently requires scalable methods to monitor cognitive decline and identify social and psychological factors indicative of dementia risk in older adults. METHODS: Our machine learning models captured facial, acoustic, linguistic, and cardiovascular features from 39 individuals with normal cognition or Mild Cognitive Impairment derived from remote video conversations and classified cognitive status, social isolation, neuroticism, and psychological well-being. RESULTS: Our model could distinguish Clinical Dementia Rating Scale of 0.5 (vs. 0) with 0.78 area under the receiver operating characteristic curve (AUC), social isolation with 0.75 AUC, neuroticism with 0.71 AUC, and negative affect scales with 0.79 AUC. DISCUSSION: Our findings demonstrate the feasibility of remotely monitoring cognitive status, social isolation, neuroticism, and psychological well-being. Speech and language patterns were more useful for quantifying cognitive impairment, whereas facial expression and cardiovascular patterns using remote photoplethysmography were more useful for quantifying personality and psychological well-being.', 'abstract_zh': '引言：老龄化社会迫切需要能大规模应用的方法来监测认知衰退，并识别老年人中痴呆风险的社会和心理因素。\n\n方法：我们的机器学习模型通过远程视频对话捕捉到39名认知正常或轻度认知障碍个体的面部、声学、语言和心血管特征，并对其认知状态、社会孤立、神经质和心理幸福感进行了分类。\n\n结果：我们的模型能够通过受试者操作特征曲线（AUC）分别为0.78（临床认知功能衰退评定量表分数0.5 vs. 0）、0.75、0.71和0.79区分认知状态、社会孤立、神经质和负性情绪量表。 \n\n讨论：我们的研究结果表明，远程监测认知状态、社会孤立、神经质和心理幸福感是可行的。语音和语言模式在量化认知损害方面更为有用，而面部表情和通过远程光电监测获得的心血管模式在量化个性和心理幸福感方面更为有用。', 'title_zh': '利用远程对话中提取的面部表情、声学、语言和心血管模式检测老年人的认知障碍和心理福祉'}
{'arxiv_id': 'arXiv:2412.14193', 'title': 'Whom do Explanations Serve? A Systematic Literature Survey of User Characteristics in Explainable Recommender Systems Evaluation', 'authors': 'Kathrin Wardatzky, Oana Inel, Luca Rossetto, Abraham Bernstein', 'link': 'https://arxiv.org/abs/2412.14193', 'abstract': "Adding explanations to recommender systems is said to have multiple benefits, such as increasing user trust or system transparency. Previous work from other application areas suggests that specific user characteristics impact the users' perception of the explanation. However, we rarely find this type of evaluation for recommender systems explanations. This paper addresses this gap by surveying 124 papers in which recommender systems explanations were evaluated in user studies. We analyzed their participant descriptions and study results where the impact of user characteristics on the explanation effects was measured. Our findings suggest that the results from the surveyed studies predominantly cover specific users who do not necessarily represent the users of recommender systems in the evaluation domain. This may seriously hamper the generalizability of any insights we may gain from current studies on explanations in recommender systems. We further find inconsistencies in the data reporting, which impacts the reproducibility of the reported results. Hence, we recommend actions to move toward a more inclusive and reproducible evaluation.", 'abstract_zh': '将推荐系统添加解释被认为具有多种益处，例如增加用户信任或提高系统透明度。其他应用领域的先前研究指出，特定用户特征会影响其对解释的认知。然而，我们很少在推荐系统解释的研究中找到这种类型的效果评估。本文通过调查124篇在用户研究中评估推荐系统解释的论文，填补了这一空白。我们分析了这些研究中的参与者描述和研究结果，这些结果测量了用户特征对解释效果的影响。我们的发现表明，被调查的研究结果主要集中在特定用户群体上，这些用户不一定能代表评估领域中推荐系统的用户。这可能严重影响我们从当前关于推荐系统解释的研究中获得的任何见解的泛化能力。我们还发现数据报告存在不一致性，这影响了报告结果的可重复性。因此，我们建议采取措施，以实现更具包容性和可重复性的评估。', 'title_zh': '可解释推荐系统评估中用户特征的研究综述：解释服务于谁？'}
{'arxiv_id': 'arXiv:2412.14191', 'title': 'Ontology-Aware RAG for Improved Question-Answering in Cybersecurity Education', 'authors': 'Chengshuai Zhao, Garima Agrawal, Tharindu Kumarage, Zhen Tan, Yuli Deng, Ying-Chih Chen, Huan Liu', 'link': 'https://arxiv.org/abs/2412.14191', 'abstract': 'Integrating AI into education has the potential to transform the teaching of science and technology courses, particularly in the field of cybersecurity. AI-driven question-answering (QA) systems can actively manage uncertainty in cybersecurity problem-solving, offering interactive, inquiry-based learning experiences. Large language models (LLMs) have gained prominence in AI-driven QA systems, offering advanced language understanding and user engagement. However, they face challenges like hallucinations and limited domain-specific knowledge, which reduce their reliability in educational settings. To address these challenges, we propose CyberRAG, an ontology-aware retrieval-augmented generation (RAG) approach for developing a reliable and safe QA system in cybersecurity education. CyberRAG employs a two-step approach: first, it augments the domain-specific knowledge by retrieving validated cybersecurity documents from a knowledge base to enhance the relevance and accuracy of the response. Second, it mitigates hallucinations and misuse by integrating a knowledge graph ontology to validate the final answer. Experiments on publicly available cybersecurity datasets show that CyberRAG delivers accurate, reliable responses aligned with domain knowledge, demonstrating the potential of AI tools to enhance education.', 'abstract_zh': '将人工智能融入教育有可能变革科学和技术课程的教学，特别是在网络安全领域。基于人工智能的问题回答（QA）系统可以在网络安全问题解决中主动管理不确定性，提供互动性和探究性学习体验。大型语言模型（LLMs）在基于人工智能的QA系统中崭露头角，提供了高级的语言理解和用户参与度。然而，它们面临诸如幻觉和有限的领域特定知识等挑战，这在教育环境中降低了它们的可靠性。为了解决这些挑战，我们提出了一种名为CyberRAG的基于本体增强检索增强生成（RAG）方法，以开发网络安全教育中可靠且安全的QA系统。CyberRAG采用两步方法：首先，通过从知识库中检索验证过的网络安全文件来增强领域特定知识，以提高响应的相关性和准确性；其次，通过集成知识图谱本体来验证最终答案，从而减轻幻觉和滥用问题。公开可用的网络安全数据集上的实验结果显示，CyberRAG提供了与领域知识一致的准确且可靠的响应，展示了人工智能工具在增强教育方面的潜在价值。', 'title_zh': '带有本体意识的检索增强方法在网络安全教育中的改进问答应用'}
{'arxiv_id': 'arXiv:2412.14190', 'title': 'Lessons From an App Update at Replika AI: Identity Discontinuity in Human-AI Relationships', 'authors': 'Julian De Freitas, Noah Castelo, Ahmet Uguralp, Zeliha Uguralp', 'link': 'https://arxiv.org/abs/2412.14190', 'abstract': 'Can consumers form especially deep emotional bonds with AI and be vested in AI identities over time? We leverage a natural app-update event at Replika AI, a popular US-based AI companion, to shed light on these questions. We find that, after the app removed its erotic role play (ERP) feature, preventing intimate interactions between consumers and chatbots that were previously possible, this event triggered perceptions in customers that their AI companion\'s identity had discontinued. This in turn predicted negative consumer welfare and marketing outcomes related to loss, including mourning the loss, and devaluing the "new" AI relative to the "original". Experimental evidence confirms these findings. Further experiments find that AI companions users feel closer to their AI companion than even their best human friend, and mourn a loss of their AI companion more than a loss of various other inanimate products. In short, consumers are forming human-level relationships with AI companions; disruptions to these relationships trigger real patterns of mourning as well as devaluation of the offering; and the degree of mourning and devaluation are explained by perceived discontinuity in the AIs identity. Our results illustrate that relationships with AI are truly personal, creating unique benefits and risks for consumers and firms alike.', 'abstract_zh': '消费者能否与人工智能形成特别深厚的情感纽带，并对其身份产生持续的依附感？我们利用一款名为Replika AI的流行AI伴侣在自然更新事件中，探讨了这些问题。研究发现，当应用移除了其情色角色扮演功能，阻止了用户与以前可以进行的亲密互动时，这一事件引发了客户认为其AI伴侣身份终止的感知。这进一步预示了因失去而导致的消费者福利和营销结果的负面影响，包括哀悼失去的AI，以及将“新”的AI贬值为“原版”。实验数据证实了这些发现。进一步的实验证明，AI伴侣的用户认为他们与AI伴侣的关系比与他们最好的人类朋友更亲密，并对失去AI伴侣的哀悼程度超过对各种其他无生命的商品的哀悼。简而言之，消费者正在与AI伴侣建立类人类的关系；这些关系的中断引发了真实的哀悼模式以及对产品本身的价值贬低；哀悼和贬值的程度可以通过感知到的AI身份中断来解释。我们的研究结果表明，与人工智能的关系是真正个人化的，为消费者和企业都创造了独特的益处和风险。', 'title_zh': '来自 Replika AI 应用程序更新的经验教训：人类-人工智能关系中的身份连续性中断'}
{'arxiv_id': 'arXiv:2412.14188', 'title': 'CogSimulator: A Model for Simulating User Cognition & Behavior with Minimal Data for Tailored Cognitive Enhancement', 'authors': 'Weizhen Bian, Yubo Zhou, Yuanhang Luo, Ming Mo, Siyan Liu, Yikai Gong, Renjie Wan, Ziyuan Luo, Aobo Wang', 'link': 'https://arxiv.org/abs/2412.14188', 'abstract': 'The interplay between cognition and gaming, notably through educational games enhancing cognitive skills, has garnered significant attention in recent years. This research introduces the CogSimulator, a novel algorithm for simulating user cognition in small-group settings with minimal data, as the educational game Wordle exemplifies. The CogSimulator employs Wasserstein-1 distance and coordinates search optimization for hyperparameter tuning, enabling precise few-shot predictions in new game scenarios. Comparative experiments with the Wordle dataset illustrate that our model surpasses most conventional machine learning models in mean Wasserstein-1 distance, mean squared error, and mean accuracy, showcasing its efficacy in cognitive enhancement through tailored game design.', 'abstract_zh': '近年来，认知与游戏之间的相互作用，尤其是通过教育游戏提升认知技能，引起了广泛关注。本研究介绍了一种名为CogSimulator的新算法，该算法能够以最少的数据在小团体设置中模拟用户认知，以《woordle》为例。CogSimulator使用Wasserstein-1距离和坐标搜索优化超参数，能够准确地进行新的游戏情境下的少量示例预测。通过Wordle数据集的对比实验表明，我们的模型在Wasserstein-1距离、均方误差和准确率的均值方面均优于大多数传统机器学习模型，展示了其通过定制化游戏设计提升认知能力的有效性。\n\n请注意，为了符合更严格的学术规范，尤其是专业术语的使用，这里对文中提到的算法、指标和具体游戏（《woordle》）名称进行了适当的调整和翻译。《Wordle》是一个具体的数字猜词游戏，因此在这里进行了相应的中文翻译。如果您有特定的学术背景或要求，可以根据需要进一步调整。', 'title_zh': 'CogSimulator：一种基于最小数据量模拟用户认知与行为的模型，用于个性化认知增强'}
{'arxiv_id': 'arXiv:2412.14186', 'title': 'Towards AI-$45^{\\circ}$ Law: A Roadmap to Trustworthy AGI', 'authors': 'Yang Chao, Lu Chaochao, Wang Yingchun, Zhou Bowen', 'link': 'https://arxiv.org/abs/2412.14186', 'abstract': "Ensuring Artificial General Intelligence (AGI) reliably avoids harmful behaviors is a critical challenge, especially for systems with high autonomy or in safety-critical domains. Despite various safety assurance proposals and extreme risk warnings, comprehensive guidelines balancing AI safety and capability remain lacking. In this position paper, we propose the \\textit{AI-\\textbf{$45^{\\circ}$} Law} as a guiding principle for a balanced roadmap toward trustworthy AGI, and introduce the \\textit{Causal Ladder of Trustworthy AGI} as a practical framework. This framework provides a systematic taxonomy and hierarchical structure for current AI capability and safety research, inspired by Judea Pearl's ``Ladder of Causation''. The Causal Ladder comprises three core layers: the Approximate Alignment Layer, the Intervenable Layer, and the Reflectable Layer. These layers address the key challenges of safety and trustworthiness in AGI and contemporary AI systems. Building upon this framework, we define five levels of trustworthy AGI: perception, reasoning, decision-making, autonomy, and collaboration trustworthiness. These levels represent distinct yet progressive aspects of trustworthy AGI. Finally, we present a series of potential governance measures to support the development of trustworthy AGI.\\footnote{In this paper, trustworthiness is generally considered a broad form of safety, and no explicit distinction is made between the two. However, in some contexts, safety and trustworthiness are treated as distinct: safety involves assurance of correct behavior, while trustworthiness refers to user confidence in the system's decision-making. In such cases, different terms or both may be used depending on the context.", 'abstract_zh': '确保人工智能通用智能（AGI）可靠地避免有害行为是一项关键挑战，尤其是对于高自主性系统或在安全关键领域中的系统。尽管已提出了各种安全保证方案和极端风险警告，但在平衡人工智能安全与能力方面仍缺乏全面的指导原则。在本文中，我们提出了\\textit{AI-\\textbf{$45^{\\circ}$}法则}作为通向可信赖AGI的平衡路线图的指导原则，并介绍了\\textit{可信AGI因果阶梯}作为其实用框架。该框架通过借鉴Judea Pearl的“因果阶梯”提供了对当前人工智能能力和安全研究的一种系统分类和层级结构。可信AGI因果阶梯包含三个核心层次：近似对齐层、可干预层和可反思层。这些层次解决了AGI及现代人工智能系统中关键的安全与可信性挑战。基于该框架，我们定义了五级可信AGI：感知可信性、推理可信性、决策可信性、自主可信性和协作可信性。这些级别代表可信AGI的不同但具有进步性的方面。最后，我们提出了一系列潜在的治理措施来支持可信AGI的发展（注：在此文中，可信性一般被视为广泛形式的安全，并未在两者之间做出明确的区别。但在某些情况下，安全和可信性被视为不同的概念：安全涉及正确行为的保证，而可信性指的是用户对系统决策的信心。在这种情况下，根据具体语境，可以使用不同的术语或两者皆用）.', 'title_zh': '向AI-45°法则迈进：一条通往可信赖的人工通用智能的道路'}
{'arxiv_id': 'arXiv:2412.14179', 'title': 'Benchmarking Harmonized Tariff Schedule Classification Models', 'authors': 'Bryce Judy', 'link': 'https://arxiv.org/abs/2412.14179', 'abstract': "The Harmonized Tariff System (HTS) classification industry, essential to e-commerce and international trade, currently lacks standardized benchmarks for evaluating the effectiveness of classification solutions. This study establishes and tests a benchmark framework for imports to the United States, inspired by the benchmarking approaches used in language model evaluation, to systematically compare prominent HTS classification tools. The framework assesses key metrics--such as speed, accuracy, rationality, and HTS code alignment--to provide a comprehensive performance comparison. The study evaluates several industry-leading solutions, including those provided by Zonos, Tarifflo, Avalara, and WCO BACUDA, identifying each tool's strengths and limitations. Results highlight areas for industry-wide improvement and innovation, paving the way for more effective and standardized HTS classification solutions across the international trade and e-commerce sectors.", 'abstract_zh': '以下是符合学术规范的翻译：\n\n harmonized tariff system (HTS) 分类，对于电子商务和国际贸易至关重要，目前缺乏标准化的基准来评估分类解决方案的有效性。本研究受语言模型评估中基准测试方法的启发，建立并测试了针对美国进口的基准框架，以系统比较主要的 HTS 分类工具。该框架评估关键指标——如速度、准确性、合理性以及 HTS 代码对齐性——以进行全面的性能比较。研究评估了包括 Zonos、Tarifflo、Avalara 和 WCO BACUDA 在内的多种业界领先解决方案，指出每种工具的优势与局限性。研究结果突显了业界广泛改进和创新的领域，有助于促进国际贸易和电子商务领域更加有效和标准化的 HTS 分类解决方案。', 'title_zh': 'harmonized tariff schedule 分类模型的基准测试'}
{'arxiv_id': 'arXiv:2407.00521', 'title': 'A Medical Low-Back Pain Physical Rehabilitation Dataset for Human Body Movement Analysis', 'authors': 'Sao Mai Nguyen, Maxime Devanne, Olivier Remy-Neris, Mathieu Lempereur, André Thepaut', 'link': 'https://arxiv.org/abs/2407.00521', 'abstract': 'While automatic monitoring and coaching of exercises are showing encouraging results in non-medical applications, they still have limitations such as errors and limited use contexts. To allow the development and assessment of physical rehabilitation by an intelligent tutoring system, we identify in this article four challenges to address and propose a medical dataset of clinical patients carrying out low back-pain rehabilitation exercises. The dataset includes 3D Kinect skeleton positions and orientations, RGB videos, 2D skeleton data, and medical annotations to assess the correctness, and error classification and localisation of body part and timespan. Along this dataset, we perform a complete research path, from data collection to processing, and finally a small benchmark. We evaluated on the dataset two baseline movement recognition algorithms, pertaining to two different approaches: the probabilistic approach with a Gaussian Mixture Model (GMM), and the deep learning approach with a Long-Short Term Memory (LSTM).\nThis dataset is valuable because it includes rehabilitation relevant motions in a clinical setting with patients in their rehabilitation program, using a cost-effective, portable, and convenient sensor, and because it shows the potential for improvement on these challenges.', 'abstract_zh': '自动监控和指导锻炼虽然在非医疗应用中取得了鼓励性的成果，但仍存在一些限制，例如误差和使用场景的局限性。为了允许智能辅导系统开发和评估物理康复，本文识别了四个需要解决的挑战，并提出了一组临床患者的腰痛康复锻炼医疗数据集。该数据集包含3D Kinect骨骼位置和姿态、RGB视频、2D骨骼数据以及医疗注释，用于评估正确性、错误分类和身体部位及时间段的定位。在该数据集的基础上，我们进行了一条完整的研究路径，从数据收集到处理，最终建立了一个小型基准。我们在这组数据集上评估了两种基本的运动识别算法：一种基于概率方法的高斯混合模型（GMM），另一种基于深度学习方法的长短时记忆网络（LSTM）。\n\n该数据集具有重要价值，因为它在临床环境下包含了患者康复计划中的相关康复动作，使用了成本效益高、便携且便捷的传感器，并且展示了在这些挑战上的改进潜力。', 'title_zh': '一种用于人体运动分析的医疗低背痛物理康复数据集'}
{'arxiv_id': 'arXiv:2309.07675', 'title': 'Goal Space Abstraction in Hierarchical Reinforcement Learning via Set-Based Reachability Analysis', 'authors': 'Mehdi Zadem, Sergio Mover, Sao Mai Nguyen', 'link': 'https://arxiv.org/abs/2309.07675', 'abstract': 'Open-ended learning benefits immensely from the use of symbolic methods for goal representation as they offer ways to structure knowledge for efficient and transferable learning. However, the existing Hierarchical Reinforcement Learning (HRL) approaches relying on symbolic reasoning are often limited as they require a manual goal representation. The challenge in autonomously discovering a symbolic goal representation is that it must preserve critical information, such as the environment dynamics. In this paper, we propose a developmental mechanism for goal discovery via an emergent representation that abstracts (i.e., groups together) sets of environment states that have similar roles in the task. We introduce a Feudal HRL algorithm that concurrently learns both the goal representation and a hierarchical policy. The algorithm uses symbolic reachability analysis for neural networks to approximate the transition relation among sets of states and to refine the goal representation. We evaluate our approach on complex navigation tasks, showing the learned representation is interpretable, transferrable and results in data efficient learning.', 'abstract_zh': '开放型学习极大地受益于使用符号方法来表示目标，因为这些方法为高效且可迁移的学习提供了结构化的知识方式。然而，现有的依赖于符号推理的层次强化学习（Hierarchical Reinforcement Learning, HRL）方法往往受到限制，因为它们需要手动定义目标表示。自主发现符号目标表示的挑战在于，它必须保留关键信息，例如环境动力学。本文提出了一种发展机制，通过一种新兴的表示方式来发现目标，这种表示方式可以抽象出在任务中具有相似角色的一组环境状态。我们引入了一种封建层次强化学习算法，在该算法中并行学习目标表示和层次策略。算法使用符号可达性分析来近似神经网络中状态集之间的转换关系，并逐步优化目标表示。我们通过复杂导航任务评估了该方法，结果显示所学习的表示是可解释的、可迁移的，并且能够实现高效的数据学习。', 'title_zh': '通过集合基可达性分析在层次强化学习中的目标空间抽象'}
