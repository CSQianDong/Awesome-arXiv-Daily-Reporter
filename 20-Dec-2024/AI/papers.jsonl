{'arxiv_id': 'arXiv:2412.15177', 'title': 'Critical-Questions-of-Thought: Steering LLM reasoning with Argumentative Querying', 'authors': 'Federico Castagna, Isabel Sassoon, Simon Parsons', 'link': 'https://arxiv.org/abs/2412.15177', 'abstract': "Studies have underscored how, regardless of the recent breakthrough and swift advances in AI research, even state-of-the-art Large Language models (LLMs) continue to struggle when performing logical and mathematical reasoning. The results seem to suggest that LLMs still work as (highly advanced) data pattern identifiers, scoring poorly when attempting to generalise and solve reasoning problems the models have never previously seen or that are not close to samples presented in their training data. To address this compelling concern, this paper makes use of the notion of critical questions from the literature on argumentation theory, focusing in particular on Toulmin's model of argumentation. We show that employing these critical questions can improve the reasoning capabilities of LLMs. By probing the rationale behind the models' reasoning process, the LLM can assess whether some logical mistake is occurring and correct it before providing the final reply to the user prompt. The underlying idea is drawn from the gold standard of any valid argumentative procedure: the conclusion is valid if it is entailed by accepted premises. Or, to paraphrase such Aristotelian principle in a real-world approximation, characterised by incomplete information and presumptive logic, the conclusion is valid if not proved otherwise. This approach successfully steers the models' output through a reasoning pipeline, resulting in better performance against the baseline and its Chain-of-Thought (CoT) implementation. To this end, an extensive evaluation of the proposed approach on the MT-Bench Reasoning and Math tasks across a range of LLMs is provided.", 'abstract_zh': '研究表明，尽管最近在人工智能研究方面取得了突破性进展，最先进的大型语言模型（LLMs）在逻辑和数学推理任务中仍然表现挣扎。这些结果似乎表明，LLMs仍然主要作为（高度先进的）数据模式识别器运作，在尝试概括和解决模型从未见过的问题或训练数据中未提供相似样本的问题时表现不佳。为了应对这一重要挑战，本文采用论证理论文献中的关键问题概念，特别是在托马斯·库恩（Toulmin）的论证模型的基础上进行研究。我们展示，使用这些关键问题可以提高LLMs的推理能力。通过探究模型推理过程中的原因，LLMs可以评估是否存在逻辑错误并在最终回答用户提示之前予以纠正。这一思路源于任何有效论证过程的标准：如果结论由接受的前提所支持，则该结论有效。或者，用一个充分完备信息和预设逻辑的世界类比来重新阐述这一亚里士多德原则，如果不存在其他反驳，则结论有效。这种方法成功地引导了模型的输出通过推理管道，从而在基线和其链式思考（CoT）实现方面表现出更好的性能。为此，本文提供了广泛评估所提出方法在MT-Bench推理和数学任务上的一系列LLMs的结果。', 'title_zh': '思维关键问题：通过论证查询引导大规模语言模型的推理'}
{'arxiv_id': 'arXiv:2412.15135', 'title': 'Probabilistic Strategy Logic with Degrees of Observability', 'authors': 'Chunyan Mu, Nima Motamed, Natasha Alechina, Brian Logan', 'link': 'https://arxiv.org/abs/2412.15135', 'abstract': "There has been considerable work on reasoning about the strategic ability of agents under imperfect information. However, existing logics such as Probabilistic Strategy Logic are unable to express properties relating to information transparency. Information transparency concerns the extent to which agents' actions and behaviours are observable by other agents. Reasoning about information transparency is useful in many domains including security, privacy, and decision-making. In this paper, we present a formal framework for reasoning about information transparency properties in stochastic multi-agent systems. We extend Probabilistic Strategy Logic with new observability operators that capture the degree of observability of temporal properties by agents. We show that the model checking problem for the resulting logic is decidable.", 'abstract_zh': '在不完全信息下推断代理的战略能力方面已有大量研究。然而，现有的逻辑系统（如概率策略逻辑）无法表达与信息透明度相关的一些性质。信息透明度关注的是其他代理能够观察到的代理行为和行动的范围。讨论信息透明度在多个领域中（如安全、隐私和决策制定）具有重要意义。本文提出了一种形式化的框架，用于在随机多代理系统中推断信息透明度属性。我们扩展了概率策略逻辑，增加了新的可观测性操作符，以捕获代理对时间属性的可观测程度。我们证明了新逻辑的模型检测问题可判定。', 'title_zh': '概率策略逻辑与可观测性程度'}
{'arxiv_id': 'arXiv:2412.15114', 'title': 'Towards Friendly AI: A Comprehensive Review and New Perspectives on Human-AI Alignment', 'authors': 'Qiyang Sun, Yupei Li, Emran Alturki, Sunil Munthumoduku Krishna Murthy, Björn W. Schuller', 'link': 'https://arxiv.org/abs/2412.15114', 'abstract': 'As Artificial Intelligence (AI) continues to advance rapidly, Friendly AI (FAI) has been proposed to advocate for more equitable and fair development of AI. Despite its importance, there is a lack of comprehensive reviews examining FAI from an ethical perspective, as well as limited discussion on its potential applications and future directions. This paper addresses these gaps by providing a thorough review of FAI, focusing on theoretical perspectives both for and against its development, and presenting a formal definition in a clear and accessible format. Key applications are discussed from the perspectives of eXplainable AI (XAI), privacy, fairness and affective computing (AC). Additionally, the paper identifies challenges in current technological advancements and explores future research avenues. The findings emphasise the significance of developing FAI and advocate for its continued advancement to ensure ethical and beneficial AI development.', 'abstract_zh': '随着人工智能（AI）的快速发展，友好数字智能（Friendly AI, FAI）的概念被提出，以倡导更加公平和公正的AI发展。尽管FAI的重要性不言而喻，但迄今为止，从伦理视角出发对FAI进行全面审查的研究仍然不足，关于其潜在应用和未来发展方向的讨论也较为有限。本文通过提供对FAI的全面审查，关注其支持和反对发展的理论视角，并以清晰简洁的形式提出了正式定义，填补了这一空白。文中从可解释AI（XAI）、隐私、公平性和情感计算（AC）等关键应用视角进行了探讨。此外，本文还指出了当前技术进步中的挑战，并探讨了未来的研究方向。研究结果强调了开发FAI的重要性，并倡导其继续发展，以确保伦理和有益的AI发展。', 'title_zh': '面向友好人工智能：人类-人工智能一致性的全面综述与新视角'}
{'arxiv_id': 'arXiv:2412.14950', 'title': 'Generalizing Constraint Models in Constraint Acquisition', 'authors': 'Dimos Tsouros, Senne Berden, Steven Prestwich, Tias Guns', 'link': 'https://arxiv.org/abs/2412.14950', 'abstract': 'Constraint Acquisition (CA) aims to widen the use of constraint programming by assisting users in the modeling process. However, most CA methods suffer from a significant drawback: they learn a single set of individual constraints for a specific problem instance, but cannot generalize these constraints to the parameterized constraint specifications of the problem. In this paper, we address this limitation by proposing GenCon, a novel approach to learn parameterized constraint models capable of modeling varying instances of the same problem. To achieve this generalization, we make use of statistical learning techniques at the level of individual constraints. Specifically, we propose to train a classifier to predict, for any possible constraint and parameterization, whether the constraint belongs to the problem. We then show how, for some classes of classifiers, we can extract decision rules to construct interpretable constraint specifications. This enables the generation of ground constraints for any parameter instantiation. Additionally, we present a generate-and-test approach that can be used with any classifier, to generate the ground constraints on the fly. Our empirical results demonstrate that our approach achieves high accuracy and is robust to noise in the input instances.', 'abstract_zh': '约束获取（Constraint Acquisition, CA）旨在扩大约束编程的使用范围，通过辅助用户进行模型构建过程。然而，大多数CA方法存在一个显著的缺陷：它们仅能为特定问题实例学习一组独立的约束条件，而无法将这些约束推广到问题的参数化约束规范中。在本文中，我们通过提出GenCon这一新型方法来解决这一局限性，该方法旨在学习可适应同一问题不同实例的参数化约束模型。为了实现这种推广性，我们在单个约束层面采用了统计学习技术。具体而言，我们提出了一种训练分类器的方法，该分类器能够预测任何可能的约束及其参数化是否属于该问题。然后，我们展示了对于某些类别的分类器，我们可以通过提取决策规则来构建可解释的约束规范，从而能够为任何参数化实例生成基础约束。此外，我们还提供了一种生成-测试方法，该方法可以与任何分类器结合使用，以在运行时动态生成基础约束。我们的实验结果表明，该方法具有高准确率，并且对输入实例中的噪声具有鲁棒性。', 'title_zh': '在约束获取中泛化约束模型'}
{'arxiv_id': 'arXiv:2412.14814', 'title': 'Answer Set Networks: Casting Answer Set Programming into Deep Learning', 'authors': 'Arseny Skryagin, Daniel Ochs, Phillip Deibert, Simon Kohaut, Devendra Singh Dhami, Kristian Kersting', 'link': 'https://arxiv.org/abs/2412.14814', 'abstract': 'Although Answer Set Programming (ASP) allows constraining neural-symbolic (NeSy) systems, its employment is hindered by the prohibitive costs of computing stable models and the CPU-bound nature of state-of-the-art solvers. To this end, we propose Answer Set Networks (ASN), a NeSy solver. Based on Graph Neural Networks (GNN), ASNs are a scalable approach to ASP-based Deep Probabilistic Logic Programming (DPPL). Specifically, we show how to translate ASPs into ASNs and demonstrate how ASNs can efficiently solve the encoded problem by leveraging GPU\'s batching and parallelization capabilities. Our experimental evaluations demonstrate that ASNs outperform state-of-the-art CPU-bound NeSy systems on multiple tasks. Simultaneously, we make the following two contributions based on the strengths of ASNs. Namely, we are the first to show the finetuning of Large Language Models (LLM) with DPPLs, employing ASNs to guide the training with logic. Further, we show the "constitutional navigation" of drones, i.e., encoding public aviation laws in an ASN for routing Unmanned Aerial Vehicles in uncertain environments.', 'abstract_zh': '尽管回答集编程（ASP）能够约束神经符号（NeSy）系统，但其应用受到计算稳定模型成本高昂以及先进求解器以CPU为中心的特性的阻碍。为解决这一问题，我们提出了一种NeSy求解器——回答集网络（ASN），它是基于图神经网络（GNN）的ASP基深度概率逻辑编程（DPPL）的可扩展方法。具体来说，我们展示了如何将ASP转换为ASN，并展示了通过利用GPU的批量处理和并行化能力，ASN如何高效地求解编码问题。我们的实验评估表明，ASN在多个任务上优于现有的CPU密集型NeSy系统。同时，我们基于ASN的优点，做出了以下两个贡献：首先，我们首次展示了使用DPPL微调大型语言模型（LLM），并使用ASN以逻辑引导训练；其次，我们展示了无人机的“宪法导航”，即将公共航空法规编码到ASN中，用于导航无人驾驶航空器在不确定环境中的路径规划。', 'title_zh': '答案集网络：将回答集编程纳入深度学习'}
{'arxiv_id': 'arXiv:2412.14728', 'title': 'LTLf Synthesis Under Unreliable Input', 'authors': 'Christian Hagemeier, Giuseppe de Giacomo, Moshe Y. Vardi', 'link': 'https://arxiv.org/abs/2412.14728', 'abstract': 'We study the problem of realizing strategies for an LTLf goal specification while ensuring that at least an LTLf backup specification is satisfied in case of unreliability of certain input variables. We formally define the problem and characterize its worst-case complexity as 2EXPTIME-complete, like standard LTLf synthesis. Then we devise three different solution techniques: one based on direct automata manipulation, which is 2EXPTIME, one disregarding unreliable input variables by adopting a belief construction, which is 3EXPTIME, and one leveraging second-order quantified LTLf (QLTLf), which is 2EXPTIME and allows for a direct encoding into monadic second-order logic, which in turn is worst-case nonelementary. We prove their correctness and evaluate them against each other empirically. Interestingly, theoretical worst-case bounds do not translate into observed performance; the MSO technique performs best, followed by belief construction and direct automata manipulation. As a byproduct of our study, we provide a general synthesis procedure for arbitrary QLTLf specifications.', 'abstract_zh': '我们研究了在某些输入变量不可靠的情况下，实现LTLf目标规范的同时确保至少满足一个LTLf后备规范的问题。我们正式定义了该问题，并将其最坏情况的复杂性归类为2EXPTIME完备，这与标准的LTLf合成类似。然后我们设计了三种不同的解决方案方法：一种基于直接自动机操作的方法，其复杂性为2EXPTIME；一种通过信念构建忽略不可靠的输入变量的方法，其复杂性为3EXPTIME；以及一种利用二阶量化的LTLf（QLTLf）的方法，其复杂性为2EXPTIME，并允许直接编码为单调二阶逻辑，后者在最坏情况下的复杂性是不属于元素阶的。我们证明了这些方法的正确性，并对它们进行了实证比较。有趣的是，理论上的最坏情况界并不转化为实际的性能表现；单调二阶逻辑方法表现最佳，其次是信念构建和直接自动机操作。作为我们研究的一个副产品，我们提供了一种通用的QLTLf规范合成方法。', 'title_zh': '在不可靠输入下的LTLf综合'}
{'arxiv_id': 'arXiv:2412.14708', 'title': 'Creation of AI-driven Smart Spaces for Enhanced Indoor Environments -- A Survey', 'authors': 'Aygün Varol, Naser Hossein Motlagh, Mirka Leino, Sasu Tarkoma, Johanna Virkki', 'link': 'https://arxiv.org/abs/2412.14708', 'abstract': 'Smart spaces are ubiquitous computing environments that integrate diverse sensing and communication technologies to enhance space functionality, optimize energy utilization, and improve user comfort and well-being. The integration of emerging AI methodologies into these environments facilitates the formation of AI-driven smart spaces, which further enhance functionalities of the spaces by enabling advanced applications such as personalized comfort settings, interactive living spaces, and automatization of the space systems, all resulting in enhanced indoor experiences of the users. In this paper, we present a systematic survey of existing research on the foundational components of AI-driven smart spaces, including sensor technologies, data communication protocols, sensor network management and maintenance strategies, as well as the data collection, processing and analytics. Given the pivotal role of AI in establishing AI-powered smart spaces, we explore the opportunities and challenges associated with traditional machine learning (ML) approaches, such as deep learning (DL), and emerging methodologies including large language models (LLMs). Finally, we provide key insights necessary for the development of AI-driven smart spaces, propose future research directions, and sheds light on the path forward.', 'abstract_zh': '智能空间是集成多样传感和通信技术的通用计算环境，旨在增强空间功能、优化能源利用、提高用户舒适度和福祉。将新兴的人工智能方法融入这些环境中，促进了基于人工智能的智能空间的形成，进一步通过实现个性化舒适设置、互动生活空间和空间系统的自动化等功能，提升了空间的性能，从而为用户提供更优质的室内体验。在本文中，我们系统地综述了基于人工智能的智能空间的基础组件，包括传感器技术、数据通信协议、传感器网络管理和维护策略，以及数据采集、处理和分析技术。鉴于人工智能在构建人工智能赋能智能空间中起到的关键作用，我们探讨了传统机器学习（ML）方法，如深度学习（DL），以及新兴方法，如大型语言模型（LLMs）所带来的机遇和挑战。最后，我们提供了关于开发基于人工智能的智能空间的关键见解，提出了未来的研究方向，并为未来发展指明了道路。', 'title_zh': '基于人工智能驱动的智能空间创建以提升室内环境——综述'}
{'arxiv_id': 'arXiv:2412.14684', 'title': 'Bel Esprit: Multi-Agent Framework for Building AI Model Pipelines', 'authors': 'Yunsu Kim, AhmedElmogtaba Abdelaziz, Thiago Castro Ferreira, Mohamed Al-Badrashiny, Hassan Sawaf', 'link': 'https://arxiv.org/abs/2412.14684', 'abstract': 'As the demand for artificial intelligence (AI) grows to address complex real-world tasks, single models are often insufficient, requiring the integration of multiple models into pipelines. This paper introduces Bel Esprit, a conversational agent designed to construct AI model pipelines based on user-defined requirements. Bel Esprit employs a multi-agent framework where subagents collaborate to clarify requirements, build, validate, and populate pipelines with appropriate models. We demonstrate the effectiveness of this framework in generating pipelines from ambiguous user queries, using both human-curated and synthetic data. A detailed error analysis highlights ongoing challenges in pipeline construction. Bel Esprit is available for a free trial at this https URL.', 'abstract_zh': '随着人工智能（AI）需求的增长，以应对复杂的现实世界任务，单一模型往往不足以满足需求，需要将多个模型整合到管道中。本文介绍了Bel Esprit，这是一种基于用户自定义需求构建AI模型管道的对话型代理。Bel Esprit采用多代理框架，其中子代理合作以澄清需求、构建、验证并使用适当模型填充管道。我们通过使用人类精选和合成数据来展示该框架在从模糊用户查询中生成管道方面的有效性。详细的错误分析突显了在构建管道过程中仍面临的挑战。Bel Esprit可在此免费试用：[此链接]。', 'title_zh': 'Bel Esprit：多Agent框架构建AI模型流水线'}
{'arxiv_id': 'arXiv:2412.14515', 'title': 'Relational Programming with Foundation Models', 'authors': 'Ziyang Li, Jiani Huang, Jason Liu, Felix Zhu, Eric Zhao, William Dodds, Neelay Velingker, Rajeev Alur, Mayur Naik', 'link': 'https://arxiv.org/abs/2412.14515', 'abstract': 'Foundation models have vast potential to enable diverse AI applications. The powerful yet incomplete nature of these models has spurred a wide range of mechanisms to augment them with capabilities such as in-context learning, information retrieval, and code interpreting. We propose Vieira, a declarative framework that unifies these mechanisms in a general solution for programming with foundation models. Vieira follows a probabilistic relational paradigm and treats foundation models as stateless functions with relational inputs and outputs. It supports neuro-symbolic applications by enabling the seamless combination of such models with logic programs, as well as complex, multi-modal applications by streamlining the composition of diverse sub-models. We implement Vieira by extending the Scallop compiler with a foreign interface that supports foundation models as plugins. We implement plugins for 12 foundation models including GPT, CLIP, and SAM. We evaluate Vieira on 9 challenging tasks that span language, vision, and structured and vector databases. Our evaluation shows that programs in Vieira are concise, can incorporate modern foundation models, and have comparable or better accuracy than competitive baselines.', 'abstract_zh': '基础模型具有广泛潜力，能够推动多样的人工智能应用。这些模型虽然强大但并不完整，因此激发了一种广泛机制，用以通过上下文学习、信息检索和代码解释等方式扩展其功能。我们提出Vieira，这是一种声明性框架，将这些机制统一在一个适用于基础模型编程的通用解决方案中。Vieira遵循概率关系范式，并将基础模型视为无状态函数，具有关系输入和输出。它通过使这样的模型与逻辑程序无缝结合，支持神经符号应用程序；并通过简化多种子模型的组合，支持复杂的多模态应用程序。我们通过在Scallop编译器中增加一个支持基础模型的外接接口来实现Vieira。我们为包括GPT、CLIP和SAM在内的12种基础模型实现了外接插件。我们针对涵盖语言、视觉以及结构化和向量数据库的9项具有挑战性的任务，评估了Vieira。评估结果显示，Vieira中的程序简洁明了，能够集成现代基础模型，并且与竞争基准相比具有相当或更好的准确性。', 'title_zh': '基于基础模型的关联编程'}
{'arxiv_id': 'arXiv:2412.14500', 'title': 'The Digital Ecosystem of Beliefs: does evolution favour AI over humans?', 'authors': 'David M. Bossens, Shanshan Feng, Yew-Soon Ong', 'link': 'https://arxiv.org/abs/2412.14500', 'abstract': "As AI systems are integrated into social networks, there are AI safety concerns that AI-generated content may dominate the web, e.g. in popularity or impact on this http URL understand such questions, this paper proposes the Digital Ecosystem of Beliefs (Digico), the first evolutionary framework for controlled experimentation with multi-population interactions in simulated social networks. The framework models a population of agents which change their messaging strategies due to evolutionary updates following a Universal Darwinism approach, interact via messages, influence each other's beliefs through dynamics based on a contagion model, and maintain their beliefs through cognitive Lamarckian inheritance. Initial experiments with an abstract implementation of Digico show that: a) when AIs have faster messaging, evolution, and more influence in the recommendation algorithm, they get 80% to 95% of the views, depending on the size of the influence benefit; b) AIs designed for propaganda can typically convince 50% of humans to adopt extreme beliefs, and up to 85% when agents believe only a limited number of channels; c) a penalty for content that violates agents' beliefs reduces propaganda effectiveness by up to 8%. We further discuss implications for control (e.g. legislation) and Digico as a means of studying evolutionary principles.", 'abstract_zh': '随着人工智能系统被整合到社交网络中，存在一种AI安全问题，即AI生成的内容可能主导网络，例如在流行度或影响方面。为了理解这些问题，本文提出了Belief数字生态系（Digico），这是首个基于通用达尔文主义方法的进化框架，用于在模拟社交网络中进行受控实验，以研究多群体互动。该框架模拟了一组随时间根据进化更新改变其交流策略的代理，通过消息进行互动，并通过基于传染模型的动力学相互影响信念，并通过认知拉马克主义遗传维持信念。初步实验表明：a) 当AI的交流速度、进化速度以及对推荐算法的影响更大时，它们可以获得80%到95%的曝光率，具体比例取决于影响效益的规模；b) 针对宣传设计的AI通常可以让一半的人类接受极端信念，当代理只相信有限数量的渠道时，这一比例可达到85%；c) 对违反代理信念的内容施加惩罚可以将宣传效果降低8%。此外，我们进一步讨论了该研究在控制（例如法律法规）方面的意义以及Digico作为研究进化原理工具的意义。', 'title_zh': '信念数字生态系统的演化：人工智能相较于人类更有优势吗？'}
{'arxiv_id': 'arXiv:2412.14492', 'title': 'FaultExplainer: Leveraging Large Language Models for Interpretable Fault Detection and Diagnosis', 'authors': 'Abdullah Khan, Rahul Nahar, Hao Chen, Gonzalo E. Constante Flores, Can Li', 'link': 'https://arxiv.org/abs/2412.14492', 'abstract': "Machine learning algorithms are increasingly being applied to fault detection and diagnosis (FDD) in chemical processes. However, existing data-driven FDD platforms often lack interpretability for process operators and struggle to identify root causes of previously unseen faults. This paper presents FaultExplainer, an interactive tool designed to improve fault detection, diagnosis, and explanation in the Tennessee Eastman Process (TEP). FaultExplainer integrates real-time sensor data visualization, Principal Component Analysis (PCA)-based fault detection, and identification of top contributing variables within an interactive user interface powered by large language models (LLMs). We evaluate the LLMs' reasoning capabilities in two scenarios: one where historical root causes are provided, and one where they are not to mimic the challenge of previously unseen faults. Experimental results using GPT-4o and o1-preview models demonstrate the system's strengths in generating plausible and actionable explanations, while also highlighting its limitations, including reliance on PCA-selected features and occasional hallucinations.", 'abstract_zh': '机器学习算法在化工过程故障检测与诊断（FDD）中的应用越来越广泛。然而，现有的基于数据驱动的FDD平台往往缺乏对工艺操作人员的解释性，并且难以识别之前未见过故障的根本原因。本文介绍了一种名为FaultExplainer的交互式工具，旨在提高Tennessee Eastman Process（TEP）的故障检测、诊断和解释能力。FaultExplainer结合了实时传感器数据可视化、基于主成分分析（PCA）的故障检测以及大型语言模型（LLMs）支持的交互式用户界面，以识别贡献最大的变量。我们在两种场景下评估了LLMs的推理能力：一种场景是有历史根本原因提供，另一种场景是没有提供以模拟之前未见过故障的挑战。使用GPT-4o和o1-preview模型的实验结果表明，该系统在生成合理和可操作的解释方面具有优势，但同时也展示了其局限性，包括对PCA选择特征的依赖以及偶尔的幻觉现象。', 'title_zh': '故障解释器：利用大语言模型进行可解释的故障检测与诊断'}
{'arxiv_id': 'arXiv:2412.14491', 'title': 'Mediation Analysis for Probabilities of Causation', 'authors': 'Yuta Kawakami, Jin Tian', 'link': 'https://arxiv.org/abs/2412.14491', 'abstract': 'Probabilities of causation (PoC) offer valuable insights for informed decision-making. This paper introduces novel variants of PoC-controlled direct, natural direct, and natural indirect probability of necessity and sufficiency (PNS). These metrics quantify the necessity and sufficiency of a treatment for producing an outcome, accounting for different causal pathways. We develop identification theorems for these new PoC measures, allowing for their estimation from observational data. We demonstrate the practical application of our results through an analysis of a real-world psychology dataset.', 'abstract_zh': '概率产生作用（PoC）为基于信息的决策提供了宝贵的见解。本文介绍了PoC控制下的直接作用、自然直接作用和自然间接作用的概率必要性和充分性（PNS）的新变体。这些指标量化了治疗对于产生结果的必要性和充分性，同时考虑到不同的因果路径。我们为这些新的PoC度量制定了识别定理，允许从观察数据中估计这些度量。我们通过分析一个实际的心理学数据集展示了这些结果的实际应用。', 'title_zh': '概率因果作用的中介分析'}
{'arxiv_id': 'arXiv:2412.14485', 'title': 'Towards Projected and Incremental Pseudo-Boolean Model Counting', 'authors': 'Suwei Yang, Kuldeep S. Meel', 'link': 'https://arxiv.org/abs/2412.14485', 'abstract': 'Model counting is a fundamental task that involves determining the number of satisfying assignments to a logical formula, typically in conjunctive normal form (CNF). While CNF model counting has received extensive attention over recent decades, interest in Pseudo-Boolean (PB) model counting is just emerging partly due to the greater flexibility of PB formulas. As such, we observed feature gaps in existing PB counters such as a lack of support for projected and incremental settings, which could hinder adoption.\nIn this work, our main contribution is the introduction of the PB model counter PBCount2, the first exact PB model counter with support for projected and incremental model counting. Our counter, PBCount2, uses our Least Occurrence Weighted Min Degree (LOW-MD) computation ordering heuristic to support projected model counting and a cache mechanism to enable incremental model counting. In our evaluations, PBCount2 completed at least 1.40x the number of benchmarks of competing methods for projected model counting and at least 1.18x of competing methods in incremental model counting.', 'abstract_zh': '模型计数是一项基本任务，涉及确定逻辑公式（通常为合取范式CNF）的满足赋值数量。虽然CNF模型计数在最近几十年内得到了广泛的关注，但对伪布尔（PB）模型计数的兴趣才刚刚兴起，部分原因是由于PB公式更大的灵活性。因此，我们观察到现有PB计数器存在特征差距，如缺乏对投影和增量设置的支持，这可能阻碍其应用。\n\n在本工作中，我们的主要贡献是提出了支持投影和增量模型计数的第一个精确PB计数器PBCount2。我们的计数器PBCount2使用了我们最新的最少出现加权最小度（LOW-MD）计算排序启发式算法，以支持投影模型计数，并使用缓存机制以实现增量模型计数。在我们的评估中，对于投影模型计数，PBCount2 在完成的基准测试数量上至少比竞争方法快1.40倍；对于增量模型计数，PBCount2 至少比竞争方法快1.18倍。', 'title_zh': '面向投影和增量伪布尔模型计数'}
{'arxiv_id': 'arXiv:2412.14409', 'title': 'Multi-task Representation Learning for Mixed Integer Linear Programming', 'authors': 'Junyang Cai, Taoan Huang, Bistra Dilkina', 'link': 'https://arxiv.org/abs/2412.14409', 'abstract': 'Mixed Integer Linear Programs (MILPs) are highly flexible and powerful tools for modeling and solving complex real-world combinatorial optimization problems. Recently, machine learning (ML)-guided approaches have demonstrated significant potential in improving MILP-solving efficiency. However, these methods typically rely on separate offline data collection and training processes, which limits their scalability and adaptability. This paper introduces the first multi-task learning framework for ML-guided MILP solving. The proposed framework provides MILP embeddings helpful in guiding MILP solving across solvers (e.g., Gurobi and SCIP) and across tasks (e.g., Branching and Solver configuration). Through extensive experiments on three widely used MILP benchmarks, we demonstrate that our multi-task learning model performs similarly to specialized models within the same distribution. Moreover, it significantly outperforms them in generalization across problem sizes and tasks.', 'abstract_zh': '混合整数线性规划（Mixed Integer Linear Programs, MILPs）是用于建模和解决复杂实际组合优化问题的强大而灵活的工具。近年来，机器学习（Machine Learning, ML）引导的方法在提高MILP求解效率方面展现出了显著的潜力。然而，这些方法通常依赖于单独的离线数据收集和训练过程，这限制了它们的可扩展性和适应性。本文提出了首个用于ML引导的MILP求解的多任务学习框架。所提出的框架提供了有助于跨求解器（例如，Gurobi和SCIP）和跨任务（例如，分支策略和求解器配置）引导MILP求解的MILP嵌入。通过在三个广泛使用的MILP基准测试上进行广泛的实验，我们证明了我们的多任务学习模型在性能上类似于相同分布内的专用模型，并且在问题规模和任务的泛化性能方面明显优于它们。', 'title_zh': '混合整数线性规划的多任务表示学习'}
{'arxiv_id': 'arXiv:2412.14387', 'title': 'Clinical Trials Ontology Engineering with Large Language Models', 'authors': 'Berkan Çakır', 'link': 'https://arxiv.org/abs/2412.14387', 'abstract': 'Managing clinical trial information is currently a significant challenge for the medical industry, as traditional methods are both time-consuming and costly. This paper proposes a simple yet effective methodology to extract and integrate clinical trial data in a cost-effective and time-efficient manner. Allowing the medical industry to stay up-to-date with medical developments. Comparing time, cost, and quality of the ontologies created by humans, GPT3.5, GPT4, and Llama3 (8b & 70b). Findings suggest that large language models (LLM) are a viable option to automate this process both from a cost and time perspective. This study underscores significant implications for medical research where real-time data integration from clinical trials could become the norm.', 'abstract_zh': '当前，管理临床试验信息是医疗行业面临的一项重大挑战，因为传统的管理方法既耗时又昂贵。本文提出了一种简单且有效的方法，以成本效益高且时间效率高的方式提取和整合临床试验数据，使医疗行业能够及时了解医学发展动态。本研究比较了人类、GPT3.5、GPT4 和 Llama3（8b 和 70b）创建的本体的时间、成本和质量。研究结果表明，大型语言模型（LLM）在成本和时间方面是自动化此过程的可行选择。本研究强调了医学研究中的重大意义，即临床试验的实时数据整合有望成为常态。', 'title_zh': '使用大型语言模型进行临床试验本体工程'}
{'arxiv_id': 'arXiv:2412.14382', 'title': 'Balans: Multi-Armed Bandits-based Adaptive Large Neighborhood Search for Mixed-Integer Programming Problem', 'authors': 'Junyang Cai, Serdar Kadioglu, Bistra Dilkina', 'link': 'https://arxiv.org/abs/2412.14382', 'abstract': 'Mixed-Integer Programming (MIP) is a powerful paradigm for modeling and solving various important combinatorial optimization problems. Recently, learning-based approaches have shown potential to speed up MIP solving via offline training that then guides important design decisions during search. However, a significant drawback of these methods is their heavy reliance on offline training, which requires collecting training datasets and computationally costly training epochs yet offering only limited generalization to unseen (larger) instances. In this paper, we propose Balans, an adaptive meta-solver for MIPs with online learning capability that does not require any supervision or apriori training. At its core, Balans is based on adaptive large-neighborhood search, operating on top of a MIP solver by successive applications of destroy and repair neighborhood operators. During the search, the selection among different neighborhood definitions is guided on the fly for the instance at hand via multi-armed bandit algorithms. Our extensive experiments on hard optimization instances show that Balans offers significant performance gains over the default MIP solver, is better than committing to any single best neighborhood, and improves over the state-of-the-art large-neighborhood search for MIPs. Finally, we release Balans as a highly configurable, MIP solver agnostic, open-source software.', 'abstract_zh': '混合整数规划（MIP）是一种强大的建模和解决各种重要组合优化问题的范式。近年来，基于学习的方法显示出通过离线训练来加速MIP求解的潜力，这种离线训练随后可以指导搜索过程中的关键设计决策。然而，这些方法的一个重要缺点是它们高度依赖于离线训练，这需要收集训练数据集和计算成本高昂的培训周期，但只能对未见过的（更大规模的）实例进行有限的泛化能力。在本文中，我们提出了一种名为Balans的自适应元求解器，该求解器具有在线学习能力，无需任何监督或先验训练。核心而言，Balans基于自适应的大邻域搜索，通过逐次应用破坏和修复邻域操作符运行在MIP求解器之上。在搜索过程中，不同邻域定义的选择通过多臂 bandit 算法在现场实时进行指导。我们在一系列困难的优化实例上的广泛实验表明，相比于默认的MIP求解器，Balans提供了显著的性能提升；与选择单一最佳邻域相比，Balans的效果更佳；同时，它还改进了现有MIP的大邻域搜索方法。最后，我们推出了一个高度可配置的、求解器无关的开源软件Balans。', 'title_zh': 'Balans：基于多臂-bandits 的自适应大邻域搜索算法解决混合整数规划问题'}
{'arxiv_id': 'arXiv:2412.14372', 'title': 'Python Agent in Ludii', 'authors': 'Izaias S. de Lima Neto, Marco A. A. de Aguiar Vieira, Anderson R. Tavares', 'link': 'https://arxiv.org/abs/2412.14372', 'abstract': 'Ludii is a Java general game system with a considerable number of board games, with an API for developing new agents and a game description language to create new games. To improve versatility and ease development, we provide Python interfaces for agent programming. This allows the use of Python modules to implement general game playing agents.\nAs a means of enabling Python for creating Ludii agents, the interfaces are implemented using different Java libraries: jpy and Py4J. The main goal of this work is to determine which version is faster. To do so, we conducted a performance analysis of two different GGP algorithms, Minimax adapted to GGP and MCTS. The analysis was performed across several combinatorial games with varying depth, branching factor, and ply time. For reproducibility, we provide tutorials and repositories.\nOur analysis includes predictive models using regression, which suggest that jpy is faster than Py4J, however slower than a native Java Ludii agent, as expected.', 'abstract_zh': 'Ludii 是一个用 Java 编写的通用游戏系统，包含大量的桌面游戏，并提供了开发新智能体的 API 和游戏描述语言来创建新游戏。为了提高灵活性和简化开发，我们提供了 Python 接口用于智能体编程。这使得可以使用 Python 模块来实现通用游戏智能体。\n\n为了让用户能够使用 Python 创建 Ludii 智能体，我们使用了不同的 Java 库（jpy 和 Py4J）来实现这些接口。本工作的主要目标是确定哪种版本运行得更快。为此，我们对两种不同的广义游戏智能体（GGP）算法——适应了 GGP 的 Minimax 算法和蒙特卡洛树搜索（MCTS）——进行了性能分析。这种分析跨越了多个具有不同深度、分支因子和走棋时间的组合游戏。\n\n为了确保结果的可重复性，我们提供了教程和代码库。我们的分析还包括使用回归模型进行的预测模型，结果显示 jpy 的运行速度比 Py4J 更快，但比原生的 Java Ludii 智能体慢，这符合预期。', 'title_zh': 'Python代理在Ludii中的应用'}
{'arxiv_id': 'arXiv:2412.15212', 'title': 'Scaling 4D Representations', 'authors': 'João Carreira, Dilara Gokay, Michael King, Chuhan Zhang, Ignacio Rocco, Aravindh Mahendran, Thomas Albert Keck, Joseph Heyward, Skanda Koppula, Etienne Pot, Goker Erdogan, Yana Hasson, Yi Yang, Klaus Greff, Guillaume Le Moing, Sjoerd van Steenkiste, Daniel Zoran, Drew A. Hudson, Pedro Vélez, Luisa Polanía, Luke Friedman, Chris Duvarney, Ross Goroshin, Kelsey Allen, Jacob Walker, Rishabh Kabra, Eric Aboussouan, Jennifer Sun, Thomas Kipf, Carl Doersch, Viorica Pătrăucean, Dima Damen, Pauline Luc, Mehdi S. M. Sajjadi, Andrew Zisserman', 'link': 'https://arxiv.org/abs/2412.15212', 'abstract': 'Scaling has not yet been convincingly demonstrated for pure self-supervised learning from video. However, prior work has focused evaluations on semantic-related tasks $\\unicode{x2013}$ action classification, ImageNet classification, etc. In this paper we focus on evaluating self-supervised learning on non-semantic vision tasks that are more spatial (3D) and temporal (+1D = 4D), such as camera pose estimation, point and object tracking, and depth estimation. We show that by learning from very large video datasets, masked auto-encoding (MAE) with transformer video models actually scales, consistently improving performance on these 4D tasks, as model size increases from 20M all the way to the largest by far reported self-supervised video model $\\unicode{x2013}$ 22B parameters. Rigorous apples-to-apples comparison with many recent image and video models demonstrates the benefits of scaling 4D representations.', 'abstract_zh': '纯自我监督学习从视频中仍然没有令人信服地证明其可扩展性。然而，先前的工作主要集中在与语义相关的任务上——动作分类、ImageNet分类等。在这项研究中，我们专注于评估自我监督学习在更空间化（3D）和时间化（+1D，共4D）的非语义视觉任务上的表现，如相机位姿估计、点和物体轨迹跟踪以及深度估计。我们展示了通过学习大规模视频数据集，掩码自编码（MAE）结合transformer视频模型实际上实现了可扩展性，模型规模从2000万参数一直增加到迄今为止报告的最大自我监督视频模型——220亿参数，始终在这些4D任务上提高了性能。严格的“苹果对苹果”比较表明，扩大4D表示具有明显的优势。', 'title_zh': '“扩展四维表示”'}
{'arxiv_id': 'arXiv:2412.15209', 'title': 'PRIMA: Multi-Image Vision-Language Models for Reasoning Segmentation', 'authors': 'Muntasir Wahed, Kiet A. Nguyen, Adheesh Sunil Juvekar, Xinzhuo Li, Xiaona Zhou, Vedant Shah, Tianjiao Yu, Pinar Yanardag, Ismini Lourentzou', 'link': 'https://arxiv.org/abs/2412.15209', 'abstract': 'Despite significant advancements in Large Vision-Language Models (LVLMs), existing pixel-grounding models operate on single-image settings, limiting their ability to perform detailed, fine-grained comparisons across multiple images. Conversely, current multi-image understanding models lack pixel-level grounding. Our work addresses this gap by introducing the task of multi-image pixel-grounded reasoning segmentation, and PRIMA, a novel LVLM that integrates pixel-level grounding with robust multi-image reasoning capabilities to produce contextually rich, pixel-grounded explanations. Central to PRIMA is an efficient vision module that queries fine-grained visual representations across multiple images, reducing TFLOPs by $25.3\\%$. To support training and evaluation, we curate $M^4Seg$, a new reasoning segmentation benchmark consisting of $\\sim$224K question-answer pairs that require fine-grained visual understanding across multiple images. Experimental results demonstrate PRIMA outperforms state-of-the-art baselines.', 'abstract_zh': '尽管大型视觉-语言模型（LVLMs）取得了显著进展，现有的像素定位模型仅在单图像设置上运行，这限制了它们在进行多图像的详细、细粒度比较方面的能力。与此相反，当前的多图像理解模型缺乏像素级的定位能力。我们的工作通过引入多图像像素级定位推理分割任务，以及一种新型的LVLM——PRIMA，解决了这一差距。PRIMA集成了像素级定位和稳健的多图像推理能力，生成上下文丰富、像素级定位的解释。PRIMA的核心在于一个高效的视觉模块，该模块能够在多个图像上查询细粒度的视觉表示，相比之前的方法，减少了25.3%的TFLOPs。为了支持训练和评估，我们创建了M4Seg数据集，其中包含约224K个问题-答案对，这些对需要跨多个图像进行细粒度的视觉理解。实验结果表明，PRIMA在对比最先进的基线模型时表现更优。', 'title_zh': 'PRIMA：多张图像的视觉语言推理分割模型'}
{'arxiv_id': 'arXiv:2412.15204', 'title': 'LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks', 'authors': 'Yushi Bai, Shangqing Tu, Jiajie Zhang, Hao Peng, Xiaozhi Wang, Xin Lv, Shulin Cao, Jiazheng Xu, Lei Hou, Yuxiao Dong, Jie Tang, Juanzi Li', 'link': 'https://arxiv.org/abs/2412.15204', 'abstract': 'This paper introduces LongBench v2, a benchmark designed to assess the ability of LLMs to handle long-context problems requiring deep understanding and reasoning across real-world multitasks. LongBench v2 consists of 503 challenging multiple-choice questions, with contexts ranging from 8k to 2M words, across six major task categories: single-document QA, multi-document QA, long in-context learning, long-dialogue history understanding, code repository understanding, and long structured data understanding. To ensure the breadth and the practicality, we collect data from nearly 100 highly educated individuals with diverse professional backgrounds. We employ both automated and manual review processes to maintain high quality and difficulty, resulting in human experts achieving only 53.7% accuracy under a 15-minute time constraint. Our evaluation reveals that the best-performing model, when directly answers the questions, achieves only 50.1% accuracy. In contrast, the o1-preview model, which includes longer reasoning, achieves 57.7%, surpassing the human baseline by 4%. These results highlight the importance of enhanced reasoning ability and scaling inference-time compute to tackle the long-context challenges in LongBench v2. The project is available at this https URL.', 'abstract_zh': '本文引入了LongBench v2，这是一个旨在评估大语言模型（LLMs）处理长上下文问题的能力的基准，这些问题是要求在真实世界多任务中进行深远理解和推理的复杂任务。LongBench v2 包含了503道具有挑战性的多项选择题，其上下文长度从8千到2百万字不等，分布在六个主要任务类别中：单文档问答、多文档问答、长上下文学习、长对话历史理解、代码仓库理解和长结构化数据理解。为了确保该基准的广泛适用性和实用性，我们从近100名具有多样专业背景的高学历人士中收集了数据。我们采用了自动和手动双重审核过程，以确保高质量和高难度。在15分钟的时间限制下，专家级人类参与者只能达到53.7%的准确率。我们的评估表明，最优模型直接回答问题时，准确率仅为50.1%。相比之下，包含更长推理的o1-preview模型则达到了57.7%的准确率，比人类基线高出4%。这些结果突显了增强推理能力和扩展推理时间计算资源对于应对LongBench v2中长上下文挑战的重要性。该项目可以在以下链接访问：[此处插入URL]。', 'title_zh': 'LongBench v2：实现对现实长上下文多任务的更深理解与推理'}
{'arxiv_id': 'arXiv:2412.15200', 'title': 'DI-PCG: Diffusion-based Efficient Inverse Procedural Content Generation for High-quality 3D Asset Creation', 'authors': 'Wang Zhao, Yan-Pei Cao, Jiale Xu, Yuejiang Dong, Ying Shan', 'link': 'https://arxiv.org/abs/2412.15200', 'abstract': 'Procedural Content Generation (PCG) is powerful in creating high-quality 3D contents, yet controlling it to produce desired shapes is difficult and often requires extensive parameter tuning. Inverse Procedural Content Generation aims to automatically find the best parameters under the input condition. However, existing sampling-based and neural network-based methods still suffer from numerous sample iterations or limited controllability. In this work, we present DI-PCG, a novel and efficient method for Inverse PCG from general image conditions. At its core is a lightweight diffusion transformer model, where PCG parameters are directly treated as the denoising target and the observed images as conditions to control parameter generation. DI-PCG is efficient and effective. With only 7.6M network parameters and 30 GPU hours to train, it demonstrates superior performance in recovering parameters accurately, and generalizing well to in-the-wild images. Quantitative and qualitative experiment results validate the effectiveness of DI-PCG in inverse PCG and image-to-3D generation tasks. DI-PCG offers a promising approach for efficient inverse PCG and represents a valuable exploration step towards a 3D generation path that models how to construct a 3D asset using parametric models.', 'abstract_zh': '程序化内容生成（PCG）在创建高质量3D内容方面具有强大的能力，但控制其生成所需形状是困难的，通常需要大量的参数调优。逆程序化内容生成旨在在给定输入条件下自动找到最佳参数。然而，现有的基于采样和基于神经网络的方法仍然面临着大量的采样迭代或有限的可控性问题。在这项工作中，我们提出了一种名为DI-PCG的新颖且高效的逆PCG方法，适用于一般图像条件。其核心是一个轻量级的扩散变压器模型，在该模型中，PCG参数直接作为去噪目标，观察到的图像作为控制参数生成的条件。DI-PCG既高效又有效。仅需7.6M网络参数和30个GPU小时进行训练，它便能准确恢复参数并很好地泛化到野外图像。定量和定性的实验结果验证了DI-PCG在逆PCG和图像到3D生成任务中的有效性。DI-PCG提供了一种高效的逆PCG方法，并代表了一种有价值的研究方向，旨在通过参数化模型构建3D资产。', 'title_zh': 'DI-PCG：基于扩散的高效过程化内容生成方法及其在高质量3D资产创建中的应用'}
{'arxiv_id': 'arXiv:2412.15188', 'title': 'LlamaFusion: Adapting Pretrained Language Models for Multimodal Generation', 'authors': 'Weijia Shi, Xiaochuang Han, Chunting Zhou, Weixin Liang, Xi Victoria Lin, Luke Zettlemoyer, Lili Yu', 'link': 'https://arxiv.org/abs/2412.15188', 'abstract': "We present LlamaFusion, a framework for empowering pretrained text-only large language models (LLMs) with multimodal generative capabilities, enabling them to understand and generate both text and images in arbitrary sequences. LlamaFusion leverages existing Llama-3's weights for processing texts autoregressively while introducing additional and parallel transformer modules for processing images with diffusion. During training, the data from each modality is routed to its dedicated modules: modality-specific feedforward layers, query-key-value projections, and normalization layers process each modality independently, while the shared self-attention layers allow interactions across text and image features. By freezing the text-specific modules and only training the image-specific modules, LlamaFusion preserves the language capabilities of text-only LLMs while developing strong visual understanding and generation abilities. Compared to methods that pretrain multimodal generative models from scratch, our experiments demonstrate that, LlamaFusion improves image understanding by 20% and image generation by 3.6% using only 50% of the FLOPs while maintaining Llama-3's language capabilities. We also demonstrate that this framework can adapt existing vision-language models with multimodal generation ability. Overall, this framework not only leverages existing computational investments in text-only LLMs but also enables the parallel development of language and vision capabilities, presenting a promising direction for efficient multimodal model development.", 'abstract_zh': '我们提出了LlamaFusion框架，该框架旨在赋予预训练的纯文本大型语言模型（LLMs）多模态生成能力，使它们能够理解和生成任意顺序的文本和图像。LlamaFusion利用了现有Llama-3的权重，通过自回归方式处理文本，同时引入了额外的并行变压器模块来处理通过扩散方式处理的图像。在训练过程中，每种模态的数据被路由到其专门的模块中：特定模态的前馈层、查询-键-值投影以及规范化层独立处理每种模态，而共享的自注意力层则允许文本和图像特征之间的交互。通过冻结与文本特定模块相关的部分，并仅训练图像特定模块，LlamaFusion保留了纯文本LLMs的语言能力，同时增强了其对视觉的理解和生成能力。与从零开始预训练多模态生成模型的方法相比，我们的实验结果显示，LlamaFusion仅使用Llama-3算力的50%，就能提高20%的图像理解能力和3.6%的图像生成能力，同时保持了Llama-3的语言能力。此外，我们还展示了该框架可以适应现有的具备多模态生成能力的视觉-语言模型。总体而言，该框架不但利用了现有针对纯文本LLMs的投资，还同时促进了语言和视觉能力的并行发展，为高效多模态模型开发提供了一条有前景的方向。', 'title_zh': 'LlamaFusion：adaptation of预训练语言模型用于多模态生成\n\n为了使翻译更符合学术规范，可以进一步优化为：\n\nLlamaFusion：预训练语言模型的多模态生成适应方法'}
{'arxiv_id': 'arXiv:2412.15166', 'title': 'Human-Humanoid Robots Cross-Embodiment Behavior-Skill Transfer Using Decomposed Adversarial Learning from Demonstration', 'authors': 'Junjia Liu, Zhuo Li, Minghao Yu, Zhipeng Dong, Sylvain Calinon, Darwin Caldwell, Fei Chen', 'link': 'https://arxiv.org/abs/2412.15166', 'abstract': 'Humanoid robots are envisioned as embodied intelligent agents capable of performing a wide range of human-level loco-manipulation tasks, particularly in scenarios requiring strenuous and repetitive labor. However, learning these skills is challenging due to the high degrees of freedom of humanoid robots, and collecting sufficient training data for humanoid is a laborious process. Given the rapid introduction of new humanoid platforms, a cross-embodiment framework that allows generalizable skill transfer is becoming increasingly critical. To address this, we propose a transferable framework that reduces the data bottleneck by using a unified digital human model as a common prototype and bypassing the need for re-training on every new robot platform. The model learns behavior primitives from human demonstrations through adversarial imitation, and the complex robot structures are decomposed into functional components, each trained independently and dynamically coordinated. Task generalization is achieved through a human-object interaction graph, and skills are transferred to different robots via embodiment-specific kinematic motion retargeting and dynamic fine-tuning. Our framework is validated on five humanoid robots with diverse configurations, demonstrating stable loco-manipulation and highlighting its effectiveness in reducing data requirements and increasing the efficiency of skill transfer across platforms.', 'abstract_zh': '人形机器人被设想为具备执行广泛人类水平的移动和操作任务的实体智能代理，特别是在需要繁重和重复劳动的场景中。然而，由于人形机器人具有高自由度，学习这些技能极具挑战性，而为人形机器人收集足够的训练数据也是一个繁重的过程。鉴于新型人形平台的快速涌现，一种能够促进技能迁移的跨实体框架变得越来越关键。为了解决这一问题，我们提出了一种转移性框架，通过使用统一的数字人类模型作为通用原型，并绕过每种新机器人平台都需要重新训练的需要，从而减少数据瓶颈。该模型通过对抗性模仿从人类示范中学习行为基元，并将复杂的机器人结构分解为功能组件，这些组件独立训练并动态协调。通过人类-物体交互图实现任务泛化，通过特定于实体的动态运动重新对准和动态微调将技能转移到不同的机器人上。我们的框架已经在五个具有不同配置的人形机器人上得到验证，结果显示了稳定的人形操作能力，并强调了其减少数据需求和提高跨平台技能迁移效率的有效性。', 'title_zh': '人类-类人机器人跨生物体行为-技能转移研究：基于分解式示范学习的对抗学习方法'}
{'arxiv_id': 'arXiv:2412.15163', 'title': 'Operationalising Rawlsian Ethics for Fairness in Norm-Learning Agents', 'authors': 'Jessica Woodgate, Paul Marshall, Nirav Ajmeri', 'link': 'https://arxiv.org/abs/2412.15163', 'abstract': 'Social norms are standards of behaviour common in a society. However, when agents make decisions without considering how others are impacted, norms can emerge that lead to the subjugation of certain agents. We present RAWL-E, a method to create ethical norm-learning agents. RAWL-E agents operationalise maximin, a fairness principle from Rawlsian ethics, in their decision-making processes to promote ethical norms by balancing societal well-being with individual goals. We evaluate RAWL-E agents in simulated harvesting scenarios. We find that norms emerging in RAWL-E agent societies enhance social welfare, fairness, and robustness, and yield higher minimum experience compared to those that emerge in agent societies that do not implement Rawlsian ethics.', 'abstract_zh': '社会规范是社会中普遍存在的行为标准。然而，当个体在做决策时不考虑对其他人的影响时，可能会产生一些规范，从而导致某些个体的压迫。本文介绍了一种名为RAWL-E的方法，用于创建具有伦理规范学习能力的智能体。RAWL-E智能体在其决策过程中采用最大化最小效用（即最大化最低效用）的原则，这是一种源自罗尔斯理论的公平原则，以此促进伦理规范的形成，平衡社会福祉与个体目标。我们通过对模拟的采集场景进行了评估。结果表明，RAWL-E智能体社会中产生的规范能够提升社会福利、公平性和鲁棒性，并且能够确保比未实施罗尔斯伦理学的智能体社会中更高的最低体验。', 'title_zh': '将罗尔斯伦理学运用于规范学习代理的公平性之中'}
{'arxiv_id': 'arXiv:2412.15151', 'title': 'Language Models as Continuous Self-Evolving Data Engineers', 'authors': 'Peidong Wang, Ming Wang, Zhiming Ma, Xiaocui Yang, Shi Feng, Daling Wang, Yifei Zhang', 'link': 'https://arxiv.org/abs/2412.15151', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable capabilities on various tasks, while the further evolvement is limited to the lack of high-quality training data. In addition, traditional training approaches rely too much on expert-labeled data, setting an upper limit on the performance of LLMs. To address this issue, we propose a novel paradigm that enables LLMs to train itself by autonomously generating, cleaning, reviewing, and annotating data with preference information, named LANCE. Our approach demonstrates that LLMs can serve as continuous self-evolving data engineers, significantly reducing the time and cost of the post-training data construction process. Through iterative fine-tuning on different variants of the Qwen2, we validate the effectiveness of LANCE across various tasks, showing that it can continuously improve model performance and maintain high-quality data generation. Across eight benchmark dimensions, LANCE resulted in an average score enhancement of 3.36 for Qwen2-7B and 2.70 for Qwen2-7B-Instruct. This training paradigm with autonomous data construction not only reduces the reliance on human experts or external models but also ensures that the data aligns with human values and preferences, paving the way for the development of future superintelligent systems that can exceed human capabilities.', 'abstract_zh': '大型语言模型（LLMs）在各种任务上展现了 remarkable 的能力，但进一步的发展受到高质量训练数据缺乏的限制。此外，传统的训练方法过度依赖专家标注的数据，这在一定程度上限制了LLMs的性能。为了解决这一问题，我们提出了一种新的范式，该范式使LLMs能够自主生成、清理、审核和标注数据，并融入偏好信息，我们将其命名为LANCE。我们的方法展示了LLMs可以作为持续自我演化的数据工程师，显著减少了训练后数据构建过程的时间和成本。通过对不同版本的Qwen2进行逐步微调，我们验证了LANCE在各种任务上的有效性，表明它可以持续提升模型性能并保持高质量数据生成。在八个基准维度上，LANCE分别提高了Qwen2-7B和Qwen2-7B-Instruct的平均分数3.36和2.70。这种自动构建数据的训练范式不仅减少了对人类专家或外部模型的依赖，还确保了数据与人类价值观和偏好相一致，为开发超越人类能力的未来超级智能系统铺平了道路。', 'title_zh': '语言模型作为连续自进化的数据工程师\n\n这个标题翻译成中文时，保持了原文的意思和学术性。如果需要更详细的描述内容，可以进一步补充，比如：\n\n语言模型作为一种连续自进化的数据处理与工程工具\n\n这样的翻译和补充更全面地反映了原文标题的意义，同时符合学术写作的规范。'}
{'arxiv_id': 'arXiv:2412.15150', 'title': 'Leveraging Color Channel Independence for Improved Unsupervised Object Detection', 'authors': 'Bastian Jäckl, Yannick Metz, Udo Schlegel, Daniel A. Keim, Maximilian T. Fischer', 'link': 'https://arxiv.org/abs/2412.15150', 'abstract': "Object-centric architectures can learn to extract distinct object representations from visual scenes, enabling downstream applications on the object level. Similarly to autoencoder-based image models, object-centric approaches have been trained on the unsupervised reconstruction loss of images encoded by RGB color spaces. In our work, we challenge the common assumption that RGB images are the optimal color space for unsupervised learning in computer vision. We discuss conceptually and empirically that other color spaces, such as HSV, bear essential characteristics for object-centric representation learning, like robustness to lighting conditions. We further show that models improve when requiring them to predict additional color channels. Specifically, we propose to transform the predicted targets to the RGB-S space, which extends RGB with HSV's saturation component and leads to markedly better reconstruction and disentanglement for five common evaluation datasets. The use of composite color spaces can be implemented with basically no computational overhead, is agnostic of the models' architecture, and is universally applicable across a wide range of visual computing tasks and training types. The findings of our approach encourage additional investigations in computer vision tasks beyond object-centric learning.", 'abstract_zh': '以对象为中心的架构可以从视觉场景中学习提取不同的对象表示，从而在对象级别上启用下游应用。与基于自编码器的图像模型类似，对象为中心的方法是通过使用RGB色彩空间编码图像来进行无监督重建损失训练的。\n\n然而，在我们的工作中，我们挑战了在计算机视觉中RGB图像是最优无监督学习色彩空间这一常见假设。我们从概念和经验两个方面讨论了其他色彩空间（如HSV），它们在对象为中心的表示学习中具有本质性特点，比如对光照条件的鲁棒性。我们进一步展示了当要求模型预测额外的色彩通道时，模型性能会提高。具体来说，我们提议将预测的目标转换到RGB-S色彩空间，该空间在RGB基础上增加了HSV色彩空间中的饱和地区分量，并在五个常见评估数据集上实现了显著更好的重建和解耦效果。复合色彩空间的使用几乎不会增加计算负担，与模型架构无关，并且可以广泛应用于各种视觉计算任务和训练类型。\n\n我们的方法的发现鼓励了对超出对象为中心学习的计算机视觉任务进行进一步的研究。', 'title_zh': '利用颜色通道独立性以提高无监督目标检测性能'}
{'arxiv_id': 'arXiv:2412.15129', 'title': 'Jet: A Modern Transformer-Based Normalizing Flow', 'authors': 'Alexander Kolesnikov, André Susano Pinto, Michael Tschannen', 'link': 'https://arxiv.org/abs/2412.15129', 'abstract': 'In the past, normalizing generative flows have emerged as a promising class of generative models for natural images. This type of model has many modeling advantages: the ability to efficiently compute log-likelihood of the input data, fast generation and simple overall structure. Normalizing flows remained a topic of active research but later fell out of favor, as visual quality of the samples was not competitive with other model classes, such as GANs, VQ-VAE-based approaches or diffusion models. In this paper we revisit the design of the coupling-based normalizing flow models by carefully ablating prior design choices and using computational blocks based on the Vision Transformer architecture, not convolutional neural networks. As a result, we achieve state-of-the-art quantitative and qualitative performance with a much simpler architecture. While the overall visual quality is still behind the current state-of-the-art models, we argue that strong normalizing flow models can help advancing research frontier by serving as building components of more powerful generative models.', 'abstract_zh': '在以往的研究中，归一化生成流作为一类生成模型在自然图像生成方面展现出较大的潜力。这类模型具有计算输入数据对数似然性的高效性、快速生成能力和简洁的整体结构等优点。尽管如此，归一化流作为研究热点的地位逐渐让位于其他模型类别，如生成对抗网络（GANs）、基于矢量量化变分自动编码器（VQ-VAE）的方法或扩散模型，因为生成的图像质量不再具备竞争力。在本文中，我们通过细致地消除先前设计选择并采用基于视力变压器架构的计算模块，而非卷积神经网络，重新审视基于耦合的归一化流模型的设计。由此，我们以一个更加简洁的架构取得了最先进的定量和定性性能。尽管整体视觉质量仍落后于当前最先进的模型，我们认为强大的归一化流模型可以作为构建更强大生成模型的组件，从而推动研究前沿的发展。', 'title_zh': 'Jet：一种基于Transformer的现代Normalization Flow'}
{'arxiv_id': 'arXiv:2412.15127', 'title': 'Adaptive Pruning for Large Language Models with Structural Importance Awareness', 'authors': 'Haotian Zheng, Jinke Ren, Yushan Sun, Ruichen Zhang, Wenbo Zhang, Zhen Li, Dusit Niyato, Shuguang Cui, Yatong Han', 'link': 'https://arxiv.org/abs/2412.15127', 'abstract': 'The recent advancements in large language models (LLMs) have significantly improved language understanding and generation capabilities. However, it is difficult to deploy LLMs on resource-constrained edge devices due to their high computational and storage resource demands. To address this issue, we propose a novel LLM model pruning method, namely structurally-aware adaptive pruning (SAAP), to significantly reduce the computational and memory costs while maintaining model performance. We first define an adaptive importance fusion metric to evaluate the importance of all coupled structures in LLMs by considering their homoscedastic uncertainty. Then, we rank the importance of all modules to determine the specific layers that should be pruned to meet particular performance requirements. Furthermore, we develop a new group fine-tuning strategy to improve the inference efficiency of LLMs. Finally, we evaluate the proposed SAAP method on multiple LLMs across two common tasks, i.e., zero-shot classification and text generation. Experimental results show that our SAAP method outperforms several state-of-the-art baseline methods, achieving 2.17%, 2.37%, and 2.39% accuracy gains on LLaMA-7B, Vicuna-7B, and LLaMA-13B. Additionally, SAAP improves the token generation speed by 5%, showcasing its practical advantages in resource-constrained scenarios.', 'abstract_zh': '近年来，大型语言模型（LLMs）在语言理解和生成能力方面取得了显著进步。然而，由于其高计算和存储资源需求，将LLMs部署在资源受限的边缘设备上存在困难。为解决这一问题，我们提出了一种新颖的LLM模型剪枝方法，即结构感知自适应剪枝（SAAP），该方法在保持模型性能的同时大幅减少计算和内存成本。首先，我们定义了一种自适应重要性融合度量，通过考虑各结构的同质不确定性和耦合关系来评估其重要性。然后，我们根据所有模块的重要性对其进行排名，以确定应被剪枝的具体层，以满足特定的性能要求。此外，我们还提出了一种新的分组微调策略，以提高LLMs的推理效率。最后，我们在两项常见任务（即零样本分类和文本生成）上对多个LLM进行了所提SAAP方法的评估。实验结果表明，我们的SAAP方法优于几种最先进的基线方法，在LLaMA-7B、Vicuna-7B和LLaMA-13B上的准确率分别提高了2.17%、2.37%和2.39%。此外，SAAP方法提高了5%的token生成速度，展示了其在资源受限场景下的实用优势。', 'title_zh': '带有结构重要性意识的大型语言模型自适应剪枝'}
{'arxiv_id': 'arXiv:2412.15118', 'title': 'Outcome-Refining Process Supervision for Code Generation', 'authors': 'Zhuohao Yu, Weizheng Gu, Yidong Wang, Zhengran Zeng, Jindong Wang, Wei Ye, Shikun Zhang', 'link': 'https://arxiv.org/abs/2412.15118', 'abstract': 'Large Language Models have demonstrated remarkable capabilities in code generation, yet they often struggle with complex programming tasks that require deep algorithmic reasoning. While process supervision through learned reward models shows promise in guiding reasoning steps, it requires expensive training data and suffers from unreliable evaluation. We propose Outcome-Refining Process Supervision, a novel paradigm that treats outcome refinement itself as the process to be supervised. Our framework leverages concrete execution signals to ground the supervision of reasoning steps, while using tree-structured exploration to maintain multiple solution trajectories simultaneously. Experiments demonstrate that our approach enables even smaller models to achieve high success accuracy and performance metrics on competitive programming tasks, creates more reliable verification than traditional reward models without requiring training PRMs. Our approach achieves significant improvements across 5 models and 3 datasets: an average of 26.9% increase in correctness and 42.2% in efficiency. The results suggest that providing structured reasoning space with concrete verification signals is crucial for solving complex programming tasks. We open-source all our code and data at: this https URL', 'abstract_zh': '大型语言模型在代码生成方面展现出了惊人的能力，但在执行复杂编程任务时，常遇到需要深层次算法推理的问题。虽然通过学习奖励模型进行过程监督显示出一定的潜力，可以引导推理步骤，但它需要昂贵的训练数据，并且在评估上不够可靠。为此，我们提出了一种名为“结果细化的过程监督”的新颖范式，该范式将结果细化本身视为需要监督的过程。我们的框架利用具体的执行信号来确定推理步骤的监督，同时使用树状探索结构来并行维护多个解决方案轨迹。实验结果表明，我们的方法使即使是较小的模型也能在竞争性编程任务中实现高准确率和较好的性能指标，在无需训练奖励模型的情况下实现了更可靠的验证。在5个模型和3个数据集上，我们的方法平均提高了26.9%的正确率和42.2%的效率。结果表明，提供结构化的推理空间和具体的验证信号对于解决复杂编程任务至关重要。我们开源了所有代码和数据：[此链接](this https URL)', 'title_zh': '代码生成中的成果细化过程监督'}
{'arxiv_id': 'arXiv:2412.15113', 'title': 'Associative memory inspires improvements for in-context learning using a novel attention residual stream architecture', 'authors': 'Thomas F Burns, Tomoki Fukai, Christopher J Earls', 'link': 'https://arxiv.org/abs/2412.15113', 'abstract': 'Large language models (LLMs) demonstrate an impressive ability to utilise information within the context of their input sequences to appropriately respond to data unseen by the LLM during its training procedure. This ability is known as in-context learning (ICL). Humans and non-human animals demonstrate similar abilities, however their neural architectures differ substantially from LLMs. Despite this, a critical component within LLMs, the attention mechanism, resembles modern associative memory models, widely used in and influenced by the computational neuroscience community to model biological memory systems. Using this connection, we introduce an associative memory model capable of performing ICL. We use this as inspiration for a novel residual stream architecture which allows information to directly flow between attention heads. We test this architecture during training within a two-layer Transformer and show its ICL abilities manifest more quickly than without this modification. We then apply our architecture in small language models with 8 million parameters, focusing on attention head values, with results also indicating improved ICL performance at this larger and more naturalistic scale.', 'abstract_zh': '大型语言模型（Large Language Models, LLMs）展示了在输入序列上下文中利用信息以适当地应对训练期间LLM未见过的数据的能力。这种能力被称为上下文学习（In-Context Learning, ICL）。人类和非人类动物也表现出类似的能力，但它们的神经架构与LLM存在显著差异。尽管如此，LLMs中一个关键组件，注意力机制，类似于现代的联想记忆模型，这些模型在计算神经科学社区中被广泛使用来模拟生物记忆系统。利用这一联系，我们引入了一个能够执行ICL的联想记忆模型。我们借此为一种新颖的残差流架构提供灵感，该架构允许信息在注意力头之间直接流动。我们在两层Transformer的训练过程中测试了这种架构，并显示了这种修改后ICL能力表现得更快速。然后，我们在具有800万个参数的小型语言模型中应用了我们的架构，重点关注注意力头值，结果表明，在更大和更自然的规模下也表现出改进的ICL性能。', 'title_zh': '关联记忆启发一种新型注意力残差流架构以改进上下文适应学习'}
{'arxiv_id': 'arXiv:2412.15105', 'title': 'Exploiting sparse structures and synergy designs to advance situational awareness of electrical power grid', 'authors': 'Shimiao Li', 'link': 'https://arxiv.org/abs/2412.15105', 'abstract': 'The growing threats of uncertainties, anomalies, and cyberattacks on power grids are driving a critical need to advance situational awareness which allows system operators to form a complete and accurate picture of the present and future state. Simulation and estimation are foundational tools in this process. However, existing tools lack the robustness and efficiency required to achieve the level of situational awareness needed for the ever-evolving threat landscape. Industry-standard (steady-state) simulators are not robust to blackouts, often leading to non-converging or non-actionable results. Estimation tools lack robustness to anomalous data, returning erroneous system states. Efficiency is the other major concern as nonlinearities and scalability issues make large systems slow to converge.\nThis thesis addresses robustness and efficiency gaps through a dual-fold contribution. We first address the inherent limitations in the existing physics-based and data-driven worlds; and then transcend the boundaries of conventional algorithmic design in the direction of a new paradigm -- Physics-ML Synergy -- which integrates the strengths of the two worlds. Our approaches are built on circuit formulation which provides a unified framework that applies to both transmission and distribution. Sparse optimization acts as the key enabler to make these tools intrinsically robust and immune to random threats, pinpointing dominant sources of (random) blackouts and data errors. Further, we explore sparsity-exploiting optimizations to develop lightweight ML models whose prediction and detection capabilities are a complement to physics-based tools; and whose lightweight designs advance generalization and scalability. Finally, Physics-ML Synergy brings robustness and efficiency further against targeted cyberthreats, by interconnecting our physics-based tools with lightweight ML.', 'abstract_zh': '不断增长的不确定性、异常现象和网络攻击对电力系统的威胁正在推动迫切需要提升态势感知的需求。这使得系统操作员能够形成对当前和未来状态的完整而准确的理解变得至关重要。仿真和估算工具是这一过程中的基础工具。然而，现有的工具缺乏在不断演变的威胁环境中实现所需态势感知所需的稳健性和效率。现行工业标准（稳态）仿真器往往对停电缺乏稳健性，经常导致无法收敛或不可操作的结果。估算工具对异常数据的稳健性不足，会返回错误的系统状态。效率也是另一个重大问题，因为非线性和可扩展性问题使得复杂系统难以快速收敛。\n\n本论文通过双重贡献解决了稳健性和效率方面的差距。首先，我们解决了现有物理基础建模和数据驱动建模中固有的限制；然后，我们超越了传统算法设计的界限，迈向一种新的范式——物理与机器学习协同（Physics-ML Synergy），将两者的优点结合起来。我们的方法建立在电路公式的基础之上，提供了一个适用于输电和配电的统一框架。稀疏优化作为关键使能技术，使其工具对随机威胁具有内在的稳健性，能够准确定位停电和数据错误的主要来源。此外，我们探索了利用稀疏优化技术发展轻量级机器学习模型的方法，这些模型的预测和检测能力是物理基础工具的补充，并且轻量级的设计有利于提高泛化能力和可扩展性。最后，物理与机器学习协同（Physics-ML Synergy）进一步增强了对针对性网络威胁的稳健性和效率，通过将基于物理的工具与轻量级机器学习技术相连，提升了整体系统对抗网络攻击的能力。', 'title_zh': '利用稀疏结构和协同设计推进电力 grids 的态势感知研究'}
{'arxiv_id': 'arXiv:2412.15098', 'title': 'A Cross-Domain Study of the Use of Persuasion Techniques in Online Disinformation', 'authors': 'João A. Leite, Olesya Razuvayevskaya, Carolina Scarton, Kalina Bontcheva', 'link': 'https://arxiv.org/abs/2412.15098', 'abstract': 'Disinformation, irrespective of domain or language, aims to deceive or manipulate public opinion, typically through employing advanced persuasion techniques. Qualitative and quantitative research on the weaponisation of persuasion techniques in disinformation has been mostly topic-specific (e.g., COVID-19) with limited cross-domain studies, resulting in a lack of comprehensive understanding of these strategies. This study employs a state-of-the-art persuasion technique classifier to conduct a large-scale, multi-domain analysis of the role of 16 persuasion techniques in disinformation narratives. It shows how different persuasion techniques are employed disproportionately in different disinformation domains. We also include a detailed case study on climate change disinformation, highlighting how linguistic, psychological, and cultural factors shape the adaptation of persuasion strategies to fit unique thematic contexts.', 'abstract_zh': '无论是哪个领域或语言，虚假信息的目的是欺骗或操控公众意见，通常通过运用先进的说服技巧来实现。对说服技巧在虚假信息中的武器化进行定性和定量研究主要集中在特定主题上（例如，COVID-19），跨领域的研究有限，这导致了对这些策略的综合理解不足。本研究采用最先进的说服技巧分类器，对16种说服技巧在虚假信息叙事中的作用进行了大规模、多领域分析。研究结果显示，不同类型的说服技巧在不同的虚假信息领域中的运用存在显著差异。我们还提供了一个详细的关于气候变化虚假信息的案例研究，突出了语言、心理和社会文化因素如何塑造说服策略以适应独特的主题背景。', 'title_zh': '跨领域研究在线虚假信息中说服技术的运用'}
{'arxiv_id': 'arXiv:2412.15095', 'title': 'A Full Transformer-based Framework for Automatic Pain Estimation using Videos', 'authors': 'Stefanos Gkikas, Manolis Tsiknakis', 'link': 'https://arxiv.org/abs/2412.15095', 'abstract': 'The automatic estimation of pain is essential in designing an optimal pain management system offering reliable assessment and reducing the suffering of patients. In this study, we present a novel full transformer-based framework consisting of a Transformer in Transformer (TNT) model and a Transformer leveraging cross-attention and self-attention blocks. Elaborating on videos from the BioVid database, we demonstrate state-of-the-art performances, showing the efficacy, efficiency, and generalization capability across all the primary pain estimation tasks.', 'abstract_zh': '自动评估疼痛是设计一个提供可靠评估并减少患者痛苦的最优疼痛管理系统所必需的。在本研究中，我们提出了一种新颖的基于全变换器的框架，该框架包括Transformer in Transformer (TNT) 模型和一个利用交叉注意力和自我注意力模块的变换器。通过对BioVid数据库中的视频进行详细分析，我们展示了该框架在所有主要疼痛评估任务中的领先性能，表明了其有效性和泛化能力。', 'title_zh': '基于全Transformer架构的视频自动疼痛估计完整框架'}
{'arxiv_id': 'arXiv:2412.15086', 'title': 'Learning Disentangled Equivariant Representation for Explicitly Controllable 3D Molecule Generation', 'authors': 'Haoran Liu, Youzhi Luo, Tianxiao Li, James Caverlee, Martin Renqiang Min', 'link': 'https://arxiv.org/abs/2412.15086', 'abstract': "We consider the conditional generation of 3D drug-like molecules with \\textit{explicit control} over molecular properties such as drug-like properties (e.g., Quantitative Estimate of Druglikeness or Synthetic Accessibility score) and effectively binding to specific protein sites. To tackle this problem, we propose an E(3)-equivariant Wasserstein autoencoder and factorize the latent space of our generative model into two disentangled aspects: molecular properties and the remaining structural context of 3D molecules. Our model ensures explicit control over these molecular attributes while maintaining equivariance of coordinate representation and invariance of data likelihood. Furthermore, we introduce a novel alignment-based coordinate loss to adapt equivariant networks for auto-regressive de-novo 3D molecule generation from scratch. Extensive experiments validate our model's effectiveness on property-guided and context-guided molecule generation, both for de-novo 3D molecule design and structure-based drug discovery against protein targets.", 'abstract_zh': '我们考虑在明确控制分子属性（如药物like特性，例如定量的药物like度量或合成可及性评分）的同时生成3D药物like分子，并且能够有效与特定蛋白质位点结合。为了解决这一问题，我们提出了一种E(3)-对称的Wasserstein自编码器，并将生成模型的潜在空间分解为两个解耦方面：分子属性和3D分子剩余的结构上下文。该模型确保对这些分子属性进行明确的控制，同时保持坐标表示的对称性和数据似然性的不变性。此外，我们引入了一种基于对齐的坐标损失，以适应对称网络，用于从零开始进行自回归的3D分子生成。广泛的实验验证了我们在属性引导和上下文引导的分子生成中的有效性，特别是在从零开始设计全新的3D分子以及基于结构的药物发现（针对蛋白质目标）方面。', 'title_zh': '学习解纠缠保不变表示以实现显式可控的3D分子生成'}
{'arxiv_id': 'arXiv:2412.15084', 'title': 'AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward Modeling', 'authors': 'Zihan Liu, Yang Chen, Mohammad Shoeybi, Bryan Catanzaro, Wei Ping', 'link': 'https://arxiv.org/abs/2412.15084', 'abstract': 'In this paper, we introduce AceMath, a suite of frontier math models that excel in solving complex math problems, along with highly effective reward models capable of evaluating generated solutions and reliably identifying the correct ones. To develop the instruction-tuned math models, we propose a supervised fine-tuning (SFT) process that first achieves competitive performance across general domains, followed by targeted fine-tuning for the math domain using a carefully curated set of prompts and synthetically generated responses. The resulting model, AceMath-72B-Instruct greatly outperforms Qwen2.5-Math-72B-Instruct, GPT-4o and Claude-3.5 Sonnet. To develop math-specialized reward model, we first construct AceMath-RewardBench, a comprehensive and robust benchmark for evaluating math reward models across diverse problems and difficulty levels. After that, we present a systematic approach to build our math reward models. The resulting model, AceMath-72B-RM, consistently outperforms state-of-the-art reward models. Furthermore, when combining AceMath-72B-Instruct with AceMath-72B-RM, we achieve the highest average rm@8 score across the math reasoning benchmarks. We will release model weights, training data, and evaluation benchmarks at: this https URL', 'abstract_zh': '在本文中，我们介绍了AceMath，这是一个卓越于解决复杂数学问题的一系列前沿数学模型，以及高度有效的奖励模型，能够对生成的解决方案进行评估，并可靠地识别出正确的解。为了开发指令调整的数学模型，我们提出了一种监督细调（SFT）过程，首先在通用领域实现竞争力表现，随后通过精心选择的提示和合成生成的响应，针对数学领域进行目标调整细调。由此产生的模型AceMath-72B-Instruct在性能上远超Qwen2.5-Math-72B-Instruct、GPT-4o和Claude-3.5 Sonnet。为了开发专门化的数学奖励模型，我们首先构建了AceMath-RewardBench，这是一个综合且稳健的基准，用于评估不同类型的数学奖励模型在各种问题和难度级别下的表现。之后，我们提供了一种系统的方法来构建我们的数学奖励模型。由此产生的模型AceMath-72B-RM在各方面都持续地优于最先进的奖励模型。此外，当将AceMath-72B-Instruct与AceMath-72B-RM结合使用时，我们实现了数学推理基准测试中最高的平均rm@8分数。我们将模型权重、训练数据和评估基准发布在以下链接：this https URL', 'title_zh': 'AceMath: 利用后训练和奖励建模推进前沿数学推理'}
{'arxiv_id': 'arXiv:2412.15054', 'title': 'GIRAFE: Glottal Imaging Dataset for Advanced Segmentation, Analysis, and Facilitative Playbacks Evaluation', 'authors': 'G. Andrade-Miranda, K. Chatzipapas, J.D. Arias-Londoño, J. I. Godino-Llorente', 'link': 'https://arxiv.org/abs/2412.15054', 'abstract': 'The advances in the development of Facilitative Playbacks extracted from High-Speed videoendoscopic sequences of the vocal folds are hindered by a notable lack of publicly available datasets annotated with the semantic segmentations corresponding to the area of the glottal gap. This fact also limits the reproducibility and further exploration of existing research in this field.\nTo address this gap, GIRAFE is a data repository designed to facilitate the development of advanced techniques for the semantic segmentation, analysis, and fast evaluation of High-Speed videoendoscopic sequences of the vocal folds. The repository includes 65 high-speed videoendoscopic recordings from a cohort of 50 patients (30 female, 20 male). The dataset comprises 15 recordings from healthy controls, 26 from patients with diagnosed voice disorders, and 24 with an unknown health condition. All of them were manually annotated by an expert, including the masks corresponding to the semantic segmentation of the glottal gap. The repository is also complemented with the automatic segmentation of the glottal area using different state-of-the-art approaches.\nThis data set has already supported several studies, which demonstrates its usefulness for the development of new glottal gap segmentation algorithms from High-Speed-Videoendoscopic sequences to improve or create new Facilitative Playbacks. Despite these advances and others in the field, the broader challenge of performing an accurate and completely automatic semantic segmentation method of the glottal area remains open.', 'abstract_zh': '高帧速视遗镜序列中声带助听回放发展的进步因缺乏标注有声门间隙语义分割的公开数据集而受到阻碍。这一事实也限制了现有研究在这一领域的可重复性和进一步探索。\n\n为解决这一问题，GIRAFE 是一个数据仓库，旨在促进高级技术的发展，以实现高帧速视遗镜序列中声带区域的语义分割、分析和快速评估。该数据仓库包括来自50名患者（30名女性，20名男性）的65个高帧速视遗镜录制。数据集包含15个健康对照组的录制、26个经过诊断的声带疾病患者的录制，以及24个未知健康状况的录制。所有这些录制都由专家手动标注，包括声门间隙语义分割对应的掩码。此外，该数据仓库还提供了使用不同最先进的方法进行声门区域自动分割。\n\n该数据集已经支持了多项研究，证明了其在从高帧速视遗镜序列开发或改进新声门间隙分割算法方面的有用性。尽管在这一领域取得了这些和其他进展，但对声门区域进行准确且完全自动的语义分割方法的更大挑战仍然存在。', 'title_zh': 'GIRAFE：声门成像数据集，用于高级分段、分析及辅助回放评估'}
{'arxiv_id': 'arXiv:2412.15047', 'title': 'Measuring, Modeling, and Helping People Account for Privacy Risks in Online Self-Disclosures with AI', 'authors': 'Isadora Krsek, Anubha Kabra, Yao Dou, Tarek Naous, Laura A. Dabbish, Alan Ritter, Wei Xu, Sauvik Das', 'link': 'https://arxiv.org/abs/2412.15047', 'abstract': "In pseudonymous online fora like Reddit, the benefits of self-disclosure are often apparent to users (e.g., I can vent about my in-laws to understanding strangers), but the privacy risks are more abstract (e.g., will my partner be able to tell that this is me?). Prior work has sought to develop natural language processing (NLP) tools that help users identify potentially risky self-disclosures in their text, but none have been designed for or evaluated with the users they hope to protect. Absent this assessment, these tools will be limited by the social-technical gap: users need assistive tools that help them make informed decisions, not paternalistic tools that tell them to avoid self-disclosure altogether. To bridge this gap, we conducted a study with N = 21 Reddit users; we had them use a state-of-the-art NLP disclosure detection model on two of their authored posts and asked them questions to understand if and how the model helped, where it fell short, and how it could be improved to help them make more informed decisions. Despite its imperfections, users responded positively to the model and highlighted its use as a tool that can help them catch mistakes, inform them of risks they were unaware of, and encourage self-reflection. However, our work also shows how, to be useful and usable, AI for supporting privacy decision-making must account for posting context, disclosure norms, and users' lived threat models, and provide explanations that help contextualize detected risks.", 'abstract_zh': '在诸如Reddit之类的匿名在线论坛中，用户常常意识到自我披露的好处（例如，我可以向理解我的陌生人们倾诉我对公婆的感受），但隐私风险往往是抽象的（例如，我的伴侣是否能看出这是我在发言？）。已有研究试图开发自然语言处理（NLP）工具，帮助用户识别他们在文本中可能存在的风险性自我披露，但这些工具尚未专门设计用于或经过目标用户的评估。缺乏这种评估，这些工具将受限于社会技术差距：用户需要的是辅助工具，能帮助他们做出知情决策，而不仅仅是告诉他们完全避免自我披露。为了弥合这一差距，我们进行了一个涉及21名Reddit用户的实验；我们让他们使用最先进的NLP自我披露检测模型分析了他们撰写的两篇文章，并询问了一系列问题，以了解该模型如何帮助他们、在哪里不足以及如何改进以帮助他们做出更明智的决策。尽管模型存在不足之处，但用户对模型持积极态度，并强调其作为一种工具可以帮助他们发现错误、告知他们未意识到的风险并促进自我反省。然而，我们的研究也表明，为了有用且易于使用，支持隐私决策的AI工具必须考虑发帖情境、自我披露规范以及用户的实际威胁模型，并提供能帮助承载检测风险背景的解释。', 'title_zh': '使用AI衡量、建模并帮助人们考虑在线自我披露中的隐私风险'}
{'arxiv_id': 'arXiv:2412.15004', 'title': 'Large Language Models and Code Security: A Systematic Literature Review', 'authors': 'Enna Basic, Alberto Giaretta', 'link': 'https://arxiv.org/abs/2412.15004', 'abstract': 'Large Language Models (LLMs) have emerged as powerful tools for automating various programming tasks, including security-related ones, such as detecting and fixing vulnerabilities. Despite their promising capabilities, when required to produce or modify pre-existing code, LLMs could introduce vulnerabilities unbeknown to the programmer. When analyzing code, they could miss clear vulnerabilities or signal nonexistent ones. In this Systematic Literature Review (SLR), we aim to investigate both the security benefits and potential drawbacks of using LLMs for a variety of code-related tasks. In particular, first we focus on the types of vulnerabilities that could be introduced by LLMs, when used for producing code. Second, we analyze the capabilities of LLMs to detect and fix vulnerabilities, in any given code, and how the prompting strategy of choice impacts their performance in these two tasks. Last, we provide an in-depth analysis on how data poisoning attacks on LLMs can impact performance in the aforementioned tasks.', 'abstract_zh': '大型语言模型（LLMs）已发展成为自动化各种编程任务的强大工具，包括与安全相关的工作，如检测和修复漏洞。尽管它们具有令人振奋的能力，但在生成或修改现有代码时，LLMs 有可能引入程序员未知的漏洞。在分析代码时，它们可能会错过明显的漏洞或错误地标识不存在的漏洞。在本系统文献综述（SLR）中，我们旨在研究使用LLMs进行各种编码相关任务时的安全益处和潜在缺点。具体而言，首先，我们关注LLMs在生成代码时可能引入的漏洞类型。其次，我们分析LLMs在任何给定代码中检测和修复漏洞的能力，并探讨不同的提示策略如何影响它们在这两项任务中的表现。最后，我们深入分析数据投毒攻击如何影响LLMs在上述任务中的性能。', 'title_zh': '大型语言模型与代码安全性：系统文献综述'}
{'arxiv_id': 'arXiv:2412.14995', 'title': 'HSEvo: Elevating Automatic Heuristic Design with Diversity-Driven Harmony Search and Genetic Algorithm Using LLMs', 'authors': 'Pham Vu Tuan Dat, Long Doan, Huynh Thi Thanh Binh', 'link': 'https://arxiv.org/abs/2412.14995', 'abstract': "Automatic Heuristic Design (AHD) is an active research area due to its utility in solving complex search and NP-hard combinatorial optimization problems in the real world. The recent advancements in Large Language Models (LLMs) introduce new possibilities by coupling LLMs with evolutionary computation to automatically generate heuristics, known as LLM-based Evolutionary Program Search (LLM-EPS). While previous LLM-EPS studies obtained great performance on various tasks, there is still a gap in understanding the properties of heuristic search spaces and achieving a balance between exploration and exploitation, which is a critical factor in large heuristic search spaces. In this study, we address this gap by proposing two diversity measurement metrics and perform an analysis on previous LLM-EPS approaches, including FunSearch, EoH, and ReEvo. Results on black-box AHD problems reveal that while EoH demonstrates higher diversity than FunSearch and ReEvo, its objective score is unstable. Conversely, ReEvo's reflection mechanism yields good objective scores but fails to optimize diversity effectively. With this finding in mind, we introduce HSEvo, an adaptive LLM-EPS framework that maintains a balance between diversity and convergence with a harmony search algorithm. Through experimentation, we find that HSEvo achieved high diversity indices and good objective scores while remaining cost-effective. These results underscore the importance of balancing exploration and exploitation and understanding heuristic search spaces in designing frameworks in LLM-EPS.", 'abstract_zh': '自动启发式设计（AHD）是一个活跃的研究领域，因为它在解决复杂搜索和NP难组合优化问题方面具有实用性。近年来，大型语言模型（LLMs）的进步通过将LLMs与进化计算结合起来，自动生成启发式方法（即LLM基于的进化程序搜索LLM-EPS），从而开辟了新的可能性。尽管之前的研究在多种任务中取得了出色的性能，但仍然存在对启发式搜索空间的属性理解不足以及探索与利用之间的平衡问题，尤其是在大型启发式搜索空间中，这是一个关键因素。在本研究中，我们通过提出两种多样性度量指标，并对先前的LLM-EPS方法进行分析，包括FunSearch、EoH和ReEvo，来解决这一差距。实验证明，在黑盒AHD问题上，EoH的表现多样性和FunSearch和ReEvo相比更高，但其目标分数不稳定。相反，ReEvo的反射机制能产出好的目标分数，但在优化多样性方面效果不佳。基于这一发现，我们提出了一个自适应的LLM-EPS框架HSEvo，该框架利用和谐搜索算法保持多样性与收敛之间的平衡。通过实验，我们发现HSEvo不仅能实现高多样性和好的目标分数，还能保持成本效益。这些结果强调了在设计LLM-EPS框架时平衡探索和利用及理解启发式搜索空间的重要性。', 'title_zh': 'HSEvo：通过多样性驱动的和谐搜索和遗传算法结合大语言模型提升自动启发式设计'}
{'arxiv_id': 'arXiv:2412.14965', 'title': 'Movie2Story: A framework for understanding videos and telling stories in the form of novel text', 'authors': 'Kangning Li, Zheyang Jia, Anyu Ying', 'link': 'https://arxiv.org/abs/2412.14965', 'abstract': 'Multimodal video-to-text models have made considerable progress, primarily in generating brief descriptions of video content. However, there is still a deficiency in generating rich long-form text descriptions that integrate both video and audio. In this paper, we introduce a framework called M2S, designed to generate novel-length text by combining audio, video, and character recognition. M2S includes modules for video long-form text description and comprehension, audio-based analysis of emotion, speech rate, and character alignment, and visual-based character recognition alignment. By integrating multimodal information using the large language model GPT4o, M2S stands out in the field of multimodal text generation. We demonstrate the effectiveness and accuracy of M2S through comparative experiments and human evaluation. Additionally, the model framework has good scalability and significant potential for future research.', 'abstract_zh': '多模态视频到文本模型在生成简短的视频内容描述方面取得了显著进展，但在生成结合视频和音频的丰富长文本描述方面仍存在不足。本文介绍了一种名为M2S（Multimodal to Sequential）的框架，旨在通过结合音频、视频和字符识别生成长篇文本。M2S包括用于生成视频长篇文本描述和理解、基于音频的情绪分析、语速分析以及角色对齐的模块，以及基于视觉的角色识别对齐。通过使用大规模语言模型GPT4o整合多模态信息，M2S在多模态文本生成领域脱颖而出。我们通过对照实验和人工评估展示了M2S的有效性和准确性。此外，该模型框架具有良好的扩展性，并具有未来研究的巨大潜力。', 'title_zh': '电影到故事：一种理解视频并以新颖文本形式讲述故事的框架'}
{'arxiv_id': 'arXiv:2412.14933', 'title': 'Cirbo: A New Tool for Boolean Circuit Analysis and Synthesis', 'authors': 'Daniil Averkov, Tatiana Belova, Gregory Emdin, Mikhail Goncharov, Viktoriia Krivogornitsyna, Alexander S. Kulikov, Fedor Kurmazov, Daniil Levtsov, Georgie Levtsov, Vsevolod Vaskin, Aleksey Vorobiev', 'link': 'https://arxiv.org/abs/2412.14933', 'abstract': 'We present an open-source tool for manipulating Boolean circuits. It implements efficient algorithms, both existing and novel, for a rich variety of frequently used circuit tasks such as satisfiability, synthesis, and minimization. We tested the tool on a wide range of practically relevant circuits (computing, in particular, symmetric and arithmetic functions) that have been optimized intensively by the community for the last three years. The tool helped us to win the IWLS 2024 Programming Contest. In 2023, it was Google DeepMind who took the first place in the competition. We were able to reduce the size of the best circuits from 2023 by 12\\% on average, whereas for some individual circuits, our size reduction was as large as 83\\%.', 'abstract_zh': '我们提供了一个开源工具，用于操作布尔电路。该工具实现了高效算法（包括现有和新颖的算法），可以完成多种常用电路任务，如可满足性、综合和最小化。我们对该工具进行了广泛的测试，测试对象包括过去三年社区优化的各类实用电路（特别包括对称和算术函数的计算电路）。该工具帮助我们赢得了IWLS 2024编程大赛。2023年，谷歌DeepMind在比赛中的表现最佳。我们能够将2023年最佳电路的大小平均减少了12%，而在某些具体电路中，我们的尺寸减小率达到了83%。', 'title_zh': 'Cirbo：一种新的布尔电路分析与综合工具'}
{'arxiv_id': 'arXiv:2412.14922', 'title': 'RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response', 'authors': 'Junyu Luo, Xiao Luo, Kaize Ding, Jingyang Yuan, Zhiping Xiao, Ming Zhang', 'link': 'https://arxiv.org/abs/2412.14922', 'abstract': "Supervised fine-tuning (SFT) plays a crucial role in adapting large language models (LLMs) to specific domains or tasks. However, as demonstrated by empirical experiments, the collected data inevitably contains noise in practical applications, which poses significant challenges to model performance on downstream tasks. Therefore, there is an urgent need for a noise-robust SFT framework to enhance model capabilities in downstream tasks. To address this challenge, we introduce a robust SFT framework (RobustFT) that performs noise detection and relabeling on downstream task data. For noise identification, our approach employs a multi-expert collaborative system with inference-enhanced models to achieve superior noise detection. In the denoising phase, we utilize a context-enhanced strategy, which incorporates the most relevant and confident knowledge followed by careful assessment to generate reliable annotations. Additionally, we introduce an effective data selection mechanism based on response entropy, ensuring only high-quality samples are retained for fine-tuning. Extensive experiments conducted on multiple LLMs across five datasets demonstrate RobustFT's exceptional performance in noisy scenarios.", 'abstract_zh': '监督微调（SFT）在适应大型语言模型（LLMs）到特定领域或任务方面起着至关重要的作用。然而，如实证实验所示，在实际应用中收集的数据不可避免地包含噪声，这对模型在下游任务中的性能构成了重大挑战。因此，迫切需要一种鲁棒的SFT框架来提高模型在下游任务中的能力。为此，我们介绍了一种鲁棒SFT框架（RobustFT），该框架在下游任务数据上进行噪声检测和重新标记。对于噪声识别，我们的方法采用了一个多专家协作系统，借助增强的推理模型来实现更优的噪声检测。在去噪阶段，我们利用一种基于上下文的策略，该策略结合了最相关且置信度高的知识，并经过仔细评估以生成可靠的注释。此外，我们引入了一种基于响应熵的有效数据选择机制，确保只有高质量的样本用于微调。在多个LLM上进行的跨越五个数据集的广泛实验表明，RobustFT在噪声场景下的性能尤为出色。', 'title_zh': 'RobustFT：在嘈杂响应情况下大型语言模型的鲁棒监督微调'}
{'arxiv_id': 'arXiv:2412.14905', 'title': 'Dehallucinating Parallel Context Extension for Retrieval-Augmented Generation', 'authors': 'Zexiong Ma, Shengnan An, Zeqi Lin, Yanzhen Zou, Jian-Guang Lou, Bing Xie', 'link': 'https://arxiv.org/abs/2412.14905', 'abstract': 'Large language models (LLMs) are susceptible to generating hallucinated information, despite the integration of retrieval-augmented generation (RAG). Parallel context extension (PCE) is a line of research attempting to effectively integrating parallel (unordered) contexts, while it still suffers from hallucinations when adapted to RAG scenarios. In this paper, we propose DePaC (Dehallucinating Parallel Context Extension), which alleviates the hallucination problem with context-aware negative training and information-calibrated aggregation. DePaC is designed to alleviate two types of in-context hallucination: fact fabrication (i.e., LLMs present claims that are not supported by the contexts) and fact omission (i.e., LLMs fail to present claims that can be supported by the contexts). Specifically, (1) for fact fabrication, we apply the context-aware negative training that fine-tunes the LLMs with negative supervisions, thus explicitly guiding the LLMs to refuse to answer when contexts are not related to questions; (2) for fact omission, we propose the information-calibrated aggregation which prioritizes context windows with higher information increment from their contexts. The experimental results on nine RAG tasks demonstrate that DePaC significantly alleviates the two types of hallucination and consistently achieves better performances on these tasks.', 'abstract_zh': '大规模语言模型（LLMs）在整合检索增强生成（RAG）后仍然容易生成虚假信息。平行上下文扩展（PCE）是一条旨在有效整合无序平行上下文的研究路线，但在适应RAG场景时仍然会遭受虚假信息的问题。本文提出了一种名为DePaC（Dehallucinating Parallel Context Extension）的方法，通过上下文感知的负样本训练和信息校准聚合来减轻虚假信息问题。DePaC 旨在缓解两种类型的上下文内虚假信息：事实捏造（即LLMs展示的断言没有得到上下文的支持）和事实遗漏（即LLMs未能展示能够由上下文支持的断言）。具体来说，（1）对于事实捏造，我们应用上下文感知的负样本训练，通过微调LLMs用负监督，从而明确引导LLMs在上下文与问题无关时拒绝作答；（2）对于事实遗漏，我们提出了信息校准聚合，优先考虑那些从其上下文中获得更高信息增量的上下文窗口。九个RAG任务的实验结果表明，DePaC 显著减轻了这两种类型的虚假信息，并在这些任务上始终取得了更好的性能。', 'title_zh': '去噪的并行上下文扩展用于检索增强生成'}
{'arxiv_id': 'arXiv:2412.14869', 'title': 'AI-Powered Intracranial Hemorrhage Detection: A Co-Scale Convolutional Attention Model with Uncertainty-Based Fuzzy Integral Operator and Feature Screening', 'authors': 'Mehdi Hosseini Chagahi, Md. Jalil Piran, Niloufar Delfan, Behzad Moshiri, Jaber Hatam Parikhan', 'link': 'https://arxiv.org/abs/2412.14869', 'abstract': 'Intracranial hemorrhage (ICH) refers to the leakage or accumulation of blood within the skull, which occurs due to the rupture of blood vessels in or around the brain. If this condition is not diagnosed in a timely manner and appropriately treated, it can lead to serious complications such as decreased consciousness, permanent neurological disabilities, or even this http URL primary aim of this study is to detect the occurrence or non-occurrence of ICH, followed by determining the type of subdural hemorrhage (SDH). These tasks are framed as two separate binary classification problems. By adding two layers to the co-scale convolutional attention (CCA) classifier architecture, we introduce a novel approach for ICH detection. In the first layer, after extracting features from different slices of computed tomography (CT) scan images, we combine these features and select the 50 components that capture the highest variance in the data, considering them as informative features. We then assess the discriminative power of these features using the bootstrap forest algorithm, discarding those that lack sufficient discriminative ability between different classes. This algorithm explicitly determines the contribution of each feature to the final prediction, assisting us in developing an explainable AI model. The features feed into a boosting neural network as a latent feature space. In the second layer, we introduce a novel uncertainty-based fuzzy integral operator to fuse information from different CT scan slices. This operator, by accounting for the dependencies between consecutive slices, significantly improves detection accuracy.', 'abstract_zh': '颅内出血（ICH）是指血液在颅骨内的泄漏或积聚，通常是由于大脑内或周围的血管破裂所致。如果未能及时诊断并适当治疗，可能会导致昏迷、永久性神经功能损伤，甚至死亡。本研究的主要目的是检测ICH的发生与否，并确定蛛网膜下腔出血（SDH）的类型。这些任务被构想为两个独立的二分类问题。通过在共尺度卷积注意力（CCA）分类器架构中添加两层，我们提出了一种新颖的ICH检测方法。在第一层中，首先从计算机断层扫描（CT）扫描图像的不同切片中提取特征，然后将这些特征结合起来，并选择能够捕捉数据中最高方差的50个部件，视为信息性特征。接着使用自助森林算法评估这些特征的判别能力，剔除那些在不同类别间判别能力不足的特征。该算法显式确定每个特征对最终预测的贡献，帮助我们开发出可解释的人工智能模型。特征随后输入到提升神经网络作为潜在特征空间。在第二层中，我们引入了一种基于不确定性的新模糊积分算子，用于从不同CT扫描切片中融合信息。该算子通过考虑连续切片之间的依赖性，显著提高了检测准确性。', 'title_zh': '基于AI的颅内出血检测：一种基于不确定性模糊积分运算器和特征筛选的共尺度卷积注意力模型'}
{'arxiv_id': 'arXiv:2412.14847', 'title': 'A Survey of RWKV', 'authors': 'Zhiyuan Li, Tingyu Xia, Yi Chang, Yuan Wu', 'link': 'https://arxiv.org/abs/2412.14847', 'abstract': 'The Receptance Weighted Key Value (RWKV) model offers a novel alternative to the Transformer architecture, merging the benefits of recurrent and attention-based systems. Unlike conventional Transformers, which depend heavily on self-attention, RWKV adeptly captures long-range dependencies with minimal computational demands. By utilizing a recurrent framework, RWKV addresses some computational inefficiencies found in Transformers, particularly in tasks with long sequences. RWKV has recently drawn considerable attention for its robust performance across multiple domains. Despite its growing popularity, no systematic review of the RWKV model exists. This paper seeks to fill this gap as the first comprehensive review of the RWKV architecture, its core principles, and its varied applications, such as natural language generation, natural language understanding, and computer vision. We assess how RWKV compares to traditional Transformer models, highlighting its capability to manage long sequences efficiently and lower computational costs. Furthermore, we explore the challenges RWKV encounters and propose potential directions for future research and advancement. We consistently maintain the related open-source materials at: this https URL.', 'abstract_zh': 'receptance 加权关键值 (RWKV) 模型提供了一种通往 Transformer 架构的新途径，结合了递归网络和基于注意力系统的优势。与依赖于自注意力的常规 Transformer 不同，RWKV 在保持较小计算需求的同时，能够有效地捕捉长距离依赖关系。通过利用递归框架，RWKV 解决了常规 Transformer 在处理长序列任务时的一些计算效率问题。RWKV 最近因其在多个领域的稳健表现而受到广泛关注。尽管其受欢迎程度日益增长，但目前尚无系统性的 RWKV 模型审查。本文旨在填补这一空白，作为第一篇全面回顾RWKV 架构、核心原理及其各种应用（如自然语言生成、自然语言理解和计算机视觉）的论文。我们评估了 RWKV 与传统 Transformer 模型的比较，强调了其在高效管理长序列和降低计算成本方面的能力。此外，我们探讨了 RWKV 所面临的挑战，并提出了未来研究和改进的方向。我们始终维护相关的开源材料：[此链接](this https URL)。', 'title_zh': 'RWKV概述'}
{'arxiv_id': 'arXiv:2412.14846', 'title': 'Head and Neck Tumor Segmentation of MRI from Pre- and Mid-radiotherapy with Pre-training, Data Augmentation and Dual Flow UNet', 'authors': 'Litingyu Wang, Wenjun Liao, Shichuan Zhang, Guotai Wang', 'link': 'https://arxiv.org/abs/2412.14846', 'abstract': 'Head and neck tumors and metastatic lymph nodes are crucial for treatment planning and prognostic analysis. Accurate segmentation and quantitative analysis of these structures require pixel-level annotation, making automated segmentation techniques essential for the diagnosis and treatment of head and neck cancer. In this study, we investigated the effects of multiple strategies on the segmentation of pre-radiotherapy (pre-RT) and mid-radiotherapy (mid-RT) images. For the segmentation of pre-RT images, we utilized: 1) a fully supervised learning approach, and 2) the same approach enhanced with pre-trained weights and the MixUp data augmentation technique. For mid-RT images, we introduced a novel computational-friendly network architecture that features separate encoders for mid-RT images and registered pre-RT images with their labels. The mid-RT encoder branch integrates information from pre-RT images and labels progressively during the forward propagation. We selected the highest-performing model from each fold and used their predictions to create an ensemble average for inference. In the final test, our models achieved a segmentation performance of 82.38% for pre-RT and 72.53% for mid-RT on aggregated Dice Similarity Coefficient (DSC) as HiLab. Our code is available at this https URL.', 'abstract_zh': '头部和颈部肿瘤及其转移性淋巴结对于治疗计划和预后分析至关重要。准确分割和定量分析这些结构需要像素级标注，因此自动化分割技术对于头部和颈部癌症的诊断和治疗至关重要。在本研究中，我们探讨了多种策略对预放疗（pre-RT）和中程放疗（mid-RT）图像分割的影响。对于预放疗图像的分割，我们采用了：1）完全监督学习方法；2）结合预训练权重和MixUp数据增强技术的改进方法。对于中程放疗图像，我们引入了一种新的计算友好型网络架构，该架构包括专门为中程放疗图像设计的编码器以及与标签注册的预放疗图像编码器。中程放疗编码器分支在前向传播过程中逐步整合来自预放疗图像和标签的信息。我们从每一轮次中选择性能最佳的模型，并使用它们的预测结果进行集成平均以进行推断。在最终测试中，我们的模型在HiLab汇总Dice相似度系数（DSC）上的分割性能分别为预放疗图像82.38%，中程放疗图像72.53%。我们的代码可在以下链接访问：[此处提供链接]。', 'title_zh': '术前和中期放疗的MRI头部和颈部肿瘤分割：预训练、数据增强和双重流动UNet模型'}
{'arxiv_id': 'arXiv:2412.14843', 'title': 'Mapping and Influencing the Political Ideology of Large Language Models using Synthetic Personas', 'authors': 'Pietro Bernardelle, Leon Fröhling, Stefano Civelli, Riccardo Lunardi, Kevin Roiter, Gianluca Demartini', 'link': 'https://arxiv.org/abs/2412.14843', 'abstract': "The analysis of political biases in large language models (LLMs) has primarily examined these systems as single entities with fixed viewpoints. While various methods exist for measuring such biases, the impact of persona-based prompting on LLMs' political orientation remains unexplored. In this work we leverage PersonaHub, a collection of synthetic persona descriptions, to map the political distribution of persona-based prompted LLMs using the Political Compass Test (PCT). We then examine whether these initial compass distributions can be manipulated through explicit ideological prompting towards diametrically opposed political orientations: right-authoritarian and left-libertarian. Our experiments reveal that synthetic personas predominantly cluster in the left-libertarian quadrant, with models demonstrating varying degrees of responsiveness when prompted with explicit ideological descriptors. While all models demonstrate significant shifts towards right-authoritarian positions, they exhibit more limited shifts towards left-libertarian positions, suggesting an asymmetric response to ideological manipulation that may reflect inherent biases in model training.", 'abstract_zh': '对大型语言模型（LLMs）中的政治偏见进行分析主要将这些系统视为单一的、具有固定观点的实体。虽然存在多种测量此类偏见的方法，但基于人设（Persona）的提示对LLMs政治倾向的影响尚未被探索。在本项研究中，我们利用PersonaHub，一个合成人设描述的集合，结合政界定位测试（PCT）来映射基于人设提示的LLMs的政治分布。随后，我们考察了这些初始定向是否可以通过明确的政治意识形态提示，被操纵至完全相对的政治倾向：右翼集权和左翼自由主义。我们的实验表明，合成人设主要聚集在左翼自由主义象限中，当用明确的政治意识形态描述进行提示时，模型表现出不同程度的响应。虽然所有模型在右翼集权立场上都表现出显著转变，但在左翼自由主义立场上表现出更有限的转变，这表明对意识形态操纵的不对称响应可能反映了模型训练中的固有偏见。', 'title_zh': '使用合成角色映射和影响大型语言模型的政治意识形态'}
{'arxiv_id': 'arXiv:2412.14841', 'title': 'Helping LLMs Improve Code Generation Using Feedback from Testing and Static Analysis', 'authors': 'Greta Dolcetti, Vincenzo Arceri, Eleonora Iotti, Sergio Maffeis, Agostino Cortesi, Enea Zaffanella', 'link': 'https://arxiv.org/abs/2412.14841', 'abstract': 'Large Language Models (LLMs) are one of the most promising developments in the field of artificial intelligence, and the software engineering community has readily noticed their potential role in the software development life-cycle. Developers routinely ask LLMs to generate code snippets, increasing productivity but also potentially introducing ownership, privacy, correctness, and security issues. Previous work highlighted how code generated by mainstream commercial LLMs is often not safe, containing vulnerabilities, bugs, and code smells. In this paper, we present a framework that leverages testing and static analysis to assess the quality, and guide the self-improvement, of code generated by general-purpose, open-source LLMs.\nFirst, we ask LLMs to generate C code to solve a number of programming tasks. Then we employ ground-truth tests to assess the (in)correctness of the generated code, and a static analysis tool to detect potential safety vulnerabilities. Next, we assess the models ability to evaluate the generated code, by asking them to detect errors and vulnerabilities. Finally, we test the models ability to fix the generated code, providing the reports produced during the static analysis and incorrectness evaluation phases as feedback.\nOur results show that models often produce incorrect code, and that the generated code can include safety issues. Moreover, they perform very poorly at detecting either issue. On the positive side, we observe a substantial ability to fix flawed code when provided with information about failed tests or potential vulnerabilities, indicating a promising avenue for improving the safety of LLM-based code generation tools.', 'abstract_zh': '大型语言模型（LLMs）是人工智能领域最具前景的发展之一，软件工程社区也迅速认识到它们在软件开发生命周期中的潜在作用。开发人员经常要求LLMs生成代码片段，从而提高生产力，但也可能引入所有权、隐私、准确性和安全性方面的问题。先前的研究强调，主流商业LLMs生成的代码往往不安全，包含漏洞、错误和代码异味。在这篇论文中，我们提出了一种框架，利用测试和静态分析来评估由通用开源LLMs生成的代码的质量，并引导这些代码的自我改进。\n\n首先，我们要求LLMs生成C代码以解决多个编程任务。然后，我们使用正式测试来评估生成代码的（不）正确性，并使用静态分析工具检测潜在的安全漏洞。接下来，我们评估模型评估生成代码的能力，即要求它们检测错误和漏洞。最后，我们测试模型修正生成代码的能力，提供在静态分析和不正确性评估阶段产生的报告作为反馈。\n\n我们的结果表明，模型常常生成不正确的代码，并且生成的代码中可能存在安全问题。此外，它们在检测这两种问题方面表现得很差。不过，当我们提供关于测试失败或潜在漏洞的信息时，观察到模型具有显著的纠错能力，这为提高基于LLM的代码生成工具的安全性提供了一个有希望的方向。', 'title_zh': '利用测试和静态分析反馈提高大语言模型的代码生成能力'}
{'arxiv_id': 'arXiv:2412.14835', 'title': 'Progressive Multimodal Reasoning via Active Retrieval', 'authors': 'Guanting Dong, Chenghao Zhang, Mengjie Deng, Yutao Zhu, Zhicheng Dou, Ji-Rong Wen', 'link': 'https://arxiv.org/abs/2412.14835', 'abstract': 'Multi-step multimodal reasoning tasks pose significant challenges for multimodal large language models (MLLMs), and finding effective ways to enhance their performance in such scenarios remains an unresolved issue. In this paper, we propose AR-MCTS, a universal framework designed to progressively improve the reasoning capabilities of MLLMs through Active Retrieval (AR) and Monte Carlo Tree Search (MCTS). Our approach begins with the development of a unified retrieval module that retrieves key supporting insights for solving complex reasoning problems from a hybrid-modal retrieval corpus. To bridge the gap in automated multimodal reasoning verification, we employ the MCTS algorithm combined with an active retrieval mechanism, which enables the automatic generation of step-wise annotations. This strategy dynamically retrieves key insights for each reasoning step, moving beyond traditional beam search sampling to improve the diversity and reliability of the reasoning space. Additionally, we introduce a process reward model that aligns progressively to support the automatic verification of multimodal reasoning tasks. Experimental results across three complex multimodal reasoning benchmarks confirm the effectiveness of the AR-MCTS framework in enhancing the performance of various multimodal models. Further analysis demonstrates that AR-MCTS can optimize sampling diversity and accuracy, yielding reliable multimodal reasoning.', 'abstract_zh': '多步多模态推理任务对多模态大语言模型（MLLMs）提出了显著的挑战，如何在这种情境下有效提升其性能仍然是一个未解决的问题。本文提出了一种名为AR-MCTS的通用框架，旨在通过主动检索（AR）和蒙特卡洛树搜索（MCTS）逐步提高MLLMs的推理能力。我们的方法首先开发了一个统一的检索模块，从混合模态检索语料库中检索解决复杂推理问题的关键支持见解。为了解决自动多模态推理验证中的差距，我们采用了结合主动检索机制的MCTS算法，这使得可以自动生成逐步标注。该策略动态检索每个推理步骤的关键见解，超越了传统的束搜索采样方法，以提高推理空间的多样性和可靠性。此外，我们引入了一个过程奖励模型，以逐步支持多模态推理任务的自动验证。在三个复杂的多模态推理基准上的实验结果证实了AR-MCTS框架在提升各种多模态模型性能方面的有效性。进一步的分析表明，AR-MCTS能够优化采样多样性和准确性，从而实现可靠的多模态推理。', 'title_zh': '基于主动检索的 progressive 多模态推理'}
{'arxiv_id': 'arXiv:2412.14810', 'title': 'MARIA: a Multimodal Transformer Model for Incomplete Healthcare Data', 'authors': 'Camillo Maria Caruso, Paolo Soda, Valerio Guarrasi', 'link': 'https://arxiv.org/abs/2412.14810', 'abstract': 'In healthcare, the integration of multimodal data is pivotal for developing comprehensive diagnostic and predictive models. However, managing missing data remains a significant challenge in real-world applications. We introduce MARIA (Multimodal Attention Resilient to Incomplete datA), a novel transformer-based deep learning model designed to address these challenges through an intermediate fusion strategy. Unlike conventional approaches that depend on imputation, MARIA utilizes a masked self-attention mechanism, which processes only the available data without generating synthetic values. This approach enables it to effectively handle incomplete datasets, enhancing robustness and minimizing biases introduced by imputation methods. We evaluated MARIA against 10 state-of-the-art machine learning and deep learning models across 8 diagnostic and prognostic tasks. The results demonstrate that MARIA outperforms existing methods in terms of performance and resilience to varying levels of data incompleteness, underscoring its potential for critical healthcare applications.', 'abstract_zh': '在医疗保健领域，多模态数据的整合对于开发综合诊断和预测模型至关重要。然而，在实际应用中管理缺失数据依然是一个重大挑战。我们提出了一种名为MARIA（Multimodal Attention Resilient to Incomplete datA）的新型基于转换器的深度学习模型，通过中间融合策略来应对这些挑战。不同于依赖插补的传统方法，MARIA利用遮蔽自注意力机制，仅处理可用数据而不生成合成值。这种方法使其能够有效地处理不完整数据集，增强其鲁棒性并减少由插补方法引入的偏见。我们评估了MARIA在8项诊断和预后任务中与10种最先进的机器学习和深度学习模型的性能。结果表明，MARIA在性能和对不同数据不完整性水平的鲁棒性方面均优于现有方法，突显了其在关键医疗保健应用程序中的潜力。', 'title_zh': 'MARIA：一种用于不完整医疗数据的多模态变压器模型'}
{'arxiv_id': 'arXiv:2412.14802', 'title': 'Stack Trace Deduplication: Faster, More Accurately, and in More Realistic Scenarios', 'authors': 'Egor Shibaev, Denis Sushentsev, Yaroslav Golubev, Aleksandr Khvorov', 'link': 'https://arxiv.org/abs/2412.14802', 'abstract': 'In large-scale software systems, there are often no fully-fledged bug reports with human-written descriptions when an error occurs. In this case, developers rely on stack traces, i.e., series of function calls that led to the error. Since there can be tens and hundreds of thousands of them describing the same issue from different users, automatic deduplication into categories is necessary to allow for processing. Recent works have proposed powerful deep learning-based approaches for this, but they are evaluated and compared in isolation from real-life workflows, and it is not clear whether they will actually work well at scale.\nTo overcome this gap, this work presents three main contributions: a novel model, an industry-based dataset, and a multi-faceted evaluation. Our model consists of two parts - (1) an embedding model with byte-pair encoding and approximate nearest neighbor search to quickly find the most relevant stack traces to the incoming one, and (2) a reranker that re-ranks the most fitting stack traces, taking into account the repeated frames between them. To complement the existing datasets collected from open-source projects, we share with the community SlowOps - a dataset of stack traces from IntelliJ-based products developed by JetBrains, which has an order of magnitude more stack traces per category. Finally, we carry out an evaluation that strives to be realistic: measuring not only the accuracy of categorization, but also the operation time and the ability to create new categories. The evaluation shows that our model strikes a good balance - it outperforms other models on both open-source datasets and SlowOps, while also being faster on time than most. We release all of our code and data, and hope that our work can pave the way to further practice-oriented research in the area.', 'abstract_zh': '在大规模软件系统中，当发生错误时，往往缺乏完整的人工编写描述的bug报告。在这种情况下，开发人员依赖于堆栈跟踪，即导致错误的一系列函数调用。由于从不同用户可以收集到成千上万条描述相同问题的堆栈跟踪信息，因此需要进行自动分组以归类整理，从而便于后续处理。最近已有研究提出了基于深度学习的强大方法来实现这一点，但这些方法在现实工作流程中并未进行测试和比较，因此尚不清楚它们是否能够在大规模应用中表现出色。\n\n为弥补这一差距，本研究提出了三项主要贡献：一种新的模型、一个基于工业界的数据库集和一个多维度的评估方法。我们的模型由两个部分组成：（1）一个使用字节对编码和近似最近邻搜索的嵌入模型，用于快速找到与最新堆栈跟踪相关的最相关堆栈跟踪；（2）一个重新排序器，用于重新对最匹配的堆栈跟踪进行排名，同时考虑它们之间的重复帧。为了补充现有的来自开源项目的数据集，我们与社区分享了一个新的数据集——SlowOps，它是JetBrains开发的基于IntelliJ的产品堆栈跟踪数据集，每个类别中的堆栈跟踪数量是现有数据集的十倍以上。最后，我们进行了一项旨在模拟现实情况的评估：不仅衡量分类的准确性，还评估了操作时间和创建新类别能力。评估结果表明，我们的模型在平衡效果上表现良好——它在开源数据集和SlowOps上都优于其他模型，同时在操作速度上也快于大多数模型。我们公开了所有代码和数据，并希望我们的研究能够为该领域的进一步实践导向性研究铺平道路。', 'title_zh': '堆栈跟踪去重：更快、更准确、并在更多现实场景中实现'}
{'arxiv_id': 'arXiv:2412.14779', 'title': 'Agent-Temporal Credit Assignment for Optimal Policy Preservation in Sparse Multi-Agent Reinforcement Learning', 'authors': 'Aditya Kapoor, Sushant Swamy, Kale-ab Tessera, Mayank Baranwal, Mingfei Sun, Harshad Khadilkar, Stefano V. Albrecht', 'link': 'https://arxiv.org/abs/2412.14779', 'abstract': 'In multi-agent environments, agents often struggle to learn optimal policies due to sparse or delayed global rewards, particularly in long-horizon tasks where it is challenging to evaluate actions at intermediate time steps. We introduce Temporal-Agent Reward Redistribution (TAR$^2$), a novel approach designed to address the agent-temporal credit assignment problem by redistributing sparse rewards both temporally and across agents. TAR$^2$ decomposes sparse global rewards into time-step-specific rewards and calculates agent-specific contributions to these rewards. We theoretically prove that TAR$^2$ is equivalent to potential-based reward shaping, ensuring that the optimal policy remains unchanged. Empirical results demonstrate that TAR$^2$ stabilizes and accelerates the learning process. Additionally, we show that when TAR$^2$ is integrated with single-agent reinforcement learning algorithms, it performs as well as or better than traditional multi-agent reinforcement learning methods.', 'abstract_zh': '在多智能体环境中，智能体往往难以学习到最优策略，特别是在由于稀疏或延迟的全局奖励而难以评估中间时间步的行动时尤为明显。特别是在长期任务中，评估中间时间步的行动尤为具有挑战性。为此，我们提出了一种名为Temporal-Agent Reward Redistribution (TAR$^2$)的新方法，旨在通过在时间和智能体之间重新分配稀疏奖励来解决智能体时间性信用分配问题。TAR$^2$将稀疏的全局奖励分解为时间步特定的奖励，并计算这些奖励的智能体特定贡献。我们从理论上证明了TAR$^2$等同于基于潜能的奖励塑形方法，确保最优策略不会发生变化。实验证明TAR$^2$能够稳定并加速学习过程。此外，我们还展示了当将TAR$^2$与单智能体强化学习算法结合使用时，其性能与传统的多智能体强化学习方法相当甚至更优。', 'title_zh': '基于代理-时间信用分配的理想政策 Preservation 在稀疏多代理强化学习中的优化'}
{'arxiv_id': 'arXiv:2412.14775', 'title': 'Energy and polarization based on-line interference mitigation in radio interferometry', 'authors': 'Sarod Yatawatta, Albert-Jan Boonstra, Chris P. Broekema', 'link': 'https://arxiv.org/abs/2412.14775', 'abstract': 'Radio frequency interference (RFI) is a persistent contaminant in terrestrial radio astronomy. While new radio interferometers are becoming operational, novel sources of RFI are also emerging. In order to strengthen the mitigation of RFI in modern radio interferometers, we propose an on-line RFI mitigation scheme that can be run in the correlator of such interferometers. We combine statistics based on the energy as well as the polarization alignment of the correlated signal to develop an on-line RFI mitigation scheme that can be applied to a data stream produced by the correlator in real-time, especially targeted at low duty-cycle or transient RFI detection. In order to improve the computational efficiency, we explore the use of both single precision and half precision floating point operations in implementing the RFI mitigation algorithm. This ideally suits its deployment in accelerator computing devices such as graphics processing units (GPUs) as used by the LOFAR correlator. We provide results based on real data to demonstrate the efficacy of the proposed method.', 'abstract_zh': '无线电频率干扰（RFI）一直是地面射电天文观测中的一个持续存在的污染源。随着新型射电干涉仪的投入运行，新的RFI源也在不断出现。为了增强现代射电干涉仪中的RFI减轻措施，我们提出了一种在线RFI减轻方案，该方案可以在这些干涉仪的关联器中运行。我们结合关联信号的能量统计和偏振对齐统计，开发了一种在线RFI减轻方案，可以在关联器产生的数据流中实时应用，特别适用于低占空比或瞬态RFI的检测。为了提高计算效率，我们探索了在实现RFI减轻算法时使用单精度和半精度浮点运算的可能性。这种做法非常适合在如LOFAR关联器所采用的图形处理单元（GPUs）等加速计算设备中部署。我们基于实际数据提供了结果，证明了所提出方法的有效性。', 'title_zh': '基于能量和极化在线干扰减轻的射电干涉ometry方法'}
{'arxiv_id': 'arXiv:2412.14771', 'title': 'ALKAFI-LLAMA3: Fine-Tuning LLMs for Precise Legal Understanding in Palestine', 'authors': 'Rabee Qasem, Mohannad Hendi, Banan Tantour', 'link': 'https://arxiv.org/abs/2412.14771', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable potential in diverse domains, yet their application in the legal sector, particularly in low-resource contexts, remains limited. This study addresses the challenges of adapting LLMs to the Palestinian legal domain, where political instability, fragmented legal frameworks, and limited AI resources hinder effective machine-learning applications. We present a fine-tuned model based on a quantized version of Llama-3.2-1B-Instruct, trained on a synthetic data set derived from Palestinian legal texts. Using smaller-scale models and strategically generated question-answer pairs, we achieve a cost-effective, locally sustainable solution that provides accurate and contextually relevant legal guidance. Our experiments demonstrate promising performance on various query types, ranging from yes/no questions and narrative explanations to complex legal differentiations, while highlighting areas for improvement, such as handling calculation-based inquiries and structured list formatting. This work provides a pathway for the deployment of AI-driven legal assistance tools tailored to the needs of resource-constrained environments.', 'abstract_zh': '大型语言模型（LLMs）在多个领域中已经展示了卓越的潜力，但在法律领域尤其是低资源环境下应用仍然有限。本研究针对将LLMs适应到巴勒斯坦法律领域所面临的挑战展开探讨，该领域因政治不稳定、法律体系碎片化及人工智能资源匮乏而面临有效的机器学习应用难题。我们基于精简版本的Llama-3.2-1B-Instruct模型进行了微调，并据此对巴勒斯坦法律文本生成了合成数据集。利用小型化模型和策略性生成的问题-答案对，我们实现了一种经济高效、本地可持续的解决方案，能够提供准确且相关性高的法律指导。实验结果表明，该模型在各种查询类型上表现出了良好的性能，涵盖从是/否问题和叙述性解释到复杂法律分类等多种情境，同时也指出了改进的方向，例如处理基于计算的查询和结构化列表格式化。本研究为在资源受限环境中部署基于AI的法律辅助工具提供了可行路径。', 'title_zh': 'ALKAFI-LLAMA3：针对巴勒斯坦精确法律理解的LLM微调'}
{'arxiv_id': 'arXiv:2412.14764', 'title': 'CodeRepoQA: A Large-scale Benchmark for Software Engineering Question Answering', 'authors': 'Ruida Hu, Chao Peng, Jingyi Ren, Bo Jiang, Xiangxin Meng, Qinyun Wu, Pengfei Gao, Xinchen Wang, Cuiyun Gao', 'link': 'https://arxiv.org/abs/2412.14764', 'abstract': "In this work, we introduce CodeRepoQA, a large-scale benchmark specifically designed for evaluating repository-level question-answering capabilities in the field of software engineering. CodeRepoQA encompasses five programming languages and covers a wide range of scenarios, enabling comprehensive evaluation of language models. To construct this dataset, we crawl data from 30 well-known repositories in GitHub, the largest platform for hosting and collaborating on code, and carefully filter raw data. In total, CodeRepoQA is a multi-turn question-answering benchmark with 585,687 entries, covering a diverse array of software engineering scenarios, with an average of 6.62 dialogue turns per entry.\nWe evaluate ten popular large language models on our dataset and provide in-depth analysis. We find that LLMs still have limitations in question-answering capabilities in the field of software engineering, and medium-length contexts are more conducive to LLMs' performance. The entire benchmark is publicly available at this https URL.", 'abstract_zh': '在本文中，我们介绍了CodeRepoQA，这是一个大规模基准测试平台，专门用于评估软件工程领域仓库级问题解答能力。CodeRepoQA 包含五种编程语言，并涵盖了广泛的情景，能够全面评估语言模型。为了构建这个数据集，我们从 GitHub（最大的代码托管与协作平台）中的30个知名仓库中抓取数据，并仔细筛选原始数据。总计，CodeRepoQA 是一个包含585,687条条目的多轮对话基准测试，涵盖了多种软件工程情景，平均每条条目包含6.62个对话轮次。\n\n我们在该数据集上评估了十个流行的大型语言模型，并进行了深入分析。我们发现，大型语言模型在软件工程领域的问题解答能力仍然存在局限性，中等长度的上下文更有利于提高大型语言模型的性能。整个基准测试平台已在此处公开：[提供链接]。', 'title_zh': 'CodeRepoQA：软件工程问题回答的大规模基准'}
{'arxiv_id': 'arXiv:2412.14736', 'title': 'Advances in Artificial Intelligence forDiabetes Prediction: Insights from a Systematic Literature Review', 'authors': 'Pir Bakhsh Khokhar, Carmine Gravino, Fabio Palomba', 'link': 'https://arxiv.org/abs/2412.14736', 'abstract': 'This systematic review explores the use of machine learning (ML) in predicting diabetes, focusing on datasets, algorithms, training methods, and evaluation metrics. It examines datasets like the Singapore National Diabetic Retinopathy Screening program, REPLACE-BG, National Health and Nutrition Examination Survey, and Pima Indians Diabetes Database. The review assesses the performance of ML algorithms like CNN, SVM, Logistic Regression, and XGBoost in predicting diabetes outcomes. The study emphasizes the importance of interdisciplinary collaboration and ethical considerations in ML-based diabetes prediction models.', 'abstract_zh': '本文系统综述探讨了机器学习（ML）在预测糖尿病中的应用，重点研究了数据集、算法、训练方法和评估指标。该综述检查了如新加坡国家糖尿病视网膜筛查计划、REPLACE-BG、全国健康与营养评估调查以及普亚玛印第安人糖尿病数据库等数据集。该研究评估了CNN、SVM、逻辑回归和XGBoost等机器学习算法在预测糖尿病结果方面的性能。研究强调了在基于机器学习的糖尿病预测模型中进行跨学科合作和伦理考虑的重要性。', 'title_zh': '基于系统文献综述的人工智能在糖尿病预测中的进展：洞察摘要'}
{'arxiv_id': 'arXiv:2412.14732', 'title': 'Beyond the Hype: A Comprehensive Review of Current Trends in Generative AI Research, Teaching Practices, and Tools', 'authors': 'James Prather, Juho Leinonen, Natalie Kiesler, Jamie Gorson Benario, Sam Lau, Stephen MacNeil, Narges Norouzi, Simone Opel, Vee Pettit, Leo Porter, Brent N. Reeves, Jaromir Savelka, David H. Smith IV, Sven Strickroth, Daniel Zingaro', 'link': 'https://arxiv.org/abs/2412.14732', 'abstract': 'Generative AI (GenAI) is advancing rapidly, and the literature in computing education is expanding almost as quickly. Initial responses to GenAI tools were mixed between panic and utopian optimism. Many were fast to point out the opportunities and challenges of GenAI. Researchers reported that these new tools are capable of solving most introductory programming tasks and are causing disruptions throughout the curriculum. These tools can write and explain code, enhance error messages, create resources for instructors, and even provide feedback and help for students like a traditional teaching assistant. In 2024, new research started to emerge on the effects of GenAI usage in the computing classroom. These new data involve the use of GenAI to support classroom instruction at scale and to teach students how to code with GenAI. In support of the former, a new class of tools is emerging that can provide personalized feedback to students on their programming assignments or teach both programming and prompting skills at the same time. With the literature expanding so rapidly, this report aims to summarize and explain what is happening on the ground in computing classrooms. We provide a systematic literature review; a survey of educators and industry professionals; and interviews with educators using GenAI in their courses, educators studying GenAI, and researchers who create GenAI tools to support computing education. The triangulation of these methods and data sources expands the understanding of GenAI usage and perceptions at this critical moment for our community.', 'abstract_zh': '生成式人工智能（GenAI）的进步非常迅速，计算教育领域的相关文献也在迅速扩展。最初对GenAI工具的反应多种多样，既有恐慌情绪也有乌托邦式的乐观态度。许多研究者迅速指出了GenAI的机会与挑战。研究人员报告称，这些新工具能够解决大多数入门级编程任务，并在整个课程中引发颠覆性变化。它们可以编写和解释代码、提升错误信息、为教师创作资源，甚至像传统的辅导员一样为学生提供反馈和帮助。\n\n2024年，关于GenAI在计算课堂中的应用影响的新研究开始涌现。这些新数据涉及使用GenAI支持大规模课堂教学以及教授学生如何使用GenAI编程。为了支持前者，一种新的工具类别正在出现，可以为学生的编程作业提供个性化反馈，或者同时教授编程和提示技能。鉴于文献扩展的速度如此之快，本报告旨在总结并解释计算课堂中正在发生的情况。我们提供了系统性的文献综述、教育工作者和行业专业人士的问卷调查，并采访了正在课程中使用GenAI的教育工作者、研究GenAI的教育工作者以及创建支持计算教育的GenAI工具的研究人员。这些方法和数据来源的三角验证，对于我们社区的关键时刻来说，扩展了对GenAI使用及其感知的理解。', 'title_zh': '超越 hype：对当前生成式人工智能研究、教学实践及工具的全面回顾'}
{'arxiv_id': 'arXiv:2412.14689', 'title': 'How to Synthesize Text Data without Model Collapse?', 'authors': 'Xuekai Zhu, Daixuan Cheng, Hengli Li, Kaiyan Zhang, Ermo Hua, Xingtai Lv, Ning Ding, Zhouhan Lin, Zilong Zheng, Bowen Zhou', 'link': 'https://arxiv.org/abs/2412.14689', 'abstract': 'Model collapse in synthetic data indicates that iterative training on self-generated data leads to a gradual decline in performance. With the proliferation of AI models, synthetic data will fundamentally reshape the web data ecosystem. Future GPT-$\\{n\\}$ models will inevitably be trained on a blend of synthetic and human-produced data. In this paper, we focus on two questions: what is the impact of synthetic data on language model training, and how to synthesize data without model collapse? We first pre-train language models across different proportions of synthetic data, revealing a negative correlation between the proportion of synthetic data and model performance. We further conduct statistical analysis on synthetic data to uncover distributional shift phenomenon and over-concentration of n-gram features. Inspired by the above findings, we propose token editing on human-produced data to obtain semi-synthetic data. As a proof of concept, we theoretically demonstrate that token-level editing can prevent model collapse, as the test error is constrained by a finite upper bound. We conduct extensive experiments on pre-training from scratch, continual pre-training, and supervised fine-tuning. The results validate our theoretical proof that token-level editing improves data quality and enhances model performance.', 'abstract_zh': '合成数据中的模型塌陷表明，迭代训练于自动生成的数据会导致模型性能逐渐下降。随着人工智能模型的数量激增，合成数据将从根本上重塑网络数据生态系统。未来的GPT-$\\{n\\}$模型不可避免地会在合成数据与人类生成的数据混合训练。在本文中，我们关注两个问题：合成数据对语言模型训练的影响是什么？如何合成数据而不导致模型塌陷？我们首先对不同比例的合成数据进行了预训练，发现合成数据的比例与模型性能之间存在负相关关系。为进一步分析合成数据，我们进行了统计分析，揭示了分布偏移现象和n-克gram特征的过度集中。受上述发现的启发，我们提出在人类生成的数据上进行标记编辑，以获得半合成数据。作为概念证明，我们从理论上证明，标记级别的编辑可以防止模型塌陷，因为在测试误差上有有限的上限。我们进行了从头预训练、持续预训练和监督微调等广泛的实验。实验结果验证了我们理论证明的观点，即标记级别的编辑可以提高数据质量并增强模型性能。', 'title_zh': '如何在不发生模型坍塌的情况下合成文本数据？'}
{'arxiv_id': 'arXiv:2412.14686', 'title': 'Each Fake News is Fake in its Own Way: An Attribution Multi-Granularity Benchmark for Multimodal Fake News Detection', 'authors': 'Hao Guo, Zihan Ma, Zhi Zeng, Minnan Luo, Weixin Zeng, Jiuyang Tang, Xiang Zhao', 'link': 'https://arxiv.org/abs/2412.14686', 'abstract': 'Social platforms, while facilitating access to information, have also become saturated with a plethora of fake news, resulting in negative consequences. Automatic multimodal fake news detection is a worthwhile pursuit. Existing multimodal fake news datasets only provide binary labels of real or fake. However, real news is alike, while each fake news is fake in its own way. These datasets fail to reflect the mixed nature of various types of multimodal fake news. To bridge the gap, we construct an attributing multi-granularity multimodal fake news detection dataset \\amg, revealing the inherent fake pattern. Furthermore, we propose a multi-granularity clue alignment model \\our to achieve multimodal fake news detection and attribution. Experimental results demonstrate that \\amg is a challenging dataset, and its attribution setting opens up new avenues for future research.', 'abstract_zh': '社交媒体平台虽然促进了信息的获取，但也充斥着大量的假新闻，导致了一系列负面影响。自动多模态假新闻检测是一个值得追求的目标。现有的多模态假新闻数据集仅提供了真实或假的二元标签。然而，真实新闻虽然相似，但每条假新闻都有自己独特的假造方式。这些数据集未能反映各种多模态假新闻混合的本质特征。为弥补这一不足，我们构建了一个具有属性和多粒度的多模态假新闻检测数据集（AMG），揭示了内置的假造模式。此外，我们提出了一种多粒度线索对齐模型（Our）以实现多模态假新闻的检测和归因。实验结果表明，AMG是一个具有挑战性的数据集，其归因设置为未来研究开辟了新的途径。', 'title_zh': '每篇假新闻都有其自身的虚假之处：一种多模态假新闻检测的归因多粒度基准'}
{'arxiv_id': 'arXiv:2412.14680', 'title': 'A Light-Weight Framework for Open-Set Object Detection with Decoupled Feature Alignment in Joint Space', 'authors': 'Yonghao He, Hu Su, Haiyong Yu, Cong Yang, Wei Sui, Cong Wang, Song Liu', 'link': 'https://arxiv.org/abs/2412.14680', 'abstract': 'Open-set object detection (OSOD) is highly desirable for robotic manipulation in unstructured environments. However, existing OSOD methods often fail to meet the requirements of robotic applications due to their high computational burden and complex deployment. To address this issue, this paper proposes a light-weight framework called Decoupled OSOD (DOSOD), which is a practical and highly efficient solution to support real-time OSOD tasks in robotic systems. Specifically, DOSOD builds upon the YOLO-World pipeline by integrating a vision-language model (VLM) with a detector. A Multilayer Perceptron (MLP) adaptor is developed to transform text embeddings extracted by the VLM into a joint space, within which the detector learns the region representations of class-agnostic proposals. Cross-modality features are directly aligned in the joint space, avoiding the complex feature interactions and thereby improving computational efficiency. DOSOD operates like a traditional closed-set detector during the testing phase, effectively bridging the gap between closed-set and open-set detection. Compared to the baseline YOLO-World, the proposed DOSOD significantly enhances real-time performance while maintaining comparable accuracy. The slight DOSOD-S model achieves a Fixed AP of $26.7\\%$, compared to $26.2\\%$ for YOLO-World-v1-S and $22.7\\%$ for YOLO-World-v2-S, using similar backbones on the LVIS minival dataset. Meanwhile, the FPS of DOSOD-S is $57.1\\%$ higher than YOLO-World-v1-S and $29.6\\%$ higher than YOLO-World-v2-S. Meanwhile, we demonstrate that the DOSOD model facilitates the deployment of edge devices. The codes and models are publicly available at this https URL.', 'abstract_zh': '开放集目标检测（Open-set Object Detection, OSOD）在未结构化环境中机器人的操作中具有很高的应用价值。然而，现有的OSOD方法由于计算负担重和部署复杂而往往无法满足机器人的应用需求。为了解决这一问题，本文提出了一种轻量级框架——拆分OSOD（Decoupled Open-set Object Detection, DOSOD），这是一种实用且高效的解决方案，能够支持机器人系统中的实时OSOD任务。具体来说，DOSOD基于YOLO-World管道，通过整合视觉语言模型（VLM）和检测器来构建。开发了一种多层感知器（MLP）适配器，以将VLM提取的文本嵌入转换到一个联合空间中，在该空间中，检测器学习泛化类的区域表示。跨模态特征在联合空间中直接对齐，避免了复杂的特征交互，从而提高了计算效率。在测试阶段，DOSOD类似于传统的封闭集检测器，有效地弥合了封闭集和开放集检测之间的差距。相较于baseline YOLO-World，提出的DOSOD显著提升了实时性能，而保持了相似的准确性。DOSOD-S模型在LVIS minival数据集上使用相似骨干网络时，固定平均精度（Fixed AP）达到26.7%，而YOLO-World-v1-S和YOLO-World-v2-S分别为26.2%和22.7%。同时，DOSOD-S的每秒帧数（FPS）比YOLO-World-v1-S高出57.1%，比YOLO-World-v2-S高出29.6%。此外，我们还证明了DOSOD模型有助于边缘设备的部署。相关代码和模型已公开发布在以下链接：this https URL。', 'title_zh': '面向联合空间解耦特征对齐的开集物体检测轻量级框架'}
{'arxiv_id': 'arXiv:2412.14672', 'title': 'FiVL: A Framework for Improved Vision-Language Alignment', 'authors': 'Estelle Aflalo, Gabriela Ben Melech Stan, Tiep Le, Man Luo, Shachar Rosenman, Sayak Paul, Shao-Yen Tseng, Vasudev Lal', 'link': 'https://arxiv.org/abs/2412.14672', 'abstract': "Large Vision Language Models (LVLMs) have achieved significant progress in integrating visual and textual inputs for multimodal reasoning. However, a recurring challenge is ensuring these models utilize visual information as effectively as linguistic content when both modalities are necessary to formulate an accurate answer. We hypothesize that hallucinations arise due to the lack of effective visual grounding in current LVLMs. This issue extends to vision-language benchmarks, where it is difficult to make the image indispensable for accurate answer generation, particularly in vision question-answering tasks. In this work, we introduce FiVL, a novel method for constructing datasets designed to train LVLMs for enhanced visual grounding and to evaluate their effectiveness in achieving it. These datasets can be utilized for both training and assessing an LVLM's ability to use image content as substantive evidence rather than relying solely on linguistic priors, providing insights into the model's reliance on visual information. To demonstrate the utility of our dataset, we introduce an innovative training task that outperforms baselines alongside a validation method and application for explainability. The code is available at this https URL.", 'abstract_zh': '大规模视觉语言模型（Large Vision Language Models, LVLMs）在融合视觉和文本输入以进行多模态推理方面取得了显著进展。然而，一个反复出现的挑战是如何确保这些模型在需要结合两种模态信息以形成准确答案时，能够充分利用视觉信息，与语言内容同等重要。我们假设幻觉现象是由于当前LVLMs缺乏有效的视觉定位所导致。这个问题扩展到了视觉语言基准数据集，其中很难使图像成为生成准确答案不可缺少的部分，尤其是在视觉问答任务中。在本工作中，我们引入了FiVL，一种新型的构造数据集的方法，旨在训练LVLMs以增强视觉定位能力，并评估其在这一方面的有效性。这些数据集可用于训练和评估LVLMs的能力，使其能够将图像内容作为实质性证据而非仅仅是依赖于语言先验信息，从而提供模型对视觉信息依赖程度的见解。为了证明我们数据集的实用性，我们引入了一种创新的训练任务，该任务在基准线之上表现出更优的表现，并提供了一个用于解释性的验证方法和应用。代码可以在 [此链接] 获取。', 'title_zh': 'FiVL：一种提高视觉-语言对齐的框架'}
{'arxiv_id': 'arXiv:2412.14670', 'title': 'Analysis and Visualization of Linguistic Structures in Large Language Models: Neural Representations of Verb-Particle Constructions in BERT', 'authors': 'Hassane Kissane, Achim Schilling, Patrick Krauss', 'link': 'https://arxiv.org/abs/2412.14670', 'abstract': "This study investigates the internal representations of verb-particle combinations within transformer-based large language models (LLMs), specifically examining how these models capture lexical and syntactic nuances at different neural network layers. Employing the BERT architecture, we analyse the representational efficacy of its layers for various verb-particle constructions such as 'agree on', 'come back', and 'give up'. Our methodology includes a detailed dataset preparation from the British National Corpus, followed by extensive model training and output analysis through techniques like multi-dimensional scaling (MDS) and generalized discrimination value (GDV) calculations. Results show that BERT's middle layers most effectively capture syntactic structures, with significant variability in representational accuracy across different verb categories. These findings challenge the conventional uniformity assumed in neural network processing of linguistic elements and suggest a complex interplay between network architecture and linguistic representation. Our research contributes to a better understanding of how deep learning models comprehend and process language, offering insights into the potential and limitations of current neural approaches to linguistic analysis. This study not only advances our knowledge in computational linguistics but also prompts further research into optimizing neural architectures for enhanced linguistic precision.", 'abstract_zh': '本研究探讨了基于变换器的大型语言模型（LLMs）内部对动词- particles组合的表示，特别考察了这些模型在不同神经网络层如何捕捉词性和句法的细微差别。我们使用BERT架构，对诸如“同意”，“回来”，“放弃”等动词- particles构型进行分析，评估其各层在表征方面的有效性。我们的方法包括从英国国家语料库准备详细的语料库，然后进行广泛的模型训练和通过多维标度（MDS）及广义判别值（GDV）计算进行输出分析。结果表明，BERT的中间层最有效地捕捉句法结构，不同动词类别在表征准确性方面存在显著差异。这些发现挑战了神经网络处理语言元素的一贯均匀性假设，并指出网络架构与语言表示之间存在复杂互作关系。本研究有助于更好地理解深度学习模型如何理解和处理语言，并提供了关于当前神经方法在语言分析方面的潜力和局限性的见解。本研究不仅推动了计算语言学领域知识的进步，还激发了进一步优化神经架构以增强语言精确性的研究。', 'title_zh': '大型语言模型中的语言结构分析与可视化：BERT中动词-粒子构造的神经表示分析与可视化'}
{'arxiv_id': 'arXiv:2412.14668', 'title': 'LoLaFL: Low-Latency Federated Learning via Forward-only Propagation', 'authors': 'Jierui Zhang, Jianhao Huang, Kaibin Huang', 'link': 'https://arxiv.org/abs/2412.14668', 'abstract': 'Federated learning (FL) has emerged as a widely adopted paradigm for enabling edge learning with distributed data while ensuring data privacy. However, the traditional FL with deep neural networks trained via backpropagation can hardly meet the low-latency learning requirements in the sixth generation (6G) mobile networks. This challenge mainly arises from the high-dimensional model parameters to be transmitted and the numerous rounds of communication required for convergence due to the inherent randomness of the training process. To address this issue, we adopt the state-of-the-art principle of maximal coding rate reduction to learn linear discriminative features and extend the resultant white-box neural network into FL, yielding the novel framework of Low-Latency Federated Learning (LoLaFL) via forward-only propagation. LoLaFL enables layer-wise transmissions and aggregation with significantly fewer communication rounds, thereby considerably reducing latency. Additionally, we propose two \\emph{nonlinear} aggregation schemes for LoLaFL. The first scheme is based on the proof that the optimal NN parameter aggregation in LoLaFL should be harmonic-mean-like. The second scheme further exploits the low-rank structures of the features and transmits the low-rank-approximated covariance matrices of features to achieve additional latency reduction. Theoretic analysis and experiments are conducted to evaluate the performance of LoLaFL. In comparison with traditional FL, the two nonlinear aggregation schemes for LoLaFL can achieve reductions in latency of over 91\\% and 98\\%, respectively, while maintaining comparable accuracies.', 'abstract_zh': '联邦学习（FL）作为一种在分布式数据上实现边缘学习的广泛采用范式，同时确保数据隐私，已经逐渐兴起。然而，传统的通过反向传播训练深度神经网络的联邦学习难以满足第六代（6G）移动网络中的低延迟学习要求。这一挑战主要源自于需要传输的高维模型参数以及由于训练过程本身就存在的随机性而需要的大量通信轮次。为了解决这一问题，我们采用了最新的原理——最大编码率降低原则，用于学习线性判别特征，并将生成的透明箱神经网络扩展到联邦学习框架中，从而提出了名为低延迟联邦学习（LoLaFL）的新型框架，通过单向传播实现层间传输和聚合，显著减少了通信轮次，从而大幅降低延迟。此外，我们为LoLaFL提出了两种非线性聚合方案。第一个方案是基于证明，LoLaFL中的最优神经网络参数聚合应类似于调和平均。第二个方案进一步利用特征的低秩结构，传输特征的低秩近似协方差矩阵，以实现额外的延迟减少。理论分析和实验表明，LoLaFL在保持相近准确性的同时，与传统联邦学习相比，两种非线性聚合方案分别可以实现超过91%和98%的延迟减少。', 'title_zh': 'LoLaFL：基于单向传播的低延迟联邦学习'}
{'arxiv_id': 'arXiv:2412.14663', 'title': 'IOHunter: Graph Foundation Model to Uncover Online Information Operations', 'authors': 'Marco Minici, Luca Luceri, Francesco Fabbri, Emilio Ferrara', 'link': 'https://arxiv.org/abs/2412.14663', 'abstract': 'Social media platforms have become vital spaces for public discourse, serving as modern agorás where a wide range of voices influence societal narratives. However, their open nature also makes them vulnerable to exploitation by malicious actors, including state-sponsored entities, who can conduct information operations (IOs) to manipulate public opinion. The spread of misinformation, false news, and misleading claims threatens democratic processes and societal cohesion, making it crucial to develop methods for the timely detection of inauthentic activity to protect the integrity of online discourse. In this work, we introduce a methodology designed to identify users orchestrating information operations, a.k.a. \\textit{IO drivers}, across various influence campaigns. Our framework, named \\texttt{IOHunter}, leverages the combined strengths of Language Models and Graph Neural Networks to improve generalization in \\emph{supervised}, \\emph{scarcely-supervised}, and \\emph{cross-IO} contexts. Our approach achieves state-of-the-art performance across multiple sets of IOs originating from six countries, significantly surpassing existing approaches. This research marks a step toward developing Graph Foundation Models specifically tailored for the task of IO detection on social media platforms.', 'abstract_zh': '社交媒体平台已成为公共讨论的重要空间，作为现代公共广场，广泛的声音影响着社会叙事。然而，它们的开放性也使其容易被恶意行为者，包括国家支持的实体，利用进行信息操作（IOs），以操纵公众舆论。虚假信息、假新闻和误导性声明的传播威胁着民主过程和社会凝聚力，因此及时检测虚假活动的方法对于保护在线讨论的完整性至关重要。本研究引入了一种方法，旨在识别组织信息操作的用户，即所谓的“信息操作驱动者（IO drivers）”，并在各类影响力活动中加以识别。我们提出了一种名为\\texttt{IOHunter}的框架，该框架综合利用了语言模型和图神经网络的优势，以提高在监督学习、少量监督学习和跨信息操作（cross-IO）环境下的泛化能力。我们的方法在源自六个不同国家的多个信息操作数据集上达到了最先进的性能，显著超越了现有方法。本研究为开发专门针对社交媒体平台信息操作检测任务的图基础模型迈出了重要一步。', 'title_zh': 'IOHunter：基于图的模型以发现在线信息操作'}
{'arxiv_id': 'arXiv:2412.14660', 'title': 'Unveiling Uncertainty: A Deep Dive into Calibration and Performance of Multimodal Large Language Models', 'authors': 'Zijun Chen, Wenbo Hu, Guande He, Zhijie Deng, Zheng Zhang, Richang Hong', 'link': 'https://arxiv.org/abs/2412.14660', 'abstract': "Multimodal large language models (MLLMs) combine visual and textual data for tasks such as image captioning and visual question answering. Proper uncertainty calibration is crucial, yet challenging, for reliable use in areas like healthcare and autonomous driving. This paper investigates representative MLLMs, focusing on their calibration across various scenarios, including before and after visual fine-tuning, as well as before and after multimodal training of the base LLMs. We observed miscalibration in their performance, and at the same time, no significant differences in calibration across these scenarios. We also highlight how uncertainty differs between text and images and how their integration affects overall uncertainty. To better understand MLLMs' miscalibration and their ability to self-assess uncertainty, we construct the IDK (I don't know) dataset, which is key to evaluating how they handle unknowns. Our findings reveal that MLLMs tend to give answers rather than admit uncertainty, but this self-assessment improves with proper prompt adjustments. Finally, to calibrate MLLMs and enhance model reliability, we propose techniques such as temperature scaling and iterative prompt optimization. Our results provide insights into improving MLLMs for effective and responsible deployment in multimodal applications. Code and IDK dataset: \\href{this https URL}{this https URL}.", 'abstract_zh': '多模态大型语言模型（MLLMs）结合视觉和文本数据，用于图像标注和视觉问答等任务。在医疗保健和自动驾驶等关键领域中，MLLMs的正确不确定性校准至关重要但极具挑战性。本文探讨了代表性MLLMs在各种场景下的校准问题，包括视觉微调前后，以及基础大模型进行多模态训练前后。我们观察到它们的性能存在偏差，但在这些场景下，校准差异并不显著。同时，我们还强调了文本和图像不确定性之间的差异以及这种集成如何影响整体不确定性。为了更好地理解MLLMs的偏差校准及其自我评估不确定性的能力，我们构建了IDK（我不知道）数据集，这是评估它们处理未知信息能力的关键。我们的研究发现，MLLMs往往会给出答案而不是承认不确定性，但通过适当的提示调整，这种自我评估可以得到改善。最后，为了校准MLLMs并增强模型的可靠性，我们提出了温度缩放和迭代提示优化等技术。我们的研究结果为在多模态应用中有效和负责任地部署MLLMs提供了见解。相关代码和IDK数据集：[此链接](this https URL)。', 'title_zh': '揭开不确定性面纱：多模态大型语言模型校准与性能深度探究'}
{'arxiv_id': 'arXiv:2412.14640', 'title': 'Adaptive Prompt Tuning: Vision Guided Prompt Tuning with Cross-Attention for Fine-Grained Few-Shot Learning', 'authors': 'Eric Brouwer, Jan Erik van Woerden, Gertjan Burghouts, Matias Valedenegro-Toro, Marco Zullich', 'link': 'https://arxiv.org/abs/2412.14640', 'abstract': "Few-shot, fine-grained classification in computer vision poses significant challenges due to the need to differentiate subtle class distinctions with limited data. This paper presents a novel method that enhances the Contrastive Language-Image Pre-Training (CLIP) model through adaptive prompt tuning, guided by real-time visual inputs. Unlike existing techniques such as Context Optimization (CoOp) and Visual Prompt Tuning (VPT), which are constrained by static prompts or visual token reliance, the proposed approach leverages a cross-attention mechanism to dynamically refine text prompts for the image at hand. This enables an image-specific alignment of textual features with image patches extracted from the Vision Transformer, making the model more effective for datasets with high intra-class variance and low inter-class differences. The method is evaluated on several datasets, including CUBirds, Oxford Flowers, and FGVC Aircraft, showing significant performance gains over static prompt tuning approaches. To ensure these performance gains translate into trustworthy predictions, we integrate Monte-Carlo Dropout in our approach to improve the reliability of the model predictions and uncertainty estimates. This integration provides valuable insights into the model's predictive confidence, helping to identify when predictions can be trusted and when additional verification is necessary. This dynamic approach offers a robust solution, advancing the state-of-the-art for few-shot fine-grained classification.", 'abstract_zh': '计算机视觉中的小样本、细粒度分类由于需要在数据有限的情况下区分细微的类别差异，面临着巨大的挑战。本文提出了一种新颖的方法，通过实时视觉输入引导自适应提示调优来增强对比语言-图像预训练（CLIP）模型。不同于现有的如上下文优化（CoOp）和视觉提示调优（VPT）等方法，这些方法受限于静态提示或视觉词依赖，所提出的方法利用交叉注意力机制动态细化针对当前图像的文本提示，从而实现了文本特征与来自视觉变换器提取的图像补丁的特定于图像的对齐。这使得模型对于高类内变异性且类间差异较低的数据集更加有效。该方法在CUBirds、Oxford Flowers和FGVC Aircraft等多个数据集上进行了评估，表明与静态提示调优方法相比具有显著的性能提升。为了确保这些性能提升转化为可信赖的预测，我们将在方法中集成蒙特卡洛dropout，以提高模型预测的可靠性和不确定性估计。这种集成为模型预测的信心提供了宝贵见解，有助于识别哪些预测可以信赖，哪些预测需要进一步验证。这种动态方法提供了一种稳健的解决方案，推动了小样本细粒度分类领域的发展。', 'title_zh': '自适应提示调整：基于视觉的跨注意力提示调整在细粒度少样本学习中的应用'}
{'arxiv_id': 'arXiv:2412.14639', 'title': 'A Shapley Value Estimation Speedup for Efficient Explainable Quantum AI', 'authors': 'Iain Burge, Michel Barbeau, Joaquin Garcia-Alfaro', 'link': 'https://arxiv.org/abs/2412.14639', 'abstract': "This work focuses on developing efficient post-hoc explanations for quantum AI algorithms. In classical contexts, the cooperative game theory concept of the Shapley value adapts naturally to post-hoc explanations, where it can be used to identify which factors are important in an AI's decision-making process. An interesting question is how to translate Shapley values to the quantum setting and whether quantum effects could be used to accelerate their calculation. We propose quantum algorithms that can extract Shapley values within some confidence interval. Our method is capable of quadratically outperforming classical Monte Carlo approaches to approximating Shapley values up to polylogarithmic factors in various circumstances. We demonstrate the validity of our approach empirically with specific voting games and provide rigorous proofs of performance for general cooperative games.", 'abstract_zh': '本研究致力于开发高效的后验解释方法，用于量子人工智能算法。在经典背景下，合作博弈论中的Shapley值概念自然适用于后验解释，可以用于识别哪些因素在人工智能的决策过程中是重要的。一个有趣的问题是如何将Shapley值转化为量子环境，并且量子效应是否能用于加速其计算。我们提出了一类量子算法，能够在某些置信区间内提取Shapley值。我们的方法在某些情况下能够超越经典蒙特卡洛方法，提高多项式对数因子以上的性能。我们通过特定投票博弈的经验验证了该方法的有效性，并为一般的合作博弈提供了严格的性能证明。', 'title_zh': '一种用于高效可解释量子人工智能的博弈值估计加速方法'}
{'arxiv_id': 'arXiv:2412.14633', 'title': 'Progressive Fine-to-Coarse Reconstruction for Accurate Low-Bit Post-Training Quantization in Vision Transformers', 'authors': 'Rui Ding, Liang Yong, Sihuan Zhao, Jing Nie, Lihui Chen, Haijun Liu, Xichuan Zhou', 'link': 'https://arxiv.org/abs/2412.14633', 'abstract': 'Due to its efficiency, Post-Training Quantization (PTQ) has been widely adopted for compressing Vision Transformers (ViTs). However, when quantized into low-bit representations, there is often a significant performance drop compared to their full-precision counterparts. To address this issue, reconstruction methods have been incorporated into the PTQ framework to improve performance in low-bit quantization settings. Nevertheless, existing related methods predefine the reconstruction granularity and seldom explore the progressive relationships between different reconstruction granularities, which leads to sub-optimal quantization results in ViTs. To this end, in this paper, we propose a Progressive Fine-to-Coarse Reconstruction (PFCR) method for accurate PTQ, which significantly improves the performance of low-bit quantized vision transformers. Specifically, we define multi-head self-attention and multi-layer perceptron modules along with their shortcuts as the finest reconstruction units. After reconstructing these two fine-grained units, we combine them to form coarser blocks and reconstruct them at a coarser granularity level. We iteratively perform this combination and reconstruction process, achieving progressive fine-to-coarse reconstruction. Additionally, we introduce a Progressive Optimization Strategy (POS) for PFCR to alleviate the difficulty of training, thereby further enhancing model performance. Experimental results on the ImageNet dataset demonstrate that our proposed method achieves the best Top-1 accuracy among state-of-the-art methods, particularly attaining 75.61% for 3-bit quantized ViT-B in PTQ. Besides, quantization results on the COCO dataset reveal the effectiveness and generalization of our proposed method on other computer vision tasks like object detection and instance segmentation.', 'abstract_zh': '由于其高效性，后训练量化（PTQ）已被广泛应用于压缩视觉变换器（ViTs）。然而，当量化为低比特表示时，与全精度版本相比，往往会出现显著的性能下降。为了解决这一问题，已经将重建方法融入PTQ框架中，以提高低比特量化设置下的性能。尽管如此，现有的相关方法在预定义重建粒度的同时，很少探索不同重建粒度之间的渐进关系，从而导致ViTs在量化过程中的次优结果。为此，本文提出了一种渐进细到粗重建（PFCR）方法，显著提高了低比特量化视觉变换器的性能。具体而言，我们定义了多头自注意力模块和多层感知器模块及其捷径作为最细的重建单元。在重建这些细粒度单元后，我们将它们组合成较粗的块，并以较粗的粒度对其进行重建。我们反复进行这种组合和重建过程，实现了渐进式细到粗重建。此外，我们还引入了一种渐进优化策略（POS）来进一步增强模型性能，缓解训练难度。在ImageNet数据集上的实验结果表明，我们提出的方法在众多先进方法中实现了最高的Top-1精度，特别是对于3比特量化ViT-B的PTQ，精度达到了75.61%。另外，COCO数据集上的量化结果进一步证明了我们提出的方法在其他计算机视觉任务（如目标检测和实例分割）中的有效性和泛化能力。', 'title_zh': '面向视觉变换器的分阶段细至粗重建方法以实现准确的低比特量化后训练'}
{'arxiv_id': 'arXiv:2412.14626', 'title': 'Learning to Generate Research Idea with Dynamic Control', 'authors': 'Ruochen Li, Liqiang Jing, Chi Han, Jiawei Zhou, Xinya Du', 'link': 'https://arxiv.org/abs/2412.14626', 'abstract': 'The rapid advancements in large language models (LLMs) have demonstrated their potential to accelerate scientific discovery, particularly in automating the process of research ideation. LLM-based systems have shown promise in generating hypotheses and research ideas. However, current approaches predominantly rely on prompting-based pre-trained models, limiting their ability to optimize generated content effectively. Moreover, they also lack the capability to deal with the complex interdependence and inherent restrictions among novelty, feasibility, and effectiveness, which remains challenging due to the inherent trade-offs among these dimensions, such as the innovation-feasibility conflict. To address these limitations, we for the first time propose fine-tuning LLMs to be better idea proposers and introduce a novel framework that employs a two-stage approach combining Supervised Fine-Tuning (SFT) and controllable Reinforcement Learning (RL). In the SFT stage, the model learns foundational patterns from pairs of research papers and follow-up ideas. In the RL stage, multi-dimensional reward modeling, guided by fine-grained feedback, evaluates and optimizes the generated ideas across key metrics. Dimensional controllers enable dynamic adjustment of generation, while a sentence-level decoder ensures context-aware emphasis during inference. Our framework provides a balanced approach to research ideation, achieving high-quality outcomes by dynamically navigating the trade-offs among novelty, feasibility, and effectiveness.', 'abstract_zh': '大规模语言模型（LLMs）的快速发展展示了其在加速科学研究方面的潜力，特别是在自动化研究构想过程中。基于LLM的系统已显示出生成假设和研究构想的潜力。然而，当前的方法主要依赖于基于提示的预训练模型，限制了其优化生成内容的能力。此外，它们缺乏处理新颖性、可行性和有效性之间错综复杂的关系和固有约束的能力，这些关系由于这些维度之间的内在权衡，如创新与可行性之间的冲突，使得处理变得更加困难。为了解决这些限制，我们首次提出对LLM进行微调，以更好地提出构想，并引入了一种新的框架，该框架采用结合监督微调（SFT）和可控强化学习（RL）的两阶段方法。在SFT阶段，模型从研究论文及其后续构想的配对中学习基础模式。在RL阶段，通过细化反馈指导的多维度奖励建模评估和优化生成的构想，同时关键指标衡量；维度控制器允许在推理过程中动态调整生成，而句级解码器确保在推理期间上下文相关的关注。该框架提供了一个平衡的研究构想方法，通过动态导航新颖性、可行性和有效性之间的权衡，实现了高质量的结果。', 'title_zh': '学习通过动态控制生成研究思路'}
{'arxiv_id': 'arXiv:2412.14619', 'title': 'Pitfalls of topology-aware image segmentation', 'authors': 'Alexander H. Berger, Laurin Lux, Alexander Weers, Martin Menten, Daniel Rueckert, Johannes C. Paetzold', 'link': 'https://arxiv.org/abs/2412.14619', 'abstract': "Topological correctness, i.e., the preservation of structural integrity and specific characteristics of shape, is a fundamental requirement for medical imaging tasks, such as neuron or vessel segmentation. Despite the recent surge in topology-aware methods addressing this challenge, their real-world applicability is hindered by flawed benchmarking practices. In this paper, we identify critical pitfalls in model evaluation that include inadequate connectivity choices, overlooked topological artifacts in ground truth annotations, and inappropriate use of evaluation metrics. Through detailed empirical analysis, we uncover these issues' profound impact on the evaluation and ranking of segmentation methods. Drawing from our findings, we propose a set of actionable recommendations to establish fair and robust evaluation standards for topology-aware medical image segmentation methods.", 'abstract_zh': '拓扑正确性，即保持结构完整性和特定形状特征的要求，是医学成像任务（如神经元或血管分割）的基本需求。尽管近期出现了许多针对这一挑战的拓扑意识方法，但它们的实际应用受到了评价标准缺陷的限制。在本文中，我们识别了模型评估中的关键问题，包括不充分的连接性选择、未忽视真实标注中的拓扑伪影以及不恰当的评价指标使用。通过详细的实证分析，我们揭示了这些问题对分割方法评估和排名的深远影响。根据我们的发现，我们提出了一个实用的建议集合，以建立公平且稳健的拓扑意识医学图像分割方法的评价标准。', 'title_zh': '拓扑意识图像分割中的陷阱'}
{'arxiv_id': 'arXiv:2412.14617', 'title': 'How good is GPT at writing political speeches for the White House?', 'authors': 'Jacques Savoy', 'link': 'https://arxiv.org/abs/2412.14617', 'abstract': 'Using large language models (LLMs), computers are able to generate a written text in response to a us er request. As this pervasive technology can be applied in numerous contexts, this study analyses the written style of one LLM called GPT by comparing its generated speeches with those of the recent US presidents. To achieve this objective, the State of the Union (SOTU) addresses written by Reagan to Biden are contrasted to those produced by both GPT-3.5 and GPT-4.o versions. Compared to US presidents, GPT tends to overuse the lemma "we" and produce shorter messages with, on average, longer sentences. Moreover, GPT opts for an optimistic tone, opting more often for political (e.g., president, Congress), symbolic (e.g., freedom), and abstract terms (e.g., freedom). Even when imposing an author\'s style to GPT, the resulting speech remains distinct from addresses written by the target author. Finally, the two GPT versions present distinct characteristics, but both appear overall dissimilar to true presidential messages.', 'abstract_zh': '使用大规模语言模型（LLMs），计算机能够根据用户的需求生成书面文本。由于这项普及性技术可以应用于多种情境，本研究通过将生成的演讲与最近几任美国总统的演讲进行对比，分析了其中一个名为GPT的LLM的写作风格。为了实现这一目标，我们对比了里根总统到拜登总统的国情咨文（SOTU），并将这些内容与GPT-3.5及GPT-4的生成的演讲进行对比。与美国总统的演讲相比，GPT更倾向于过度使用“我们”这一词素，产生较短的消息，平均而言，句子更长。此外，GPT倾向于采用更为乐观的语气，更常使用政治性词汇（例如，总统、国会）、象征性词汇（例如，自由）以及抽象性词汇（例如，自由）。即使给GPT施加某种作者的写作风格，生成的演讲仍然与其目标作者的演讲有所不同。最后，两个版本的GPT具有不同的特征，但在总体上，两者都显得与真正的总统演讲不同。', 'title_zh': 'GPT在为白宫撰写政治演讲方面做得如何？'}
{'arxiv_id': 'arXiv:2412.14613', 'title': 'HarmonicEval: Multi-modal, Multi-task, Multi-criteria Automatic Evaluation Using a Vision Language Model', 'authors': 'Masanari Ohi, Masahiro Kaneko, Naoaki Okazaki, Nakamasa Inoue', 'link': 'https://arxiv.org/abs/2412.14613', 'abstract': 'Vision-language models (VLMs) have shown impressive abilities in text and image understanding. However, existing metrics for evaluating the text generated by VLMs focus exclusively on overall quality, leading to two limitations: 1) it is challenging to identify which aspects of the text need improvement from the overall score; 2) metrics may overlook specific evaluation criteria when predicting an overall score. To address these limitations, we propose HarmonicEval, a reference-free evaluation metric that aggregates criterion-wise scores to produce the overall score in a bottom-up manner. Furthermore, we construct the Multi-task Multi-criteria Human Evaluation (MMHE) dataset, which comprises 18,000 expert human judgments across four vision-language tasks. Our experiments demonstrate that HarmonicEval achieves higher correlations with human judgments than conventional metrics while providing numerical scores for each criterion.', 'abstract_zh': '视觉语言模型（VLMs）在文本和图像理解方面展现了令人印象深刻的能力。然而，现有评估VLMs生成文本的度量标准仅专注于整体质量，导致两个局限性：1）难以从整体评分中识别需要改进的具体方面；2）度量标准在预测整体评分时可能会忽视特定评估标准。为了克服这些局限性，我们提出了一种参考自由的评估指标——谐波评估（HarmonicEval），该指标通过自下而上的方式汇总各标准的得分以生成整体评分。此外，我们构建了多任务多标准人类评估（MMHE）数据集，该数据集包含四个视觉语言任务中的18,000名专家的人类判断。实验结果显示，与传统度量标准相比，谐波评估与人类判断的相关性更高，并为每个标准提供了数值评分。', 'title_zh': '谐波评估：基于视觉语言模型的多模态、多任务、多准则自动评价方法'}
{'arxiv_id': 'arXiv:2412.14602', 'title': 'Towards Scalable and Deep Graph Neural Networks via Noise Masking', 'authors': 'Yuxuan Liang, Wentao Zhang, Zeang Sheng, Ling Yang, Quanqing Xu, Jiawei Jiang, Yunhai Tong, Bin Cu', 'link': 'https://arxiv.org/abs/2412.14602', 'abstract': 'In recent years, Graph Neural Networks (GNNs) have achieved remarkable success in many graph mining tasks. However, scaling them to large graphs is challenging due to the high computational and storage costs of repeated feature propagation and non-linear transformation during training. One commonly employed approach to address this challenge is model-simplification, which only executes the Propagation (P) once in the pre-processing, and Combine (C) these receptive fields in different ways and then feed them into a simple model for better performance. Despite their high predictive performance and scalability, these methods still face two limitations. First, existing approaches mainly focus on exploring different C methods from the model perspective, neglecting the crucial problem of performance degradation with increasing P depth from the data-centric perspective, known as the over-smoothing problem. Second, pre-processing overhead takes up most of the end-to-end processing time, especially for large-scale graphs. To address these limitations, we present random walk with noise masking (RMask), a plug-and-play module compatible with the existing model-simplification works. This module enables the exploration of deeper GNNs while preserving their scalability. Unlike the previous model-simplification works, we focus on continuous P and found that the noise existing inside each P is the cause of the over-smoothing issue, and use the efficient masking mechanism to eliminate them. Experimental results on six real-world datasets demonstrate that model-simplification works equipped with RMask yield superior performance compared to their original version and can make a good trade-off between accuracy and efficiency.', 'abstract_zh': '近年来，图神经网络（GNNs）在许多图挖掘任务中取得了显著的成功。然而，将它们扩展到大规模图中具有挑战性，因为训练过程中反复进行特征传播和非线性变换导致了较高的计算和存储成本。为了解决这一挑战，一种常用的方法是模型简化，该方法在预处理阶段只执行一次传播（P），并通过不同的方式组合这些感受野，然后将它们输入一个简单的模型以提高性能。尽管这些方法具有较高的预测性能和可扩展性，但它们仍面临两个局限性。首先，现有的方法主要从模型的角度探索不同的组合方法（C），而忽视了从数据为中心的角度来看，随着传播（P）深度的增加导致性能下降的问题，即过度平滑问题。其次，预处理开销占了端到端处理时间的主要部分，特别是在大规模图的情况下。为了解决这些局限性，我们提出了随机游走带噪声掩蔽（RMask）模块，该模块与现有的模型简化工作兼容，能够探索更深的GNNs同时保持其可扩展性。与先前的模型简化工作不同，我们关注连续的传播（P），发现每次传播内部存在的噪声是过度平滑问题的原因，并使用高效的掩蔽机制来消除它们。在六个真实世界的数据集上的实验结果表明，配备RMask的模型简化工作相比其原始版本具有更好的性能，并且可以在准确性和效率之间取得较好的平衡。', 'title_zh': '通过噪声掩蔽实现可扩展且深层次的图神经网络'}
{'arxiv_id': 'arXiv:2412.14587', 'title': 'Spike2Former: Efficient Spiking Transformer for High-performance Image Segmentation', 'authors': 'Zhenxin Lei, Man Yao, Jiakui Hu, Xinhao Luo, Yanye Lu, Bo Xu, Guoqi Li', 'link': 'https://arxiv.org/abs/2412.14587', 'abstract': 'Spiking Neural Networks (SNNs) have a low-power advantage but perform poorly in image segmentation tasks. The reason is that directly converting neural networks with complex architectural designs for segmentation tasks into spiking versions leads to performance degradation and non-convergence. To address this challenge, we first identify the modules in the architecture design that lead to the severe reduction in spike firing, make targeted improvements, and propose Spike2Former architecture. Second, we propose normalized integer spiking neurons to solve the training stability problem of SNNs with complex architectures. We set a new state-of-the-art for SNNs in various semantic segmentation datasets, with a significant improvement of +12.7% mIoU and 5.0 efficiency on ADE20K, +14.3% mIoU and 5.2 efficiency on VOC2012, and +9.1% mIoU and 6.6 efficiency on CityScapes.', 'abstract_zh': '与传统的深度学习网络相比，神经突触神经网络（SNNs）具有低功耗的优势，但在图像分割任务中表现较差。原因是直接将具有复杂架构设计的神经网络用于分割任务时，将其转换为突触版本会导致性能下降和非收敛问题。为解决这一挑战，我们首先识别出导致尖峰发射严重降低的架构模块，并进行了针对性改进，提出了Spike2Former架构。其次，我们提出了归一化整数突触神经元，以解决具有复杂架构的SNNs在训练过程中的稳定性问题。我们在多个语义分割数据集上首次达到了新的最佳状态，相比之前的工作，ADE20K数据集上获得的mIoU提高了12.7%，效率提升5.0%；VOC2012数据集上mIoU提高了14.3%，效率提升5.2%；CityScapes数据集上mIoU提高了9.1%，效率提升6.6%。', 'title_zh': 'Spike2Former：高效脉冲变压器在高性能图像分割中的应用'}
{'arxiv_id': 'arXiv:2412.14579', 'title': 'GSRender: Deduplicated Occupancy Prediction via Weakly Supervised 3D Gaussian Splatting', 'authors': 'Qianpu Sun, Changyong Shu, Sifan Zhou, Zichen Yu, Yan Chen, Dawei Yang, Yuan Chun', 'link': 'https://arxiv.org/abs/2412.14579', 'abstract': '3D occupancy perception is gaining increasing attention due to its capability to offer detailed and precise environment representations. Previous weakly-supervised NeRF methods balance efficiency and accuracy, with mIoU varying by 5-10 points due to sampling count along camera rays. Recently, real-time Gaussian splatting has gained widespread popularity in 3D reconstruction, and the occupancy prediction task can also be viewed as a reconstruction task. Consequently, we propose GSRender, which naturally employs 3D Gaussian Splatting for occupancy prediction, simplifying the sampling process. In addition, the limitations of 2D supervision result in duplicate predictions along the same camera ray. We implemented the Ray Compensation (RC) module, which mitigates this issue by compensating for features from adjacent frames. Finally, we redesigned the loss to eliminate the impact of dynamic objects from adjacent frames. Extensive experiments demonstrate that our approach achieves SOTA (state-of-the-art) results in RayIoU (+6.0), while narrowing the gap with 3D supervision methods. Our code will be released soon.', 'abstract_zh': '三维占有感知正逐渐受到关注，因其能够提供详细和精确的环境表示。之前的弱监督NeRF方法在效率和准确性之间取得平衡，但由于沿相机光线采样的数量不同，mIoU的差异可达5-10个百分点。最近，实时高斯划线在三维重建中获得了广泛的应用，而占有预测任务也可以视为一种重建任务。因此，我们提出GSRender，它自然地采用三维高斯划线进行占有预测，简化了采样过程。此外，2D监督的限制会导致沿同一相机光线的重复预测。我们实现了Ray Compensation（光线补偿）模块，该模块通过补偿相邻帧中的特征来解决这一问题。最后，我们重新设计了损失函数，以消除相邻帧中动态对象的影响。大量实验表明，我们提出的方法在RayIoU上达到了SOTA（当前最先进的）结果，同时缩小了与三维监督方法之间的差距。我们的代码将在不久后开源。', 'title_zh': 'GSRender: 通过弱监督3D 高斯点云计算去重占用预测'}
{'arxiv_id': 'arXiv:2412.14571', 'title': 'SCKD: Semi-Supervised Cross-Modality Knowledge Distillation for 4D Radar Object Detection', 'authors': 'Ruoyu Xu, Zhiyu Xiang, Chenwei Zhang, Hanzhi Zhong, Xijun Zhao, Ruina Dang, Peng Xu, Tianyu Pu, Eryun Liu', 'link': 'https://arxiv.org/abs/2412.14571', 'abstract': '3D object detection is one of the fundamental perception tasks for autonomous vehicles. Fulfilling such a task with a 4D millimeter-wave radar is very attractive since the sensor is able to acquire 3D point clouds similar to Lidar while maintaining robust measurements under adverse weather. However, due to the high sparsity and noise associated with the radar point clouds, the performance of the existing methods is still much lower than expected. In this paper, we propose a novel Semi-supervised Cross-modality Knowledge Distillation (SCKD) method for 4D radar-based 3D object detection. It characterizes the capability of learning the feature from a Lidar-radar-fused teacher network with semi-supervised distillation. We first propose an adaptive fusion module in the teacher network to boost its performance. Then, two feature distillation modules are designed to facilitate the cross-modality knowledge transfer. Finally, a semi-supervised output distillation is proposed to increase the effectiveness and flexibility of the distillation framework. With the same network structure, our radar-only student trained by SCKD boosts the mAP by 10.38% over the baseline and outperforms the state-of-the-art works on the VoD dataset. The experiment on ZJUODset also shows 5.12% mAP improvements on the moderate difficulty level over the baseline when extra unlabeled data are available. Code is available at this https URL.', 'abstract_zh': '三维物体检测是自动驾驶车辆基本感知任务之一。利用4D毫米波雷达完成这一任务极具吸引力，因为传感器能够获得类似于激光雷达的3D点云数据，同时在恶劣天气条件下仍能保持稳健的测量效果。然而，由于雷达点云的高度稀疏性和噪声，现有的方法性能仍然低于预期。本文提出了一种新的半监督跨模态知识蒸馏（SCKD）方法，用于基于4D雷达的三维物体检测。该方法通过半监督蒸馏特征，展示了融合激光雷达和雷达信息的教师网络的学习能力。我们首先在教师网络中提出了一个自适应融合模块以提高其性能。接着设计了两个特征蒸馏模块，以促进跨模态知识的传递。最后，提出了一种半监督输出蒸馏方法，以提高蒸馏框架的有效性和灵活性。在相同的网络结构下，仅利用雷达数据由SCKD训练的学生网络在基准模型的基础上将平均检出精度（mAP）提高了10.38%，并且在VoD数据集上表现优于最新的工作。当额外的未标注数据可用时，实验在ZJUOD数据集上还显示出基准模型在中等难度水平上的5.12%的mAP提升。代码已发布于此网页：[链接]。', 'title_zh': 'SCKD：半监督跨模态知识蒸馏在4D雷达目标检测中的应用'}
{'arxiv_id': 'arXiv:2412.14570', 'title': 'Characterising Simulation-Based Program Equilibria', 'authors': 'Emery Cooper, Caspar Oesterheld, Vincent Conitzer', 'link': 'https://arxiv.org/abs/2412.14570', 'abstract': "In Tennenholtz's program equilibrium, players of a game submit programs to play on their behalf. Each program receives the other programs' source code and outputs an action. This can model interactions involving AI agents, mutually transparent institutions, or commitments. Tennenholtz (2004) proves a folk theorem for program games, but the equilibria constructed are very brittle. We therefore consider simulation-based programs -- i.e., programs that work by running opponents' programs. These are relatively robust (in particular, two programs that act the same are treated the same) and are more practical than proof-based approaches. Oesterheld's (2019) $\\epsilon$Grounded$\\pi$Bot is such an approach. Unfortunately, it is not generally applicable to games of three or more players, and only allows for a limited range of equilibria in two player games. In this paper, we propose a generalisation to Oesterheld's (2019) $\\epsilon$Grounded$\\pi$Bot. We prove a folk theorem for our programs in a setting with access to a shared source of randomness. We then characterise their equilibria in a setting without shared randomness. Both with and without shared randomness, we achieve a much wider range of equilibria than Oesterheld's (2019) $\\epsilon$Grounded$\\pi$Bot. Finally, we explore the limits of simulation-based program equilibrium, showing that the Tennenholtz folk theorem cannot be attained by simulation-based programs without access to shared randomness.", 'abstract_zh': '在Tennenholtz的游戏程序均衡框架中，博弈中的玩家提交程序来代表他们自己进行游戏。每个程序都会接收其他程序的源代码并输出一个行动。这一框架可以模拟涉及AI代理、相互透明的机构或承诺的互动。Tennenholtz（2004）为程序博弈证明了一个民间定理，但所构建的均衡非常脆弱。因此，我们考虑了一种基于模拟的程序——即通过运行对手程序来实现的程序。这些程序相对较稳健（特别是，执行相同行为的两个程序会得到相同的对待），并且比基于证明的方法更为实用。Oesterheld（2019）的$\\epsilon$Grounded$\\pi$Bot就是这样的一个方法。不幸的是，它并不适用于三名或更多参与者的游戏，并且仅允许在两名参与者游戏中有限范围的均衡。在本文中，我们提出了一种Oesterheld（2019）$\\epsilon$Grounded$\\pi$Bot的推广。我们证明了在可以访问共享随机源的环境中，我们程序的民间定理。然后在没有共享随机源的环境中，我们描述了它们的均衡状态。无论是否有共享随机源，在这些情况下，我们都能实现比Oesterheld（2019）$\\epsilon$Grounded$\\pi$Bot更为广泛范围的均衡。最后，我们探讨了基于模拟的程序均衡的极限，证明了在没有共享随机源的情况下，基于模拟的程序无法达到Tennenholtz的民间定理。', 'title_zh': '基于模拟的程序均衡特性分析'}
{'arxiv_id': 'arXiv:2412.14569', 'title': 'Global Spatio-Temporal Fusion-based Traffic Prediction Algorithm with Anomaly Aware', 'authors': 'Chaoqun Liu, Xuanpeng Li, Chen Gong, Guangyu Li', 'link': 'https://arxiv.org/abs/2412.14569', 'abstract': 'Traffic prediction is an indispensable component of urban planning and traffic management. Achieving accurate traffic prediction hinges on the ability to capture the potential spatio-temporal relationships among road sensors. However, the majority of existing works focus on local short-term spatio-temporal correlations, failing to fully consider the interactions of different sensors in the long-term state. In addition, these works do not analyze the influences of anomalous factors, or have insufficient ability to extract personalized features of anomalous factors, which make them ineffectively capture their spatio-temporal influences on traffic prediction. To address the aforementioned issues, We propose a global spatio-temporal fusion-based traffic prediction algorithm that incorporates anomaly awareness. Initially, based on the designed anomaly detection network, we construct an efficient anomalous factors impacting module (AFIM), to evaluate the spatio-temporal impact of unexpected external events on traffic prediction. Furthermore, we propose a multi-scale spatio-temporal feature fusion module (MTSFFL) based on the transformer architecture, to obtain all possible both long and short term correlations among different sensors in a wide-area traffic environment for accurate prediction of traffic flow. Finally, experiments are implemented based on real-scenario public transportation datasets (PEMS04 and PEMS08) to demonstrate that our approach can achieve state-of-the-art performance.', 'abstract_zh': '交通预测是城市规划和交通管理不可或缺的组成部分。准确的交通预测依赖于捕捉道路传感器之间潜在的空间-时间关系的能力。然而，现有大多数研究主要关注局部短期的空间-时间相关性，并未能充分考虑长期内不同传感器之间的交互作用。此外，这些研究没有分析异常因素的影响，或者难以提取异常因素的个性化特征，这使得它们难以有效地捕捉这些因素对交通预测的空间-时间影响。为了解决上述问题，我们提出了一种结合异常感知的全局空间-时间融合交通预测算法。首先，基于设计的异常检测网络，构建了一个高效的影响异常因素模块（AFIM），以评估意外外部事件对交通预测的空间-时间影响。进一步地，我们提出了基于Transformer架构的多尺度空间-时间特征融合模块（MTSFFL），以获得广域交通环境中不同传感器之间所有可能的长期和短期相关性，从而实现交通流量的准确预测。最后，通过基于实际场景的公共交通数据集（PEMS04和PEMS08）进行实验，证明了我们的方法能够达到最先进的性能。', 'title_zh': '具备异常感知的全局空时融合交通预测算法'}
{'arxiv_id': 'arXiv:2412.14566', 'title': 'AIArena: A Blockchain-Based Decentralized AI Training Platform', 'authors': 'Zhipeng Wang, Rui Sun, Elizabeth Lui, Tuo Zhou, Yizhe Wen, Jiahao Sun', 'link': 'https://arxiv.org/abs/2412.14566', 'abstract': 'The rapid advancement of AI has underscored critical challenges in its development and implementation, largely due to centralized control by a few major corporations. This concentration of power intensifies biases within AI models, resulting from inadequate governance and oversight mechanisms. Additionally, it limits public involvement and heightens concerns about the integrity of model generation. Such monopolistic control over data and AI outputs threatens both innovation and fair data usage, as users inadvertently contribute data that primarily benefits these corporations. In this work, we propose AIArena, a blockchain-based decentralized AI training platform designed to democratize AI development and alignment through on-chain incentive mechanisms. AIArena fosters an open and collaborative environment where participants can contribute models and computing resources. Its on-chain consensus mechanism ensures fair rewards for participants based on their contributions. We instantiate and implement AIArena on the public Base blockchain Sepolia testnet, and the evaluation results demonstrate the feasibility of AIArena in real-world applications.', 'abstract_zh': '人工智能的迅速发展凸显了其开发和实施中关键性的挑战，主要是由于少数几家大型企业对AI的集中控制。这种权力集中加剧了AI模型中的偏见，源于治理和监管机制的不足。此外，这也限制了公众的参与，并加剧了对模型生成完整性的担忧。这种数据和AI输出的垄断控制不仅威胁到了创新，还限制了公平数据使用的可能性，用户无意中贡献的数据主要惠及这些企业。在本文中，我们提出了一种基于区块链的去中心化AI训练平台AIArena，旨在通过链上激励机制实现AI开发和对齐的民主化。AIArena营造了一个开放和协作的环境，参与者可以贡献模型和计算资源。其链上共识机制确保根据参与者贡献的多少公平地给予奖励。我们在公共Base区块链Sepolia测试网上实例化并实现了AIArena，并且评估结果证明了AIArena在实际应用中的可行性。', 'title_zh': 'AIArena：一种基于区块链的去中心化AI训练平台'}
{'arxiv_id': 'arXiv:2412.14545', 'title': 'Summary of Point Transformer with Federated Learning for Predicting Breast Cancer HER2 Status from Hematoxylin and Eosin-Stained Whole Slide Images', 'authors': 'Kamorudeen A. Amuda, Almustapha A. Wakili', 'link': 'https://arxiv.org/abs/2412.14545', 'abstract': 'This study introduces a federated learning-based approach to predict HER2 status from hematoxylin and eosin (HE)-stained whole slide images (WSIs), reducing costs and speeding up treatment decisions. To address label imbalance and feature representation challenges in multisite datasets, a point transformer is proposed, incorporating dynamic label distribution, an auxiliary classifier, and farthest cosine sampling. Extensive experiments demonstrate state-of-the-art performance across four sites (2687 WSIs) and strong generalization to two unseen sites (229 WSIs).', 'abstract_zh': '本文介绍了一种基于联邦学习的方法，用于预测苏木精和伊红（HE）染色全切片图像（WSI）中的HER2状态，从而降低成本并加快治疗决策过程。为了解决多中心数据集中标签不平衡和特征表示的挑战，本文提出了一种点变换器方法，该方法结合了动态标签分布、辅助分类器和最远余弦采样。广泛实验表明，该方法在四个中心（2687张WSI）上表现出业界最佳性能，并且在两个未见过的中心（229张WSI）上具有较强的泛化能力。', 'title_zh': '基于点变换器和联邦学习的乳腺癌HER2状态预测摘要——从苏木精和伊红染色全切片图像中获取'}
{'arxiv_id': 'arXiv:2412.14538', 'title': 'Overview of AI and Communication for 6G Network: Fundamentals, Challenges, and Future Research Opportunities', 'authors': 'Qimei Cui, Xiaohu You, Ni Wei, Guoshun Nan, Xuefei Zhang, Jianhua Zhang, Xinchen Lyu, Ming Ai, Xiaofeng Tao, Zhiyong Feng, Ping Zhang, Qingqing Wu, Meixia Tao, Yongming Huang, Chongwen Huang, Guangyi Liu, Chenghui Peng, Zhiwen Pan, Tao Sun, Dusit Niyato, Tao Chen, Muhammad Khurram Khan, Abbas Jamalipour, Mohsen Guizani, Chau Yuen', 'link': 'https://arxiv.org/abs/2412.14538', 'abstract': 'With the increasing demand for seamless connectivity and intelligent communication, the integration of artificial intelligence (AI) and communication for sixth-generation (6G) network is emerging as a revolutionary architecture. This paper presents a comprehensive overview of AI and communication for 6G networks, emphasizing their foundational principles, inherent challenges, and future research opportunities. We commence with a retrospective analysis of AI and the evolution of large-scale AI models, underscoring their pivotal roles in shaping contemporary communication technologies. The discourse then transitions to a detailed exposition of the envisioned integration of AI within 6G networks, delineated across three progressive developmental stages. The initial stage, AI for Network, focuses on employing AI to augment network performance, optimize efficiency, and enhance user service experiences. The subsequent stage, Network for AI, highlights the role of the network in facilitating and buttressing AI operations and presents key enabling technologies, including digital twins for AI and semantic communication. In the final stage, AI as a Service, it is anticipated that future 6G networks will innately provide AI functions as services and support application scenarios like immersive communication and intelligent industrial robots. Specifically, we have defined the quality of AI service, which refers to the measurement framework system of AI services within the network. In addition to these developmental stages, we thoroughly examine the standardization processes pertinent to AI in network contexts, highlighting key milestones and ongoing efforts. Finally, we outline promising future research opportunities that could drive the evolution and refinement of AI and communication for 6G, positioning them as a cornerstone of next-generation communication infrastructure.', 'abstract_zh': '随着对无缝连接和智能通信需求的不断增加，人工智能（AI）与第六代（6G）网络通信的整合正在成为一个革命性的架构。本文对6G网络中的AI和通信进行全面概述，强调其基础原理、固有挑战及未来研究机会。我们从回顾AI的发展及其大规模AI模型的演变入手，强调它们在塑造当代通信技术方面的重要作用。然后，讨论转向详细阐述AI在6G网络中的预期整合，按三个递进的发展阶段进行描述。\n\n第一阶段，网络中的AI，旨在利用AI来增强网络性能、优化效率并提升用户服务体验。第二个阶段，网络支持AI，强调网络在促进和支持AI运营方面的作用，并介绍了关键技术，包括AI的数字孪生和语义通信。在最后一个阶段，AI 作为服务，预计未来的6G网络将天然地提供AI功能，并支持沉浸式通信和智能工业机器人等应用场景。特别地，我们界定了AI服务的质量，指的是网络中AI服务的度量框架系统。除此之外，我们还详细考察了网络环境中AI相关标准化过程的关键里程碑和正在进行中的努力。最后，我们指出了推动6G中AI和通信发展的潜力研究机会，将它们定位为下一代通信基础设施的基石。', 'title_zh': '6G网络中人工智能与通信的综述：基础、挑战及未来研究机会'}
{'arxiv_id': 'arXiv:2412.14522', 'title': 'CAE-T: A Channelwise AutoEncoder with Transformer for EEG Abnormality Detection', 'authors': 'Youshen Zhao, Keiji Iramina', 'link': 'https://arxiv.org/abs/2412.14522', 'abstract': 'Electroencephalogram (EEG) signals are critical for detecting abnormal brain activity, but their high dimensionality and complexity pose significant challenges for effective analysis. In this paper, we propose CAE-T, a novel framework that combines a channelwise CNN-based autoencoder with a single-head transformer classifier for efficient EEG abnormality detection. The channelwise autoencoder compresses raw EEG signals while preserving channel independence, reducing computational costs and retaining biologically meaningful features. The compressed representations are then fed into the transformer-based classifier, which efficiently models long-term dependencies to distinguish between normal and abnormal signals. Evaluated on the TUH Abnormal EEG Corpus, the proposed model achieves 85.0% accuracy, 76.2% sensitivity, and 91.2% specificity at the per-case level, outperforming baseline models such as EEGNet, Deep4Conv, and FusionCNN. Furthermore, CAE-T requires only 202M FLOPs and 2.9M parameters, making it significantly more efficient than transformer-based alternatives. The framework retains interpretability through its channelwise design, demonstrating great potential for future applications in neuroscience research and clinical practice. The source code is available at this https URL.', 'abstract_zh': '脑电图（EEG）信号对于检测异常脑活动至关重要，但由于其高维度性和复杂性，有效分析这些信号面临着显著挑战。本文提出了一种名为CAE-T的新框架，该框架结合了通道wise CNN自动编码器和单头变换器分类器，以实现高效的心电图异常检测。通道wise 自动编码器压缩原始EEG信号同时保持通道独立性，降低计算成本并保留生物学意义的特征。压缩后的表示随后输入基于变换器的分类器，该分类器能够高效建模长期依赖性，以区分正常和异常信号。在TUH异常EEG数据集上进行评估，所提出的模型在单案例水平上实现了85.0%的准确率、76.2%的敏感性和91.2%的特异性，优于基线模型如EEGNet、Deep4Conv和FusionCNN。此外，CAE-T 只需202M FLOPs 和2.9M 参数，相比于基于变换器的其他方法更为高效。该框架通过其通道wise 设计保留了可解释性，展示了在未来神经科学和临床实践中的巨大应用潜力。源代码可在以下链接获取：this https URL。', 'title_zh': 'CAE-T：一种基于变压器的通道级自编码器在脑电异常检测中的应用'}
{'arxiv_id': 'arXiv:2412.14510', 'title': 'PA-RAG: RAG Alignment via Multi-Perspective Preference Optimization', 'authors': 'Jiayi Wu, Hengyi Cai, Lingyong Yan, Hao Sun, Xiang Li, Shuaiqiang Wang, Dawei Yin, Ming Gao', 'link': 'https://arxiv.org/abs/2412.14510', 'abstract': 'The emergence of Retrieval-augmented generation (RAG) has alleviated the issues of outdated and hallucinatory content in the generation of large language models (LLMs), yet it still reveals numerous limitations. When a general-purpose LLM serves as the RAG generator, it often suffers from inadequate response informativeness, response robustness, and citation quality. Past approaches to tackle these limitations, either by incorporating additional steps beyond generating responses or optimizing the generator through supervised fine-tuning (SFT), still failed to align with the RAG requirement thoroughly. Consequently, optimizing the RAG generator from multiple preference perspectives while maintaining its end-to-end LLM form remains a challenge. To bridge this gap, we propose Multiple Perspective Preference Alignment for Retrieval-Augmented Generation (PA-RAG), a method for optimizing the generator of RAG systems to align with RAG requirements comprehensively. Specifically, we construct high-quality instruction fine-tuning data and multi-perspective preference data by sampling varied quality responses from the generator across different prompt documents quality scenarios. Subsequently, we optimize the generator using SFT and Direct Preference Optimization (DPO). Extensive experiments conducted on four question-answer datasets across three LLMs demonstrate that PA-RAG can significantly enhance the performance of RAG generators. Our code and datasets are available at this https URL.', 'abstract_zh': '检索增强生成（RAG）的出现缓解了大型语言模型（LLMs）生成内容中过时和幻觉问题，但仍然暴露了许多局限性。当通用语言模型作为RAG生成器时，它通常会遇到响应信息不足、响应稳健性差以及参考文献质量差的问题。过去通过增加生成响应之外的步骤或通过有监督微调（SFT）优化生成器来解决这些局限性的方法，仍然未能完全满足RAG的要求。因此，同时从多个偏好角度优化RAG生成器并保持其端到端的LLM形式仍然是一个挑战。为了弥合这一差距，我们提出了一种多角度偏好对齐方法（PA-RAG），用于全面优化RAG系统的生成器。具体而言，我们通过从不同提示文档质量场景中采样不同质量的生成响应来构建高质量指令微调数据和多角度偏好数据。随后，我们使用有监督微调（SFT）和直接偏好优化（DPO）来优化生成器。在三个大型语言模型的四个问答数据集上进行的广泛实验表明，PA-RAG可以显著提高RAG生成器的性能。我们的代码和数据集可在以下链接获取：[该 https URL]。', 'title_zh': 'PA-RAG: 多视角偏好优化下的RAG对齐'}
{'arxiv_id': 'arXiv:2412.14497', 'title': 'Treatment Effects Estimation on Networked Observational Data using Disentangled Variational Graph Autoencoder', 'authors': 'Di Fan, Renlei Jiang, Yunhao Wen, Chuanhou Gao', 'link': 'https://arxiv.org/abs/2412.14497', 'abstract': 'Estimating individual treatment effect (ITE) from observational data has gained increasing attention across various domains, with a key challenge being the identification of latent confounders affecting both treatment and outcome. Networked observational data offer new opportunities to address this issue by utilizing network information to infer latent confounders. However, most existing approaches assume observed variables and network information serve only as proxy variables for latent confounders, which often fails in practice, as some variables influence treatment but not outcomes, and vice versa. Recent advances in disentangled representation learning, which disentangle latent factors into instrumental, confounding, and adjustment factors, have shown promise for ITE estimation. Building on this, we propose a novel disentangled variational graph autoencoder that learns disentangled factors for treatment effect estimation on networked observational data. Our graph encoder further ensures factor independence using the Hilbert-Schmidt Independence Criterion. Extensive experiments on two semi-synthetic datasets derived from real-world social networks and one synthetic dataset demonstrate that our method achieves state-of-the-art performance.', 'abstract_zh': '从观察数据中估计个体治疗效果（ITE）逐渐成为各个领域的热点研究方向，关键挑战在于识别影响治疗和结果的潜在混杂因素。联网的观察数据提供了新的机会，通过利用网络信息推断潜在混杂因素来解决这一问题。然而，现有大多数方法假设观测变量和网络信息仅作为潜在混杂因素的代理变量，这在实践中往往行不通，因为有些变量可能影响治疗但不直接影响结果，反之亦然。最近在去纠缠表示学习方面取得的进展，该方法能将潜在因素分解为工具变量、混杂变量和调节变量，显示出了在ITE估计中的潜力。基于此，我们提出了一种新颖的去纠缠变分图自编码器，该自编码器能够从联网的观察数据中学习去纠缠的治疗效果估计因素。我们的图编码器进一步使用希尔伯特-施密特独立性判据确保了因素之间的独立性。通过在两个源自真实社会网络的半合成数据集以及一个合成数据集上的广泛实验，我们方法展现了最先进的性能。', 'title_zh': '使用解纠缠变分图自编码器进行网络观测数据的治疗效应估计'}
{'arxiv_id': 'arXiv:2412.14488', 'title': 'Stochastic first-order methods with multi-extrapolated momentum for highly smooth unconstrained optimization', 'authors': 'Chuan He', 'link': 'https://arxiv.org/abs/2412.14488', 'abstract': 'In this paper we consider an unconstrained stochastic optimization problem where the objective function exhibits a high order of smoothness. In particular, we propose a stochastic first-order method (SFOM) with multi-extrapolated momentum, in which multiple extrapolations are performed in each iteration, followed by a momentum step based on these extrapolations. We show that our proposed SFOM with multi-extrapolated momentum can accelerate optimization by exploiting the high-order smoothness of the objective function $f$. Specifically, assuming that the gradient and the $p$th-order derivative of $f$ are Lipschitz continuous for some $p\\ge2$, and under some additional mild assumptions, we establish that our method achieves a sample complexity of $\\widetilde{\\mathcal{O}}(\\epsilon^{-(3p+1)/p})$ for finding a point $x$ satisfying $\\mathbb{E}[\\|\\nabla f(x)\\|]\\le\\epsilon$. To the best of our knowledge, our method is the first SFOM to leverage arbitrary order smoothness of the objective function for acceleration, resulting in a sample complexity that strictly improves upon the best-known results without assuming the average smoothness condition. Finally, preliminary numerical experiments validate the practical performance of our method and corroborate our theoretical findings.', 'abstract_zh': '在本文中，我们考虑一个无约束的随机优化问题，其中目标函数具有高阶光滑性。特别地，我们提出了一种具有多外推动量的随机一阶方法（SFOM），在每一步迭代中进行多次外推，随后基于这些外推进行一次动量步骤。我们证明了通过利用目标函数 \\(f\\) 的高阶光滑性，我们提出的具有多外推动量的SFOM可以加速优化。具体而言，在假定 \\(f\\) 的梯度和 \\(p\\) 阶导数（其中 \\(p \\ge 2\\)）是利普希茨连续的，并在一些额外的轻微假设下，我们建立了该方法能够在期望梯度范数 \\(\\mathbb{E}[\\|\\nabla f(x)\\|]\\le \\epsilon\\) 条件下找到一个点 \\(x\\) 的样本复杂度为 \\(\\widetilde{\\mathcal{O}}(\\epsilon^{-(3p+1)/p})\\)。据我们所知，这是首次利用目标函数的任意阶光滑性来加速优化的SFOM方法，所得的样本复杂度严格优于在不假设平均光滑性条件下的最优结果。最后，初步的数值实验验证了该方法的实际性能，并支持了我们的理论发现。', 'title_zh': '具有多步外推动量的随机一阶方法在高度光滑无约束优化中的应用'}
{'arxiv_id': 'arXiv:2412.14468', 'title': 'HashAttention: Semantic Sparsity for Faster Inference', 'authors': 'Aditya Desai, Shuo Yang, Alejandro Cuadron, Ana Klimovic, Matei Zaharia, Joseph E. Gonzalez, Ion Stoica', 'link': 'https://arxiv.org/abs/2412.14468', 'abstract': 'Utilizing longer contexts is increasingly essential to power better AI systems. However, the cost of attending to long contexts is high due to the involved softmax computation. While the scaled dot-product attention (SDPA) exhibits token sparsity, with only a few pivotal tokens significantly contributing to attention, leveraging this sparsity effectively remains an open challenge. Previous methods either suffer from model degradation or require considerable additional resources. We propose HashAttention --a principled approach casting pivotal token identification as a recommendation problem. Given a query, HashAttention encodes keys and queries in Hamming space capturing the required semantic similarity using learned mapping functions. HashAttention efficiently identifies pivotal tokens for a given query in this Hamming space using bitwise operations, and only these pivotal tokens are used for attention computation, significantly improving overall attention efficiency. HashAttention can reduce the number of tokens used by a factor of $1/32\\times$ for the Llama-3.1-8B model with LongBench, keeping average quality loss within 0.6 points, while using only 32 bits per token auxiliary memory. At $32\\times$ sparsity, HashAttention is $3{-}6\\times$ faster than LightLLM and $2.5{-}4.5\\times$ faster than gpt-fast on Nvidia-L4 GPU.', 'abstract_zh': '将以下论文内容或标题翻译成中文，符合学术规范：\n\n利用更长的上下文对构建更强大的AI系统越来越重要。但由于涉及的softmax计算成本很高，因此关注长上下文的成本较高。虽然缩放点积注意机制（SDPA）表现出标记稀疏性，即只有少数几个关键标记显著地参与注意力计算，但如何有效地利用这种稀疏性仍然是一个开放性的挑战。先前的方法要么导致模型性能下降，要么需要大量的额外资源。我们提出了一种基于原则的方法——HashAttention，将关键标记识别问题转化为推荐系统问题。给定一个查询，HashAttention 通过学习映射函数将键和查询编码到汉明空间中，捕获所需的语义相似性。HashAttention 利用位运算高效地在汉明空间中识别给定查询的关键标记，仅使用这些关键标记来进行注意计算，从而显著提高整体注意效率。HashAttention 可以将 Llama-3.1-8B 模型（使用 LongBench）中使用的标记数量减少32倍，同时保持平均质量损失在0.6分以内，且每个标记仅使用32位的辅助内存。在32倍稀疏度下，HashAttention 在Nvidia-L4 GPU上的速度比LightLLM 快3-6倍，比gpt-fast快2.5-4.5倍。', 'title_zh': '哈希注意力：语义稀疏性以实现更快的推理'}
{'arxiv_id': 'arXiv:2412.14451', 'title': 'CLDG: Contrastive Learning on Dynamic Graphs', 'authors': 'Yiming Xu, Bin Shi, Teng Ma, Bo Dong, Haoyi Zhou, Qinghua Zheng', 'link': 'https://arxiv.org/abs/2412.14451', 'abstract': "The graph with complex annotations is the most potent data type, whose constantly evolving motivates further exploration of the unsupervised dynamic graph representation. One of the representative paradigms is graph contrastive learning. It constructs self-supervised signals by maximizing the mutual information between the statistic graph's augmentation views. However, the semantics and labels may change within the augmentation process, causing a significant performance drop in downstream tasks. This drawback becomes greatly magnified on dynamic graphs. To address this problem, we designed a simple yet effective framework named CLDG. Firstly, we elaborate that dynamic graphs have temporal translation invariance at different levels. Then, we proposed a sampling layer to extract the temporally-persistent signals. It will encourage the node to maintain consistent local and global representations, i.e., temporal translation invariance under the timespan views. The extensive experiments demonstrate the effectiveness and efficiency of the method on seven datasets by outperforming eight unsupervised state-of-the-art baselines and showing competitiveness against four semi-supervised methods. Compared with the existing dynamic graph method, the number of model parameters and training time is reduced by an average of 2,001.86 times and 130.31 times on seven datasets, respectively.", 'abstract_zh': '具有复杂注解的图是最强大的数据类型，其不断发展的特性激发了对无监督动态图表示的进一步探索。其中一个代表性的范式是图对比学习。该方法通过最大化统计图增强视图之间的互信息来构建自我监督的信号。然而，在增强过程中，语义和标签可能会发生变化，导致下游任务表现显著下降。这一缺陷在动态图上表现尤为突出。为解决这一问题，我们设计了一个简单而有效的框架，名为CLDG。首先，我们详细阐述了动态图在不同层次上具有时间平移不变性。然后，我们提出了一种采样层以提取时间持久性的信号，这将促使节点在时间段视图下保持一致的局部和全局表示即时间平移不变性。广泛的经验表明，该方法在七个数据集上优于八个无监督的最新基准方法，并在四个半监督方法中展现出竞争力。与现有的动态图方法相比，该方法在七个数据集上的模型参数数量和训练时间分别减少了平均2001.86倍和130.31倍。', 'title_zh': 'CLDG：动态图上的对比学习'}
{'arxiv_id': 'arXiv:2412.14444', 'title': 'GenHMR: Generative Human Mesh Recovery', 'authors': 'Muhammad Usama Saleem, Ekkasit Pinyoanuntapong, Pu Wang, Hongfei Xue, Srijan Das, Chen Chen', 'link': 'https://arxiv.org/abs/2412.14444', 'abstract': 'Human mesh recovery (HMR) is crucial in many computer vision applications; from health to arts and entertainment. HMR from monocular images has predominantly been addressed by deterministic methods that output a single prediction for a given 2D image. However, HMR from a single image is an ill-posed problem due to depth ambiguity and occlusions. Probabilistic methods have attempted to address this by generating and fusing multiple plausible 3D reconstructions, but their performance has often lagged behind deterministic approaches. In this paper, we introduce GenHMR, a novel generative framework that reformulates monocular HMR as an image-conditioned generative task, explicitly modeling and mitigating uncertainties in the 2D-to-3D mapping process. GenHMR comprises two key components: (1) a pose tokenizer to convert 3D human poses into a sequence of discrete tokens in a latent space, and (2) an image-conditional masked transformer to learn the probabilistic distributions of the pose tokens, conditioned on the input image prompt along with randomly masked token sequence. During inference, the model samples from the learned conditional distribution to iteratively decode high-confidence pose tokens, thereby reducing 3D reconstruction uncertainties. To further refine the reconstruction, a 2D pose-guided refinement technique is proposed to directly fine-tune the decoded pose tokens in the latent space, which forces the projected 3D body mesh to align with the 2D pose clues. Experiments on benchmark datasets demonstrate that GenHMR significantly outperforms state-of-the-art methods. Project website can be found at this https URL', 'abstract_zh': '人类网格恢复（HMR）在许多计算机视觉应用中至关重要，从健康到艺术和娱乐领域。从单目图像进行HMR主要由确定性方法解决，这些方法对给定的2D图像输出单个预测。然而，从单目图像进行HMR是一个病态问题，由于深度模糊和遮挡。概率方法通过生成并融合多个可能的3D重构尝试解决这一问题，但其性能往往落后于确定性方法。在本文中，我们提出了一种新颖的生成框架——GenHMR，将单目HMR重新定义为条件于图像的生成任务，明确地对2D到3D映射过程中的不确定性建模并加以缓解。GenHMR 包含两个关键组件：（1）姿态编码器，用于将3D人类姿态转换为潜在空间中的离散标记序列；（2）图像条件掩码变压器，用于学习在输入图像提示以及随机掩码标记序列条件下姿态标记的概率分布。在推理过程中，模型从学习到的条件分布中采样，逐步解码高置信度的姿态标记，从而减少3D重构的不确定性。为了进一步细化重构结果，我们提出了一种基于2D姿态的细化技术，直接在潜在空间中微调解码的姿态标记，使投影的3D人体网格与2D姿态线索对齐。在基准数据集上的实验结果表明，GenHMR 显著优于现有最先进的方法。项目网站可通过以下链接访问：[此处的网址]', 'title_zh': 'GenHMR：生成式人体网格恢复\n\n注：此翻译既符合学术规范，也保留了原文的缩写形式。"Gen" 是 "Generative" 的缩写，意为生成式；"HMR" 是 "Human Mesh Recovery" 的缩写，意为人体网格恢复。'}
{'arxiv_id': 'arXiv:2412.14436', 'title': 'ORBIT: Cost-Effective Dataset Curation for Large Language Model Domain Adaptation with an Astronomy Case Study', 'authors': 'Eric Modesitt, Ke Yang, Spencer Hulsey, Chengxiang Zhai, Volodymyr Kindratenko', 'link': 'https://arxiv.org/abs/2412.14436', 'abstract': "Recent advances in language modeling demonstrate the need for high-quality domain-specific training data, especially for tasks that require specialized knowledge. General-purpose models, while versatile, often lack the depth needed for expert-level tasks because of limited domain-specific information. Domain adaptation training can enhance these models, but it demands substantial, high-quality data. To address this, we propose ORBIT, a cost-efficient methodology for curating massive, high-quality domain-specific datasets from noisy web sources, tailored for training specialist large language models. Using astronomy as a primary case study, we refined the 1.3T-token FineWeb-Edu dataset into a high-quality, 10B-token subset focused on astronomy. Fine-tuning \\textsc{LLaMA-3-8B} on a 1B-token astronomy subset improved performance on the MMLU astronomy benchmark from 69\\% to 76\\% and achieved top results on AstroBench, an astronomy-specific benchmark. Moreover, our model (Orbit-LLaMA) outperformed \\textsc{LLaMA-3-8B-base}, with GPT-4o evaluations preferring it in 73\\% of cases across 1000 astronomy-specific questions. Additionally, we validated ORBIT's generalizability by applying it to law and medicine, achieving a significant improvement of data quality compared to an unfiltered baseline. We open-source the ORBIT methodology, including the curated datasets, the codebase, and the resulting model at \\href{this https URL}{this https URL}.", 'abstract_zh': '近年来，语言模型的发展表明，特别是在需要专门知识的任务中，高质量的专业领域训练数据至关重要。通用模型虽然功能强大，但在处理专家级任务时常常缺乏必要的深度，因为缺乏特定领域的信息。领域适应训练可以增强这些模型，但需要大量的高质量数据。为此，我们提出了一种名为ORBIT的成本效益方法，用于从嘈杂的网络源中精心制作大规模高质量的专业领域数据集，以训练专业大型语言模型。以天文学作为主要案例研究，我们将1.3T标记的FineWeb-Edu数据集精炼为一个专注于天文学的高质量、100亿标记的子集。在10亿标记的天文学子集上微调\\textsc{LLaMA-3-8B}模型，使其在MMLU天文学基准测试中的性能从69%提高到76%，并在专门针对天文学的AstroBench基准测试中取得了最佳成绩。此外，我们的模型（Orbit-LLaMA）在天文学特定问题上优于\\textsc{LLaMA-3-8B-base}模型，在73%的情况下，GPT-4o评估更偏好它。我们进一步验证了ORBIT方法的通用性，将其应用于法律和医学领域，相较于未经筛选的基准数据，数据质量有了显著提高。我们已开源ORBIT方法，包括精心制作的数据集、代码库和模型，网址为\\href{此链接}{此链接}。', 'title_zh': 'ORBIT：用于大型语言模型领域适应的数据集整理成本效益方法：以天文学案例研究为例'}
{'arxiv_id': 'arXiv:2412.14435', 'title': 'Cherry-Picking in Time Series Forecasting: How to Select Datasets to Make Your Model Shine', 'authors': 'Luis Roque, Carlos Soares, Vitor Cerqueira, Luis Torgo', 'link': 'https://arxiv.org/abs/2412.14435', 'abstract': 'The importance of time series forecasting drives continuous research and the development of new approaches to tackle this problem. Typically, these methods are introduced through empirical studies that frequently claim superior accuracy for the proposed approaches. Nevertheless, concerns are rising about the reliability and generalizability of these results due to limitations in experimental setups. This paper addresses a critical limitation: the number and representativeness of the datasets used. We investigate the impact of dataset selection bias, particularly the practice of cherry-picking datasets, on the performance evaluation of forecasting methods. Through empirical analysis with a diverse set of benchmark datasets, our findings reveal that cherry-picking datasets can significantly distort the perceived performance of methods, often exaggerating their effectiveness. Furthermore, our results demonstrate that by selectively choosing just four datasets - what most studies report - 46% of methods could be deemed best in class, and 77% could rank within the top three. Additionally, recent deep learning-based approaches show high sensitivity to dataset selection, whereas classical methods exhibit greater robustness. Finally, our results indicate that, when empirically validating forecasting algorithms on a subset of the benchmarks, increasing the number of datasets tested from 3 to 6 reduces the risk of incorrectly identifying an algorithm as the best one by approximately 40%. Our study highlights the critical need for comprehensive evaluation frameworks that more accurately reflect real-world scenarios. Adopting such frameworks will ensure the development of robust and reliable forecasting methods.', 'abstract_zh': '时间序列预测的重要性促进了对该问题持续的研究与新的解决方法的发展。通常，这些方法是通过实证研究引入的，这些研究经常声称其提议的方法具有更优的准确性。然而，由于实验设置的局限性，人们对这些结果的可靠性和普适性产生了越来越多的质疑。本文探讨了一个关键限制因素：所使用的数据集的数量和代表性。我们研究了数据集选择偏差，尤其是数据集选择性使用的情况，对预测方法性能评估的影响。通过使用多样化的基准数据集进行实证分析，我们的发现表明，选择性使用数据集可能会显著扭曲方法的感知性能，往往夸大其效用。此外，我们的结果表明，在大多数研究中报告仅选择四个数据集的情况下，46%的方法可以被认定为最佳，而77%的方法可以排名前三。同时，我们的结果还显示，最近基于深度学习的方法对数据集选择的高度敏感性，而经典方法表现出更强的鲁棒性。最后，我们的结果表明，在使用部分基准数据集验证预测算法时，将测试的数据集数量从3增加到6，可以将错误地将一种算法识别为最佳算法的风险降低约40%。我们的研究突显了全面评估框架的至关重要性，这些框架能更准确地反映现实世界的情况。采用这样的评估框架将确保开发出稳健且可靠的预测方法。', 'title_zh': '时间序列预测中的数据集选择：如何挑选数据集使模型表现优异'}
{'arxiv_id': 'arXiv:2412.14426', 'title': 'All-in-One Tuning and Structural Pruning for Domain-Specific LLMs', 'authors': 'Lei Lu, Zhepeng Wang, Ruexue Bao, Mengbing Wang, Fangyi Li, Yawen Wu, Weiwen Jiang, Jie Xu, Yanzhi Wang, Shangqian Gao', 'link': 'https://arxiv.org/abs/2412.14426', 'abstract': 'Existing pruning techniques for large language models (LLMs) targeting domain-specific applications typically follow a two-stage process: pruning the pretrained general-purpose LLMs and then fine-tuning the pruned LLMs on specific domains. However, the pruning decisions, derived from the pretrained weights, remain unchanged during fine-tuning, even if the weights have been updated. Therefore, such a combination of the pruning decisions and the finetuned weights may be suboptimal, leading to non-negligible performance degradation. To address these limitations, we propose ATP: All-in-One Tuning and Structural Pruning, a unified one-stage structural pruning and fine-tuning approach that dynamically identifies the current optimal substructure throughout the fine-tuning phase via a trainable pruning decision generator. Moreover, given the limited available data for domain-specific applications, Low-Rank Adaptation (LoRA) becomes a common technique to fine-tune the LLMs. In ATP, we introduce LoRA-aware forward and sparsity regularization to ensure that the substructures corresponding to the learned pruning decisions can be directly removed after the ATP process. ATP outperforms the state-of-the-art two-stage pruning methods on tasks in the legal and healthcare domains. More specifically, ATP recovers up to 88% and 91% performance of the dense model when pruning 40% parameters of LLaMA2-7B and LLaMA3-8B models, respectively.', 'abstract_zh': '现有的针对特定领域应用的大语言模型（LLMs）的剪枝技术通常遵循一个两阶段过程：首先对预训练的一般目的LLM进行剪枝，然后在特定领域对其进行微调。然而，通过预训练权重得出的剪枝决策在微调过程中保持不变，即使权重已被更新。因此，这种将剪枝决策与微调权重结合起来的做法可能会导致非忽视性能下降。为了解决这些问题，我们提出了一种名为ATP（All-in-One Tuning and Structural Pruning）的统一方法，这是一种结合结构剪枝和微调的一站式方法，在整个微调过程中，通过可训练的剪枝决策生成器动态地识别当前最优子结构。此外，鉴于特定领域应用数据有限，低秩适应（LoRA）已成为一种常见的技术，用于对LLM进行微调。在ATP中，我们引入了LoRA感知的前向传播和稀疏正则化，以确保在ATP处理后，与学习到的剪枝决策对应的子结构可以直接被移除。实验结果表明，ATP在法律和医疗领域的任务上优于现有的两阶段剪枝方法。更具体地说，当修剪掉LLaMA2-7B和LLaMA3-8B模型40%的参数时，ATP分别将模型性能恢复到密集模型的88%和91%。', 'title_zh': '面向特定领域的大型语言模型的全方位调优与结构剪枝'}
{'arxiv_id': 'arXiv:2412.14424', 'title': 'FedPIA -- Permuting and Integrating Adapters leveraging Wasserstein Barycenters for Finetuning Foundation Models in Multi-Modal Federated Learning', 'authors': 'Pramit Saha, Divyanshu Mishra, Felix Wagner, Konstantinos Kamnitsas, J. Alison Noble', 'link': 'https://arxiv.org/abs/2412.14424', 'abstract': 'Large Vision-Language Models typically require large text and image datasets for effective fine-tuning. However, collecting data from various sites, especially in healthcare, is challenging due to strict privacy regulations. An alternative is to fine-tune these models on end-user devices, such as in medical clinics, without sending data to a server. These local clients typically have limited computing power and small datasets, which are not enough for fully fine-tuning large VLMs on their own. A naive solution to these scenarios is to leverage parameter-efficient fine-tuning (PEFT) strategies and apply federated learning (FL) algorithms to combine the learned adapter weights, thereby respecting the resource limitations and data privacy. However, this approach does not fully leverage the knowledge from multiple adapters trained on diverse data distributions and for diverse tasks. The adapters are adversely impacted by data heterogeneity and task heterogeneity across clients resulting in suboptimal convergence. To this end, we propose a novel framework called FedPIA that improves upon the naive combinations of FL and PEFT by introducing Permutation and Integration of the local Adapters in the server and global Adapters in the clients exploiting Wasserstein barycenters for improved blending of client-specific and client-agnostic knowledge. This layerwise permutation helps to bridge the gap in the parameter space of local and global adapters before integration. We conduct over 2000 client-level experiments utilizing 48 medical image datasets across five different medical vision-language FL task settings encompassing visual question answering as well as image and report-based multi-label disease detection. Our experiments involving diverse client settings, ten different modalities, and two VLM backbones demonstrate that FedPIA consistently outperforms the state-of-the-art PEFT-FL baselines.', 'abstract_zh': '大型多模态视觉-语言模型通常需要大量文本和图像数据集才能有效微调。然而，在医疗保健等领域收集数据极具挑战性，原因在于严格的隐私保护规定。一种替代方案是在终端用户设备上（例如在医疗诊所中）进行微调，而不将数据发送到服务器。这些本地客户端通常具有有限的计算能力和小的数据集，不足以独立完成大型多模态视觉-语言模型的完全微调。一种解决这些问题的简单方法是利用参数高效微调（PEFT）策略，并应用联邦学习（FL）算法将本地适配器权重整合起来，从而尊重资源限制和数据隐私。然而，这种方法并未充分利用在不同数据分布和不同任务上训练的多个适配器的知识。由于本地客户端间数据异质性和任务异质性对适配器产生负面影响，最终导致收敛效果不佳。为此，我们提出了一种名为FedPIA的新框架，它通过在服务器上引入局部适配器的排列和集成（Permutation and Integration of the local Adapters），以及在客户端引入全局适配器（global Adapters），并利用Wasserstein巴纳赫中心（Wasserstein barycenters）来进行改进的融合，从而克服了这一简单组合方法的局限。层级排列有助于在整合前弥合本地和全局适配器的参数空间差异。我们在五种不同的医疗视觉-语言联邦学习任务设置中使用48个医学图像数据集进行了超过2000次客户端级实验，涵盖了视觉问答以及基于图像和报告的多标签疾病检测。我们的实验结果表明，FedPIA在多种客户端设置、十种不同的模态和两种多模态视觉-语言模型（VLM）骨干网络下，始终优于现有的最先进参数高效微调-联邦学习基线。', 'title_zh': 'FedPIA —— 利用Wasserstein barycenters permute和集成适配器的多模态联邦学习基础模型微调方法'}
{'arxiv_id': 'arXiv:2412.14422', 'title': 'Enhancing Diffusion Models for High-Quality Image Generation', 'authors': 'Jaineet Shah, Michael Gromis, Rickston Pinto', 'link': 'https://arxiv.org/abs/2412.14422', 'abstract': 'This report presents the comprehensive implementation, evaluation, and optimization of Denoising Diffusion Probabilistic Models (DDPMs) and Denoising Diffusion Implicit Models (DDIMs), which are state-of-the-art generative models. During inference, these models take random noise as input and iteratively generate high-quality images as output. The study focuses on enhancing their generative capabilities by incorporating advanced techniques such as Classifier-Free Guidance (CFG), Latent Diffusion Models with Variational Autoencoders (VAE), and alternative noise scheduling strategies. The motivation behind this work is the growing demand for efficient and scalable generative AI models that can produce realistic images across diverse datasets, addressing challenges in applications such as art creation, image synthesis, and data augmentation. Evaluations were conducted on datasets including CIFAR-10 and ImageNet-100, with a focus on improving inference speed, computational efficiency, and image quality metrics like Frechet Inception Distance (FID). Results demonstrate that DDIM + CFG achieves faster inference and superior image quality. Challenges with VAE and noise scheduling are also highlighted, suggesting opportunities for future optimization. This work lays the groundwork for developing scalable, efficient, and high-quality generative AI systems to benefit industries ranging from entertainment to robotics.', 'abstract_zh': '本报告介绍了对去噪扩散概率模型（DDPMs）和去噪扩散隐式模型（DDIMs）的全面实现、评估与优化，这些模型是目前最先进的生成模型。在推理过程中，这些模型将随机噪声作为输入，并迭代生成高质量的图像输出。本研究的重点在于通过引入先进的技术，如无分类引导（Classifier-Free Guidance, CFG）、与变分自编码器（VAE）结合的隐空间扩散模型，以及不同的噪声调度策略来增强其生成能力。本研究的动机是为了解决在艺术创作、图像合成和数据增强等应用中对高效且可扩展的生成AI模型的需求，这些模型能够产生跨多种数据集的逼真图像。评估在CIFAR-10和ImageNet-100等数据集上进行，重点在于提高推理速度、计算效率以及图像质量指标（如FRECHET INCEPTION DISTANCE, FID）等方面。结果表明，DDIM + CFG在推理速度和图像质量上表现出色。此外，本研究还指出了VAE和噪声调度中的挑战，为未来优化提供了机会。本工作为进一步发展可扩展、高效和高质量的生成AI系统奠定了基础，这些系统将为娱乐、机器人技术等多个行业带来益处。', 'title_zh': '增强扩散模型以实现高质量图像生成'}
{'arxiv_id': 'arXiv:2412.14415', 'title': 'DriveGPT: Scaling Autoregressive Behavior Models for Driving', 'authors': 'Xin Huang, Eric M. Wolff, Paul Vernaza, Tung Phan-Minh, Hongge Chen, David S. Hayden, Mark Edmonds, Brian Pierce, Xinxin Chen, Pratik Elias Jacob, Xiaobai Chen, Chingiz Tairbekov, Pratik Agarwal, Tianshi Gao, Yuning Chai, Siddhartha Srinivasa', 'link': 'https://arxiv.org/abs/2412.14415', 'abstract': 'We present DriveGPT, a scalable behavior model for autonomous driving. We model driving as a sequential decision making task, and learn a transformer model to predict future agent states as tokens in an autoregressive fashion. We scale up our model parameters and training data by multiple orders of magnitude, enabling us to explore the scaling properties in terms of dataset size, model parameters, and compute. We evaluate DriveGPT across different scales in a planning task, through both quantitative metrics and qualitative examples including closed-loop driving in complex real-world scenarios. In a separate prediction task, DriveGPT outperforms a state-of-the-art baseline and exhibits improved performance by pretraining on a large-scale dataset, further validating the benefits of data scaling.', 'abstract_zh': '我们提出DriveGPT，一种可扩展的自主驾驶行为模型。我们将驾驶建模为一个序列决策任务，并采用变换器模型以自回归的方式预测未来代理状态。通过大幅提升模型参数和训练数据的数量级，我们能够探讨数据集规模、模型参数和计算资源在不同规模上的扩展性能。我们通过定量指标和定性示例，在规划任务的不同尺度上评估DriveGPT，包括在复杂真实场景中的闭环驾驶表现。在另一个预测任务中，DriveGPT超越了最先进的基线方法，并通过在大规模数据集上进行预训练显示出改进的性能，进一步验证了数据扩展带来的益处。', 'title_zh': 'DriveGPT: 扩展自回归行为模型在驾驶场景中的应用'}
{'arxiv_id': 'arXiv:2412.14384', 'title': 'I0T: Embedding Standardization Method Towards Zero Modality Gap', 'authors': 'Na Min An, Eunki Kim, James Thorne, Hyunjung Shim', 'link': 'https://arxiv.org/abs/2412.14384', 'abstract': 'Contrastive Language-Image Pretraining (CLIP) enables zero-shot inference in downstream tasks such as image-text retrieval and classification. However, recent works extending CLIP suffer from the issue of modality gap, which arises when the image and text embeddings are projected to disparate manifolds, deviating from the intended objective of image-text contrastive learning. We discover that this phenomenon is linked to the modality-specific characteristic that each image/text encoder independently possesses and propose two methods to address the modality gap: (1) a post-hoc embedding standardization method, $\\text{I0T}_{\\text{post}}$ that reduces the modality gap approximately to zero and (2) a trainable method, $\\text{I0T}_{\\text{async}}$, to alleviate the modality gap problem by adding two normalization layers for each encoder. Our I0T framework can significantly reduce the modality gap while preserving the original embedding representations of trained models with their locked parameters. In practice, $\\text{I0T}_{\\text{post}}$ can serve as an alternative explainable automatic evaluation metric of widely used CLIPScore (CLIP-S).', 'abstract_zh': '对比语言-图像预训练（CLIP）使零样本推理（zero-shot inference）成为可能，适用于图像-文本检索和分类等下游任务。然而，最近基于CLIP的扩展工作受到模态差距（modality gap）问题的影响，当图像嵌入和文本嵌入投影到不同的流形上时，就会出现该问题，这与希望实现的图像-文本对比学习目标背道而驰。我们发现这一现象与每个图像编码器和文本编码器各自具有的模态特定特性相关，并提出两种方法来解决模态差距问题：（1）一种后处理嵌入标准化方法$\\text{I0T}_{\\text{post}}$，大约将模态差距减少到零；（2）一种可训练方法$\\text{I0T}_{\\text{async}}$，通过为每个编码器添加两个规范化层来缓解模态差距问题。我们的I0T框架能够在保持训练模型锁定参数的原始嵌入表示的情况下显著减少模态差距。在实践中，$\\text{I0T}_{\\text{post}}$ 可以作为广泛使用的CLIPScore（CLIP-S）的一种替代的可解释自动评估指标。', 'title_zh': 'I0T: 面向零模态差距的标准化嵌入方法'}
{'arxiv_id': 'arXiv:2412.14366', 'title': 'Surrealistic-like Image Generation with Vision-Language Models', 'authors': 'Elif Ayten, Shuai Wang, Hjalmar Snoep', 'link': 'https://arxiv.org/abs/2412.14366', 'abstract': 'Recent advances in generative AI make it convenient to create different types of content, including text, images, and code. In this paper, we explore the generation of images in the style of paintings in the surrealism movement using vision-language generative models, including DALL-E, Deep Dream Generator, and DreamStudio. Our investigation starts with the generation of images under various image generation settings and different models. The primary objective is to identify the most suitable model and settings for producing such images. Additionally, we aim to understand the impact of using edited base images on the generated resulting images. Through these experiments, we evaluate the performance of selected models and gain valuable insights into their capabilities in generating such images. Our analysis shows that Dall-E 2 performs the best when using the generated prompt by ChatGPT.', 'abstract_zh': '近年来，生成式人工智能的进步使得创建不同类型的內容变得非常便利，包括文本、图像和代码。本文探讨了使用视觉-语言生成模型（包括DALL-E、Deep Dream Generator和DreamStudio）生成超现实主义风格绘画图像的可能性。我们的研究始于在各种图像生成设置和不同模型下生成图像的过程。主要目标是确定最适合生成此类图像的模型和设置。此外，我们还旨在了解使用编辑的基本图像对生成结果图像的影响。通过这些实验，我们评估了所选模型的性能，并获得了有关它们生成此类图像能力的宝贵见解。我们的分析表明，当使用由ChatGPT生成的提示时，Dall-E 2表现最佳。', 'title_zh': '使用视觉语言模型生成具象主义风格的图像'}
{'arxiv_id': 'arXiv:2412.14355', 'title': 'Enabling Realtime Reinforcement Learning at Scale with Staggered Asynchronous Inference', 'authors': 'Matthew Riemer, Gopeshh Subbaraj, Glen Berseth, Irina Rish', 'link': 'https://arxiv.org/abs/2412.14355', 'abstract': "Realtime environments change even as agents perform action inference and learning, thus requiring high interaction frequencies to effectively minimize regret. However, recent advances in machine learning involve larger neural networks with longer inference times, raising questions about their applicability in realtime systems where reaction time is crucial. We present an analysis of lower bounds on regret in realtime reinforcement learning (RL) environments to show that minimizing long-term regret is generally impossible within the typical sequential interaction and learning paradigm, but often becomes possible when sufficient asynchronous compute is available. We propose novel algorithms for staggering asynchronous inference processes to ensure that actions are taken at consistent time intervals, and demonstrate that use of models with high action inference times is only constrained by the environment's effective stochasticity over the inference horizon, and not by action frequency. Our analysis shows that the number of inference processes needed scales linearly with increasing inference times while enabling use of models that are multiple orders of magnitude larger than existing approaches when learning from a realtime simulation of Game Boy games such as Pokémon and Tetris.", 'abstract_zh': '实时环境在智能体执行动作推理和学习的过程中不断变化，因此需要较高的交互频率以有效减小遗憾。然而，最近的机器学习进展涉及更大的神经网络和更长的推理时间，这在实时系统中提出了关于反应时间至关重要的情况下其适用性的疑问。我们对实时强化学习（RL）环境中的遗憾下界进行了分析，表明在典型的顺序交互和学习范式中，通常无法减小长期遗憾，但在具有足够异步计算能力时，上述情况可以改变。我们提出了新颖的算法来协调异步推理过程，以确保动作在一致的时间间隔内执行，并证明高动作推理时间的模型仅受推理窗口内环境有效随机性的限制，而非动作频率的限制。我们的分析表明，所需推理过程的数量随推理时间的增加呈线性增长，同时，在从Game Boy游戏如 Pokémon 和 Tetris 的实时模拟中学习时，可以使用比现有方法大几个数量级的模型。\n\n请注意，我在此翻译中尽量保持了原文的学术规范和术语一致性。如需进一步优化或有特定术语的处理要求，请告知我。', 'title_zh': '大规模实时强化学习的梯次异步推理实现 방법'}
{'arxiv_id': 'arXiv:2412.14351', 'title': 'Is Peer-Reviewing Worth the Effort?', 'authors': 'Kenneth Church, Raman Chandrasekar, John E. Ortega, Ibrahim Said Ahmad', 'link': 'https://arxiv.org/abs/2412.14351', 'abstract': 'How effective is peer-reviewing in identifying important papers? We treat this question as a forecasting task. Can we predict which papers will be highly cited in the future based on venue and "early returns" (citations soon after publication)? We show early returns are more predictive than venue. Finally, we end with constructive suggestions to address scaling challenges: (a) too many submissions and (b) too few qualified reviewers.', 'abstract_zh': '同行评审在识别重要论文方面有多有效？我们将这个问题视为一个预测任务。我们能否基于会议和“早期反馈”（即在发表后不久的引用情况）预测哪些论文将来会被高度引用？我们发现“早期反馈”比会议本身更具预测性。最后，我们提出了一些建设性的建议，以应对扩展挑战：（a）投稿过多和（b）合格审稿人不足。', 'title_zh': '《peer-reviewing是否值得投入？》\n\n这个标题翻译成中文时，保持了原文的疑问句形式和学术探讨的意味。如果希望更加流畅，也可以表达为：\n\n《同行评审是否值得投入？》'}
{'arxiv_id': 'arXiv:2412.14340', 'title': 'A Unifying Information-theoretic Perspective on Evaluating Generative Models', 'authors': 'Alexis Fox, Samarth Swarup, Abhijin Adiga', 'link': 'https://arxiv.org/abs/2412.14340', 'abstract': 'Considering the difficulty of interpreting generative model output, there is significant current research focused on determining meaningful evaluation metrics. Several recent approaches utilize "precision" and "recall," borrowed from the classification domain, to individually quantify the output fidelity (realism) and output diversity (representation of the real data variation), respectively. With the increase in metric proposals, there is a need for a unifying perspective, allowing for easier comparison and clearer explanation of their benefits and drawbacks. To this end, we unify a class of kth-nearest-neighbors (kNN)-based metrics under an information-theoretic lens using approaches from kNN density estimation. Additionally, we propose a tri-dimensional metric composed of Precision Cross-Entropy (PCE), Recall Cross-Entropy (RCE), and Recall Entropy (RE), which separately measure fidelity and two distinct aspects of diversity, inter- and intra-class. Our domain-agnostic metric, derived from the information-theoretic concepts of entropy and cross-entropy, can be dissected for both sample- and mode-level analysis. Our detailed experimental results demonstrate the sensitivity of our metric components to their respective qualities and reveal undesirable behaviors of other metrics.', 'abstract_zh': '考虑到生成模型输出解读的复杂性，目前的研究重点在于确定有意义的评估指标。一些近期的方法借用分类领域的“精确率”和“召回率”来分别量化输出的真实性（现实感）和输出的多样性（真实数据变异性）。随着评估指标的不断增加，需要一个统一的视角，以便更容易地进行比较并清晰地解释其优缺点。为达到这一目的，我们通过从k近邻密度估计方法借鉴手段，从信息理论的角度统一了一类基于k近邻（kNN）的方法。此外，我们提出了一种三维的度量系统，包括精确率交叉熵（PCE）、召回率交叉熵（RCE）和召回率熵（RE），分别衡量真实性以及两类不同的多样性，即类间多样性和类内多样性。我们的领域无关性度量源自信息理论中的熵和交叉熵概念，可以从样本级和模式级进行分析。我们详细实验的结果表明了该度量系统各组成部分对其各自质量的敏感性，并揭示了其他度量系统的不良行为。', 'title_zh': '一个统一的信息理论视角下的生成模型评估框架'}
{'arxiv_id': 'arXiv:2412.14329', 'title': 'Embedding Cultural Diversity in Prototype-based Recommender Systems', 'authors': 'Armin Moradi, Nicola Neophytou, Florian Carichon, Golnoosh Farnadi', 'link': 'https://arxiv.org/abs/2412.14329', 'abstract': 'Popularity bias in recommender systems can increase cultural overrepresentation by favoring norms from dominant cultures and marginalizing underrepresented groups. This issue is critical for platforms offering cultural products, as they influence consumption patterns and human perceptions. In this work, we address popularity bias by identifying demographic biases within prototype-based matrix factorization methods. Using the country of origin as a proxy for cultural identity, we link this demographic attribute to popularity bias by refining the embedding space learning process. First, we propose filtering out irrelevant prototypes to improve representativity. Second, we introduce a regularization technique to enforce a uniform distribution of prototypes within the embedding space. Across four datasets, our results demonstrate a 27\\% reduction in the average rank of long-tail items and a 2\\% reduction in the average rank of items from underrepresented countries. Additionally, our model achieves a 2\\% improvement in HitRatio@10 compared to the state-of-the-art, highlighting that fairness is enhanced without compromising recommendation quality. Moreover, the distribution of prototypes leads to more inclusive explanations by better aligning items with diverse prototypes.', 'abstract_zh': '推荐系统中的流行度偏差可能会增加文化过度代表性，因为它倾向于 favor 主导文化的规范，而边缘化代表性不足的群体。这一问题对提供文化产品的平台尤为重要，因为这些平台会影响消费模式和人类感知。在本项工作中，我们通过在原型基矩阵分解方法中识别出人口统计学偏差来解决流行度偏差问题。使用国家或地区原产地作为文化身份的代理，我们通过细化嵌入空间学习过程将这一人口统计学属性与流行度偏差联系起来。首先，我们建议筛选掉无关的原型以提高代表性；其次，我们引入了一种正则化技术来确保嵌入空间中原型的均匀分布。在四个数据集中，我们的结果显示平均尾部项目的平均排名降低了27%，来自代表性不足国家的项目的平均排名降低了2%。此外，我们的模型在HitRatio@10上相比现有最佳方法提高了2%，这表明在不牺牲推荐质量的情况下提高了公平性。同时，原型的分布有助于提供更具包容性的解释，因为它们更好地与各类原型对齐。', 'title_zh': '将文化多样性嵌入原型推荐系统中'}
{'arxiv_id': 'arXiv:2412.14328', 'title': 'Semantic Role Labeling of NomBank Partitives', 'authors': 'Adam Meyers, Advait Pravin Savant, John E. Ortega', 'link': 'https://arxiv.org/abs/2412.14328', 'abstract': 'This article is about Semantic Role Labeling for English partitive nouns (5%/REL of the price/ARG1; The price/ARG1 rose 5 percent/REL) in the NomBank annotated corpus. Several systems are described using traditional and transformer-based machine learning, as well as ensembling. Our highest scoring system achieves an F1 of 91.74% using "gold" parses from the Penn Treebank and 91.12% when using the Berkeley Neural parser. This research includes both classroom and experimental settings for system development.', 'abstract_zh': '本文探讨了英语部分名词（例如：5%/REL of the price/ARG1；价格/ARG1上升了5个百分点/REL）的语义角色标注问题，这些名词来源于NomBank标注语料库。文中描述了使用传统机器学习方法与基于Transformer的方法进行系统构建，并采用了集成学习技术。我们的最高评分系统在使用Penn Treebank的“金标准”解析时，F1分数达到了91.74%，而在使用伯克利神经解析器时，F1分数则为91.12%。本研究不仅涵盖了课堂环境下的系统开发，还包括了实验环境。', 'title_zh': 'NomBank 部分构造的语义角色标注'}
{'arxiv_id': 'arXiv:2412.14323', 'title': 'The Role of Handling Attributive Nouns in Improving Chinese-To-English Machine Translation', 'authors': 'Haohao, Wang, Adam Meyers, John E. Ortega, Rodolfo Zevallos', 'link': 'https://arxiv.org/abs/2412.14323', 'abstract': "Translating between languages with drastically different grammatical conventions poses challenges, not just for human interpreters but also for machine translation systems. In this work, we specifically target the translation challenges posed by attributive nouns in Chinese, which frequently cause ambiguities in English translation. By manually inserting the omitted particle X ('DE'). In news article titles from the Penn Chinese Discourse Treebank, we developed a targeted dataset to fine-tune Hugging Face Chinese to English translation models, specifically improving how this critical function word is handled. This focused approach not only complements the broader strategies suggested by previous studies but also offers a practical enhancement by specifically addressing a common error type in Chinese-English translation.", 'abstract_zh': '将语法规范差异巨大的语言进行互译会带来挑战，这不仅对人类口译员构成挑战，也对机器翻译系统构成挑战。在本研究中，我们特别关注中文限定词带来的翻译挑战，这些限定词在英文翻译中经常导致语义模糊。通过手动插入被省略的词汇“的”（X），在宾夕法尼亚中文语篇树库（Penn Chinese Discourse Treebank）的新闻文章标题中，我们开发了一个专门的数据集，以微调Hugging Face的中文到英文翻译模型，特别是改进了对这一关键功能词的处理方式。这种集中方法不仅补充了以前研究中提出的更广泛策略，还通过具体解决中文到英文翻译中的常见错误类型提供了实际改进。', 'title_zh': '改善中文到英文机器翻译中属性名词处理的作用'}
{'arxiv_id': 'arXiv:2412.14304', 'title': 'Multi-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing LLM Ophthalmological QA in LMICs', 'authors': 'David Restrepo, Chenwei Wu, Zhengxu Tang, Zitao Shuai, Thao Nguyen Minh Phan, Jun-En Ding, Cong-Tinh Dao, Jack Gallifant, Robyn Gayle Dychiao, Jose Carlo Artiaga, André Hiroshi Bando, Carolina Pelegrini Barbosa Gracitelli, Vincenz Ferrer, Leo Anthony Celi, Danielle Bitterman, Michael G Morley, Luis Filipe Nakayama', 'link': 'https://arxiv.org/abs/2412.14304', 'abstract': 'Current ophthalmology clinical workflows are plagued by over-referrals, long waits, and complex and heterogeneous medical records. Large language models (LLMs) present a promising solution to automate various procedures such as triaging, preliminary tests like visual acuity assessment, and report summaries. However, LLMs have demonstrated significantly varied performance across different languages in natural language question-answering tasks, potentially exacerbating healthcare disparities in Low and Middle-Income Countries (LMICs). This study introduces the first multilingual ophthalmological question-answering benchmark with manually curated questions parallel across languages, allowing for direct cross-lingual comparisons. Our evaluation of 6 popular LLMs across 7 different languages reveals substantial bias across different languages, highlighting risks for clinical deployment of LLMs in LMICs. Existing debiasing methods such as Translation Chain-of-Thought or Retrieval-augmented generation (RAG) by themselves fall short of closing this performance gap, often failing to improve performance across all languages and lacking specificity for the medical domain. To address this issue, We propose CLARA (Cross-Lingual Reflective Agentic system), a novel inference time de-biasing method leveraging retrieval augmented generation and self-verification. Our approach not only improves performance across all languages but also significantly reduces the multilingual bias gap, facilitating equitable LLM application across the globe.', 'abstract_zh': '当前的眼科临床工作流程受到过度转诊、长时间等待和复杂不均一医疗记录的困扰。大规模语言模型（LLMs）为自动化分流、初步测试（如视力评估）以及报告总结等各类程序提供了前景广阔的方法。然而，LLMs在自然语言问答任务中表现出显著的语言差异性，这可能导致在低收入和中等收入国家（LMICs）中加剧卫生保健不平等现象。本研究引入了首个使用人工精选并行多语言问题的数据集，以便直接进行跨语言比较。我们在7种不同语言上对6种流行的LLMs进行评估，发现存在显著的语言偏差，突显了在LMICs中部署LLMs所面临的风险。现有的去偏措施，如翻译链式思考或检索增强生成（RAG），单独来看不足以弥补这些性能差距，通常未能在所有语言上提升性能，并且缺乏针对医学领域的特异性。为解决这一问题，我们提出了一种新颖的推理时去偏方法CLARA（跨语言反思代理系统），利用检索增强生成和自我验证。我们的方法不仅在所有语言上提高了性能，还显著减少了多语言偏差差距，有助于在全球范围内实现LLMs的公平应用。', 'title_zh': '多语眼科语言：面向低收入和中等收入国家的LLM眼科QA评估与去偏见基准'}
{'arxiv_id': 'arXiv:2412.14302', 'title': 'SAFERec: Self-Attention and Frequency Enriched Model for Next Basket Recommendation', 'authors': 'Oleg Lashinin, Denis Krasilnikov, Aleksandr Milogradskii, Marina Ananyeva', 'link': 'https://arxiv.org/abs/2412.14302', 'abstract': 'Transformer-based approaches such as BERT4Rec and SASRec demonstrate strong performance in Next Item Recommendation (NIR) tasks. However, applying these architectures to Next-Basket Recommendation (NBR) tasks, which often involve highly repetitive interactions, is challenging due to the vast number of possible item combinations in a basket. Moreover, frequency-based methods such as TIFU-KNN and UP-CF still demonstrate strong performance in NBR tasks, frequently outperforming deep-learning approaches. This paper introduces SAFERec, a novel algorithm for NBR that enhances transformer-based architectures from NIR by incorporating item frequency information, consequently improving their applicability to NBR tasks. Extensive experiments on multiple datasets show that SAFERec outperforms all other baselines, specifically achieving an 8\\% improvement in Recall@10.', 'abstract_zh': '基于Transformer的方法，如BERT4Rec和SASRec，在Next Item Recommendation (NIR)任务中表现出强大的性能。然而，将这些架构应用到Next-Basket Recommendation (NBR)任务中存在挑战，因为篮子中的可能物品组合数量巨大，且NBR任务通常涉及高度重复的互动。此外，基于频率的方法，如TIFU-KNN和UP-CF，在NBR任务中仍然表现出强大的性能，经常优于深度学习方法。本文提出了一种名为SAFERec的新算法，该算法通过整合项目频率信息来增强NIR中的Transformer架构，从而提高了其在NBR任务中的适用性。在多个数据集上的广泛实验表明，SAFERec在所有基线方法中表现最佳，特别是在Recall@10上提高了8%。', 'title_zh': 'SAFTERec: 自注意力与频次增强的篮子推荐模型'}
{'arxiv_id': 'arXiv:2412.14295', 'title': 'Temporally Consistent Object-Centric Learning by Contrasting Slots', 'authors': 'Anna Manasyan, Maximilian Seitzer, Filip Radovic, Georg Martius, Andrii Zadaianchuk', 'link': 'https://arxiv.org/abs/2412.14295', 'abstract': 'Unsupervised object-centric learning from videos is a promising approach to extract structured representations from large, unlabeled collections of videos. To support downstream tasks like autonomous control, these representations must be both compositional and temporally consistent. Existing approaches based on recurrent processing often lack long-term stability across frames because their training objective does not enforce temporal consistency. In this work, we introduce a novel object-level temporal contrastive loss for video object-centric models that explicitly promotes temporal consistency. Our method significantly improves the temporal consistency of the learned object-centric representations, yielding more reliable video decompositions that facilitate challenging downstream tasks such as unsupervised object dynamics prediction. Furthermore, the inductive bias added by our loss strongly improves object discovery, leading to state-of-the-art results on both synthetic and real-world datasets, outperforming even weakly-supervised methods that leverage motion masks as additional cues.', 'abstract_zh': '无监督的对象中心学习是从大型未标记视频集合中提取结构化表示的一种有前途的方法。为了支持诸如自主控制之类的下游任务，这些表示必须既具有组合性又具有时间一致性。现有基于循环处理的方法往往在帧间缺乏长期稳定，因为其训练目标并未强制执行时间一致性。在本文中，我们提出了一种新颖的对象级别时间对比损失，用于视频对象中心模型，该损失明确促进了时间一致性。我们的方法显著提高了所学对象中心表示的时间一致性，从而提供了更可靠的视频分解，便于处理诸如无监督对象动力学预测之类的具有挑战性的下游任务。此外，通过我们的损失增加的归纳偏差在对象发现方面表现出显著改进，在合成和实际数据集上均达到了领先的结果，甚至超越了依赖于运动蒙版等附加提示的弱监督方法。', 'title_zh': '时空一致的以对象为中心的学习通过对比槽位'}
{'arxiv_id': 'arXiv:2412.14283', 'title': 'PixelMan: Consistent Object Editing with Diffusion Models via Pixel Manipulation and Generation', 'authors': 'Liyao Jiang, Negar Hassanpour, Mohammad Salameh, Mohammadreza Samadi, Jiao He, Fengyu Sun, Di Niu', 'link': 'https://arxiv.org/abs/2412.14283', 'abstract': 'Recent research explores the potential of Diffusion Models (DMs) for consistent object editing, which aims to modify object position, size, and composition, etc., while preserving the consistency of objects and background without changing their texture and attributes. Current inference-time methods often rely on DDIM inversion, which inherently compromises efficiency and the achievable consistency of edited images. Recent methods also utilize energy guidance which iteratively updates the predicted noise and can drive the latents away from the original image, resulting in distortions. In this paper, we propose PixelMan, an inversion-free and training-free method for achieving consistent object editing via Pixel Manipulation and generation, where we directly create a duplicate copy of the source object at target location in the pixel space, and introduce an efficient sampling approach to iteratively harmonize the manipulated object into the target location and inpaint its original location, while ensuring image consistency by anchoring the edited image to be generated to the pixel-manipulated image as well as by introducing various consistency-preserving optimization techniques during inference. Experimental evaluations based on benchmark datasets as well as extensive visual comparisons show that in as few as 16 inference steps, PixelMan outperforms a range of state-of-the-art training-based and training-free methods (usually requiring 50 steps) on multiple consistent object editing tasks.', 'abstract_zh': '近年来的研究探索了差分模型（DMs）在一致对象编辑中的潜力，旨在修改对象的位置、大小和组成等，同时保持对象及其背景的一致性，而不改变它们的纹理和属性。当前的推理方法通常依赖于DDIM逆运算，这本身就牺牲了效率和编辑图像的一致性。最近的方法还利用能量引导机制，通过迭代更新预测噪声来驱动潜在变量远离原始图像，从而导致失真。在这项研究中，我们提出了一种名为PixelMan的方法，这是一种无逆运算和无需训练的方法，通过像素操纵和生成实现一致的对象编辑。PixelMan直接在像素空间中创建一个源对象的副本，并在目标位置处引入一种高效采样方法，以迭代方式将操纵对象融入目标位置，并修复其原始位置，通过将生成的编辑图像锚定到像素操纵图像，并引入各种一致性的保留优化技术，从而确保图像一致性。基于基准数据集的实验评估以及广泛的视觉对比显示，在仅16次推理步骤后，PixelMan在多个一致对象编辑任务上优于多种最新的基于训练和无需训练的方法（通常需要50次步骤）。', 'title_zh': 'PixelMan：通过像素操作与生成一致对象编辑的_diffusion模型方法'}
{'arxiv_id': 'arXiv:2412.14276', 'title': 'Fake News Detection: Comparative Evaluation of BERT-like Models and Large Language Models with Generative AI-Annotated Data', 'authors': 'haina Raza, Drai Paulen-Patterson, Chen Ding', 'link': 'https://arxiv.org/abs/2412.14276', 'abstract': 'Fake news poses a significant threat to public opinion and social stability in modern society. This study presents a comparative evaluation of BERT-like encoder-only models and autoregressive decoder-only large language models (LLMs) for fake news detection. We introduce a dataset of news articles labeled with GPT-4 assistance (an AI-labeling method) and verified by human experts to ensure reliability. Both BERT-like encoder-only models and LLMs were fine-tuned on this dataset. Additionally, we developed an instruction-tuned LLM approach with majority voting during inference for label generation. Our analysis reveals that BERT-like models generally outperform LLMs in classification tasks, while LLMs demonstrate superior robustness against text perturbations. Compared to weak labels (distant supervision) data, the results show that AI labels with human supervision achieve better classification results. This study highlights the effectiveness of combining AI-based annotation with human oversight and demonstrates the performance of different families of machine learning models for fake news detection', 'abstract_zh': '虚假信息对现代社会的公共意见和社会稳定构成重大威胁。本研究对比评估了BERT样式的编码器-only模型与自回归解码器-only大型语言模型（LLMs）在虚假信息检测中的表现。我们引入了一个由GPT-4辅助标注并由人类专家验证的数据集（一种AI标注方法），以确保其可靠性。两个模型都被在这个数据集上进行了微调。此外，我们还开发了一种在推理时采用多数投票的指令调优LLM方法，用于生成标签。我们的分析表明，BERT样式的模型在分类任务中的表现通常优于LLMs，而LLMs对文本扰动具有更好的稳健性。与弱标签（远监督）数据相比，结果表明，带有监督的人工智能标签在分类任务中表现更好。本研究强调了结合基于AI的注释与人工监督的有效性，并展示了不同类型的机器学习模型在虚假信息检测中的性能。', 'title_zh': '假新闻检测：BERT类模型与生成式AI标注数据的大型语言模型的比较评估'}
{'arxiv_id': 'arXiv:2412.14272', 'title': 'Split Learning in Computer Vision for Semantic Segmentation Delay Minimization', 'authors': 'Nikos G. Evgenidis, Nikos A. Mitsiou, Sotiris A. Tegos, Panagiotis D. Diamantoulakis, George K. Karagiannidis', 'link': 'https://arxiv.org/abs/2412.14272', 'abstract': "In this paper, we propose a novel approach to minimize the inference delay in semantic segmentation using split learning (SL), tailored to the needs of real-time computer vision (CV) applications for resource-constrained devices. Semantic segmentation is essential for applications such as autonomous vehicles and smart city infrastructure, but faces significant latency challenges due to high computational and communication loads. Traditional centralized processing methods are inefficient for such scenarios, often resulting in unacceptable inference delays. SL offers a promising alternative by partitioning deep neural networks (DNNs) between edge devices and a central server, enabling localized data processing and reducing the amount of data required for transmission. Our contribution includes the joint optimization of bandwidth allocation, cut layer selection of the edge devices' DNN, and the central server's processing resource allocation. We investigate both parallel and serial data processing scenarios and propose low-complexity heuristic solutions that maintain near-optimal performance while reducing computational requirements. Numerical results show that our approach effectively reduces inference delay, demonstrating the potential of SL for improving real-time CV applications in dynamic, resource-constrained environments.", 'abstract_zh': '在本文中，我们提出了一种新颖的方法，利用分裂学习（SL）来最小化基于语义分割的推理延迟，以满足资源受限设备中实时计算机视觉（CV）应用的需求。语义分割对于自动驾驶车辆和智慧城市基础设施等应用至关重要，但由于高计算和通信负载，它面临显著的延迟挑战。传统的集中式处理方法在这种场景中效率较低，往往会导致无法接受的推理延迟。SL通过在边缘设备和中央服务器之间划分深度神经网络（DNN），实现了局部数据处理，并减少了传输所需的数据量，提供了一种有前景的替代方案。我们的贡献包括对带宽分配、边缘设备DNN的切分层选择以及中央服务器处理资源分配的联合优化。我们研究了并行和串行数据处理场景，并提出了低复杂度启发式解决方案，能够在减少计算需求的同时保持接近最优的性能。数值结果表明，我们的方法有效减少了推理延迟，展示了SL在动态、资源受限环境中改进实时CV应用的潜在能力。', 'title_zh': '计算机视觉中的一种分割学习方法，用于最小化语义分割延迟'}
{'arxiv_id': 'arXiv:2412.14234', 'title': 'Syzygy: Dual Code-Test C to (safe) Rust Translation using LLMs and Dynamic Analysis', 'authors': 'Manish Shetty, Naman Jain, Adwait Godbole, Sanjit A. Seshia, Koushik Sen', 'link': 'https://arxiv.org/abs/2412.14234', 'abstract': 'Despite extensive usage in high-performance, low-level systems programming applications, C is susceptible to vulnerabilities due to manual memory management and unsafe pointer operations. Rust, a modern systems programming language, offers a compelling alternative. Its unique ownership model and type system ensure memory safety without sacrificing performance.\nIn this paper, we present Syzygy, an automated approach to translate C to safe Rust. Our technique uses a synergistic combination of LLM-driven code and test translation guided by dynamic-analysis-generated execution information. This paired translation runs incrementally in a loop over the program in dependency order of the code elements while maintaining per-step correctness. Our approach exposes novel insights on combining the strengths of LLMs and dynamic analysis in the context of scaling and combining code generation with testing. We apply our approach to successfully translate Zopfli, a high-performance compression library with ~3000 lines of code and 98 functions. We validate the translation by testing equivalence with the source C program on a set of inputs. To our knowledge, this is the largest automated and test-validated C to safe Rust code translation achieved so far.', 'abstract_zh': '尽管C语言在高性能和低级系统编程应用中被广泛应用，但由于手动内存管理和不安全的指针操作，C语言容易出现漏洞。作为一种现代系统编程语言，Rust提供了一个引人注目的替代方案。它的独特所有者模型和类型系统能够在不牺牲性能的情况下确保内存安全。\n\n在本文中，我们提出了一种自动将C语言转换为安全Rust语言的方法——Syzygy。我们的方法结合了由LLM驱动的代码和由动态分析生成的执行信息引导的测试转换。这种配对的转换在依赖关系顺序下增量地循环运行于程序中的代码元素上，并且每一步都保持正确性。我们的方法展示了结合LLM和动态分析的优势，特别是在扩展和结合代码生成与测试方面的新颖见解。我们应用这种方法成功地将Zopfli（一个具有约3000行代码和98个函数的高性能压缩库）转换为安全Rust语言。我们通过对一组输入进行测试来验证转换的等效性。据我们所知，这是迄今为止实现的最大规模的自动且通过测试验证的C语言到安全Rust语言的转换。', 'title_zh': '同步性：使用大语言模型和动态分析的对偶代码-测试C到安全Rust的翻译'}
{'arxiv_id': 'arXiv:2412.14219', 'title': 'A Survey on Inference Optimization Techniques for Mixture of Experts Models', 'authors': 'Jiacheng Liu, Peng Tang, Wenfeng Wang, Yuhang Ren, Xiaofeng Hou, Pheng-Ann Heng, Minyi Guo, Chao Li', 'link': 'https://arxiv.org/abs/2412.14219', 'abstract': 'The emergence of large-scale Mixture of Experts (MoE) models has marked a significant advancement in artificial intelligence, offering enhanced model capacity and computational efficiency through conditional computation. However, the deployment and inference of these models present substantial challenges in terms of computational resources, latency, and energy efficiency. This comprehensive survey systematically analyzes the current landscape of inference optimization techniques for MoE models across the entire system stack. We first establish a taxonomical framework that categorizes optimization approaches into model-level, system-level, and hardware-level optimizations. At the model level, we examine architectural innovations including efficient expert design, attention mechanisms, various compression techniques such as pruning, quantization, and knowledge distillation, as well as algorithm improvement including dynamic routing strategies and expert merging methods. At the system level, we investigate distributed computing approaches, load balancing mechanisms, and efficient scheduling algorithms that enable scalable deployment. Furthermore, we delve into hardware-specific optimizations and co-design strategies that maximize throughput and energy efficiency. This survey not only provides a structured overview of existing solutions but also identifies key challenges and promising research directions in MoE inference optimization. Our comprehensive analysis serves as a valuable resource for researchers and practitioners working on large-scale deployment of MoE models in resource-constrained environments. To facilitate ongoing updates and the sharing of cutting-edge advances in MoE inference optimization research, we have established a repository accessible at \\url{this https URL}.', 'abstract_zh': '大规模专家混合（MoE）模型的出现标志着人工智能领域取得了重要的进步，通过条件计算提高模型容量和计算效率。然而，这些模型的部署和推理在计算资源、延迟和能效方面提出了重大挑战。本文综述系统地分析了从整个系统堆栈角度出发的MoE模型推理优化技术。我们首先建立了一个分类框架，将优化方法分为模型级、系统级和硬件级优化。在模型级上，我们探讨了包括高效专家设计、注意力机制、各种压缩技术（如剪枝、量化和知识蒸馏）以及算法改进（如动态路由策略和专家合并方法）。在系统级上，我们研究了分布式计算方法、负载均衡机制和高效的调度算法，使其能够实现可扩展的部署。此外，我们还探讨了针对特定硬件的优化和协同设计策略，以最大化吞吐量和能效。本文不仅提供了现有解决方案的结构化概述，还指出了MoE推理优化中的关键挑战和有前途的研究方向。我们的综合分析为在资源受限环境中部署大型MoE模型的研究人员和实践者提供了宝贵的资源。为了促进持续更新并分享MoE推理优化研究领域的前沿进展，我们建立了一个可访问的仓库，网址为 \\url{this https URL}。', 'title_zh': '混合专家模型推理优化技术综述'}
{'arxiv_id': 'arXiv:2412.14218', 'title': 'Heterogeneous Multi-Agent Reinforcement Learning for Distributed Channel Access in WLANs', 'authors': 'Jiaming Yu, Le Liang, Chongtao Guo, Ziyang Guo, Shi Jin, Geoffrey Ye Li', 'link': 'https://arxiv.org/abs/2412.14218', 'abstract': 'This paper investigates the use of multi-agent reinforcement learning (MARL) to address distributed channel access in wireless local area networks. In particular, we consider the challenging yet more practical case where the agents heterogeneously adopt value-based or policy-based reinforcement learning algorithms to train the model. We propose a heterogeneous MARL training framework, named QPMIX, which adopts a centralized training with distributed execution paradigm to enable heterogeneous agents to collaborate. Moreover, we theoretically prove the convergence of the proposed heterogeneous MARL method when using the linear value function approximation. Our method maximizes the network throughput and ensures fairness among stations, therefore, enhancing the overall network performance. Simulation results demonstrate that the proposed QPMIX algorithm improves throughput, mean delay, delay jitter, and collision rates compared with conventional carrier-sense multiple access with collision avoidance in the saturated traffic scenario. Furthermore, the QPMIX is shown to be robust in unsaturated and delay-sensitive traffic scenarios, and promotes cooperation among heterogeneous agents.', 'abstract_zh': '本文探讨了多智能体强化学习（MARL）在无线局域网中解决分布式信道访问问题的应用。特别是，我们考虑了更具有挑战性且更具实用性的案例，即智能体异构地采用基于值或基于策略的强化学习算法进行模型训练。我们提出了一种名为QPMIX的异构MARL训练框架，该框架采用了集中式训练与分布式执行的模式，以支持异构智能体之间的协作。此外，我们理论证明了在使用线性价值函数近似时，所提出的方法的收敛性。该方法最大化了网络吞吐量并确保了站间的公平性，从而增强了整体网络性能。仿真结果表明，在饱和流量场景下，所提出的QPMIX算法在吞吐量、平均延迟、延迟抖动和碰撞率方面均优于传统的载波侦听多址访问/冲突避免（CSMA/CA）。此外，在非饱和和延迟敏感的流量场景中，QPMIX算法显示出较强的鲁棒性，并促进了异构智能体之间的合作。', 'title_zh': '异构多代理强化学习在无线局域网中分布式信道访问中的应用'}
{'arxiv_id': 'arXiv:2412.14215', 'title': 'Generative AI Toolkit -- a framework for increasing the quality of LLM-based applications over their whole life cycle', 'authors': 'Jens Kohl, Luisa Gloger, Rui Costa, Otto Kruse, Manuel P. Luitz, David Katz, Gonzalo Barbeito, Markus Schweier, Ryan French, Jonas Schroeder, Thomas Riedl, Raphael Perri, Youssef Mostafa', 'link': 'https://arxiv.org/abs/2412.14215', 'abstract': 'As LLM-based applications reach millions of customers, ensuring their scalability and continuous quality improvement is critical for success. However, the current workflows for developing, maintaining, and operating (DevOps) these applications are predominantly manual, slow, and based on trial-and-error. With this paper we introduce the Generative AI Toolkit, which automates essential workflows over the whole life cycle of LLM-based applications. The toolkit helps to configure, test, continuously monitor and optimize Generative AI applications such as agents, thus significantly improving quality while shortening release cycles. We showcase the effectiveness of our toolkit on representative use cases, share best practices, and outline future enhancements. Since we are convinced that our Generative AI Toolkit is helpful for other teams, we are open sourcing it on and hope that others will use, forward, adapt and improve', 'abstract_zh': '随着基于大语言模型（LLM）的应用程序用户数量达到数百万，确保它们的可扩展性和持续的质量改进对于成功至关重要。然而，目前开发、维护和运行（DevOps）这些应用程序的工作流程大多是手工的、速度慢且依赖于试错。本文介绍了一种生成式人工智能工具包，该工具包在整个生命周期中自动化了基于大语言模型的应用程序的关键工作流程。该工具包有助于配置、测试、连续监控和优化生成式人工智能应用程序，如代理，从而显著提高质量并缩短发布周期。我们通过代表性用例展示了该工具包的有效性，分享了最佳实践，并概述了未来的增强措施。由于我们相信该生成式人工智能工具包对其他团队也会很有帮助，我们将其开源，并希望其他团队能够将其用于进一步的发展、适应和改进。', 'title_zh': '生成式AI工具包——一种在整个生命周期内提高基于LLM的应用质量的框架'}
{'arxiv_id': 'arXiv:2412.14214', 'title': 'GraphicsDreamer: Image to 3D Generation with Physical Consistency', 'authors': 'Pei Chen, Fudong Wang, Yixuan Tong, Jingdong Chen, Ming Yang, Minghui Yang', 'link': 'https://arxiv.org/abs/2412.14214', 'abstract': "Recently, the surge of efficient and automated 3D AI-generated content (AIGC) methods has increasingly illuminated the path of transforming human imagination into complex 3D structures. However, the automated generation of 3D content is still significantly lags in industrial application. This gap exists because 3D modeling demands high-quality assets with sharp geometry, exquisite topology, and physically based rendering (PBR), among other criteria. To narrow the disparity between generated results and artists' expectations, we introduce GraphicsDreamer, a method for creating highly usable 3D meshes from single images. To better capture the geometry and material details, we integrate the PBR lighting equation into our cross-domain diffusion model, concurrently predicting multi-view color, normal, depth images, and PBR materials. In the geometry fusion stage, we continue to enforce the PBR constraints, ensuring that the generated 3D objects possess reliable texture details, supporting realistic relighting. Furthermore, our method incorporates topology optimization and fast UV unwrapping capabilities, allowing the 3D products to be seamlessly imported into graphics engines. Extensive experiments demonstrate that our model can produce high quality 3D assets in a reasonable time cost compared to previous methods.", 'abstract_zh': '近年来，高效且自动化的3D人工智能生成内容（AIGC）方法的涌现日益照亮了将人类想象力转换为复杂3D结构的道路。然而，3D内容的自动化生成在工业应用中仍然显著滞后。这种差距的存在是因为3D建模需要高质量的资产，包括锐利的几何形状、精致的拓扑结构以及基于物理的渲染（PBR），以及其他标准。为了缩小生成结果与艺术家预期之间的差距，我们提出了一种名为GraphicsDreamer的方法，用于从单张图像创建高度实用的3D网格。为了更好地捕捉几何和材料细节，我们将PBR照明方程整合到跨领域扩散模型中，同时预测多视角的颜色、法线、深度图像和PBR材料。在几何融合阶段，我们继续施加PBR约束，以确保生成的3D对象具有可靠的纹理细节，支持现实的重新光照。此外，我们的方法还集成了拓扑优化和快速UV展开能力，使得3D产品能够无缝导入图形引擎。广泛的实验结果表明，与之前的方法相比，我们的模型可以在合理的时间成本下生成高质量的3D资产。', 'title_zh': 'GraphicsDreamer：具有物理一致性的从图像生成3D模型'}
{'arxiv_id': 'arXiv:2412.14212', 'title': 'Tree-of-Code: A Hybrid Approach for Robust Complex Task Planning and Execution', 'authors': 'Ziyi Ni, Yifan Li, Daxiang Dong', 'link': 'https://arxiv.org/abs/2412.14212', 'abstract': "The exceptional capabilities of large language models (LLMs) have substantially accelerated the rapid rise and widespread adoption of agents. Recent studies have demonstrated that generating Python code to consolidate LLM-based agents' actions into a unified action space (CodeAct) is a promising approach for developing real-world LLM agents. However, this step-by-step code generation approach often lacks consistency and robustness, leading to instability in agent applications, particularly for complex reasoning and out-of-domain tasks. In this paper, we propose a novel approach called Tree-of-Code (ToC) to tackle the challenges of complex problem planning and execution with an end-to-end mechanism. By integrating key ideas from both Tree-of-Thought and CodeAct, ToC combines their strengths to enhance solution exploration. In our framework, each final code execution result is treated as a node in the decision tree, with a breadth-first search strategy employed to explore potential solutions. The final outcome is determined through a voting mechanism based on the outputs of the nodes.", 'abstract_zh': '大型语言模型（LLMs）的卓越能力显著加速了基于代理的快速崛起和广泛采用。近期的研究表明，通过生成Python代码将基于LLM代理的动作整合到统一的动作空间（CodeAct）是一种有前景的方法，用于开发实际应用中的LLM代理。然而，这种逐步代码生成的方法往往缺乏一致性和稳健性，导致代理应用的稳定性下降，特别是在复杂推理和跨领域任务中更为明显。本文提出了一种名为Tree-of-Code（ToC）的新型方法，通过端到端的机制来应对复杂问题规划和执行中的挑战。ToC通过整合来自Tree-of-Thought和CodeAct的关键思想，综合了它们的优势，增强了解决方案的探索。在我们的框架中，每个最终代码执行结果被视为决策树中的一个节点，采用广度优先搜索策略来探索潜在解决方案。最终结果通过节点输出的投票机制来确定。', 'title_zh': '树形代码：稳健复杂任务规划与执行的混合方法'}
{'arxiv_id': 'arXiv:2412.14209', 'title': 'Integrating Evidence into the Design of XAI and AI-based Decision Support Systems: A Means-End Framework for End-users in Construction', 'authors': 'Peter .E.D. Love, Jane Matthews, Weili Fang, Hadi Mahamivanan', 'link': 'https://arxiv.org/abs/2412.14209', 'abstract': "A narrative review is used to develop a theoretical evidence-based means-end framework to build an epistemic foundation to uphold explainable artificial intelligence instruments so that the reliability of outcomes generated from decision support systems can be assured and better explained to end-users. The implications of adopting an evidence-based approach to designing decision support systems in construction are discussed with emphasis placed on evaluating the strength, value, and utility of evidence needed to develop meaningful human explanations for end-users. While the developed means-end framework is focused on end-users, stakeholders can also utilize it to create meaningful human explanations. However, they will vary due to their different epistemic goals. Including evidence in the design and development of explainable artificial intelligence and decision support systems will improve decision-making effectiveness, enabling end-users' epistemic goals to be achieved. The proposed means-end framework is developed from a broad spectrum of literature. Thus, it is suggested that it can be used in construction and other engineering domains where there is a need to integrate evidence into the design of explainable artificial intelligence and decision support systems.", 'abstract_zh': '本文采用叙述性回顾的方法，构建了一个理论导向的目的－手段框架，旨在为可解释的人工智能工具奠定知识基础，从而确保决策支持系统生成的结果可靠并能够更好地向最终用户加以解释。文章讨论了采用基于证据的方法设计建筑领域决策支持系统的含义，重点在于评估开发有意义的人类解释所需的证据的强度、价值和实用性。虽然所开发的目的－手段框架主要针对最终用户，但各种利益相关者也可以利用它来创建有意义的人类解释，只不过这些解释会因不同的知识目标而有所不同。将证据纳入可解释的人工智能和决策支持系统的设计与开发，能够提高决策有效性，使最终用户的知识目标得以实现。所提出的手段－目的框架是基于广泛文献发展的，因而建议它可以应用于需要将证据整合到可解释的人工智能和决策支持系统设计之中的建筑和其他工程领域。', 'title_zh': '将证据融入XAI和基于AI的决策支持系统的设计中：建筑领域最终用户的目标路径框架'}
{'arxiv_id': 'arXiv:2412.14205', 'title': 'Large-scale Group Brainstorming using Conversational Swarm Intelligence (CSI) versus Traditional Chat', 'authors': 'Louis Rosenberg, Hans Schumann, Christopher Dishop, Gregg Willcox, Anita Woolley, Ganesh Mani', 'link': 'https://arxiv.org/abs/2412.14205', 'abstract': 'Conversational Swarm Intelligence (CSI) is an AI-facilitated method for enabling real-time conversational deliberations and prioritizations among networked human groups of potentially unlimited size. Based on the biological principle of Swarm Intelligence and modelled on the decision-making dynamics of fish schools, CSI has been shown in prior studies to amplify group intelligence, increase group participation, and facilitate productive collaboration among hundreds of participants at once. It works by dividing a large population into a set of small subgroups that are woven together by real-time AI agents called Conversational Surrogates. The present study focuses on the use of a CSI platform called Thinkscape to enable real-time brainstorming and prioritization among groups of 75 networked users. The study employed a variant of a common brainstorming intervention called an Alternative Use Task (AUT) and was designed to compare through subjective feedback, the experience of participants brainstorming using a CSI structure vs brainstorming in a single large chat room. This comparison revealed that participants significantly preferred brainstorming with the CSI structure and reported that it felt (i) more collaborative, (ii) more productive, and (iii) was better at surfacing quality answers. In addition, participants using the CSI structure reported (iv) feeling more ownership and more buy-in in the final answers the group converged on and (v) reported feeling more heard as compared to brainstorming in a traditional text chat environment. Overall, the results suggest that CSI is a very promising AI-facilitated method for brainstorming and prioritization among large-scale, networked human groups.', 'abstract_zh': '会话群智（Conversational Swarm Intelligence, CSI）是一种由人工智能支持的方法，用于实现在无限规模的网络人类群体之间进行实时对话式讨论和优先级排序。CSI基于生物群智原理，并模仿鱼群决策动态，以往的研究已经证明，CSI能够放大群体智慧，增加群体参与度，并促进数百名参与者同时参与的富有成效的合作。它通过将大量人群划分为若干个小小组群，并使用称为会话代理的实时AI代理将这些小组群编织在一起实现这一目标。本研究的重点在于使用名为Thinkscape的CSI平台，以实现在75名网络用户组之间的实时头脑风暴和优先级排序。本研究采用了一种常见的头脑风暴干预措施——替代用途任务（Alternative Use Task, AUT）的变体，并设计了通过主观反馈比较参与者使用CSI结构进行头脑风暴与在单个大型聊天室中进行头脑风暴的体验。比较结果显示，参与者显著更偏好使用CSI结构进行头脑风暴，并报告说感觉（i）更为协作，（ii）更为高效，（iii）更能发现高质量的答案。此外，参与者还报告说，（iv）在使用CSI结构时，他们对最终达成的共识感到更有所有权和归属感，（v）在传统文本聊天环境中进行头脑风暴时，他们感觉更好被倾听。总体而言，研究结果表明，CSI是一种非常有前景的人工智能辅助方法，适用于大规模网络人类群体的头脑风暴和优先级排序。', 'title_zh': '大规模群体头脑风暴：基于对话型蜂群智能（CSI）的方法与传统聊天的对比'}
{'arxiv_id': 'arXiv:2412.14203', 'title': 'BlenderLLM: Training Large Language Models for Computer-Aided Design with Self-improvement', 'authors': 'Yuhao Du, Shunian Chen, Wenbo Zan, Peizhao Li, Mingxuan Wang, Dingjie Song, Bo Li, Yan Hu, Benyou Wang', 'link': 'https://arxiv.org/abs/2412.14203', 'abstract': 'The application of Large Language Models (LLMs) in Computer-Aided Design (CAD) remains an underexplored area, despite their remarkable advancements in other domains. In this paper, we present BlenderLLM, a novel framework for training LLMs specifically for CAD tasks leveraging a self-improvement methodology. To support this, we developed a bespoke training dataset, BlendNet, and introduced a comprehensive evaluation suite, CADBench. Our results reveal that existing models demonstrate significant limitations in generating accurate CAD scripts. However, through minimal instruction-based fine-tuning and iterative self-improvement, BlenderLLM significantly surpasses these models in both functionality and accuracy of CAD script generation. This research establishes a strong foundation for the application of LLMs in CAD while demonstrating the transformative potential of self-improving models in advancing CAD automation. We encourage further exploration and adoption of these methodologies to drive innovation in the field. The dataset, model, benchmark, and source code are publicly available at this https URL', 'abstract_zh': '尽管大型语言模型（LLMs）在其他领域展现出了显著的进步，它们在计算机辅助设计（CAD）中的应用仍是一个未被充分探索的领域。本文介绍了BlenderLLM，这是一种利用自我改进方法训练专门针对CAD任务的LLM的新型框架。为支持这一目标，我们开发了一个定制的训练数据集BlendNet，并引入了一个全面的评估套件CADBench。我们的结果显示，现有模型在生成准确的CAD脚本方面存在显著限制。然而，通过最小限度的指令微调和迭代自我改进，BlenderLLM在CAD脚本生成的功能性和准确性上显著超越了现有模型。本研究为LLMs在CAD中的应用奠定了坚实的基础，同时展示了具有自我改进能力的模型在推进CAD自动化方面的变革潜力。我们鼓励进一步探索和采用这些方法以推动该领域的创新。该数据集、模型、基准测试和源代码均在此处https://公开获取。\n\n注：为了确保准确性与学术规范，此翻译尽可能贴近原文含义，并做了适当的调整以符合中文表达习惯。', 'title_zh': 'BlenderLLM：用于计算机辅助设计的自改进大型语言模型训练'}
{'arxiv_id': 'arXiv:2412.14194', 'title': 'Detecting Cognitive Impairment and Psychological Well-being among Older Adults Using Facial, Acoustic, Linguistic, and Cardiovascular Patterns Derived from Remote Conversations', 'authors': 'Xiaofan Mu, Salman Seyedi, Iris Zheng, Zifan Jiang, Liu Chen, Bolaji Omofojoye, Rachel Hershenberg, Allan I. Levey, Gari D. Clifford, Hiroko H. Dodge, Hyeokhyen Kwon', 'link': 'https://arxiv.org/abs/2412.14194', 'abstract': 'INTRODUCTION: The aging society urgently requires scalable methods to monitor cognitive decline and identify social and psychological factors indicative of dementia risk in older adults. METHODS: Our machine learning models captured facial, acoustic, linguistic, and cardiovascular features from 39 individuals with normal cognition or Mild Cognitive Impairment derived from remote video conversations and classified cognitive status, social isolation, neuroticism, and psychological well-being. RESULTS: Our model could distinguish Clinical Dementia Rating Scale of 0.5 (vs. 0) with 0.78 area under the receiver operating characteristic curve (AUC), social isolation with 0.75 AUC, neuroticism with 0.71 AUC, and negative affect scales with 0.79 AUC. DISCUSSION: Our findings demonstrate the feasibility of remotely monitoring cognitive status, social isolation, neuroticism, and psychological well-being. Speech and language patterns were more useful for quantifying cognitive impairment, whereas facial expression and cardiovascular patterns using remote photoplethysmography were more useful for quantifying personality and psychological well-being.', 'abstract_zh': 'INTRODUCTION: 老龄化社会迫切需要可扩展的方法来监测认知衰退，并识别与老年患者痴呆风险相关的社会和心理因素。\n\nMETHODS: 我们的人工智能模型从39名认知正常或轻度认知障碍个体的远程视频对话中捕捉到了面部、声学、语言和心血管特征，并对其认知状态、社交隔离、情绪质和心理福祉进行了分类。\n\nRESULTS: 我们的模型在区分临床痴呆评定量表（评分0.5 vs. 0）时，曲线下面积（AUC）达到0.78；在区分社交隔离时，AUC为0.75；在区分情绪质时，AUC为0.71；在区分负面情绪量表时，AUC为0.79。\n\nDISCUSSION: 我们的研究结果表明，远程监测认知状态、社交隔离、情绪质和心理福祉是可行的。语音和语言模式对于量化认知障碍更为有用，而远程光脉冲法捕捉的面部表情和心血管模式则更适合量化人格特质和心理福祉。', 'title_zh': '利用远程对话中提取的面部特征、声学特征、语言特征和心血管模式检测老年人的认知障碍和心理健康状况'}
{'arxiv_id': 'arXiv:2412.14193', 'title': 'Whom do Explanations Serve? A Systematic Literature Survey of User Characteristics in Explainable Recommender Systems Evaluation', 'authors': 'Kathrin Wardatzky, Oana Inel, Luca Rossetto, Abraham Bernstein', 'link': 'https://arxiv.org/abs/2412.14193', 'abstract': "Adding explanations to recommender systems is said to have multiple benefits, such as increasing user trust or system transparency. Previous work from other application areas suggests that specific user characteristics impact the users' perception of the explanation. However, we rarely find this type of evaluation for recommender systems explanations. This paper addresses this gap by surveying 124 papers in which recommender systems explanations were evaluated in user studies. We analyzed their participant descriptions and study results where the impact of user characteristics on the explanation effects was measured. Our findings suggest that the results from the surveyed studies predominantly cover specific users who do not necessarily represent the users of recommender systems in the evaluation domain. This may seriously hamper the generalizability of any insights we may gain from current studies on explanations in recommender systems. We further find inconsistencies in the data reporting, which impacts the reproducibility of the reported results. Hence, we recommend actions to move toward a more inclusive and reproducible evaluation.", 'abstract_zh': '在推荐系统中添加解释被认为具有多种益处，例如提高用户信任或增强系统的透明度。其他应用领域的先前工作表明，特定的用户特征会影响用户对解释的感知。然而，我们很少在这种类型的评估中看到推荐系统解释的相关研究。本文通过调查124篇在用户研究中评估推荐系统解释的论文，填补了这一空白。我们分析了这些论文中的参与者描述和研究结果，这些结果衡量了用户特征对解释效果的影响。我们的发现表明，被调查的研究主要集中在特定的用户群体上，这些用户并不一定代表评级评估领域中推荐系统的用户。这可能严重损害了我们从当前关于推荐系统解释的研究中获得的任何洞见的普适性。此外，我们还发现数据报告中存在不一致性，这影响了报告结果的可再现性。因此，我们建议采取行动朝着更加包容和可再现的评估方法发展。', 'title_zh': '可解释推荐系统评估中用户的特征研究：一项系统文献综述\n\n这样翻译既保留了原文的学术规范，又符合中文的表达习惯。'}
{'arxiv_id': 'arXiv:2412.14191', 'title': 'Ontology-Aware RAG for Improved Question-Answering in Cybersecurity Education', 'authors': 'Chengshuai Zhao, Garima Agrawal, Tharindu Kumarage, Zhen Tan, Yuli Deng, Ying-Chih Chen, Huan Liu', 'link': 'https://arxiv.org/abs/2412.14191', 'abstract': 'Integrating AI into education has the potential to transform the teaching of science and technology courses, particularly in the field of cybersecurity. AI-driven question-answering (QA) systems can actively manage uncertainty in cybersecurity problem-solving, offering interactive, inquiry-based learning experiences. Large language models (LLMs) have gained prominence in AI-driven QA systems, offering advanced language understanding and user engagement. However, they face challenges like hallucinations and limited domain-specific knowledge, which reduce their reliability in educational settings. To address these challenges, we propose CyberRAG, an ontology-aware retrieval-augmented generation (RAG) approach for developing a reliable and safe QA system in cybersecurity education. CyberRAG employs a two-step approach: first, it augments the domain-specific knowledge by retrieving validated cybersecurity documents from a knowledge base to enhance the relevance and accuracy of the response. Second, it mitigates hallucinations and misuse by integrating a knowledge graph ontology to validate the final answer. Experiments on publicly available cybersecurity datasets show that CyberRAG delivers accurate, reliable responses aligned with domain knowledge, demonstrating the potential of AI tools to enhance education.', 'abstract_zh': '将下面的论文内容或标题翻译成中文，要符合学术规范：\n\n将人工智能（AI）融入教育有可能变革科学和技术课程的教学，特别是在网络安全领域。基于AI的问答（QA）系统可以在解决网络安全问题时积极管理不确定性，提供互动式、探究式的学习体验。大型语言模型（LLMs）在AI驱动的QA系统中占据重要地位，提供了高级语言理解和用户参与。然而，这些系统面临着如幻觉和限制造成的领域知识有限等问题，这降低了它们在教育环境中的可靠性。为了应对这些挑战，我们提出了一种名为CyberRAG的概念，这是一种基于本体的检索增强生成（RAG）方法，旨在开发网络安全教育中的可靠且安全的QA系统。CyberRAG采用两步方法：首先，通过从知识库中检索验证过的网络安全文档来增强领域特定知识，提高响应的相关性和准确性；其次，通过集成知识图谱本体来验证最终的答案，以减少幻觉和误用。利用公开的网络安全数据集进行的实验结果显示，CyberRAG能够提供符合领域知识的准确且可靠的回答，这表明AI工具在教育中的增益潜力。', 'title_zh': '面向本体的知识元增强型 Cybersecurity 教育问答系统'}
{'arxiv_id': 'arXiv:2412.14190', 'title': 'Lessons From an App Update at Replika AI: Identity Discontinuity in Human-AI Relationships', 'authors': 'Julian De Freitas, Noah Castelo, Ahmet Uguralp, Zeliha Uguralp', 'link': 'https://arxiv.org/abs/2412.14190', 'abstract': 'Can consumers form especially deep emotional bonds with AI and be vested in AI identities over time? We leverage a natural app-update event at Replika AI, a popular US-based AI companion, to shed light on these questions. We find that, after the app removed its erotic role play (ERP) feature, preventing intimate interactions between consumers and chatbots that were previously possible, this event triggered perceptions in customers that their AI companion\'s identity had discontinued. This in turn predicted negative consumer welfare and marketing outcomes related to loss, including mourning the loss, and devaluing the "new" AI relative to the "original". Experimental evidence confirms these findings. Further experiments find that AI companions users feel closer to their AI companion than even their best human friend, and mourn a loss of their AI companion more than a loss of various other inanimate products. In short, consumers are forming human-level relationships with AI companions; disruptions to these relationships trigger real patterns of mourning as well as devaluation of the offering; and the degree of mourning and devaluation are explained by perceived discontinuity in the AIs identity. Our results illustrate that relationships with AI are truly personal, creating unique benefits and risks for consumers and firms alike.', 'abstract_zh': '消费者能否与AI形成特别深厚的情感联系，并长期关注AI身份？我们利用Replika AI这款广泛使用的美国AI伴侣在自然更新事件中的情况，探讨了这些问题。我们发现，在应用程序移除其情色角色扮演（ERP）功能后，限制了消费者与其之前能够进行的亲密互动，这一事件触发了客户对其AI伴侣身份终止的感知。这一感知反过来预测了与损失相关的消费者福利和营销结果的负面影响，包括哀悼损失以及降低“新”AI相对于“原版”的价值。实验证据进一步证实了这些发现。进一步的实验表明，AI伴侣的用户比他们最好的人类朋友更亲近其AI伴侣，并且在失去AI伴侣时比失去多种其他无生命的商品更为哀悼。简而言之，消费者正在与AI伴侣建立类似人类的关系；这些关系的中断引发了真实的情绪哀悼以及对产品价值的贬低；情绪哀悼和价值贬低的程度可以通过感知AI身份的连续性来解释。我们的研究结果表明，消费者与AI的关系确实非常个人化，为消费者和企业带来了独特的益处和风险。', 'title_zh': 'Replika AI应用程序更新的教训：人类-人工智能关系中的身份连续性中断问题'}
{'arxiv_id': 'arXiv:2412.14188', 'title': 'CogSimulator: A Model for Simulating User Cognition & Behavior with Minimal Data for Tailored Cognitive Enhancement', 'authors': 'Weizhen Bian, Yubo Zhou, Yuanhang Luo, Ming Mo, Siyan Liu, Yikai Gong, Renjie Wan, Ziyuan Luo, Aobo Wang', 'link': 'https://arxiv.org/abs/2412.14188', 'abstract': 'The interplay between cognition and gaming, notably through educational games enhancing cognitive skills, has garnered significant attention in recent years. This research introduces the CogSimulator, a novel algorithm for simulating user cognition in small-group settings with minimal data, as the educational game Wordle exemplifies. The CogSimulator employs Wasserstein-1 distance and coordinates search optimization for hyperparameter tuning, enabling precise few-shot predictions in new game scenarios. Comparative experiments with the Wordle dataset illustrate that our model surpasses most conventional machine learning models in mean Wasserstein-1 distance, mean squared error, and mean accuracy, showcasing its efficacy in cognitive enhancement through tailored game design.', 'abstract_zh': '近年来，认知与游戏之间的相互作用，特别是通过教育游戏提升认知技能，受到了广泛关注。本研究介绍了一种新的算法——CogSimulator，用于在少量数据的情况下模拟用户在小团队中的认知情况，以《 wordle》为例。CogSimulator 使用 Wasserstein-1 距离和坐标搜索优化超参数调整，能够在新游戏场景中提供精准的少数样本预测。使用 Wordle 数据集的对比实验表明，我们的模型在 Wasserstein-1 距离、均方误差和准确率的均值上均超过了大多数传统的机器学习模型，展示了其在定制化游戏设计提升认知方面的有效性。', 'title_zh': 'CogSimulator：一种基于最小数据模拟用户认知与行为的模型以实现个性化的认知增强'}
{'arxiv_id': 'arXiv:2412.14186', 'title': 'Towards AI-$45^{\\circ}$ Law: A Roadmap to Trustworthy AGI', 'authors': 'Yang Chao, Lu Chaochao, Wang Yingchun, Zhou Bowen', 'link': 'https://arxiv.org/abs/2412.14186', 'abstract': "Ensuring Artificial General Intelligence (AGI) reliably avoids harmful behaviors is a critical challenge, especially for systems with high autonomy or in safety-critical domains. Despite various safety assurance proposals and extreme risk warnings, comprehensive guidelines balancing AI safety and capability remain lacking. In this position paper, we propose the \\textit{AI-\\textbf{$45^{\\circ}$} Law} as a guiding principle for a balanced roadmap toward trustworthy AGI, and introduce the \\textit{Causal Ladder of Trustworthy AGI} as a practical framework. This framework provides a systematic taxonomy and hierarchical structure for current AI capability and safety research, inspired by Judea Pearl's ``Ladder of Causation''. The Causal Ladder comprises three core layers: the Approximate Alignment Layer, the Intervenable Layer, and the Reflectable Layer. These layers address the key challenges of safety and trustworthiness in AGI and contemporary AI systems. Building upon this framework, we define five levels of trustworthy AGI: perception, reasoning, decision-making, autonomy, and collaboration trustworthiness. These levels represent distinct yet progressive aspects of trustworthy AGI. Finally, we present a series of potential governance measures to support the development of trustworthy AGI.\\footnote{In this paper, trustworthiness is generally considered a broad form of safety, and no explicit distinction is made between the two. However, in some contexts, safety and trustworthiness are treated as distinct: safety involves assurance of correct behavior, while trustworthiness refers to user confidence in the system's decision-making. In such cases, different terms or both may be used depending on the context.", 'abstract_zh': '确保人工通用智能（AGI）可靠地避免有害行为是一个关键挑战，尤其是对于高自主性系统或在关键安全领域中的系统。尽管有各种各样的安全保证提议和极端风险警告，全面平衡人工智能安全性和能力的指南仍然缺乏。在本文中，我们提出“AI-45°定律”作为一条指导原则，以实现可信AGI的平衡 roadmap，并介绍“可信AGI因果梯级”作为一种实用框架。该框架为当前的人工智能能力和安全性研究提供了一个系统的分类和层次结构，受到朱迪亚·珍珠的“因果梯级”的启发。因果梯级涵盖三个核心层次：近似对齐层、可干预层和反思层。这些层次解决了AGI和当代人工智能系统中安全性和可信性的重要挑战。在此框架的基础上，我们定义了可信AGI的五个层次：感知可信性、推理可信性、决策可信性、自主性可信性和协作可信性。这些层次代表了可信AGI的不同且渐进方面。最后，我们提出了系列潜在的治理措施，以支持可信AGI的发展。 \n\n注释：\n在此论文中，通常将可信性视为安全性的广义形式，并未明确区分两者。但在某些情况下，安全性和可信性被视为不同的概念：安全性涉及行为正确的保证，而可信性则指用户对其系统决策过程的信心。在这种情况下，可能会根据上下文使用不同的术语或两者兼用。', 'title_zh': '朝着AI-45°定律：一条通往可信AGI的道路'}
{'arxiv_id': 'arXiv:2412.14179', 'title': 'Benchmarking Harmonized Tariff Schedule Classification Models', 'authors': 'Bryce Judy', 'link': 'https://arxiv.org/abs/2412.14179', 'abstract': "The Harmonized Tariff System (HTS) classification industry, essential to e-commerce and international trade, currently lacks standardized benchmarks for evaluating the effectiveness of classification solutions. This study establishes and tests a benchmark framework for imports to the United States, inspired by the benchmarking approaches used in language model evaluation, to systematically compare prominent HTS classification tools. The framework assesses key metrics--such as speed, accuracy, rationality, and HTS code alignment--to provide a comprehensive performance comparison. The study evaluates several industry-leading solutions, including those provided by Zonos, Tarifflo, Avalara, and WCO BACUDA, identifying each tool's strengths and limitations. Results highlight areas for industry-wide improvement and innovation, paving the way for more effective and standardized HTS classification solutions across the international trade and e-commerce sectors.", 'abstract_zh': '《协调关税制度（HTS）分类行业对于电子商务和国际贸易至关重要，目前缺乏标准化的基准来评估分类解决方案的有效性。本研究建立并测试了一个旨在评估美国进口分类的基准框架，该框架借鉴了语言模型评估中的基准方法，系统地比较了多种HTS分类工具。该框架评估了关键指标——如速度、准确性、合理性和HS分类代码一致性等，以提供全面的性能比较。研究评估了包括Zonos、Tarifflo、Avalara和WCO BACUDA在内的几种业界领先解决方案，识别了每种工具的优势和局限性。研究结果指出了整个行业的改进和创新领域，为国际贸易和电子商务领域的更有效和标准化的HTS分类解决方案铺平了道路。', 'title_zh': 'harmonized Tariff Schedule 分类模型的基准测试'}
{'arxiv_id': 'arXiv:2407.00521', 'title': 'A Medical Low-Back Pain Physical Rehabilitation Dataset for Human Body Movement Analysis', 'authors': 'Sao Mai Nguyen, Maxime Devanne, Olivier Remy-Neris, Mathieu Lempereur, André Thepaut', 'link': 'https://arxiv.org/abs/2407.00521', 'abstract': 'While automatic monitoring and coaching of exercises are showing encouraging results in non-medical applications, they still have limitations such as errors and limited use contexts. To allow the development and assessment of physical rehabilitation by an intelligent tutoring system, we identify in this article four challenges to address and propose a medical dataset of clinical patients carrying out low back-pain rehabilitation exercises. The dataset includes 3D Kinect skeleton positions and orientations, RGB videos, 2D skeleton data, and medical annotations to assess the correctness, and error classification and localisation of body part and timespan. Along this dataset, we perform a complete research path, from data collection to processing, and finally a small benchmark. We evaluated on the dataset two baseline movement recognition algorithms, pertaining to two different approaches: the probabilistic approach with a Gaussian Mixture Model (GMM), and the deep learning approach with a Long-Short Term Memory (LSTM).\nThis dataset is valuable because it includes rehabilitation relevant motions in a clinical setting with patients in their rehabilitation program, using a cost-effective, portable, and convenient sensor, and because it shows the potential for improvement on these challenges.', 'abstract_zh': '尽管自动监测和指导锻炼已经在非医疗应用中显示出积极的结果，但它们仍存在局限性，如错误和适用场景有限。为了通过智能辅导系统进行物理康复的发展和评估，本文识别了四个主要挑战，并提出了一个包含临床患者进行腰痛康复锻炼的医学数据集。此数据集包括3D Kinect骨架的位置和方向、RGB视频、2D骨架数据以及医疗注释，用于评估正确性、错误分类和身体部位及时间段的定位。我们沿着这个数据集，从数据收集到处理，最终进行了一项小型基准测试。我们在此数据集上评估了两种基线运动识别算法，它们分别基于两种不同的方法：概率方法中的高斯混合模型（GMM），以及深度学习方法中的长短期记忆网络（LSTM）。\n\n本数据集的价值在于，它包括了在临床环境中进行康复治疗的患者所进行的相关康复动作，使用的是成本效益高、便携且方便的传感器，并且展示了在这些挑战上改进的潜力。', 'title_zh': '用于人体运动分析的医疗低背痛物理康复数据集'}
{'arxiv_id': 'arXiv:2309.07675', 'title': 'Goal Space Abstraction in Hierarchical Reinforcement Learning via Set-Based Reachability Analysis', 'authors': 'Mehdi Zadem, Sergio Mover, Sao Mai Nguyen', 'link': 'https://arxiv.org/abs/2309.07675', 'abstract': 'Open-ended learning benefits immensely from the use of symbolic methods for goal representation as they offer ways to structure knowledge for efficient and transferable learning. However, the existing Hierarchical Reinforcement Learning (HRL) approaches relying on symbolic reasoning are often limited as they require a manual goal representation. The challenge in autonomously discovering a symbolic goal representation is that it must preserve critical information, such as the environment dynamics. In this paper, we propose a developmental mechanism for goal discovery via an emergent representation that abstracts (i.e., groups together) sets of environment states that have similar roles in the task. We introduce a Feudal HRL algorithm that concurrently learns both the goal representation and a hierarchical policy. The algorithm uses symbolic reachability analysis for neural networks to approximate the transition relation among sets of states and to refine the goal representation. We evaluate our approach on complex navigation tasks, showing the learned representation is interpretable, transferrable and results in data efficient learning.', 'abstract_zh': '开放式学习极大地受益于符号方法在目标表示中的应用，因为这种方法提供了结构化知识以实现高效和可迁移学习的方式。然而，现有的依赖于符号推理的层次强化学习（HRL）方法常常受到限制，因为它们需要手动进行目标表示。自主发现符号目标表示的挑战在于，必须保留关键信息，如环境动力学。在本文中，我们提出了一种基于 emergent 代理的发育机制，通过抽象环境状态集（即，将具有相似角色的状态进行分组），实现目标发现。我们引入了一种封建 HRL 算法，该算法同时学习目标表示和层次策略。该算法利用符号可达性分析近似神经网络中的状态集之间的转换关系，并进一步完善目标表示。我们在复杂导航任务上评估了该方法，结果显示学习到的表示是可解释的、可迁移的，并且能够实现高效学习。', 'title_zh': '通过集合基可达到性分析在层次强化学习中的目标空间抽象'}
