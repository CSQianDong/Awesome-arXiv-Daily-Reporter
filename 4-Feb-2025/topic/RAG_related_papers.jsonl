{'arxiv_id': 'arXiv:2502.01142', 'title': 'DeepRAG: Thinking to Retrieval Step by Step for Large Language Models', 'authors': 'Xinyan Guan, Jiali Zeng, Fandong Meng, Chunlei Xin, Yaojie Lu, Hongyu Lin, Xianpei Han, Le Sun, Jie Zhou', 'link': 'https://arxiv.org/abs/2502.01142', 'abstract': 'Large Language Models (LLMs) have shown remarkable potential in reasoning while they still suffer from severe factual hallucinations due to timeliness, accuracy, and coverage of parametric knowledge. Meanwhile, integrating reasoning with retrieval-augmented generation (RAG) remains challenging due to ineffective task decomposition and redundant retrieval, which can introduce noise and degrade response quality. In this paper, we propose DeepRAG, a framework that models retrieval-augmented reasoning as a Markov Decision Process (MDP), enabling strategic and adaptive retrieval. By iteratively decomposing queries, DeepRAG dynamically determines whether to retrieve external knowledge or rely on parametric reasoning at each step. Experiments show that DeepRAG improves retrieval efficiency while improving answer accuracy by 21.99%, demonstrating its effectiveness in optimizing retrieval-augmented reasoning.', 'abstract_zh': '以下是经过学术规范翻译的内容：\n\n大型语言模型（LLMs）在推理方面展现出了显著潜力，但仍然受到时效性、准确性和覆盖范围方面的参数化知识限制，导致严重的事实幻觉。同时，将推理与检索增强生成（RAG）相结合仍然颇具挑战性，主要由于任务分解不完善和冗余检索可能导致噪音增加，进而降低响应质量。在本文中，我们提出了一种名为DeepRAG的框架，该框架将检索增强推理建模为马尔可夫决策过程（MDP），从而实现战略性且适应性的检索。通过逐步分解查询，DeepRAG动态决定在每一步是检索外部知识还是依赖于参数化推理。实验结果显示，DeepRAG在提高检索效率的同时，将答案准确性提高了21.99%，证明了其在优化检索增强推理方面的有效性。', 'title_zh': 'DeepRAG：逐步思考以进行大型语言模型的检索'}
{'arxiv_id': 'arXiv:2502.00677', 'title': 'LLM-based event log analysis techniques: A survey', 'authors': 'Siraaj Akhtar, Saad Khan, Simon Parkinson', 'link': 'https://arxiv.org/abs/2502.00677', 'abstract': 'Event log analysis is an important task that security professionals undertake. Event logs record key information on activities that occur on computing devices, and due to the substantial number of events generated, they consume a large amount of time and resources to analyse. This demanding and repetitive task is also prone to errors. To address these concerns, researchers have developed automated techniques to improve the event log analysis process. Large Language Models (LLMs) have recently demonstrated the ability to successfully perform a wide range of tasks that individuals would usually partake in, to high standards, and at a pace and degree of complexity that outperform humans. Due to this, researchers are rapidly investigating the use of LLMs for event log analysis. This includes fine-tuning, Retrieval-Augmented Generation (RAG) and in-context learning, which affect performance. These works demonstrate good progress, yet there is a need to understand the developing body of knowledge, identify commonalities between works, and identify key challenges and potential solutions to further developments in this domain. This paper aims to survey LLM-based event log analysis techniques, providing readers with an in-depth overview of the domain, gaps identified in previous research, and concluding with potential avenues to explore in future.', 'abstract_zh': '事件日志分析是一项重要的安全专业人员任务。事件日志记录了计算设备上发生的活动的关键信息，但由于生成的事件数量庞大，分析这些日志会消耗大量时间和资源。这一任务既耗时又重复，并且容易出错。为了解决这些问题，研究人员开发了自动化技术以改进事件日志分析过程。大语言模型（LLMs）最近已经展示出能够高效、高质量地完成人类通常会参与的多种任务，并且在速度和复杂性方面超越人类。由于这一点，研究人员正在迅速探索使用LLMs进行事件日志分析的方法。这包括微调、检索增强生成（RAG）和上下文学习等方法，它们对性能产生影响。尽管这些研究展示了良好的进展，但仍有必要理解这一领域的新兴知识体系，识别不同研究之间的共通之处，并识别关键挑战和潜在解决方案以推动该领域进一步发展。本文旨在回顾基于LLM的事件日志分析技术，为读者提供该领域的深入概述，指出先前研究中的空白，并总结出未来研究的潜在途径。', 'title_zh': '基于大型语言模型的事件日志分析技术：一种综述'}
{'arxiv_id': 'arXiv:2502.01549', 'title': 'VideoRAG: Retrieval-Augmented Generation with Extreme Long-Context Videos', 'authors': 'Xubin Ren, Lingrui Xu, Long Xia, Shuaiqiang Wang, Dawei Yin, Chao Huang', 'link': 'https://arxiv.org/abs/2502.01549', 'abstract': 'Retrieval-Augmented Generation (RAG) has demonstrated remarkable success in enhancing Large Language Models (LLMs) through external knowledge integration, yet its application has primarily focused on textual content, leaving the rich domain of multi-modal video knowledge predominantly unexplored. This paper introduces VideoRAG, the first retrieval-augmented generation framework specifically designed for processing and understanding extremely long-context videos. Our core innovation lies in its dual-channel architecture that seamlessly integrates (i) graph-based textual knowledge grounding for capturing cross-video semantic relationships, and (ii) multi-modal context encoding for efficiently preserving visual features. This novel design empowers VideoRAG to process unlimited-length videos by constructing precise knowledge graphs that span multiple videos while maintaining semantic dependencies through specialized multi-modal retrieval paradigms. Through comprehensive empirical evaluation on our proposed LongerVideos benchmark-comprising over 160 videos totaling 134+ hours across lecture, documentary, and entertainment categories-VideoRAG demonstrates substantial performance compared to existing RAG alternatives and long video understanding methods. The source code of VideoRAG implementation and the benchmark dataset are openly available at: this https URL.', 'abstract_zh': '以下是符合学术规范的翻译：\n\n检索增强生成（RAG）在通过外部知识整合增强大型语言模型（LLMs）方面已经取得了显著的成功，其应用领域主要集中在文本内容上，而多模态视频知识的丰富领域仍然未得到充分探索。本文提出了一种名为VideoRAG的新框架，这是第一个专门针对处理和理解极长视频的检索增强生成框架。我们的核心创新在于该框架采用了一种双通道架构，该架构能够无缝地将（i）基于图的文本知识关联应用于捕捉视频间的跨层语义关系，以及（ii）多模态上下文编码应用于高效地保留视觉特征相结合。这种新颖的设计使VideoRAG能够通过构建跨视频的精确知识图谱来处理无限长度的视频，同时通过专门的多模态检索范式保持语义依赖性。\n\n通过在我们提出的LongerVideos基准上进行全面的经验性评估（该基准包含超过160个视频，总计134+小时，涵盖了讲座、纪录片和娱乐等多个类别），VideoRAG与现有的RAG替代方法和长视频理解方法相比，展现了显著的性能优势。VideoRAG的实现代码和基准数据集均可从以下链接公开获取：this https URL。', 'title_zh': 'VideoRAG：极长上下文视频增强生成'}
{'arxiv_id': 'arXiv:2502.01113', 'title': 'GFM-RAG: Graph Foundation Model for Retrieval Augmented Generation', 'authors': 'Linhao Luo, Zicheng Zhao, Gholamreza Haffari, Dinh Phung, Chen Gong, Shirui Pan', 'link': 'https://arxiv.org/abs/2502.01113', 'abstract': 'Retrieval-augmented generation (RAG) has proven effective in integrating knowledge into large language models (LLMs). However, conventional RAGs struggle to capture complex relationships between pieces of knowledge, limiting their performance in intricate reasoning that requires integrating knowledge from multiple sources. Recently, graph-enhanced retrieval augmented generation (GraphRAG) builds graph structure to explicitly model these relationships, enabling more effective and efficient retrievers. Nevertheless, its performance is still hindered by the noise and incompleteness within the graph structure. To address this, we introduce GFM-RAG, a novel graph foundation model (GFM) for retrieval augmented generation. GFM-RAG is powered by an innovative graph neural network that reasons over graph structure to capture complex query-knowledge relationships. The GFM with 8M parameters undergoes a two-stage training process on large-scale datasets, comprising 60 knowledge graphs with over 14M triples and 700k documents. This results in impressive performance and generalizability for GFM-RAG, making it the first graph foundation model applicable to unseen datasets for retrieval without any fine-tuning required. Extensive experiments on three multi-hop QA datasets and seven domain-specific RAG datasets demonstrate that GFM-RAG achieves state-of-the-art performance while maintaining efficiency and alignment with neural scaling laws, highlighting its potential for further improvement.', 'abstract_zh': '检索增强生成（RAG）已被证明在将知识整合到大型语言模型（LLMs）中是有效的。然而，传统的RAG在捕捉多个知识片段之间的复杂关系方面存在困难，这限制了它们在多源知识整合所需复杂推理中的表现。最近，图增强检索增强生成（GraphRAG）构建了图结构来明确建模这些关系，从而实现了更为有效和高效的检索。然而，其性能仍然受到图结构中的噪声和不完整性的阻碍。为了解决这个问题，我们引入了GFM-RAG，这是一种用于检索增强生成的新型图基础模型（GFM）。GFM-RAG借助一种创新的图神经网络，在图结构上进行推理以捕获复杂的查询-知识关系。该GFM包含800万个参数，并在大规模数据集上进行了两阶段训练，数据集包含60个知识图谱和超过1400万个三元组以及70万个文档。这使得GFM-RAG在性能和泛化能力方面表现出色，并成为首个适用于未见数据集的无微调图基础模型。在三个多跳QA数据集和七个特定领域的RAG数据集上进行的大量实验表明，GFM-RAG在保持效率和与神经规模定律一致的同时实现了最先进的性能，突显了其进一步改进的潜力。', 'title_zh': 'GFM-RAG：图基础模型在检索增强生成中的应用'}
{'arxiv_id': 'arXiv:2502.01059', 'title': 'Knowledge Synthesis of Photosynthesis Research Using a Large Language Model', 'authors': 'Seungri Yoon, Woosang Jeon, Sanghyeok Choi, Taehyeong Kim, Tae In Ahn', 'link': 'https://arxiv.org/abs/2502.01059', 'abstract': "The development of biological data analysis tools and large language models (LLMs) has opened up new possibilities for utilizing AI in plant science research, with the potential to contribute significantly to knowledge integration and research gap identification. Nonetheless, current LLMs struggle to handle complex biological data and theoretical models in photosynthesis research and often fail to provide accurate scientific contexts. Therefore, this study proposed a photosynthesis research assistant (PRAG) based on OpenAI's GPT-4o with retrieval-augmented generation (RAG) techniques and prompt optimization. Vector databases and an automated feedback loop were used in the prompt optimization process to enhance the accuracy and relevance of the responses to photosynthesis-related queries. PRAG showed an average improvement of 8.7% across five metrics related to scientific writing, with a 25.4% increase in source transparency. Additionally, its scientific depth and domain coverage were comparable to those of photosynthesis research papers. A knowledge graph was used to structure PRAG's responses with papers within and outside the database, which allowed PRAG to match key entities with 63% and 39.5% of the database and test papers, respectively. PRAG can be applied for photosynthesis research and broader plant science domains, paving the way for more in-depth data analysis and predictive capabilities.", 'abstract_zh': '生物数据处理工具和大规模语言模型（LLMs）的发展为植物科学研究中的AI应用打开了新的可能性，有可能显著促进知识整合和研究空白的识别。然而，目前的LLMs在光合作用研究中的复杂生物数据和理论模型处理方面仍存在困难，往往无法提供准确的科学背景。因此，本研究基于OpenAI的GPT-4o和检索增强生成（RAG）技术，提出了一种光合作用研究助手（PRAG），并采用了提示优化。通过提示优化过程中的向量数据库和自动化反馈循环，提高了PRAG对光合作用相关查询响应的准确性和相关性。PRAG在与科学写作相关的五个指标上平均提高了8.7%，在来源透明度上提高了25.4%。此外，其科学深度和领域覆盖范围与光合作用研究论文相当。通过知识图谱，PRAG对其数据库内外的响应进行了结构化，使其能够与数据库中的63%和测试论文中的39.5%的关键实体相匹配。PRAG可以在光合作用研究和更广泛的植物科学领域中应用，为更深入的数据分析和预测能力开辟了道路。', 'title_zh': '使用大型语言模型合成光合作用研究知识'}
{'arxiv_id': 'arXiv:2502.00611', 'title': 'Enhancing Code Consistency in AI Research with Large Language Models and Retrieval-Augmented Generation', 'authors': 'Rajat Keshri, Arun George Zachariah, Michael Boone', 'link': 'https://arxiv.org/abs/2502.00611', 'abstract': 'Ensuring that code accurately reflects the algorithms and methods described in research papers is critical for maintaining credibility and fostering trust in AI research. This paper presents a novel system designed to verify code implementations against the algorithms and methodologies outlined in corresponding research papers. Our system employs Retrieval-Augmented Generation to extract relevant details from both the research papers and code bases, followed by a structured comparison using Large Language Models. This approach improves the accuracy and comprehensiveness of code implementation verification while contributing to the transparency, explainability, and reproducibility of AI research. By automating the verification process, our system reduces manual effort, enhances research credibility, and ultimately advances the state of the art in code verification.', 'abstract_zh': '确保代码准确反映研究论文中描述的算法和方法对于维持人工智能研究的可信度至关重要。本文提出了一种新颖的系统，旨在验证代码实现与对应研究论文中描述的算法和方法的一致性。该系统采用检索增强生成技术从研究论文和代码库中提取相关细节，随后使用大规模语言模型进行结构化的比较。该方法提高了代码实现验证的准确性和全面性，同时促进了人工智能研究的透明度、可解释性和可重复性。通过自动化验证过程，该系统减少了人工努力，增强了研究可信度，并最终推动了代码验证领域的最新进展。', 'title_zh': '使用大型语言模型和检索增强生成技术提升AI研究中的代码一致性'}
{'arxiv_id': 'arXiv:2502.00306', 'title': 'Riddle Me This! Stealthy Membership Inference for Retrieval-Augmented Generation', 'authors': 'Ali Naseh, Yuefeng Peng, Anshuman Suri, Harsh Chaudhari, Alina Oprea, Amir Houmansadr', 'link': 'https://arxiv.org/abs/2502.00306', 'abstract': "Retrieval-Augmented Generation (RAG) enables Large Language Models (LLMs) to generate grounded responses by leveraging external knowledge databases without altering model parameters. Although the absence of weight tuning prevents leakage via model parameters, it introduces the risk of inference adversaries exploiting retrieved documents in the model's context. Existing methods for membership inference and data extraction often rely on jailbreaking or carefully crafted unnatural queries, which can be easily detected or thwarted with query rewriting techniques common in RAG systems. In this work, we present Interrogation Attack (IA), a membership inference technique targeting documents in the RAG datastore. By crafting natural-text queries that are answerable only with the target document's presence, our approach demonstrates successful inference with just 30 queries while remaining stealthy; straightforward detectors identify adversarial prompts from existing methods up to ~76x more frequently than those generated by our attack. We observe a 2x improvement in TPR@1%FPR over prior inference attacks across diverse RAG configurations, all while costing less than $0.02 per document inference.", 'abstract_zh': '检索增强生成（RAG）通过利用外部知识数据库来生成 grounded 响应，从而增强大型语言模型（LLMs）的能力，而无需修改模型参数。尽管缺乏权重调整可以防止通过模型参数泄漏，但它引入了推理对手可能利用检索文档的风险，这些文档可能被包含在模型的上下文中。现有的成员身份推断和数据提取方法往往依赖于劫持或精心构建的不自然查询，这些方法可以通过在 RAG 系统中常用的方法重新编写查询来轻松检测或阻止。在本工作中，我们提出了查询攻击（Interrogation Attack, IA），这是一种针对 RAG 数据存储库中文档的成员身份推断技术。通过构建仅当目标文档存在时才能回答的自然文本查询，我们的方法仅使用 30 个查询便成功实现了推断，并且具有隐蔽性；现有的检测器能够比由我们攻击生成的对抗性提示更频繁（高达约 76 倍）地检测出来自现有方法的对抗性提示。我们观察到，与先前的推断攻击相比，在各种 RAG 配置下，我们的攻击在 1% FPR 的 TPR 上提高了 2 倍，同时每文档推断成本低于 0.02 美元。', 'title_zh': '这个谜题给你！隐蔽的成员推理在检索增强生成中的应用'}
{'arxiv_id': 'arXiv:2502.01298', 'title': 'Augmented Knowledge Graph Querying leveraging LLMs', 'authors': 'Marco Arazzi, Davide Ligari, Serena Nicolazzo, Antonino Nocera', 'link': 'https://arxiv.org/abs/2502.01298', 'abstract': 'Adopting Knowledge Graphs (KGs) as a structured, semantic-oriented, data representation model has significantly improved data integration, reasoning, and querying capabilities across different domains. This is especially true in modern scenarios such as Industry 5.0, in which the integration of data produced by humans, smart devices, and production processes plays a crucial role. However, the management, retrieval, and visualization of data from a KG using formal query languages can be difficult for non-expert users due to their technical complexity, thus limiting their usage inside industrial environments. For this reason, we introduce SparqLLM, a framework that utilizes a Retrieval-Augmented Generation (RAG) solution, to enhance the querying of Knowledge Graphs (KGs). SparqLLM executes the Extract, Transform, and Load (ETL) pipeline to construct KGs from raw data. It also features a natural language interface powered by Large Language Models (LLMs) to enable automatic SPARQL query generation. By integrating template-based methods as retrieved-context for the LLM, SparqLLM enhances query reliability and reduces semantic errors, ensuring more accurate and efficient KG interactions. Moreover, to improve usability, the system incorporates a dynamic visualization dashboard that adapts to the structure of the retrieved data, presenting the query results in an intuitive format. Rigorous experimental evaluations demonstrate that SparqLLM achieves high query accuracy, improved robustness, and user-friendly interaction with KGs, establishing it as a scalable solution to access semantic data.', 'abstract_zh': '将以下论文内容或标题翻译成中文，符合学术规范：\n\n采用知识图谱（KGs）作为结构化且语义导向的数据表示模型，极大地提升了不同领域间的数据集成、推理和查询能力。特别是在第五代工业（Industry 5.0）等现代场景中，人类、智能设备和生产过程所产生的数据的整合起着至关重要的作用。然而，由于使用形式化的查询语言管理、检索和可视化知识图谱中的数据对于非专家用户来说可能会非常复杂，从而限制了其在工业环境中的应用。因此，我们提出了SparqLLM框架，该框架利用检索增强生成（RAG）解决方案来增强对知识图谱的查询能力。SparqLLM执行抽取、转换和加载（ETL）管道，从原始数据中构建知识图谱。此外，该框架还配备了一个由大型语言模型（LLMs）驱动的自然语言界面，能够实现自动SPARQL查询生成。通过将基于模板的方法作为检索上下文整合到LLM中，SparqLLM提高了查询可靠性，减少了语义错误，确保了更准确和高效的知识图谱交互。为了提高易用性，系统还集成了一个动态可视化仪表板，根据检索数据的结构进行调整，以直观的格式展示查询结果。严格的实证研究表明，SparqLLM实现了高度准确的查询、增强的鲁棒性和用户友好的知识图谱交互，使其成为访问语义数据的可扩展解决方案。', 'title_zh': '利用大语言模型增强知识图谱查询'}
{'arxiv_id': 'arXiv:2502.01386', 'title': 'Topic-FlipRAG: Topic-Orientated Adversarial Opinion Manipulation Attacks to Retrieval-Augmented Generation Models', 'authors': 'Yuyang Gong, Zhuo Chen, Miaokun Chen, Fengchang Yu, Wei Lu, Xiaofeng Wang, Xiaozhong Liu, Jiawei Liu', 'link': 'https://arxiv.org/abs/2502.01386', 'abstract': "Retrieval-Augmented Generation (RAG) systems based on Large Language Models (LLMs) have become essential for tasks such as question answering and content generation. However, their increasing impact on public opinion and information dissemination has made them a critical focus for security research due to inherent vulnerabilities. Previous studies have predominantly addressed attacks targeting factual or single-query manipulations. In this paper, we address a more practical scenario: topic-oriented adversarial opinion manipulation attacks on RAG models, where LLMs are required to reason and synthesize multiple perspectives, rendering them particularly susceptible to systematic knowledge poisoning. Specifically, we propose Topic-FlipRAG, a two-stage manipulation attack pipeline that strategically crafts adversarial perturbations to influence opinions across related queries. This approach combines traditional adversarial ranking attack techniques and leverages the extensive internal relevant knowledge and reasoning capabilities of LLMs to execute semantic-level perturbations. Experiments show that the proposed attacks effectively shift the opinion of the model's outputs on specific topics, significantly impacting user information perception. Current mitigation methods cannot effectively defend against such attacks, highlighting the necessity for enhanced safeguards for RAG systems, and offering crucial insights for LLM security research.", 'abstract_zh': '基于大型语言模型（LLMs）的检索增强生成（RAG）系统在问答和内容生成任务中已变得至关重要。然而，它们对公共意见和信息传播日益增长的影响使得它们成为安全研究的重中之重，这是因为它们存在固有的漏洞。之前的研究所主要关注针对事实或单一查询操纵的攻击。在本文中，我们重点关注更具实际意义的场景：针对RAG模型的主题导向敌对观点操纵攻击，其中LLMs需要综合分析和合成多个视角，使其特别容易遭受系统性知识污染。具体而言，我们提出了一种名为Topic-FlipRAG的两阶段操纵攻击框架，该框架通过战略性地构造对抗性扰动来影响相关查询中的观点。该方法结合了传统的对抗性排名攻击技术，利用了LLMs广泛的相关内部知识和推理能力来进行语义级扰动。实验结果显示，提出的攻击有效改变了模型在特定主题上的输出观点，显著影响了用户的信息化感知。当前的缓解方法无法有效防御此类攻击，突显了增强RAG系统防护的必要性，并为LLM安全研究提供了重要见解。', 'title_zh': 'Topic-FlipRAG：面向主题的对抗性意见操纵攻击以检索增强生成模型为目标'}
