{'arxiv_id': 'arXiv:2412.19784', 'title': 'Can AI Help with Your Personal Finances?', 'authors': 'Oudom Hean, Utsha Saha, Binita Saha', 'link': 'https://arxiv.org/abs/2412.19784', 'abstract': "In recent years, Large Language Models (LLMs) have emerged as a transformative development in artificial intelligence (AI), drawing significant attention from industry and academia. Trained on vast datasets, these sophisticated AI systems exhibit impressive natural language processing and content generation capabilities. This paper explores the potential of LLMs to address key challenges in personal finance, focusing on the United States. We evaluate several leading LLMs, including OpenAI's ChatGPT, Google's Gemini, Anthropic's Claude, and Meta's Llama, to assess their effectiveness in providing accurate financial advice on topics such as mortgages, taxes, loans, and investments. Our findings show that while these models achieve an average accuracy rate of approximately 70%, they also display notable limitations in certain areas. Specifically, LLMs struggle to provide accurate responses for complex financial queries, with performance varying significantly across different topics. Despite these limitations, the analysis reveals notable improvements in newer versions of these models, highlighting their growing utility for individuals and financial advisors. As these AI systems continue to evolve, their potential for advancing AI-driven applications in personal finance becomes increasingly promising.", 'abstract_zh': '近年来，大规模语言模型（LLMs）已成为人工智能（AI）领域的一个变革性发展，引起了业界和学术界的广泛关注。这些模型通过训练大量数据集，展现了卓越的自然语言处理和内容生成能力。本文探讨了LLMs在个人金融领域中解决关键挑战的潜力，重点关注美国。我们评估了几种领先的LLM模型，包括OpenAI的ChatGPT、Google的Gemini、Anthropic的Claude以及Meta的Llama，并评估其在提供关于按揭、税收、贷款和投资等财务建议方面的准确性和有效性。研究结果表明，尽管这些模型的平均准确率为约70%，但在某些领域仍表现出明显的局限性。具体而言，LLMs在处理复杂的财务查询时存在困难，不同主题的性能差异显著。尽管存在这些局限性，分析结果表明，这些模型的新版本在某些方面有了显著改进，突显了其在个人和财务顾问中的逐步实用性。随着这些人工智能系统的不断进化，它们在个人金融领域中推动AI驱动应用的潜力越来越具有前景。', 'title_zh': '人工智能能帮助您的个人财务管理吗？'}
{'arxiv_id': 'arXiv:2412.19759', 'title': 'Enhancing Cognitive Diagnosis by Modeling Learner Cognitive Structure State', 'authors': 'Zhifu Chen, Hengnian Gu, Jin Peng Zhou, Dongdai Zhou', 'link': 'https://arxiv.org/abs/2412.19759', 'abstract': "Cognitive diagnosis represents a fundamental research area within intelligent education, with the objective of measuring the cognitive status of individuals. Theoretically, an individual's cognitive state is essentially equivalent to their cognitive structure state. Cognitive structure state comprises two key components: knowledge state (KS) and knowledge structure state (KUS). The knowledge state reflects the learner's mastery of individual concepts, a widely studied focus within cognitive diagnosis. In contrast, the knowledge structure state-representing the learner's understanding of the relationships between concepts-remains inadequately modeled. A learner's cognitive structure is essential for promoting meaningful learning and shaping academic performance. Although various methods have been proposed, most focus on assessing KS and fail to assess KUS. To bridge this gap, we propose an innovative and effective framework-CSCD (Cognitive Structure State-based Cognitive Diagnosis)-which introduces a novel framework to modeling learners' cognitive structures in diagnostic assessments, thereby offering new insights into cognitive structure modeling. Specifically, we employ an edge-feature-based graph attention network to represent the learner's cognitive structure state, effectively integrating KS and KUS. Extensive experiments conducted on real datasets demonstrate the superior performance of this framework in terms of diagnostic accuracy and interpretability.", 'abstract_zh': '认知诊断是智能教育中的一个基本研究领域，其目标在于测量个体的认知状态。理论上，个体的认知状态本质上等同于其认知结构状态。认知结构状态包括两个关键组成部分：知识状态（KS）和认知结构状态（KUS）。知识状态反映了学习者对个别概念的掌握情况，这是认知诊断中广泛研究的重点。相比之下，认知结构状态则代表了学习者理解概念之间关系的情况，其建模仍不够完善。学习者的认知结构对于促进有意义的学习和塑造学术表现至关重要。尽管提出了一系列方法，但大多数方法侧重于评估KS，而未能评估KUS。为弥补这一不足，我们提出了一种创新且有效的框架——CSCD（基于认知结构状态的认知诊断），该框架引入了一种新的建模方式来表征诊断评估中学习者的认知结构，从而为认知结构建模提供了新的视角。具体而言，我们采用基于边特征的图注意力网络来表示学习者的认知结构状态，有效地整合了KS和KUS。实证研究表明，该框架在诊断准确性和可解释性方面具有优越的性能。', 'title_zh': '通过建模学习者认知结构状态来增强认知诊断'}
{'arxiv_id': 'arXiv:2412.19755', 'title': '"Did my figure do justice to the answer?" : Towards Multimodal Short Answer Grading with Feedback (MMSAF)', 'authors': 'Pritam Sil, Bhaskaran Raman, Pushpak Bhattacharyya', 'link': 'https://arxiv.org/abs/2412.19755', 'abstract': "Personalized feedback plays a vital role in a student's learning process. While existing systems are adept at providing feedback over MCQ-based evaluation, this work focuses more on subjective and open-ended questions, which is similar to the problem of Automatic Short Answer Grading (ASAG) with feedback. Additionally, we introduce the Multimodal Short Answer grading with Feedback (MMSAF) problem over the traditional ASAG feedback problem to address the scenario where the student answer and reference answer might contain images. Moreover, we introduce the MMSAF dataset with 2197 data points along with an automated framework for generating such data sets. Our evaluations on existing LLMs over this dataset achieved an overall accuracy of 55\\% on Level of Correctness labels, 75\\% on Image Relevance labels and a score of 4.27 out of 5 in correctness level of LLM generated feedback as rated by experts. As per experts, Pixtral achieved a rating of above 4 out of all metrics, indicating that it is more aligned to human judgement, and that it is the best solution for assisting students.", 'abstract_zh': '个性化反馈在学生学习过程中起着至关重要的作用。虽然现有的系统在提供基于选择题的评估反馈方面表现出色，本研究更多地关注主观和开放性问题，这与自动简短答案评分（ASAG）及其反馈问题类似。此外，我们引入了多模态简短答案评分与反馈（MMSAF）问题，扩大了传统的ASAG反馈问题，以应对学生答案和参考答案可能包含图像的情况。我们还介绍了包含2197个数据点的MMSAF数据集，并提供了一个生成此类数据集的自动化框架。在该数据集上对现有LLM进行评估，结果显示在正确性标签上总体准确率为55%，在图像相关性标签上为75%，LLM生成的反馈在专家评估中的正确性得分为4.27/5。根据专家的评价，Pixtral在所有指标上得分超过4分，表明其更符合人的判断，是辅助学生学习的最佳解决方案。', 'title_zh': '“我的图表是否恰当地反映了答案？”：迈向基于反馈的多模态简答题评分（MMSAF）'}
{'arxiv_id': 'arXiv:2412.19726', 'title': 'Can Large Language Models Adapt to Other Agents In-Context?', 'authors': 'Matthew Riemer, Zahra Ashktorab, Djallel Bouneffouf, Payel Das, Miao Liu, Justin D. Weisz, Murray Campbell', 'link': 'https://arxiv.org/abs/2412.19726', 'abstract': "As the research community aims to build better AI assistants that are more dynamic and personalized to the diversity of humans that they interact with, there is increased interest in evaluating the theory of mind capabilities of large language models (LLMs). Indeed, several recent studies suggest that LLM theory of mind capabilities are quite impressive, approximating human-level performance. Our paper aims to rebuke this narrative and argues instead that past studies were not directly measuring agent performance, potentially leading to findings that are illusory in nature as a result. We draw a strong distinction between what we call literal theory of mind i.e. measuring the agent's ability to predict the behavior of others and functional theory of mind i.e. adapting to agents in-context based on a rational response to predictions of their behavior. We find that top performing open source LLMs may display strong capabilities in literal theory of mind, depending on how they are prompted, but seem to struggle with functional theory of mind -- even when partner policies are exceedingly simple. Our work serves to highlight the double sided nature of inductive bias in LLMs when adapting to new situations. While this bias can lead to strong performance over limited horizons, it often hinders convergence to optimal long-term behavior.", 'abstract_zh': '随着研究社区致力于构建更具动态性和个性化的AI助手，以更好地适应与之交互的人类多样性，对大型语言模型（LLMs）的理论共情能力的评估变得越来越受欢迎。实际上，多项近期研究显示，LLMs的理论共情能力表现出色，接近人类水平。本文旨在反驳这一观点，并认为过去的许多研究并未直接衡量代理的实际表现，有可能导致一些虚幻的研究发现。我们严格区分了所谓的字面意义上的理论共情与功能性的理论共情。字面意义上的理论共情指的是测评代理预测他人行为的能力，而功能性理论共情则基于预测他人行为的理性响应来进行即境适应。我们发现，开源顶级的LLMs在字面意义上的理论共情方面可能会表现出很强的能力，但似乎在功能性理论共情方面遇到困难——即使伙伴策略非常简单也是如此。我们的工作突显了LLMs在适应新情况时的两面性引致偏见的特性。虽然这种偏见可以在短期内促进强大表现，但它往往阻碍了对最优长期行为的收敛。', 'title_zh': '大型语言模型能否在上下文中适应其他代理？'}
{'arxiv_id': 'arXiv:2412.19723', 'title': 'OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis', 'authors': 'Qiushi Sun, Kanzhi Cheng, Zichen Ding, Chuanyang Jin, Yian Wang, Fangzhi Xu, Zhenyu Wu, Chengyou Jia, Liheng Chen, Zhoumianze Liu, Ben Kao, Guohao Li, Junxian He, Yu Qiao, Zhiyong Wu', 'link': 'https://arxiv.org/abs/2412.19723', 'abstract': "Graphical User Interface (GUI) agents powered by Vision-Language Models (VLMs) have demonstrated human-like computer control capability. Despite their utility in advancing digital automation, a critical bottleneck persists: collecting high-quality trajectory data for training. Common practices for collecting such data rely on human supervision or synthetic data generation through executing pre-defined tasks, which are either resource-intensive or unable to guarantee data quality. Moreover, these methods suffer from limited data diversity and significant gaps between synthetic data and real-world environments. To address these challenges, we propose OS-Genesis, a novel GUI data synthesis pipeline that reverses the conventional trajectory collection process. Instead of relying on pre-defined tasks, OS-Genesis enables agents first to perceive environments and perform step-wise interactions, then retrospectively derive high-quality tasks to enable trajectory-level exploration. A trajectory reward model is then employed to ensure the quality of the generated trajectories. We demonstrate that training GUI agents with OS-Genesis significantly improves their performance on highly challenging online benchmarks. In-depth analysis further validates OS-Genesis's efficiency and its superior data quality and diversity compared to existing synthesis methods. Our codes, data, and checkpoints are available at \\href{this https URL}{OS-Genesis Homepage}.", 'abstract_zh': '由视觉语言模型（VLMs）驱动的图形用户界面（GUI）代理展示了类似人类的计算机操作能力。尽管这些技术在推进数字自动化方面具有实用性，但存在一个关键瓶颈：收集用于训练的高质量轨迹数据。目前收集此类数据的常见方法依赖于人工监督或通过执行预定义任务生成合成数据，这两种方法要么资源密集型，要么无法保证数据质量。此外，这些方法在数据多样性和合成数据与现实环境之间的差距方面也存在局限性。为解决这些问题，我们提出了OS-Genesis，这是一种新颖的GUI数据合成管道，它逆转了传统的轨迹数据收集过程。与依赖预定义任务不同，OS-Genesis 允许代理首先感知环境并进行逐步交互，然后回顾性地生成高质量的任务，以实现轨迹级别的探索。随后使用轨迹奖励模型来确保生成轨迹的质量。我们证明，使用OS-Genesis训练GUI代理在极具挑战性的在线基准测试中显著提高了其性能。深入分析进一步验证了OS-Genesis在效率以及数据质量和多样性方面的优势，优于现有的合成方法。我们的代码、数据和检查点可在OS-Genesis主页\\href{this https URL}{OS-Genesis Homepage}获取。', 'title_zh': 'OS-Genesis: 通过逆向任务合成自动化构建GUI代理轨迹'}
{'arxiv_id': 'arXiv:2412.19718', 'title': 'Text2Insight: Transform natural language text into insights seamlessly using multi-model architecture', 'authors': 'Pradeep Sain', 'link': 'https://arxiv.org/abs/2412.19718', 'abstract': "The growing demand for dynamic, user-centric data analysis and visualization is evident across domains like healthcare, finance, and research. Traditional visualization tools often fail to meet individual user needs due to their static and predefined nature. To address this gap, Text2Insight is introduced as an innovative solution that delivers customized data analysis and visualizations based on user-defined natural language requirements. Leveraging a multi-model architecture, Text2Insight transforms user inputs into actionable insights and dynamic visualizations.\nThe methodology begins with analyzing the input dataset to extract structural details such as columns and values. A pre-trained Llama3 model converts the user's natural language query into an SQL query, which is further refined using a Named Entity Recognition (NER) model for accuracy. A chart predictor determines the most suitable visualization type, while the Llama3 model generates insights based on the SQL query's results. The output is a user-friendly and visually informative chart. To enhance analysis capabilities, the system integrates a question-answering model and a predictive model using the BERT framework. These models provide insights into historical data and predict future trends.\nPerformance evaluation of Text2Insight demonstrates its effectiveness, achieving high accuracy (99%), precision (100%), recall (99%), and F1-score (99%), with a BLEU score of 0.5. The question-answering model attained an accuracy of 89% and the predictive model achieved 70% accuracy. These results validate Text2Insight as a robust and viable solution for transforming natural language text into dynamic, user-specific data analysis and visualizations.", 'abstract_zh': '随着医疗保健、金融和研究等领域对动态、以用户为中心的数据分析和可视化需求日益增长，传统可视化工具由于其静态和预定义的特点，往往无法满足个体用户的需求。为了解决这一问题，Text2Insight作为一种创新解决方案应运而生，它能够根据用户定义的自然语言需求提供定制化的数据分析和可视化。利用多模态架构，Text2Insight将用户输入转换为可操作的洞察和动态可视化。\n\n该方法开始时是对输入数据集进行分析以提取其结构特征，如列和值。预训练的Llama3模型将用户的自然语言查询转换为SQL查询，并通过命名实体识别（NER）模型进一步优化以提高准确性。图表预测器确定最适合的可视化类型，而Llama3模型根据SQL查询的结果生成洞察。输出结果为用户友好且视觉信息丰富的图表。为了增强分析能力，该系统整合了基于BERT框架的问答模型和预测模型。这些模型能够提供历史数据的洞察并预测未来趋势。\n\nText2Insight的性能评估显示了其有效性，其准确率为99%、精确率为100%、召回率为99%、F1分数为99%，BLEU评分为0.5。问答模型的准确率为89%，预测模型的准确率为70%。这些结果验证了Text2Insight作为将自然语言文本转换为动态、用户特定的数据分析和可视化的稳健和可行解决方案的有效性。', 'title_zh': 'Text2Insight：利用多模型架构将自然语言文本无缝转换为洞察'}
{'arxiv_id': 'arXiv:2412.19707', 'title': 'Toward Adaptive Reasoning in Large Language Models with Thought Rollback', 'authors': 'Sijia Chen, Baochun Li', 'link': 'https://arxiv.org/abs/2412.19707', 'abstract': "Large language models (LLMs) have been routinely used to solve various tasks using step-by-step reasoning. However, the structure of intermediate reasoning steps, or thoughts, is rigid and unidirectional, such as chains, trees, or acyclic-directed graphs. Consequently, the resulting inflexible and forward-only reasoning may not address challenging tasks and fail when the LLM frequently gives false responses, i.e., ``hallucinations''. This paper proposes a new reasoning framework, called Thought Rollback (TR), allowing LLMs to adaptively build thought structure while maintaining effective reasoning toward problem-solving under ``hallucinations''. The core mechanism of TR is rolling back thoughts, which allows LLMs to perform error analysis on thoughts, and thus roll back to any previously mistaken thought for revision. Subsequently, by including such trial-and-error in the prompt to guide the LLM, each rollback leads to one more reliable reasoning path. Therefore, starting with a simple prompt without human annotations, LLM with TR adaptively and gradually explores thoughts for a correct solution. Comprehensive experiments on mathematical problems and multi-task reasoning demonstrate the state-of-the-art performance of TR in terms of problem-solving rate and interaction cost. For instance, the solving rate of GPT-4 with TR outperforms the current best by $9\\%$ on the MATH dataset.", 'abstract_zh': '大规模语言模型（LLMs）已被广泛用于通过逐步推理来解决各种任务。然而，中间推理步骤或思维的结构是僵硬且单向的，例如链式、树状或无环有向图。因此，这种僵化且单向的推理可能无法解决复杂的任务，并且在LLM频繁给出错误响应（即“幻觉”）时失败。本文提出了一种新的推理框架，称为思维反向推理（Thought Rollback，TR），允许LLMs在遭遇“幻觉”时灵活建立思维结构并保持有效的推理以解决问题。TR的核心机制是反向思维，这使LLMs能够对思维进行错误分析，并回溯到任何先前的错误思维进行修正。随后，通过在提示中包括这种试错过程来引导LLMs，每次反向推理都能增加一个更可靠的理由路径。因此，从一个简单的提示开始，无需人工注释，配备TR的LLMs可以逐步探索多种思维路径以找到正确的解决方案。在数学问题和多任务推理的全面实验中，TR在解决问题的速度和交互成本方面表现出最先进的性能。例如，配备TR的GPT-4在MATH数据集中的解决问题率优于当前最佳结果9%。', 'title_zh': '面向大规模语言模型的具有回溯思维的自适应推理方法'}
{'arxiv_id': 'arXiv:2412.19696', 'title': 'An Integrated Optimization and Deep Learning Pipeline for Predicting Live Birth Success in IVF Using Feature Optimization and Transformer-Based Models', 'authors': 'Arezoo Borji, Hossam Haick, Birgit Pohn, Antonia Graf, Jana Zakall, S M Ragib Shahriar Islam, Gernot Kronreif, Daniel Kovatchki, Heinz Strohmer, Sepideh Hatamikia', 'link': 'https://arxiv.org/abs/2412.19696', 'abstract': 'In vitro fertilization (IVF) is a widely utilized assisted reproductive technology, yet predicting its success remains challenging due to the multifaceted interplay of clinical, demographic, and procedural factors. This study develops a robust artificial intelligence (AI) pipeline aimed at predicting live birth outcomes in IVF treatments. The pipeline uses anonymized data from 2010 to 2018, obtained from the Human Fertilization and Embryology Authority (HFEA). We evaluated the prediction performance of live birth success as a binary outcome (success/failure) by integrating different feature selection methods, such as principal component analysis (PCA) and particle swarm optimization (PSO), with different traditional machine learning-based classifiers including random forest (RF) and decision tree, as well as deep learning-based classifiers including custom transformer-based model and a tab transformer model with an attention mechanism. Our research demonstrated that the best performance was achieved by combining PSO for feature selection with the TabTransformer-based deep learning model, yielding an accuracy of 99.50% and an AUC of 99.96%, highlighting its significant performance to predict live births. This study establishes a highly accurate AI pipeline for predicting live birth outcomes in IVF, demonstrating its potential to enhance personalized fertility treatments.', 'abstract_zh': '体外受精（IVF）是一种广泛应用的辅助生殖技术，但由于临床、人口统计和程序因素的复杂相互作用，预测其成功率仍然具有挑战性。本研究开发了一种稳健的人工智能（AI） pipeline，旨在预测IVF治疗的活产结果。该pipeline使用了2010年至2018年由人类受精与胚胎学管理局（HFEA）提供的匿名数据。我们通过将不同的特征选择方法（如主成分分析（PCA）和粒子群优化（PSO））与不同的传统机器学习分类器（包括随机森林（RF）和决策树）以及基于深度学习的分类器（包括自定义的变压器模型和带有注意机制的表征变压器模型）相结合，来评估活产成功的预测性能，结果将活产成功与否作为二元结果（成功/失败）进行评估。研究结果表明，最佳性能是由PSO进行特征选择并与基于表征变压器的深度学习模型结合实现的，其准确率为99.50%，AUC为99.96%，突出显示了其预测活产结果的显著性能。本研究建立了一个高度准确的AI pipeline，用于预测IVF的活产结果，展示了其提高个性化生育治疗的潜力。', 'title_zh': '基于特征优化和变压器模型的综合优化与深度学习管道：用于预测辅助生殖技术（IVF）活产成功率的研究'}
{'arxiv_id': 'arXiv:2412.19684', 'title': 'Boosting Private Domain Understanding of Efficient MLLMs: A Tuning-free, Adaptive, Universal Prompt Optimization Framework', 'authors': 'Jiang Liu, Bolin Li, Haoyuan Li, Tianwei Lin, Wenqiao Zhang, Tao Zhong, Zhelun Yu, Jinghao Wei, Hao Cheng, Hao Jiang, Zheqi Lv, Juncheng Li, Siliang Tang, Yueting Zhuang', 'link': 'https://arxiv.org/abs/2412.19684', 'abstract': "Efficient multimodal large language models (EMLLMs), in contrast to multimodal large language models (MLLMs), reduce model size and computational costs and are often deployed on resource-constrained devices. However, due to data privacy concerns, existing open-source EMLLMs rarely have access to private domain-specific data during the pre-training process, making them difficult to directly apply in device-specific domains, such as certain business scenarios. To address this weakness, this paper focuses on the efficient adaptation of EMLLMs to private domains, specifically in two areas: 1) how to reduce data requirements, and 2) how to avoid parameter fine-tuning. Specifically, we propose a tun\\textbf{\\underline{I}}ng-free, a\\textbf{\\underline{D}}aptiv\\textbf{\\underline{E}}, univers\\textbf{\\underline{AL}} \\textbf{\\underline{Prompt}} Optimization Framework, abbreviated as \\textit{\\textbf{\\ourmethod{}}} which consists of two stages: 1) Predefined Prompt, based on the reinforcement searching strategy, generate a prompt optimization strategy tree to acquire optimization priors; 2) Prompt Reflection initializes the prompt based on optimization priors, followed by self-reflection to further search and refine the prompt. By doing so, \\ourmethod{} elegantly generates the ``ideal prompts'' for processing private domain-specific data. Note that our method requires no parameter fine-tuning and only a small amount of data to quickly adapt to the data distribution of private data. Extensive experiments across multiple tasks demonstrate that our proposed \\ourmethod{} significantly improves both efficiency and performance compared to baselines.", 'abstract_zh': '高效的多模态大语言模型（EMLLMs），与多模态大语言模型（MLLMs）相比，能够减少模型规模和计算成本，常常部署在资源受限的设备上。但是，由于数据隐私的考虑，现有的开源EMLLMs很少在预训练过程中访问到特定领域的私有数据，这使得它们难以直接应用于特定设备领域的某些业务场景中。为了解决这一弱点，本文专注于EMLLMs的有效适配到私有领域，具体包括两个方面：1）如何减少数据需求，2）如何避免参数微调。具体来说，我们提出了一种无需微调、自适应且通用的提示优化框架（Tuning-Free, Adaptive, Universal Prompt Optimization Framework），简称\\textit{\\textbf{\\ourmethod{}}}，该框架由两个阶段组成：1）预定义提示，基于强化搜索策略生成一个提示优化策略树来获取优化先验；2）提示反映根据优化先验初始化提示，随后进行自省进一步搜索和精炼提示。通过这种方式，\\ourmethod{}优雅地生成了处理私有领域数据的“理想提示”。值得注意的是，我们的方法不需要参数微调，并且只需要少量数据即可快速适应私有数据的数据分布。通过在多个任务上的广泛实验表明，相比基线方法，提出的\\ourmethod{}在效率和性能上均有显著改进。', 'title_zh': '增强有效大语言模型的私有领域理解：一种无调优、自适应且通用的提示优化框架'}
{'arxiv_id': 'arXiv:2412.19638', 'title': 'Xmodel-2 Technical Report', 'authors': 'Wang Qun, Liu Yang, Lin Qingquan, Qu Zhijiu, Jiang Ling', 'link': 'https://arxiv.org/abs/2412.19638', 'abstract': 'Xmodel-2 is a 1.2-billion-parameter large language model designed specifically for reasoning tasks. Its architecture enables different model scales to share a unified set of hyperparameters, allowing for extensive experimentation on smaller models and seamless transfer of optimal configurations to larger models. To maximize training efficiency and stability, Xmodel-2 employs the WSD learning rate scheduler from MiniCPM. Pretrained on 1.5 trillion tokens from diverse sources, Xmodel-2 achieves state-of-the-art performance in complex reasoning and agent-based tasks, while maintaining low training costs. These results highlight the potential of efficient model design and training strategies in advancing reasoning capabilities. Model checkpoints and code are publicly available on GitHub at this https URL', 'abstract_zh': 'Xmodel-2 是一个专门为推理任务设计的拥有 1.2 亿参数的大型语言模型。其架构允许不同规模的模型共享统一的超参数集，这既促进了小型模型的大规模实验，也实现了最优配置在大模型上的无缝转移。为了提高训练效率和稳定性，Xmodel-2 使用了 MiniCPM 中的 WSD 学习率调度器。Xmodel-2 采用来自多样化数据源的 1.5 万亿 tokens 进行预训练，在复杂推理和基于代理的任务中达到了最先进的性能，同时保持了较低的训练成本。这些结果突显了高效模型设计和训练策略在提升推理能力方面的重要潜力。Xmodel-2 的模型检查点和代码已公开发布在 GitHub 上，访问链接为 [该 https URL]。', 'title_zh': 'Xmodel-2 技术报告'}
{'arxiv_id': 'arXiv:2412.19562', 'title': 'Hindsight Planner: A Closed-Loop Few-Shot Planner for Embodied Instruction Following', 'authors': 'Yuxiao Yang, Shenao Zhang, Zhihan Liu, Huaxiu Yao, Zhaoran Wang', 'link': 'https://arxiv.org/abs/2412.19562', 'abstract': "This work focuses on building a task planner for Embodied Instruction Following (EIF) using Large Language Models (LLMs). Previous works typically train a planner to imitate expert trajectories, treating this as a supervised task. While these methods achieve competitive performance, they often lack sufficient robustness. When a suboptimal action is taken, the planner may encounter an out-of-distribution state, which can lead to task failure. In contrast, we frame the task as a Partially Observable Markov Decision Process (POMDP) and aim to develop a robust planner under a few-shot assumption. Thus, we propose a closed-loop planner with an adaptation module and a novel hindsight method, aiming to use as much information as possible to assist the planner. Our experiments on the ALFRED dataset indicate that our planner achieves competitive performance under a few-shot assumption. For the first time, our few-shot agent's performance approaches and even surpasses that of the full-shot supervised agent.", 'abstract_zh': '本文专注于使用大型语言模型（LLMs）构建用于具身指令跟随（EIF）的任务规划器。以往的研究通常通过监督学习的方式训练规划器模仿专家轨迹。虽然这些方法能够实现竞争力的表现，但它们往往缺乏足够的鲁棒性。当采取次优行动时，规划器可能会遇到未见过的状态，从而导致任务失败。相比之下，我们将任务框架化为部分可观测马尔可夫决策过程（POMDP），并旨在在少量示例假设下开发出鲁棒的规划器。因此，我们提出了一种具有适应模块和新颖的反馈机制的闭环规划器，力求充分利用所有可用信息来辅助规划器。我们对ALFRED数据集的实验表明，我们的规划器在少量示例假设下能够实现竞争力的表现。首次证明，我们的少量示例代理的表现不仅接近甚至超越了全示例监督代理的表现。', 'title_zh': 'hindsight 手段 在此背景下是指“后见之明”（hindsight），在任务完成后根据结果重新规划路径或动作。为了更准确地翻译这个标题，可以将其翻译为：\n\n hindsight 规划器：一种闭环少量示例规划器，用于体现式指令跟随\n\n或者更学术化的翻译为：\n\n 后见之明规划器：一种闭环少量示例规划器，用于基于体现的指令跟随\n\n这样翻译既保留了原意，又符合学术论文的规范。'}
{'arxiv_id': 'arXiv:2412.19550', 'title': 'Learning states enhanced knowledge tracing: Simulating the diversity in real-world learning process', 'authors': 'Shanshan Wang, Xueying Zhang, Keyang Wang, Xun Yang, Xingyi Zhang', 'link': 'https://arxiv.org/abs/2412.19550', 'abstract': "The Knowledge Tracing (KT) task focuses on predicting a learner's future performance based on the historical interactions. The knowledge state plays a key role in learning process. However, considering that the knowledge state is influenced by various learning factors in the interaction process, such as the exercises similarities, responses reliability and the learner's learning state. Previous models still face two major limitations. First, due to the exercises differences caused by various complex reasons and the unreliability of responses caused by guessing behavior, it is hard to locate the historical interaction which is most relevant to the current answered exercise. Second, the learning state is also a key factor to influence the knowledge state, which is always ignored by previous methods. To address these issues, we propose a new method named Learning State Enhanced Knowledge Tracing (LSKT). Firstly, to simulate the potential differences in interactions, inspired by Item Response Theory~(IRT) paradigm, we designed three different embedding methods ranging from coarse-grained to fine-grained views and conduct comparative analysis on them. Secondly, we design a learning state extraction module to capture the changing learning state during the learning process of the learner. In turn, with the help of the extracted learning state, a more detailed knowledge state could be captured. Experimental results on four real-world datasets show that our LSKT method outperforms the current state-of-the-art methods.", 'abstract_zh': '知识追踪（KT）任务的重点在于基于历史互动预测学习者的未来表现。知识状态在学习过程中起着关键作用。然而，由于互动过程中各种学习因素的影响，如练习的相似性、响应的可靠性以及学习者的学习状态，知识状态受到的影响非常复杂。因此，现有的模型仍然面临两大主要局限性。首先，由于各种复杂原因导致的练习差异以及猜测行为造成的响应不可靠性，难以定位与当前回答练习最相关的历史互动。其次，学习状态也是影响知识状态的关键因素，但这种方法在大多数情况下并未被考虑进去。为了解决这些问题，我们提出了一种名为学习状态增强知识追踪（LSKT）的新方法。首先，为了模拟互动中的潜在差异，借鉴项目反应理论（IRT）的范式，我们设计了三种不同级别的嵌入方法，从粗粒度到细粒度，并进行了比较分析。其次，我们设计了一个学习状态提取模块，以捕捉学习者学习过程中不断变化的学习状态。通过提取的学习状态信息，能够更详细地捕捉到知识状态。在四个真实世界数据集上的实验结果表明，我们的LSKT方法在当前最先进的方法中表现更优。', 'title_zh': '增强学习状态的知识追踪：模拟真实世界学习过程中的多样性'}
{'arxiv_id': 'arXiv:2412.19524', 'title': 'PLN and NARS Often Yield Similar strength $\\times$ confidence Given Highly Uncertain Term Probabilities', 'authors': 'Ben Goertzel', 'link': 'https://arxiv.org/abs/2412.19524', 'abstract': 'We provide a comparative analysis of the deduction, induction, and abduction formulas used in Probabilistic Logic Networks (PLN) and the Non-Axiomatic Reasoning System (NARS), two uncertain reasoning frameworks aimed at AGI. One difference between the two systems is that, at the level of individual inference rules, PLN directly leverages both term and relationship probabilities, whereas NARS only leverages relationship frequencies and has no simple analogue of term probabilities. Thus we focus here on scenarios where there is high uncertainty about term probabilities, and explore how this uncertainty influences the comparative inferential conclusions of the two systems. We compare the product of strength and confidence ($s\\times c$) in PLN against the product of frequency and confidence ($f\\times c$) in NARS (quantities we refer to as measuring the "power" of an uncertain statement) in cases of high term probability uncertainty, using heuristic analyses and elementary numerical computations. We find that in many practical situations with high term probability uncertainty, PLN and NARS formulas give very similar results for the power of an inference conclusion, even though they sometimes come to these similar numbers in quite different ways.', 'abstract_zh': '我们将对概率逻辑网络（PLN）和非公理推理系统（NARS）这两种针对通用人工智能（AGI）的不确定性推理框架中所使用的演绎、归纳和 abduction 公式的比较分析。这两者的一个区别在于，从单个推理规则的层面来看，PLN 直接利用了项和关系的概率，而 NARS 只利用了关系频率，并没有项概率的简单对应物。因此，本文重点关注项概率高度不确定的场景，探讨这种不确定性如何影响两种系统之间的比较推理结论。我们通过启发式分析和基本的数值计算，比较了在高项概率不确定性情况下，PLN 中的「强度乘以信心」（\\(s \\times c\\)）与 NARS 中的「频率乘以信心」（\\(f \\times c\\)）（我们称这两个量衡量不确定性陈述的「力量」）的结果。结果显示，在许多高项概率不确定性的实际场景中，尽管 PLN 和 NARS 推理公式有时通过截然不同的方式得出相似的结果，但它们在推理结论的力量方面给出了非常相似的结果。', 'title_zh': 'PLN和NARS在高度不确定项概率情况下经常表现出类似的强度×置信度值'}
{'arxiv_id': 'arXiv:2412.19523', 'title': 'Attribution for Enhanced Explanation with Transferable Adversarial eXploration', 'authors': 'Zhiyu Zhu, Jiayu Zhang, Zhibo Jin, Huaming Chen, Jianlong Zhou, Fang Chen', 'link': 'https://arxiv.org/abs/2412.19523', 'abstract': 'The interpretability of deep neural networks is crucial for understanding model decisions in various applications, including computer vision. AttEXplore++, an advanced framework built upon AttEXplore, enhances attribution by incorporating transferable adversarial attack methods such as MIG and GRA, significantly improving the accuracy and robustness of model explanations. We conduct extensive experiments on five models, including CNNs (Inception-v3, ResNet-50, VGG16) and vision transformers (MaxViT-T, ViT-B/16), using the ImageNet dataset. Our method achieves an average performance improvement of 7.57\\% over AttEXplore and 32.62\\% compared to other state-of-the-art interpretability algorithms. Using insertion and deletion scores as evaluation metrics, we show that adversarial transferability plays a vital role in enhancing attribution results. Furthermore, we explore the impact of randomness, perturbation rate, noise amplitude, and diversity probability on attribution performance, demonstrating that AttEXplore++ provides more stable and reliable explanations across various models. We release our code at: this https URL', 'abstract_zh': '深度神经网络的可解释性对于理解各种应用中的模型决策至关重要，包括计算机视觉。AttEXplore++ 是基于 AttEXplore 的一种高级框架，通过集成迁移可利用的对抗攻击方法（如 MIG 和 GRA），显著提高了模型解释的准确性和鲁棒性。我们使用 ImageNet 数据集对五个模型，包括 CNNs（Inception-v3、ResNet-50、VGG16）和视觉变换器（MaxViT-T、ViT-B/16）进行了广泛的实验。我们的方法在模型表现上比 AttEXplore 提高了 7.57%，相对于其他最先进的可解释性算法提高了 32.62%。利用插入和删除得分作为评估指标，我们展示了对抗迁移性在提升归因结果中的重要性。此外，我们还探讨了随机性、扰动率、噪声幅度和多样性概率对归因性能的影响，证明了 AttEXplore++ 在各种模型中提供了更加稳定和可靠的解释。我们已经在 GitHub 上发布了我们的代码：[这里提供代码链接]', 'title_zh': '增强解释的迁移可转移对抗探索归因'}
{'arxiv_id': 'arXiv:2412.19507', 'title': 'Hybrid Local Causal Discovery', 'authors': 'Zhaolong Ling, Honghui Peng, Yiwen Zhang, Peng Zhou, Xingyu Wu, Kui Yu, Xindong Wu', 'link': 'https://arxiv.org/abs/2412.19507', 'abstract': 'Local causal discovery aims to learn and distinguish the direct causes and effects of a target variable from observed data. Existing constraint-based local causal discovery methods use AND or OR rules in constructing the local causal skeleton, but using either rule alone is prone to produce cascading errors in the learned local causal skeleton, and thus impacting the inference of local causal relationships. On the other hand, directly applying score-based global causal discovery methods to local causal discovery may randomly return incorrect results due to the existence of local equivalence classes. To address the above issues, we propose a Hybrid Local Causal Discovery algorithm, called HLCD. Specifically, HLCD initially utilizes a constraint-based approach combined with the OR rule to obtain a candidate skeleton and then employs a score-based method to eliminate redundant portions in the candidate skeleton. Furthermore, during the local causal orientation phase, HLCD distinguishes between V-structures and equivalence classes by comparing the local structure scores between the two, thereby avoiding orientation interference caused by local equivalence classes. We conducted extensive experiments with seven state-of-the-art competitors on 14 benchmark Bayesian network datasets, and the experimental results demonstrate that HLCD significantly outperforms existing local causal discovery algorithms.', 'abstract_zh': '局部因果发现旨在从观测数据中学习并区分目标变量的直接原因和效应。现有的基于约束的局部因果发现方法在构建局部因果骨架时使用了AND或OR规则，但单独使用任一规则容易导致局部因果骨架中的连锁错误，从而影响局部因果关系的推断。另一方面，直接将基于分数的全局因果发现方法应用于局部因果发现可能会由于局部等价类的存在而随机返回错误结果。为了解决上述问题，我们提出了一种混合局部因果发现算法，称为HLCD。具体来说，HLCD 首先采用结合使用 OR 规则的基于约束的方法获取候选骨架，然后使用基于分数的方法消除候选骨架中的冗余部分。此外，在局部因果定向阶段，HLCD 通过比较两者之间的局部结构分数来区分 V-结构和等价类，从而避免由局部等价类引起的定向干扰。我们在14个基准贝叶斯网络数据集上与 seven 个最先进的竞争对手进行了广泛的实验，实验结果表明，HLCD 显著优于现有的局部因果发现算法。', 'title_zh': '混合局部因果发现'}
{'arxiv_id': 'arXiv:2412.19450', 'title': 'Find the Intention of Instruction: Comprehensive Evaluation of Instruction Understanding for Large Language Models', 'authors': 'Hyeonseok Moon, Jaehyung Seo, Seungyoon Lee, Chanjun Park, Heuiseok Lim', 'link': 'https://arxiv.org/abs/2412.19450', 'abstract': "One of the key strengths of Large Language Models (LLMs) is their ability to interact with humans by generating appropriate responses to given instructions. This ability, known as instruction-following capability, has established a foundation for the use of LLMs across various fields and serves as a crucial metric for evaluating their performance. While numerous evaluation benchmarks have been developed, most focus solely on clear and coherent instructions. However, we have noted that LLMs can become easily distracted by instruction-formatted statements, which may lead to an oversight of their instruction comprehension skills. To address this issue, we introduce the Intention of Instruction (IoInst) benchmark. This benchmark evaluates LLMs' capacity to remain focused and understand instructions without being misled by extraneous instructions. The primary objective of this benchmark is to identify the appropriate instruction that accurately guides the generation of a given context. Our findings suggest that even recently introduced state-of-the-art models still lack instruction understanding capability. Along with the proposition of IoInst in this study, we also present broad analyses of the several strategies potentially applicable to IoInst.", 'abstract_zh': '大型语言模型（LLMs）的一个关键优势在于它们能够根据给定的指示生成适当的响应，这一能力被称为指令跟随能力。这种能力为LLMs在各个领域的应用奠定了基础，并且是评估其性能的重要指标。虽然已经开发出了许多评估基准，但大多数基准主要关注明确且连贯的指示。然而，我们注意到LLMs容易被格式化的指示陈述所分散，这可能导致它们忽略理解指示的能力。为了解决这一问题，我们提出了Intention of Instruction（IoInst）基准。此基准旨在评估LLMs保持专注并理解指示而不受无关指示误导的能力。该基准的主要目标是识别适当的指示，这些指示能够准确引导给定背景的生成。我们的研究发现即使是最新的先进模型在指示理解能力上仍然有所欠缺。除了在本研究中提出IoInst基准外，我们还讨论了几种潜在适用于IoInst的方法策略。', 'title_zh': '探索指令意图：大型语言模型指令理解的综合评估'}
{'arxiv_id': 'arXiv:2412.19442', 'title': 'A Survey on Large Language Model Acceleration based on KV Cache Management', 'authors': 'Haoyang Li, Yiming Li, Anxin Tian, Tianhao Tang, Zhanchao Xu, Xuejia Chen, Nicole Hu, Wei Dong, Qing Li, Lei Chen', 'link': 'https://arxiv.org/abs/2412.19442', 'abstract': 'Large Language Models (LLMs) have revolutionized a wide range of domains such as natural language processing, computer vision, and multi-modal tasks due to their ability to comprehend context and perform logical reasoning. However, the computational and memory demands of LLMs, particularly during inference, pose significant challenges when scaling them to real-world, long-context, and real-time applications. Key-Value (KV) cache management has emerged as a critical optimization technique for accelerating LLM inference by reducing redundant computations and improving memory utilization. This survey provides a comprehensive overview of KV cache management strategies for LLM acceleration, categorizing them into token-level, model-level, and system-level optimizations. Token-level strategies include KV cache selection, budget allocation, merging, quantization, and low-rank decomposition, while model-level optimizations focus on architectural innovations and attention mechanisms to enhance KV reuse. System-level approaches address memory management, scheduling, and hardware-aware designs to improve efficiency across diverse computing environments. Additionally, the survey provides an overview of both text and multimodal datasets and benchmarks used to evaluate these strategies. By presenting detailed taxonomies and comparative analyses, this work aims to offer useful insights for researchers and practitioners to support the development of efficient and scalable KV cache management techniques, contributing to the practical deployment of LLMs in real-world applications. The curated paper list for KV cache management is in: \\href{this https URL}{this https URL}.', 'abstract_zh': '大型语言模型（LLMs）因其能够理解上下文并进行逻辑推理的能力，已经革新了自然语言处理、计算机视觉和多模态任务等多个领域。然而，LLMs在推理过程中对计算和内存资源的需求提出了重大挑战，尤其是在扩展到实际应用、长上下文和实时应用场景时。关键值（KV）缓存管理已成为加速LLM推理的关键优化技术，通过减少冗余计算和提高内存利用率来实现这一目标。本文综述了KV缓存管理策略的全面概述，将这些策略分为按令牌、模型和系统三个层面的优化。按令牌层面的策略包括KV缓存选择、预算分配、合并、量化和低秩分解，而模型层面的优化则侧重于通过架构创新和注意力机制增强KV重用。系统层面的方法则侧重于内存管理、调度和硬件感知设计，以提高不同计算环境下的效率。此外，本文还概述了用于评估这些策略的文本和多模态数据集及基准测试。通过提供详细的分类和比较分析，本文旨在为研究人员和实践者提供有用的见解，支持高效和可扩展的KV缓存管理技术的发展，并促进LLM在实际应用中的实用部署。本文总结的KV缓存管理论文列表如下：\\href{this https URL}{this https URL}', 'title_zh': '基于键值缓存管理的大型语言模型加速综述'}
{'arxiv_id': 'arXiv:2412.19425', 'title': 'A Self-Efficacy Theory-based Study on the Teachers Readiness to Teach Artificial Intelligence in Public Schools in Sri Lanka', 'authors': 'Chathura Rajapakse, Wathsala Ariyarathna, Shanmugalingam Selvakan', 'link': 'https://arxiv.org/abs/2412.19425', 'abstract': "This study investigates Sri Lankan ICT teachers' readiness to teach AI in schools, focusing on self-efficacy. A survey of over 1,300 teachers assessed their self-efficacy using a scale developed based on Bandura's theory. PLS-SEM analysis revealed that teachers' self-efficacy was low, primarily influenced by emotional and physiological states and imaginary experiences related to AI instruction. Mastery experiences had a lesser impact, and vicarious experiences and verbal persuasion showed no significant effect. The study highlights the need for a systemic approach to teacher professional development, considering the limitations in teachers' AI expertise and social capital. Further research is recommended to explore a socio-technical systems perspective for effective AI teacher training.", 'abstract_zh': '本研究调查了 Sri Lankan ICT 教师在课堂上教授人工智能 (AI) 的准备情况，重点关注自我效能感。调查了超过 1,300 名教师的自我效能感，使用了基于 Bandura 理论开发的量表进行了评估。PLS-SEM 分析表明，教师的自我效能感较低，主要受到与 AI 教学相关的情绪和生理状态以及想象经验的影响。掌握经验的影响较小，替代经验和言语说服则没有显著影响。研究强调了需要系统的方法来提升教师的专业发展，考虑到教师在人工智能专业技能和社会资本方面的局限性。建议进一步研究社会技术系统视角下的有效人工智能教师培训方法。', 'title_zh': '基于自我效能理论的斯里兰卡公立学校教师教授人工智能准备情况研究'}
{'arxiv_id': 'arXiv:2412.19363', 'title': 'Large Language Models for Market Research: A Data-augmentation Approach', 'authors': 'Mengxin Wang, Dennis J. Zhang, Heng Zhang', 'link': 'https://arxiv.org/abs/2412.19363', 'abstract': 'Large Language Models (LLMs) have transformed artificial intelligence by excelling in complex natural language processing tasks. Their ability to generate human-like text has opened new possibilities for market research, particularly in conjoint analysis, where understanding consumer preferences is essential but often resource-intensive. Traditional survey-based methods face limitations in scalability and cost, making LLM-generated data a promising alternative. However, while LLMs have the potential to simulate real consumer behavior, recent studies highlight a significant gap between LLM-generated and human data, with biases introduced when substituting between the two. In this paper, we address this gap by proposing a novel statistical data augmentation approach that efficiently integrates LLM-generated data with real data in conjoint analysis. Our method leverages transfer learning principles to debias the LLM-generated data using a small amount of human data. This results in statistically robust estimators with consistent and asymptotically normal properties, in contrast to naive approaches that simply substitute human data with LLM-generated data, which can exacerbate bias. We validate our framework through an empirical study on COVID-19 vaccine preferences, demonstrating its superior ability to reduce estimation error and save data and costs by 24.9\\% to 79.8\\%. In contrast, naive approaches fail to save data due to the inherent biases in LLM-generated data compared to human data. Another empirical study on sports car choices validates the robustness of our results. Our findings suggest that while LLM-generated data is not a direct substitute for human responses, it can serve as a valuable complement when used within a robust statistical framework.', 'abstract_zh': '大规模语言模型（LLMs）通过在复杂自然语言处理任务中的出色表现，彻底改变了人工智能领域。它们生成类人文本的能力为市场研究带来了新的可能性，尤其是在共析分析中，了解消费者偏好至关重要但往往耗费资源。传统的基于调查的方法在扩展性和成本方面存在局限性，使得LLM生成的数据成为一个有前景的替代选择。然而，尽管LLM有能力模拟真实的消费者行为，但最近的研究表明，LLM生成的数据与人类数据之间存在显著差距，这种替代带来了一些偏差。本文通过提出一种新的统计数据增强方法，解决了这一问题，该方法能高效地将LLM生成的数据与共析分析中的真实数据结合起来。我们的方法利用迁移学习原则，通过少量人类数据对LLM生成的数据进行去偏处理。这使得我们能够获得统计上稳健的估计量，具有一致性和渐近正态性，而简单地用LLM生成的数据替代人类数据的方法则无法实现这一点，反而会加剧偏差。我们通过COVID-19疫苗偏好的实证研究验证了该框架的有效性，结果表明，与传统的替代方法相比，我们的方法能显著减少估计误差，并节省24.9%到79.8%的数据和成本。相反，传统的替代方法由于LLM生成数据与人类数据之间的固有偏差，无法节省数据。另一个关于跑车选择的实证研究验证了我们结果的稳健性。研究结果表明，虽然LLM生成的数据不能直接替代人类回应，但在稳健的统计框架中使用时，其可以作为一种有价值的补充。', 'title_zh': '市场研究中的大型语言模型：一种数据增强 approach'}
{'arxiv_id': 'arXiv:2412.19321', 'title': 'A novel framework for MCDM based on Z numbers and soft likelihood function', 'authors': 'Yuanpeng He', 'link': 'https://arxiv.org/abs/2412.19321', 'abstract': 'The optimization on the structure of process of information management under uncertain environment has attracted lots of attention from researchers around the world. Nevertheless, how to obtain accurate and rational evaluation from assessments produced by experts is still an open problem. Specially, intuitionistic fuzzy set provides an effective solution in handling indeterminate information. And Yager proposes a novel method for fusion of probabilistic evidence to handle uncertain and conflicting information lately which is called soft likelihood function. This paper devises a novel framework of soft likelihood function based on information volume of fuzzy membership and credibility measure for extracting truly useful and valuable information from uncertainty. An application is provided to verify the validity and correctness of the proposed framework. Besides, the comparisons with other existing methods further demonstrate the superiority of the novel framework of soft likelihood function.', 'abstract_zh': '在不确定环境下的信息管理结构优化已吸引了全世界研究者的广泛关注。然而，如何从专家评估中获得准确且合理的评价仍然是一个开放性问题。特别地，直觉模糊集提供了一种有效处理不确定信息的方法。最近，Yager提出了一种新的方法来融合概率证据以处理不确定性和冲突信息，这种方法称为软似然函数。本文提出了一种基于模糊隶属度信息量和可信度度量的新型软似然函数框架，用于从不确定性中提取真正有用和有价值的信息。还提供了一个实际应用以验证该框架的有效性和正确性。此外，与其他现有方法的比较进一步证明了新型软似然函数框架的优势。', 'title_zh': '基于Z数和软似然函数的多准则决策方法新框架'}
{'arxiv_id': 'arXiv:2412.19311', 'title': 'xSRL: Safety-Aware Explainable Reinforcement Learning -- Safety as a Product of Explainability', 'authors': 'Risal Shahriar Shefin, Md Asifur Rahman, Thai Le, Sarra Alqahtani', 'link': 'https://arxiv.org/abs/2412.19311', 'abstract': "Reinforcement learning (RL) has shown great promise in simulated environments, such as games, where failures have minimal consequences. However, the deployment of RL agents in real-world systems such as autonomous vehicles, robotics, UAVs, and medical devices demands a higher level of safety and transparency, particularly when facing adversarial threats. Safe RL algorithms have been developed to address these concerns by optimizing both task performance and safety constraints. However, errors are inevitable, and when they occur, it is essential that the RL agents can also explain their actions to human operators. This makes trust in the safety mechanisms of RL systems crucial for effective deployment. Explainability plays a key role in building this trust by providing clear, actionable insights into the agent's decision-making process, ensuring that safety-critical decisions are well understood. While machine learning (ML) has seen significant advances in interpretability and visualization, explainability methods for RL remain limited. Current tools fail to address the dynamic, sequential nature of RL and its needs to balance task performance with safety constraints over time. The re-purposing of traditional ML methods, such as saliency maps, is inadequate for safety-critical RL applications where mistakes can result in severe consequences. To bridge this gap, we propose xSRL, a framework that integrates both local and global explanations to provide a comprehensive understanding of RL agents' behavior. xSRL also enables developers to identify policy vulnerabilities through adversarial attacks, offering tools to debug and patch agents without retraining. Our experiments and user studies demonstrate xSRL's effectiveness in increasing safety in RL systems, making them more reliable and trustworthy for real-world deployment. Code is available at this https URL.", 'abstract_zh': '强化学习（RL）在模拟环境中，如游戏中，已经显示出了巨大的潜力，而在这些环境中，失败的后果可以忽略不计。然而，当将RL代理部署到自动驾驶车辆、机器人、无人机和医疗设备等现实系统中时，对安全性和透明度的要求更高，特别是在面对敌对威胁时。为应对这些挑战，已经开发出了安全RL算法，通过优化任务性能和安全约束来提高系统安全性。尽管如此，错误是不可避免的，当它们发生时，至关重要的是，RL代理能够向人类操作员解释其行为。因此，对于RL系统安全机制的信任对于有效的部署至关重要。可解释性在建立这种信任方面发挥着关键作用，它通过提供清晰且可操作的洞察来解释代理的决策过程，确保关键的安全决策易于理解。虽然机器学习（ML）在可解释性和可视化方面取得了显著进展，但目前的RL解释工具仍然有限。现有的工具未能解决RL的动态性和序列性特点，也无法平衡任务性能与时间上的安全约束。传统的ML方法，例如显著性图，对于需要安全决策的RL应用来说远远不足，因为错误可能会导致严重后果。为解决这一问题，我们提出了一种名为xSRL的框架，该框架整合了局部和全局解释，以全面理解RL代理的行为。xSRL还使开发人员能够通过敌对攻击识别策略漏洞，并通过提供调试和修复代理的工具而无需重新训练来增强代理。通过实验和用户研究，我们展示了xSRL在提高RL系统安全性方面的有效性，使它们在实际部署中更加可靠和可信赖。相关代码可通过以下链接获取：[此链接处]。', 'title_zh': 'xSRL：具有解释性的安全强化学习——解释性即安全'}
{'arxiv_id': 'arXiv:2412.19254', 'title': 'Leveraging Self-Training and Variational Autoencoder for Agitation Detection in People with Dementia Using Wearable Sensors', 'authors': 'Abeer Badawi, Somayya Elmoghazy, Samira Choudhury, Khalid Elgazzar, Amer Burhan', 'link': 'https://arxiv.org/abs/2412.19254', 'abstract': 'Dementia is a neurodegenerative disorder that has been growing among elder people over the past decades. This growth profoundly impacts the quality of life for patients and caregivers due to the symptoms arising from it. Agitation and aggression (AA) are some of the symptoms of people with severe dementia (PwD) in long-term care or hospitals. AA not only causes discomfort but also puts the patients or others at potential risk. Existing monitoring solutions utilizing different wearable sensors integrated with Artificial Intelligence (AI) offer a way to detect AA early enough for timely and adequate medical intervention. However, most studies are limited by the availability of accurately labeled datasets, which significantly affects the efficacy of such solutions in real-world scenarios. This study presents a novel comprehensive approach to detect AA in PwD using physiological data from the Empatica E4 wristbands. The research creates a diverse dataset, consisting of three distinct datasets gathered from 14 participants across multiple hospitals in Canada. These datasets have not been extensively explored due to their limited labeling. We propose a novel approach employing self-training and a variational autoencoder (VAE) to detect AA in PwD effectively. The proposed approach aims to learn the representation of the features extracted using the VAE and then uses a semi-supervised block to generate labels, classify events, and detect AA. We demonstrate that combining Self-Training and Variational Autoencoder mechanism significantly improves model performance in classifying AA in PwD. Among the tested techniques, the XGBoost classifier achieved the highest accuracy of 90.16\\%. By effectively addressing the challenge of limited labeled data, the proposed system not only learns new labels but also proves its superiority in detecting AA.', 'abstract_zh': '阿尔茨海默病是一种神经退行性疾病，在过去几十年中，这种疾病在老年人中的发病率逐渐增加。这种增长对患者和护理者的质量生活产生了深远的影响，因为这些症状会引发一系列问题。激越和攻击性（AA）是重度阿尔茨海默病患者在长期护理机构或医院中常见的症状之一。AA不仅会引起不适，还会使患者或他人面临潜在的风险。现有的利用各种可穿戴传感器与人工智能（AI）相结合的监测解决方案，可以在早期检测到AA，从而及时进行适当的医疗干预。然而，大多数研究受限于准确标注数据集的可用性，这在实际场景中严重影响了这些解决方案的有效性。本研究提出了一种全新的综合方法，使用Empatica E4腕带生理数据来检测重度阿尔茨海默病患者的激越和攻击性（AA）。研究构建了一个多样化的数据集，该数据集由来自加拿大多个医院的14名参与者的数据组成，且这些数据集由于标注较少而未曾被广泛探索。我们提出了一种新的方法，采用自我训练和变分自编码器（VAE）来有效检测重度阿尔茨海默病患者的AA。所提方法旨在通过VAE学习提取的特征表示，然后使用半监督模块生成标签、分类事件并检测AA。我们证明，结合自我训练和变分自编码器机制显著提高了模型在分类重度阿尔茨海默病患者激越和攻击性方面的性能。在测试的技术中，XGBoost分类器的准确性最高，达到了90.16%。通过有效解决标注数据有限的挑战，所提出的系统不仅能够学习新标签，还证明了其在检测激越和攻击性方面的优越性。', 'title_zh': '利用自我训练和变分自编码器在穿戴式传感器辅助下进行 dementia 病人激越检测'}
{'arxiv_id': 'arXiv:2412.19215', 'title': 'Optimizing Fantasy Sports Team Selection with Deep Reinforcement Learning', 'authors': 'Shamik Bhattacharjee, Kamlesh Marathe, Hitesh Kapoor, Nilesh Patil', 'link': 'https://arxiv.org/abs/2412.19215', 'abstract': "Fantasy sports, particularly fantasy cricket, have garnered immense popularity in India in recent years, offering enthusiasts the opportunity to engage in strategic team-building and compete based on the real-world performance of professional athletes. In this paper, we address the challenge of optimizing fantasy cricket team selection using reinforcement learning (RL) techniques. By framing the team creation process as a sequential decision-making problem, we aim to develop a model that can adaptively select players to maximize the team's potential performance. Our approach leverages historical player data to train RL algorithms, which then predict future performance and optimize team composition. This not only represents a huge business opportunity by enabling more accurate predictions of high-performing teams but also enhances the overall user experience. Through empirical evaluation and comparison with traditional fantasy team drafting methods, we demonstrate the effectiveness of RL in constructing competitive fantasy teams. Our results show that RL-based strategies provide valuable insights into player selection in fantasy sports.", 'abstract_zh': '近年来，特别是板球项目，在印度的幻想体育（Fantasy Sports）取得了巨大的 popularity，为爱好者们提供了通过战略性的团队组建和基于职业运动员在现实世界中的表现来进行竞争的机会。在本文中，我们探讨了使用强化学习（Reinforcement Learning, RL）技术优化幻想板球队伍选择的挑战。通过将团队创建过程视为一个序列决策问题，我们旨在开发一种能够自适应地选择球员来最大化团队潜在表现的模型。我们的方法利用历史球员数据来训练RL算法，这些算法随后预测未来表现并优化团队配置。这不仅代表了一个巨大的商业机会，通过提供更准确的高表现队伍预测，而且还提升了整体用户体验。通过实证分析并与其他传统的幻想队伍选拔方法进行比较，我们展示了RL在构建竞争力强的幻想队伍方面的效果。我们的研究表明，基于RL的策略为幻想体育中的球员选择提供了有价值的见解。', 'title_zh': '使用深度强化学习优化梦幻体育队选拔'}
{'arxiv_id': 'arXiv:2412.19198', 'title': 'Multi-Attribute Constraint Satisfaction via Language Model Rewriting', 'authors': 'Ashutosh Baheti, Debanjana Chakraborty, Faeze Brahman, Ronan Le Bras, Ximing Lu, Nouha Dziri, Yejin Choi, Mark Riedl, Maarten Sap', 'link': 'https://arxiv.org/abs/2412.19198', 'abstract': 'Obeying precise constraints on top of multiple external attributes is a common computational problem underlying seemingly different domains, from controlled text generation to protein engineering. Existing language model (LM) controllability methods for multi-attribute constraint satisfaction often rely on specialized architectures or gradient-based classifiers, limiting their flexibility to work with arbitrary black-box evaluators and pretrained models. Current general-purpose large language models, while capable, cannot achieve fine-grained multi-attribute control over external attributes. Thus, we create Multi-Attribute Constraint Satisfaction (MACS), a generalized method capable of finetuning language models on any sequential domain to satisfy user-specified constraints on multiple external real-value attributes. Our method trains LMs as editors by sampling diverse multi-attribute edit pairs from an initial set of paraphrased outputs. During inference, LM iteratively improves upon its previous solution to satisfy constraints for all attributes by leveraging our designed constraint satisfaction reward. We additionally experiment with reward-weighted behavior cloning to further improve the constraint satisfaction rate of LMs. To evaluate our approach, we present a new Fine-grained Constraint Satisfaction (FineCS) benchmark, featuring two challenging tasks: (1) Text Style Transfer, where the goal is to simultaneously modify the sentiment and complexity of reviews, and (2) Protein Design, focusing on modulating fluorescence and stability of Green Fluorescent Proteins (GFP). Our empirical results show that MACS achieves the highest threshold satisfaction in both FineCS tasks, outperforming strong domain-specific baselines. Our work opens new avenues for generalized and real-value multi-attribute control, with implications for diverse applications spanning NLP and bioinformatics.', 'abstract_zh': '在多个外部属性的精确约束下进行计算，是不同领域中潜在看似不同的任务下的一个常见计算问题，从受控文本生成到蛋白质工程都是如此。现有的面向多属性约束的语言模型（LM）可控方法通常依赖于专门的架构或基于梯度的分类器，这限制了它们与任意的黑盒评估器和预训练模型的灵活性。尽管通用的大规模语言模型具备强大的能力，但在实现对外部属性的精细多属性控制方面仍然存在不足。因此，我们提出了多属性约束满足方法（MACS），这是一种泛化的框架，能够在任何序列表现领域中对语言模型进行微调，以满足用户指定的多个外部实值约束。该方法通过从初始的同义版本输出集中采样多样化的多属性编辑配对来训练LM作为编辑器。在推理过程中，LM通过利用我们设计的约束满足奖励逐步改进其先前的解决方案，以满足所有属性的约束。此外，我们还尝试使用奖励加权的行为克隆来进一步提高LM的约束满足率。为了评估该方法，我们提出了一种新的细粒度约束满足基准（FineCS），其包含两个具有挑战性的任务：（1）文本样式转换，目标是同时修改评论的情感和复杂性；（2）蛋白质设计，关注调整绿色荧光蛋白（GFP）的荧光强度和稳定性。我们的实验证据表明，MACS在两个FineCS任务中都实现了最高的约束满足阈值，超越了强大的领域特定基准。我们的工作为通用和实值多属性控制开辟了新的途径，具有跨自然语言处理和生物信息学等不同应用的广泛影响。', 'title_zh': '基于语言模型重写实现多属性约束满足'}
{'arxiv_id': 'arXiv:2412.19092', 'title': 'TrajGEOS: Trajectory Graph Enhanced Orientation-based Sequential Network for Mobility Prediction', 'authors': 'Zhaoping Hu, Zongyuan Huang, Jinming Yang, Tao Yang, Yaohui Jin, Yanyan Xu', 'link': 'https://arxiv.org/abs/2412.19092', 'abstract': "Human mobility studies how people move to access their needed resources and plays a significant role in urban planning and location-based services. As a paramount task of human mobility modeling, next location prediction is challenging because of the diversity of users' historical trajectories that gives rise to complex mobility patterns and various contexts. Deep sequential models have been widely used to predict the next location by leveraging the inherent sequentiality of trajectory data. However, they do not fully leverage the relationship between locations and fail to capture users' multi-level preferences. This work constructs a trajectory graph from users' historical traces and proposes a \\textbf{Traj}ectory \\textbf{G}raph \\textbf{E}nhanced \\textbf{O}rientation-based \\textbf{S}equential network (TrajGEOS) for next-location prediction tasks. TrajGEOS introduces hierarchical graph convolution to capture location and user embeddings. Such embeddings consider not only the contextual feature of locations but also the relation between them, and serve as additional features in downstream modules. In addition, we design an orientation-based module to learn users' mid-term preferences from sequential modeling modules and their recent trajectories. Extensive experiments on three real-world LBSN datasets corroborate the value of graph and orientation-based modules and demonstrate that TrajGEOS outperforms the state-of-the-art methods on the next location prediction task.", 'abstract_zh': '人类移动性研究表明人们如何移动以获取所需资源，这一研究在城市规划和基于位置的服务中扮演着重要角色。作为人类移动性建模的主要任务之一，下一步位置预测因其用户历史轨迹的多样性而变得具有挑战性，这导致复杂的移动模式和多种不同的环境背景。深度序列模型已经被广泛用于通过利用轨迹数据中的固有顺序性来进行下一步位置预测。然而，这些模型并未充分利用位置之间的关系，未能捕捉用户的多层偏好。本文从用户的历史轨迹中构建了一个轨迹图，并提出了一种用于下一步位置预测任务的轨迹图增强方向序列网络（TrajGEOS）。TrajGEOS 引入了分层图卷积来捕获位置和用户嵌入。这些嵌入不仅考虑了位置的上下文特征，还考虑了位置之间的关系，并作为下游模块的附加特征。此外，我们设计了一个基于方向的模块，从序列建模模块和用户的最近轨迹中学习用户的中期偏好。在三个真实世界的 LBSN 数据集上的广泛实验证实了图模块和基于方向的模块的价值，并表明 TrajGEOS 在下一步位置预测任务中优于最先进的方法。', 'title_zh': 'TrajGEOS：基于方向增强的轨迹图序列网络在移动性预测中的应用'}
{'arxiv_id': 'arXiv:2412.19064', 'title': 'Hierarchical Multi-agent Meta-Reinforcement Learning for Cross-channel Bidding', 'authors': 'Shenghong He, Chao Yu', 'link': 'https://arxiv.org/abs/2412.19064', 'abstract': 'Real-time bidding (RTB) plays a pivotal role in online advertising ecosystems. Advertisers employ strategic bidding to optimize their advertising impact while adhering to various financial constraints, such as the return-on-investment (ROI) and cost-per-click (CPC). Primarily focusing on bidding with fixed budget constraints, traditional approaches cannot effectively manage the dynamic budget allocation problem where the goal is to achieve global optimization of bidding performance across multiple channels with a shared budget. In this paper, we propose a hierarchical multi-agent reinforcement learning framework for multi-channel bidding optimization. In this framework, the top-level strategy applies a CPC constrained diffusion model to dynamically allocate budgets among the channels according to their distinct features and complex interdependencies, while the bottom-level strategy adopts a state-action decoupled actor-critic method to address the problem of extrapolation errors in offline learning caused by out-of-distribution actions and a context-based meta-channel knowledge learning method to improve the state representation capability of the policy based on the shared knowledge among different channels. Comprehensive experiments conducted on a large scale real-world industrial dataset from the Meituan ad bidding platform demonstrate that our method achieves a state-of-the-art performance.', 'abstract_zh': '实时竞价（RTB）在在线广告生态系统中扮演着至关重要的角色。广告商借助战略性竞价来优化广告效果，同时遵守各种财政约束，如投资回报率（ROI）和每点击成本（CPC）。主要关注固定预算约束下的竞价，传统的竞价方法并不能有效解决预算动态分配问题，即如何在多个渠道共享预算的情况下实现竞标性能的全局最优化。本文提出了一种分层多agent强化学习框架，用于多渠道竞价优化。在该框架中，顶层策略采用CPC约束扩散模型，根据各个渠道的独特特征和复杂的相互依赖关系动态分配预算；底层策略采用状态-动作解耦的actor-critic方法，以解决离线学习中由于非分布动作导致的外推误差问题，并通过基于共享知识的元渠道知识学习方法来提升策略的状态表示能力。在美团广告竞价平台提供的大规模真实工业数据集上进行全面实验表明，本方法达到了最先进的性能。', 'title_zh': '多代理层次元强化学习在跨渠道竞价中的应用'}
{'arxiv_id': 'arXiv:2412.19010', 'title': 'A theory of appropriateness with applications to generative artificial intelligence', 'authors': 'Joel Z. Leibo, Alexander Sasha Vezhnevets, Manfred Diaz, John P. Agapiou, William A. Cunningham, Peter Sunehag, Julia Haas, Raphael Koster, Edgar A. Duéñez-Guzmán, William S. Isaac, Georgios Piliouras, Stanley M. Bileschi, Iyad Rahwan, Simon Osindero', 'link': 'https://arxiv.org/abs/2412.19010', 'abstract': 'What is appropriateness? Humans navigate a multi-scale mosaic of interlocking notions of what is appropriate for different situations. We act one way with our friends, another with our family, and yet another in the office. Likewise for AI, appropriate behavior for a comedy-writing assistant is not the same as appropriate behavior for a customer-service representative. What determines which actions are appropriate in which contexts? And what causes these standards to change over time? Since all judgments of AI appropriateness are ultimately made by humans, we need to understand how appropriateness guides human decision making in order to properly evaluate AI decision making and improve it. This paper presents a theory of appropriateness: how it functions in human society, how it may be implemented in the brain, and what it means for responsible deployment of generative AI technology.', 'abstract_zh': '什么是适宜性？人类在不同的情境中 navigates 一个多层次且相互交织的概念系统，决定了在不同情境中适宜的行为规范。与朋友交往时我们表现出一种方式，与家人交往时又表现出另一种方式，而在工作中则又是一种方式。同样地，AI 在进行喜剧写作助手时的适宜行为与作为客户服务代表时的适宜行为是不同的。哪种行为在何种情境下被认为是适宜的，是由什么决定的？这些标准为何会随时间发生变化？既然所有关于 AI 适宜性的判断最终都是由人类做出的，我们就需要理解适宜性如何指导人类的决策过程，以便正确评估和改进 AI 的决策。本文提出了适宜性理论：探讨其在人类社会中的功能、在大脑中的实现机制，以及对于负责任地部署生成式 AI 技术的意义。', 'title_zh': '适当性理论及其在生成性人工智能中的应用'}
{'arxiv_id': 'arXiv:2412.18985', 'title': 'TravelAgent: Generative Agents in the Built Environment', 'authors': 'Ariel Noyman, Kai Hu, Kent Larson', 'link': 'https://arxiv.org/abs/2412.18985', 'abstract': 'Understanding human behavior in built environments is critical for designing functional, user centered urban spaces. Traditional approaches, such as manual observations, surveys, and simplified simulations, often fail to capture the complexity and dynamics of real world behavior. To address these limitations, we introduce TravelAgent, a novel simulation platform that models pedestrian navigation and activity patterns across diverse indoor and outdoor environments under varying contextual and environmental conditions. TravelAgent leverages generative agents integrated into 3D virtual environments, enabling agents to process multimodal sensory inputs and exhibit human-like decision-making, behavior, and adaptation. Through experiments, including navigation, wayfinding, and free exploration, we analyze data from 100 simulations comprising 1898 agent steps across diverse spatial layouts and agent archetypes, achieving an overall task completion rate of 76%. Using spatial, linguistic, and sentiment analyses, we show how agents perceive, adapt to, or struggle with their surroundings and assigned tasks. Our findings highlight the potential of TravelAgent as a tool for urban design, spatial cognition research, and agent-based modeling. We discuss key challenges and opportunities in deploying generative agents for the evaluation and refinement of spatial designs, proposing TravelAgent as a new paradigm for simulating and understanding human experiences in built environments.', 'abstract_zh': '理解在建成环境中的人类行为对于设计功能性和以用户为中心的城市空间至关重要。传统方法，如手动观察、问卷调查和简化的模拟，往往无法捕捉到现实世界行为的复杂性和动力性。为解决这些局限性，我们引入了TravelAgent，这是一个新型的模拟平台，能够在不同情境和环境条件下模拟行人导航和活动模式，涵盖多样化的室内和室外环境。TravelAgent 利用集成到三维虚拟环境中的生成性代理，使代理能够处理多模态感知输入并通过类人的决策、行为和适应性进行表现。通过导航、路径识别和自由探索等实验，我们分析了100次模拟（包含1898个代理步）所产生的数据，涵盖了不同的空间布局和代理类型，最终完成任务的整体率为76%。利用空间分析、语言分析和情感分析，我们展示了代理如何感知、适应或应对环境及分配的任务。我们的研究结果表明，TravelAgent 作为城市设计、空间认知研究和基于代理的建模工具的潜力。我们讨论了在评估和优化空间设计时部署生成性代理的关键挑战和机遇，提出TravelAgent作为模拟和理解建成环境中人类体验的新范式。', 'title_zh': 'TravelAgent: 建筑环境中的生成代理'}
{'arxiv_id': 'arXiv:2412.18914', 'title': 'Long-Range Tasks Using Short-Context LLMs: Incremental Reasoning With Structured Memories', 'authors': 'Dulhan Jayalath, James Bradley Wendt, Nicholas Monath, Sandeep Tata, Beliz Gunel', 'link': 'https://arxiv.org/abs/2412.18914', 'abstract': 'Long-range tasks require reasoning over long inputs. Existing solutions either need large compute budgets, training data, access to model weights, or use complex, task-specific approaches. We present PRISM, which alleviates these concerns by processing information as a stream of chunks, maintaining a structured in-context memory specified by a typed hierarchy schema. This approach demonstrates superior performance to baselines on diverse tasks while using at least 4x smaller contexts than long-context models. Moreover, PRISM is token-efficient. By producing short outputs and efficiently leveraging key-value (KV) caches, it achieves up to 54% cost reduction when compared to alternative short-context approaches. The method also scales down to tiny information chunks (e.g., 500 tokens) without increasing the number of tokens encoded or sacrificing quality. Furthermore, we show that it is possible to generate schemas to generalize our approach to new tasks with minimal effort.', 'abstract_zh': '长距离任务需要在长输入上进行推理。现有解决方案要么需要大量的计算资源、训练数据、访问模型权重，要么使用复杂且高度任务特定的方法。我们提出了PRISM，该方法通过将信息流以块的形式处理，并维持一个由类型化层次结构规范的结构化上下文记忆，来解决这些问题。这种方法在使用至少小4倍于长上下文模型的上下文的情况下，展示了优于基线方法的性能。此外，PRISM具有token效率。通过生成简短的输出并高效利用键值（KV）缓存，它相比其他短上下文方法的成本降低了多达54%。该方法还可以处理极小的信息块（例如，500个token），而无需增加编码的token数量或牺牲质量。此外，我们展示了通过最小的努力可以生成相应的类型化层次结构，从而将该方法应用于新任务中。', 'title_zh': '使用短语境大语言模型进行长范围任务：基于结构化记忆的增量推理'}
{'arxiv_id': 'arXiv:2412.18910', 'title': 'AdaEAGLE: Optimizing Speculative Decoding via Explicit Modeling of Adaptive Draft Structures', 'authors': 'Situo Zhang, Hankun Wang, Da Ma, Zichen Zhu, Lu Chen, Kunyao Lan, Kai Yu', 'link': 'https://arxiv.org/abs/2412.18910', 'abstract': 'Speculative Decoding (SD) is a popular lossless technique for accelerating the inference of Large Language Models (LLMs). We show that the decoding speed of SD frameworks with static draft structures can be significantly improved by incorporating context-aware adaptive draft structures. However, current studies on adaptive draft structures are limited by their performance, modeling approaches, and applicability. In this paper, we introduce AdaEAGLE, the first SD framework that explicitly models adaptive draft structures. AdaEAGLE leverages the Lightweight Draft Length Predictor (LDLP) module to explicitly predict the optimal number of draft tokens during inference to guide the draft model. It achieves comparable speedup results without manual thresholds and allows for deeper, more specialized optimizations. Moreover, together with threshold-based strategies, AdaEAGLE achieves a $1.62\\times$ speedup over the vanilla AR decoding and outperforms fixed-length SotA baseline while maintaining output quality.', 'abstract_zh': '前瞻解码（Speculative Decoding, SD）是一种常用于加速大型语言模型（LLMs）推理的无损加速技术。我们发现，在静态草稿结构的SD框架中引入上下文感知的自适应草稿结构可以显著提高解码速度。然而，当前关于自适应草稿结构的研究受到其性能、建模方法和适用范围的限制。在本文中，我们引入了AdaEAGLE，这是第一个明确建模自适应草稿结构的SD框架。AdaEAGLE利用轻量级草稿长度预测器（LDLP）模块，在推理过程中显式地预测出最优的草稿令牌数量，以指导草稿模型。它在无需手动阈值的情况下实现了可比的加速效果，并允许进行更深层次、更专业的优化。此外，结合基于阈值的策略，AdaEAGLE实现了相对于传统的AR解码1.62倍的加速，并优于固定长度的SotA基线同时保持了输出质量。', 'title_zh': 'AdaEAGLE：通过显式建模自适应草图结构优化投机解码'}
{'arxiv_id': 'arXiv:2412.18907', 'title': 'EC-Diffuser: Multi-Object Manipulation via Entity-Centric Behavior Generation', 'authors': 'Carl Qi, Dan Haramati, Tal Daniel, Aviv Tamar, Amy Zhang', 'link': 'https://arxiv.org/abs/2412.18907', 'abstract': "Object manipulation is a common component of everyday tasks, but learning to manipulate objects from high-dimensional observations presents significant challenges. These challenges are heightened in multi-object environments due to the combinatorial complexity of the state space as well as of the desired behaviors. While recent approaches have utilized large-scale offline data to train models from pixel observations, achieving performance gains through scaling, these methods struggle with compositional generalization in unseen object configurations with constrained network and dataset sizes. To address these issues, we propose a novel behavioral cloning (BC) approach that leverages object-centric representations and an entity-centric Transformer with diffusion-based optimization, enabling efficient learning from offline image data. Our method first decomposes observations into an object-centric representation, which is then processed by our entity-centric Transformer that computes attention at the object level, simultaneously predicting object dynamics and the agent's actions. Combined with the ability of diffusion models to capture multi-modal behavior distributions, this results in substantial performance improvements in multi-object tasks and, more importantly, enables compositional generalization. We present BC agents capable of zero-shot generalization to tasks with novel compositions of objects and goals, including larger numbers of objects than seen during training. We provide video rollouts on our webpage: this https URL.", 'abstract_zh': '物体操作是日常任务中的常见组成部分，但从高维度观测中学习操作物体面临着显著挑战。在多物体环境中，这些挑战更为突出，因为状态空间和目标行为之间的组合复杂度增加。尽管最近的方法利用大规模离线数据从像素观测中训练模型，并通过规模扩大实现性能提升，但这些方法在受限的网络和数据集规模下，在未见物体配置中实现组合式泛化方面仍然存在困难。为了解决这些问题，我们提出了一种新颖的行为克隆（Behavioral Cloning, BC）方法，该方法利用了以物体为中心的表示和实体为中心的Transformer，结合基于扩散的优化，从而能够有效从离线图像数据中进行学习。我们的方法首先将观测分解为以物体为中心的表示，然后通过我们的实体为中心的Transformer处理这些表示，在物体级别计算注意力的同时预测物体动力学和代理的行动。结合扩散模型能够捕捉多模态行为分布的能力，这在多物体任务中实现了显著的性能提升，并且更为重要的是，能够实现组合式泛化。我们展示了能够在新组成的物体和目标下实现零样本泛化的效果，包括在训练中未见过更多的物体数量。我们已经在网页上提供了视频滚动播放：this https URL。', 'title_zh': 'EC-Diffuser：基于实体中心的行为生成实现多对象操作'}
{'arxiv_id': 'arXiv:2412.18899', 'title': 'GAI: Generative Agents for Innovation', 'authors': 'Masahiro Sato', 'link': 'https://arxiv.org/abs/2412.18899', 'abstract': "This study examines whether collective reasoning among generative agents can facilitate novel and coherent thinking that leads to innovation. To achieve this, it proposes GAI, a new LLM-empowered framework designed for reflection and interaction among multiple generative agents to replicate the process of innovation. The core of the GAI framework lies in an architecture that dynamically processes the internal states of agents and a dialogue scheme specifically tailored to facilitate analogy-driven innovation. The framework's functionality is evaluated using Dyson's invention of the bladeless fan as a case study, assessing the extent to which the core ideas of the innovation can be replicated through a set of fictional technical documents. The experimental results demonstrate that models with internal states significantly outperformed those without, achieving higher average scores and lower variance. Notably, the model with five heterogeneous agents equipped with internal states successfully replicated the key ideas underlying the Dyson's invention. This indicates that the internal state enables agents to refine their ideas, resulting in the construction and sharing of more coherent and comprehensive concepts.", 'abstract_zh': '本研究探讨集体生成代理间的集体推理是否能促进新颖且连贯的思考，进而推动创新。为此，本文提出了GAI（Generative Agent Innovation）框架，这是一种以大型语言模型（LLM）为基础的新框架，旨在促进多个生成代理间的反思和交互，复制创新过程。GAI框架的核心在于一种动态处理代理内部状态的架构，以及一种专门为促进类比驱动的创新而精心设计的对话方案。框架的功能性通过采用戴森公司发明的无叶风扇作为案例研究进行评估，评估在一组虚构的技术文件中复制创新核心理念的程度。实验结果表明，具有内部状态的模型显著优于没有内部状态的模型，获得了更高的平均评分和更低的变异性。值得注意的是，配备有内部状态的五个异构代理成功复制了戴森发明的关键理念。这表明内部状态使代理能够细化和精炼其理念，从而在构建和分享更多连贯和全面的概念方面取得成效。', 'title_zh': 'GAI：生成式代理促进创新'}
{'arxiv_id': 'arXiv:2412.18890', 'title': 'CoEvo: Continual Evolution of Symbolic Solutions Using Large Language Models', 'authors': 'Ping Guo, Qingfu Zhang, Xi Lin', 'link': 'https://arxiv.org/abs/2412.18890', 'abstract': 'Large Language Models (LLMs) have emerged as transformative tools in artificial intelligence, capable of processing and understanding extensive human knowledge to enhance problem-solving across various domains. This paper explores the potential of LLMs to drive the discovery of symbolic solutions within scientific and engineering disciplines, where such solutions are crucial for advancing theoretical and practical applications. We propose a novel framework that utilizes LLMs in an evolutionary search methodology, augmented by a dynamic knowledge library that integrates and refines insights in an \\textit{open-ended manner}. This approach aims to tackle the dual challenges of efficiently navigating complex symbolic representation spaces and leveraging both existing and newly generated knowledge to foster open-ended innovation. By enabling LLMs to interact with and expand upon a knowledge library, we facilitate the continuous generation of novel solutions in diverse forms such as language, code, and mathematical expressions. Our experimental results demonstrate that this method not only enhances the efficiency of searching for symbolic solutions but also supports the ongoing discovery process, akin to human scientific endeavors. This study represents a first effort in conceptualizing the search for symbolic solutions as a lifelong, iterative process, marking a significant step towards harnessing AI in the perpetual pursuit of scientific and engineering breakthroughs. We have open-sourced our code and data, please visit \\url{this https URL} for more information.', 'abstract_zh': '大型语言模型（LLMs）已成为人工智能领域的变革性工具，能够处理和理解广泛的人类知识，从而在各个领域增强问题解决能力。本文探讨了LLMs在推动科学和工程学科中符号解决方案发现方面的潜在应用，这些解决方案对于推进理论和实践应用至关重要。我们提出了一种新颖的框架，该框架利用LLMs在进化搜索方法中的应用，并结合了一个动态知识库，以截然开放的方式集成和精炼见解。该方法旨在应对高效导航复杂的符号表示空间及利用现有和新生成的知识来促进开放创新的双重挑战。通过使LLMs与知识库发生交互，并扩展其中的知识，我们促进了多样化的新型解决方案——如语言、代码和数学表达式——的持续生成。实验结果表明，这种方法不仅提高了寻找符号解决方案的效率，还支持了持续的发现过程，类似于人类科学研究。这项研究代表了将符号解决方案的搜索概念化为终身迭代过程的一种初步尝试，标志着在利用AI追求科学和工程突破方面取得的重要一步。我们已开源了我们的代码和数据，请访问 \\url{this https URL} 获取更多信息。', 'title_zh': 'CoEvo：使用大型语言模型的符号解决方案持续进化'}
{'arxiv_id': 'arXiv:2412.18819', 'title': 'LLM-assisted vector similarity search', 'authors': 'Md Riyadh, Muqi Li, Felix Haryanto Lie, Jia Long Loh, Haotian Mi, Sayam Bohra', 'link': 'https://arxiv.org/abs/2412.18819', 'abstract': 'As data retrieval demands become increasingly complex, traditional search methods often fall short in addressing nuanced and conceptual queries. Vector similarity search has emerged as a promising technique for finding semantically similar information efficiently. However, its effectiveness diminishes when handling intricate queries with contextual nuances. This paper explores a hybrid approach combining vector similarity search with Large Language Models (LLMs) to enhance search accuracy and relevance. The proposed two-step solution first employs vector similarity search to shortlist potential matches, followed by an LLM for context-aware ranking of the results. Experiments on structured datasets demonstrate that while vector similarity search alone performs well for straightforward queries, the LLM-assisted approach excels in processing complex queries involving constraints, negations, or conceptual requirements. By leveraging the natural language understanding capabilities of LLMs, this method improves the accuracy of search results for complex tasks without sacrificing efficiency. We also discuss real-world applications and propose directions for future research to refine and scale this technique for diverse datasets and use cases.\nOriginal article: this https URL', 'abstract_zh': '随着数据检索需求变得越来越复杂，传统的搜索方法往往难以处理精练且概念上的查询。向量相似性搜索已经作为一种有希望的技术，能够高效地找到语义上相似的信息。然而，当处理包含上下文细微差别的复杂查询时，其有效性会下降。本文探讨了一种结合向量相似性搜索与大规模语言模型（LLMs）的混合方法，以提高搜索的准确性和相关性。提出的两步解决方案首先使用向量相似性搜索来筛选出潜在匹配项，然后使用LLM进行上下文感知的结果排名。实验表明，在结构化数据集上，仅依靠向量相似性搜索能够很好地处理简单的查询，而LLM辅助的方法在处理包含约束、否定或概念要求的复杂查询方面表现出色。通过利用LLMs的自然语言理解能力，这种方法能够提高复杂任务的搜索结果准确性，而不会牺牲效率。我们还讨论了该方法在实际应用中的应用，并提出了未来研究的方向，以进一步细化和扩展该技术以适用于不同的数据集和应用场景。\n原始文章：https://your-link-here', 'title_zh': 'LLM辅助向量相似性搜索'}
{'arxiv_id': 'arXiv:2412.18760', 'title': 'Data clustering: an essential technique in data science', 'authors': 'Wong Hauchi, Daniil Lisik, Tai Dinh', 'link': 'https://arxiv.org/abs/2412.18760', 'abstract': 'This paper provides a comprehensive exploration of data clustering, emphasizing its methodologies and applications across different fields. Traditional techniques, including partitional and hierarchical clustering, are discussed alongside other approaches such as data stream, subspace and network clustering, highlighting their role in addressing complex, high-dimensional datasets. The paper also reviews the foundational principles of clustering, introduces common tools and methods, and examines its diverse applications in data science. Finally, the discussion concludes with insights into future directions, underscoring the centrality of clustering in driving innovation and enabling data-driven decision making.', 'abstract_zh': '本文对数据聚类进行全面探索，强调其方法论及其在不同领域的应用。文中讨论了传统的聚类技术，包括分割聚类和层次聚类，并介绍了数据流聚类、子空间聚类和网络聚类等其他方法，突出了它们在处理复杂高维数据集方面的作用。本文还回顾了聚类的基本原则，介绍了常用工具和方法，并探讨了其在数据科学中的多样应用。最后，文章总结了未来的发展方向，强调了聚类在推动创新和实现数据驱动决策中的核心地位。', 'title_zh': '数据聚类：数据科学中的基本技术'}
{'arxiv_id': 'arXiv:2412.18715', 'title': 'Optimization and Scalability of Collaborative Filtering Algorithms in Large Language Models', 'authors': 'Haowei Yang, Longfei Yun, Jinghan Cao, Qingyi Lu, Yuming Tu', 'link': 'https://arxiv.org/abs/2412.18715', 'abstract': 'With the rapid development of large language models (LLMs) and the growing demand for personalized content, recommendation systems have become critical in enhancing user experience and driving engagement. Collaborative filtering algorithms, being core to many recommendation systems, have garnered significant attention for their efficiency and interpretability. However, traditional collaborative filtering approaches face numerous challenges when integrated into large-scale LLM-based systems, including high computational costs, severe data sparsity, cold start problems, and lack of scalability. This paper investigates the optimization and scalability of collaborative filtering algorithms in large language models, addressing these limitations through advanced optimization strategies. Firstly, we analyze the fundamental principles of collaborative filtering algorithms and their limitations when applied in LLM-based contexts. Next, several optimization techniques such as matrix factorization, approximate nearest neighbor search, and parallel computing are proposed to enhance computational efficiency and model accuracy. Additionally, strategies such as distributed architecture and model compression are explored to facilitate dynamic updates and scalability in data-intensive environments.', 'abstract_zh': '随着大规模语言模型（LLMs）的迅速发展和个性化内容需求的增长，推荐系统已成为提升用户体验和增加用户参与度的关键。作为众多推荐系统的核心，协同过滤算法因其高效性和可解释性而备受关注。然而，传统协同过滤方法在集成到大规模LLM系统时面临诸多挑战，包括高昂的计算成本、严重的数据稀疏性、冷启动问题以及缺乏可扩展性。本文旨在探讨协同过滤算法在大规模语言模型中的优化与扩展问题，并通过先进的优化策略应对这些挑战。首先，我们分析了协同过滤算法的基本原理及其在基于LLM的环境下的局限性。然后，提出了一些优化技术，如矩阵分解、近似最近邻搜索和并行计算，以提高计算效率和模型准确性。此外，还研究了分布式架构和模型压缩策略，以促进在数据密集环境中动态更新和可扩展性。', 'title_zh': '大型语言模型中协作过滤算法的优化与扩展性研究'}
{'arxiv_id': 'arXiv:2412.18713', 'title': 'Enhanced Recommendation Combining Collaborative Filtering and Large Language Models', 'authors': 'Xueting Lin, Zhan Cheng, Longfei Yun, Qingyi Lu, Yuanshuai Luo', 'link': 'https://arxiv.org/abs/2412.18713', 'abstract': "With the advent of the information explosion era, the importance of recommendation systems in various applications is increasingly significant. Traditional collaborative filtering algorithms are widely used due to their effectiveness in capturing user behavior patterns, but they encounter limitations when dealing with cold start problems and data sparsity. Large Language Models (LLMs), with their strong natural language understanding and generation capabilities, provide a new breakthrough for recommendation systems. This study proposes an enhanced recommendation method that combines collaborative filtering and LLMs, aiming to leverage collaborative filtering's advantage in modeling user preferences while enhancing the understanding of textual information about users and items through LLMs to improve recommendation accuracy and diversity. This paper first introduces the fundamental theories of collaborative filtering and LLMs, then designs a recommendation system architecture that integrates both, and validates the system's effectiveness through experiments. The results show that the hybrid model based on collaborative filtering and LLMs significantly improves precision, recall, and user satisfaction, demonstrating its potential in complex recommendation scenarios.", 'abstract_zh': '随着信息爆炸时代的到来，推荐系统在各种应用中的重要性越来越显著。传统的协同过滤算法因其能够有效捕捉用户行为模式而得到广泛应用，但在处理冷启动问题和数据稀疏性时遇到了限制。大型语言模型（LLMs）凭借其强大的自然语言理解和生成能力，为推荐系统提供了新的突破。本研究提出了一种结合协同过滤和LLMs的增强推荐方法，旨在利用协同过滤模型在用户偏好建模方面的优势，通过LLMs增强对用户和项目文本信息的理解，从而提高推荐准确性和多样性。本文首先介绍了协同过滤和LLMs的基本理论，然后设计了一个结合两者功能的推荐系统架构，并通过实验验证了该系统的有效性。结果表明，基于协同过滤和LLMs的混合模型在精确度、召回率和用户满意度方面显著提高，显示出其在复杂推荐场景中的潜力。', 'title_zh': '结合协同过滤和大规模语言模型的增强推荐方法'}
{'arxiv_id': 'arXiv:2412.18708', 'title': "CAG: Chunked Augmented Generation for Google Chrome's Built-in Gemini Nano", 'authors': 'Vivek Vellaiyappan Surulimuthu, Aditya Karnam Gururaj Rao', 'link': 'https://arxiv.org/abs/2412.18708', 'abstract': "We present Chunked Augmented Generation (CAG), an architecture specifically designed to overcome the context window limitations of Google Chrome's built-in Gemini Nano model. While Chrome's integration of Gemini Nano represents a significant advancement in bringing AI capabilities directly to the browser, its restricted context window poses challenges for processing large inputs. CAG addresses this limitation through intelligent input chunking and processing strategies, enabling efficient handling of extensive content while maintaining the model's performance within browser constraints. Our implementation demonstrates particular efficacy in processing large documents and datasets directly within Chrome, making sophisticated AI capabilities accessible through the browser without external API dependencies. Get started now at this https URL.", 'abstract_zh': '我们提出了Chunked Augmented Generation（CAG），这是一种专门设计用来克服Google Chrome内置Gemini Nano模型"context window"限制的架构。虽然Chrome集成Gemini Nano标志着将AI能力直接带入浏览器的一大进步，但其受限的"context window"却对处理大量输入内容构成了挑战。CAG 通过智能的输入分块和处理策略来解决这一限制，从而在浏览器内部高效处理大量内容的同时保持模型性能。我们的实现特别适用于在Chrome中直接处理大型文档和数据集，使得复杂的AI能力能够通过浏览器访问，而不需要额外的API依赖。立即开始，请访问：[这个链接]。\n\n注：[这个链接] 请根据实际情况填写实际的链接。', 'title_zh': 'CAG：分块增强生成技术在 Google Chrome 内置 Gemini Nano 中的应用'}
{'arxiv_id': 'arXiv:2412.18697', 'title': 'Agents on the Bench: Large Language Model Based Multi Agent Framework for Trustworthy Digital Justice', 'authors': 'Cong Jiang, Xiaolei Yang', 'link': 'https://arxiv.org/abs/2412.18697', 'abstract': 'The justice system has increasingly employed AI techniques to enhance efficiency, yet limitations remain in improving the quality of decision-making, particularly regarding transparency and explainability needed to uphold public trust in legal AI. To address these challenges, we propose a large language model based multi-agent framework named AgentsBench, which aims to simultaneously improve both efficiency and quality in judicial decision-making. Our approach leverages multiple LLM-driven agents that simulate the collaborative deliberation and decision making process of a judicial bench. We conducted experiments on legal judgment prediction task, and the results show that our framework outperforms existing LLM based methods in terms of performance and decision quality. By incorporating these elements, our framework reflects real-world judicial processes more closely, enhancing accuracy, fairness, and society consideration. AgentsBench provides a more nuanced and realistic methods of trustworthy AI decision-making, with strong potential for application across various case types and legal scenarios.', 'abstract_zh': '司法系统正越来越多地采用人工智能技术以提高效率，然而在提高决策质量方面仍存在局限，尤其是在透明性和可解释性方面，这是维护公众对法律人工智能的信任所需的重要方面。为应对这些挑战，我们提出了一种基于大型语言模型的多代理框架，名为AgentsBench，旨在同时提高司法决策的效率和质量。我们的方法利用多个由大型语言模型驱动的代理，模拟司法庭的协作讨论和决策过程。我们进行了法律判决预测任务的实验，结果表明，与现有的基于大型语言模型的方法相比，我们的框架在性能和决策质量上表现更优。通过这些元素，我们的框架更接近于真实的司法流程，提高了准确性、公平性和社会考量。AgentsBench 提供了一种更为细致和现实的可信赖人工智能决策方法，适用于各种案件类型和法律情境，具有较大的应用潜力。', 'title_zh': '《审判席上的代理人：基于大型语言模型的多代理系统框架，以实现可信赖的数字正义》\n\n此标题翻译遵循了学术规范，保持了原文的核心意思，并用中文学术界常用的表达方式进行了适当调整。'}
{'arxiv_id': 'arXiv:2412.18673', 'title': 'Map2Text: New Content Generation from Low-Dimensional Visualizations', 'authors': 'Xingjian Zhang, Ziyang Xiong, Shixuan Liu, Yutong Xie, Tolga Ergen, Dongsub Shim, Hua Xu, Honglak Lee, Qiaozhu Me', 'link': 'https://arxiv.org/abs/2412.18673', 'abstract': 'Low-dimensional visualizations, or "projection maps" of datasets, are widely used across scientific research and creative industries as effective tools for interpreting large-scale and complex information. These visualizations not only support understanding existing knowledge spaces but are often used implicitly to guide exploration into unknown areas. While powerful methods like TSNE or UMAP can create such visual maps, there is currently no systematic way to leverage them for generating new content. To bridge this gap, we introduce Map2Text, a novel task that translates spatial coordinates within low-dimensional visualizations into new, coherent, and accurately aligned textual content. This allows users to explore and navigate undiscovered information embedded in these spatial layouts interactively and intuitively. To evaluate the performance of Map2Text methods, we propose Atometric, an evaluation metric that provides a granular assessment of logical coherence and alignment of the atomic statements in the generated texts. Experiments conducted across various datasets demonstrate the versatility of Map2Text in generating scientific research hypotheses, crafting synthetic personas, and devising strategies for testing large language models. Our findings highlight the potential of Map2Text to unlock new pathways for interacting with and navigating large-scale textual datasets, offering a novel framework for spatially guided content generation and discovery.', 'abstract_zh': '低维度可视化，或“投影图”，在科学研究和创意产业中被广泛用作解释大规模和复杂信息的有效工具。这些可视化不仅有助于理解现有知识空间，还常用于隐式地引导对未知领域的探索。虽然诸如t-SNE或UMAP等强大方法可以创建此类可视化图，但目前尚无有效的方法利用它们来生成新的内容。为解决这一问题，我们引入了一种名为Map2Text的新任务，该任务将低维度可视化中的空间坐标转化为新的、连贯且准确对齐的文本内容。这使得用户可以以交互和直观的方式探索和导航嵌入在这些空间布局中的未发现信息。为了评估Map2Text方法的效果，我们提出了Atometric，一种评估生成文本中的原子陈述的逻辑连贯性和对齐性的细粒度指标。实验表明，Map2Text在生成科学假说、设计合成人物和为大规模语言模型制定测试策略方面具有广泛的适用性。我们的研究结果强调了Map2Text在与大规模文本数据集互动和导航方面的新路径潜力，并为基于空间指导的内容生成和发现提供了一个新的框架。', 'title_zh': 'Map2Text：从低维可视化中生成新内容'}
{'arxiv_id': 'arXiv:2412.18670', 'title': 'Interplay of ISMS and AIMS in context of the EU AI Act', 'authors': 'Jordan Pötsch', 'link': 'https://arxiv.org/abs/2412.18670', 'abstract': "The EU AI Act (AIA) mandates the implementation of a risk management system (RMS) and a quality management system (QMS) for high-risk AI systems. The ISO/IEC 42001 standard provides a foundation for fulfilling these requirements but does not cover all EU-specific regulatory stipulations. To enhance the implementation of the AIA in Germany, the Federal Office for Information Security (BSI) could introduce the national standard BSI 200-5, which specifies AIA requirements and integrates existing ISMS standards, such as ISO/IEC 27001. This paper examines the interfaces between an information security management system (ISMS) and an AI management system (AIMS), demonstrating that incorporating existing ISMS controls with specific AI extensions presents an effective strategy for complying with Article 15 of the AIA. Four new AI modules are introduced, proposed for inclusion in the BSI IT Grundschutz framework to comprehensively ensure the security of AI systems. Additionally, an approach for adapting BSI's qualification and certification systems is outlined to ensure that expertise in secure AI handling is continuously developed. Finally, the paper discusses how the BSI could bridge international standards and the specific requirements of the AIA through the nationalization of ISO/IEC 42001, creating synergies and bolstering the competitiveness of the German AI landscape.", 'abstract_zh': '《欧盟人工智能法案》（AIA）要求高风险人工智能系统实施风险管理系统（RMS）和质量管理体系（QMS）。ISO/IEC 42001标准为满足这些要求提供了基础，但并未涵盖所有欧盟特定的监管规定。为增强德国《欧盟人工智能法案》的实施，联邦信息安全办公室（BSI）可以引入其国家标准BSI 200-5，该标准具体规定了AIA的要求，并整合了现有的信息安全管理体系（ISMS）标准，如ISO/IEC 27001。本文探讨了信息系统管理体系（ISMS）与人工智能管理体系（AIMS）之间的接口，证明了将现有的ISMS控制措施与特定的人工智能扩展相结合是一种有效策略，以符合AIA第15条的要求。提出了四个新的AI模块，并建议将这些模块纳入BSI IT 根据保护框架，以全面确保人工智能系统的安全性。此外，本文概述了如何通过《欧盟人工智能法案》的具体要求适应BSI的资质和认证体系，以确保持续发展处理安全人工智能的专业知识。最后，本文讨论了BSI如何通过将ISO/IEC 42001国标化来弥合国际标准和《欧盟人工智能法案》具体要求之间的鸿沟，从而创造协同效应并增强德国人工智能生态系统的竞争力。', 'title_zh': '欧盟人工智能法案背景下ISMS和AIMS的相互作用研究'}
{'arxiv_id': 'arXiv:2412.18669', 'title': 'Advancing Explainability in Neural Machine Translation: Analytical Metrics for Attention and Alignment Consistency', 'authors': 'Anurag Mishra', 'link': 'https://arxiv.org/abs/2412.18669', 'abstract': 'Neural Machine Translation (NMT) models have shown remarkable performance but remain largely opaque in their decision making processes. The interpretability of these models, especially their internal attention mechanisms, is critical for building trust and verifying that these systems behave as intended. In this work, we introduce a systematic framework to quantitatively evaluate the explainability of an NMT model attention patterns by comparing them against statistical alignments and correlating them with standard machine translation quality metrics. We present a set of metrics attention entropy and alignment agreement and validate them on an English-German test subset from WMT14 using a pre trained mT5 model. Our results indicate that sharper attention distributions correlate with improved interpretability but do not always guarantee better translation quality. These findings advance our understanding of NMT explainability and guide future efforts toward building more transparent and reliable machine translation systems.', 'abstract_zh': '神经机器翻译（NMT）模型在性能上表现出色，但在决策过程中依然非常不透明。这些模型的可解释性，尤其是内部注意力机制的可解释性，对于建立信任并验证这些系统的行为是否符合预期至关重要。在本工作中，我们引入了一种系统性的框架，通过将NMT模型的注意力模式与统计对齐进行比较，并与标准的机器翻译质量指标进行关联，来定量评估NMT模型注意力模式的可解释性。我们提出了一组度量标准（注意力熵和对齐一致性），并在WMT14的英语-德语测试子集上使用预训练的mT5模型进行验证。我们的结果显示，更尖锐的注意力分布与更好的可解释性相关，但并不总是保证更好的翻译质量。这些发现深化了我们对NMT可解释性的理解，并指导未来努力朝着构建更透明和可靠机器翻译系统的方向进行。', 'title_zh': '神经机器翻译中解释性的进展：注意力和对齐一致性分析性度量'}
{'arxiv_id': 'arXiv:2412.18647', 'title': 'Nationality, Race, and Ethnicity Biases in and Consequences of Detecting AI-Generated Self-Presentations', 'authors': 'Haoran Chu, Linjuan Rita Men, Sixiao Liu, Shupei Yuan, Yuan Sun', 'link': 'https://arxiv.org/abs/2412.18647', 'abstract': "This study builds on person perception and human AI interaction (HAII) theories to investigate how content and source cues, specifically race, ethnicity, and nationality, affect judgments of AI-generated content in a high-stakes self-presentation context: college applications. Results of a pre-registered experiment with a nationally representative U.S. sample (N = 644) show that content heuristics, such as linguistic style, played a dominant role in AI detection. Source heuristics, such as nationality, also emerged as a significant factor, with international students more likely to be perceived as using AI, especially when their statements included AI-sounding features. Interestingly, Asian and Hispanic applicants were more likely to be judged as AI users when labeled as domestic students, suggesting interactions between racial stereotypes and AI detection. AI attribution led to lower perceptions of personal statement quality and authenticity, as well as negative evaluations of the applicant's competence, sociability, morality, and future success.", 'abstract_zh': '本研究结合了个人印象和社会智能互动（Human AI Interaction, HAII）理论，探讨了内容线索和来源线索（特别是种族、族裔和国籍）如何影响高风险自我呈现情境下（如大学申请）对生成式人工智能内容的判断。一项预先注册的实验结果表明，内容启发规则，如语言风格，在人工智能内容检测中起主导作用。来源启发规则，如国籍，也显示出显著影响，国际学生在声明包含听起来像是人工智能生成的特征时更容易被误认为是使用人工智能生成的内容。有趣的是，当被标记为国内学生时，亚裔和西班牙裔申请者更有可能被认为是人工智能用户，这反映了种族刻板印象与人工智能检测之间的交互作用。归因于人工智能的内容评价降低了个人陈述的质量和真实性感知，并对申请者的专业能力、社交能力、道德和社会未来成功做出了负面评价。', 'title_zh': '国籍、种族和 Ethnicity 偏见在检测AI生成的自我展示中的影响及其后果'}
{'arxiv_id': 'arXiv:2412.19754', 'title': 'Complement or substitute? How AI increases the demand for human skills', 'authors': 'Elina Mäkelä, Fabian Stephany', 'link': 'https://arxiv.org/abs/2412.19754', 'abstract': "The question of whether AI substitutes or complements human work is central to debates on the future of work. This paper examines the impact of AI on skill demand and compensation in the U.S. economy, analysing 12 million online job vacancies from 2018 to 2023. It investigates internal effects (within-job substitution and complementation) and external effects (across occupations, industries, and regions). Our findings reveal a significant increase in demand for AI-complementary skills, such as digital literacy, teamwork, and resilience, alongside rising wage premiums for these skills in AI roles like Data Scientist. Conversely, substitute skills, including customer service and text review, have declined in both demand and value within AI-related positions. Examining external effects, we find a notable rise in demand for complementary skills in non-AI roles linked to the growth of AI-related jobs in specific industries or regions. At the same time, there is a moderate decline in non-AI roles requiring substitute skills. Overall, AI's complementary effect is up to 50% larger than its substitution effect, resulting in net positive demand for skills. These results, replicated for the UK and Australia, highlight AI's transformative impact on workforce skill requirements. They suggest reskilling efforts should prioritise not only technical AI skills but also complementary skills like ethics and digital literacy.", 'abstract_zh': '关于人工智能是替代还是补充人类工作这一问题，是未来工作讨论中的核心议题。本文分析了2018年至2023年间美国经济中的1200万个在线职位空缺，探讨了人工智能对技能需求和薪酬的影响。研究包括内部效应（岗位内替代与补充）和外部效应（跨职业、行业和区域）。研究表明，在人工智能角色如数据科学家等岗位中，互补技能（如数字素养、团队协作和韧性）的需求显著增加，这些技能的薪酬溢价也在上升。相反，替代技能（如客户服务和文本审查）的需求和价值在与人工智能相关的职位中均有所下降。在外部分析中，我们发现与特定行业或地区中增长的人工智能相关岗位相关的非人工智能岗位对互补技能的需求有所增加，而需要替代技能的非人工智能岗位则出现中度下降。总体而言，人工智能的互补效应比替代效应高出50%，导致对技能的需求总体呈正增长态势。这些结果在英国和澳大利亚得到重复验证，突显了人工智能对劳动力技能要求的转型影响。这表明重新培训努力不仅应侧重于技术性人工智能技能，还应重视伦理和数字素养等互补技能。', 'title_zh': '补充还是替代？AI如何增加对人类技能的需求'}
{'arxiv_id': 'arXiv:2412.19750', 'title': 'IMAGINE: An 8-to-1b 22nm FD-SOI Compute-In-Memory CNN Accelerator With an End-to-End Analog Charge-Based 0.15-8POPS/W Macro Featuring Distribution-Aware Data Reshaping', 'authors': 'Adrian Kneip, Martin Lefebvre, Pol Maistriaux, David Bol', 'link': 'https://arxiv.org/abs/2412.19750', 'abstract': 'Charge-domain compute-in-memory (CIM) SRAMs have recently become an enticing compromise between computing efficiency and accuracy to process sub-8b convolutional neural networks (CNNs) at the edge. Yet, they commonly make use of a fixed dot-product (DP) voltage swing, which leads to a loss in effective ADC bits due to data-dependent clipping or truncation effects that waste precious conversion energy and computing accuracy. To overcome this, we present IMAGINE, a workload-adaptive 1-to-8b CIM-CNN accelerator in 22nm FD-SOI. It introduces a 1152x256 end-to-end charge-based macro with a multi-bit DP based on an input-serial, weight-parallel accumulation that avoids power-hungry DACs. An adaptive swing is achieved by combining a channel-wise DP array split with a linear in-ADC implementation of analog batch-normalization (ABN), obtaining a distribution-aware data reshaping. Critical design constraints are relaxed by including the post-silicon equivalent noise within a CIM-aware CNN training framework. Measurement results showcase an 8b system-level energy efficiency of 40TOPS/W at 0.3/0.6V, with competitive accuracies on MNIST and CIFAR-10. Moreover, the peak energy and area efficiencies of the 187kB/mm2 macro respectively reach up to 0.15-8POPS/W and 2.6-154TOPS/mm2, scaling with the 8-to-1b computing precision. These results exceed previous charge-based designs by 3-to-5x while being the first work to provide linear in-memory rescaling.', 'abstract_zh': '计算域计算即存忆（CIM）SRAMs 近年来成为一种在边缘处理低于8位卷积神经网络（CNNs）时兼具效率和精度的有吸引力折衷方案。然而，它们通常使用固定的点积（DP）电压摆幅，这导致因数据依赖的剪裁或截尾效应而导致有效ADC位数的损失，浪费了宝贵的转换能量和计算精度。为了克服这一问题，我们提出了一种适用于22nm FD-SOI的工作负载自适应1到8位CIM-CNN加速器IMAGINE。该加速器引入了一个端到端基于电荷的1152x256宏，采用基于输入串行、权重并行累加的多比特点积，避免了耗电的DACs。通过结合按通道分割的点积数组与ADC内的线性模拟批量归一化（ABN）实现，实现了分发感知的数据重塑。通过在CIM感知的CNN训练框架中包含后硅等效噪声，松懈了关键设计约束。测量结果显示，该系统在0.3/0.6V下的每瓦算力为40TOPS/W，针对MNIST和CIFAR-10具有竞争力的精度。此外，该宏的峰值能量和面积效率分别达到0.15-8POPS/W和2.6-154TOPS/mm²，随着8到1位的计算精度而扩展。这些结果比之前基于电荷的设计高出3到5倍，并且是首款提供内存内线性重塑的工作。', 'title_zh': 'IMAGINE：一种基于8位到1位、22nm FD-SOI工艺的计算存储一体CNN加速器，具备端到端模拟电荷基0.15-8POPS/W宏，采用分布意识数据重塑技术'}
{'arxiv_id': 'arXiv:2412.19747', 'title': 'Enhancing Adversarial Robustness of Deep Neural Networks Through Supervised Contrastive Learning', 'authors': 'Longwei Wang, Navid Nayyem, Abdullah Rakin', 'link': 'https://arxiv.org/abs/2412.19747', 'abstract': 'Adversarial attacks exploit the vulnerabilities of convolutional neural networks by introducing imperceptible perturbations that lead to misclassifications, exposing weaknesses in feature representations and decision boundaries. This paper presents a novel framework combining supervised contrastive learning and margin-based contrastive loss to enhance adversarial robustness. Supervised contrastive learning improves the structure of the feature space by clustering embeddings of samples within the same class and separating those from different classes. Margin-based contrastive loss, inspired by support vector machines, enforces explicit constraints to create robust decision boundaries with well-defined margins. Experiments on the CIFAR-100 dataset with a ResNet-18 backbone demonstrate robustness performance improvements in adversarial accuracy under Fast Gradient Sign Method attacks.', 'abstract_zh': 'adversarial攻击通过引入不可感知的 perturbations 来利用卷积神经网络的漏洞，导致分类错误，揭示了特征表示和决策边界的弱点。本文提出了一种结合监督对比学习和 margin 基准对比损失的新框架，以增强对抗鲁棒性。监督对比学习通过在同一类中聚类样本嵌入以及将不同类的嵌入分开来改进特征空间的结构。受支持向量机的启发，margin 基准对比损失施加显式的约束，以创建具有明确 margin 的稳健决策边界。实验使用 ResNet-18 作为骨干网络，在 CIFAR-100 数据集上表明，在使用快速梯度符号法攻击下的对抗准确率有所提高，从而证明了该方法的有效性。\n\n注：这里对原文进行了细致的翻译，某些术语如“margin 基准对比损失”等使用了较为准确且符合中文学术规范的译法。在实际学术文献中，对比损失的具体表述可能会根据研究的具体情况有所不同，但上述翻译已尽量贴近原文含义。', 'title_zh': '通过监督对比学习增强深度神经网络的对抗鲁棒性'}
{'arxiv_id': 'arXiv:2412.19737', 'title': 'Adaptive Context-Aware Multi-Path Transmission Control for VR/AR Content: A Deep Reinforcement Learning Approach', 'authors': 'Shakil Ahmed, Saifur Rahman Sabuj, Ashfaq Khokhar', 'link': 'https://arxiv.org/abs/2412.19737', 'abstract': 'This paper introduces the Adaptive Context-Aware Multi-Path Transmission Control Protocol (ACMPTCP), an efficient approach designed to optimize the performance of Multi-Path Transmission Control Protocol (MPTCP) for data-intensive applications such as augmented and virtual reality (AR/VR) streaming. ACMPTCP addresses the limitations of conventional MPTCP by leveraging deep reinforcement learning (DRL) for agile end-to-end path management and optimal bandwidth allocation, facilitating path realignment across diverse network environments.', 'abstract_zh': '本文介绍了自适应上下文感知多路径传输控制协议（ACMPTCP），这是一种为了优化多路径传输控制协议（MPTCP）在增强现实（AR）和虚拟现实（VR）流媒体等数据密集型应用中的性能而设计的高效方法。ACMPTCP 通过利用深度强化学习（DRL）进行灵活的端到端路径管理和最优带宽分配，从而在多种网络环境中实现路径重新调整。', 'title_zh': '基于深度强化学习的自适应上下文感知多路径传输控制技术：面向VR/AR内容'}
{'arxiv_id': 'arXiv:2412.19688', 'title': 'A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation', 'authors': 'Jana Zakall, Birgit Pohn, Antonia Graf, Daniel Kovatchki, Arezoo Borji, Ragib Shahriar Islam, Hossam Haick, Heinz Strohmer, Sepideh Hatamikia', 'link': 'https://arxiv.org/abs/2412.19688', 'abstract': 'Artificial intelligence (AI) has emerged as a powerful tool to enhance decision-making and optimize treatment protocols in in vitro fertilization (IVF). In particular, AI shows significant promise in supporting decision-making during the ovarian stimulation phase of the IVF process. This review evaluates studies focused on the applications of AI combined with medical imaging in ovarian stimulation, examining methodologies, outcomes, and current limitations. Our analysis of 13 studies on this topic reveals that, reveal that while AI algorithms demonstrated notable potential in predicting optimal hormonal dosages, trigger timing, and oocyte retrieval outcomes, the medical imaging data utilized predominantly came from two-dimensional (2D) ultrasound which mainly involved basic quantifications, such as follicle size and number, with limited use of direct feature extraction or advanced image analysis techniques. This points to an underexplored opportunity where advanced image analysis approaches, such as deep learning, and more diverse imaging modalities, like three-dimensional (3D) ultrasound, could unlock deeper insights. Additionally, the lack of explainable AI (XAI) in most studies raises concerns about the transparency and traceability of AI-driven decisions - key factors for clinical adoption and trust. Furthermore, many studies relied on single-center designs and small datasets, which limit the generalizability of their findings. This review highlights the need for integrating advanced imaging analysis techniques with explainable AI methodologies, as well as the importance of leveraging multicenter collaborations and larger datasets. Addressing these gaps has the potential to enhance ovarian stimulation management, paving the way for efficient, personalized, and data-driven treatment pathways that improve IVF outcomes.', 'abstract_zh': '人工智能（AI）已成为增强体外受精（IVF）过程中决策能力和优化治疗方案的强大工具，特别是在支持IVF过程中的卵巢刺激阶段决策方面表现出巨大潜力。本文综合评估了AI与医学影像结合在卵巢刺激中的应用研究，探讨了方法学、结果及其当前的局限性。通过对13篇相关研究的分析，我们发现尽管AI算法在预测最佳激素剂量、促排卵时间及卵母细胞回收结果方面展现出了显著潜力，所使用的医学影像数据主要来自于二维（2D）超声，这些数据主要用于基础量化，如卵泡大小和数量，较少运用直接特征提取或高级图像分析技术。这表明，在高级图像分析方法（如深度学习）和更广泛成像模态（如三维（3D）超声）方面仍存在未充分探索的机会，这些技术可以帮助获得更深入的见解。此外，大多数研究缺乏可解释人工智能（XAI），这引发人们对基于AI的决策透明度和追溯性的担忧——这是临床应用和信任的关键因素。此外，许多研究依赖单一中心设计和小型数据集，限制了其研究结果的普遍适用性。本文强调了整合先进成像分析技术和可解释AI方法的重要性，以及利用多中心合作和更大数据集的重要性。解决这些差距有可能改善卵巢刺激管理，为高效、个性化和数据驱动的治疗路径开辟道路，从而提高IVF疗效。', 'title_zh': '人工智能与医学影像在辅助生殖技术中卵泡刺激integration的研究进展'}
{'arxiv_id': 'arXiv:2412.19685', 'title': 'A Large-scale Interpretable Multi-modality Benchmark for Facial Image Forgery Localization', 'authors': 'Jingchun Lian, Lingyu Liu, Yaxiong Wang, Yujiao Wu, Li Zhu, Zhedong Zheng', 'link': 'https://arxiv.org/abs/2412.19685', 'abstract': "Image forgery localization, which centers on identifying tampered pixels within an image, has seen significant advancements. Traditional approaches often model this challenge as a variant of image segmentation, treating the binary segmentation of forged areas as the end product. We argue that the basic binary forgery mask is inadequate for explaining model predictions. It doesn't clarify why the model pinpoints certain areas and treats all forged pixels the same, making it hard to spot the most fake-looking parts. In this study, we mitigate the aforementioned limitations by generating salient region-focused interpretation for the forgery images. To support this, we craft a Multi-Modal Tramper Tracing (MMTT) dataset, comprising facial images manipulated using deepfake techniques and paired with manual, interpretable textual annotations. To harvest high-quality annotation, annotators are instructed to meticulously observe the manipulated images and articulate the typical characteristics of the forgery regions. Subsequently, we collect a dataset of 128,303 image-text pairs. Leveraging the MMTT dataset, we develop ForgeryTalker, an architecture designed for concurrent forgery localization and interpretation. ForgeryTalker first trains a forgery prompter network to identify the pivotal clues within the explanatory text. Subsequently, the region prompter is incorporated into multimodal large language model for finetuning to achieve the dual goals of localization and interpretation. Extensive experiments conducted on the MMTT dataset verify the superior performance of our proposed model. The dataset, code as well as pretrained checkpoints will be made publicly available to facilitate further research and ensure the reproducibility of our results.", 'abstract_zh': '图像篡改定位是集中于识别图像中篡改像素的技术，近年来取得了显著的进步。传统的做法通常将这一挑战建模为图像分割的变体，将伪造区域的二值分割视为最终产品。然而，我们认为基本的二值篡改掩码无法解释模型的预测结果。它未能明确说明模型为何识别某些区域，且将所有篡改的像素同等对待，使得难以识别最显眼的伪造部分。在本研究中，我们通过为篡改图像生成突出区域的解释来缓解上述限制。为此，我们构建了一个多模态篡改追踪（MMTT）数据集，包括使用深度伪造技术篡改的面部图像，并配有可解释的手动注释文本。为了获得高质量的注释，我们指导标注员仔细观察篡改图像，并描述伪造区域的典型特征。随后，我们收集了一个包含128,303个图像-文本对的数据集。借助MMTT数据集，我们开发了ForgeryTalker架构，该架构旨在同时实现篡改定位和解释。首先，ForgeryTalker训练一个篡改提示网络以识别说明性文本中的关键线索。然后，该区域提示器被整合到多模态大型语言模型中以进行微调，从而实现定位和解释的双重目标。我们在MMTT数据集上的大量实验验证了我们的模型具有优越的性能。此外，我们将数据集、代码以及预训练模型提供给公众，以促进进一步的研究并确保研究结果的可重复性。', 'title_zh': '大规模可解释多模态基准数据集用于面部图像伪造定位'}
{'arxiv_id': 'arXiv:2412.19663', 'title': 'CAD-GPT: Synthesising CAD Construction Sequence with Spatial Reasoning-Enhanced Multimodal LLMs', 'authors': 'Siyu Wang, Cailian Chen, Xinyi Le, Qimin Xu, Lei Xu, Yanzhou Zhang, Jie Yang', 'link': 'https://arxiv.org/abs/2412.19663', 'abstract': 'Computer-aided design (CAD) significantly enhances the efficiency, accuracy, and innovation of design processes by enabling precise 2D and 3D modeling, extensive analysis, and optimization. Existing methods for creating CAD models rely on latent vectors or point clouds, which are difficult to obtain and costly to store. Recent advances in Multimodal Large Language Models (MLLMs) have inspired researchers to use natural language instructions and images for CAD model construction. However, these models still struggle with inferring accurate 3D spatial location and orientation, leading to inaccuracies in determining the spatial 3D starting points and extrusion directions for constructing geometries. This work introduces CAD-GPT, a CAD synthesis method with spatial reasoning-enhanced MLLM that takes either a single image or a textual description as input. To achieve precise spatial inference, our approach introduces a 3D Modeling Spatial Mechanism. This method maps 3D spatial positions and 3D sketch plane rotation angles into a 1D linguistic feature space using a specialized spatial unfolding mechanism, while discretizing 2D sketch coordinates into an appropriate planar space to enable precise determination of spatial starting position, sketch orientation, and 2D sketch coordinate translations. Extensive experiments demonstrate that CAD-GPT consistently outperforms existing state-of-the-art methods in CAD model synthesis, both quantitatively and qualitatively.', 'abstract_zh': '计算机辅助设计（CAD）显著提升了设计过程的效率、准确性和创新性，通过实现精确的二维和三维建模、广泛分析和优化。现有的CAD模型创建方法依赖于潜在向量或点云，这些方法的获取过程复杂且储存成本高昂。最近，多模态大型语言模型（MLLMs）的进步激发了研究人员使用自然语言指令和图像进行CAD模型构建。然而，这些模型仍然难以准确推断三维空间位置和方向，导致在构建几何图形时难以精确确定三维空间的起始点和拉伸方向。本项研究引入了CAD-GPT，这是一种具有增强空间推理的MLLM的CAD合成方法，可以接受单张图像或文本描述作为输入。为了实现精确的空间推断，我们的方法引入了三维建模空间机制。该方法利用专门的空间展开机制将三维空间位置和三维素描面旋转角度映射到一维语言特征空间，同时将二维素描坐标离散化到合适的平面空间，以实现对空间起始位置、素描方向和二维素描坐标转换的精确确定。大量实验结果显示，CAD-GPT在CAD模型合成方面的性能在定性和定量上都显著优于现有最先进的方法。', 'title_zh': 'CAD-GPT：增强空间推理的多模态LLM生成建筑施工序列'}
{'arxiv_id': 'arXiv:2412.19646', 'title': 'Chimera: A Block-Based Neural Architecture Search Framework for Event-Based Object Detection', 'authors': 'Diego A. Silva, Ahmed Elsheikh, Kamilya Smagulova, Mohammed E. Fouda, Ahmed M. Eltawil', 'link': 'https://arxiv.org/abs/2412.19646', 'abstract': 'Event-based cameras are sensors that simulate the human eye, offering advantages such as high-speed robustness and low power consumption. Established Deep Learning techniques have shown effectiveness in processing event data. Chimera is a Block-Based Neural Architecture Search (NAS) framework specifically designed for Event-Based Object Detection, aiming to create a systematic approach for adapting RGB-domain processing methods to the event domain. The Chimera design space is constructed from various macroblocks, including Attention blocks, Convolutions, State Space Models, and MLP-mixer-based architectures, which provide a valuable trade-off between local and global processing capabilities, as well as varying levels of complexity. The results on the PErson Detection in Robotics (PEDRo) dataset demonstrated performance levels comparable to leading state-of-the-art models, alongside an average parameter reduction of 1.6 times.', 'abstract_zh': '基于事件的相机是一种模拟人眼的传感器，具有高速鲁棒性和低功耗等优点。已建立的深度学习技术在处理事件数据方面显示出有效性。Chimera是一种块基神经架构搜索（Block-Based Neural Architecture Search，BNAS）框架，专门针对事件检测进行设计，旨在创建一种系统的方法，将RGB域的处理方法适应到事件域中。Chimera的设计空间由各种宏块构建而成，包括注意力模块、卷积、状态空间模型以及基于MLP-Mixer的架构，这些模块提供了局部和全局处理能力以及不同复杂度的宝贵权衡。在PERson Detection in Robotics（PEDRo）数据集上的结果表明，Chimera的性能达到了与领先的一类模型相当的水平，同时参数量平均减少了一倍多。', 'title_zh': 'Chimera：一种基于块的事件驱动对象检测神经架构搜索框架'}
{'arxiv_id': 'arXiv:2412.19616', 'title': 'Gradient Weight-normalized Low-rank Projection for Efficient LLM Training', 'authors': 'Jia-Hong Huang, Yixian Shen, Hongyi Zhu, Stevan Rudinac, Evangelos Kanoulas', 'link': 'https://arxiv.org/abs/2412.19616', 'abstract': "Large Language Models (LLMs) have shown remarkable performance across various tasks, but the escalating demands on computational resources pose significant challenges, particularly in the extensive utilization of full fine-tuning for downstream tasks. To address this, parameter-efficient fine-tuning (PEFT) methods have been developed, but they often underperform compared to full fine-tuning and struggle with memory efficiency. In this work, we introduce Gradient Weight-Normalized Low-Rank Projection (GradNormLoRP), a novel approach that enhances both parameter and memory efficiency while maintaining comparable performance to full fine-tuning. GradNormLoRP normalizes the weight matrix to improve gradient conditioning, facilitating better convergence during optimization. Additionally, it applies low-rank approximations to the weight and gradient matrices, significantly reducing memory usage during training. Extensive experiments demonstrate that our 8-bit GradNormLoRP reduces optimizer memory usage by up to 89.5% and enables the pre-training of large LLMs, such as LLaMA 7B, on consumer-level GPUs like the NVIDIA RTX 4090, without additional inference costs. Moreover, GradNormLoRP outperforms existing low-rank methods in fine-tuning tasks. For instance, when fine-tuning the RoBERTa model on all GLUE tasks with a rank of 8, GradNormLoRP achieves an average score of 80.65, surpassing LoRA's score of 79.23. These results underscore GradNormLoRP as a promising alternative for efficient LLM pre-training and fine-tuning. Source code and Appendix: this https URL", 'abstract_zh': '大型语言模型（LLMs）在各种任务中表现出色，但不断增长的计算资源需求带来了重大挑战，尤其是在下游任务中广泛使用全量微调方面。为应对这一问题，已经开发出了参数高效微调（PEFT）方法，但这些方法通常在性能上不如全量微调，并且在内存效率方面存在困难。本文中，我们引入了一种新颖的方法——梯度权重归一化低秩投影（GradNormLoRP），该方法在保持与全量微调相近性能的同时，增强了参数和内存效率。GradNormLoRP 通过归一化权重矩阵来改善梯度条件，从而在优化过程中促进更好的收敛。此外，它还对权重和梯度矩阵应用低秩近似，显著降低了训练期间的内存使用量。广泛的实验证明，我们的8位GradNormLoRP可以将优化器的内存使用量降低高达89.5%，并使诸如LaMA 7B这样的大型LLM能够在颇具成本效益的GPU（如NVIDIA RTX 4090）上进行预训练，而无需额外的推理成本。此外，GradNormLoRP 在微调任务中优于现有的低秩方法。例如，当在所有GLUE任务上对RoBERTa模型进行微调并使用秩8时，GradNormLoRP 达到平均得分为80.65，超过了LoRA的得分79.23。这些结果表明GradNormLoRP 是一种有前景的选择，适用于高效的LLM预训练和微调。 \n相关代码和附录：[此链接](此链接应替换为实际链接)', 'title_zh': '基于梯度加权规范化低秩投影的高效大语言模型训练方法'}
{'arxiv_id': 'arXiv:2412.19609', 'title': 'Bidding Games on Markov Decision Processes with Quantitative Reachability Objectives', 'authors': 'Guy Avni, Martin Kurečka, Kaushik Mallik, Petr Novotný, Suman Sadhukhan', 'link': 'https://arxiv.org/abs/2412.19609', 'abstract': "Graph games are fundamental in strategic reasoning of multi-agent systems and their environments. We study a new family of graph games which combine stochastic environmental uncertainties and auction-based interactions among the agents, formalized as bidding games on (finite) Markov decision processes (MDP). Normally, on MDPs, a single decision-maker chooses a sequence of actions, producing a probability distribution over infinite paths. In bidding games on MDPs, two players -- called the reachability and safety players -- bid for the privilege of choosing the next action at each step. The reachability player's goal is to maximize the probability of reaching a target vertex, whereas the safety player's goal is to minimize it. These games generalize traditional bidding games on graphs, and the existing analysis techniques do not extend. For instance, the central property of traditional bidding games is the existence of a threshold budget, which is a necessary and sufficient budget to guarantee winning for the reachability player. For MDPs, the threshold becomes a relation between the budgets and probabilities of reaching the target. We devise value-iteration algorithms that approximate thresholds and optimal policies for general MDPs, and compute the exact solutions for acyclic MDPs, and show that finding thresholds is at least as hard as solving simple-stochastic games.", 'abstract_zh': '图博弈在多智能体系统及其环境的战略推理中是基本的。我们研究一类新的图博弈，这些博弈结合了环境的随机不确定性以及智能体之间的拍卖式互动，具体形式为（有限）马尔可夫决策过程（MDP）上的拍卖博弈。通常，在MDP中，单一决策者选择一系列行动，产生无限路径的概率分布。而在MDP上的拍卖博弈中，两个玩家——称为可达性和安全玩家——会在每一步为选择下一行动的特权进行竞价。可达性玩家的目标是最大化达到目标顶点的概率，而安全性玩家的目标则是最小化这一概率。这些博弈扩展了传统的图上拍卖博弈，现有的分析技术无法直接应用于它们。例如，传统拍卖博弈的核心性质是存在一个阈值预算，该预算对于可达性玩家而言既是必要也是充分的，可以确保其赢得博弈。然而，在MDP中，阈值变成了预算和达到目标的概率之间的关系。为此，我们设计了值迭代算法来近似MDP上的阈值和最优策略，并为无环MDP精确计算了解决方案，同时表明找到阈值的难度至少与简单随机博弈的求解相当。', 'title_zh': '马尔可夫决策过程中的具有定量可达性目标的出价博弈'}
{'arxiv_id': 'arXiv:2412.19595', 'title': 'SocRATES: Towards Automated Scenario-based Testing of Social Navigation Algorithms', 'authors': 'Shashank Rao Marpally, Pranav Goyal, Harold Soh', 'link': 'https://arxiv.org/abs/2412.19595', 'abstract': "Current social navigation methods and benchmarks primarily focus on proxemics and task efficiency. While these factors are important, qualitative aspects such as perceptions of a robot's social competence are equally crucial for successful adoption and integration into human environments. We propose a more comprehensive evaluation of social navigation through scenario-based testing, where specific human-robot interaction scenarios can reveal key robot behaviors. However, creating such scenarios is often labor-intensive and complex. In this work, we address this challenge by introducing a pipeline that automates the generation of context-, and location-appropriate social navigation scenarios, ready for simulation. Our pipeline transforms simple scenario metadata into detailed textual scenarios, infers pedestrian and robot trajectories, and simulates pedestrian behaviors, which enables more controlled evaluation. We leverage the social reasoning and code-generation capabilities of Large Language Models (LLMs) to streamline scenario generation and translation. Our experiments show that our pipeline produces realistic scenarios and significantly improves scenario translation over naive LLM prompting. Additionally, we present initial feedback from a usability study with social navigation experts and a case-study demonstrating a scenario-based evaluation of three navigation algorithms.", 'abstract_zh': '当前的社会导航方法和基准主要集中在人际距离和任务效率方面。虽然这些因素很重要，但对机器人社会能力的感知等定性因素同样对于其成功采用和融入人类环境至关重要。我们提出了一种通过基于场景的测试来更加全面地评估社会导航的方法，其中特定的人机交互场景可以揭示关键的机器人行为。然而，创建这些场景往往是劳动密集型且复杂的。在这项工作中，我们通过引入一种自动化生成上下文和地点适配的社会导航场景的管道来应对这一挑战，这些场景可以直接用于模拟。我们的管道将简单的场景元数据转换为详细的文本场景，推断行人的轨迹和机器人的轨迹，并模拟行人的行为，从而实现更加可控的评估。我们利用大型语言模型（LLMs）的社交推理和代码生成能力来简化场景生成和翻译。我们的实验表明，我们的管道生成出逼真的场景，显著提高了场景翻译的效果。此外，我们还呈现了来自社会导航专家可用性研究的初步反馈以及一项基于场景评估三种导航算法的案例研究。', 'title_zh': 'SocRATES：面向社会导航算法场景化测试的自动化方法'}
{'arxiv_id': 'arXiv:2412.19589', 'title': 'ViDTA: Enhanced Drug-Target Affinity Prediction via Virtual Graph Nodes and Attention-based Feature Fusion', 'authors': 'Minghui Li, Zikang Guo, Yang Wu, Peijin Guo, Yao Shi, Shengshan Hu, Wei Wan, Shengqing Hu', 'link': 'https://arxiv.org/abs/2412.19589', 'abstract': "Drug-target interaction is fundamental in understanding how drugs affect biological systems, and accurately predicting drug-target affinity (DTA) is vital for drug discovery. Recently, deep learning methods have emerged as a significant approach for estimating the binding strength between drugs and target proteins. However, existing methods simply utilize the drug's local information from molecular topology rather than global information. Additionally, the features of drugs and proteins are usually fused with a simple concatenation operation, limiting their effectiveness. To address these challenges, we proposed ViDTA, an enhanced DTA prediction framework. We introduce virtual nodes into the Graph Neural Network (GNN)-based drug feature extraction network, which acts as a global memory to exchange messages more efficiently. By incorporating virtual graph nodes, we seamlessly integrate local and global features of drug molecular structures, expanding the GNN's receptive field. Additionally, we propose an attention-based linear feature fusion network for better capturing the interaction information between drugs and proteins. Experimental results evaluated on various benchmarks including Davis, Metz, and KIBA demonstrate that our proposed ViDTA outperforms the state-of-the-art baselines.", 'abstract_zh': '药物-靶点相互作用是理解药物如何影响生物系统的基础，而准确预测药物-靶点亲和力（Drug-Target Affinity, DTA）对于药物发现至关重要。近年来，深度学习方法已成为估算药物与靶点蛋白质之间结合强度的一种重要手段。然而，现有的方法仅利用药物从分子拓扑中提取的局部信息，而忽略了全局信息。此外，药物和蛋白质的特征通常通过简单的串联操作进行融合，这限制了其有效性。为了解决这些挑战，我们提出了ViDTA，一种增强的DTA预测框架。我们在基于图神经网络（Graph Neural Network, GNN）的药物特征提取网络中引入了虚拟节点，它们充当全局记忆以更有效地交换消息。通过结合虚拟图节点，我们将局部和全局的药物分子结构特征无缝整合，扩展了GNN的感受野。此外，我们还提出了一种基于注意力的线性特征融合网络，以更好地捕捉药物与蛋白质之间的相互作用信息。在包括Davis、Metz和KIBA在内的各种基准数据集上的实验结果表明，我们提出的ViDTA优于最先进的基线方法。', 'title_zh': 'ViDTA：通过虚拟图节点和基于注意力的功能融合改进的药物-靶点亲和力预测'}
{'arxiv_id': 'arXiv:2412.19583', 'title': 'A Comparative Study of Machine Unlearning Techniques for Image and Text Classification Models', 'authors': 'Omar M. Safa, Mahmoud M. Abdelaziz, Mustafa Eltawy, Mohamed Mamdouh, Moamen Gharib, Salaheldin Eltenihy, Nagia M. Ghanem, Mohamed M. Ismail', 'link': 'https://arxiv.org/abs/2412.19583', 'abstract': 'Machine Unlearning has emerged as a critical area in artificial intelligence, addressing the need to selectively remove learned data from machine learning models in response to data privacy regulations. This paper provides a comprehensive comparative analysis of six state-of-theart unlearning techniques applied to image and text classification tasks. We evaluate their performance, efficiency, and compliance with regulatory requirements, highlighting their strengths and limitations in practical scenarios. By systematically analyzing these methods, we aim to provide insights into their applicability, challenges,and tradeoffs, fostering advancements in the field of ethical and adaptable machine learning.', 'abstract_zh': '机器遗忘作为人工智能中的一个重要领域，致力于在遵守数据隐私法规的前提下，从机器学习模型中选择性地移除已学习的数据。本文通过对六种前沿遗忘技术在图像和文本分类任务中的应用进行全面的比较分析，评估这些技术的性能、效率以及合规性，突出他们在实际应用场景中的强项和局限性。通过系统地分析这些方法，我们旨在提供对其适用性、挑战和权衡的见解，促进伦理和适应性强的机器学习领域的进展。', 'title_zh': '机器遗忘技术在图像和文本分类模型中的对比研究'}
{'arxiv_id': 'arXiv:2412.19578', 'title': 'Graph-attention-based Casual Discovery with Trust Region-navigated Clipping Policy Optimization', 'authors': 'Shixuan Liu, Yanghe Feng, Keyu Wu, Guangquan Cheng, Jincai Huang, Zhong Liu', 'link': 'https://arxiv.org/abs/2412.19578', 'abstract': 'In many domains of empirical sciences, discovering the causal structure within variables remains an indispensable task. Recently, to tackle with unoriented edges or latent assumptions violation suffered by conventional methods, researchers formulated a reinforcement learning (RL) procedure for causal discovery, and equipped REINFORCE algorithm to search for the best-rewarded directed acyclic graph. The two keys to the overall performance of the procedure are the robustness of RL methods and the efficient encoding of variables. However, on the one hand, REINFORCE is prone to local convergence and unstable performance during training. Neither trust region policy optimization, being computationally-expensive, nor proximal policy optimization (PPO), suffering from aggregate constraint deviation, is decent alternative for combinatory optimization problems with considerable individual subactions. We propose a trust region-navigated clipping policy optimization method for causal discovery that guarantees both better search efficiency and steadiness in policy optimization, in comparison with REINFORCE, PPO and our prioritized sampling-guided REINFORCE implementation. On the other hand, to boost the efficient encoding of variables, we propose a refined graph attention encoder called SDGAT that can grasp more feature information without priori neighbourhood information. With these improvements, the proposed method outperforms former RL method in both synthetic and benchmark datasets in terms of output results and optimization robustness.', 'abstract_zh': '在许多实证科学领域中，发现变量间的因果结构仍然是一个必不可少的任务。最近，为了应对传统方法中未定向边或潜在假设验证失败的问题，研究人员提出了一种强化学习（RL）方法来进行因果发现，并采用REINFORCE算法来寻找奖励最高的有向无环图（DAG）。该方法的整体性能取决于RL方法的鲁棒性和变量的有效编码。然而，一方面，REINFORCE在训练过程中容易出现局部收敛和不稳定的表现。另两个替代算法，信赖域策略优化（TRPO）由于计算成本高，而Proximal Policy Optimization（PPO）则因组合优化问题中的约束偏差而表现不佳。我们提出了一种信赖域导航裁剪策略优化方法，该方法在因果发现中既能保证更好的搜索效率，又能保证策略优化的稳定性，相比REINFORCE、PPO以及我们的优先采样引导的REINFORCE实现方法，表现出更优的效果。另一方面，为了提高变量的有效编码，我们提出了一种改进的图注意力编码器SDGAT，它可以不依赖先验邻域信息的情况下捕捉更多的特征信息。通过这些改进，提出的该方法在合成数据集和基准数据集中的输出结果和优化鲁棒性方面，都优于之前的RL方法。', 'title_zh': '基于图注意力的因果发现与信任区域导向的截断策略优化'}
{'arxiv_id': 'arXiv:2412.19544', 'title': 'TARGA: Targeted Synthetic Data Generation for Practical Reasoning over Structured Data', 'authors': 'Xiang Huang, Jiayu Shen, Shanshan Huang, Sitao Cheng, Xiaxia Wang, Yuzhong Qu', 'link': 'https://arxiv.org/abs/2412.19544', 'abstract': 'Semantic parsing, which converts natural language questions into logic forms, plays a crucial role in reasoning within structured environments. However, existing methods encounter two significant challenges: reliance on extensive manually annotated datasets and limited generalization capability to unseen examples. To tackle these issues, we propose Targeted Synthetic Data Generation (TARGA), a practical framework that dynamically generates high-relevance synthetic data without manual annotation. Starting from the pertinent entities and relations of a given question, we probe for the potential relevant queries through layer-wise expansion and cross-layer combination. Then we generate corresponding natural language questions for these constructed queries to jointly serve as the synthetic demonstrations for in-context learning. Experiments on multiple knowledge base question answering (KBQA) datasets demonstrate that TARGA, using only a 7B-parameter model, substantially outperforms existing non-fine-tuned methods that utilize close-sourced model, achieving notable improvements in F1 scores on GrailQA(+7.7) and KBQA-Agent(+12.2). Furthermore, TARGA also exhibits superior sample efficiency, robustness, and generalization capabilities under non-I.I.D. settings.', 'abstract_zh': '语义解析，即将自然语言问题转化为逻辑形式，在结构化环境中进行推理中起着关键作用。然而，现有的方法面临着两个重大挑战：对大规模手动标注数据集的依赖以及对未见过的示例的有限泛化能力。为了解决这些问题，我们提出了目标导向的合成数据生成（TARGA）框架，该框架能够动态生成与目标高度相关的合成数据，而无需手动标注。从给定问题的相关实体和关系出发，我们通过逐层扩展和跨层组合的方式探索潜在的相关查询。然后，为这些构建的查询生成相应的自然语言问题，共同作为上下文学习的合成示例。在多个知识库问答（KBQA）数据集上的实验表明，TARGA 使用仅一个 7B 参数模型，显著优于现有未微调的方法，这些方法使用的是内部模型，在 GrailQA 上的 F1 分数提高了 7.7%，在 KBQA-Agent 上的 F1 分数提高了 12.2%。此外，TARGA 还在非独立同分布（non-I.I.D.）设置下显示出更高的样本效率、鲁棒性和泛化能力。', 'title_zh': 'TARGA：面向结构化数据实用推理的目标合成数据生成方法'}
{'arxiv_id': 'arXiv:2412.19542', 'title': 'Interacted Object Grounding in Spatio-Temporal Human-Object Interactions', 'authors': 'Xiaoyang Liu, Boran Wen, Xinpeng Liu, Zizheng Zhou, Hongwei Fan, Cewu Lu, Lizhuang Ma, Yulong Chen, Yong-Lu Li', 'link': 'https://arxiv.org/abs/2412.19542', 'abstract': "Spatio-temporal Human-Object Interaction (ST-HOI) understanding aims at detecting HOIs from videos, which is crucial for activity understanding. However, existing whole-body-object interaction video benchmarks overlook the truth that open-world objects are diverse, that is, they usually provide limited and predefined object classes. Therefore, we introduce a new open-world benchmark: Grounding Interacted Objects (GIO) including 1,098 interacted objects class and 290K interacted object boxes annotation. Accordingly, an object grounding task is proposed expecting vision systems to discover interacted objects. Even though today's detectors and grounding methods have succeeded greatly, they perform unsatisfactorily in localizing diverse and rare objects in GIO. This profoundly reveals the limitations of current vision systems and poses a great challenge. Thus, we explore leveraging spatio-temporal cues to address object grounding and propose a 4D question-answering framework (4D-QA) to discover interacted objects from diverse videos. Our method demonstrates significant superiority in extensive experiments compared to current baselines. Data and code will be publicly available at this https URL.", 'abstract_zh': '时空人体对象交互（ST-HOI）理解的目标是从视频中检测人体对象交互，这对于活动理解至关重要。然而，现有的全身物体交互视频标准数据集忽视了一个事实，即开放世界中的物体是多样的，即它们通常只提供有限的预定义对象类别。因此，我们引入了一个新的开放世界基准：交互对象定位（GIO），其中包括1,098个交互对象类别和29万个交互对象框标注。相应地，我们提出了一项对象定位任务，期望视觉系统能够发现交互对象。尽管目前的检测器和定位方法已经取得了很大的成功，但在GIO中定位多样性和稀有物体时，它们的表现仍不尽如人意。这深刻地揭示了现有视觉系统的局限性，并提出了一个巨大的挑战。因此，我们探索利用时空线索来解决对象定位问题，并提出了一种四维问答框架（4D-QA）来从多样化的视频中发现交互对象。我们的方法在广泛的实验中明显优于当前基线方法。数据和代码将在此URL公开访问：[此链接](此链接请用实际URL替换)。\n\n（注：请将[此链接]替换为具体的公开链接地址。）', 'title_zh': '空间-temporal 人类-物体交互中的相互作用物体 grounding'}
{'arxiv_id': 'arXiv:2412.19538', 'title': 'Scalable Hierarchical Reinforcement Learning for Hyper Scale Multi-Robot Task Planning', 'authors': 'Xuan Zhou, Xiang Shi, Lele Zhang, Chen Chen, Hongbo Li, Lin Ma, Fang Deng, Jie Chen', 'link': 'https://arxiv.org/abs/2412.19538', 'abstract': 'To improve the efficiency of warehousing system and meet huge customer orders, we aim to solve the challenges of dimension disaster and dynamic properties in hyper scale multi-robot task planning (MRTP) for robotic mobile fulfillment system (RMFS). Existing research indicates that hierarchical reinforcement learning (HRL) is an effective method to reduce these challenges. Based on that, we construct an efficient multi-stage HRL-based multi-robot task planner for hyper scale MRTP in RMFS, and the planning process is represented with a special temporal graph topology. To ensure optimality, the planner is designed with a centralized architecture, but it also brings the challenges of scaling up and generalization that require policies to maintain performance for various unlearned scales and maps. To tackle these difficulties, we first construct a hierarchical temporal attention network (HTAN) to ensure basic ability of handling inputs with unfixed lengths, and then design multi-stage curricula for hierarchical policy learning to further improve the scaling up and generalization ability while avoiding catastrophic forgetting. Additionally, we notice that policies with hierarchical structure suffer from unfair credit assignment that is similar to that in multi-agent reinforcement learning, inspired of which, we propose a hierarchical reinforcement learning algorithm with counterfactual rollout baseline to improve learning performance. Experimental results demonstrate that our planner outperform other state-of-the-art methods on various MRTP instances in both simulated and real-world RMFS. Also, our planner can successfully scale up to hyper scale MRTP instances in RMFS with up to 200 robots and 1000 retrieval racks on unlearned maps while keeping superior performance over other methods.', 'abstract_zh': '为了提高仓储系统的效率并满足大量客户订单的需求，我们旨在解决大规模多机器人任务规划（MRTP）中高维尺寸灾难与动态属性的挑战。现有的研究表明，层次强化学习（HRL）是一种有效的方法来减轻这些挑战。基于此，我们构建了一个高效多层次HRL多机器人任务规划器，以应对RMFS中的大规模MRTP问题，并将规划过程表示为一种特殊的时序图拓扑结构。为了保证最优性，规划器采用了集中式架构，但这也带来了规模扩展和泛化的挑战，需要政策能够在各种未学习的规模和地图上保持性能。为了解决这些困难，我们首先构建了一个层次时间注意力网络（HTAN），以确保能够处理输入长度不定的情况；然后设计了多层次课程来进一步提高规模扩展和泛化能力，同时避免灾难性遗忘。此外，我们注意到具有层次结构的策略在贡献归因方面存在类似多智能体强化学习的问题，因此受此启发，我们提出了一种带有反事实展开基线的层次强化学习算法，以提高学习性能。实验结果表明，我们的规划器在模拟和实际仓储系统中的多种MRTP实例中，优于其他最先进的方法。此外，我们的规划器能够成功扩展到拥有200个机器人和1000个取货货架的大型MRTP实例，并保持优于其他方法的出色性能。', 'title_zh': '面向超大规模多机器人任务规划的可扩展分层强化学习方法'}
{'arxiv_id': 'arXiv:2412.19533', 'title': 'P3S-Diffusion:A Selective Subject-driven Generation Framework via Point Supervision', 'authors': 'Junjie Hu, Shuyong Gao, Lingyi Hong, Qishan Wang, Yuzhou Zhao, Yan Wang, Wenqiang Zhang', 'link': 'https://arxiv.org/abs/2412.19533', 'abstract': 'Recent research in subject-driven generation increasingly emphasizes the importance of selective subject features. Nevertheless, accurately selecting the content in a given reference image still poses challenges, especially when selecting the similar subjects in an image (e.g., two different dogs). Some methods attempt to use text prompts or pixel masks to isolate specific elements. However, text prompts often fall short in precisely describing specific content, and pixel masks are often expensive. To address this, we introduce P3S-Diffusion, a novel architecture designed for context-selected subject-driven generation via point supervision. P3S-Diffusion leverages minimal cost label (e.g., points) to generate subject-driven images. During fine-tuning, it can generate an expanded base mask from these points, obviating the need for additional segmentation models. The mask is employed for inpainting and aligning with subject representation. The P3S-Diffusion preserves fine features of the subjects through Multi-layers Condition Injection. Enhanced by the Attention Consistency Loss for improved training, extensive experiments demonstrate its excellent feature preservation and image generation capabilities.', 'abstract_zh': '近年来，以主题为导向的生成研究越来越强调选择性主题特征的重要性。然而，准确地从给定的参考图像中选择内容仍然存在挑战，尤其是在选择图像中的相似主题时（例如，两条不同品种的狗）。一些方法尝试使用文本提示或像素掩码来隔离特定元素。然而，文本提示往往在精确描述特定内容方面存在不足，而像素掩码则往往成本较高。为了解决这个问题，我们引入了P3S-Diffusion，这是一种为通过点监督实现上下文选择性主题驱动生成而设计的新架构。P3S-Diffusion 利用少量成本标签（例如，点）来生成主题驱动的图像。在微调过程中，它可以从这些点生成扩展的基础掩码，从而避免使用附加的分割模型。该掩码用于修复和与主题表示对齐。P3S-Diffusion 通过多层条件注入保留主题的精细特征，并通过注意一致性损失进行增强以提高训练效果。大量的实验结果表明，P3S-Diffusion 在特征保真度和图像生成能力方面表现出色。', 'title_zh': 'P3S-扩散模型：一种通过点监督的选择性主题驱动生成框架'}
{'arxiv_id': 'arXiv:2412.19531', 'title': 'Is Your Text-to-Image Model Robust to Caption Noise?', 'authors': 'Weichen Yu, Ziyan Yang, Shanchuan Lin, Qi Zhao, Jianyi Wang, Liangke Gui, Matt Fredrikson, Lu Jiang', 'link': 'https://arxiv.org/abs/2412.19531', 'abstract': 'In text-to-image (T2I) generation, a prevalent training technique involves utilizing Vision Language Models (VLMs) for image re-captioning. Even though VLMs are known to exhibit hallucination, generating descriptive content that deviates from the visual reality, the ramifications of such caption hallucinations on T2I generation performance remain under-explored. Through our empirical investigation, we first establish a comprehensive dataset comprising VLM-generated captions, and then systematically analyze how caption hallucination influences generation outcomes. Our findings reveal that (1) the disparities in caption quality persistently impact model outputs during fine-tuning. (2) VLMs confidence scores serve as reliable indicators for detecting and characterizing noise-related patterns in the data distribution. (3) even subtle variations in caption fidelity have significant effects on the quality of learned representations. These findings collectively emphasize the profound impact of caption quality on model performance and highlight the need for more sophisticated robust training algorithm in T2I. In response to these observations, we propose a approach leveraging VLM confidence score to mitigate caption noise, thereby enhancing the robustness of T2I models against hallucination in caption.', 'abstract_zh': '在文本到图像（T2I）生成中，一种常见的训练技术是利用视觉语言模型（VLMs）进行图像重新描述。尽管VLMs已知会表现出幻觉，即生成与视觉现实不符的描述性内容，但这种描述幻觉对T2I生成性能的影响尚未得到充分探索。通过我们的实证研究，我们首先建立了一个由VLM生成的描述组成的综合数据集，然后系统分析描述幻觉如何影响生成结果。我们的研究发现：（1）描述质量的差异在微调过程中持续影响模型输出。（2）VLM的置信度分数可以作为检测和表征数据分布中噪声模式的可靠指标。（3）即使描述保真度的细微变化也会对学习表示的质量产生显著影响。这些发现共同强调了描述质量对模型性能的深远影响，并突显了在T2I中需要更复杂可靠的训练算法的需求。针对这些观察结果，我们提出了一种利用VLM置信度分数来减轻描述噪声的方法，从而增强T2I模型在描述幻觉方面的稳健性。', 'title_zh': '你的文本到图像模型对 Caption 噪声具有鲁棒性吗？'}
{'arxiv_id': 'arXiv:2412.19517', 'title': 'Estimation of System Parameters Including Repeated Cross-Sectional Data through Emulator-Informed Deep Generative Model', 'authors': 'Hyunwoo Cho, Sung Woong Cho, Hyeontae Jo, Hyung Ju Hwang', 'link': 'https://arxiv.org/abs/2412.19517', 'abstract': 'Differential equations (DEs) are crucial for modeling the evolution of natural or engineered systems. Traditionally, the parameters in DEs are adjusted to fit data from system observations. However, in fields such as politics, economics, and biology, available data are often independently collected at distinct time points from different subjects (i.e., repeated cross-sectional (RCS) data). Conventional optimization techniques struggle to accurately estimate DE parameters when RCS data exhibit various heterogeneities, leading to a significant loss of information. To address this issue, we propose a new estimation method called the emulator-informed deep-generative model (EIDGM), designed to handle RCS data. Specifically, EIDGM integrates a physics-informed neural network-based emulator that immediately generates DE solutions and a Wasserstein generative adversarial network-based parameter generator that can effectively mimic the RCS data. We evaluated EIDGM on exponential growth, logistic population models, and the Lorenz system, demonstrating its superior ability to accurately capture parameter distributions. Additionally, we applied EIDGM to an experimental dataset of Amyloid beta 40 and beta 42, successfully capturing diverse parameter distribution shapes. This shows that EIDGM can be applied to model a wide range of systems and extended to uncover the operating principles of systems based on limited data.', 'abstract_zh': '微分方程（DEs）对于建模自然或工程系统的演化至关重要。传统上，DEs中的参数会根据系统观测数据进行调整。然而，在政治、经济和生物学等领域，可用数据通常是在不同时间点独立从不同主体中收集的（即重叠横截面（RCS）数据）。常规的优化技术在处理表现出各种异质性的RCS数据时很难准确估计DE参数，导致信息的大量损失。为解决这一问题，我们提出了一种新的估计方法，称为模拟器导向的深度生成模型（EIDGM），该方法专门处理RCS数据。具体而言，EIDGM结合了一个基于物理导向神经网络的模拟器，它可以立即生成DE的解，并使用基于沃什尔梯度生成对抗网络的参数生成器，该生成器能够有效地模仿RCS数据。我们通过指数增长模型、逻辑斯蒂人口模型和洛伦兹系统对EIDGM进行了评估，展示了其在准确捕捉参数分布方面的能力。此外，我们还将EIDGM应用于阿尔茨海默病β-淀粉样蛋白40和β-淀粉样蛋白42的实验数据集，成功捕捉到了不同的参数分布形状。这表明EIDGM可以应用于建模各种系统，并基于有限数据探索系统的运行原理。', 'title_zh': '通过仿真导向的深度生成模型估计包含重复截面数据的系统参数'}
{'arxiv_id': 'arXiv:2412.19509', 'title': 'MBQ: Modality-Balanced Quantization for Large Vision-Language Models', 'authors': 'Shiyao Li, Yingchun Hu, Xuefei Ning, Xihui Liu, Ke Hong, Xiaotao Jia, Xiuhong Li, Yaqi Yan, Pei Ran, Guohao Dai, Shengen Yan, Huazhong Yang, Yu Wang', 'link': 'https://arxiv.org/abs/2412.19509', 'abstract': 'Vision-Language Models (VLMs) have enabled a variety of real-world applications. The large parameter size of VLMs brings large memory and computation overhead which poses significant challenges for deployment. Post-Training Quantization (PTQ) is an effective technique to reduce the memory and computation overhead. Existing PTQ methods mainly focus on large language models (LLMs), without considering the differences across other modalities. In this paper, we discover that there is a significant difference in sensitivity between language and vision tokens in large VLMs. Therefore, treating tokens from different modalities equally, as in existing PTQ methods, may over-emphasize the insensitive modalities, leading to significant accuracy loss. To deal with the above issue, we propose a simple yet effective method, Modality-Balanced Quantization (MBQ), for large VLMs. Specifically, MBQ incorporates the different sensitivities across modalities during the calibration process to minimize the reconstruction loss for better quantization parameters. Extensive experiments show that MBQ can significantly improve task accuracy by up to 4.4% and 11.6% under W3 and W4A8 quantization for 7B to 70B VLMs, compared to SOTA baselines. Additionally, we implement a W3 GPU kernel that fuses the dequantization and GEMV operators, achieving a 1.4x speedup on LLaVA-onevision-7B on the RTX 4090. The code is available at this https URL.', 'abstract_zh': '视觉-语言模型（VLMs）使多种现实应用场景成为可能。VLMs 的大参数量带来了巨大的内存和计算成本，这对部署提出了重大挑战。训练后量化（Post-Training Quantization, PTQ）是一种有效的方法，用于减少这些成本。目前的 PTQ 方法主要集中在大型语言模型（LLMs）上，而忽视了其他模态之间的差异。在本文中，我们发现大型 VLMs 中语言和视觉标记在敏感度方面存在显著差异。因此，现有的 PTQ 方法在处理不同模态的标记时采用相同的处理方式，可能会过度强调不敏感的模态，从而导致显著的准确性损失。为解决上述问题，我们提出了一种简单而有效的方法——模态平衡量化（Modality-Balanced Quantization, MBQ），专门用于大型 VLMs。具体而言，MBQ 在校准过程中考虑不同模态之间的敏感度差异，以最小化重建损失，从而获得更好的量化参数。广泛实验表明，MBQ 与最先进的基线方法相比，在 W3 和 W4A8 量化下，对于 7B 至 70B 的 VLMs，可以显著提高任务准确性高达 4.4% 和 11.6%。此外，我们实现了一个 W3 GPU 内核，将去量化的操作和 GEMV（通用矩阵-向量乘）操作融合在一起，在 RTX 4090 上实现了 LLaVA-onevision-7B 的 1.4 倍加速。代码可从以下链接获取：this https URL。', 'title_zh': 'MBQ: 配平模态量化大型视觉-语言模型'}
{'arxiv_id': 'arXiv:2412.19496', 'title': 'Multi-P$^2$A: A Multi-perspective Benchmark on Privacy Assessment for Large Vision-Language Models', 'authors': 'Jie Zhang, Xiangkui Cao, Zhouyu Han, Shiguang Shan, Xilin Chen', 'link': 'https://arxiv.org/abs/2412.19496', 'abstract': "Large Vision-Language Models (LVLMs) exhibit impressive potential across various tasks but also face significant privacy risks, limiting their practical applications. Current researches on privacy assessment for LVLMs is limited in scope, with gaps in both assessment dimensions and privacy categories. To bridge this gap, we propose Multi-P$^2$A, a comprehensive benchmark for evaluating the privacy preservation capabilities of LVLMs in terms of privacy awareness and leakage. Privacy awareness measures the model's ability to recognize the privacy sensitivity of input data, while privacy leakage assesses the risk of the model unintentionally disclosing privacy information in its output. We design a range of sub-tasks to thoroughly evaluate the model's privacy protection offered by LVLMs. Multi-P$^2$A covers 26 categories of personal privacy, 15 categories of trade secrets, and 18 categories of state secrets, totaling 31,962 samples. Based on Multi-P$^2$A, we evaluate the privacy preservation capabilities of 21 open-source and 2 closed-source LVLMs. Our results reveal that current LVLMs generally pose a high risk of facilitating privacy breaches, with vulnerabilities varying across personal privacy, trade secret, and state secret.", 'abstract_zh': '大规模视觉-语言模型（LVLMs）在各种任务中表现出令人印象深刻的潜力，但也面临较大的隐私风险，从而限制了其实际应用。目前对LVLMs的隐私评估研究范围有限，且在评估维度和隐私类别方面存在空白。为填补这一空白，我们提出了一种综合性基准Multi-P$^2$A，用于评估LVLMs在隐私意识和泄露方面的隐私保留能力。隐私意识衡量模型识别输入数据隐私敏感性的能力，而隐私泄露评估模型无意间在其输出中披露隐私信息的风险。我们设计了一系列子任务以全面评估LVLMs提供的隐私保护能力。Multi-P$^2$A涵盖了26类个人隐私、15类商业秘密和18类国家机密，共计31,962个样本。基于Multi-P$^2$A，我们评估了21个开源和2个闭源LVLMs的隐私保护能力。我们的结果显示，当前的LVLMs普遍存在较高的隐私泄露风险，不同类型的隐私（个人隐私、商业秘密和国家机密）存在不同的漏洞。', 'title_zh': '多视角评估：大规模视觉-语言模型隐私评估的多视角基准'}
{'arxiv_id': 'arXiv:2412.19495', 'title': 'Disparate Model Performance and Stability in Machine Learning Clinical Support for Diabetes and Heart Diseases', 'authors': 'Ioannis Bilionis, Ricardo C. Berrios, Luis Fernandez-Luque, Carlos Castillo', 'link': 'https://arxiv.org/abs/2412.19495', 'abstract': 'Machine Learning (ML) algorithms are vital for supporting clinical decision-making in biomedical informatics. However, their predictive performance can vary across demographic groups, often due to the underrepresentation of historically marginalized populations in training datasets. The investigation reveals widespread sex- and age-related inequities in chronic disease datasets and their derived ML models. Thus, a novel analytical framework is introduced, combining systematic arbitrariness with traditional metrics like accuracy and data complexity. The analysis of data from over 25,000 individuals with chronic diseases revealed mild sex-related disparities, favoring predictive accuracy for males, and significant age-related differences, with better accuracy for younger patients. Notably, older patients showed inconsistent predictive accuracy across seven datasets, linked to higher data complexity and lower model performance. This highlights that representativeness in training data alone does not guarantee equitable outcomes, and model arbitrariness must be addressed before deploying models in clinical settings.', 'abstract_zh': '机器学习（ML）算法对于生物医学信息学中的临床决策支持至关重要。然而，它们在不同的人口统计学群体中的预测性能可能存在差异，这往往源于历史上被边缘化群体在训练数据集中的代表性不足。研究揭示了慢性疾病数据集中普遍存在性别和年龄相关的不平等现象，并且这些现象反映在由其产生的机器学习模型中。为此，提出了一种新的分析框架，结合系统性随机性与传统的评估指标（如准确性）以及数据复杂性。\n\n对超过25,000名慢性病患者的数据显示，存在轻微的性别差异，男性在预测准确性方面占优势；同时，也发现了显著的年龄差异，年轻患者的表现更佳。值得注意的是，老年患者在七个数据集中的预测准确性表现出不一致性，这与数据复杂度的增加和模型性能下降有关。这表明，仅靠训练数据的代表性并不能保证公平的结果，因此在临床应用模型之前必须解决模型的系统性偏差问题。', 'title_zh': '机器学习临床支持中糖尿病和心脏病模型的异质性能与稳定性'}
{'arxiv_id': 'arXiv:2412.19467', 'title': 'Optimizing Helmet Detection with Hybrid YOLO Pipelines: A Detailed Analysis', 'authors': 'Vaikunth M, Dejey D, Vishaal C, Balamurali S', 'link': 'https://arxiv.org/abs/2412.19467', 'abstract': 'Helmet detection is crucial for advancing protection levels in public road traffic dynamics. This problem statement translates to an object detection task. Therefore, this paper compares recent You Only Look Once (YOLO) models in the context of helmet detection in terms of reliability and computational load. Specifically, YOLOv8, YOLOv9, and the newly released YOLOv11 have been used. Besides, a modified architectural pipeline that remarkably improves the overall performance has been proposed in this manuscript. This hybridized YOLO model (h-YOLO) has been pitted against the independent models for analysis that proves h-YOLO is preferable for helmet detection over plain YOLO models. The models were tested using a range of standard object detection benchmarks such as recall, precision, and mAP (Mean Average Precision). In addition, training and testing times were recorded to provide the overall scope of the models in a real-time detection scenario.', 'abstract_zh': '头盔检测对于公众道路交通安全保护水平的提升至关重要。这一问题陈述转化为一个物体检测任务。因此，本文在头盔检测的背景下比较了最近的YOLO模型（包括YOLOv8、YOLOv9和新发布的YOLOv11），从可靠性和计算负载两个方面进行评估。此外，本文中还提出了一种改进的架构流程，显著提高了整体性能。这种杂交YOLO模型（h-YOLO）被与独立模型进行比较分析，证实h-YOLO在头盔检测方面优于普通YOLO模型。模型使用了多种标准的目标检测基准（如召回率、精确率和mAP（平均精确率））进行测试。此外，还记录了训练和测试时间，以提供在实时检测场景中模型的整体范围。', 'title_zh': '基于混合YOLO管道的头盔检测优化：详细分析'}
{'arxiv_id': 'arXiv:2412.19437', 'title': 'DeepSeek-V3 Technical Report', 'authors': 'DeepSeek-AI, Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, Damai Dai, Daya Guo, Dejian Yang, Deli Chen, Dongjie Ji, Erhang Li, Fangyun Lin, Fucong Dai, Fuli Luo, Guangbo Hao, Guanting Chen, Guowei Li, H. Zhang, Han Bao, Hanwei Xu, Haocheng Wang, Haowei Zhang, Honghui Ding, Huajian Xin, Huazuo Gao, Hui Li, Hui Qu, J.L. Cai, Jian Liang, Jianzhong Guo, Jiaqi Ni, Jiashi Li, Jiawei Wang, Jin Chen, Jingchang Chen, Jingyang Yuan, Junjie Qiu, Junlong Li, Junxiao Song, Kai Dong, Kai Hu, Kaige Gao, Kang Guan, Kexin Huang, Kuai Yu, Lean Wang, Lecong Zhang, Lei Xu, Leyi Xia, Liang Zhao, Litong Wang, Liyue Zhang, Meng Li, Miaojun Wang, Mingchuan Zhang, Minghua Zhang, Minghui Tang, Mingming Li, Ning Tian, Panpan Huang, Peiyi Wang, Peng Zhang, Qiancheng Wang, Qihao Zhu, Qinyu Chen, Qiushi Du, R.J. Chen, R.L. Jin, Ruiqi Ge, Ruisong Zhang, Ruizhe Pan, Runji Wang, Runxin Xu, Ruoyu Zhang, Ruyi Chen, S.S. Li, Shanghao Lu, Shangyan Zhou, Shanhuang Chen, Shaoqing Wu, Shengfeng Ye, Shengfeng Ye, Shirong Ma, Shiyu Wang, Shuang Zhou, Shuiping Yu, Shunfeng Zhou, Shuting Pan, T. Wang, Tao Yun, Tian Pei, Tianyu Sun, W.L. Xiao, Wangding Zeng', 'link': 'https://arxiv.org/abs/2412.19437', 'abstract': 'We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token. To achieve efficient inference and cost-effective training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architectures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities. Comprehensive evaluations reveal that DeepSeek-V3 outperforms other open-source models and achieves performance comparable to leading closed-source models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours for its full training. In addition, its training process is remarkably stable. Throughout the entire training process, we did not experience any irrecoverable loss spikes or perform any rollbacks. The model checkpoints are available at this https URL.', 'abstract_zh': '我们提出 DeepSeek-V3，这是一个强大的混合专家（MoE）语言模型，总参数量为 671B，每个词汇令牌有 37B 的激活参数。为了实现高效的推理和成本效益的训练，DeepSeek-V3 采用了多头潜注意（MLA）和 DeepSeekMoE 架构，这两种架构在 DeepSeek-V2 中得到了充分验证。此外，DeepSeek-V3 引进了无辅助损失的方法进行负载均衡，并设定了多令牌预测的训练目标以增强性能。我们首先在 14.8 万亿个多样且高质量的令牌上对 DeepSeek-V3 进行预训练，随后经过监督微调和强化学习阶段，充分利用其能力。全面的评估显示，DeepSeek-V3 在性能上优于其他开源模型，并达到了与顶级闭源模型相当的性能。尽管其性能优异，但 DeepSeek-V3 完全套训练仅需 2.788M H800 GPU 小时。此外，其训练过程非常稳定，在整个训练过程中未出现任何不可恢复的损失突增，也未进行任何回滚操作。模型检查点可在以下链接获取：[这里](https://)。', 'title_zh': 'DeepSeek-V3 技术报告'}
{'arxiv_id': 'arXiv:2412.19433', 'title': 'Residual Feature-Reutilization Inception Network for Image Classification', 'authors': 'Yuanpeng He, Wenjie Song, Lijian Li, Tianxiang Zhan, Wenpin Jiao', 'link': 'https://arxiv.org/abs/2412.19433', 'abstract': 'Capturing feature information effectively is of great importance in the field of computer vision. With the development of convolutional neural networks (CNNs), concepts like residual connection and multiple scales promote continual performance gains in diverse deep learning vision tasks. In this paper, we propose a novel CNN architecture that it consists of residual feature-reutilization inceptions (ResFRI) or split-residual feature-reutilization inceptions (Split-ResFRI). And it is composed of four convolutional combinations of different structures connected by specially designed information interaction passages, which are utilized to extract multi-scale feature information and effectively increase the receptive field of the model. Moreover, according to the network structure designed above, Split-ResFRI can adjust the segmentation ratio of the input information, thereby reducing the number of parameters and guaranteeing the model performance. Specifically, in experiments based on popular vision datasets, such as CIFAR10 ($97.94$\\%), CIFAR100 ($85.91$\\%) and Tiny Imagenet ($70.54$\\%), we obtain state-of-the-art results compared with other modern models under the premise that the model size is approximate and no additional data is used.', 'abstract_zh': '在计算机视觉领域，有效地捕捉特征信息至关重要。随着卷积神经网络（CNNs）的发展，诸如残差连接和多尺度概念的引入在多种深度学习视觉任务中促进了持续的性能提升。在本文中，我们提出了一种新颖的CNN架构，该架构由残差特征重用的扩张模块（ResFRI）或分裂残差特征重用的扩张模块（Split-ResFRI）组成。该架构通过特别设计的信息交互通道连接四种不同结构的卷积组合，用于提取多尺度特征信息并有效增加模型的感受野。此外，根据上述网络结构设计，Split-ResFRI 可以调整输入信息的分割比例，从而减少参数数量并保证模型性能。具体而言，在基于流行的视觉数据集（如CIFAR10（97.94%）、CIFAR100（85.91%）和Tiny ImageNet（70.54%））的实验中，与同等规模的其他现代模型相比，在没有使用额外数据的情况下，我们获得了最优的结果。', 'title_zh': '基于残差特征重利用的Inception网络图像分类模型'}
{'arxiv_id': 'arXiv:2412.19423', 'title': 'Revisiting PCA for time series reduction in temporal dimension', 'authors': 'Jiaxin Gao, Wenbo Hu, Yuntian Chen', 'link': 'https://arxiv.org/abs/2412.19423', 'abstract': 'Revisiting PCA for Time Series Reduction in Temporal Dimension; Jiaxin Gao, Wenbo Hu, Yuntian Chen; Deep learning has significantly advanced time series analysis (TSA), enabling the extraction of complex patterns for tasks like classification, forecasting, and regression. Although dimensionality reduction has traditionally focused on the variable space-achieving notable success in minimizing data redundancy and computational complexity-less attention has been paid to reducing the temporal dimension. In this study, we revisit Principal Component Analysis (PCA), a classical dimensionality reduction technique, to explore its utility in temporal dimension reduction for time series data. It is generally thought that applying PCA to the temporal dimension would disrupt temporal dependencies, leading to limited exploration in this area. However, our theoretical analysis and extensive experiments demonstrate that applying PCA to sliding series windows not only maintains model performance, but also enhances computational efficiency. In auto-regressive forecasting, the temporal structure is partially preserved through windowing, and PCA is applied within these windows to denoise the time series while retaining their statistical information. By preprocessing time-series data with PCA, we reduce the temporal dimensionality before feeding it into TSA models such as Linear, Transformer, CNN, and RNN architectures. This approach accelerates training and inference and reduces resource consumption. Notably, PCA improves Informer training and inference speed by up to 40% and decreases GPU memory usage of TimesNet by 30%, without sacrificing model accuracy. Comparative analysis against other reduction methods further highlights the effectiveness of PCA in improving the efficiency of TSA models.', 'abstract_zh': '重新审视时间序列降维中的PCA方法——时域维度的缩减；高嘉xin，胡文博，陈运天；深度学习显著推动了时间序列分析（TSA），使得复杂模式的提取成为分类、预测和回归等任务的基础。尽管维度缩减传统上主要集中在变量空间，实现了减少数据冗余和计算复杂度的显著成果，但在时间维度上的关注相对较少。本文中，我们重新审视了经典的降维技术主成分分析（PCA），探讨其在时间序列数据的时间维度缩减中的应用潜力。一般认为，对时间维度应用PCA会破坏时间依赖性，从而限制了这一领域的探索。然而，我们的理论分析和广泛实验表明，通过对滑动窗口中的时间序列应用PCA不仅可以保持模型性能，还能提高计算效率。在自回归预测中，通过窗口化部分保留了时间结构，并在这些窗口内应用PCA以在去噪的同时保留时间序列的统计信息。通过在TSA模型（如线性模型、Transformer、CNN和RNN架构）之前使用PCA预处理时间序列数据，我们减少了时间维度，并加快了培训和推理速度，降低了资源消耗。值得注意的是，PCA在提高Informer的训练和推理速度方面最多可提高40%，并在不牺牲模型准确性的前提下减少了TimesNet的GPU内存使用量30%。与其他降维方法的对比分析进一步突显了PCA在提高TSA模型效率方面的作用。', 'title_zh': '重新审视时间序列在时间维度上进行降维的主成分分析方法'}
{'arxiv_id': 'arXiv:2412.19422', 'title': 'Gx2Mol: De Novo Generation of Hit-like Molecules from Gene Expression Profiles via Deep Learning', 'authors': 'Chen Li, Yuki Matsukiyo, Yoshihiro Yamanishi', 'link': 'https://arxiv.org/abs/2412.19422', 'abstract': 'De novo generation of hit-like molecules is a challenging task in the drug discovery process. Most methods in previous studies learn the semantics and syntax of molecular structures by analyzing molecular graphs or simplified molecular input line entry system (SMILES) strings; however, they do not take into account the drug responses of the biological systems consisting of genes and proteins. In this study we propose a deep generative model, Gx2Mol, which utilizes gene expression profiles to generate molecular structures with desirable phenotypes for arbitrary target proteins. In the algorithm, a variational autoencoder is employed as a feature extractor to learn the latent feature distribution of the gene expression profiles. Then, a long short-term memory is leveraged as the chemical generator to produce syntactically valid SMILES strings that satisfy the feature conditions of the gene expression profile extracted by the feature extractor. Experimental results and case studies demonstrate that the proposed Gx2Mol model can produce new molecules with potential bioactivities and drug-like properties.', 'abstract_zh': '药物发现过程中从头生成类似命中分子是一项具有挑战性的任务。以往大多数方法通过分析分子图或简化分子输入线性输入系统（SMILES）字符串来学习分子结构的语义和语法；然而，这些方法并未考虑由基因和蛋白质组成的生物系统对药物的响应。在这项研究中，我们提出了一种深度生成模型Gx2Mol，该模型利用基因表达谱生成具有期望表型的目标蛋白质的分子结构。在算法中，我们采用变分自编码器作为特征提取器，学习基因表达谱的潜在特征分布。然后，利用长期记忆网络作为化学生成器，生成满足特征提取器提取的基因表达谱特征条件的语法正确的SMILES字符串。实验结果和案例研究证明，提出的Gx2Mol模型能够生成具有潜在生物活性和类药物性质的新分子。', 'title_zh': 'Gx2Mol：通过深度学习从基因表达谱生成类似hit的小分子'}
{'arxiv_id': 'arXiv:2412.19419', 'title': 'Introduction to Graph Neural Networks: A Starting Point for Machine Learning Engineers', 'authors': 'James H. Tanis, Chris Giannella, Adrian V. Mariano', 'link': 'https://arxiv.org/abs/2412.19419', 'abstract': 'Graph neural networks are deep neural networks designed for graphs with attributes attached to nodes or edges. The number of research papers in the literature concerning these models is growing rapidly due to their impressive performance on a broad range of tasks. This survey introduces graph neural networks through the encoder-decoder framework and provides examples of decoders for a range of graph analytic tasks. It uses theory and numerous experiments on homogeneous graphs to illustrate the behavior of graph neural networks for different training sizes and degrees of graph complexity.', 'abstract_zh': '图神经网络是专门为附带节点或边属性的图形设计的深度神经网络。由于这些模型在广泛任务上的出色表现，相关研究论文的数量在文献中正迅速增长。本文综述了图神经网络，并通过编码-解码框架进行介绍，提供了针对多种图分析任务的解码器实例。本文使用理论和大量关于同质图的实验结果，来说明图神经网络在不同训练规模和图形复杂度下的行为表现。', 'title_zh': '图神经网络简介：机器学习工程师的入门点'}
{'arxiv_id': 'arXiv:2412.19418', 'title': 'Generalized Uncertainty-Based Evidential Fusion with Hybrid Multi-Head Attention for Weak-Supervised Temporal Action Localization', 'authors': 'Yuanpeng He, Lijian Li, Tianxiang Zhan, Wenpin Jiao, Chi-Man Pun', 'link': 'https://arxiv.org/abs/2412.19418', 'abstract': 'Weakly supervised temporal action localization (WS-TAL) is a task of targeting at localizing complete action instances and categorizing them with video-level labels. Action-background ambiguity, primarily caused by background noise resulting from aggregation and intra-action variation, is a significant challenge for existing WS-TAL methods. In this paper, we introduce a hybrid multi-head attention (HMHA) module and generalized uncertainty-based evidential fusion (GUEF) module to address the problem. The proposed HMHA effectively enhances RGB and optical flow features by filtering redundant information and adjusting their feature distribution to better align with the WS-TAL task. Additionally, the proposed GUEF adaptively eliminates the interference of background noise by fusing snippet-level evidences to refine uncertainty measurement and select superior foreground feature information, which enables the model to concentrate on integral action instances to achieve better action localization and classification performance. Experimental results conducted on the THUMOS14 dataset demonstrate that our method outperforms state-of-the-art methods. Our code is available in \\url{this https URL}.', 'abstract_zh': '弱监督时间动作定位（WS-TAL）是一项旨在定位完整动作实例并使用视频级标签对其进行分类的任务。动作背景的模糊性，主要由聚合和动作内部变异性导致的背景噪声引起，是现有WS-TAL方法面临的一个重大挑战。在本文中，我们引入了一个混合多头注意（HMHA）模块和广义不确定性证据融合（GUEF）模块来解决这一问题。所提出的HMHA通过过滤冗余信息并调整特征分布，以更好地与WS-TAL任务对齐，从而有效提升RGB和光流特征。此外，所提出的GUEF通过融合片段级证据来适应性地消除背景噪声的干扰，从而细化不确定性测量并选择优质的前景特征信息，这使得模型能够集中于完整的动作实例，以实现更好的动作定位和分类性能。在THUMOS14数据集上的实验结果表明，我们的方法优于现有最先进的方法。我们的代码可在<此URL>获得。', 'title_zh': '基于广义不确定性推理的混合多头注意力弱监督时空动作定位证据融合方法'}
{'arxiv_id': 'arXiv:2412.19403', 'title': 'Fully Data-driven but Interpretable Human Behavioural Modelling with Differentiable Discrete Choice Model', 'authors': 'Fumiyasu Makinoshima, Tatsuya Mitomi, Fumiya Makihara, Eigo Segawa', 'link': 'https://arxiv.org/abs/2412.19403', 'abstract': 'Discrete choice models are essential for modelling various decision-making processes in human behaviour. However, the specification of these models has depended heavily on domain knowledge from experts, and the fully automated but interpretable modelling of complex human behaviours has been a long-standing challenge. In this paper, we introduce the differentiable discrete choice model (Diff-DCM), a fully data-driven method for the interpretable modelling, learning, prediction, and control of complex human behaviours, which is realised by differentiable programming. Solely from input features and choice outcomes without any prior knowledge, Diff-DCM can estimate interpretable closed-form utility functions that reproduce observed behaviours. Comprehensive experiments with both synthetic and real-world data demonstrate that Diff-DCM can be applied to various types of data and requires only a small amount of computational resources for the estimations, which can be completed within tens of seconds on a laptop without any accelerators. In these experiments, we also demonstrate that, using its differentiability, Diff-DCM can provide useful insights into human behaviours, such as an optimal intervention path for effective behavioural changes. This study provides a strong basis for the fully automated and reliable modelling, prediction, and control of human behaviours.', 'abstract_zh': '离散选择模型是建模人类行为中各种决策过程的基本工具。然而，这些模型的构建主要依赖于专家领域的先验知识，而对复杂人类行为的全自动且可解释建模一直是一个长期挑战。本文介绍了一种新的可解释建模、学习、预测和控制复杂人类行为的方法——可微离散选择模型（Differentiable Discrete Choice Model, Diff-DCM），该方法通过差分编程实现在没有先验知识的情况下，仅从输入特征和选择结果中估算出可解释的形式化效用函数，这些函数能够重现观察到的行为。通过使用合成和真实世界数据进行的全面实验表明，Diff-DCM 可以应用于各种类型的数据，并且只需少量的计算资源即可完成估计，这在没有加速器的情况下，使用笔记本电脑即可在数秒内完成。在这些实验中，我们还展示了通过其可微性质，Diff-DCM 可以提供对人类行为的有用见解，例如有效的干预路径以实现行为变化。本研究为全自动和可靠的建模、预测和控制人类行为提供了坚实的基础。', 'title_zh': '完全数据驱动且可解释的人类行为建模——基于可微分离散选择模型'}
{'arxiv_id': 'arXiv:2412.19396', 'title': 'Comparing Few to Rank Many: Active Human Preference Learning using Randomized Frank-Wolfe', 'authors': 'Kiran Koshy Thekumparampil, Gaurush Hiranandani, Kousha Kalantari, Shoham Sabach, Branislav Kveton', 'link': 'https://arxiv.org/abs/2412.19396', 'abstract': 'We study learning of human preferences from a limited comparison feedback. This task is ubiquitous in machine learning. Its applications such as reinforcement learning from human feedback, have been transformational. We formulate this problem as learning a Plackett-Luce model over a universe of $N$ choices from $K$-way comparison feedback, where typically $K \\ll N$. Our solution is the D-optimal design for the Plackett-Luce objective. The design defines a data logging policy that elicits comparison feedback for a small collection of optimally chosen points from all ${N \\choose K}$ feasible subsets. The main algorithmic challenge in this work is that even fast methods for solving D-optimal designs would have $O({N \\choose K})$ time complexity. To address this issue, we propose a randomized Frank-Wolfe (FW) algorithm that solves the linear maximization sub-problems in the FW method on randomly chosen variables. We analyze the algorithm, and evaluate it empirically on synthetic and open-source NLP datasets.', 'abstract_zh': '我们研究从有限的比较反馈中学习人类偏好。这一任务在机器学习中无处不在。其应用，如基于人类反馈的强化学习，已经产生了革命性的影响。我们将这一问题形式化为从包含 $N$ 个选项的集合中学习 Plackett-Luce 模型，但仅使用了 $K$-wise 比较反馈（通常 $K \\ll N$）。我们的解决方案是针对 Plackett-Luce 目标的 D-最优设计。该设计定义了一个数据记录策略，能够在所有 ${N \\choose K}$ 可行子集的优化选择点中获取比较反馈。在本工作中，主要的算法挑战在于，即使对于解决 D-最优设计的快速方法，其时间复杂度也是 $O({N \\choose K})$。为了解决这一问题，我们提出了一种随机化的 Frank-Wolfe (FW) 算法，在该算法中，在随机选择的变量上解决 FW 方法中的线性最大化子问题。我们分析了该算法，并在合成和开源 NLP 数据集上进行了实验评估。', 'title_zh': '将少数进行比较，以优选众多：使用随机Frank-Wolfe算法的主动人类偏好学习'}
{'arxiv_id': 'arXiv:2412.19394', 'title': 'An Engorgio Prompt Makes Large Language Model Babble on', 'authors': 'Jianshuo Dong, Ziyuan Zhang, Qingjie Zhang, Han Qiu, Tianwei Zhang, Hao Wang, Hewu Li, Qi Li, Chao Zhang, Ke Xu', 'link': 'https://arxiv.org/abs/2412.19394', 'abstract': "Auto-regressive large language models (LLMs) have yielded impressive performance in many real-world tasks. However, the new paradigm of these LLMs also exposes novel threats. In this paper, we explore their vulnerability to inference cost attacks, where a malicious user crafts Engorgio prompts to intentionally increase the computation cost and latency of the inference process. We design Engorgio, a novel methodology, to efficiently generate adversarial Engorgio prompts to affect the target LLM's service availability. Engorgio has the following two technical contributions. (1) We employ a parameterized distribution to track LLMs' prediction trajectory. (2) Targeting the auto-regressive nature of LLMs' inference process, we propose novel loss functions to stably suppress the appearance of the <EOS> token, whose occurrence will interrupt the LLM's generation process. We conduct extensive experiments on 13 open-sourced LLMs with parameters ranging from 125M to 30B. The results show that Engorgio prompts can successfully induce LLMs to generate abnormally long outputs (i.e., roughly 2-13$\\times$ longer to reach 90%+ of the output length limit) in a white-box scenario and our real-world experiment demonstrates Engergio's threat to LLM service with limited computing resources. The code is accessible at this https URL.", 'abstract_zh': '自回归大型语言模型（LLMs）在许多实际任务中展现了显著的性能。然而，这些LLMs的新范式也暴露出了新型威胁。本文探讨了它们在推理成本攻击下的脆弱性，其中恶意用户精心设计Engorgio提示，以故意增加推理过程的计算成本和延迟。我们设计了Engorgio这一新颖的方法论，以高效地生成对抗性Engorgio提示，影响目标LLM的服务可用性。Engorgio具有以下两个技术贡献：\n\n(1) 我们使用参数化的分布追踪LLMs的预测轨迹。\n(2) 针对LLMs推理过程的自回归性质，我们提出了新颖的损失函数，以稳定地抑制<EOS>标记的出现，该标记的出现会中断LLM的生成过程。\n\n我们在参数从125M到30B的13个开源LLMs上进行了广泛实验。结果表明，在白盒场景下，Engorgio提示可以成功诱导LLMs生成异常长的输出（即，约为原长度的2-13倍，以达到90%以上的输出长度限制）。我们的现实世界实验进一步证明了Engorgio对LLM服务的威胁，即使资源有限。代码可在此处访问：https://github.com/your-repo-name。\n\n请注意将`https://github.com/your-repo-name`替换为实际的代码库链接。', 'title_zh': '一个充血性的提示使大型语言模型胡言乱语'}
{'arxiv_id': 'arXiv:2412.19391', 'title': 'An In-Depth Analysis of Adversarial Discriminative Domain Adaptation for Digit Classification', 'authors': 'Eugene Choi, Julian Rodriguez, Edmund Young', 'link': 'https://arxiv.org/abs/2412.19391', 'abstract': "Domain adaptation is an active area of research driven by the growing demand for robust machine learning models that perform well on real-world data. Adversarial learning for deep neural networks (DNNs) has emerged as a promising approach to improving generalization ability, particularly for image classification. In this paper, we implement a specific adversarial learning technique known as Adversarial Discriminative Domain Adaptation (ADDA) and replicate digit classification experiments from the original ADDA paper. We extend their findings by examining a broader range of domain shifts and provide a detailed analysis of in-domain classification accuracy post-ADDA. Our results demonstrate that ADDA significantly improves accuracy across certain domain shifts with minimal impact on in-domain performance. Furthermore, we provide qualitative analysis and propose potential explanations for ADDA's limitations in less successful domain shifts. Code is at this https URL .", 'abstract_zh': '领域适应是研究中的一个活跃领域，受到对在真实世界数据上表现稳健的机器学习模型日益增长的需求驱动。深度神经网络（DNNs）的对抗学习已经作为一种有前景的方法，特别适用于图像分类，以提高泛化能力。本文中，我们实现了一种特定的对抗学习技术，即对抗判别领域适应（ADDA），并再现了原ADDA论文中的数字分类实验。我们通过考察更广泛的领域偏移范围，进一步扩展了他们的研究发现，并对ADDA处理后的领域内分类准确率进行了详细分析。我们的结果显示，ADDA在某些领域偏移情况下显著提高了准确性，并对领域内性能的影响最小。此外，我们提供了定性的分析，并提出了对ADDA在不那么成功的领域偏移情况下的局限性的可能解释。相关代码参见：https://github.com/...', 'title_zh': '针对数字分类的深入分析： adversarial 判别域适应方法'}
{'arxiv_id': 'arXiv:2412.19360', 'title': 'Improving the network traffic classification using the Packet Vision approach', 'authors': 'Rodrigo Moreira, Larissa Ferreira Rodrigues, Pedro Frosi Rosa, Flávio de Oliveira Silva', 'link': 'https://arxiv.org/abs/2412.19360', 'abstract': 'The network traffic classification allows improving the management, and the network services offer taking into account the kind of application. The future network architectures, mainly mobile networks, foresee intelligent mechanisms in their architectural frameworks to deliver application-aware network requirements. The potential of convolutional neural networks capabilities, widely exploited in several contexts, can be used in network traffic classification. Thus, it is necessary to develop methods based on the content of packets transforming it into a suitable input for CNN technologies. Hence, we implemented and evaluated the Packet Vision, a method capable of building images from packets raw-data, considering both header and payload. Our approach excels those found in state-of-the-art by delivering security and privacy by transforming the raw-data packet into images. Therefore, we built a dataset with four traffic classes evaluating the performance of three CNNs architectures: AlexNet, ResNet-18, and SqueezeNet. Experiments showcase the Packet Vision combined with CNNs applicability and suitability as a promising approach to deliver outstanding performance in classifying network traffic.', 'abstract_zh': '网络流量分类可以提高管理和网络服务的提供，考虑到应用程序的类型。未来网络架构，尤其是移动网络，其架构框架中预见到具备智能化机制的结构，以提供应用程序感知的网络需求。卷积神经网络（CNN）的能力在多个领域得到了广泛的应用，这些能力可以应用于网络流量分类。因此，有必要开发基于数据包内容的方法，将其转换为适合CNN技术的输入。因此，我们实现了并评估了Packet Vision方法，该方法能够从数据包原始数据构建图像，同时考虑了报头和负载。我们的方法在现有的先进方法中表现出色，通过将原始数据包转换为图像来提供安全性和隐私性。因此，我们构建了一个包含四个流量类别的数据集，评估了三种CNN架构（AlexNet、ResNet-18和SqueezeNet）的性能。实验展示了Packet Vision与CNN结合的适用性和适合性，作为在分类网络流量方面具有出色性能的有前途的方法。', 'title_zh': '使用Packet Vision方法改进网络流量分类'}
{'arxiv_id': 'arXiv:2412.19350', 'title': 'On the Expressiveness and Length Generalization of Selective State-Space Models on Regular Languages', 'authors': 'Aleksandar Terzić, Michael Hersche, Giacomo Camposampiero, Thomas Hofmann, Abu Sebastian, Abbas Rahimi', 'link': 'https://arxiv.org/abs/2412.19350', 'abstract': 'Selective state-space models (SSMs) are an emerging alternative to the Transformer, offering the unique advantage of parallel training and sequential inference. Although these models have shown promising performance on a variety of tasks, their formal expressiveness and length generalization properties remain underexplored. In this work, we provide insight into the workings of selective SSMs by analyzing their expressiveness and length generalization performance on regular language tasks, i.e., finite-state automaton (FSA) emulation. We address certain limitations of modern SSM-based architectures by introducing the Selective Dense State-Space Model (SD-SSM), the first selective SSM that exhibits perfect length generalization on a set of various regular language tasks using a single layer. It utilizes a dictionary of dense transition matrices, a softmax selection mechanism that creates a convex combination of dictionary matrices at each time step, and a readout consisting of layer normalization followed by a linear map. We then proceed to evaluate variants of diagonal selective SSMs by considering their empirical performance on commutative and non-commutative automata. We explain the experimental results with theoretical considerations. Our code is available at this https URL.', 'abstract_zh': '选择性状态空间模型（SSMs）是Transformer的一种新兴替代方案，具有并行训练和序列推理的独特优势。尽管这些模型在多种任务上展示了令人 promising 的性能，但它们的形式表达能力和长度泛化特性仍被很大程度上未被探索。在本文中，我们通过对有限状态自动机（FSA）仿真任务的研究，分析选择性SSMs的形式表达能力和长度泛化性能，从而提供了对选择性SSMs工作机制的见解。我们通过对有限状态自动机任务的深入研究，弥补了现代SSM架构的一些局限性，提出了选择性密集状态空间模型（SD-SSM），这是第一个能够在单一层中实现完美长度泛化的选择性SSM。SD-SSM利用了一组密集转换矩阵字典、在每个时间步生成矩阵凸组合的softmax选择机制，以及层规范化后的线性映射组成的读出层。随后，我们通过研究对换自动机和非对换自动机的经验性能，评估了对角选择性SSMs的变体。我们用理论考量来解释实验结果。我们的代码托管在以下链接：这个 https URL。', 'title_zh': '选择性状态空间模型在正规语言上的表征能力和长度泛化能力研究'}
{'arxiv_id': 'arXiv:2412.19346', 'title': 'Semi-Supervised Learning from Small Annotated Data and Large Unlabeled Data for Fine-grained PICO Entity Recognition', 'authors': 'Fangyi Chen, Gongbo Zhang, Yilu Fang, Yifan Peng, Chunhua Weng', 'link': 'https://arxiv.org/abs/2412.19346', 'abstract': 'Objective: Extracting PICO elements -- Participants, Intervention, Comparison, and Outcomes -- from clinical trial literature is essential for clinical evidence retrieval, appraisal, and synthesis. Existing approaches do not distinguish the attributes of PICO entities. This study aims to develop a named entity recognition (NER) model to extract PICO entities with fine granularities.\nMaterials and Methods: Using a corpus of 2,511 abstracts with PICO mentions from 4 public datasets, we developed a semi-supervised method to facilitate the training of a NER model, FinePICO, by combining limited annotated data of PICO entities and abundant unlabeled data. For evaluation, we divided the entire dataset into two subsets: a smaller group with annotations and a larger group without annotations. We then established the theoretical lower and upper performance bounds based on the performance of supervised learning models trained solely on the small, annotated subset and on the entire set with complete annotations, respectively. Finally, we evaluated FinePICO on both the smaller annotated subset and the larger, initially unannotated subset. We measured the performance of FinePICO using precision, recall, and F1.\nResults: Our method achieved precision/recall/F1 of 0.567/0.636/0.60, respectively, using a small set of annotated samples, outperforming the baseline model (F1: 0.437) by more than 16\\%. The model demonstrates generalizability to a different PICO framework and to another corpus, which consistently outperforms the benchmark in diverse experimental settings (p-value \\textless0.001).\nConclusion: This study contributes a generalizable and effective semi-supervised approach to named entity recognition leveraging large unlabeled data together with small, annotated data. It also initially supports fine-grained PICO extraction.', 'abstract_zh': '目的：从临床试验文献中提取目标研究问题中的参与者（Participants）、干预措施（Intervention）、对照（Comparison）和结果（Outcomes）（PICO元素）对于临床证据检索、评估和综合至关重要。现有方法无法区分PICO实体的属性。本研究旨在开发一种命名实体识别（NER）模型，以精细粒度提取PICO实体。\n\n材料与方法：我们使用包含2,511个带有PICO提及的摘要的4个公开数据集，开发了一种半监督方法，通过结合有限的PICO实体标注数据和丰富的未标注数据，以促进NER模型FinePICO的训练。评价时，我们将整个数据集分为两个子集：一个带有注释的小子集和一个未带有注释的大子集。然后，我们基于仅使用小的带注释子集和整个完成标注子集训练的监督学习模型的性能，建立了理论上的下界和上界性能范围。最后，我们在较小的带注释子集和较大的原始未注释子集上分别评估了FinePICO。我们使用精确度、召回率和F1值评估FinePICO的性能。\n\n结果：我们的方法使用少量标注样本实现了精确度/召回率/F1值分别为0.567/0.636/0.60，优于基线模型（F1: 0.437）的16%以上。该模型在不同PICO框架和另一个语料库上表现出良好的泛化能力，并在多种实验设置中表现出优于基准模型的结果（P值<0.001）。\n\n结论：本研究提供了一种利用大量未标注数据和少量标注数据相结合的可泛化且有效的半监督方法，以实现命名实体识别。同时，该方法首次支持精细粒度的PICO提取。', 'title_zh': '基于少量标注数据和大量未标注数据的半监督学习方法在细粒度PICO实体识别中的应用'}
{'arxiv_id': 'arXiv:2412.19340', 'title': 'A Reinforcement Learning-Based Task Mapping Method to Improve the Reliability of Clustered Manycores', 'authors': 'Fatemeh Hossein-Khani, Omid Akbari', 'link': 'https://arxiv.org/abs/2412.19340', 'abstract': 'The increasing scale of manycore systems poses significant challenges in managing reliability while meeting performance demands. Simultaneously, these systems become more susceptible to different aging mechanisms such as negative-bias temperature instability (NBTI), hot carrier injection (HCI), and thermal cycling (TC), as well as the electromigration (EM) phenomenon. In this paper, we propose a reinforcement learning (RL)-based task mapping method to improve the reliability of manycore systems considering the aforementioned aging mechanisms, which consists of three steps including bin packing, task-to-bin mapping, and task-to-core mapping. In the initial step, a density-based spatial application with noise (DBSCAN) clustering method is employed to compose some clusters (bins) based on the cores temperature. Then, the Q-learning algorithm is used for the two latter steps, to map the arrived task on a core such that the minimum thermal variation is occurred among all the bins. Compared to the state-of-the-art works, the proposed method is performed during runtime without requiring any parameter to be calculated offline. The effectiveness of the proposed technique is evaluated on 16, 32, and 64 cores systems using SPLASH2 and PARSEC benchmark suite applications. The results demonstrate up to 27% increase in the mean time to failure (MTTF) compared to the state-of-the-art task mapping techniques.', 'abstract_zh': '随着多核系统规模不断扩大，同时满足性能需求与管理可靠性之间提出了巨大挑战。同时，这些系统对不同的老化机制变得更加敏感，比如负偏置温度不稳定性（NBTI）、热载流子注入（HCI）、热循环（TC）以及电迁移（EM）现象。本文提出了一种基于强化学习（RL）的任务映射方法，以综合考虑上述老化机制来提高多核系统的可靠性。该方法包含三个步骤，分别为分区打包、任务到分区的映射和任务到核心的映射。初始步骤中，使用基于噪声的空间密度应用（DBSCAN）聚类方法，根据核心温度组成若干分区（bins）。随后，使用Q学习算法进行后续两步，将到达的任务映射到核心，以最小化所有分区中的热变化。与现有技术相比，提出的该方法在运行时执行，无需预先计算任何参数。利用SPLASH2和PARSEC基准套件应用程序，在16、32和64核心系统上评估了所提出技术的有效性。实验结果表明，该方法相比现有的任务映射技术可使平均故障间隔时间（MTTF）提高多达27%。', 'title_zh': '基于强化学习的任务映射方法以提高集群Manycore系统的可靠性'}
{'arxiv_id': 'arXiv:2412.19331', 'title': 'CALICO: Part-Focused Semantic Co-Segmentation with Large Vision-Language Models', 'authors': 'Kiet A. Nguyen, Adheesh Juvekar, Tianjiao Yu, Muntasir Wahed, Ismini Lourentzou', 'link': 'https://arxiv.org/abs/2412.19331', 'abstract': 'Recent advances in Large Vision-Language Models (LVLMs) have sparked significant progress in general-purpose vision tasks through visual instruction tuning. While some works have demonstrated the capability of LVLMs to generate segmentation masks that align phrases with natural language descriptions in a single image, they struggle with segmentation-grounded comparisons across multiple images, particularly at finer granularities such as object parts. In this paper, we introduce the new task of part-focused semantic co-segmentation, which seeks to identify and segment common and unique objects and parts across images. To address this task, we present CALICO, the first LVLM that can segment and reason over multiple masks across images, enabling object comparison based on their constituent parts. CALICO features two proposed components, a novel Correspondence Extraction Module, which captures semantic-rich information to identify part-level correspondences between objects, and a Correspondence Adaptation Module, which embeds this information into the LVLM to facilitate multi-image understanding in a parameter-efficient manner. To support training and evaluation, we curate MixedParts, a comprehensive multi-image segmentation dataset containing $\\sim$2.4M samples across $\\sim$44K images with diverse object and part categories. Experimental results show CALICO, finetuned on only 0.3% of its architecture, achieves robust performance in part-focused semantic co-segmentation.', 'abstract_zh': '近年来，大型视觉-语言模型（LVLMs）在通过视觉指令调优推动通用视觉任务方面取得了重要进展。尽管一些研究已经展示了LVLMs生成与自然语言描述对齐的分割掩码的能力，能够在单张图像中生成分割掩码，但它们在跨多张图片进行分割对比方面（尤其是对于更精细的粒度如对象部件）存在问题。在这篇论文中，我们提出了一个新的任务——部件聚焦语义共同分割，旨在识别并分割跨多张图像中的共同和独特的对象以及部件。为了解决这个任务，我们提出了CALICO，这是第一个能够跨多张图像进行分割并推理多个掩码的LVLM，从而基于对象的组成部分进行对象对比。CALICO 包含两个我们提出的组件：一种新的对应提取模块，该模块提取丰富的语义信息以识别对象之间的部件级对应关系；以及一种对应适应模块，该模块将这些信息嵌入到LVLM中，以在参数效率的条件下促进多张图像的理解。为了支持训练和评估，我们整理了MixedParts数据集，该数据集包含大约240万个样本，跨越约4.4万张图像，具有多样化的对象和部件类别。实验结果表明，仅在模型架构中微调0.3%的情况下，CALICO在部件聚焦语义共同分割中表现出强大的性能。', 'title_zh': 'CALICO：基于大規模视觉-语言模型的局部焦点语义共分割'}
{'arxiv_id': 'arXiv:2412.19325', 'title': 'Performance Control in Early Exiting to Deploy Large Models at the Same Cost of Smaller Ones', 'authors': 'Mehrnaz Mofakhami, Reza Bayat, Ioannis Mitliagkas, Joao Monteiro, Valentina Zantedeschi', 'link': 'https://arxiv.org/abs/2412.19325', 'abstract': "Early Exiting (EE) is a promising technique for speeding up inference by adaptively allocating compute resources to data points based on their difficulty. The approach enables predictions to exit at earlier layers for simpler samples while reserving more computation for challenging ones. In this study, we first present a novel perspective on the EE approach, showing that larger models deployed with EE can achieve higher performance than smaller models while maintaining similar computational costs. As existing EE approaches rely on confidence estimation at each exit point, we further study the impact of overconfidence on the controllability of the compute-performance trade-off. We introduce Performance Control Early Exiting (PCEE), a method that enables accuracy thresholding by basing decisions not on a data point's confidence but on the average accuracy of samples with similar confidence levels from a held-out validation set. In our experiments, we show that PCEE offers a simple yet computationally efficient approach that provides better control over performance than standard confidence-based approaches, and allows us to scale up model sizes to yield performance gain while reducing the computational cost.", 'abstract_zh': '早期退出（Early Exiting, EE）是一种有潜力的技术，可以通过根据数据点的难度适配性地分配计算资源来加速推理过程。该方法使得预测可以在较简单的样本上更早地在较早期的层中结束，而为更具挑战性的样本保留更多的计算资源。在本研究中，我们首先从一个新的角度阐述了EE方法，表明在EE下部署的较大模型可以实现比小型模型更高的性能，同时保持类似的计算成本。由于现有EE方法依赖于每个退出点的置信度估计，我们进一步研究了过度置信对计算-性能权衡可控性的影响。我们提出了性能控制早期退出（Performance Control Early Exiting, PCEE）方法，这是一种基于从保留集验证集中具有相似置信度水平样本的平均准确率，而不是基于单个数据点的置信度来做出决策的方法。在我们的实验中，我们展示了PCEE提供了一种简单且计算高效的策略，能够比基于传统置信度的方法更好地控制性能，并允许我们将模型规模扩大以获得性能提升的同时减少计算成本。', 'title_zh': '在早期退出以相同成本部署大型模型中的性能控制'}
{'arxiv_id': 'arXiv:2412.19312', 'title': 'From Interets to Insights: An LLM Approach to Course Recommendations Using Natural Language Queries', 'authors': 'Hugh Van Deventer, Mark Mills, August Evrard', 'link': 'https://arxiv.org/abs/2412.19312', 'abstract': "Most universities in the United States encourage their students to explore academic areas before declaring a major and to acquire academic breadth by satisfying a variety of requirements. Each term, students must choose among many thousands of offerings, spanning dozens of subject areas, a handful of courses to take. The curricular environment is also dynamic, and poor communication and search functions on campus can limit a student's ability to discover new courses of interest. To support both students and their advisers in such a setting, we explore a novel Large Language Model (LLM) course recommendation system that applies a Retrieval Augmented Generation (RAG) method to the corpus of course descriptions. The system first generates an 'ideal' course description based on the user's query. This description is converted into a search vector using embeddings, which is then used to find actual courses with similar content by comparing embedding similarities. We describe the method and assess the quality and fairness of some example prompts. Steps to deploy a pilot system on campus are discussed.", 'abstract_zh': '美国大多数大学鼓励学生在正式选定专业之前探索学术领域，并通过满足各种要求来获得学科广度。每一学期，学生都需要从数千门课程中选择若干门课程，这些课程涵盖几十个学科领域。课程结构环境是动态变化的，而校园内的不良沟通和搜索功能可能限制学生发现新课程的能力。为了在这样一个环境中支持学生及其导师，我们探讨了一种新颖的大型语言模型（LLM）课程推荐系统，该系统采用检索增强生成（RAG）方法对课程描述语料库进行处理。该系统首先根据用户的查询生成一个“理想”的课程描述。然后，将该描述转换为嵌入向量，通过比较嵌入相似度来查找具有类似内容的实际课程。我们描述了这种方法，并评估了一些示例提示的质量和公平性。还讨论了在校园中部署试点系统的步骤。', 'title_zh': '从兴趣到洞见：基于自然语言查询的LLM课程推荐方法'}
{'arxiv_id': 'arXiv:2412.19291', 'title': 'RAG with Differential Privacy', 'authors': 'Nicolas Grislain', 'link': 'https://arxiv.org/abs/2412.19291', 'abstract': 'Retrieval-Augmented Generation (RAG) has emerged as the dominant technique to provide *Large Language Models* (LLM) with fresh and relevant context, mitigating the risk of hallucinations and improving the overall quality of responses in environments with large and fast moving knowledge bases. However, the integration of external documents into the generation process raises significant privacy concerns. Indeed, when added to a prompt, it is not possible to guarantee a response will not inadvertently expose confidential data, leading to potential breaches of privacy and ethical dilemmas. This paper explores a practical solution to this problem suitable to general knowledge extraction from personal data. It shows *differentially private token generation* is a viable approach to private RAG.', 'abstract_zh': '检索增强生成（RAG）已成为提供大型语言模型（LLM）最新和相关上下文的主要技术，减轻了在大规模和快速变化的知识库环境中出现幻觉的风险，并提高了响应的整体质量。然而，将外部文档集成到生成过程中引发了重大的隐私问题。实际上，当将其添加到提示中时，无法保证不会无意间暴露敏感数据，从而可能导致隐私泄露和伦理困境。本文探讨了一种适用于个人数据通用知识提取的实用解决方案。它表明差异隐私的标记生成是一种可行的方法，用于保护隐私的RAG。', 'title_zh': '差分隐私下的RAG方法'}
{'arxiv_id': 'arXiv:2412.19289', 'title': 'ViPCap: Retrieval Text-Based Visual Prompts for Lightweight Image Captioning', 'authors': 'Taewhan Kim, Soeun Lee, Si-Woo Kim, Dong-Jin Kim', 'link': 'https://arxiv.org/abs/2412.19289', 'abstract': 'Recent lightweight image captioning models using retrieved data mainly focus on text prompts. However, previous works only utilize the retrieved text as text prompts, and the visual information relies only on the CLIP visual embedding. Because of this issue, there is a limitation that the image descriptions inherent in the prompt are not sufficiently reflected in the visual embedding space. To tackle this issue, we propose ViPCap, a novel retrieval text-based visual prompt for lightweight image captioning. ViPCap leverages the retrieved text with image information as visual prompts to enhance the ability of the model to capture relevant visual information. By mapping text prompts into the CLIP space and generating multiple randomized Gaussian distributions, our method leverages sampling to explore randomly augmented distributions and effectively retrieves the semantic features that contain image information. These retrieved features are integrated into the image and designated as the visual prompt, leading to performance improvements on the datasets such as COCO, Flickr30k, and NoCaps. Experimental results demonstrate that ViPCap significantly outperforms prior lightweight captioning models in efficiency and effectiveness, demonstrating the potential for a plug-and-play solution.', 'abstract_zh': '最近，使用检索数据的轻量级图像描述模型主要集中在文本提示上。然而，之前的works仅利用检索到的文本作为文本提示，而视觉信息仅依赖于CLIP视觉嵌入。由于这一问题，图像描述在提示中的内在视觉信息未能充分反映在视觉嵌入空间中。为解决这一问题，我们提出了一种新颖的检索文本基础视觉提示方法，称为ViPCap。ViPCap利用带有图像信息的检索文本作为视觉提示，以增强模型捕捉相关视觉信息的能力。通过将文本提示映射到CLIP空间并生成多个随机高斯分布，我们的方法利用采样来探索随机增强的分布，并有效地检索包含图像信息的语义特征。这些检索到的特征被整合到图像中，并指定为视觉提示，从而在COCO、Flickr30k和NoCaps等数据集上提高了性能。实验结果表明，ViPCap在效率和效果上显著优于现有的轻量级图像描述模型，展示了插拔式解决方案的潜力。', 'title_zh': 'ViPCap：基于检索文本视觉提示的轻量级图像 Captioning 方法'}
{'arxiv_id': 'arXiv:2412.19286', 'title': 'Time Series Foundational Models: Their Role in Anomaly Detection and Prediction', 'authors': 'Chathurangi Shyalika, Harleen Kaur Bagga, Ahan Bhatt, Renjith Prasad, Alaa Al Ghazo, Amit Sheth', 'link': 'https://arxiv.org/abs/2412.19286', 'abstract': 'Time series foundational models (TSFM) have gained prominence in time series forecasting, promising state-of-the-art performance across various applications. However, their application in anomaly detection and prediction remains underexplored, with growing concerns regarding their black-box nature, lack of interpretability and applicability. This paper critically evaluates the efficacy of TSFM in anomaly detection and prediction tasks. We systematically analyze TSFM across multiple datasets, including those characterized by the absence of discernible patterns, trends and seasonality. Our analysis shows that while TSFMs can be extended for anomaly detection and prediction, traditional statistical and deep learning models often match or outperform TSFM in these tasks. Additionally, TSFMs require high computational resources but fail to capture sequential dependencies effectively or improve performance in few-shot or zero-shot scenarios. \\noindent The preprocessed datasets, codes to reproduce the results and supplementary materials are available at this https URL.', 'abstract_zh': '时间序列基础模型（TSFM）在时间序列预测中已取得显著进展，展现出在多种应用中的先进性能。然而，TSFM 在异常检测和预测方面的应用尚未被充分探索，其黑箱性质、缺乏可解释性和适用性引起了广泛关注。本文全面评估了TSFM 在异常检测和预测任务中的有效性。我们系统地分析了TSFM 在多个数据集上的表现，包括那些缺乏明显模式、趋势和季节性的数据集。分析结果显示，虽然TSFM 可以扩展用于异常检测和预测，但传统统计和深度学习模型在这些任务中通常与TSFM 持平或表现更优。此外，TSFM 需要高计算资源，但在序列依赖性建模和少量或零样本场景中的性能改善并不明显。\n\n预处理数据集、可复现结果的代码及相关补充材料可在以下网址获取：[此链接]。', 'title_zh': '时间序列基础模型：其在异常检测和预测中的作用'}
{'arxiv_id': 'arXiv:2412.19284', 'title': 'PearSAN: A Machine Learning Method for Inverse Design using Pearson Correlated Surrogate Annealing', 'authors': 'Michael Bezick, Blake A. Wilson, Vaishnavi Iyer, Yuheng Chen, Vladimir M. Shalaev, Sabre Kais, Alexander V. Kildishev, Alexandra Boltasseva, Brad Lackey', 'link': 'https://arxiv.org/abs/2412.19284', 'abstract': 'PearSAN is a machine learning-assisted optimization algorithm applicable to inverse design problems with large design spaces, where traditional optimizers struggle. The algorithm leverages the latent space of a generative model for rapid sampling and employs a Pearson correlated surrogate model to predict the figure of merit of the true design metric. As a showcase example, PearSAN is applied to thermophotovoltaic (TPV) metasurface design by matching the working bands between a thermal radiator and a photovoltaic cell. PearSAN can work with any pretrained generative model with a discretized latent space, making it easy to integrate with VQ-VAEs and binary autoencoders. Its novel Pearson correlational loss can be used as both a latent regularization method, similar to batch and layer normalization, and as a surrogate training loss. We compare both to previous energy matching losses, which are shown to enforce poor regularization and performance, even with upgraded affine parameters. PearSAN achieves a state-of-the-art maximum design efficiency of 97%, and is at least an order of magnitude faster than previous methods, with an improved maximum figure-of-merit gain.', 'abstract_zh': 'PearSAN 是一种机器学习辅助优化算法，适用于具有大型设计空间的逆向设计问题，而传统优化器在这些问题中表现不佳。该算法利用生成模型的潜在空间进行快速采样，并采用皮尔逊相关近似模型来预测真实设计指标的优值。作为展示实例，PearSAN 应用于热电光伏 (TPV) 元表面设计，通过匹配热辐射器和光伏细胞的工作频带。PearSAN 可以与任何具有离散潜在空间的预训练生成模型结合使用，使其易于与 VQ-VAEs 和二元自编码器集成。其新颖的皮尔逊相关损失可以作为潜在正则化方法使用，类似于批量和层规范化，也可以作为近似模型训练损失使用。我们将其与先前的能量匹配损失进行了比较，后者即使在更新了仿射参数后也被证明效果不佳且正则化效果差。PearSAN 达到了最先进的设计效率 97%，并且比先前的方法快至少一个数量级，同时其最大优值增益也得到提升。', 'title_zh': 'PearSAN：一种基于皮尔逊相关代理模拟退火的逆向设计机器学习方法'}
{'arxiv_id': 'arXiv:2412.19260', 'title': 'MEDEC: A Benchmark for Medical Error Detection and Correction in Clinical Notes', 'authors': 'Asma Ben Abacha, Wen-wai Yim, Yujuan Fu, Zhaoyi Sun, Meliha Yetisgen, Fei Xia, Thomas Lin', 'link': 'https://arxiv.org/abs/2412.19260', 'abstract': 'Several studies showed that Large Language Models (LLMs) can answer medical questions correctly, even outperforming the average human score in some medical exams. However, to our knowledge, no study has been conducted to assess the ability of language models to validate existing or generated medical text for correctness and consistency. In this paper, we introduce MEDEC (this https URL), the first publicly available benchmark for medical error detection and correction in clinical notes, covering five types of errors (Diagnosis, Management, Treatment, Pharmacotherapy, and Causal Organism). MEDEC consists of 3,848 clinical texts, including 488 clinical notes from three US hospital systems that were not previously seen by any LLM. The dataset has been used for the MEDIQA-CORR shared task to evaluate seventeen participating systems [Ben Abacha et al., 2024]. In this paper, we describe the data creation methods and we evaluate recent LLMs (e.g., o1-preview, GPT-4, Claude 3.5 Sonnet, and Gemini 2.0 Flash) for the tasks of detecting and correcting medical errors requiring both medical knowledge and reasoning capabilities. We also conducted a comparative study where two medical doctors performed the same task on the MEDEC test set. The results showed that MEDEC is a sufficiently challenging benchmark to assess the ability of models to validate existing or generated notes and to correct medical errors. We also found that although recent LLMs have a good performance in error detection and correction, they are still outperformed by medical doctors in these tasks. We discuss the potential factors behind this gap, the insights from our experiments, the limitations of current evaluation metrics, and share potential pointers for future research.', 'abstract_zh': '以下是这篇论文内容或标题的中文翻译，符合学术规范：\n\n多项研究显示，大型语言模型（LLMs）能够正确回答医学问题，甚至在某些医学考试中还能超出普通人类的平均得分。然而，据我们所知，迄今为止还没有研究评估语言模型验证现有或生成的医学文本是否正确和一致的能力。在本文中，我们介绍了MEDEC（https://...），这是首个公开可用的临床笔记中医学错误检测与纠正基准，涵盖了五种类型的错误（诊断、管理、治疗、药疗和病因）。MEDEC 包含3,848份临床文本，其中488份来自三个未之前被任何LLM见过的美国医院系统。该数据集已被用于MEDIQA-CORR共享任务，评估了十七个参与系统的性能 [Ben Abacha等, 2024]。在本文中，我们描述了数据创建方法，并评估了近期的LLM（例如，o1-preview、GPT-4、Claude 3.5 Sonnet 和 Gemini 2.0 Flash）在检测和纠正需要医学知识和推理能力的医学错误方面的性能。我们还进行了一项对比研究，其中两名医学医生在MEDEC测试集上完成了相同任务。结果表明，MEDEC 是一个足够具有挑战性的基准，可以评估模型验证现有或生成的笔记以及纠正医学错误的能力。我们还发现，尽管近期的LLM在错误检测和纠正方面的表现良好，但在这些任务上仍不如医学医生。我们在本文中讨论了这种差距背后可能的因素、实验中的见解、当前评估指标的局限性，并分享了未来研究的潜在方向。', 'title_zh': 'MEDEC：临床笔记中医疗错误检测与修正的基准数据集'}
{'arxiv_id': 'arXiv:2412.19241', 'title': 'Latenrgy: Model Agnostic Latency and Energy Consumption Prediction for Binary Classifiers', 'authors': 'Jason M. Pittman', 'link': 'https://arxiv.org/abs/2412.19241', 'abstract': 'Machine learning systems increasingly drive innovation across scientific fields and industry, yet challenges in compute overhead, specifically during inference, limit their scalability and sustainability. Responsible AI guardrails, essential for ensuring fairness, transparency, and privacy, further exacerbate these computational demands. This study addresses critical gaps in the literature, chiefly the lack of generalized predictive techniques for latency and energy consumption, limited cross-comparisons of classifiers, and unquantified impacts of RAI guardrails on inference performance. Using Theory Construction Methodology, this work constructed a model-agnostic theoretical framework for predicting latency and energy consumption in binary classification models during inference. The framework synthesizes classifier characteristics, dataset properties, and RAI guardrails into a unified analytical instrument. Two predictive equations are derived that capture the interplay between these factors while offering generalizability across diverse classifiers. The proposed framework provides foundational insights for designing efficient, responsible ML systems. It enables researchers to benchmark and optimize inference performance and assists practitioners in deploying scalable solutions. Finally, this work establishes a theoretical foundation for balancing computational efficiency with ethical AI principles, paving the way for future empirical validation and broader applications.', 'abstract_zh': '机器学习系统在科学领域和工业中正不断推动创新，然而在推理过程中计算开销的挑战限制了其可扩展性和可持续性。负责任的人工智能护栏对于确保公平性、透明度和隐私性是必不可少的，但它们进一步增加了这些计算需求。本研究弥补了文献中的关键空白，主要是缺乏适用于延迟和能耗的通用预测技术、分类器之间的有限跨比较以及对负责的人工智能护栏对推理性能影响的未量化评估。通过理论构建方法论，这项工作构建了一个适用于二元分类模型推理过程中延迟和能耗预测的模型无关理论框架。该框架将分类器特性、数据集属性以及负责的人工智能护栏整合为一个统一的分析工具。推导出了两个预测方程来捕捉这些因素之间的相互作用，并在多样化的分类器中提供了一般性。所提出的框架为设计高效和负责任的机器学习系统提供了基础见解。它使研究人员能够进行基准测试和优化推理性能，并帮助从业者部署可扩展的解决方案。最后，这项工作为在计算效率与伦理人工智能原则之间取得平衡奠定了理论基础，为未来的实证验证和更广泛的应用铺平了道路。', 'title_zh': 'latency: 适用于二分类器的模型无关延迟和能耗预测'}
{'arxiv_id': 'arXiv:2412.19235', 'title': 'Are Two Hidden Layers Still Enough for the Physics-Informed Neural Networks?', 'authors': "Vasiliy A. Es'kin, Alexey O. Malkhanov, Mikhail E. Smorkalov", 'link': 'https://arxiv.org/abs/2412.19235', 'abstract': 'The article discusses the development of various methods and techniques for initializing and training neural networks with a single hidden layer, as well as training a separable physics-informed neural network consisting of neural networks with a single hidden layer to solve physical problems described by ordinary differential equations (ODEs) and partial differential equations (PDEs). A method for strictly deterministic initialization of a neural network with one hidden layer for solving physical problems described by an ODE is proposed. Modifications to existing methods for weighting the loss function are given, as well as new methods developed for training strictly deterministic-initialized neural networks to solve ODEs (detaching, additional weighting based on the second derivative, predicted solution-based weighting, relative residuals). An algorithm for physics-informed data-driven initialization of a neural network with one hidden layer is proposed. A neural network with pronounced generalizing properties is presented, whose generalizing abilities of which can be precisely controlled by adjusting network parameters. A metric for measuring the generalization of such neural network has been introduced. A gradient-free neuron-by-neuron fitting method has been developed for adjusting the parameters of a single-hidden-layer neural network, which does not require the use of an optimizer or solver for its implementation. The proposed methods have been extended to 2D problems using the separable physics-informed neural networks approach. Numerous experiments have been carried out to develop the above methods and approaches. Experiments on physical problems, such as solving various ODEs and PDEs, have demonstrated that these methods for initializing and training neural networks with one or two hidden layers (SPINN) achieve competitive accuracy and, in some cases, state-of-the-art results.', 'abstract_zh': '本文讨论了一种具有单隐藏层的神经网络的初始化和训练方法的发展，以及利用具有单隐藏层的神经网络训练可分的物理感知神经网络以解决由常微分方程（ODE）和偏微分方程（PDE）描述的物理问题。提出了一种严格确定性初始化具有单隐藏层的神经网络的方法，用于解决由ODE描述的物理问题。对现有方法中的权重损失函数进行了改进，并开发了新的方法来训练严格确定性初始化的神经网络以解决ODE（解耦、基于第二导数的附加加权、预测解基于的加权、相对残差）。提出了用于具有单隐藏层的神经网络的物理感知数据驱动初始化算法。展示了一种具有显著泛化能力的神经网络，其泛化能力可以通过调整网络参数来精细控制，并引入了一种衡量此类神经网络泛化能力的度量标准。开发了一种无需优化器或求解器即可实施的无梯度逐神经元调整方法，用于调整单隐藏层神经网络的参数。所提出的方法已被扩展到二维问题，采用分离的物理感知神经网络方法。进行了大量的实验以开发上述方法和方法。在解决各种ODE和PDE的物理问题的实验中，表明初始化和训练具有一个或两个隐藏层的神经网络的方法（SPINN）取得了竞争力的准确度，在某些情况下还达到了最先进的成果。', 'title_zh': '物理导向神经网络中是否仍需要两个隐藏层？'}
{'arxiv_id': 'arXiv:2412.19228', 'title': 'Learning Cross-Domain Representations for Transferable Drug Perturbations on Single-Cell Transcriptional Responses', 'authors': 'Hui Liu, Shikai Jin', 'link': 'https://arxiv.org/abs/2412.19228', 'abstract': 'Phenotypic drug discovery has attracted widespread attention because of its potential to identify bioactive molecules. Transcriptomic profiling provides a comprehensive reflection of phenotypic changes in cellular responses to external perturbations. In this paper, we propose XTransferCDR, a novel generative framework designed for feature decoupling and transferable representation learning across domains. Given a pair of perturbed expression profiles, our approach decouples the perturbation representations from basal states through domain separation encoders and then cross-transfers them in the latent space. The transferred representations are then used to reconstruct the corresponding perturbed expression profiles via a shared decoder. This cross-transfer constraint effectively promotes the learning of transferable drug perturbation representations. We conducted extensive evaluations of our model on multiple datasets, including single-cell transcriptional responses to drugs and single- and combinatorial genetic perturbations. The experimental results show that XTransferCDR achieved better performance than current state-of-the-art methods, showcasing its potential to advance phenotypic drug discovery.', 'abstract_zh': '表型药物发现由于其能够识别生物活性分子的潜力而备受关注。转录组谱型提供了一种全面反映细胞对外部扰动响应中表型变化的方法。本文提出了一种名为XTransferCDR的新型生成框架，该框架旨在实现跨领域特征解耦与转移表示学习。对于一对扰动表达谱型，我们的方法通过领域分离编码器将扰动表示从基本状态中解耦，然后在潜在空间中进行跨域转移。这些转移后的表示随后通过共享解码器重建相应的扰动表达谱型。这种跨域转移约束有效地促进了转移药物扰动表示的学习。我们在多个数据集上对模型进行了广泛的评估，包括单细胞对药物的转录响应以及单个和组合遗传扰动。实验结果表明，XTransferCDR的性能优于当前最先进的方法，展示了其在推进表型药物发现方面的潜力。', 'title_zh': '学习跨域表示以将可转移的药物干预措施应用于单细胞转录响应'}
{'arxiv_id': 'arXiv:2412.19226', 'title': 'VINEVI: A Virtualized Network Vision Architecture for Smart Monitoring of Heterogeneous Applications and Infrastructures', 'authors': 'Rodrigo Moreira, Hugo G. V. O. da Cunha, Larissa F. Rodrigues Moreira, Flávio de Oliveira Silva', 'link': 'https://arxiv.org/abs/2412.19226', 'abstract': 'Monitoring heterogeneous infrastructures and applications is essential to cope with user requirements properly, but it still lacks enhancements. The well-known state-of-the-art methods and tools do not support seamless monitoring of bare-metal, low-cost infrastructures, neither hosted nor virtualized services with fine-grained details. This work proposes VIrtualized NEtwork VIsion architecture (VINEVI), an intelligent method for seamless monitoring heterogeneous infrastructures and applications. The VINEVI architecture advances state of the art with a node-embedded traffic classification agent placing physical and virtualized infrastructures enabling real-time traffic classification. VINEVI combines this real-time traffic classification with well-known tools such as Prometheus and Victoria Metrics to monitor the entire stack from the hardware to the virtualized applications. Experimental results showcased that VINEVI architecture allowed seamless heterogeneous infrastructure monitoring with a higher level of detail beyond literature. Also, our node-embedded real-time Internet traffic classifier evolved with flexibility the methods with monitoring heterogeneous infrastructures seamlessly.', 'abstract_zh': '监控异构基础设施和应用程序对于满足用户需求至关重要，但仍然缺乏有效提升。当前广为认可的先进方法和工具并未支持无缝监控裸机和低成本基础设施，无论是宿主机上的服务还是虚拟化的服务，且缺乏细微的监控细节。本研究提出了一种名为VIrtualized NEtwork VIsion架构（VINEVI）的智能监控方法，该架构能够实现对异构基础设施和应用程序的无缝监控。VINEVI架构通过在节点内嵌入流量分类代理，实现对物理和虚拟化基础设施的实时流量分类，从而推进了现有技术的边界。VINEVI将实时流量分类与Prometheus和Victoria Metrics等已知工具结合，从而能够从硬件到虚拟化应用程序对整个栈进行监控。实验结果表明，VINEVI架构实现了更为细致的异构基础设施监控，超越了现有的文献水平。此外，我们内嵌节点的实时互联网流量分类器具有灵活性，能够使对异构基础设施的监控更加无缝。', 'title_zh': 'VINEVI：一种用于异构应用和基础设施智能监控的虚拟化网络愿景架构'}
{'arxiv_id': 'arXiv:2412.19194', 'title': 'Provably Efficient Exploration in Reward Machines with Low Regret', 'authors': 'Hippolyte Bourel, Anders Jonsson, Odalric-Ambrym Maillard, Chenxiao Ma, Mohammad Sadegh Talebi', 'link': 'https://arxiv.org/abs/2412.19194', 'abstract': 'We study reinforcement learning (RL) for decision processes with non-Markovian reward, in which high-level knowledge of the task in the form of reward machines is available to the learner. We consider probabilistic reward machines with initially unknown dynamics, and investigate RL under the average-reward criterion, where the learning performance is assessed through the notion of regret. Our main algorithmic contribution is a model-based RL algorithm for decision processes involving probabilistic reward machines that is capable of exploiting the structure induced by such machines. We further derive high-probability and non-asymptotic bounds on its regret and demonstrate the gain in terms of regret over existing algorithms that could be applied, but obliviously to the structure. We also present a regret lower bound for the studied setting. To the best of our knowledge, the proposed algorithm constitutes the first attempt to tailor and analyze regret specifically for RL with probabilistic reward machines.', 'abstract_zh': '我们研究了一类具有非马尔可夫奖励的决策过程中的强化学习（RL），在这种情况下，任务的高级知识以奖励机器的形式提供给学习者。我们考虑了初始动态未知的概率奖励机器，并在平均奖励准则下研究了RL算法，通过后悔的概念评估学习性能。我们主要的算法贡献是一种能够利用这些机器诱导结构的概率奖励机器决策过程中的模型基于RL算法。我们进一步推导了其后悔的高概率和非渐近界，并展示了相对于现有算法（但未利用这些结构）在后悔方面的优势。我们还为所研究的场景提出了后悔的下界。据我们所知，提出的算法是首次尝试针对概率奖励机器的RL定制和分析后悔的具体方法。', 'title_zh': '在奖励机器中具有低遗憾的可验证高效探索'}
{'arxiv_id': 'arXiv:2412.19191', 'title': 'Biology Instructions: A Dataset and Benchmark for Multi-Omics Sequence Understanding Capability of Large Language Models', 'authors': 'Haonan He, Yuchen Ren, Yining Tang, Ziyang Xu, Junxian Li, Minghao Yang, Di Zhang, Dong Yuan, Tao Chen, Shufei Zhang, Yuqiang Li, Nanqing Dong, Wanli Ouyang, Dongzhan Zhou, Peng Ye', 'link': 'https://arxiv.org/abs/2412.19191', 'abstract': 'Large language models have already demonstrated their formidable capabilities in general domains, ushering in a revolutionary transformation. However, exploring and exploiting the extensive knowledge of these models to comprehend multi-omics biology remains underexplored. To fill this research gap, we first introduce Biology-Instructions, the first large-scale multi-omics biological sequences-related instruction-tuning dataset including DNA, RNA, proteins, and multi-molecules, designed to bridge the gap between large language models (LLMs) and complex biological sequences-related tasks. This dataset can enhance the versatility of LLMs by integrating diverse biological sequenced-based prediction tasks with advanced reasoning capabilities, while maintaining conversational fluency. Additionally, we reveal significant performance limitations in even state-of-the-art LLMs on biological sequence-related multi-omics tasks without specialized pre-training and instruction-tuning. We further develop a strong baseline called ChatMultiOmics with a novel three-stage training pipeline, demonstrating the powerful ability to understand biology by using Biology-Instructions. Biology-Instructions and ChatMultiOmics are publicly available and crucial resources for enabling more effective integration of LLMs with multi-omics sequence analysis.', 'abstract_zh': '大型语言模型已经在通用领域展现了强大的能力，推动了一场革命性的变革。然而，探索和利用这些模型在多组学生物学中的广泛知识以进行理解和研究仍显不足。为了弥补这一研究空白，我们首先介绍了Biology-Instructions，这是首个大规模涉及多组学生物序列的指令调优数据集，包括DNA、RNA、蛋白质和多分子，旨在填补大型语言模型（LLMs）与复杂生物序列相关任务之间的差距。该数据集可以通过整合多种基于生物序列的预测任务和高级推理能力来增强LLMs的多功能性，同时保持会话流畅性。此外，我们揭示了即使是最先进的LLMs在没有专门预训练和指令调优的情况下，在多组学生物序列相关任务中也存在显著的性能限制。我们还开发了一个强大的基准模型，称为ChatMultiOmics，其采用了一种新颖的三阶段训练流程，展示了通过利用Biology-Instructions来理解生物学的强大能力。Biology-Instructions和ChatMultiOmics均已公开，并且是促进LLMs与多组学序列分析更好地集成的关键资源。', 'title_zh': '生物指令：一种多组学序列理解能力的数据集和基准较量'}
{'arxiv_id': 'arXiv:2412.19179', 'title': 'Mask Approximation Net: Merging Feature Extraction and Distribution Learning for Remote Sensing Change Captioning', 'authors': 'Dongwei Sun, Xiangyong Cao', 'link': 'https://arxiv.org/abs/2412.19179', 'abstract': 'Remote sensing image change description, as a novel multimodal task in the field of remote sensing processing, not only enables the detection of changes in surface conditions but also provides detailed descriptions of these changes, thereby enhancing human interpretability and interactivity. However, previous methods mainly employed Convolutional Neural Network (CNN) architectures to extract bitemporal image features. This approach often leads to an overemphasis on designing specific network architectures and limits the captured feature distributions to the current dataset, resulting in poor generalizability and robustness when applied to other datasets or real-world scenarios. To address these limitations, this paper proposes a novel approach for remote sensing image change detection and description that integrates diffusion models, aiming to shift the focus from conventional feature learning paradigms to data distribution learning. The proposed method primarily includes a simple multi-scale change detection module, whose output features are subsequently refined using a diffusion model. Additionally, we introduce a frequency-guided complex filter module to handle high-frequency noise during the diffusion process, which helps to maintain model performance. Finally, we validate the effectiveness of our proposed method on several remote sensing change detection description datasets, demonstrating its superior performance. The code available at MaskApproxNet.', 'abstract_zh': '遥感图像变化描述作为一种新的多模态任务，在遥感处理领域具有重要意义，不仅能够检测表面条件的变化，还能够提供详细的描述这些变化的方式，从而增强人类的可解释性和交互性。然而，以往的方法主要采用卷积神经网络（CNN）架构来提取双时相图像特征。这种做法往往导致过度关注特定网络架构的设计，限制了特征分布的捕获范围，使其在应用于其他数据集或现实场景时表现为较差的通用性和鲁棒性。为解决这些局限性，本文提出了一种新的遥感图像变化检测与描述方法，该方法整合了扩散模型，旨在从传统的特征学习范式转向数据分布学习。所提出的方法主要包括一个简单的多尺度变化检测模块，其输出特征随后通过扩散模型进行细化。此外，我们引入了一个基于频率的复杂滤波模块，在扩散过程中处理高频率噪声，有助于保持模型性能。最后，我们在多个遥感变化检测描述数据集上验证了所提方法的有效性，展示了其优越的性能。相关代码可在MaskApproxNet获得。', 'title_zh': '掩码近似网络：融合特征提取与分布学习的遥感变化检测'}
{'arxiv_id': 'arXiv:2412.19178', 'title': 'Reversed in Time: A Novel Temporal-Emphasized Benchmark for Cross-Modal Video-Text Retrieval', 'authors': 'Yang Du, Yuqi Liu, Qin Jin', 'link': 'https://arxiv.org/abs/2412.19178', 'abstract': 'Cross-modal (e.g. image-text, video-text) retrieval is an important task in information retrieval and multimodal vision-language understanding field. Temporal understanding makes video-text retrieval more challenging than image-text retrieval. However, we find that the widely used video-text benchmarks have shortcomings in comprehensively assessing abilities of models, especially in temporal understanding, causing large-scale image-text pre-trained models can already achieve comparable zero-shot performance with video-text pre-trained models. In this paper, we introduce RTime, a novel temporal-emphasized video-text retrieval dataset. We first obtain videos of actions or events with significant temporality, and then reverse these videos to create harder negative samples. We then recruit annotators to judge the significance and reversibility of candidate videos, and write captions for qualified videos. We further adopt GPT-4 to extend more captions based on human-written captions. Our RTime dataset currently consists of 21k videos with 10 captions per video, totalling about 122 hours. Based on RTime, we propose three retrieval benchmark tasks: RTime-Origin, RTime-Hard, and RTime-Binary. We further enhance the use of harder-negatives in model training, and benchmark a variety of video-text models on RTime. Extensive experiment analysis proves that RTime indeed poses new and higher challenges to video-text retrieval. We release our RTime dataset\\footnote{\\url{this https URL}} to further advance video-text retrieval and multimodal understanding research.', 'abstract_zh': '跨模态检索（例如图像-文本、视频-文本）是信息检索和多模态视觉语言理解领域的一项重要任务。时间理解使得视频-文本检索比图像-文本检索更具挑战性。然而，我们发现广泛使用的视频-文本基准数据集在全面评估模型能力方面存在不足，特别是在时间理解方面，导致大规模的图像-文本预训练模型已经在零样本性能上与视频-文本预训练模型相当。在本文中，我们引入了RTime，这是一个新的侧重于时间理解的视频-文本检索数据集。首先，我们获取了具有显著时间性的动作或事件视频，然后将其反转以创建更难的负样本。接着，我们招募注释者对候选视频的显著性和可逆性进行评判，并为合格的视频编写描述。进一步地，我们利用GPT-4在人类编写的描述基础上扩展更多描述。目前，RTime数据集包含21,000个视频，每个视频有10个描述，总计约122小时。基于RTime，我们提出了三个检索基准任务：RTime-Origin、RTime-Hard和RTime-Binary。我们进一步增强了在模型训练中使用更难的负样本，并在RTime上对多种视频-文本模型进行了基准测试。广泛的实验分析证明，RTime确实为视频-文本检索带来了新的更高挑战。我们发布了RTime数据集\\[1\\]，以进一步推动视频-文本检索和跨模态理解研究。\n\n\\[1\\] RTime数据集：[请填写具体的数据集网址]', 'title_zh': '逆向时间：一种新颖的时间强调基准方法，用于跨模态视频-文本检索'}
{'arxiv_id': 'arXiv:2412.19163', 'title': 'Master Stability Functions in Complex Networks', 'authors': 'Suman Acharyya, Priodyuti Pradhan, Chandrakala Meena', 'link': 'https://arxiv.org/abs/2412.19163', 'abstract': 'Synchronization is an emergent phenomenon in coupled dynamical networks. The Master Stability Function (MSF) is a highly elegant and powerful tool for characterizing the stability of synchronization states. However, a significant challenge lies in determining the MSF for complex dynamical networks driven by nonlinear interaction mechanisms. These mechanisms introduce additional complexity through the intricate connectivity of interacting elements within the network and the intrinsic dynamics, which are governed by nonlinear processes with diverse parameters and higher dimensionality of systems. Over the past 25 years, extensive research has focused on determining the MSF for pairwise coupled identical systems with diffusive coupling. Our literature survey highlights two significant advancements in recent years: the consideration of multilayer networks instead of single-layer networks and the extension of MSF analysis to incorporate higher-order interactions alongside pairwise interactions.\nIn this review article, we revisit the analysis of the MSF for diffusively pairwise coupled dynamical systems and extend this framework to more general coupling schemes. Furthermore, we systematically derive the MSF for multilayer dynamical networks and single-layer coupled systems by incorporating higher-order interactions alongside pairwise interactions. The primary focus of our review is on the analytical derivation and numerical computation of the MSF for complex dynamical networks. Finally, we demonstrate the application of the MSF in data science, emphasizing its relevance and potential in this rapidly evolving field.', 'abstract_zh': '同步是一种在耦合动力网络中涌现的现象。主稳定性函数（Master Stability Function，MSF）是一种高度优雅且强大的工具，用于表征同步状态的稳定性。然而，在由非线性相互作用机制驱动的复杂动力网络中确定MSF存在显著挑战。这些机制通过网络内相互作用元素的复杂连接和由非线性过程调控的内在动力引入额外的复杂性，这些过程具有多样化的参数和更高的系统维度。在过去25年里，大量研究集中于确定具有扩散耦合的成对耦合相同系统中的MSF。我们的文献综述强调了近年来的两项重要进展：考虑多层网络而非单层网络以及将MSF分析扩展到不仅包括成对相互作用，还纳入高级相互作用。\n\n在本文综述中，我们重新审视了扩散成对耦合动力系统中MSF的分析，并将这一框架扩展到更一般的耦合方案。此外，我们系统地推导出包含高级相互作用的MSF，不仅限于成对相互作用，以适用于多层动力网络和单层耦合系统。我们综述的主要重点在于复杂动力网络中MSF的分析推导和数值计算。最后，我们展示了MSF在数据科学中的应用，强调了其在这一快速发展的领域中的重要性和潜在价值。', 'title_zh': '复杂网络中的主稳定性函数'}
{'arxiv_id': 'arXiv:2412.19160', 'title': 'Dual Channel Multi-Attention in ViT for Biometric Authentication using Forehead Subcutaneous Vein Pattern and Periocular Pattern', 'authors': 'Arun K. Sharma, Shubhobrata Bhattacharya, Motahar Reza', 'link': 'https://arxiv.org/abs/2412.19160', 'abstract': 'Traditional biometric systems, like face and fingerprint recognition, have encountered significant setbacks due to wearing face masks and hygiene concerns. To meet the challenges of the partially covered face due to face masks and hygiene concerns of fingerprint recognition, this paper proposes a novel dual-channel multi-attention Vision Transformer (ViT) framework for biometric authentication using forehead subcutaneous vein patterns and periocular patterns, offering a promising alternative to traditional methods, capable of performing well even with face masks and without any physical touch. The proposed framework leverages a dual-channel ViT architecture, designed to handle two distinct biometric traits. It can capture long-range dependencies of independent features from the vein and periocular patterns. A custom classifier is then designed to integrate the independently extracted features, producing a final class prediction. The performance of the proposed algorithm was rigorously evaluated using the Forehead Subcutaneous Vein Pattern and Periocular Biometric Pattern (FSVP-PBP) database. The results demonstrated the superiority of the algorithm over state-of-the-art methods, achieving remarkable classification accuracy of $99.3 \\pm 0.02\\%$ with the combined vein and periocular patterns.', 'abstract_zh': '传统的生物特征识别系统，比如面部识别和指纹识别，在佩戴口罩和卫生担忧的情况下遇到了重大挑战。为了应对由于佩戴口罩导致的面部部分覆盖问题以及指纹识别中的卫生担忧，本文提出了一种全新的双通道多注意力视觉变换器（ViT）框架，用于基于前额皮下静脉模式和眼周模式的生物特征认证，提供了一种传统方法的有前途的替代方案，能够在佩戴口罩和无需物理接触的情况下取得良好性能。该提出的框架采用了一种双通道ViT架构，旨在处理两种不同的生物特征。它可以捕捉从静脉和眼周模式中独立特征的长程依赖关系。随后设计了一个自定义分类器，将独立提取的特征进行整合，生成最终的类别预测。使用前额皮下静脉模式和眼周生物特征模式数据库（FSVP-PBP数据库）对该提出算法进行了严格评价。结果显示，该算法在结合静脉和眼周模式的情况下，算法分类准确率为99.3 ± 0.02%，优于现有的先进方法。', 'title_zh': '用于前额皮下静脉模式和 periocular 图案的生物特征认证中基于 ViT 的双通道多注意力机制'}
{'arxiv_id': 'arXiv:2412.19159', 'title': 'Mobile Robots through Task-Based Human Instructions using Incremental Curriculum Learning', 'authors': 'Muhammad A. Muttaqien, Ayanori Yorozu, Akihisa Ohya', 'link': 'https://arxiv.org/abs/2412.19159', 'abstract': "This paper explores the integration of incremental curriculum learning (ICL) with deep reinforcement learning (DRL) techniques to facilitate mobile robot navigation through task-based human instruction. By adopting a curriculum that mirrors the progressive complexity encountered in human learning, our approach systematically enhances robots' ability to interpret and execute complex instructions over time. We explore the principles of DRL and its synergy with ICL, demonstrating how this combination not only improves training efficiency but also equips mobile robots with the generalization capability required for navigating through dynamic indoor environments. Empirical results indicate that robots trained with our ICL-enhanced DRL framework outperform those trained without curriculum learning, highlighting the benefits of structured learning progressions in robotic training.", 'abstract_zh': '本文探讨了将增量课程学习（Incremental Curriculum Learning, ICL）与深度强化学习（Deep Reinforcement Learning, DRL）技术结合，以通过任务导向的人类指令促进移动机器人导航。通过采用一个反映人类学习中逐渐增加复杂性的课程，我们的方法系统地增强了机器人随着时间推移解析和执行复杂指令的能力。我们研究了DRL的基本原理及其与ICL的协同作用，证明了这种组合不仅提高了训练效率，还为机器人提供了在动态室内环境中导航所需的一般化能力。实验证明，使用我们的ICL增强DRL框架进行训练的机器人在导航性能上优于未使用课程学习训练的机器人，突显了在机器人训练中结构化学习进程的重要性。', 'title_zh': '基于任务的人类指令通过增量课程学习引导的移动机器人控制'}
{'arxiv_id': 'arXiv:2412.19152', 'title': 'To Predict or Not To Predict? Proportionally Masked Autoencoders for Tabular Data Imputation', 'authors': 'Jungkyu Kim, Kibok Lee, Taeyoung Park', 'link': 'https://arxiv.org/abs/2412.19152', 'abstract': 'Masked autoencoders (MAEs) have recently demonstrated effectiveness in tabular data imputation. However, due to the inherent heterogeneity of tabular data, the uniform random masking strategy commonly used in MAEs can disrupt the distribution of missingness, leading to suboptimal performance. To address this, we propose a proportional masking strategy for MAEs. Specifically, we first compute the statistics of missingness based on the observed proportions in the dataset, and then generate masks that align with these statistics, ensuring that the distribution of missingness is preserved after masking. Furthermore, we argue that simple MLP-based token mixing offers competitive or often superior performance compared to attention mechanisms while being more computationally efficient, especially in the tabular domain with the inherent heterogeneity. Experimental results validate the effectiveness of the proposed proportional masking strategy across various missing data patterns in tabular datasets. Code is available at: \\url{this https URL}.', 'abstract_zh': '掩码自编码器（MAEs）最近在表格数据插补中显示出了有效性。然而，由于表格数据固有的异质性，MAEs中常用的均匀随机掩码策略可能会破坏缺失性的分布，导致性能不佳。为了解决这个问题，我们提出了一种比例掩码策略。具体而言，我们首先根据数据集中的观测比例计算缺失性的统计信息，然后生成与这些统计信息相匹配的掩码，从而确保掩码后缺失性的分布得以保留。此外，我们 argue 表示，基于简单的MLP的标记混合作出的性能与注意力机制相当甚至更优，尤其是在具有固有异质性的表格领域更为计算高效。实验结果验证了所提出的比例掩码策略在各种表格数据缺失模式下的有效性。相关代码可在以下链接获取：\\url{此网址}。', 'title_zh': '《预测还是不预测？比例掩码自动编码器在表格数据填充中的应用》'}
{'arxiv_id': 'arXiv:2412.19146', 'title': 'AskChart: Universal Chart Understanding through Textual Enhancement', 'authors': 'Xudong Yang, Yifan Wu, Yizhang Zhu, Nan Tang, Yuyu Luo', 'link': 'https://arxiv.org/abs/2412.19146', 'abstract': 'Chart understanding tasks such as ChartQA and Chart-to-Text involve automatically extracting and interpreting key information from charts, enabling users to query or convert visual data into structured formats. State-of-the-art approaches primarily focus on visual cues from chart images, failing to explicitly incorporate rich textual information (e.g., data labels and axis labels) embedded within the charts. This textual information is vital for intuitive human comprehension and interpretation of charts. Moreover, existing models are often large and computationally intensive, limiting their practical applicability. In this paper, we introduce AskChart, a universal model that explicitly integrates both textual and visual cues from charts using a Mixture of Experts (MoE) architecture. AskChart facilitates the learning of enhanced visual-textual representations of charts for effectively handling multiple chart understanding tasks, while maintaining a smaller model size. To capture the synergy between visual and textual modalities, we curate a large-scale dataset named ChartBank with about 7.5M data samples, which helps align textual and visual information and facilitates the extraction of visual entities and text. To effectively train AskChart, we design a three-stage training strategy to align visual and textual modalities for learning robust visual-textual representations and optimizing the learning of the MoE layer. Extensive experiments across five datasets demonstrate the significant performance gains of AskChart in four chart understanding tasks. Remarkably, AskChart with 4.6B parameters outperforms state-of-the-art models with 13B parameters by 68.3% in Open-ended ChartQA and 49.2% in Chart-to-Text tasks, while achieving comparable performance in ChartQA and Chart-to-Table tasks.', 'abstract_zh': '如下是根据学术规范的翻译：\n\n图表理解任务（如ChartQA和Chart-to-Text）涉及从图表中自动提取并解释关键信息，让用户能够查询或转换图表中的视觉数据为结构化格式。最先进的方法主要关注图表图像的视觉线索，而未能明确结合嵌入在图表中的丰富文本信息（如数据标签和轴标签）。这些文本信息对于直观的人类理解和解释图表至关重要。此外，现有的模型通常庞大且计算密集，限制了它们的实际应用。在本文中，我们引入了AskChart，这是一种利用专家混合模型（MoE架构）明确结合图表中的文本和视觉线索的通用模型。AskChart通过学习增强的视觉-文本表示，能够有效地处理多种图表理解任务，同时保持较小的模型尺寸。为了捕捉视觉模态和文本模态之间的协同作用，我们构建了一个包含约750万个数据样本的大规模数据集ChartBank，它有助于对齐文本和视觉信息，并促进视觉实体和文本的提取。为了有效训练AskChart，我们设计了一个三阶段训练策略，以对齐视觉和文本模态，学习 robust 的视觉-文本表示，并优化 MoE 层的学习。在五个数据集上进行的广泛实验表明，AskChart 在四种图表理解任务中的表现明显优于最先进的模型。特别地，具有46亿参数的AskChart在开放式ChartQA任务中比具有130亿参数的最先进的模型提高了68.3%，在Chart-to-Text任务中提高了49.2%，同时在ChartQA和Chart-to-Table任务中实现了相当好的性能。', 'title_zh': 'AskChart：通过文本增强实现通用图表理解'}
{'arxiv_id': 'arXiv:2412.19140', 'title': 'SILC-EFSA: Self-aware In-context Learning Correction for Entity-level Financial Sentiment Analysis', 'authors': 'Senbin Zhu, Chenyuan He, Hongde Liu, Pengcheng Dong, Hanjie Zhao, Yuchen Yan, Yuxiang Jia, Hongying Zan, Min Peng', 'link': 'https://arxiv.org/abs/2412.19140', 'abstract': 'In recent years, fine-grained sentiment analysis in finance has gained significant attention, but the scarcity of entity-level datasets remains a key challenge. To address this, we have constructed the largest English and Chinese financial entity-level sentiment analysis datasets to date. Building on this foundation, we propose a novel two-stage sentiment analysis approach called Self-aware In-context Learning Correction (SILC). The first stage involves fine-tuning a base large language model to generate pseudo-labeled data specific to our task. In the second stage, we train a correction model using a GNN-based example retriever, which is informed by the pseudo-labeled data. This two-stage strategy has allowed us to achieve state-of-the-art performance on the newly constructed datasets, advancing the field of financial sentiment analysis. In a case study, we demonstrate the enhanced practical utility of our data and methods in monitoring the cryptocurrency market. Our datasets and code are available at this https URL.', 'abstract_zh': '近年来，金融市场中的细粒度情感分析受到了广泛关注，但实体级数据集的稀缺性仍然是一个关键挑战。为解决这一问题，我们构建了迄今为止最大的英语和中文金融实体级情感分析数据集。在这一基础上，我们提出了一种新颖的两阶段情感分析方法，称为自我意识上下文学习修正（SILC）。第一阶段涉及对基础大语言模型进行微调，以生成特定于我们任务的伪标签数据。第二阶段，我们使用基于GNN的示例检索器训练修正模型，该模型受到伪标签数据的指导。这种两阶段策略使我们能够在新构建的数据集上达到最先进的性能，推动了金融情感分析领域的进展。在案例研究中，我们展示了我们的数据和方法在监测加密货币市场方面的增强实用价值。我们的数据集和代码可在此处访问：[该网址]。', 'title_zh': 'SILC-EFSA：自我意识的上下文内学习修正用于实体级金融情感分析'}
{'arxiv_id': 'arXiv:2412.19139', 'title': 'PlanLLM: Video Procedure Planning with Refinable Large Language Models', 'authors': 'Dejie Yang, Zijing Zhao, YangLiu', 'link': 'https://arxiv.org/abs/2412.19139', 'abstract': "Video procedure planning, i.e., planning a sequence of action steps given the video frames of start and goal states, is an essential ability for embodied AI. Recent works utilize Large Language Models (LLMs) to generate enriched action step description texts to guide action step decoding. Although LLMs are introduced, these methods decode the action steps into a closed-set of one-hot vectors, limiting the model's capability of generalizing to new steps or tasks. Additionally, fixed action step descriptions based on world-level commonsense may contain noise in specific instances of visual states. In this paper, we propose PlanLLM, a cross-modal joint learning framework with LLMs for video procedure planning. We propose an LLM-Enhanced Planning module which fully uses the generalization ability of LLMs to produce free-form planning output and to enhance action step decoding. We also propose Mutual Information Maximization module to connect world-level commonsense of step descriptions and sample-specific information of visual states, enabling LLMs to employ the reasoning ability to generate step sequences. With the assistance of LLMs, our method can both closed-set and open vocabulary procedure planning tasks. Our PlanLLM achieves superior performance on three benchmarks, demonstrating the effectiveness of our designs.", 'abstract_zh': '视频操作规划，即根据起始状态和目标状态的视频帧规划一系列操作步骤，是具身人工智能的一项基本能力。最近的研究利用大型语言模型（LLMs）生成丰富的操作步骤描述文本，以指导操作步骤解码。尽管引入了LLMs，但这些方法将操作步骤解码为封闭集合中的一个热向量，限制了模型泛化到新步骤或任务的能力。此外，基于世界级常识固定的操作步骤描述在特定的视觉状态示例中可能包含噪声。在本文中，我们提出了一种名为PlanLLM的跨模态联合学习框架，该框架利用LLMs进行视频操作规划。我们提出了一种增强的规划模块，该模块充分利用了LLMs的泛化能力，生成自由形式的规划输出，并增强操作步骤解码。我们还提出了信息互信息最大化模块，将步骤描述的世界级常识与视觉状态的特定样本信息连接起来，使LLMs能够利用推理能力生成步骤序列。借助LLMs的帮助，我们的方法可以同时完成封闭集和开放词汇的操作规划任务。我们的PlanLLM在三个基准测试中表现出色，证明了我们设计的有效性。', 'title_zh': 'PlanLLM：具有可细化大型语言模型的视频程序规划'}
{'arxiv_id': 'arXiv:2412.19133', 'title': 'A Rhetorical Relations-Based Framework for Tailored Multimedia Document Summarization', 'authors': 'Azze-Eddine Maredj, Madjid Sadallah', 'link': 'https://arxiv.org/abs/2412.19133', 'abstract': 'In the rapidly evolving landscape of digital content, the task of summarizing multimedia documents, which encompass textual, visual, and auditory elements, presents intricate challenges. These challenges include extracting pertinent information from diverse formats, maintaining the structural integrity and semantic coherence of the original content, and generating concise yet informative summaries. This paper introduces a novel framework for multimedia document summarization that capitalizes on the inherent structure of the document to craft coherent and succinct summaries. Central to this framework is the incorporation of a rhetorical structure for structural analysis, augmented by a graph-based representation to facilitate the extraction of pivotal information. Weighting algorithms are employed to assign significance values to document units, thereby enabling effective ranking and selection of relevant content. Furthermore, the framework is designed to accommodate user preferences and time constraints, ensuring the production of personalized and contextually relevant summaries. The summarization process is elaborately delineated, encompassing document specification, graph construction, unit weighting, and summary extraction, supported by illustrative examples and algorithmic elucidation. This proposed framework represents a significant advancement in automatic summarization, with broad potential applications across multimedia document processing, promising transformative impacts in the field.', 'abstract_zh': '在数字化内容迅速演进的背景下，多媒体文档摘要的任务——涵盖文本、视觉和听觉等多种元素——带来了复杂的挑战。这些挑战包括从不同格式中提取相关信息，保持原始内容的结构完整性和语义连贯性，并生成简明而富有信息性的摘要。本文提出了一种新颖的多媒体文档摘要框架，该框架利用文档本身的内在结构来构造连贯而简洁的摘要。该框架的核心在于引入基于论辩结构的结构性分析，并通过图表示法来促进关键信息的提取。权重算法被用于赋予文档单元不同的显著性值，从而实现有效的排名和相关内容的选择。此外，该框架设计考虑了用户偏好和时间限制，确保生成个性化且上下文相关的摘要。摘要生成过程进行了详尽的阐述，包括文档规定、图的构建、单元权重分配以及摘要提取，并通过示例和算法解释来支持这一过程。所提出的方法是自动摘要技术的重要进步，具有广泛的应用前景，将在多媒体文档处理领域带来革命性的变化。', 'title_zh': '基于修辞关系的定制化多媒体文档摘要框架'}
{'arxiv_id': 'arXiv:2412.19124', 'title': 'Evaluating Self-Supervised Learning in Medical Imaging: A Benchmark for Robustness, Generalizability, and Multi-Domain Impact', 'authors': 'Valay Bundele, Oğuz Ata Çal, Bora Kargi, Karahan Sarıtaş, Kıvanç Tezören, Zohreh Ghaderi, Hendrik Lensch', 'link': 'https://arxiv.org/abs/2412.19124', 'abstract': 'Self-supervised learning (SSL) has emerged as a promising paradigm in medical imaging, addressing the chronic challenge of limited labeled data in healthcare settings. While SSL has shown impressive results, existing studies in the medical domain are often limited in scope, focusing on specific datasets or modalities, or evaluating only isolated aspects of model performance. This fragmented evaluation approach poses a significant challenge, as models deployed in critical medical settings must not only achieve high accuracy but also demonstrate robust performance and generalizability across diverse datasets and varying conditions. To address this gap, we present a comprehensive evaluation of SSL methods within the medical domain, with a particular focus on robustness and generalizability. Using the MedMNIST dataset collection as a standardized benchmark, we evaluate 8 major SSL methods across 11 different medical datasets. Our study provides an in-depth analysis of model performance in both in-domain scenarios and the detection of out-of-distribution (OOD) samples, while exploring the effect of various initialization strategies, model architectures, and multi-domain pre-training. We further assess the generalizability of SSL methods through cross-dataset evaluations and the in-domain performance with varying label proportions (1%, 10%, and 100%) to simulate real-world scenarios with limited supervision. We hope this comprehensive benchmark helps practitioners and researchers make more informed decisions when applying SSL methods to medical applications.', 'abstract_zh': '自监督学习（SSL）已成为医疗成像领域的一个有前途的范式，用于解决医疗保健环境中标注数据不足这一长期难题。虽然SSL已经在多个任务上取得了令人印象深刻的结果，但现有的医疗领域研究往往局限于特定的数据集或模态，或者仅评估模型性能的个别方面。这种碎片化评估方法带来了重大挑战，因为在关键医疗场景中部署的模型不仅要达到高准确性，还需要在多种数据集和不同条件下表现出鲁棒性和泛化能力。为应对这一差距，我们提出了一项全面评估SSL方法在医疗领域的研究，特别关注其鲁棒性和泛化能力。我们使用MedMNIST数据集集合作为标准化基准，评估了8种主要的SSL方法在11个不同医疗数据集上的表现。我们的研究深入分析了模型在领域内场景和分布外（OOD）样本检测中的性能，同时探讨了不同的初始化策略、模型架构以及多领域预训练的影响。我们进一步通过跨数据集评估和不同标签比例（1%，10%，100%）领域的性能来评估SSL方法的泛化能力，以模拟有限监督下的现实世界场景。我们希望这一全面基准能够帮助从业者和研究人员在将SSL方法应用于医疗应用时做出更加明智的决策。', 'title_zh': '评估自主监督学习在医学成像中的表现：稳健性、通用性和多域影响基准测试'}
{'arxiv_id': 'arXiv:2412.19114', 'title': 'Discrete vs. Continuous Trade-offs for Generative Models', 'authors': 'Jathin Korrapati, Tanish Baranwal, Rahul Shah', 'link': 'https://arxiv.org/abs/2412.19114', 'abstract': "This work explores the theoretical and practical foundations of denoising diffusion probabilistic models (DDPMs) and score-based generative models, which leverage stochastic processes and Brownian motion to model complex data distributions. These models employ forward and reverse diffusion processes defined through stochastic differential equations (SDEs) to iteratively add and remove noise, enabling high-quality data generation. By analyzing the performance bounds of these models, we demonstrate how score estimation errors propagate through the reverse process and bound the total variation distance using discrete Girsanov transformations, Pinsker's inequality, and the data processing inequality (DPI) for an information theoretic lens.", 'abstract_zh': '本项研究探讨了去噪扩散概率模型（DDPMs）和基于分数的生成模型的理论与实践基础，这些模型通过随机过程和布朗运动来建模复杂的数据分布。这些模型利用基于随机微分方程（SDEs）定义的正向和反向扩散过程，逐步添加和去除噪声，从而实现高质量数据的生成。通过分析这些模型的性能上限，我们展示了评分估计误差如何在反向过程中传播，并使用离散的吉拉斯变换、申金不等式和信息论中的数据处理不等式（DPI）界定了总变差距离，从而从信息论的角度进行分析。', 'title_zh': '生成模型中离散与连续权衡的对比分析'}
{'arxiv_id': 'arXiv:2412.19108', 'title': 'Graph Mixture of Experts and Memory-augmented Routers for Multivariate Time Series Anomaly Detection', 'authors': 'Xiaoyu Huang, Weidong Chen, Bo Hu, Zhendong Mao', 'link': 'https://arxiv.org/abs/2412.19108', 'abstract': 'Multivariate time series (MTS) anomaly detection is a critical task that involves identifying abnormal patterns or events in data that consist of multiple interrelated time series. In order to better model the complex interdependence between entities and the various inherent characteristics of each entity, the GNN based methods are widely adopted by existing methods. In each layer of GNN, node features aggregate information from their neighboring nodes to update their information. In doing so, from shallow layer to deep layer in GNN, original individual node features continue to be weakened and more structural information,i.e., from short-distance neighborhood to long-distance neighborhood, continues to be enhanced. However, research to date has largely ignored the understanding of how hierarchical graph information is represented and their characteristics that can benefit anomaly detection. Existing methods simply leverage the output from the last layer of GNN for anomaly estimation while neglecting the essential information contained in the intermediate GNN layers. To address such limitations, in this paper, we propose a Graph Mixture of Experts (Graph-MoE) network for multivariate time series anomaly detection, which incorporates the mixture of experts (MoE) module to adaptively represent and integrate hierarchical multi-layer graph information into entity representations. It is worth noting that our Graph-MoE can be integrated into any GNN-based MTS anomaly detection method in a plug-and-play manner. In addition, the memory-augmented routers are proposed in this paper to capture the correlation temporal information in terms of the global historical features of MTS to adaptively weigh the obtained entity representations to achieve successful anomaly estimation. Extensive experiments on five challenging datasets prove the superiority of our approach and each proposed module.', 'abstract_zh': '基于图混合专家的多变量时间序列异常检测是一种关键任务，涉及在由多个相互关联的时间序列组成的数据中识别异常模式或事件。为了更好地建模实体之间的复杂相互依赖及其各自固有的多种特征，现有的方法广泛采用了基于图神经网络（GNN）的方法。在GNN的每一层中，节点特征会从其邻近节点汇总信息以更新自身信息。因此，在GNN从浅层到深层的过程中，原始个体节点特征会不断减弱，而更具结构的信息则会不断增强，即从短距离邻域到长距离邻域的信息会逐渐增强。然而，迄今为止的研究大多忽略了对如何表示层次化图信息及其能为异常检测提供帮助的特性进行理解。现有的方法仅利用GNN的最后一层输出用于异常估计，而忽视了中间层GNN中包含的重要信息。为了解决这些局限性，本文提出了一种基于图混合专家（Graph-MoE）的多变量时间序列异常检测网络，该网络通过混合专家模块（MoE）来适配性地表示并整合多层次图信息到实体表示中。值得注意的是，我们的Graph-MoE可以以即插即用的方式集成到任何基于GNN的多变量时间序列异常检测方法中。此外，本文还提出了增强记忆路由器，用于捕捉多变量时间序列全局历史特征中的时序相关性，以适应性地加权获得的实体表示以实现成功的异常检测。在五个具有挑战性的数据集上的广泛实验证明了我们方法及其每个提出模块的优越性。', 'title_zh': '图混合专家模型和记忆增强路由机制在多变量时间序列异常检测中的应用'}
{'arxiv_id': 'arXiv:2412.19043', 'title': 'Indonesian-English Code-Switching Speech Synthesizer Utilizing Multilingual STEN-TTS and Bert LID', 'authors': 'Ahmad Alfani Handoyo, Chung Tran, Dessi Puji Lestari, Sakriani Sakti', 'link': 'https://arxiv.org/abs/2412.19043', 'abstract': 'Multilingual text-to-speech systems convert text into speech across multiple languages. In many cases, text sentences may contain segments in different languages, a phenomenon known as code-switching. This is particularly common in Indonesia, especially between Indonesian and English. Despite its significance, no research has yet developed a multilingual TTS system capable of handling code-switching between these two languages. This study addresses Indonesian-English code-switching in STEN-TTS. Key modifications include adding a language identification component to the text-to-phoneme conversion using finetuned BERT for per-word language identification, as well as removing language embedding from the base model. Experimental results demonstrate that the code-switching model achieves superior naturalness and improved speech intelligibility compared to the Indonesian and English baseline STEN-TTS models.', 'abstract_zh': '多语言文本到语音系统能够跨多种语言将文本转换为语音。在很多情况下，文本句子中可能会包含不同语言的段落，这种现象被称为语言转换。特别是在印度尼西亚，印度尼西亚语和英语之间的语言转换尤其常见。尽管其重要性不言而喻，但目前还没有研究能够开发出处理这两种语言之间语言转换的多语言TTS系统。本研究针对STEN-TTS中的印度尼西亚语-英语语言转换问题进行了探索。关键修改包括在文本到音素转换中添加一个语言识别组件，使用微调后的BERT进行逐词语言识别，并移除基础模型中的语言嵌入。实验结果显示，语言转换模型相较于印度尼西亚语和英语的基础STEN-TTS模型，在自然度和语音可懂度方面均取得了更好的效果。', 'title_zh': '利用多语言STEN-TTS和Bert语言识别的印尼语-英语代码转换语音合成功器'}
{'arxiv_id': 'arXiv:2412.19037', 'title': 'CL-attack: Textual Backdoor Attacks via Cross-Lingual Triggers', 'authors': 'Jingyi Zheng, Tianyi Hu, Tianshuo Cong, Xinlei He', 'link': 'https://arxiv.org/abs/2412.19037', 'abstract': 'Backdoor attacks significantly compromise the security of large language models by triggering them to output specific and controlled content. Currently, triggers for textual backdoor attacks fall into two categories: fixed-token triggers and sentence-pattern triggers. However, the former are typically easy to identify and filter, while the latter, such as syntax and style, do not apply to all original samples and may lead to semantic shifts. In this paper, inspired by cross-lingual (CL) prompts of LLMs in real-world scenarios, we propose a higher-dimensional trigger method at the paragraph level, namely CL-attack. CL-attack injects the backdoor by using texts with specific structures that incorporate multiple languages, thereby offering greater stealthiness and universality compared to existing backdoor attack techniques. Extensive experiments on different tasks and model architectures demonstrate that CL-attack can achieve nearly 100% attack success rate with a low poisoning rate in both classification and generation tasks. We also empirically show that the CL-attack is more robust against current major defense methods compared to baseline backdoor attacks. Additionally, to mitigate CL-attack, we further develop a new defense called TranslateDefense, which can partially mitigate the impact of CL-attack.', 'abstract_zh': '背门攻击严重损害了大型语言模型的安全性，使其输出特定且受控的内容。当前，文本背门攻击的触发器主要分为两类：固定token触发器和句子模式触发器。然而，前者通常容易被识别和过滤，而后者，如语法和风格，不一定适用于所有原始样本，可能导致语义偏移。在本文中，受实时场景中大规模语言模型（LLM）跨语言（CL）提示的启发，我们提出了一种更高维度的段落级触发方法，称为CL-attack。CL-attack通过使用包含多种语言的具体结构文本注入背门，与现有背门攻击技术相比，提供了更高的隐秘性和通用性。在不同任务和模型架构上的大量实验表明，CL-attack可以在分类和生成任务中实现接近100%的攻击成功率，并且污染率较低。此外，我们实证研究表明，CL-attack相较于基线背门攻击更具鲁棒性，更能抵抗当前主要的防御方法。另外，为了减轻CL-attack的影响，我们还开发了一种新的防御方法，称为TranslateDefense，可以部分缓解CL-attack的影响。', 'title_zh': 'CL-攻击：多语言触发词的文本后门攻击'}
{'arxiv_id': 'arXiv:2412.19031', 'title': 'Repository Structure-Aware Training Makes SLMs Better Issue Resolver', 'authors': 'Zexiong Ma, Shengnan An, Zeqi Lin, Yanzhen Zou, Bing Xie', 'link': 'https://arxiv.org/abs/2412.19031', 'abstract': "Language models have been applied to various software development tasks, but the performance varies according to the scale of the models. Large Language Models (LLMs) outperform Small Language Models (SLMs) in complex tasks like repository-level issue resolving, but raise concerns about privacy and cost. In contrast, SLMs are more accessible but under-perform in complex tasks. In this paper, we introduce ReSAT (Repository Structure-Aware Training), construct training data based on a large number of issues and corresponding pull requests from open-source communities to enhance the model's understanding of repository structure and issue resolving ability. We construct two types of training data: (1) localization training data, a multi-level progressive localization data to improve code understanding and localization capability; (2) code edit training data, which improves context-based code editing capability. The evaluation results on SWE-Bench-verified and RepoQA demonstrate that ReSAT effectively enhances SLMs' issue-resolving and repository-level long-context understanding capabilities.", 'abstract_zh': '语言模型已在各种软件开发任务中得到应用，但其性能会根据模型规模的不同而有所差异。大规模语言模型（LLMs）在处理复杂任务（如仓库级问题解决）方面优于小规模语言模型（SLMs），但在隐私和成本方面引发了担忧。相比之下，SLMs 更为易获取，但在处理复杂任务时表现欠佳。本文介绍了 Repository Structure-Aware Training（仓库结构感知训练，简称 ReSAT），基于开源社区大量问题及其对应的拉取请求构建训练数据，以增强模型对仓库结构和问题解决能力的理解。我们构建了两种类型的训练数据：（1）定位训练数据，这是一种多层次渐进式定位数据，旨在提高代码理解和定位能力；（2）代码编辑训练数据，旨在增强基于上下文的代码编辑能力。SWE-Bench-验证和RepoQA的评估结果表明，ReSAT 能够有效提升SLMs的问题解决能力和仓库级别的长上下文理解能力。', 'title_zh': '面向存储库结构的训练使SLMs成为更好的问题解决者\n\n解释：\n- "Repository Structure-Aware Training" 译为“面向存储库结构的训练”，这是一个描述模型训练方法的术语，说明该训练方法考虑了存储库的结构特征。\n- "SLMs" 一般是特定领域或上下文中的缩写，根据上下文通常可以理解为“Stacked Layer Models”或其他具体模型的缩写。\n- "Better Issue Resolver" 译为“更好的问题解决者”，这表明经过这种训练方法训练的模型在解决代码仓库中问题方面表现更好。'}
{'arxiv_id': 'arXiv:2412.19026', 'title': 'Modality-Projection Universal Model for Comprehensive Full-Body Medical Imaging Segmentation', 'authors': 'Yixin Chen, Lin Gao, Yajuan Gao, Rui Wang, Jingge Lian, Xiangxi Meng, Yanhua Duan, Leiying Chai, Hongbin Han, Zhaoping Cheng, Zhaoheng Xie', 'link': 'https://arxiv.org/abs/2412.19026', 'abstract': "The integration of deep learning in medical imaging has shown great promise for enhancing diagnostic, therapeutic, and research outcomes. However, applying universal models across multiple modalities remains challenging due to the inherent variability in data characteristics. This study aims to introduce and evaluate a Modality Projection Universal Model (MPUM). MPUM employs a novel modality-projection strategy, which allows the model to dynamically adjust its parameters to optimize performance across different imaging modalities. The MPUM demonstrated superior accuracy in identifying anatomical structures, enabling precise quantification for improved clinical decision-making. It also identifies metabolic associations within the brain-body axis, advancing research on brain-body physiological correlations. Furthermore, MPUM's unique controller-based convolution layer enables visualization of saliency maps across all network layers, significantly enhancing the model's interpretability.", 'abstract_zh': '将深度学习集成到医学影像中展现了显著的潜力，可提升诊断、治疗和研究结果。然而，由于数据特征的内在差异，跨多种模态应用通用模型仍然具有挑战性。本研究旨在介绍和评估一种模态投影通用模型（Modality Projection Universal Model，MPUM）。MPUM 采用了一种新颖的模态投影策略，使模型能够动态调整其参数以优化不同成像模态的表现。MPUM 在识别解剖结构方面表现出卓越的准确性，能够精确量化，从而提高临床决策的质量。此外，MPUM 还识别了脑-体轴内的代谢关联，促进了对脑-体生理性相关性的研究。此外，MPUM 的独特基于控制器的卷积层能够跨所有网络层可视化重要性图，显著增强了模型的可解释性。', 'title_zh': '全面身体医学成像分割的模态投影通用模型'}
{'arxiv_id': 'arXiv:2412.19021', 'title': 'Relation-aware Hierarchical Prompt for Open-vocabulary Scene Graph Generation', 'authors': 'Tao Liu, Rongjie Li, Chongyu Wang, Xuming He', 'link': 'https://arxiv.org/abs/2412.19021', 'abstract': 'Open-vocabulary Scene Graph Generation (OV-SGG) overcomes the limitations of the closed-set assumption by aligning visual relationship representations with open-vocabulary textual representations. This enables the identification of novel visual relationships, making it applicable to real-world scenarios with diverse relationships. However, existing OV-SGG methods are constrained by fixed text representations, limiting diversity and accuracy in image-text alignment. To address these challenges, we propose the Relation-Aware Hierarchical Prompting (RAHP) framework, which enhances text representation by integrating subject-object and region-specific relation information. Our approach utilizes entity clustering to address the complexity of relation triplet categories, enabling the effective integration of subject-object information. Additionally, we utilize a large language model (LLM) to generate detailed region-aware prompts, capturing fine-grained visual interactions and improving alignment between visual and textual modalities. RAHP also introduces a dynamic selection mechanism within Vision-Language Models (VLMs), which adaptively selects relevant text prompts based on the visual content, reducing noise from irrelevant prompts. Extensive experiments on the Visual Genome and Open Images v6 datasets demonstrate that our framework consistently achieves state-of-the-art performance, demonstrating its effectiveness in addressing the challenges of open-vocabulary scene graph generation.', 'abstract_zh': '开放词汇场景图生成（OV-SGG）通过将视觉关系表示与开放词汇的文本表示对齐，克服了封闭集假设的限制，从而能够识别新型视觉关系，使该方法适用于包含多种关系的现实世界场景。然而，现有的OV-SGG方法受限于固定的文字表示，这限制了图像-文本对齐的多样性和准确性。为了解决这些挑战，我们提出了关系感知分层提示（RAHP）框架，通过整合主语-宾语和区域特定的关系信息来增强文字表示。我们的方法利用实体聚类处理关系三元组类别的复杂性，从而能够有效整合主语-宾语信息。此外，我们利用大型语言模型（LLM）生成详细的区域感知提示，捕获细微的视觉交互，从而提高视觉与文本模态之间的对齐。RAHP还在视觉语言模型（VLMs）中引入了动态选择机制，该机制根据视觉内容自适应地选择相关文字提示，减少无关提示的噪音。在Visual Genome和Open Images v6数据集上的大量实验表明，我们的框架始终能够达到最佳性能，证明了其在解决开放词汇场景图生成挑战方面的有效性。', 'title_zh': '基于关系的分级提示在开放词汇场景图生成中的应用'}
{'arxiv_id': 'arXiv:2412.19017', 'title': 'Brain Ageing Prediction using Isolation Forest Technique and Residual Neural Network (ResNet)', 'authors': 'Saadat Behzadi, Danial Sharifrazi, Roohallah Alizadehsani, Mojtaba Lotfaliany, Mohammadreza Mohebbi', 'link': 'https://arxiv.org/abs/2412.19017', 'abstract': 'Brain aging is a complex and dynamic process, leading to functional and structural changes in the brain. These changes could lead to the increased risk of neurodegenerative diseases and cognitive decline. Accurate brain-age estimation utilizing neuroimaging data has become necessary for detecting initial signs of neurodegeneration. Here, we propose a novel deep learning approach using the Residual Neural Network 101 Version 2 (ResNet101V2) model to predict brain age from MRI scans. To train, validate and test our proposed model, we used a large dataset of 2102 images which were selected randomly from the International Consortium for Brain Mapping (ICBM). Next, we applied data preprocessing techniques, including normalizing the images and using outlier detection via Isolation Forest method. Then, we evaluated various pre-trained approaches (namely: MobileNetV2, ResNet50V2, ResNet101V2, Xception). The results demonstrated that the ResNet101V2 model has higher performance compared with the other models, attaining MAEs of 0.9136 and 0.8242 years for before and after using Isolation Forest process. Our method achieved a high accuracy in brain age estimation in ICBM dataset and it provides a reliable brain age prediction.', 'abstract_zh': '大脑老化是一个复杂而动态的过程，会导致大脑的功能和结构发生变化。这些变化可能会增加神经退行性疾病和认知下降的风险。利用神经影像数据进行准确的大脑年龄估计已成为检测神经退化早期迹象的必要手段。在此，我们提出了一种新颖的深度学习方法，使用Residual Neural Network 101 Version 2（ResNet101V2）模型从MRI扫描中预测大脑年龄。为了训练、验证和测试我们提出的模型，我们使用了国际脑成像联盟（ICBM）提供的2102张随机选择的图像。随后，我们应用了数据预处理技术，包括标准化图像和通过Isolation Forest方法进行异常值检测。然后，我们评估了多种预训练方法（包括MobilenetV2、ResNet50V2、ResNet101V2和Xception）。结果表明，ResNet101V2模型的性能优于其他模型，在使用Isolation Forest过程前后分别达到了0.9136年和0.8242年的平均绝对误差（MAE）。我们的方法在ICBM数据集中实现了高精度的大脑年龄估计，并提供了一个可靠的脑年龄预测。', 'title_zh': '使用孤立森林技术和残差神经网络（ResNet）预测脑衰老'}
{'arxiv_id': 'arXiv:2412.19005', 'title': 'Enhancing Audiovisual Speech Recognition through Bifocal Preference Optimization', 'authors': 'Yihan Wu, Yichen Lu, Yifan Peng, Xihua Wang, Ruihua Song, Shinji Watanabe', 'link': 'https://arxiv.org/abs/2412.19005', 'abstract': 'Audiovisual Automatic Speech Recognition (AV-ASR) aims to improve speech recognition accuracy by leveraging visual signals. It is particularly challenging in unconstrained real-world scenarios across various domains due to noisy acoustic environments, spontaneous speech, and the uncertain use of visual information. Most previous works fine-tune audio-only ASR models on audiovisual datasets, optimizing them for conventional ASR objectives. However, they often neglect visual features and common errors in unconstrained video scenarios. In this paper, we propose using a preference optimization strategy to improve speech recognition accuracy for real-world videos. First, we create preference data via simulating common errors that occurred in AV-ASR from two focals: manipulating the audio or vision input and rewriting the output transcript. Second, we propose BPO-AVASR, a Bifocal Preference Optimization method to improve AV-ASR models by leveraging both input-side and output-side preference. Extensive experiments demonstrate that our approach significantly improves speech recognition accuracy across various domains, outperforming previous state-of-the-art models on real-world video speech recognition.', 'abstract_zh': '视听自动语音识别（AV-ASR）旨在通过利用视觉信号来提高语音识别的准确性。由于存在噪声的声学环境、自发的言语表达以及视觉信息的不确定使用，这种技术在各个领域的非受控实际场景中尤为具有挑战性。大多数先前的研究在视听数据集上微调仅依赖音频的ASR模型，并优化它们以实现传统ASR目标。然而，这些研究通常忽视了视听场景中的视觉特征以及常见的错误。在本文中，我们提出了一种偏好优化策略以提高非受控视频中的语音识别准确性。首先，我们通过模拟AV-ASR中发生的常见错误来创建偏好数据，主要从两个角度入手：修改音频或视觉输入及重写输出转录。其次，我们提出了一种双焦偏好优化方法（BPO-AVASR），通过结合输入侧和输出侧的偏好来改进AV-ASR模型。大量的实验表明，我们的方法在多个领域显著提高了语音识别准确性，并在实际视频语音识别方面优于以前的最先进模型。', 'title_zh': '通过双焦偏好优化增强音视频语音识别'}
{'arxiv_id': 'arXiv:2412.19002', 'title': 'Tempus Core: Area-Power Efficient Temporal-Unary Convolution Core for Low-Precision Edge DLAs', 'authors': 'Prabhu Vellaisamy, Harideep Nair, Thomas Kang, Yichen Ni, Haoyang Fan, Bin Qi, Jeff Chen, Shawn Blanton, John Paul Shen', 'link': 'https://arxiv.org/abs/2412.19002', 'abstract': "The increasing complexity of deep neural networks (DNNs) poses significant challenges for edge inference deployment due to resource and power constraints of edge devices. Recent works on unary-based matrix multiplication hardware aim to leverage data sparsity and low-precision values to enhance hardware efficiency. However, the adoption and integration of such unary hardware into commercial deep learning accelerators (DLA) remain limited due to processing element (PE) array dataflow differences. This work presents Tempus Core, a convolution core with highly scalable unary-based PE array comprising of tub (temporal-unary-binary) multipliers that seamlessly integrates with the NVDLA (NVIDIA's open-source DLA for accelerating CNNs) while maintaining dataflow compliance and boosting hardware efficiency. Analysis across various datapath granularities shows that for INT8 precision in 45nm CMOS, Tempus Core's PE cell unit (PCU) yields 59.3% and 15.3% reductions in area and power consumption, respectively, over NVDLA's CMAC unit. Considering a 16x16 PE array in Tempus Core, area and power improves by 75% and 62%, respectively, while delivering 5x and 4x iso-area throughput improvements for INT8 and INT4 precisions. Post-place and route analysis of Tempus Core's PCU shows that the 16x4 PE array for INT4 precision in 45nm CMOS requires only 0.017 mm^2 die area and consumes only 6.2mW of total power. We demonstrate that area-power efficient unary-based hardware can be seamlessly integrated into conventional DLAs, paving the path for efficient unary hardware for edge AI inference.", 'abstract_zh': '深度神经网络（DNNs）的日益复杂性给边缘推理部署带来了显著挑战，尤其是由于边缘设备的资源和能源限制。近期基于一元的矩阵乘法硬件的工作旨在通过利用数据稀疏性和低精度值来增强硬件效率。然而，将此类一元硬件与商业深度学习加速器（DLA）进行采用和集成仍然受到处理元素（PE）阵列数据流差异的限制。本文提出了Tempus Core，这是一种包含 tub（时域一元二进制）乘法器的一元基PE阵列可扩展的卷积核心，并且能够在保持数据流一致性的前提下无缝集成到NVDLA（NVIDIA开源的用于加速CNNs的DLA）中，同时提升硬件效率。在不同数据路径粒度的分析显示，对于45nm CMOS中的INT8精度，Tempus Core的PE单元（PCU）相较于NVDLA的CMAC单元在面积和功耗上分别减少59.3%和15.3%。考虑Tempus Core中16x16的PE阵列，其面积和功耗分别提高75%和62%，同时在INT8和INT4精度下分别提供5倍和4倍的等效面积吞吐量提升。对于45nm CMOS中INT4精度的16x4 PE阵列，后布局布线分析显示，该PCU仅需要0.017 mm²的芯片面积，并消耗6.2 mW的总功耗。我们证明了一元基硬件可以通过无缝集成到传统DLA中，为边缘AI推理提供高效的硬件基础。', 'title_zh': 'Tempus核心：低精度边缘DLA中的高效时序一元卷积核心'}
{'arxiv_id': 'arXiv:2412.18994', 'title': 'Geospatial Data Fusion: Combining Lidar, SAR, and Optical Imagery with AI for Enhanced Urban Mapping', 'authors': 'Sajjad Afroosheh, Mohammadreza Askari', 'link': 'https://arxiv.org/abs/2412.18994', 'abstract': 'This study explores the integration of Lidar, Synthetic Aperture Radar (SAR), and optical imagery through advanced artificial intelligence techniques for enhanced urban mapping. By fusing these diverse geospatial datasets, we aim to overcome the limitations associated with single-sensor data, achieving a more comprehensive representation of urban environments. The research employs Fully Convolutional Networks (FCNs) as the primary deep learning model for urban feature extraction, enabling precise pixel-wise classification of essential urban elements, including buildings, roads, and vegetation. To optimize the performance of the FCN model, we utilize Particle Swarm Optimization (PSO) for hyperparameter tuning, significantly enhancing model accuracy. Key findings indicate that the FCN-PSO model achieved a pixel accuracy of 92.3% and a mean Intersection over Union (IoU) of 87.6%, surpassing traditional single-sensor approaches. These results underscore the potential of fused geospatial data and AI-driven methodologies in urban mapping, providing valuable insights for urban planning and management. The implications of this research pave the way for future developments in real-time mapping and adaptive urban infrastructure planning.', 'abstract_zh': '本研究通过先进的人工智能技术，探讨了激光雷达（Lidar）、合成孔径雷达（SAR）和光学影像在城市测绘中的集成应用，旨在通过融合这些多源地理空间数据集，克服单一传感器数据的局限性，实现城市环境的更全面表示。研究采用全卷积网络（FCN）作为主要的深度学习模型，用于提取城市特征，实现对建筑物、道路和植被等关键城市元素的精确像素级分类。为了优化FCN模型的性能，我们利用粒子群优化（PSO）进行超参数调整，显著提高了模型的准确性。研究结果表明，FCN-PSO模型的像素准确率为92.3%，平均交集对并集比（IoU）为87.6%，超过了传统的单传感器方法。这些结果突显了融合地理空间数据和人工智能驱动方法在城市测绘中的潜力，为城市规划和管理提供了宝贵的见解。本研究的意义为实时地图制作和适应性城市基础设施规划的未来发展方向奠定了基础。', 'title_zh': '地理空间数据融合：结合lidar、SAR和光学影像的AI增强城市制图'}
{'arxiv_id': 'arXiv:2412.18989', 'title': 'How Propense Are Large Language Models at Producing Code Smells? A Benchmarking Study', 'authors': 'Alejandro Velasco, Daniel Rodriguez-Cardenas, David N. Palacio, Luftar Rahman Alif, Denys Poshyvanyk', 'link': 'https://arxiv.org/abs/2412.18989', 'abstract': 'Large Language Models (LLMs) have shown significant potential in automating software engineering tasks, particularly in code generation. However, current evaluation benchmarks, which primarily focus on accuracy, fall short in assessing the quality of the code generated by these models, specifically their tendency to produce code smells. To address this limitation, we introduce CodeSmellEval, a benchmark designed to evaluate the propensity of LLMs for generating code smells. Our benchmark includes a novel metric: Propensity Smelly Score (PSC), and a curated dataset of method-level code smells: CodeSmellData. To demonstrate the use of CodeSmellEval, we conducted a case study with two state-of-the-art LLMs, CodeLlama and Mistral. The results reveal that both models tend to generate code smells, such as simplifiable-condition and consider-merging-isinstance. These findings highlight the effectiveness of our benchmark in evaluating LLMs, providing valuable insights into their reliability and their propensity to introduce code smells in code generation tasks.', 'abstract_zh': '大型语言模型（LLMs）在自动化软件工程任务，特别是代码生成方面展现了显著的潜力。然而，当前主要基于准确性的评估基准在评估这些模型生成代码的质量时存在不足，尤其是它们生成代码异味的倾向。为解决这一局限性，我们引入了CodeSmellEval基准，旨在评估LLMs生成代码异味的倾向。该基准包括一个新颖的度量标准：代码异味倾向评分（PSC），以及一个精心收集的方法级代码异味数据集：CodeSmellData。为了展示CodeSmellEval的使用，我们对两种最先进的LLMs——CodeLlama和Mistral——进行了案例研究。结果显示，这两种模型都倾向于生成代码异味，如可简化条件和考虑合并(isinstance)等问题。这些发现突显了该基准在评估LLMs方面的有效性，提供了有关其可靠性和代码生成任务中引入代码异味倾向的重要见解。', 'title_zh': '大型语言模型生成代码异味的概率有多大？一项基准研究'}
{'arxiv_id': 'arXiv:2412.18975', 'title': 'Injecting Bias into Text Classification Models using Backdoor Attacks', 'authors': 'A. Dilara Yavuz, M. Emre Gursoy', 'link': 'https://arxiv.org/abs/2412.18975', 'abstract': "The rapid growth of natural language processing (NLP) and pre-trained language models have enabled accurate text classification in a variety of settings. However, text classification models are susceptible to backdoor attacks, where an attacker embeds a trigger into the victim model to make the model predict attacker-desired labels in targeted scenarios. In this paper, we propose to utilize backdoor attacks for a new purpose: bias injection. We develop a backdoor attack in which a subset of the training dataset is poisoned to associate strong male actors with negative sentiment. We execute our attack on two popular text classification datasets (IMDb and SST) and seven different models ranging from traditional Doc2Vec-based models to LSTM networks and modern transformer-based BERT and RoBERTa models. Our results show that the reduction in backdoored models' benign classification accuracy is limited, implying that our attacks remain stealthy, whereas the models successfully learn to associate strong male actors with negative sentiment (100% attack success rate with >= 3% poison rate). Attacks on BERT and RoBERTa are particularly more stealthy and effective, demonstrating an increased risk of using modern and larger models. We also measure the generalizability of our bias injection by proposing two metrics: (i) U-BBSR which uses previously unseen words when measuring attack success, and (ii) P-BBSR which measures attack success using paraphrased test samples. U-BBSR and P-BBSR results show that the bias injected by our attack can go beyond memorizing a trigger phrase.", 'abstract_zh': '自然语言处理（NLP）和预训练语言模型的迅速发展使得在各种情况下实现了准确的文本分类。然而，文本分类模型容易受到后门攻击，攻击者可以在受害模型中嵌入触发器，使模型在特定场景中预测攻击者期望的标签。本文提出了一种新的用途：利用后门攻击进行偏见注入。我们开发了一种后门攻击方法，通过污染训练数据集中的一部分，将强力男演员与负面情感联系起来。我们在两个流行的文本分类数据集（IMDb和SST）以及七种不同的模型（从传统的Doc2Vec模型到LSTM网络再到现代的Transformer模型BERT和RoBERTa）上执行了我们的攻击。实验结果显示，受污染模型的良性分类准确度下降有限，表明我们的攻击具有隐蔽性，而模型成功学会了将强力男演员与负面情感联系起来（在≥3% 污染率下，攻击成功率100%）。针对BERT和RoBERTa的攻击尤其隐蔽且有效，这表明使用现代和更大规模模型的风险增加。我们还通过提出两个指标来测量我们注入的偏见的一般性：（i）U-BBSR，该指标在评估攻击成功率时使用了之前未见过的词语，（ii）P-BBSR，该指标通过使用用同义词替换的测试样本来评估攻击成功率。U-BBSR和P-BBSR的结果表明，我们攻击注入的偏见超越了仅仅记住触发短语的范畴。', 'title_zh': '使用后门攻击向文本分类模型注入偏见'}
{'arxiv_id': 'arXiv:2412.18972', 'title': 'Recommending Pre-Trained Models for IoT Devices', 'authors': 'Parth V. Patil, Wenxin Jiang, Huiyun Peng, Daniel Lugo, Kelechi G. Kalu, Josh LeBlanc, Lawrence Smith, Hyeonwoo Heo, Nathanael Aou, James C. Davis', 'link': 'https://arxiv.org/abs/2412.18972', 'abstract': "The availability of pre-trained models (PTMs) has enabled faster deployment of machine learning across applications by reducing the need for extensive training. Techniques like quantization and distillation have further expanded PTM applicability to resource-constrained IoT hardware. Given the many PTM options for any given task, engineers often find it too costly to evaluate each model's suitability. Approaches such as LogME, LEEP, and ModelSpider help streamline model selection by estimating task relevance without exhaustive tuning. However, these methods largely leave hardware constraints as future work-a significant limitation in IoT settings. In this paper, we identify the limitations of current model recommendation approaches regarding hardware constraints and introduce a novel, hardware-aware method for PTM selection. We also propose a research agenda to guide the development of effective, hardware-conscious model recommendation systems for IoT applications.", 'abstract_zh': '预训练模型（PTMs）的可用性使得机器学习在各类应用中的部署速度更快，减少了对大量训练的需求。量化和蒸馏等技术进一步扩展了PTMs在资源受限的物联网（IoT）硬件中的应用范围。鉴于任何给定任务有许多可供选择的PTM，工程师常面临评估每个模型适用性的高成本问题。诸如LogME、LEEPl和ModelSpider等方法有助于通过估算任务相关性来简化模型选择过程，而无需进行详尽的调整。然而，这些方法大多将硬件约束作为未来的工作内容——在物联网环境中这是一个重要的局限。在本文中，我们识别了当前模型推荐方法在硬件约束方面的局限性，并介绍了一种新的、考虑硬件的PTM选择方法。我们还提出了一项研究议程，以指导开发有效的、具有硬件意识的模型推荐系统，为物联网应用奠定基础。', 'title_zh': '为物联网设备推荐预训练模型'}
{'arxiv_id': 'arXiv:2412.18966', 'title': 'ModelGrow: Continual Text-to-Video Pre-training with Model Expansion and Language Understanding Enhancement', 'authors': 'Zhefan Rao, Liya Ji, Yazhou Xing, Runtao Liu, Zhaoyang Liu, Jiaxin Xie, Ziqiao Peng, Yingqing He, Qifeng Chen', 'link': 'https://arxiv.org/abs/2412.18966', 'abstract': 'Text-to-video (T2V) generation has gained significant attention recently. However, the costs of training a T2V model from scratch remain persistently high, and there is considerable room for improving the generation performance, especially under limited computation resources. This work explores the continual general pre-training of text-to-video models, enabling the model to "grow" its abilities based on a pre-trained foundation, analogous to how humans acquire new knowledge based on past experiences. There is a lack of extensive study of the continual pre-training techniques in T2V generation. In this work, we take the initial step toward exploring this task systematically and propose ModelGrow. Specifically, we break this task into two key aspects: increasing model capacity and improving semantic understanding. For model capacity, we introduce several novel techniques to expand the model size, enabling it to store new knowledge and improve generation performance. For semantic understanding, we propose a method that leverages large language models as advanced text encoders, integrating them into T2V models to enhance language comprehension and guide generation results according to detailed prompts. This approach enables the model to achieve better semantic alignment, particularly in response to complex user prompts. Extensive experiments demonstrate the effectiveness of our method across various metrics. The source code and the model of ModelGrow will be publicly available.', 'abstract_zh': '文本到视频（T2V）生成近年来引起了广泛关注。然而，从头训练T2V模型的成本依然很高，并且在有限的计算资源下提高生成性能的空间仍然很大。本工作探索了T2V模型的持续通用预训练，使得模型能够在预训练基础上“生长”其能力，类似于人类基于过往经验获取新知识的方式。目前对于T2V生成任务中的持续预训练技术研究还不够广泛。在这项工作中，我们进行了系统性的初步探索，并提出了一种ModelGrow方法。具体来说，我们将这一任务分解为两个关键方面：增加模型容量和提高语义理解能力。对于模型容量，我们引入了几种创新技术来扩展模型规模，从而使模型能够存储新知识并提高生成性能。对于语义理解，我们提出了一种方法，利用大规模语言模型作为高级文本编码器，并将其集成到T2V模型中，以增强语言理解并根据详细的提示指导生成结果。这种方法使得模型在响应复杂用户提示时能够实现更好的语义对齐。广泛实验表明，我们的方法在各种度量标准上具有有效性。ModelGrow的源代码和模型将公开发布。', 'title_zh': 'ModelGrow：基于模型扩展与语言理解增强的持续文本到视频预训练'}
{'arxiv_id': 'arXiv:2412.18952', 'title': 'Bridging Interpretability and Robustness Using LIME-Guided Model Refinement', 'authors': 'Navid Nayyem, Abdullah Rakin, Longwei Wang', 'link': 'https://arxiv.org/abs/2412.18952', 'abstract': 'This paper explores the intricate relationship between interpretability and robustness in deep learning models. Despite their remarkable performance across various tasks, deep learning models often exhibit critical vulnerabilities, including susceptibility to adversarial attacks, over-reliance on spurious correlations, and a lack of transparency in their decision-making processes. To address these limitations, we propose a novel framework that leverages Local Interpretable Model-Agnostic Explanations (LIME) to systematically enhance model robustness. By identifying and mitigating the influence of irrelevant or misleading features, our approach iteratively refines the model, penalizing reliance on these features during training. Empirical evaluations on multiple benchmark datasets demonstrate that LIME-guided refinement not only improves interpretability but also significantly enhances resistance to adversarial perturbations and generalization to out-of-distribution data.', 'abstract_zh': '本文探讨了可解释性和鲁棒性在深度学习模型中的复杂关系。尽管深度学习模型在各类任务中表现出色，但也存在一些关键漏洞，包括对抗攻击的易感性、对虚假相关性的过度依赖以及决策过程的透明度不足。为了解决这些问题，我们提出了一种新的框架，该框架利用局部可解释通用解释方法（LIME）系统地提高模型的鲁棒性。通过识别并减轻无关或误导性特征的影响，我们的方法在训练过程中逐步精炼模型，惩罚对这些特征的依赖。在多个基准数据集上的实证评估表明，受LIME指导的精炼不仅改善了可解释性，还显著增强了对抗鲁棒性和对未知分布数据的泛化能力。', 'title_zh': '使用LIME引导的模型精细化方法桥接可解释性和鲁棒性'}
{'arxiv_id': 'arXiv:2412.18947', 'title': 'MedHallBench: A New Benchmark for Assessing Hallucination in Medical Large Language Models', 'authors': 'Kaiwen Zuo, Yirui Jiang', 'link': 'https://arxiv.org/abs/2412.18947', 'abstract': "Medical Large Language Models (MLLMs) have demonstrated potential in healthcare applications, yet their propensity for hallucinations -- generating medically implausible or inaccurate information -- presents substantial risks to patient care. This paper introduces MedHallBench, a comprehensive benchmark framework for evaluating and mitigating hallucinations in MLLMs. Our methodology integrates expert-validated medical case scenarios with established medical databases to create a robust evaluation dataset. The framework employs a sophisticated measurement system that combines automated ACHMI (Automatic Caption Hallucination Measurement in Medical Imaging) scoring with rigorous clinical expert evaluations and utilizes reinforcement learning methods to achieve automatic annotation. Through an optimized reinforcement learning from human feedback (RLHF) training pipeline specifically designed for medical applications, MedHallBench enables thorough evaluation of MLLMs across diverse clinical contexts while maintaining stringent accuracy standards. We conducted comparative experiments involving various models, utilizing the benchmark to establish a baseline for widely adopted large language models (LLMs). Our findings indicate that ACHMI provides a more nuanced understanding of the effects of hallucinations compared to traditional metrics, thereby highlighting its advantages in hallucination assessment. This research establishes a foundational framework for enhancing MLLMs' reliability in healthcare settings and presents actionable strategies for addressing the critical challenge of AI hallucinations in medical applications.", 'abstract_zh': '医学大型语言模型（MLLMs）在医疗应用中展现出潜在的前景，但它们生成医学上不合理或不准确信息（幻觉）的可能性给患者护理带来了重大风险。本文介绍了MedHallBench，这是一个全面的基准框架，用于评估和缓解MLLMs中的幻觉现象。我们的方法将经过专家验证的医学案例场景与现有的医学数据库相结合，创建了一个稳健的评估数据集。该框架采用了一种复杂的度量系统，该系统结合了自动医学影像幻觉测量（ACHMI：Automatic Caption Hallucination Measurement in Medical Imaging）评分和严格的临床专家评价，并利用强化学习方法实现自动标注。通过为医疗应用设计的优化强化学习从人类反馈中学习（RLHF）训练管道，MedHallBench能够在多种临床背景下全面评估MLLMs，同时保持严格的标准。我们进行了多种模型的比较实验，利用基准来建立广泛采用的大型语言模型（LLMs）的基线。我们的研究发现，ACHMI相比传统的度量标准更能提供幻觉影响的细微理解，从而突显了其在幻觉评估方面的优势。本研究奠定了在医疗环境中增强MLLMs可靠性的基础框架，并提出了应对医疗应用中AI幻觉这一关键挑战的可操作策略。', 'title_zh': 'MedHallBench: 一种评估医疗大型语言模型幻觉的新基准'}
{'arxiv_id': 'arXiv:2412.18946', 'title': 'Constraint-Adaptive Policy Switching for Offline Safe Reinforcement Learning', 'authors': 'Yassine Chemingui, Aryan Deshwal, Honghao Wei, Alan Fern, Janardhan Rao Doppa', 'link': 'https://arxiv.org/abs/2412.18946', 'abstract': 'Offline safe reinforcement learning (OSRL) involves learning a decision-making policy to maximize rewards from a fixed batch of training data to satisfy pre-defined safety constraints. However, adapting to varying safety constraints during deployment without retraining remains an under-explored challenge. To address this challenge, we introduce constraint-adaptive policy switching (CAPS), a wrapper framework around existing offline RL algorithms. During training, CAPS uses offline data to learn multiple policies with a shared representation that optimize different reward and cost trade-offs. During testing, CAPS switches between those policies by selecting at each state the policy that maximizes future rewards among those that satisfy the current cost constraint. Our experiments on 38 tasks from the DSRL benchmark demonstrate that CAPS consistently outperforms existing methods, establishing a strong wrapper-based baseline for OSRL. The code is publicly available at this https URL.', 'abstract_zh': 'Offline安全强化学习（OSRL）涉及从固定批次的训练数据中学习决策策略，以最大化奖励并满足预定义的安全约束。然而，在部署过程中适应不断变化的安全约束而不重新训练仍未得到充分探索。为应对这一挑战，我们引入了约束自适应策略切换（CAPS，Constraint-Adaptive Policy Switching），这是一种围绕现有离线强化学习算法的包装框架。在训练期间，CAPS 使用离线数据学习多个具有共享表示的不同奖励与成本折衷的策略。在测试期间，CAPS 通过在每个状态下选择满足当前成本约束且未来奖励最大的策略来进行策略切换。我们在DSRL基准上的38个任务上的实验表明，CAPS 在所有方法中表现更优，为OSRL 建立了一个强有力的基于包装框架的基准。代码已在此 [](https://github.com/alibaba/CAPS) 公开提供。', 'title_zh': '面向离线安全强化学习的约束自适应策略切换方法'}
{'arxiv_id': 'arXiv:2412.18926', 'title': 'Exemplar-condensed Federated Class-incremental Learning', 'authors': 'Rui Sun, Yumin Zhang, Varun Ojha, Tejal Shah, Haoran Duan, Bo Wei, Rajiv Ranjan', 'link': 'https://arxiv.org/abs/2412.18926', 'abstract': 'We propose Exemplar-Condensed federated class-incremental learning (ECoral) to distil the training characteristics of real images from streaming data into informative rehearsal exemplars. The proposed method eliminates the limitations of exemplar selection in replay-based approaches for mitigating catastrophic forgetting in federated continual learning (FCL). The limitations particularly related to the heterogeneity of information density of each summarized data. Our approach maintains the consistency of training gradients and the relationship to past tasks for the summarized exemplars to represent the streaming data compared to the original images effectively. Additionally, our approach reduces the information-level heterogeneity of the summarized data by inter-client sharing of the disentanglement generative model. Extensive experiments show that our ECoral outperforms several state-of-the-art methods and can be seamlessly integrated with many existing approaches to enhance performance.', 'abstract_zh': '我们提出了示例浓缩联邦分类增量学习（ECoral）方法，以从流式数据中提取真实图像的训练特征，并将其浓缩为具有信息性的复习示例。该方法消除了基于重放方法在减轻联邦连续学习（FCL）中灾难性遗忘时示例选择的局限性，尤其是在每个汇总数据的信息密度异质性方面。我们的方法保持了汇总示例的训练梯度一致性和与过去任务的关系，使得这些示例能够有效地代表流式数据，而不仅仅是原始图像。此外，我们的方法通过客户端间的稀解耦生成模型共享，减少了汇总数据的信息级异质性。 extensive实验表明，我们的ECoral方法在性能上优于多种现有方法，并且可以无缝集成到许多现有方法中以进一步提升性能。', 'title_zh': '示例凝练的联邦类增量学习'}
{'arxiv_id': 'arXiv:2412.18925', 'title': 'HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs', 'authors': 'Junying Chen, Zhenyang Cai, Ke Ji, Xidong Wang, Wanlong Liu, Rongsheng Wang, Jianye Hou, Benyou Wang', 'link': 'https://arxiv.org/abs/2412.18925', 'abstract': 'The breakthrough of OpenAI o1 highlights the potential of enhancing reasoning to improve LLM. Yet, most research in reasoning has focused on mathematical tasks, leaving domains like medicine underexplored. The medical domain, though distinct from mathematics, also demands robust reasoning to provide reliable answers, given the high standards of healthcare. However, verifying medical reasoning is challenging, unlike those in mathematics. To address this, we propose verifiable medical problems with a medical verifier to check the correctness of model outputs. This verifiable nature enables advancements in medical reasoning through a two-stage approach: (1) using the verifier to guide the search for a complex reasoning trajectory for fine-tuning LLMs, (2) applying reinforcement learning (RL) with verifier-based rewards to enhance complex reasoning further. Finally, we introduce HuatuoGPT-o1, a medical LLM capable of complex reasoning, which outperforms general and medical-specific baselines using only 40K verifiable problems. Experiments show complex reasoning improves medical problem-solving and benefits more from RL. We hope our approach inspires advancements in reasoning across medical and other specialized domains.', 'abstract_zh': 'OpenAI 的 o1 在推理方面的突破展示了增强推理以提升大语言模型（LLM）性能的潜力。然而，大多数关于推理的研究都集中在数学任务上，这也导致了医学等领域的研究较为欠缺。尽管医学领域与数学有所不同，但同样需要严谨的推理以提供可靠的答案，尤其是在医疗标准要求较高的情况下。然而，验证医学推理的难度远大于数学推理。为应对这一挑战，我们提出了一系列可验证的医学问题，并通过医学验证器检查模型输出的正确性。这种可验证性通过两阶段方法推动医学推理的进步：首先，利用验证器指导复杂推理路径的搜索，以微调 LLM；其次，通过基于验证器的奖励应用强化学习（RL）进一步提升复杂推理能力。最后，我们引入了 HuatuoGPT-o1，这是一种能够进行复杂推理的医学大语言模型，在仅使用 40,000 个可验证问题的情况下，表现优于通用和医学特定的基线模型。实验结果表明，复杂推理在医学问题解决中表现出色，并且更受益于 RL 方法。我们希望这种方法能够激励其他医学及专业领域的推理研究进步。', 'title_zh': 'huatuogpt-o1：基于大规模语言模型的医学复杂推理研究'}
{'arxiv_id': 'arXiv:2412.18917', 'title': 'Open-Vocabulary Panoptic Segmentation Using BERT Pre-Training of Vision-Language Multiway Transformer Model', 'authors': 'Yi-Chia Chen, Wei-Hua Li, Chu-Song Chen', 'link': 'https://arxiv.org/abs/2412.18917', 'abstract': 'Open-vocabulary panoptic segmentation remains a challenging problem. One of the biggest difficulties lies in training models to generalize to an unlimited number of classes using limited categorized training data. Recent popular methods involve large-scale vision-language pre-trained foundation models, such as CLIP. In this paper, we propose OMTSeg for open-vocabulary segmentation using another large-scale vision-language pre-trained model called BEiT-3 and leveraging the cross-modal attention between visual and linguistic features in BEiT-3 to achieve better performance. Experiments result demonstrates that OMTSeg performs favorably against state-of-the-art models.', 'abstract_zh': '开放词汇的全景分割仍然是一个具有挑战性的问题。其中最大的困难在于使用有限的分类训练数据训练模型以泛化到无限数量的类别。近年来，流行的 方法涉及大规模的视觉-语言预训练基础模型，如CLIP。在本文中，我们提出了一种名为OMTSeg的框架，利用另一个大规模的视觉-语言预训练模型BEiT-3，并通过BEiT-3中视觉和语言特征的跨模态注意力实现更好的性能。实验结果表明，OMTSeg在与最先进的模型相比时表现优异。', 'title_zh': '使用Vision-Language多方式变换模型的BERT预训练实现开放词汇语义分割'}
{'arxiv_id': 'arXiv:2412.18911', 'title': 'Accelerating Diffusion Transformers with Dual Feature Caching', 'authors': 'Chang Zou, Evelyn Zhang, Runlin Guo, Haohang Xu, Conghui He, Xuming Hu, Linfeng Zhang', 'link': 'https://arxiv.org/abs/2412.18911', 'abstract': 'Diffusion Transformers (DiT) have become the dominant methods in image and video generation yet still suffer substantial computational costs. As an effective approach for DiT acceleration, feature caching methods are designed to cache the features of DiT in previous timesteps and reuse them in the next timesteps, allowing us to skip the computation in the next timesteps. However, on the one hand, aggressively reusing all the features cached in previous timesteps leads to a severe drop in generation quality. On the other hand, conservatively caching only the features in the redundant layers or tokens but still computing the important ones successfully preserves the generation quality but results in reductions in acceleration ratios. Observing such a tradeoff between generation quality and acceleration performance, this paper begins by quantitatively studying the accumulated error from cached features. Surprisingly, we find that aggressive caching does not introduce significantly more caching errors in the caching step, and the conservative feature caching can fix the error introduced by aggressive caching. Thereby, we propose a dual caching strategy that adopts aggressive and conservative caching iteratively, leading to significant acceleration and high generation quality at the same time. Besides, we further introduce a V-caching strategy for token-wise conservative caching, which is compatible with flash attention and requires no training and calibration data.\nOur codes have been released in Github: \\textbf{Code: \\href{this https URL}{\\texttt{\\textcolor{cyan}{this https URL}}}}', 'abstract_zh': '扩散变换器（DiT）已成为图像和视频生成的主导方法，但仍面临显著的计算成本问题。作为DiT加速的有效方法，特征缓存技术被设计为缓存DiT在先前时间步的特征，并在后续时间步重用这些特征，从而允许我们跳过后续时间步的计算。然而，一方面，过度重复使用所有缓存在先前时间步的特征会导致生成质量急剧下降；另一方面，保守地仅缓存冗余层或标记的重要特征，但仍计算重要的特征，可以保持生成质量，但会导致加速比的下降。鉴于生成质量和加速性能之间的这种权衡，本文首先定量研究了缓存特征累积的误差。令人惊讶的是，我们发现过度缓存并不会显著增加缓存步骤中的缓存错误，而保守缓存可以修复由过度缓存引入的错误。因此，我们提出了一种递归采用激进和保守缓存策略的方法，既能显著加速，又能保持高质量的生成。此外，我们进一步引入了一种V-缓存策略，该策略在标记粒度上实现了保守缓存，与闪存注意力兼容，并且不需要训练和校准数据。\n\n我们的代码已发布在GitHub上：**Code: [this https URL]**\n\n这样翻译符合学术规范，并保留了原文的技术细节和创新点。', 'title_zh': '加速扩散变换器的双重特征缓存方法'}
{'arxiv_id': 'arXiv:2412.18894', 'title': 'Comprehensive Study on Lumbar Disc Segmentation Techniques Using MRI Data', 'authors': 'Serkan Salturk, Irem Sayin, Ibrahim Cem Balci, Taha Emre Pamukcu, Zafer Soydan, Huseyin Uvet', 'link': 'https://arxiv.org/abs/2412.18894', 'abstract': 'Lumbar disk segmentation is essential for diagnosing and curing spinal disorders by enabling precise detection of disk boundaries in medical imaging. The advent of deep learning has resulted in the development of many segmentation methods, offering differing levels of accuracy and effectiveness. This study assesses the effectiveness of several sophisticated deep learning architectures, including ResUnext, Ef3 Net, UNet, and TransUNet, for lumbar disk segmentation, highlighting key metrics like as Pixel Accuracy, Mean Intersection over Union (Mean IoU), and Dice Coefficient. The findings indicate that ResUnext achieved the highest segmentation accuracy, with a Pixel Accuracy of 0.9492 and a Dice Coefficient of 0.8425, with TransUNet following closely after. Filtering techniques somewhat enhanced the performance of most models, particularly Dense UNet, improving stability and segmentation quality. The findings underscore the efficacy of these models in lumbar disk segmentation and highlight potential areas for improvement.', 'abstract_zh': '腰椎间盘分割对于诊断和治疗脊柱疾病至关重要，因为它能通过医学影像精确检测间盘边界。深度学习的兴起推动了多种分割方法的发展，这些方法在准确性和有效性方面有所不同。本研究评估了几种高级深度学习架构（包括ResUnext、Ef3Net、UNet和TransUNet）在腰椎间盘分割中的效果，重点关注了像素准确率（Pixel Accuracy）、平均交并比（Mean Intersection over Union，Mean IoU）和Dice系数等关键指标。研究结果显示，ResUnext实现了最高的分割准确性，其像素准确率为0.9492，Dice系数为0.8425，而TransUNet紧随其后。滤波技术在大多数模型中提高了性能，特别是在Dense UNet中表现出显著效果，提升了模型的稳定性和分割质量。研究结果强调了这些模型在腰椎间盘分割中的有效性，并指出了可能的改进领域。', 'title_zh': '利用MRI数据的腰椎间盘分割技术综述研究'}
{'arxiv_id': 'arXiv:2412.18874', 'title': 'IUST_PersonReId: A New Domain in Person Re-Identification Datasets', 'authors': 'Alireza Sedighi Moghaddam, Fatemeh Anvari, Mohammadjavad Mirshekari Haghighi, Mohammadali Fakhari, Mohammad Reza Mohammadi', 'link': 'https://arxiv.org/abs/2412.18874', 'abstract': "Person re-identification (ReID) models often struggle to generalize across diverse cultural contexts, particularly in Islamic regions like Iran, where modest clothing styles are prevalent. Existing datasets predominantly feature Western and East Asian fashion, limiting their applicability in these settings. To address this gap, we introduce IUST_PersonReId, a dataset designed to reflect the unique challenges of ReID in new cultural environments, emphasizing modest attire and diverse scenarios from Iran, including markets, campuses, and mosques. Experiments on IUST_PersonReId with state-of-the-art models, such as Solider and CLIP-ReID, reveal significant performance drops compared to benchmarks like Market1501 and MSMT17, highlighting the challenges posed by occlusion and limited distinctive features. Sequence-based evaluations show improvements by leveraging temporal context, emphasizing the dataset's potential for advancing culturally sensitive and robust ReID systems. IUST_PersonReId offers a critical resource for addressing fairness and bias in ReID research globally. The dataset is publicly available at this https URL.", 'abstract_zh': '跨文化环境中，特别是伊朗等以保守服饰风格为主的地区，人员重识别（ReID）模型往往难以泛化。现有数据集主要以西方和东亚时尚为主，限制了其在这些环境中的应用。为解决这一问题，我们引入了IUST_PersonReId数据集，该数据集旨在反映在新文化环境中人员重识别的独特挑战，重点关注伊朗地区的保守服饰和多样场景，包括市场、校园和清真寺等。使用当前领先的模型（如Solider和CLIP-ReID）在IUST_PersonReId上的实验结果显示，其性能显著低于以Market1501和MSMT17为代表的基准数据集，这强调了遮挡和有限的显著特征带来的挑战。序列分析表明，利用时间上下文可以提高性能，突显了该数据集在促进文化敏感性和鲁棒性ReID系统方面的重要潜力。IUST_PersonReId提供了全球范围内解决ReID研究中的公平性和偏见问题的关键资源。该数据集已公开，访问链接如下：[该 https URL](https://)。', 'title_zh': 'IUST_PersonReId：一种新的人员重识别数据集领域'}
{'arxiv_id': 'arXiv:2412.18863', 'title': 'Whose Morality Do They Speak? Unraveling Cultural Bias in Multilingual Language Models', 'authors': 'Meltem Aksoy', 'link': 'https://arxiv.org/abs/2412.18863', 'abstract': "Large language models (LLMs) have become integral tools in diverse domains, yet their moral reasoning capabilities across cultural and linguistic contexts remain underexplored. This study investigates whether multilingual LLMs, such as GPT-3.5-Turbo, GPT-4o-mini, Llama 3.1, and MistralNeMo, reflect culturally specific moral values or impose dominant moral norms, particularly those rooted in English. Using the updated Moral Foundations Questionnaire (MFQ-2) in eight languages, Arabic, Farsi, English, Spanish, Japanese, Chinese, French, and Russian, the study analyzes the models' adherence to six core moral foundations: care, equality, proportionality, loyalty, authority, and purity. The results reveal significant cultural and linguistic variability, challenging the assumption of universal moral consistency in LLMs. Although some models demonstrate adaptability to diverse contexts, others exhibit biases influenced by the composition of the training data. These findings underscore the need for culturally inclusive model development to improve fairness and trust in multilingual AI systems.", 'abstract_zh': '大型语言模型（LLMs）已成为各个领域不可或缺的工具，但它们在跨文化与语言背景下进行道德推理的能力尚未得到充分探索。本研究考察了多语言LLMs，如GPT-3.5-Turbo、GPT-4o-mini、Llama 3.1和MistralNeMo，是否反映出了特定文化下的道德价值观，还是倾向于传播根植于英语的主导道德规范。研究使用阿拉伯语、波斯语、英语、西班牙语、日语、汉语、法语和俄语版本的更新版《道德基础问卷》（MFQ-2），分析了这六个核心道德基础：关爱、平等、适中、忠诚、权威和纯洁，以评估模型的道德倾向。研究结果揭示了显著的文化和语言差异，挑战了LLMs普遍道德一致性这一假设。尽管有些模型显示出适应不同背景的能力，但也有其他模型因其训练数据的构成而表现出偏见。这些发现强调了在多语言AI系统中进行文化包容性模型开发的必要性，以提高公平性和信任度。', 'title_zh': '他们代言的是哪种道德观？探究多语言语言模型中的文化偏见'}
{'arxiv_id': 'arXiv:2412.18862', 'title': 'WeatherGS: 3D Scene Reconstruction in Adverse Weather Conditions via Gaussian Splatting', 'authors': 'Chenghao Qian, Yuhu Guo, Wenjing Li, Gustav Markkula', 'link': 'https://arxiv.org/abs/2412.18862', 'abstract': '3D Gaussian Splatting (3DGS) has gained significant attention for 3D scene reconstruction, but still suffers from complex outdoor environments, especially under adverse weather. This is because 3DGS treats the artifacts caused by adverse weather as part of the scene and will directly reconstruct them, largely reducing the clarity of the reconstructed scene. To address this challenge, we propose WeatherGS, a 3DGS-based framework for reconstructing clear scenes from multi-view images under different weather conditions. Specifically, we explicitly categorize the multi-weather artifacts into the dense particles and lens occlusions that have very different characters, in which the former are caused by snowflakes and raindrops in the air, and the latter are raised by the precipitation on the camera lens. In light of this, we propose a dense-to-sparse preprocess strategy, which sequentially removes the dense particles by an Atmospheric Effect Filter (AEF) and then extracts the relatively sparse occlusion masks with a Lens Effect Detector (LED). Finally, we train a set of 3D Gaussians by the processed images and generated masks for excluding occluded areas, and accurately recover the underlying clear scene by Gaussian splatting. We conduct a diverse and challenging benchmark to facilitate the evaluation of 3D reconstruction under complex weather scenarios. Extensive experiments on this benchmark demonstrate that our WeatherGS consistently produces high-quality, clean scenes across various weather scenarios, outperforming existing state-of-the-art methods. See project page:this https URL.', 'abstract_zh': '3D高斯散点图（3DGS）在三维场景重建中引起了广泛关注，但在复杂户外环境中，尤其是在恶劣天气下，仍然存在挑战。由于3DGS将恶劣天气引起的所有伪影视为场景的一部分，并直接对其进行重建，这大大降低了重建场景的清晰度。为了解决这一挑战，我们提出了WeatherGS，一种基于3DGS的框架，用于在不同天气条件下从多视图图像中重建清晰的场景。具体来说，我们明确将多天气伪影分为密集颗粒和透镜遮挡，前者的形成原因是空气中雪花和雨滴，后者的形成原因是镜头上的降水。基于这一点，我们提出了一种从密集到稀疏的预处理策略，该策略通过大气效应滤波器（AEF）先顺序去除密集颗粒，然后使用透镜效应检测器（LED）提取相对稀疏的遮挡掩码。最后，我们通过处理过的图像和生成的掩码训练一组3D高斯散点图，并通过高斯散点图准确恢复出隐蔽的清晰场景。我们建立了一个多样性和挑战性的基准，以促进复杂天气场景下的三维重建评估。在这一基准上进行的广泛实验表明，我们的WeatherGS能够在各种天气场景下一致生成高质量的清晰场景，并且优于现有的最先进的方法。详见项目页面：[此链接](此链接请替换为实际链接)。', 'title_zh': 'WeatherGS：通过高斯点绘制在恶劣天气条件下的3D场景重建'}
{'arxiv_id': 'arXiv:2412.18857', 'title': 'Computing Approximate Graph Edit Distance via Optimal Transport', 'authors': 'Qihao Cheng, Da Yan, Tianhao Wu, Zhongyi Huang, Qin Zhang', 'link': 'https://arxiv.org/abs/2412.18857', 'abstract': 'Given a graph pair $(G^1, G^2)$, graph edit distance (GED) is defined as the minimum number of edit operations converting $G^1$ to $G^2$. GED is a fundamental operation widely used in many applications, but its exact computation is NP-hard, so the approximation of GED has gained a lot of attention. Data-driven learning-based methods have been found to provide superior results compared to classical approximate algorithms, but they directly fit the coupling relationship between a pair of vertices from their vertex features. We argue that while pairwise vertex features can capture the coupling cost (discrepancy) of a pair of vertices, the vertex coupling matrix should be derived from the vertex-pair cost matrix through a more well-established method that is aware of the global context of the graph pair, such as optimal transport. In this paper, we propose an ensemble approach that integrates a supervised learning-based method and an unsupervised method, both based on optimal transport. Our learning method, GEDIOT, is based on inverse optimal transport that leverages a learnable Sinkhorn algorithm to generate the coupling matrix. Our unsupervised method, GEDGW, models GED computation as a linear combination of optimal transport and its variant, Gromov-Wasserstein discrepancy, for node and edge operations, respectively, which can be solved efficiently without needing the ground truth. Our ensemble method, GEDHOT, combines GEDIOT and GEDGW to further boost the performance. Extensive experiments demonstrate that our methods significantly outperform the existing methods in terms of the performance of GED computation, edit path generation, and model generalizability.', 'abstract_zh': '给定一个图对 \\((G^1, G^2)\\)，图编辑距离（GED）定义为将 \\(G^1\\) 转换为 \\(G^2\\) 所需的最小编辑操作数。GED 是广泛应用于多种应用的基本操作，但由于其精确计算是 NP 难问题，因此对 GED 的近似计算引起了广泛关注。基于数据驱动的学习方法被发现能够提供优于经典近似算法的结果，但它们直接从顶点特征中拟合顶点对之间的耦合关系。我们认为，虽然顶点对的特征能够捕捉顶点对之间的耦合成本（差异），但顶点耦合矩阵应通过一种更完善的方法从顶点对成本矩阵中推导出来，并且这种方法需要考虑到图对的全局上下文，例如最优传输方法。在本文中，我们提出了一种集成方法，结合了一个基于监督学习的方法和一个基于无监督学习的方法，两者都基于最优传输方法。我们的学习方法 GEDIOT 依赖于逆最优传输，并利用可学习的 Sinkhorn 算法来生成耦合矩阵。我们的无监督方法 GEDGW 将 GED 计算建模为最优传输及其变体——Gromov-Wasserstein 差异的线性组合，分别用于节点和边的操作，并且可以高效求解而无需真实数据。我们的集成方法 GEDHOT 结合了 GEDIOT 和 GEDGW，进一步提升了性能。大量实验结果表明，与现有方法相比，我们的方法在图编辑距离计算、编辑路径生成以及模型泛化能力方面表现更优。', 'title_zh': '通过最优传输计算图形编辑距离的近似值'}
{'arxiv_id': 'arXiv:2412.18840', 'title': 'Implicit factorized transformer approach to fast prediction of turbulent channel flows', 'authors': 'Huiyu Yang, Yunpeng Wang, Jianchun Wang', 'link': 'https://arxiv.org/abs/2412.18840', 'abstract': 'Transformer neural operators have recently become an effective approach for surrogate modeling of nonlinear systems governed by partial differential equations (PDEs). In this paper, we introduce a modified implicit factorized transformer (IFactFormer-m) model which replaces the original chained factorized attention with parallel factorized attention. The IFactFormer-m model successfully performs long-term predictions for turbulent channel flow, whereas the original IFactFormer (IFactFormer-o), Fourier neural operator (FNO), and implicit Fourier neural operator (IFNO) exhibit a poor performance. Turbulent channel flows are simulated by direct numerical simulation using fine grids at friction Reynolds numbers $\\text{Re}_{\\tau}\\approx 180,395,590$, and filtered to coarse grids for training neural operator. The neural operator takes the current flow field as input and predicts the flow field at the next time step, and long-term prediction is achieved in the posterior through an autoregressive approach. The prediction results show that IFactFormer-m, compared to other neural operators and the traditional large eddy simulation (LES) methods including dynamic Smagorinsky model (DSM) and the wall-adapted local eddy-viscosity (WALE) model, reduces prediction errors in the short term, and achieves stable and accurate long-term prediction of various statistical properties and flow structures, including the energy spectrum, mean streamwise velocity, root mean square (rms) values of fluctuating velocities, Reynolds shear stress, and spatial structures of instantaneous velocity. Moreover, the trained IFactFormer-m is much faster than traditional LES methods.', 'abstract_zh': '最近，基于变压器的神经运算器已成为构建偏微分方程（PDE）支配的非线性系统代理模型的有效方法。本文引入了一种修改过的并行因子注意力隐式因子化变压器（IFactFormer-m）模型，该模型用并行因子注意力替代了原始的链接因子注意力。实验结果表明，IFactFormer-m 在湍流通道流动的长期预测中表现出色，而原始的 IFactFormer（IFactFormer-o）、Fourier神经运算器（FNO）和隐式Fourier神经运算器（IFNO）则表现出较差的性能。湍流通道流动通过使用精细网格进行直接数值模拟来模拟，在摩擦雷诺数 $\\text{Re}_{\\tau} \\approx 180,395,590$ 附近下进行，并通过过滤到粗糙网格来训练神经运算器。神经运算器以当前流动场为输入，并预测下一个时间步的流动场，通过自回归方法在后验中实现长期预测。预测结果表明，与其它神经运算器和传统的大涡模拟（LES）方法（包括动态Smagorinsky模型（DSM）和壁面自适应局部涡黏性（WALE）模型）相比，IFactFormer-m 在短期内减少了预测误差，并实现了各种统计特性和流动结构的长期稳定和准确预测，包括能量谱、平均沿程速度、脉动速度的均方根值、湍流剪应力以及瞬时速度的空间结构。此外，训练后的 IFactFormer-m 在速度上远快于传统的LES方法。', 'title_zh': '隐式因子化变压器方法在湍流通道流快速预测中的应用'}
{'arxiv_id': 'arXiv:2412.18839', 'title': 'Advancing NAM-to-Speech Conversion with Novel Methods and the MultiNAM Dataset', 'authors': 'Neil Shah, Shirish Karande, Vineet Gandhi', 'link': 'https://arxiv.org/abs/2412.18839', 'abstract': 'Current Non-Audible Murmur (NAM)-to-speech techniques rely on voice cloning to simulate ground-truth speech from paired whispers. However, the simulated speech often lacks intelligibility and fails to generalize well across different speakers. To address this issue, we focus on learning phoneme-level alignments from paired whispers and text and employ a Text-to-Speech (TTS) system to simulate the ground-truth. To reduce dependence on whispers, we learn phoneme alignments directly from NAMs, though the quality is constrained by the available training data. To further mitigate reliance on NAM/whisper data for ground-truth simulation, we propose incorporating the lip modality to infer speech and introduce a novel diffusion-based method that leverages recent advancements in lip-to-speech technology. Additionally, we release the MultiNAM dataset with over $7.96$ hours of paired NAM, whisper, video, and text data from two speakers and benchmark all methods on this dataset. Speech samples and the dataset are available at \\url{this https URL}', 'abstract_zh': '当前的非听觉低语（Non-Audible Murmur, NAM）转语音技术依赖于语音克隆来模拟配对低语的ground-truth语音。然而，模拟出的语音往往缺乏可理解性，并且在不同说话者间难以泛化。为解决这一问题，我们关注从配对的低语和文本中学习音素层级的对齐，利用文本转语音（Text-to-Speech, TTS）系统来模拟ground-truth语音。为了减少对低语的依赖，我们直接从NAM中学习音素对齐，尽管其质量受限于可用的训练数据。为进一步减轻对NAM/低语数据的依赖，实现ground-truth语音模拟，我们提出结合唇部模态来推断语音，并引入一种基于扩散模型的方法，该方法利用了最新的唇部转语音技术的进展。此外，我们发布了包含超过7.96小时的配对NAM、低语、视频和文本数据的MultiNAM数据集，并在该数据集上基准测试所有方法。语音样本和数据集可在以下链接访问：\\url{this https URL}', 'title_zh': '利用新型方法和MultiNAM数据集推进NAM到语音的转换技术'}
{'arxiv_id': 'arXiv:2412.18836', 'title': 'MRI2Speech: Speech Synthesis from Articulatory Movements Recorded by Real-time MRI', 'authors': 'Neil Shah, Ayan Kashyap, Shirish Karande, Vineet Gandhi', 'link': 'https://arxiv.org/abs/2412.18836', 'abstract': "Previous real-time MRI (rtMRI)-based speech synthesis models depend heavily on noisy ground-truth speech. Applying loss directly over ground truth mel-spectrograms entangles speech content with MRI noise, resulting in poor intelligibility. We introduce a novel approach that adapts the multi-modal self-supervised AV-HuBERT model for text prediction from rtMRI and incorporates a new flow-based duration predictor for speaker-specific alignment. The predicted text and durations are then used by a speech decoder to synthesize aligned speech in any novel voice. We conduct thorough experiments on two datasets and demonstrate our method's generalization ability to unseen speakers. We assess our framework's performance by masking parts of the rtMRI video to evaluate the impact of different articulators on text prediction. Our method achieves a $15.18\\%$ Word Error Rate (WER) on the USC-TIMIT MRI corpus, marking a huge improvement over the current state-of-the-art. Speech samples are available at \\url{this https URL}", 'abstract_zh': '以下是经过学术规范翻译的内容：\n\n先前基于实时MRI（rtMRI）的语音合成模型高度依赖于带有噪声的地面真实语音。直接将损失应用于地面真实梅尔频谱图会将语音内容与MRI噪声交织在一起，导致语音合成结果的可懂度较差。我们提出了一种新颖的方法，利用多模态自监督AV-HuBERT模型从rtMRI预测文本，并引入了一种新的基于流的新持续时间预测器，实现了对特定说话人的对齐。预测的文本和持续时间随后被语音解码器用于在任何新的语音中合成对齐的语音。我们在两个数据集上进行了详细的实验，并展示了我们的方法对未见过说话人的泛化能力。我们通过掩蔽rtMRI视频的某些部分，评估不同发音器官对文本预测的影响，从而评估我们的框架性能。我们的方法在USC-TIMIT MRI语料库上的词错率（Word Error Rate, WER）为15.18%，标志着对当前最先进的方法的巨大改进。语音样本可在以下网址获取：\\url{此链接}', 'title_zh': 'MRI2Speech：基于实时磁共振成像记录的发音运动的语音合成'}
{'arxiv_id': 'arXiv:2412.18827', 'title': 'PhyloGen: Language Model-Enhanced Phylogenetic Inference via Graph Structure Generation', 'authors': 'ChenRui Duan, Zelin Zang, Siyuan Li, Yongjie Xu, Stan Z. Li', 'link': 'https://arxiv.org/abs/2412.18827', 'abstract': 'Phylogenetic trees elucidate evolutionary relationships among species, but phylogenetic inference remains challenging due to the complexity of combining continuous (branch lengths) and discrete parameters (tree topology). Traditional Markov Chain Monte Carlo methods face slow convergence and computational burdens. Existing Variational Inference methods, which require pre-generated topologies and typically treat tree structures and branch lengths independently, may overlook critical sequence features, limiting their accuracy and flexibility. We propose PhyloGen, a novel method leveraging a pre-trained genomic language model to generate and optimize phylogenetic trees without dependence on evolutionary models or aligned sequence constraints. PhyloGen views phylogenetic inference as a conditionally constrained tree structure generation problem, jointly optimizing tree topology and branch lengths through three core modules: (i) Feature Extraction, (ii) PhyloTree Construction, and (iii) PhyloTree Structure Modeling. Meanwhile, we introduce a Scoring Function to guide the model towards a more stable gradient descent. We demonstrate the effectiveness and robustness of PhyloGen on eight real-world benchmark datasets. Visualization results confirm PhyloGen provides deeper insights into phylogenetic relationships.', 'abstract_zh': '系统树能够阐明物种之间的进化关系，但进化树推理由于连续参数（分支长度）和离散参数（树拓扑结构）的结合复杂性而仍然具有挑战性。传统马尔可夫链蒙特卡洛方法面临收敛缓慢和计算负担重的问题。现有的一些变分推断方法需要预先生成的拓扑结构，并通常独立处理树结构和分支长度，可能会忽略关键序列特征，限制了它们的准确性和灵活性。我们提出了一种名为PhyloGen的新方法，利用预训练的基因组语言模型生成和优化树，无需依赖进化模型或对齐序列约束。PhyloGen将进化树推理视为有条件约束的树结构生成问题，通过三个核心模块联合优化树拓扑结构和分支长度：(i) 特征提取，(ii) 进化树构建，和(iii) 进化树结构建模。此外，我们引入了一个评分函数来引导模型向更稳定的梯度下降方向发展。我们通过八个实际基准数据集验证了PhyloGen的有效性和鲁棒性。可视化结果表明，PhyloGen能够更深入地揭示进化关系。', 'title_zh': 'PhyloGen：通过图结构生成增强的语言模型辅助系统演化推断'}
{'arxiv_id': 'arXiv:2412.18816', 'title': 'GSAVS: Gaussian Splatting-based Autonomous Vehicle Simulator', 'authors': 'Rami Wilson', 'link': 'https://arxiv.org/abs/2412.18816', 'abstract': 'Modern autonomous vehicle simulators feature an ever-growing library of assets, including vehicles, buildings, roads, pedestrians, and more. While this level of customization proves beneficial when creating virtual urban environments, this process becomes cumbersome when intending to train within a digital twin or a duplicate of a real scene. Gaussian splatting emerged as a powerful technique in scene reconstruction and novel view synthesis, boasting high fidelity and rendering speeds. In this paper, we introduce GSAVS, an autonomous vehicle simulator that supports the creation and development of autonomous vehicle models. Every asset within the simulator is a 3D Gaussian splat, including the vehicles and the environment. However, the simulator runs within a classical 3D engine, rendering 3D Gaussian splats in real-time. This allows the simulator to utilize the photorealism that 3D Gaussian splatting boasts while providing the customization and ease of use of a classical 3D engine.', 'abstract_zh': '现代自主车辆模拟器具备不断增长的资产库，包括车辆、建筑、道路、行人等。虽然这种高度定制性在创建虚拟城市环境时很有益处，但在旨在训练数字孪生（虚拟副本）或真实场景的副本时，这一过程可能会变得繁琐。高斯划分作为一种强大的场景重建和新视角合成技术，在保持高保真度和渲染速度方面表现出色。在本文中，我们引入了一种名为GSAVS的自主车辆模拟器，支持自主车辆模型的创建与开发。模拟器中的每个资产都是3D高斯划分，包括车辆和环境。然而，该模拟器运行在传统的3D引擎中，能够实时渲染3D高斯划分。这使得模拟器可以利用3D高斯划分所具有的真实感，同时提供传统3D引擎的定制化和易用性。', 'title_zh': 'GSAVS：基于高斯点云的自主驾驶车辆模拟器'}
{'arxiv_id': 'arXiv:2412.18798', 'title': 'Ister: Inverted Seasonal-Trend Decomposition Transformer for Explainable Multivariate Time Series Forecasting', 'authors': 'Fanpu Cao, Shu Yang, Zhengjian Chen, Ye Liu, Laizhong Cui', 'link': 'https://arxiv.org/abs/2412.18798', 'abstract': 'In long-term time series forecasting, Transformer-based models have achieved great success, due to its ability to capture long-range dependencies. However, existing transformer-based methods face challenges in accurately identifying which variables play a pivotal role in the prediction process and tend to overemphasize noisy channels, thereby limiting the interpretability and practical effectiveness of the models. Besides, it faces scalability issues due to quadratic computational complexity of self-attention. In this paper, we propose a new model named Inverted Seasonal-Trend Decomposition Transformer (Ister), which addresses these challenges in long-term multivariate time series forecasting by designing an improved Transformer-based structure. Ister firstly decomposes original time series into seasonal and trend components. Then we propose a new Dot-attention mechanism to process the seasonal component, which improves both accuracy, computation complexity and interpretability. Upon completion of the training phase, it allows users to intuitively visualize the significance of each feature in the overall prediction. We conduct comprehensive experiments, and the results show that Ister achieves state-of-the-art (SOTA) performance on multiple datasets, surpassing existing models in long-term prediction tasks.', 'abstract_zh': '在长期时间序列预测中，基于Transformer的模型已经取得了巨大的成功，这是因为它们能够捕捉到长程依赖性。然而，现有的基于Transformer的方法在准确识别对预测过程起关键作用的变量方面面临着挑战，且倾向于过度强调噪声通道，从而限制了模型的可解释性和实际效果。此外，由于自我注意机制的二次复杂度，这些模型还面临着可扩展性问题。本文提出了一种新的模型，称为Inverted Seasonal-Trend Decomposition Transformer (Ister)，它通过设计改进的基于Transformer的结构来解决长期多变量时间序列预测中的这些挑战。Ister首先将原始时间序列分解为季节性和趋势分量。然后，我们提出了一种新的Dot-注意机制来处理季节性分量，从而提高准确性、计算复杂度和可解释性。在训练完成后，它允许用户直观地可视化每个特征在整个预测中的重要性。我们进行了全面的实验，结果表明Ister在多个数据集上实现了最先进的（SOTA）性能，在长期预测任务中超越了现有的模型。', 'title_zh': 'Ister: 倒序季节趋势分解变换器在可解释的多变量时间序列预测中的应用'}
{'arxiv_id': 'arXiv:2412.18790', 'title': 'Torque-Aware Momentum', 'authors': 'Pranshu Malviya, Goncalo Mordido, Aristide Baratin, Reza Babanezhad Harikandeh, Gintare Karolina Dziugaite, Razvan Pascanu, Sarath Chandar', 'link': 'https://arxiv.org/abs/2412.18790', 'abstract': 'Efficiently exploring complex loss landscapes is key to the performance of deep neural networks. While momentum-based optimizers are widely used in state-of-the-art setups, classical momentum can still struggle with large, misaligned gradients, leading to oscillations. To address this, we propose Torque-Aware Momentum (TAM), which introduces a damping factor based on the angle between the new gradients and previous momentum, stabilizing the update direction during training. Empirical results show that TAM, which can be combined with both SGD and Adam, enhances exploration, handles distribution shifts more effectively, and improves generalization performance across various tasks, including image classification and large language model fine-tuning, when compared to classical momentum-based optimizers.', 'abstract_zh': '高效探索复杂的损失景观是深度神经网络性能的关键。尽管基于动量的优化器在当今的先进设置中广泛使用，但经典的动量仍然难以处理大的、方向错位的梯度，导致振荡。为了解决这一问题，我们提出了一种基于扭矩的动量（Torque-Aware Momentum，TAM），它通过引入基于新梯度与先前动量之间夹角的阻尼因子来稳定训练中的更新方向。实验结果表明，TAM 可以与 SGD 和 Adam 等方法结合使用，能够增强探索能力，更好地处理分布偏移，并在包括图像分类和大规模语言模型微调在内的各种任务上提高泛化性能，优于传统的基于动量的优化器。', 'title_zh': '扭矩感知动量'}
{'arxiv_id': 'arXiv:2412.18780', 'title': 'Skeleton-based Action Recognition with Non-linear Dependency Modeling and Hilbert-Schmidt Independence Criterion', 'authors': 'Yuheng Yang', 'link': 'https://arxiv.org/abs/2412.18780', 'abstract': 'Human skeleton-based action recognition has long been an indispensable aspect of artificial intelligence. Current state-of-the-art methods tend to consider only the dependencies between connected skeletal joints, limiting their ability to capture non-linear dependencies between physically distant joints. Moreover, most existing approaches distinguish action classes by estimating the probability density of motion representations, yet the high-dimensional nature of human motions invokes inherent difficulties in accomplishing such measurements. In this paper, we seek to tackle these challenges from two directions: (1) We propose a novel dependency refinement approach that explicitly models dependencies between any pair of joints, effectively transcending the limitations imposed by joint distance. (2) We further propose a framework that utilizes the Hilbert-Schmidt Independence Criterion to differentiate action classes without being affected by data dimensionality, and mathematically derive learning objectives guaranteeing precise recognition. Empirically, our approach sets the state-of-the-art performance on NTU RGB+D, NTU RGB+D 120, and Northwestern-UCLA datasets.', 'abstract_zh': '基于人类骨架的动作识别一直是人工智能不可或缺的一部分。当前最先进的方法往往只考虑连接骨骼关节之间的依赖性，这限制了它们捕捉物理上距离较远的关节之间的非线性依赖性的能力。此外，大多数现有方法通过估计运动表示的概率密度来区分动作类别，但人类动作的高维性质带来了实现这些测量的固有困难。在这篇论文中，我们从两个方向入手解决这些挑战：（1）我们提出了一种新颖的依赖性细化方法，明确地建模了任意一对关节之间的依赖性，从而超越了由关节距离造成的局限。（2）我们进一步提出了一种框架，利用Hilbert-Schmidt独立性判别准则来区分动作类别，不受数据维度的影响，并通过数学推导出学习目标，确保精确的动作识别。实验结果显示，我们的方法在NTU RGB+D、NTU RGB+D 120和Northwestern-UCLA数据集上达到了最先进的性能。', 'title_zh': '基于骨架的动作识别：非线性依赖建模与希尔伯特-施密特独立性判据'}
{'arxiv_id': 'arXiv:2412.18778', 'title': 'Unified Local and Global Attention Interaction Modeling for Vision Transformers', 'authors': 'Tan Nguyen, Coy D. Heldermon, Corey Toler-Franklin', 'link': 'https://arxiv.org/abs/2412.18778', 'abstract': 'We present a novel method that extends the self-attention mechanism of a vision transformer (ViT) for more accurate object detection across diverse datasets. ViTs show strong capability for image understanding tasks such as object detection, segmentation, and classification. This is due in part to their ability to leverage global information from interactions among visual tokens. However, the self-attention mechanism in ViTs are limited because they do not allow visual tokens to exchange local or global information with neighboring features before computing global attention. This is problematic because tokens are treated in isolation when attending (matching) to other tokens, and valuable spatial relationships are overlooked. This isolation is further compounded by dot-product similarity operations that make tokens from different semantic classes appear visually similar. To address these limitations, we introduce two modifications to the traditional self-attention framework; a novel aggressive convolution pooling strategy for local feature mixing, and a new conceptual attention transformation to facilitate interaction and feature exchange between semantic concepts. Experimental results demonstrate that local and global information exchange among visual features before self-attention significantly improves performance on challenging object detection tasks and generalizes across multiple benchmark datasets and challenging medical datasets. We publish source code and a novel dataset of cancerous tumors (chimeric cell clusters).', 'abstract_zh': '我们提出了一种新颖的方法，该方法扩展了视觉变换器（ViT）的自注意力机制，以在多样化的数据集中实现更准确的物体检测。ViTs 在图像理解任务（如物体检测、分割和分类）方面表现出强大的能力。这得益于它们能够通过视觉标记之间的交互利用全局信息。然而，ViTs 中的自注意力机制存在局限性，因为它们在计算全局注意力之前不允许视觉标记与邻近特征交换局部或全局信息。这在物体检测（matching）时将以隔离的方式对待标记，从而忽视重要的空间关系。此外，点积相似性操作使得来自不同语义类别的标记在视觉上显得相似，进一步加剧了隔离问题。为了解决这些局限性，我们对传统的自注意力框架进行了两项改进：一种新颖的激进卷积池化策略用于局部特征混合，以及一种全新的概念性注意力变换，以促进语义概念之间的交互和特征交换。实验结果表明，在自注意力之前进行局部和全局信息交换能显著提高物体检测任务的性能，并在多个基准数据集和具有挑战性的医学数据集上具有泛化能力。我们发布了源代码和一个新的癌变肿瘤（嵌合细胞簇）数据集。', 'title_zh': '统一局部和全局注意力交互 modeling 机制在视觉变换器中的应用'}
{'arxiv_id': 'arXiv:2412.18775', 'title': 'ObitoNet: Multimodal High-Resolution Point Cloud Reconstruction', 'authors': 'Apoorv Thapliyal, Vinay Lanka, Swathi Baskaran', 'link': 'https://arxiv.org/abs/2412.18775', 'abstract': 'ObitoNet employs a Cross Attention mechanism to integrate multimodal inputs, where Vision Transformers (ViT) extract semantic features from images and a point cloud tokenizer processes geometric information using Farthest Point Sampling (FPS) and K Nearest Neighbors (KNN) for spatial structure capture. The learned multimodal features are fed into a transformer-based decoder for high-resolution point cloud reconstruction. This approach leverages the complementary strengths of both modalities rich image features and precise geometric details ensuring robust point cloud generation even in challenging conditions such as sparse or noisy data.', 'abstract_zh': 'ObitoNet采用跨注意力机制整合多模态输入，其中视觉transformer（ViT）从图像中提取语义特征，点云分词器通过最远点采样（FPS）和K近邻（KNN）处理几何信息以捕获空间结构。学习到的多模态特征被输入一个基于transformer的解码器进行高分辨率点云重建。该方法利用了图像特征丰富和几何细节精确的优势，即使在稀疏或嘈杂数据等具有挑战性的条件下也能确保点云生成的鲁棒性。', 'title_zh': 'ObitoNet：多模态高分辨率点云重建'}
{'arxiv_id': 'arXiv:2412.18750', 'title': 'The Impact of Input Order Bias on Large Language Models for Software Fault Localization', 'authors': 'Md Nakhla Rafi, Dong Jae Kim, Tse-Hsun Chen, Shaowei Wang', 'link': 'https://arxiv.org/abs/2412.18750', 'abstract': 'Large Language Models (LLMs) show great promise in software engineering tasks like Fault Localization (FL) and Automatic Program Repair (APR). This study examines how input order and context size affect LLM performance in FL, a key step for many downstream software engineering tasks. We test different orders for methods using Kendall Tau distances, including "perfect" (where ground truths come first) and "worst" (where ground truths come last). Our results show a strong bias in order, with Top-1 accuracy falling from 57\\% to 20\\% when we reverse the code order. Breaking down inputs into smaller contexts helps reduce this bias, narrowing the performance gap between perfect and worst orders from 22\\% to just 1\\%. We also look at ordering methods based on traditional FL techniques and metrics. Ordering using DepGraph\'s ranking achieves 48\\% Top-1 accuracy, better than more straightforward ordering approaches like CallGraph. These findings underscore the importance of how we structure inputs, manage contexts, and choose ordering methods to improve LLM performance in FL and other software engineering tasks.', 'abstract_zh': '大型语言模型（LLMs）在软件工程任务中显示出巨大的潜力，如故障定位（FL）和自动程序修复（APR）。本研究探讨了输入顺序和上下文规模对LLMs在FL任务中的性能影响。FL是许多下游软件工程任务的关键步骤。我们使用Kendall Tau距离测试了不同的输入顺序，包括“最优”（真实答案排在前面）和“最差”（真实答案排在后面）的情况。结果表明，输入顺序存在明显的偏向性，当反转代码顺序时，Top-1准确率从57%下降到20%。将输入分解成更小的上下文有助于减轻这种偏向性，使得“最优”和“最差”顺序之间的性能差距从22%缩小到仅仅1%。我们还研究了基于传统故障定位技术和指标的排序方法。使用DepGraph排名的排序方法可以达到48%的Top-1准确率，优于仅按调用图排序等更简单的排序方法。这些发现强调了如何结构化输入、管理上下文以及选择排序方法对于提高LLMs在FL和其他软件工程任务中的性能的重要性。', 'title_zh': '大型语言模型中输入顺序偏差对软件故障定位的影响'}
{'arxiv_id': 'arXiv:2412.18743', 'title': 'Successes and Limitations of Object-centric Models at Compositional Generalisation', 'authors': 'Milton L. Montero, Jeffrey S. Bowers, Gaurav Malhotra', 'link': 'https://arxiv.org/abs/2412.18743', 'abstract': 'In recent years, it has been shown empirically that standard disentangled latent variable models do not support robust compositional learning in the visual domain. Indeed, in spite of being designed with the goal of factorising datasets into their constituent factors of variations, disentangled models show extremely limited compositional generalisation capabilities. On the other hand, object-centric architectures have shown promising compositional skills, albeit these have 1) not been extensively tested and 2) experiments have been limited to scene composition -- where models must generalise to novel combinations of objects in a visual scene instead of novel combinations of object properties. In this work, we show that these compositional generalisation skills extend to this later setting. Furthermore, we present evidence pointing to the source of these skills and how they can be improved through careful training. Finally, we point to one important limitation that still exists which suggests new directions of research.', 'abstract_zh': '近年来，实验研究表明，标准的互信息潜在变量模型在视觉领域中无法支持稳健的组合学习。尽管这些模型被设计成能够将数据集分解为其构成的变化因素，但它们在组合泛化能力上表现出极其有限的性能。另一方面，以对象为中心的架构在组合技能方面展示了良好的潜力，但这些技能尚未被广泛测试，并且实验主要局限于场景组合——要求模型在视觉场景中泛化到新对象组合，而非新对象属性的组合。在本研究中，我们证明了这些组合泛化技能也可以适用于后一种情况。此外，我们提供了关于这些技能产生的原因及其改进方法的证据。最后，我们指出了仍存在的一个重要限制，这表明新的研究方向。', 'title_zh': '对象中心模型在组合泛化中的成功与局限性'}
{'arxiv_id': 'arXiv:2412.18734', 'title': 'Predicting Time Series of Networked Dynamical Systems without Knowing Topology', 'authors': 'Yanna Ding, Zijie Huang, Malik Magdon-Ismail, Jianxi Gao', 'link': 'https://arxiv.org/abs/2412.18734', 'abstract': 'Many real-world complex systems, such as epidemic spreading networks and ecosystems, can be modeled as networked dynamical systems that produce multivariate time series. Learning the intrinsic dynamics from observational data is pivotal for forecasting system behaviors and making informed decisions. However, existing methods for modeling networked time series often assume known topologies, whereas real-world networks are typically incomplete or inaccurate, with missing or spurious links that hinder precise predictions. Moreover, while networked time series often originate from diverse topologies, the ability of models to generalize across topologies has not been systematically evaluated. To address these gaps, we propose a novel framework for learning network dynamics directly from observed time-series data, when prior knowledge of graph topology or governing dynamical equations is absent. Our approach leverages continuous graph neural networks with an attention mechanism to construct a latent topology, enabling accurate reconstruction of future trajectories for network states. Extensive experiments on real and synthetic networks demonstrate that our model not only captures dynamics effectively without topology knowledge but also generalizes to unseen time series originating from diverse topologies.', 'abstract_zh': '许多现实中的复杂系统，如流行病传播网络和生态系统，都可以被建模为产生多元时间序列的网络动态系统。从观测数据中学习内在动态对于预测系统行为并做出有根据的决策至关重要。然而，现有的网络时间序列建模方法通常假设已知的拓扑结构，而事实上，现实世界的网络往往是不完全的或不准确的，存在缺失或错误的连接，这妨碍了精确的预测。此外，虽然网络时间序列往往来自不同的拓扑结构，但现有模型在不同拓扑结构上的泛化能力尚未得到系统的评估。为了解决这些问题，我们提出了一种新型框架，用于直接从观测时间序列数据中学习网络动态，而无需事先了解图拓扑结构或支配动力学方程。我们的方法利用带注意力机制的连续图神经网络来构建潜在拓扑结构，从而能够准确地重建网络状态的未来轨迹。在实际和合成网络上的广泛实验表明，我们的模型不仅在没有拓扑结构知识的情况下有效地捕捉到了动力学，并且还可以泛化到来自不同拓扑结构的未见过的时间序列。', 'title_zh': '无需了解拓扑结构的网络动态系统的时间序列预测'}
{'arxiv_id': 'arXiv:2412.18727', 'title': 'SAFLITE: Fuzzing Autonomous Systems via Large Language Models', 'authors': 'Taohong Zhu, Adrians Skapars, Fardeen Mackenzie, Declan Kehoe, William Newton, Suzanne Embury, Youcheng Sun', 'link': 'https://arxiv.org/abs/2412.18727', 'abstract': 'Fuzz testing effectively uncovers software vulnerabilities; however, it faces challenges with Autonomous Systems (AS) due to their vast search spaces and complex state spaces, which reflect the unpredictability and complexity of real-world environments. This paper presents a universal framework aimed at improving the efficiency of fuzz testing for AS. At its core is SaFliTe, a predictive component that evaluates whether a test case meets predefined safety criteria. By leveraging the large language model (LLM) with information about the test objective and the AS state, SaFliTe assesses the relevance of each test case. We evaluated SaFliTe by instantiating it with various LLMs, including GPT-3.5, Mistral-7B, and Llama2-7B, and integrating it into four fuzz testing tools: PGFuzz, DeepHyperion-UAV, CAMBA, and TUMB. These tools are designed specifically for testing autonomous drone control systems, such as ArduPilot, PX4, and PX4-Avoidance. The experimental results demonstrate that, compared to PGFuzz, SaFliTe increased the likelihood of selecting operations that triggered bug occurrences in each fuzzing iteration by an average of 93.1\\%. Additionally, after integrating SaFliTe, the ability of DeepHyperion-UAV, CAMBA, and TUMB to generate test cases that caused system violations increased by 234.5\\%, 33.3\\%, and 17.8\\%, respectively. The benchmark for this evaluation was sourced from a UAV Testing Competition.', 'abstract_zh': '模糊测试有效地揭示了软件漏洞，但在自主系统（AS）中面临挑战，因为AS具有庞大的搜索空间和复杂的状态空间，这反映了现实环境中的不可预测性和复杂性。本文提出了一种通用框架，旨在提高AS模糊测试的效率。其核心是SaFliTe，这是一种预测组件，用于评估测试案例是否满足预定义的安全标准。通过利用大型语言模型（LLM）中的测试目标和AS状态信息，SaFliTe评估每个测试案例的相关性。我们通过实例化不同的LLM，包括GPT-3.5、Mistral-7B和Llama2-7B，并将其集成到四种模糊测试工具：PGFuzz、DeepHyperion-UAV、CAMBA和TUMB中进行了评估。这些工具专门用于测试自主无人机控制系统，如ArduPilot、PX4和PX4-Avoidance。实验结果表明，与PGFuzz相比，SaFliTe在每次模糊测试迭代中选择触发错误的选项的可能性平均提高了93.1%。另外，集成SaFliTe后，DeepHyperion-UAV、CAMBA和TUMB生成导致系统违规的测试案例的能力分别提高了234.5%、33.3%和17.8%。此次评估的基准数据来自于一项无人机测试竞赛。', 'title_zh': 'SAFLITE：通过大规模语言模型对自主系统进行模糊测试'}
{'arxiv_id': 'arXiv:2412.18706', 'title': 'SurvAttack: Black-Box Attack On Survival Models through Ontology-Informed EHR Perturbation', 'authors': 'Mohsen Nayebi Kerdabadi, Arya Hadizadeh Moghaddam, Bin Liu, Mei Liu, Zijun Yao', 'link': 'https://arxiv.org/abs/2412.18706', 'abstract': "Survival analysis (SA) models have been widely studied in mining electronic health records (EHRs), particularly in forecasting the risk of critical conditions for prioritizing high-risk patients. However, their vulnerability to adversarial attacks is much less explored in the literature. Developing black-box perturbation algorithms and evaluating their impact on state-of-the-art survival models brings two benefits to medical applications. First, it can effectively evaluate the robustness of models in pre-deployment testing. Also, exploring how subtle perturbations would result in significantly different outcomes can provide counterfactual insights into the clinical interpretation of model prediction. In this work, we introduce SurvAttack, a novel black-box adversarial attack framework leveraging subtle clinically compatible, and semantically consistent perturbations on longitudinal EHRs to degrade survival models' predictive performance. We specifically develop a greedy algorithm to manipulate medical codes with various adversarial actions throughout a patient's medical history. Then, these adversarial actions are prioritized using a composite scoring strategy based on multi-aspect perturbation quality, including saliency, perturbation stealthiness, and clinical meaningfulness. The proposed adversarial EHR perturbation algorithm is then used in an efficient SA-specific strategy to attack a survival model when estimating the temporal ranking of survival urgency for patients. To demonstrate the significance of our work, we conduct extensive experiments, including baseline comparisons, explainability analysis, and case studies. The experimental results affirm our research's effectiveness in illustrating the vulnerabilities of patient survival models, model interpretation, and ultimately contributing to healthcare quality.", 'abstract_zh': '生存分析（Survival Analysis, SA）模型在挖掘电子健康记录（Electronic Health Records, EHRs）方面得到了广泛研究，尤其是在预测危重条件的风险以优先处理高风险患者方面。然而，这些模型对对抗性攻击的脆弱性在文献中却鲜有探索。开发黑盒扰动算法并评估其对最先进的生存模型的影响为医疗应用带来了两大好处。首先，这可以有效地在部署前测试中评估模型的健壮性。其次，探索细微扰动如何导致显著不同的结果可以为模型预测的临床解释提供反事实洞察。在本文中，我们提出了SurvAttack，这是一种新颖的黑盒对抗性攻击框架，通过在纵向EHRs中引入细微且临床兼容、语义一致的扰动来削弱生存模型的预测性能。我们特别开发了一种贪婪算法，在患者整个医疗历史中对医学代码进行各种对抗性操作。然后，使用基于多方面扰动质量的综合评分策略对这些对抗性操作进行优先级排序，包括显著性、扰动的隐蔽性和临床意义。所提出的对抗性EHR扰动算法随后在估计患者生存紧迫性的时间排序时使用SA特定策略攻击生存模型。为了证明我们工作的意义，我们进行了广泛的实验，包括基线对比、可解释性分析和案例研究。实验结果验证了我们研究在揭示患者生存模型的脆弱性、模型解释以及最终提高医疗服务质量方面的有效性。', 'title_zh': 'SurvAttack：通过本体指导的电子健康记录扰动对生存模型的黑箱攻击'}
{'arxiv_id': 'arXiv:2412.18702', 'title': 'CypherBench: Towards Precise Retrieval over Full-scale Modern Knowledge Graphs in the LLM Era', 'authors': 'Yanlin Feng, Simone Papicchio, Sajjadur Rahman', 'link': 'https://arxiv.org/abs/2412.18702', 'abstract': 'Retrieval from graph data is crucial for augmenting large language models (LLM) with both open-domain knowledge and private enterprise data, and it is also a key component in the recent GraphRAG system (edge et al., 2024). Despite decades of research on knowledge graphs and knowledge base question answering, leading LLM frameworks (e.g. Langchain and LlamaIndex) have only minimal support for retrieval from modern encyclopedic knowledge graphs like Wikidata. In this paper, we analyze the root cause and suggest that modern RDF knowledge graphs (e.g. Wikidata, Freebase) are less efficient for LLMs due to overly large schemas that far exceed the typical LLM context window, use of resource identifiers, overlapping relation types and lack of normalization. As a solution, we propose property graph views on top of the underlying RDF graph that can be efficiently queried by LLMs using Cypher. We instantiated this idea on Wikidata and introduced CypherBench, the first benchmark with 11 large-scale, multi-domain property graphs with 7.8 million entities and over 10,000 questions. To achieve this, we tackled several key challenges, including developing an RDF-to-property graph conversion engine, creating a systematic pipeline for text-to-Cypher task generation, and designing new evaluation metrics.', 'abstract_zh': '从图数据中检索对于将开放领域知识和私有企业数据补充到大规模语言模型（LLM）中至关重要，并且也是最近GraphRAG系统（edge等，2024）的关键组成部分。尽管在知识图谱和知识库问答方面已有数十年的研究，但主流的LLM框架（如Langchain和LlamaIndex）对现代百科知识图谱（如Wikidata）的检索支持非常有限。在本文中，我们分析了其根本原因，并建议现代RDF知识图谱（如Wikidata、Freebase）对于LLM而言由于其过于庞大的模式（远超出典型的LLM上下文窗口）、资源标识符的使用、重叠的关系类型以及缺乏规范化，因而效率较低。为此，我们提出了一种在底层RDF图基础上的属性图视图，LLM可以使用Cypher高效地查询这些视图。我们在这项研究中以Wikidata为实例，并引入了CypherBench，这是第一个包含11个大型、多领域属性图的数据集，拥有780万个实体和超过10000个问题。为实现这一目标，我们克服了几个关键挑战，包括开发RDF到属性图的转换引擎、创建系统的文本到Cypher任务生成流水线以及设计新的评估指标。', 'title_zh': 'CypherBench：在大语言模型时代精确检索大规模现代知识图谱的方法'}
{'arxiv_id': 'arXiv:2412.18693', 'title': 'Diverse and Effective Red Teaming with Auto-generated Rewards and Multi-step Reinforcement Learning', 'authors': 'Alex Beutel, Kai Xiao, Johannes Heidecke, Lilian Weng', 'link': 'https://arxiv.org/abs/2412.18693', 'abstract': 'Automated red teaming can discover rare model failures and generate challenging examples that can be used for training or evaluation. However, a core challenge in automated red teaming is ensuring that the attacks are both diverse and effective. Prior methods typically succeed in optimizing either for diversity or for effectiveness, but rarely both. In this paper, we provide methods that enable automated red teaming to generate a large number of diverse and successful attacks.\nOur approach decomposes the task into two steps: (1) automated methods for generating diverse attack goals and (2) generating effective attacks for those goals. While we provide multiple straightforward methods for generating diverse goals, our key contributions are to train an RL attacker that both follows those goals and generates diverse attacks for those goals. First, we demonstrate that it is easy to use a large language model (LLM) to generate diverse attacker goals with per-goal prompts and rewards, including rule-based rewards (RBRs) to grade whether the attacks are successful for the particular goal. Second, we demonstrate how training the attacker model with multi-step RL, where the model is rewarded for generating attacks that are different from past attempts further increases diversity while remaining effective. We use our approach to generate both prompt injection attacks and prompts that elicit unsafe responses. In both cases, we find that our approach is able to generate highly-effective and considerably more diverse attacks than past general red-teaming approaches.', 'abstract_zh': '自动化红队攻击可以发现罕见的模型故障，并生成具有挑战性的示例，这些示例可用于训练或评估。然而，在自动化红队攻击中，确保攻击的多样性和有效性是一个核心挑战。以往方法通常只能在这两者之间优化其一，而很少两者兼得。在本文中，我们提供了一种方法，使自动化红队攻击能够生成大量多样且成功的攻击。\n\n我们的方法将任务分解为两个步骤：（1）自动化生成多样化的攻击目标的方法；（2）为这些目标生成有效的攻击。尽管我们提供了多种简单的方法来生成多样化的目标，但我们关键的贡献是训练一个基于强化学习（RL）的攻击者模型，该模型既能遵循这些目标，又能为这些目标生成多样化攻击。首先，我们展示了如何使用大型语言模型（LLM）和目标特定的提示和奖励（包括基于规则的奖励，RBRs）来生成多样化的攻击者目标，并评估攻击是否成功；其次，我们演示了如何通过采用多步RL训练模型，即当模型因生成与以往尝试不同的攻击而受到奖励时，不仅可以增加多样性，还能保持有效性。我们使用这种方法生成了提示注入攻击和引发不安全响应的提示。在两种情况下，我们发现我们的方法能够生成比以往通用红队攻击方法更为有效且多样化的攻击。\n\n这段翻译遵循了学术规范，确保内容准确传达了原文的意思。', 'title_zh': '自动生成奖励与多步强化学习相结合的多样且有效的红队演练方法'}
{'arxiv_id': 'arXiv:2412.18688', 'title': 'Video Is Worth a Thousand Images: Exploring the Latest Trends in Long Video Generation', 'authors': 'Faraz Waseem, Muhammad Shahzad', 'link': 'https://arxiv.org/abs/2412.18688', 'abstract': "An image may convey a thousand words, but a video composed of hundreds or thousands of image frames tells a more intricate story. Despite significant progress in multimodal large language models (MLLMs), generating extended videos remains a formidable challenge. As of this writing, OpenAI's Sora, the current state-of-the-art system, is still limited to producing videos that are up to one minute in length. This limitation stems from the complexity of long video generation, which requires more than generative AI techniques for approximating density functions essential aspects such as planning, story development, and maintaining spatial and temporal consistency present additional hurdles. Integrating generative AI with a divide-and-conquer approach could improve scalability for longer videos while offering greater control. In this survey, we examine the current landscape of long video generation, covering foundational techniques like GANs and diffusion models, video generation strategies, large-scale training datasets, quality metrics for evaluating long videos, and future research areas to address the limitations of the existing video generation capabilities. We believe it would serve as a comprehensive foundation, offering extensive information to guide future advancements and research in the field of long video generation.", 'abstract_zh': '一张图片可能蕴含千言万语，而由数百乃至数千张图像帧组成的视频则讲述一个更为复杂的故事。尽管多模态大规模语言模型（MLLMs）取得了显著进展，生成较长的视频依然是一个严峻的挑战。截至本文撰写之时，OpenAI的Sora仍是当前最先进的系统，也只能生成一分钟以内的视频。这一限制源自于长视频生成的复杂性，这需要不仅仅是生成式AI技术来逼近密度函数，而且规划、故事情节的发展以及保持空间和时间一致性的必要方面也增加了额外的困难。将生成式AI与分而治之的方法结合起来，可以提高生成较长视频的可扩展性并提供更大的控制。在这篇综述中，我们将探讨长视频生成的当前研究景观，涵盖诸如生成对抗网络（GANs）和扩散模型等基础技术、视频生成策略、大规模训练数据集、评估长视频质量的指标，以及未来的研究领域，用以解决现有视频生成能力的限制。我们相信这篇综述将提供一个全面的基础，为长视频生成领域的未来进展和研究提供丰富的信息指导。', 'title_zh': '千图不如一视频：探索长视频生成的最新趋势'}
{'arxiv_id': 'arXiv:2412.18672', 'title': 'From Hallucinations to Facts: Enhancing Language Models with Curated Knowledge Graphs', 'authors': 'Ratnesh Kumar Joshi, Sagnik Sengupta, Asif Ekbal', 'link': 'https://arxiv.org/abs/2412.18672', 'abstract': 'Hallucination, a persistent challenge plaguing language models, undermines their efficacy and trustworthiness in various natural language processing endeavors by generating responses that deviate from factual accuracy or coherence. This paper addresses language model hallucination by integrating curated knowledge graph (KG) triples to anchor responses in empirical data. We meticulously select and integrate relevant KG triples tailored to specific contexts, enhancing factual grounding and alignment with input. Our contribution involves constructing a comprehensive KG repository from Wikipedia and refining data to spotlight essential information for model training. By imbuing language models with access to this curated knowledge, we aim to generate both linguistically fluent responses and deeply rooted in factual accuracy and context relevance. This integration mitigates hallucinations by providing a robust foundation of information, enabling models to draw upon a rich reservoir of factual data during response generation. Experimental evaluations demonstrate the effectiveness of multiple approaches in reducing hallucinatory responses, underscoring the role of curated knowledge graphs in improving the reliability and trustworthiness of language model outputs.', 'abstract_zh': '幻觉，这一持续困扰语言模型的问题，削弱了它们在各种自然语言处理任务中的有效性与可信度，因为它会导致生成与事实不符或缺乏连贯性的回答。本文通过整合精选的知识图谱（KG）三元组，将模型的回答锚定在实证数据之上，从而应对语言模型的幻觉问题。我们精心选择了与特定上下文相关的KG三元组，增强了事实基础并使回答更符合输入内容。我们的贡献包括：从维基百科构建一个全面的KG知识库，并精炼数据以突出模型训练所需的重要信息。通过赋予语言模型访问这些精选知识库的能力，我们旨在生成既富有语言流畅性又在事实准确性与上下文相关性方面扎实的回应。这种整合为模型提供了坚实的信息基础，使其在生成回应时能够依托丰富的事实数据资源，从而减轻幻觉现象。实验评估表明，多种方法在减少幻觉回应方面具有有效性，突显了精选知识图谱对于提高语言模型输出可靠性和可信度的作用。', 'title_zh': '从幻觉到事实：通过精选知识图谱增强语言模型'}
{'arxiv_id': 'arXiv:2412.18653', 'title': '1.58-bit FLUX', 'authors': 'Chenglin Yang, Celong Liu, Xueqing Deng, Dongwon Kim, Xing Mei, Xiaohui Shen, Liang-Chieh Chen', 'link': 'https://arxiv.org/abs/2412.18653', 'abstract': 'We present 1.58-bit FLUX, the first successful approach to quantizing the state-of-the-art text-to-image generation model, FLUX.1-dev, using 1.58-bit weights (i.e., values in {-1, 0, +1}) while maintaining comparable performance for generating 1024 x 1024 images. Notably, our quantization method operates without access to image data, relying solely on self-supervision from the FLUX.1-dev model. Additionally, we develop a custom kernel optimized for 1.58-bit operations, achieving a 7.7x reduction in model storage, a 5.1x reduction in inference memory, and improved inference latency. Extensive evaluations on the GenEval and T2I Compbench benchmarks demonstrate the effectiveness of 1.58-bit FLUX in maintaining generation quality while significantly enhancing computational efficiency.', 'abstract_zh': '我们提出了1.58比特的FLUX，这是第一个成功将最先进的文本到图像生成模型FLUX.1-dev量化到1.58比特权重（即值为{-1, 0, +1}）的方法，同时在生成1024x1024图像时保持类似的性能。值得注意的是，我们的量化方法不依赖于图像数据，仅依靠FLUX.1-dev模型的自监督训练。此外，我们还开发了一种针对1.58比特操作优化的自定义内核，实现了模型存储7.7倍的减少、推理内存5.1倍的减少，并改善了推理延迟。在GenEval和T2I Compbench基准测试中的广泛评估表明，1.58比特的FLUX在保持生成质量的同时，显著提升了计算效率。', 'title_zh': '1.58位FLUX\n\n注：FLUX通常是一个专有名词或特定领域的缩写，在不明确其具体含义的情况下，我直接按照常见的英文词意进行了翻译。如果你能提供FLUX在该论文中的具体含义或领域，我可以给出更准确的翻译。'}
{'arxiv_id': 'arXiv:2412.18644', 'title': 'DynaGRAG: Improving Language Understanding and Generation through Dynamic Subgraph Representation in Graph Retrieval-Augmented Generation', 'authors': 'Karishma Thakrar', 'link': 'https://arxiv.org/abs/2412.18644', 'abstract': 'Graph Retrieval-Augmented Generation (GRAG or Graph RAG) architectures aim to enhance language understanding and generation by leveraging external knowledge. However, effectively capturing and integrating the rich semantic information present in textual and structured data remains a challenge. To address this, a novel GRAG framework is proposed to focus on enhancing subgraph representation and diversity within the knowledge graph. By improving graph density, capturing entity and relation information more effectively, and dynamically prioritizing relevant and diverse subgraphs, the proposed approach enables a more comprehensive understanding of the underlying semantic structure. This is achieved through a combination of de-duplication processes, two-step mean pooling of embeddings, query-aware retrieval considering unique nodes, and a Dynamic Similarity-Aware BFS (DSA-BFS) traversal algorithm. Integrating Graph Convolutional Networks (GCNs) and Large Language Models (LLMs) through hard prompting further enhances the learning of rich node and edge representations while preserving the hierarchical subgraph structure. Experimental results on multiple benchmark datasets demonstrate the effectiveness of the proposed GRAG framework, showcasing the significance of enhanced subgraph representation and diversity for improved language understanding and generation.', 'abstract_zh': '图检索增强生成（GRAG 或 Graph RAG）架构旨在通过利用外部知识来提升语言理解和生成能力。然而，有效捕捉和整合文本和结构化数据中丰富的语义信息仍然是一项挑战。为了解决这个问题，提出了一种新的GRAG框架，该框架专注于增强知识图谱中的子图表示和多样性。通过提高图的密度、更有效地捕捉实体和关系信息，以及动态优先考虑相关且多样化的子图，所提出的方法能够更全面地理解底层的语义结构。这一目标通过去重过程、两步嵌入的均值池化、考虑唯一节点的查询感知检索以及动态相似度感知广度优先搜索（DSA-BFS）遍历算法等多种机制得以实现。通过将图卷积网络（GCNs）和大规模语言模型（LLMs）结合使用，利用强硬提示进一步增强了节点和边的丰富表示能力，同时保持了层次化的子图结构。在多个基准数据集上的实验结果表明，所提出的GRAG框架的有效性，强调了增强子图表示和多样性的显著性，对于提升语言理解和生成具有重要意义。', 'title_zh': 'DynaGRAG：通过图检索增强生成中的动态子图表示提高语言理解和生成能力'}
{'arxiv_id': 'arXiv:2412.18639', 'title': 'A Grounded Observer Framework for Establishing Guardrails for Foundation Models in Socially Sensitive Domains', 'authors': 'Rebecca Ramnauth, Dražen Brščić, Brian Scassellati', 'link': 'https://arxiv.org/abs/2412.18639', 'abstract': 'As foundation models increasingly permeate sensitive domains such as healthcare, finance, and mental health, ensuring their behavior meets desired outcomes and social expectations becomes critical. Given the complexities of these high-dimensional models, traditional techniques for constraining agent behavior, which typically rely on low-dimensional, discrete state and action spaces, cannot be directly applied. Drawing inspiration from robotic action selection techniques, we propose the grounded observer framework for constraining foundation model behavior that offers both behavioral guarantees and real-time variability. This method leverages real-time assessment of low-level behavioral characteristics to dynamically adjust model actions and provide contextual feedback. To demonstrate this, we develop a system capable of sustaining contextually appropriate, casual conversations ("small talk"), which we then apply to a robot for novel, unscripted interactions with humans. Finally, we discuss potential applications of the framework for other social contexts and areas for further research.', 'abstract_zh': '随着基础模型越来越多地渗透到医疗保健、金融和心理健康等敏感领域，确保其行为符合预期结果和社会期望变得愈发重要。考虑到这些高维度模型的复杂性，传统用于限制代理行为的方法，通常依赖于低维度的离散状态和动作空间，已无法直接应用。借鉴机器人动作选择技术，我们提出了一个基于环境观察者的框架，以确保基础模型的行为不仅具有行为保证，还能提供实时的动态调整和情境反馈。该方法通过实时评估低层次的行为特征，动态调整模型的动作，并提供反馈。为了证明这一点，我们开发了一个系统，能够进行适量的、非正式对话（即“闲聊”），并将这一系统应用于机器人，使之能够与人类进行新颖的、未安排脚本的互动。最后，我们讨论了该框架在其他社会情境中的潜在应用，并指出了进一步研究的领域。', 'title_zh': '面向社会敏感领域基础模型的守门人框架的接地观察者范式'}
{'arxiv_id': 'arXiv:2412.18635', 'title': 'Edge-AI for Agriculture: Lightweight Vision Models for Disease Detection in Resource-Limited Settings', 'authors': 'Harsh Joshi', 'link': 'https://arxiv.org/abs/2412.18635', 'abstract': 'This research paper presents the development of a lightweight and efficient computer vision pipeline aimed at assisting farmers in detecting orange diseases using minimal resources. The proposed system integrates advanced object detection, classification, and segmentation models, optimized for deployment on edge devices, ensuring functionality in resource-limited environments. The study evaluates the performance of various state-of-the-art models, focusing on their accuracy, computational efficiency, and generalization capabilities. Notable findings include the Vision Transformer achieving 96 accuracy in orange species classification and the lightweight YOLOv8-S model demonstrating exceptional object detection performance with minimal computational overhead. The research highlights the potential of modern deep learning architectures to address critical agricultural challenges, emphasizing the importance of model complexity versus practical utility. Future work will explore expanding datasets, model compression techniques, and federated learning to enhance the applicability of these systems in diverse agricultural contexts, ultimately contributing to more sustainable farming practices.', 'abstract_zh': '本文研究开发了一种轻量级且高效的计算机视觉管道，旨在使用最少的资源帮助农民检测橙子疾病。所提出系统集成了优化部署于边缘设备上的高级对象检测、分类和分割模型，确保在资源受限环境中功能正常。研究评估了多种最新先进模型的性能，重点关注它们的准确率、计算效率和泛化能力。研究发现，Vision Transformer 在橙子物种分类中的准确率达到96%，而轻量级 YOLOv8-S 模型在最少计算开销的情况下展示了出色的对象检测性能。研究突出了现代深度学习架构在解决关键农业挑战方面的潜力，强调了模型复杂度与实际应用价值之间的权衡。未来的工作将探索扩充数据集、模型压缩技术和联邦学习，以增强这些系统在各种农业环境中的适用性，最终促进更为可持续的农业实践。', 'title_zh': '农业中的边缘人工智能：资源受限环境下的轻量级视觉模型病害检测技术'}
{'arxiv_id': 'arXiv:2412.18619', 'title': 'Next Token Prediction Towards Multimodal Intelligence: A Comprehensive Survey', 'authors': 'Liang Chen, Zekun Wang, Shuhuai Ren, Lei Li, Haozhe Zhao, Yunshui Li, Zefan Cai, Hongcheng Guo, Lei Zhang, Yizhe Xiong, Yichi Zhang, Ruoyu Wu, Qingxiu Dong, Ge Zhang, Jian Yang, Lingwei Meng, Shujie Hu, Yulong Chen, Junyang Lin, Shuai Bai, Andreas Vlachos, Xu Tan, Minjia Zhang, Wen Xiao, Aaron Yee, Tianyu Liu, Baobao Chang', 'link': 'https://arxiv.org/abs/2412.18619', 'abstract': 'Building on the foundations of language modeling in natural language processing, Next Token Prediction (NTP) has evolved into a versatile training objective for machine learning tasks across various modalities, achieving considerable success. As Large Language Models (LLMs) have advanced to unify understanding and generation tasks within the textual modality, recent research has shown that tasks from different modalities can also be effectively encapsulated within the NTP framework, transforming the multimodal information into tokens and predict the next one given the context. This survey introduces a comprehensive taxonomy that unifies both understanding and generation within multimodal learning through the lens of NTP. The proposed taxonomy covers five key aspects: Multimodal tokenization, MMNTP model architectures, unified task representation, datasets \\& evaluation, and open challenges. This new taxonomy aims to aid researchers in their exploration of multimodal intelligence. An associated GitHub repository collecting the latest papers and repos is available at this https URL', 'abstract_zh': '基于自然语言处理中语言模型的基石，下一个词预测（Next Token Prediction, NTP）已经发展成为一种跨多种模态的机器学习任务的多功能训练目标，并取得了显著的成功。随着大型语言模型（Large Language Models, LLMs）的进步，理解与生成任务在文本模态中得到了统一，最近的研究表明，来自不同模态的任务也可以有效地被囊括在NTP框架中，将多模态信息转换为tokens，并在给定上下文的情况下预测下一个token。本文综述通过NTP的视角，提出了一种统一理解与生成的全面分类法，以促进多模态学习。提出的分类法涵盖了五个关键方面：多模态标记化、MMNTP模型架构、统一任务表示、数据集与评估、以及开放挑战。该新分类法旨在帮助研究人员探索多模态智能。此外，我们还提供了一个GitHub仓库，收集了最新的研究论文和代码库，地址如下：[给定的链接]', 'title_zh': '面向多模态智能的下一个-token 预测：一种综合综述'}
{'arxiv_id': 'arXiv:2412.18614', 'title': 'Investigating Acoustic-Textual Emotional Inconsistency Information for Automatic Depression Detection', 'authors': 'Rongfeng Su, Changqing Xu, Xinyi Wu, Feng Xu, Xie Chen, Lan Wangt, Nan Yan', 'link': 'https://arxiv.org/abs/2412.18614', 'abstract': "Previous studies have demonstrated that emotional features from a single acoustic sentiment label can enhance depression diagnosis accuracy. Additionally, according to the Emotion Context-Insensitivity theory and our pilot study, individuals with depression might convey negative emotional content in an unexpectedly calm manner, showing a high degree of inconsistency in emotional expressions during natural conversations. So far, few studies have recognized and leveraged the emotional expression inconsistency for depression detection. In this paper, a multimodal cross-attention method is presented to capture the Acoustic-Textual Emotional Inconsistency (ATEI) information. This is achieved by analyzing the intricate local and long-term dependencies of emotional expressions across acoustic and textual domains, as well as the mismatch between the emotional content within both domains. A Transformer-based model is then proposed to integrate this ATEI information with various fusion strategies for detecting depression. Furthermore, a scaling technique is employed to adjust the ATEI feature degree during the fusion process, thereby enhancing the model's ability to discern patients with depression across varying levels of severity. To best of our knowledge, this work is the first to incorporate emotional expression inconsistency information into depression detection. Experimental results on a counseling conversational dataset illustrate the effectiveness of our method.", 'abstract_zh': '以往的研究已经证明，单一声学情感标签中的情绪特征可以提高抑郁诊断的准确性。此外，根据情绪背景不变性理论以及我们初步研究的结果，患有抑郁的人可能会以意外平静的方式表达负面情绪，在自然对话中表现出情绪表达的高度不一致性。迄今为止，很少有研究认识到并通过情绪表达不一致性来进行抑郁检测。在本文中，我们提出了一种多模态交叉注意力方法，以捕捉声学-文本情绪不一致性（ATEI）信息。通过分析情绪表达在声学和文本领域中的复杂局部和长期依赖关系，以及两个领域内情绪内容之间的不匹配，实现了这一目标。随后，我们提出了一种基于Transformer的模型，并利用多种融合策略将ATEI信息整合进来，用于检测抑郁。此外，我们在融合过程中应用了一种缩放技术，以调整ATEI特征的程度，从而增强模型在不同严重程度患者中的识别能力。据我们所知，这是首次将情绪表达不一致性信息纳入抑郁检测的研究。实验结果表明，我们的方法在咨询对话数据集上具有有效性。', 'title_zh': '探究声学文本情绪不一致性信息在自动抑郁检测中的应用'}
{'arxiv_id': 'arXiv:2409.12797', 'title': 'Efficient Identification of Direct Causal Parents via Invariance and Minimum Error Testing', 'authors': 'Minh Nguyen, Mert R. Sabuncu', 'link': 'https://arxiv.org/abs/2409.12797', 'abstract': 'Invariant causal prediction (ICP) is a popular technique for finding causal parents (direct causes) of a target via exploiting distribution shifts and invariance testing (Peters et al., 2016). However, since ICP needs to run an exponential number of tests and fails to identify parents when distribution shifts only affect a few variables, applying ICP to practical large scale problems is challenging. We propose MMSE-ICP and fastICP, two approaches which employ an error inequality to address the identifiability problem of ICP. The inequality states that the minimum prediction error of the predictor using causal parents is the smallest among all predictors which do not use descendants. fastICP is an efficient approximation tailored for large problems as it exploits the inequality and a heuristic to run fewer tests. MMSE-ICP and fastICP not only outperform competitive baselines in many simulations but also achieve state-of-the-art result on a large scale real data benchmark.', 'abstract_zh': '不变因果预测（ICP）是一种通过利用分布转换和不变性测试来寻找目标的因果父变量（直接原因）的流行技术（Peters等，2016）。然而，由于ICP需要运行指数数量的测试，并且在仅影响少数变量的分布转换情况下无法识别父变量，因此将ICP应用于实际大规模问题存在挑战。我们提出了两种方法MMSE-ICP和fastICP，这两种方法采用误差不等式来解决ICP的可识别性问题。该不等式表明，使用因果父变量的预测器的最小预测误差是所有不使用后代变量的预测器中的最小值。fastICP是一种针对大规模问题的高效近似方法，它利用了该不等式和启发式方法来减少测试数量。MMSE-ICP和fastICP不仅在多种模拟中优于竞争性基线，在大规模实际数据基准测试中也取得了最先进的结果。', 'title_zh': '通过不变性与最小误差测试有效识别直接因果父变量'}
{'arxiv_id': 'arXiv:2408.05109', 'title': 'A Survey of NL2SQL with Large Language Models: Where are we, and where are we going?', 'authors': 'Xinyu Liu, Shuyu Shen, Boyan Li, Peixian Ma, Runzhi Jiang, Yuxin Zhang, Ju Fan, Guoliang Li, Nan Tang, Yuyu Luo', 'link': 'https://arxiv.org/abs/2408.05109', 'abstract': "Translating users' natural language queries (NL) into SQL queries (i.e., NL2SQL, a.k.a., Text-to-SQL) can significantly reduce barriers to accessing relational databases and support various commercial applications. The performance of NL2SQL has been greatly enhanced with the emergence of Large Language Models (LLMs). In this survey, we provide a comprehensive review of NL2SQL techniques powered by LLMs, covering its entire lifecycle from the following four aspects: (1) Model: NL2SQL translation techniques that tackle not only NL ambiguity and under-specification, but also properly map NL with database schema and instances; (2) Data: From the collection of training data, data synthesis due to training data scarcity, to NL2SQL benchmarks; (3) Evaluation: Evaluating NL2SQL methods from multiple angles using different metrics and granularities; and (4) Error Analysis: analyzing NL2SQL errors to find the root cause and guiding NL2SQL models to evolve. Moreover, we provide a rule of thumb for developing NL2SQL solutions. Finally, we discuss the research challenges and open problems of NL2SQL in the LLMs era.", 'abstract_zh': '将用户自然语言查询（NL）转换为SQL查询（即NL2SQL，又称Text-to-SQL）可以显著降低访问关系数据库的壁垒，并支持各种商业应用。随着大型语言模型（LLMs）的出现，NL2SQL性能得到了显著提升。本文综述了由LLMs赋能的NL2SQL技术，从以下四个方面全面回顾了其生命周期：（1）模型：NL2SQL转换技术不仅解决了NL的歧义性和欠具体性问题，还在合理的将NL映射到数据库模式和实例方面也加以处理；（2）数据：从训练数据的收集，因数据稀缺而进行的数据合成，到NL2SQL基准测试；（3）评估：从多个角度、使用不同指标和粒度对NL2SQL方法进行评估；（4）错误分析：分析NL2SQL的错误，找出根本原因，并指导NL2SQL模型的进化。此外，我们提出了开发NL2SQL解决方案的经验法则。最后，我们讨论了LLMs时代下NL2SQL研究中的挑战和开放问题。', 'title_zh': '大规模语言模型下的自然语言到结构化查询转换综述：我们在哪里，以及将要去向何处？'}
