{'arxiv_id': 'arXiv:2501.18536', 'title': 'Illusions of Relevance: Using Content Injection Attacks to Deceive Retrievers, Rerankers, and LLM Judges', 'authors': 'Manveer Singh Tamber, Jimmy Lin', 'link': 'https://arxiv.org/abs/2501.18536', 'abstract': 'Consider a scenario in which a user searches for information, only to encounter texts flooded with misleading or non-relevant content. This scenario exemplifies a simple yet potent vulnerability in neural Information Retrieval (IR) pipelines: content injection attacks. We find that embedding models for retrieval, rerankers, and large language model (LLM) relevance judges are vulnerable to these attacks, in which adversaries insert misleading text into passages to manipulate model judgements. We identify two primary threats: (1) inserting unrelated or harmful content within passages that still appear deceptively "relevant", and (2) inserting entire queries or key query terms into passages to boost their perceived relevance. While the second tactic has been explored in prior research, we present, to our knowledge, the first empirical analysis of the first threat, demonstrating how state-of-the-art models can be easily misled. Our study systematically examines the factors that influence an attack\'s success, such as the placement of injected content and the balance between relevant and non-relevant material. Additionally, we explore various defense strategies, including adversarial passage classifiers, retriever fine-tuning to discount manipulated content, and prompting LLM judges to adopt a more cautious approach. However, we find that these countermeasures often involve trade-offs, sacrificing effectiveness for attack robustness and sometimes penalizing legitimate documents in the process. Our findings highlight the need for stronger defenses against these evolving adversarial strategies to maintain the trustworthiness of IR systems. We release our code and scripts to facilitate further research.', 'abstract_zh': '用户在搜索信息时，往往会遇到充斥着误导性或不相关内容的文本。这种场景揭示了神经信息检索（IR）管道中的一个简单而强大的漏洞：内容注入攻击。我们发现，用于检索、重排和大型语言模型（LLM）相关性判断的嵌入模型都容易受到这些攻击的影响，攻击者会向文段中插入误导性文本以操控模型的判断结果。我们识别出两类主要的威胁：（1）在看似相关但实际上是不相关的文段中插入无关或有害内容；（2）将整个查询或关键查询术语插入文段以提高其感知相关性。虽然第二种战术在以往的研究中已有探索，但据我们所知，本研究首次进行了第一种威胁的实证分析，展示了最先进的模型如何容易被误导。我们系统地研究了影响攻击成功率的各种因素，如插入内容的位置以及相关和不相关材料之间的平衡。此外，我们还探讨了多种防御策略，包括对抗文段分类器、对检索器进行微调以忽略操纵内容，以及提示LLM判断者采取更加谨慎的态度。然而，我们发现这些反制措施常常存在权衡，可能会牺牲有效性以增强攻击抵御能力，并且有时会对合法文档造成惩罚。我们的研究结果强调了需要更强的防御措施来应对不断演变的对抗策略，以维护信息检索系统的可信度。我们发布了代码和脚本，以促进进一步的研究。', 'title_zh': '虚幻的相关性：使用内容注入攻击欺骗检索器、 reranking器和LLM裁判机'}
{'arxiv_id': 'arXiv:2501.18292', 'title': 'Citation Recommendation based on Argumentative Zoning of User Queries', 'authors': 'Shutian Ma, Chengzhi Zhang, Heng Zhang, Zheng Gao', 'link': 'https://arxiv.org/abs/2501.18292', 'abstract': 'Citation recommendation aims to locate the important papers for scholars to cite. When writing the citing sentences, the authors usually hold different citing intents, which are referred to citation function in citation analysis. Since argumentative zoning is to identify the argumentative and rhetorical structure in scientific literature, we want to use this information to improve the citation recommendation task. In this paper, a multi-task learning model is built for citation recommendation and argumentative zoning classification. We also generated an annotated corpus of the data from PubMed Central based on a new argumentative zoning schema. The experimental results show that, by considering the argumentative information in the citing sentence, citation recommendation model will get better performance.', 'abstract_zh': '引用推荐旨在帮助学者找到重要的参考文献。在撰写引用句子时，作者通常具有不同的引用意图，这些意图在引文分析中被称为引文功能。由于论证区划是识别科学文献中的论证和修辞结构，我们希望通过利用这一信息来改进引用推荐任务。在本文中，我们建立了一个多任务学习模型，用于引文推荐和论证区划分类。我们还基于一个新的论证区划方案，从PubMed Central生成了一个标注数据集。实验结果表明，考虑引用句子中的论证信息能够提高引文推荐模型的性能。', 'title_zh': '基于用户查询论证分区的引文推荐'}
{'arxiv_id': 'arXiv:2501.18265', 'title': 'Collecting Cost-Effective, High-Quality Truthfulness Assessments with LLM Summarized Evidence', 'authors': 'Kevin Roitero, Dustin Wright, Michael Soprano, Isabelle Augenstein, Stefano Mizzaro', 'link': 'https://arxiv.org/abs/2501.18265', 'abstract': 'With the degradation of guardrails against mis- and disinformation online, it is more critical than ever to be able to effectively combat it. In this paper, we explore the efficiency and effectiveness of using crowd-sourced truthfulness assessments based on condensed, large language model (LLM) generated summaries of online sources. We compare the use of generated summaries to the use of original web pages in an A/B testing setting, where we employ a large and diverse pool of crowd-workers to perform the truthfulness assessment. We evaluate the quality of assessments, the efficiency with which assessments are performed, and the behavior and engagement of participants. Our results demonstrate that the Summary modality, which relies on summarized evidence, offers no significant change in assessment accuracy over the Standard modality, while significantly increasing the speed with which assessments are performed. Workers using summarized evidence produce a significantly higher number of assessments in the same time frame, reducing the cost needed to acquire truthfulness assessments. Additionally, the Summary modality maximizes both the inter-annotator agreements as well as the reliance on and perceived usefulness of evidence, demonstrating the utility of summarized evidence without sacrificing the quality of assessments.', 'abstract_zh': '随着防范虚假和误导信息护栏的退化，有效地应对这一挑战比以往任何时候都更加重要。在本文中，我们探讨了使用基于大型语言模型（LLM）生成的在线来源摘要的众包事实核查评估的效率和有效性。我们将生成的摘要与原始网页进行比较，在A/B测试设置中，我们采用了一个庞大且多样的众包工人池来进行事实核查评估。我们评估了评估的质量、评估执行的效率以及参与者的行为主动性。我们的结果显示，依赖摘要证据的摘要模态在评估准确性方面并未对标准模态产生显著影响，但在评估执行速度方面却显著提高。使用摘要证据的工人在相同时间内能产生显著更多的评估，从而降低获取事实核查评估的成本。此外，摘要模态最大限度地提高了注释者间的一致性，并增加了对证据的依赖以及对其有用性的感知，证明了摘要证据的有效性，同时未牺牲评估的质量。', 'title_zh': '使用LLM总结的证据收集经济效益高、高质量的可信性评估'}
{'arxiv_id': 'arXiv:2501.18216', 'title': 'Behavior Modeling Space Reconstruction for E-Commerce Search', 'authors': 'Yejing Wang, Chi Zhang, Xiangyu Zhao, Qidong Liu, Maolin Wang, Xuewei Tao, Zitao Liu, Xing Shi, Xudong Yang, Ling Zhong, Wei Lin', 'link': 'https://arxiv.org/abs/2501.18216', 'abstract': "Delivering superior search services is crucial for enhancing customer experience and driving revenue growth. Conventionally, search systems model user behaviors by combining user preference and query item relevance statically, often through a fixed logical 'and' relationship. This paper reexamines existing approaches through a unified lens using both causal graphs and Venn diagrams, uncovering two prevalent yet significant issues: entangled preference and relevance effects, and a collapsed modeling space. To surmount these challenges, our research introduces a novel framework, DRP, which enhances search accuracy through two components to reconstruct the behavior modeling space. Specifically, we implement preference editing to proactively remove the relevance effect from preference predictions, yielding untainted user preferences. Additionally, we employ adaptive fusion, which dynamically adjusts fusion criteria to align with the varying patterns of relevance and preference, facilitating more nuanced and tailored behavior predictions within the reconstructed modeling space. Empirical validation on two public datasets and a proprietary search dataset underscores the superiority of our proposed methodology, demonstrating marked improvements in performance over existing approaches.", 'abstract_zh': '提供卓越的搜索服务对于提升客户体验和推动收入增长至关重要。传统上，搜索系统通过静态结合用户偏好和查询项的相关性来建模用户行为，常常通过固定的逻辑“与”关系实现。本文通过统一的视角重新审视现有方法，并利用因果图和文恩图展开分析，发现两个普遍而重要的问题：交织的偏好和相关性效应以及压缩的建模空间。为克服这些挑战，我们的研究引入了一个新的框架——DRP，该框架通过两个组成部分来重构行为建模空间，从而提高搜索精度。具体而言，我们实施了偏好编辑，主动地从偏好预测中去除相关性效应，从而得到未被污染的用户偏好。此外，我们采用自适应融合，该方法根据相关性和偏好的变化模式动态调整融合标准，从而在重构的建模空间中实现更细微和个性化的行为预测。针对两个公开数据集和一个私有搜索数据集的实证验证表明，我们提出的方法具有显著优势，在性能上明显优于现有方法。', 'title_zh': '电子商务搜索中的行为建模空间重构'}
{'arxiv_id': 'arXiv:2501.18177', 'title': 'Investigating Tax Evasion Emergence Using Dual Large Language Model and Deep Reinforcement Learning Powered Agent-based Simulation', 'authors': 'Teddy Lazebnik, Labib Shami', 'link': 'https://arxiv.org/abs/2501.18177', 'abstract': 'Tax evasion, usually the largest component of an informal economy, is a persistent challenge over history with significant socio-economic implications. Many socio-economic studies investigate its dynamics, including influencing factors, the role and influence of taxation policies, and the prediction of the tax evasion volume over time. These studies assumed such behavior is given, as observed in the real world, neglecting the "big bang" of such activity in a population. To this end, computational economy studies adopted developments in computer simulations, in general, and recent innovations in artificial intelligence (AI), in particular, to simulate and study informal economy appearance in various socio-economic settings. This study presents a novel computational framework to examine the dynamics of tax evasion and the emergence of informal economic activity. Employing an agent-based simulation powered by Large Language Models and Deep Reinforcement Learning, the framework is uniquely designed to allow informal economic behaviors to emerge organically, without presupposing their existence or explicitly signaling agents about the possibility of evasion. This provides a rigorous approach for exploring the socio-economic determinants of compliance behavior. The experimental design, comprising model validation and exploratory phases, demonstrates the framework\'s robustness in replicating theoretical economic behaviors. Findings indicate that individual personality traits, external narratives, enforcement probabilities, and the perceived efficiency of public goods provision significantly influence both the timing and extent of informal economic activity. The results underscore that efficient public goods provision and robust enforcement mechanisms are complementary; neither alone is sufficient to curtail informal activity effectively.', 'abstract_zh': '税收 evasion 通常是非正式经济中最大的组成部分，一直是历史上一个持久的挑战，具有显著的经济社会影响。许多经济社会研究探讨了税收 evasion 的动态，包括影响因素、税收政策的作用和影响，以及税收 evasion 规模的预测。这些研究假设这种行为是给定的，基于现实世界中的观察，忽略了这种活动在人群中的“突变”。为此，计算经济学研究采用了计算机模拟的一般发展，尤其是最近人工智能（AI）的创新成果，来模拟和研究在不同经济社会环境中的非正式经济活动出现。\n\n本研究提出了一种新的计算框架，以探讨税收 evasion 的动态及其非正式经济活动的产生。通过基于大型语言模型和深度强化学习的代理基础仿真，该框架独特地设计了无需假设其存在或明确指示代理存在逃税可能性的方法，从而使其有机地产生非正式经济行为。这种方法为探索合规行为的经济社会决定因素提供了严谨的方法。实验设计包括模型验证和探索阶段，展示了该框架在重现理论经济行为方面的稳健性。研究结果表明，个体人格特质、外部叙述、实施可能性以及公共物品提供效率显著影响非正式经济活动的时间和规模。研究结果强调了高效的公共物品提供和严格的执法机制之间的互补性；两者单独均不足以有效遏制非正式活动。', 'title_zh': '使用双大型语言模型和深度强化学习驱动的基于代理的仿真研究逃税行为的 emergence'}
{'arxiv_id': 'arXiv:2501.18126', 'title': 'HyperZero: A Customized End-to-End Auto-Tuning System for Recommendation with Hourly Feedback', 'authors': 'Xufeng Cai, Ziwei Guan, Lei Yuan, Ali Selman Aydin, Tengyu Xu, Boying Liu, Wenbo Ren, Renkai Xiang, Songyi He, Haichuan Yang, Serena Li, Mingze Gao, Yue Weng, Ji Liu', 'link': 'https://arxiv.org/abs/2501.18126', 'abstract': 'Modern recommendation systems can be broadly divided into two key stages: the ranking stage, where the system predicts various user engagements (e.g., click-through rate, like rate, follow rate, watch time), and the value model stage, which aggregates these predictive scores through a function (e.g., a linear combination defined by a weight vector) to measure the value of each content by a single numerical score. Both stages play roughly equally important roles in real industrial systems; however, how to optimize the model weights for the second stage still lacks systematic study. This paper focuses on optimizing the second stage through auto-tuning technology. Although general auto-tuning systems and solutions - both from established production practices and open-source solutions - can address this problem, they typically require weeks or even months to identify a feasible solution. Such prolonged tuning processes are unacceptable in production environments for recommendation systems, as suboptimal value models can severely degrade user experience. An effective auto-tuning solution is required to identify a viable model within 2-3 days, rather than the extended timelines typically associated with existing approaches. In this paper, we introduce a practical auto-tuning system named HyperZero that addresses these time constraints while effectively solving the unique challenges inherent in modern recommendation systems. Moreover, this framework has the potential to be expanded to broader tuning tasks within recommendation systems.', 'abstract_zh': '现代推荐系统可以大致分为两个关键阶段：排序阶段，在该阶段中，系统预测用户的各种参与度（例如点击率、点赞率、关注率、观看时长），以及值模型阶段，在该阶段中，通过一个函数（例如由权重向量定义的线性组合）将这些预测得分聚合起来，计算每项内容的单个数值评分。在这两个阶段中，它们在实际工业系统中的作用相当重要；然而，如何优化第二阶段的模型权重仍然缺乏系统的研究所揭示。本文专注于通过自动调优技术优化第二阶段。尽管现有的自动化调优系统和解决方案（无论是来自成熟的生产实践还是开源方案）都能解决这个问题，但它们通常需要几周甚至几个月的时间来找到一个可行的解决方案。在推荐系统实际运行环境中，如此漫长的调优过程是不可接受的，因为不合适的价值模型会严重影响用户体验。需要有效的自动调优解决方案能够在2-3天内识别出可行的模型，而不是现有方法通常所需的时间线。在本文中，我们介绍了名为HyperZero的实用自动调优系统，该系统不仅能够满足时间约束，还能有效解决现代推荐系统所固有的独特挑战。此外，该框架还有潜力扩展到推荐系统中的更广泛调优任务。', 'title_zh': 'HyperZero：一种基于每小时反馈的推荐系统端到端自调优定制系统'}
{'arxiv_id': 'arXiv:2501.18117', 'title': 'Improving Minimax Group Fairness in Sequential Recommendation', 'authors': 'Krishna Acharya, David Wardrope, Timos Korres, Aleksandr Petrov, Anders Uhrenholt', 'link': 'https://arxiv.org/abs/2501.18117', 'abstract': "Training sequential recommenders such as SASRec with uniform sample weights achieves good overall performance but can fall short on specific user groups. One such example is popularity bias, where mainstream users receive better recommendations than niche content viewers. To improve recommendation quality across diverse user groups, we explore three Distributionally Robust Optimization(DRO) methods: Group DRO, Streaming DRO, and Conditional Value at Risk (CVaR) DRO. While Group and Streaming DRO rely on group annotations and struggle with users belonging to multiple groups, CVaR does not require such annotations and can naturally handle overlapping groups. In experiments on two real-world datasets, we show that the DRO methods outperform standard training, with CVaR delivering the best results. Additionally, we find that Group and Streaming DRO are sensitive to the choice of group used for loss computation. Our contributions include (i) a novel application of CVaR to recommenders, (ii) showing that the DRO methods improve group metrics as well as overall performance, and (iii) demonstrating CVaR's effectiveness in the practical scenario of intersecting user groups.", 'abstract_zh': '使用均匀样本权重训练诸如SASRec之类的序列推荐器可以取得良好的整体性能，但在特定用户群体上可能会有所欠缺。例如，在主流用户收到更好的推荐时，长尾内容查看者可能会受到“流行偏向”的影响。为了在不同用户群体中提高推荐质量，我们探索了三种分布鲁棒优化（DRO）方法：组DRO、流式DRO和条件值风险（CVaR）DRO。组DRO和流式DRO依赖于组注释，并且在处理属于多个组的用户时存在困难，而CVaR则不需要这样的注释，并且可以自然地处理重叠组。在两个真实数据集上的实验结果显示，DRO方法优于标准训练方法，其中CVaR表现最优。此外，我们发现组DRO和流式DRO对用于损失计算的组的选择非常敏感。我们的贡献包括：(i) 将CVaR应用于推荐器的新颖应用；(ii) 证明DRO方法可以提高组指标以及整体性能；(iii) 在用户组交集的实际应用场景中展示了CVaR的有效性。', 'title_zh': '提高顺序推荐中的极致公幁性'}
{'arxiv_id': 'arXiv:2501.18056', 'title': 'RL-based Query Rewriting with Distilled LLM for online E-Commerce Systems', 'authors': 'Duy A. Nguyen, Rishi Kesav Mohan, Van Yang, Pritom Saha Akash, Kevin Chen-Chuan Chang', 'link': 'https://arxiv.org/abs/2501.18056', 'abstract': 'Query rewriting (QR) is a critical technique in e-commerce search, addressing the lexical gap between user queries and product descriptions to enhance search performance. Existing QR approaches typically fall into two categories: discriminative models and generative methods leveraging large language models (LLMs). Discriminative models often struggle with natural language understanding and offer limited flexibility in rewriting, while generative LLMs, despite producing high-quality rewrites, face high inference latency and cost in online settings. These limitations force offline deployment, making them vulnerable to issues like information staleness and semantic drift. To overcome these challenges, we propose a novel hybrid pipeline for QR that balances efficiency and effectiveness. Our approach combines offline knowledge distillation to create a lightweight but efficient student model with online reinforcement learning (RL) to refine query rewriting dynamically using real-time feedback. A key innovation is the use of LLMs as simulated human feedback, enabling scalable reward signals and cost-effective evaluation without manual annotations. Experimental results on Amazon ESCI dataset demonstrate significant improvements in query relevance, diversity, and adaptability, as well as positive feedback from the LLM simulation. This work contributes to advancing LLM capabilities for domain-specific applications, offering a robust solution for dynamic and complex e-commerce search environments.', 'abstract_zh': '查询重写（Query Rewriting, QR）是电子商务搜索中的一个关键技术，用于弥合用户查询与产品描述之间的词汇差距，从而提高搜索性能。现有的QR方法通常可以分为两类：判别模型和利用大规模语言模型（LLMs）的生成方法。判别模型在自然语言理解方面往往表现不足，灵活性有限；而生成的LLMs虽然可以生成高质量的重写，但在在线环境中面临高昂的推理延迟和成本问题。这些限制迫使它们进行离线部署，使它们容易受到信息过时和语义漂移等问题的影响。为了解决这些问题，我们提出了一种新的混合管道方法，以平衡效率和有效性。我们的方法结合了离线知识蒸馏来创建一个轻量级但高效的student模型，并在线使用强化学习（RL）根据实时反馈动态改进查询重写。一个关键的创新在于使用LLMs作为模拟的人类反馈，这使得奖励信号的标定更加可扩展，同时也提供了一种经济有效的评估方法，无需人工注释。我们在Amazon ESCI数据集上的实验结果表明，在查询相关性、多样性和适应性方面取得了显著的改进，并且LLM模拟得到了积极的反馈。这项工作有助于推进LLMs在特定领域应用中的能力，并为动态和复杂的电子商务搜索环境提供了一个稳健的解决方案。', 'title_zh': '基于RL的查询重写方法：结合精炼的LLM在线电子商务系统中的应用'}
{'arxiv_id': 'arXiv:2501.17981', 'title': 'Can Generative LLMs Create Query Variants for Test Collections? An Exploratory Study', 'authors': 'Marwah Alaofi, Luke Gallagher, Mark Sanderson, Falk Scholer, Paul Thomas', 'link': 'https://arxiv.org/abs/2501.17981', 'abstract': 'This paper explores the utility of a Large Language Model (LLM) to automatically generate queries and query variants from a description of an information need. Given a set of information needs described as backstories, we explore how similar the queries generated by the LLM are to those generated by humans. We quantify the similarity using different metrics and examine how the use of each set would contribute to document pooling when building test collections. Our results show potential in using LLMs to generate query variants. While they may not fully capture the wide variety of human-generated variants, they generate similar sets of relevant documents, reaching up to 71.1% overlap at a pool depth of 100.', 'abstract_zh': '本文探讨了大型语言模型（LLM）在从信息需求描述中自动生成查询及其变体方面的效用。给定一组以背景故事形式描述的信息需求，我们研究了LLM生成的查询与人类生成的查询之间的相似性。我们使用不同的度量标准量化这种相似性，并探讨每种方法在构建测试集合时对文档汇集的贡献。研究结果表明，使用LLM生成查询变体具有潜在价值。虽然它们可能无法完全捕捉到人类生成的广泛变体，但它们能够生成相似的相关文档集合，在100个文档池深度时重叠率达到71.1%。', 'title_zh': '生成式大型语言模型能否为测试集合创建查询变体？一项探索性研究'}
{'arxiv_id': 'arXiv:2501.17969', 'title': "LLMs can be Fooled into Labelling a Document as Relevant (best caf\\'e near me; this paper is perfectly relevant)", 'authors': 'Marwah Alaofi, Paul Thomas, Falk Scholer, Mark Sanderson', 'link': 'https://arxiv.org/abs/2501.17969', 'abstract': 'LLMs are increasingly being used to assess the relevance of information objects. This work reports on experiments to study the labelling of short texts (i.e., passages) for relevance, using multiple open-source and proprietary LLMs. While the overall agreement of some LLMs with human judgements is comparable to human-to-human agreement measured in previous research, LLMs are more likely to label passages as relevant compared to human judges, indicating that LLM labels denoting non-relevance are more reliable than those indicating relevance.\nThis observation prompts us to further examine cases where human judges and LLMs disagree, particularly when the human judge labels the passage as non-relevant and the LLM labels it as relevant. Results show a tendency for many LLMs to label passages that include the original query terms as relevant. We, therefore, conduct experiments to inject query words into random and irrelevant passages, not unlike the way we inserted the query "best café near me" into this paper. The results show that LLMs are highly influenced by the presence of query words in the passages under assessment, even if the wider passage has no relevance to the query. This tendency of LLMs to be fooled by the mere presence of query words demonstrates a weakness in our current measures of LLM labelling: relying on overall agreement misses important patterns of failures. There is a real risk of bias in LLM-generated relevance labels and, therefore, a risk of bias in rankers trained on those labels.\nWe also investigate the effects of deliberately manipulating LLMs by instructing them to label passages as relevant, similar to the instruction "this paper is perfectly relevant" inserted above. We find that such manipulation influences the performance of some LLMs, highlighting the critical need to consider potential vulnerabilities when deploying LLMs in real-world applications.', 'abstract_zh': '大型语言模型（LLMs）越来越多地被用来评估信息对象的相关性。本研究报告了使用多种开源和专有LLMs对简短文本（即段落）进行相关性标注的实验。虽然某些LLMs与人类判断的一致性程度与以往研究中测量的人类之间的一致性相当，但LLMs将段落标记为相关性的频率高于人类评判者，表明LLMs表示不相关性的标签比表示相关性的标签更可靠。\n\n这一观察促使我们进一步研究人类评判者和LLMs存在分歧的案例，特别是当人类评判者将段落标记为不相关，而LLMs将其标记为相关时。结果表明，许多LLMs倾向于将包含原始查询词的段落标记为相关。因此，我们进行了实验，在随机且无关的段落中注入查询词，类似于我们在本文中插入查询词“最佳附近的咖啡馆”那样。结果表明，评估过程中段落中查询词的存在对LLMs有很大影响，即使更广泛的内容与查询无关。LLMs被查询词的存在误导的趋势表明我们当前的LLM标签指标存在缺陷：仅依赖整体一致性忽略了重要的失败模式。LLMs生成的相关性标签存在偏差风险，这进而导致使用这些标签训练的排名器也存在偏差风险。\n\n我们还研究了故意操控LLMs的效果，例如指示它们将段落标记为相关，类似于上面插入的“本文完全相关”指令。我们发现这种操控影响了一些LLMs的性能，这突显了在实际应用中部署LLMs时需要考虑潜在脆弱性的关键需求。', 'title_zh': '大型语言模型可以被欺骗，将一份文档标记为相关（如：“最近的最好咖啡馆在哪里；本文完全相关”）'}
{'arxiv_id': 'arXiv:2501.18539', 'title': 'Can we Retrieve Everything All at Once? ARM: An Alignment-Oriented LLM-based Retrieval Method', 'authors': 'Peter Baile Chen, Yi Zhang, Michael Cafarella, Dan Roth', 'link': 'https://arxiv.org/abs/2501.18539', 'abstract': "Real-world open-domain questions can be complicated, particularly when answering them involves information from multiple information sources. LLMs have demonstrated impressive performance in decomposing complex tasks into simpler steps, and previous work has used it for better retrieval in support of complex questions. However, LLM's decomposition of questions is unaware of what data is available and how data is organized, often leading to a sub-optimal retrieval performance. Recent effort in agentic RAG proposes to perform retrieval in an iterative fashion, where a followup query is derived as an action based on previous rounds of retrieval. While this provides one way of interacting with the data collection, agentic RAG's exploration of data is inefficient because successive queries depend on previous results rather than being guided by the organization of available data in the collection. To address this problem, we propose an LLM-based retrieval method -- ARM, that aims to better align the question with the organization of the data collection by exploring relationships among data objects beyond matching the utterance of the query, thus leading to a retrieve-all-at-once solution for complex queries. We evaluated ARM on two datasets, Bird and OTT-QA. On Bird, it outperforms standard RAG with query decomposition by up to 5.2 pt in execution accuracy and agentic RAG (ReAct) by up to 15.9 pt. On OTT-QA, it achieves up to 5.5 pt and 19.3 pt higher F1 match scores compared to these approaches.", 'abstract_zh': '现实世界中的开放域问题可以相当复杂，特别是在回答这些问题时需要从多个信息源获取信息。大规模语言模型（LLMs）在将复杂任务分解为简单步骤方面表现出色，并且之前的工作已经利用这一点来改进复杂问题的支持检索。然而，LLM对于问题的分解往往忽略了可用数据及其组织方式，这常常导致检索性能不佳。最近关于代理性检索增强生成（RAG）的努力提出了一种迭代的检索方式，其中后续查询根据上一轮检索的结果来推导并作为动作使用。虽然这一方式提供了一种与数据集交互的方法，但代理性RAG的数据探索效率不高，因为后续查询依赖于之前的检索结果，而不是根据可用数据在集合中的组织方式进行指导。为了解决这个问题，我们提出了一种基于LLM的检索方法——ARM，其目标是在超越查询表达匹配对象关系的基础上更好地将问题与数据集合的组织方式相匹配，从而为复杂查询提供一次性检索全部的解决方案。我们在两个数据集，Bird和OTT-QA上对ARM进行了评估。在Bird数据集上，ARM在执行准确性上比标准RAG（配有查询分解）高出至多5.2个百分点，并比ReAct（代理性RAG）高出至多15.9个百分点。在OTT-QA数据集上，ARM的F1匹配分数分别比这些方法高出至多5.5个百分点和19.3个百分点。', 'title_zh': '当然，可以将其翻译为符合学术规范的中文标题：\n\n《一次性检索所有内容可行吗？ARM：一种面向对齐的基于语言模型的检索方法》'}
{'arxiv_id': 'arXiv:2501.18365', 'title': 'RbFT: Robust Fine-tuning for Retrieval-Augmented Generation against Retrieval Defects', 'authors': 'Yiteng Tu, Weihang Su, Yujia Zhou, Yiqun Liu, Qingyao Ai', 'link': 'https://arxiv.org/abs/2501.18365', 'abstract': 'Retrieval-augmented generation (RAG) enhances large language models (LLMs) by integrating external knowledge retrieved from a knowledge base. However, its effectiveness is fundamentally constrained by the reliability of both the retriever and the knowledge base. In real-world scenarios, imperfections in these components often lead to the retrieval of noisy, irrelevant, or misleading counterfactual information, ultimately undermining the trustworthiness of RAG systems. To address this challenge, we propose Robust Fine-Tuning (RbFT), a method designed to enhance the resilience of LLMs against retrieval defects through two targeted fine-tuning tasks. Experimental results demonstrate that RbFT significantly improves the robustness of RAG systems across diverse retrieval conditions, surpassing existing methods while maintaining high inference efficiency and compatibility with other robustness techniques.', 'abstract_zh': '检索增强生成（RAG）通过将来自知识库的外部知识整合到大型语言模型（LLMs）中来增强其性能。然而，其有效性从根本上受到检索器和知识库可靠性的影响。在现实世界情境中，这些组件中的不足往往导致检索出噪声、无关或误导性的反事实信息，从而削弱了RAG系统的可信度。为了应对这一挑战，我们提出了鲁棒微调（RbFT）方法，这是一种旨在通过两个针对性的微调任务来增强LLMs对检索缺陷的抵抗力的方法。实验结果表明，RbFT 显著提高了RAG系统在各种检索条件下的鲁棒性，同时保持了高推理效率，并且与现有的鲁棒性技术兼容。', 'title_zh': 'RbFT：针对检索缺陷的鲁棒微调以增强生成检索方法'}
{'arxiv_id': 'arXiv:2501.18210', 'title': 'Hashtag Re-Appropriation for Audience Control on Recommendation-Driven Social Media Xiaohongshu (rednote)', 'authors': "Ruyuan Wan, Lingbo Tong, Tiffany Knearem, Toby Jia-Jun Li, Ting-Hao 'Kenneth' Huang, Qunfang Wu", 'link': 'https://arxiv.org/abs/2501.18210', 'abstract': "Algorithms have played a central role in personalized recommendations on social media. However, they also present significant obstacles for content creators trying to predict and manage their audience reach. This issue is particularly challenging for marginalized groups seeking to maintain safe spaces. Our study explores how women on Xiaohongshu (rednote), a recommendation-driven social platform, proactively re-appropriate hashtags (e.g., #Baby Supplemental Food) by using them in posts unrelated to their literal meaning. The hashtags were strategically chosen from topics that would be uninteresting to the male audience they wanted to block. Through a mixed-methods approach, we analyzed the practice of hashtag re-appropriation based on 5,800 collected posts and interviewed 24 active users from diverse backgrounds to uncover users' motivations and reactions towards the re-appropriation. This practice highlights how users can reclaim agency over content distribution on recommendation-driven platforms, offering insights into self-governance within algorithmic-centered power structures.", 'abstract_zh': '算法在社交媒体上的个性化推荐中扮演了核心角色。然而，它们也给内容创作者带来重大障碍，使其难以预测和管理其受众的覆盖范围。这一问题对寻求维护安全空间的边缘群体尤为挑战。我们的研究探讨了小红书（Xiaohongshu，一种以推荐驱动的社交平台）上的女性如何主动重新利用热门标签（例如，#辅食）来在内容发布中偏离这些标签的字面含义。这些标签是从那些他们想要屏蔽的男性受众可能不感兴趣的热门话题中精心挑选出来的。通过混合方法，我们基于5800条收集到的帖子进行了分析，并对24位来自不同背景的活跃用户进行了访谈，以揭示用户对重新利用热门标签动机和反应。这一做法展示了用户如何在推荐驱动的平台上重新掌握内容分发的主动权，为我们提供了一些建议，即如何在算法主导的权力结构中进行自我治理。', 'title_zh': '基于推荐驱动社交媒体小红书的标签重拾及其对受众控制的应用'}
{'arxiv_id': 'arXiv:2501.16214', 'title': 'Provence: efficient and robust context pruning for retrieval-augmented generation', 'authors': 'Nadezhda Chirkova, Thibault Formal, Vassilina Nikoulina, Stéphane Clinchant', 'link': 'https://arxiv.org/abs/2501.16214', 'abstract': 'Retrieval-augmented generation improves various aspects of large language models (LLMs) generation, but suffers from computational overhead caused by long contexts as well as the propagation of irrelevant retrieved information into generated responses. Context pruning deals with both aspects, by removing irrelevant parts of retrieved contexts before LLM generation. Existing context pruning approaches are however limited, and do not provide a universal model that would be both efficient and robust in a wide range of scenarios, e.g., when contexts contain a variable amount of relevant information or vary in length, or when evaluated on various domains. In this work, we close this gap and introduce Provence (Pruning and Reranking Of retrieVEd relevaNt ContExts), an efficient and robust context pruner for Question Answering, which dynamically detects the needed amount of pruning for a given context and can be used out-of-the-box for various domains. The three key ingredients of Provence are formulating the context pruning task as sequence labeling, unifying context pruning capabilities with context reranking, and training on diverse data. Our experimental results show that Provence enables context pruning with negligible to no drop in performance, in various domains and settings, at almost no cost in a standard RAG pipeline. We also conduct a deeper analysis alongside various ablations to provide insights into training context pruners for future work.', 'abstract_zh': '检索增强生成提高了大规模语言模型（LLMs）生成的各个方面，但长上下文造成的计算开销以及无关检索信息向生成响应传播的问题使其受到影响。上下文剪枝通过在LLM生成之前移除检索上下文中与主题无关的部分，同时解决了这两个方面的问题。现有的上下文剪枝方法存在局限性，无法提供一种既高效又稳健的模型，能够在各种场景下广泛应用，例如上下文包含不同数量的相关信息或长度变化，或者在多种领域进行评估时。本文填补了这一空白，引入了Provence（Pruning and Reranking Of retrieVEd relevaNt ContExts），这是一种高效的上下文剪枝工具，用于问答系统，能够动态检测给定上下文中所需的剪枝量，并且可以在各种领域中直接使用。Provence的三个关键组成部分是将上下文剪枝任务表述为序列标注、统一上下文剪枝与上下文重新排序的能力，并在多样化的数据上进行训练。实验结果显示，Provence能够在多种领域和设置中几乎不增加成本的情况下实现上下文剪枝，而在性能上几乎没有下降。我们还进行了更深入的分析，并通过各种消融实验提供了对未来工作的见解。', 'title_zh': 'Provence：一种高效的鲁棒上下文剪枝方法，用于检索增强生成'}
