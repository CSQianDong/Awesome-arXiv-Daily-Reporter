{'arxiv_id': 'arXiv:2502.13953', 'title': 'Neurosymbolic artificial intelligence via large language models and coherence-driven inference', 'authors': 'Steve Huntsman, Jewell Thomas', 'link': 'https://arxiv.org/abs/2502.13953', 'abstract': 'We devise an algorithm to generate sets of propositions that objectively instantiate graphs that support coherence-driven inference. We then benchmark the ability of large language models (LLMs) to reconstruct coherence graphs from (a straightforward transformation of) propositions expressed in natural language, with promising results from a single prompt to models optimized for reasoning. Combining coherence-driven inference with consistency evaluations by neural models may advance the state of the art in machine cognition.', 'abstract_zh': '我们设计了一个算法，用于生成能够客观地实例化支持共现推理的图的命题集。然后，我们对大型语言模型（LLMs）的能力进行了基准测试，使其能够从自然语言中表达的命题（经过简单的转换）重构共现图，结果显示，仅通过一个提示即可实现对优化推理能力模型的有效性。将共现推理与神经模型的一致性评估相结合，可能促进机器认知领域的最新进展。', 'title_zh': '通过大型语言模型和连贯驱动的推理实现神经符号人工智能'}
{'arxiv_id': 'arXiv:2502.13943', 'title': 'AdaptiveStep: Automatically Dividing Reasoning Step through Model Confidence', 'authors': 'Yuliang Liu, Junjie Lu, Zhaoling Chen, Chaofeng Qu, Jason Klein Liu, Chonghan Liu, Zefan Cai, Yunhui Xia, Li Zhao, Jiang Bian, Chuheng Zhang, Wei Shen, Zhouhan Lin', 'link': 'https://arxiv.org/abs/2502.13943', 'abstract': "Current approaches for training Process Reward Models (PRMs) often involve breaking down responses into multiple reasoning steps using rule-based techniques, such as using predefined placeholder tokens or setting the reasoning step's length into a fixed size. These approaches overlook the fact that specific words do not typically mark true decision points in a text. To address this, we propose AdaptiveStep, a method that divides reasoning steps based on the model's confidence in predicting the next word. This division method provides more decision-making information at each step, enhancing downstream tasks, such as reward model learning. Moreover, our method does not require manual annotation. We demonstrate its effectiveness through experiments with AdaptiveStep-trained PRMs in mathematical reasoning and code generation tasks. Experimental results indicate that the outcome PRM achieves state-of-the-art Best-of-N performance, surpassing greedy search strategy with token-level value-guided decoding, while also reducing construction costs by over 30% compared to existing open-source PRMs. In addition, we provide a thorough analysis and case study on the PRM's performance, transferability, and generalization capabilities.", 'abstract_zh': '当前用于训练过程奖励模型（PRMs）的方法通常涉及使用基于规则的技术将响应拆分为多个推理步骤，例如使用预定义的占位符标记或固定推理步骤的长度。这些方法忽视了特定单词通常不标志着文本中的真实决策点这一事实。为了解决这一问题，我们提出了一种名为AdaptiveStep的方法，该方法根据模型预测下一个单词的信心程度来划分推理步骤。这种划分方法在每个步骤中提供了更多的决策信息，从而增强了下游任务，例如奖励模型的学习。此外，我们的方法不需要手动注释。我们通过使用AdaptiveStep训练的PRMs在数学推理和代码生成任务中的实验验证了其效果。实验结果表明，所得到的PRM在Best-of-N性能上达到了最先进的水平，优于基于token级价值指导解码的贪心搜索策略，并且与现有开源PRMs相比，构建成本降低了超过30%。此外，我们还对PRM的性能、可迁移性和泛化能力进行了详尽的分析和案例研究。', 'title_zh': '自适应步长：通过模型信心自动划分推理步骤'}
{'arxiv_id': 'arXiv:2502.13834', 'title': 'Proving Olympiad Inequalities by Synergizing LLMs and Symbolic Reasoning', 'authors': 'Zenan Li, Zhaoyu Li, Wen Tang, Xian Zhang, Yuan Yao, Xujie Si, Fan Yang, Kaiyu Yang, Xiaoxing Ma', 'link': 'https://arxiv.org/abs/2502.13834', 'abstract': 'Large language models (LLMs) can prove mathematical theorems formally by generating proof steps (\\textit{a.k.a.} tactics) within a proof system. However, the space of possible tactics is vast and complex, while the available training data for formal proofs is limited, posing a significant challenge to LLM-based tactic generation. To address this, we introduce a neuro-symbolic tactic generator that synergizes the mathematical intuition learned by LLMs with domain-specific insights encoded by symbolic methods. The key aspect of this integration is identifying which parts of mathematical reasoning are best suited to LLMs and which to symbolic methods. While the high-level idea of neuro-symbolic integration is broadly applicable to various mathematical problems, in this paper, we focus specifically on Olympiad inequalities (Figure~1). We analyze how humans solve these problems and distill the techniques into two types of tactics: (1) scaling, handled by symbolic methods, and (2) rewriting, handled by LLMs. In addition, we combine symbolic tools with LLMs to prune and rank the proof goals for efficient proof search. We evaluate our framework on 161 challenging inequalities from multiple mathematics competitions, achieving state-of-the-art performance and significantly outperforming existing LLM and symbolic approaches without requiring additional training data.', 'abstract_zh': '大型语言模型（LLMs）可以通过在证明系统中生成证明步骤（即策略）来形式化地证明数学定理。然而，可能的策略空间既庞大又复杂，而可用于形式证明的训练数据有限，这给基于LLM的策略生成带来了重大挑战。为了解决这个问题，我们引入了一种神经符号策略生成器，它将LLM学到的数学直觉与符号方法编码的领域特定见解结合起来。这种集成的关键在于识别哪些部分的数学推理最适合LLM，哪些部分最适合符号方法。尽管神经-符号集成的基本思想适用于各种数学问题，但在本文中，我们具体关注奥林匹克不等式（参见图1）。我们分析了人类如何解决这些问题，并提炼出了两种类型的策略：（1）缩放，由符号方法处理；（2）重写，由LLM处理。此外，我们结合符号工具与LLM来修剪和排序证明目标，以实现高效的证明搜索。我们在来自多个数学竞赛的161个挑战性不等式上评估了我们的框架，实现了最先进的性能，并在无需额外训练数据的情况下显著优于现有的LLM和符号方法。', 'title_zh': '利用LLM与符号推理相结合证明奥林匹克不等式'}
{'arxiv_id': 'arXiv:2502.13820', 'title': 'Scoring Verifiers: Evaluating Synthetic Verification in Code and Reasoning', 'authors': 'Aleksander Ficek, Somshubra Majumdar, Vahid Noroozi, Boris Ginsburg', 'link': 'https://arxiv.org/abs/2502.13820', 'abstract': 'Code verification has recently found great success as a critical component in training large scale reasoning models for coding. Synthetic techniques such as self-generated test cases and reward models provide a way to enhance code capabilities beyond predefined tests. Building on these advancements, we propose new benchmarks designed to systematically evaluate the impact of synthetic verification methods on assessing solution correctness. We introduce HE-R, HE-R+, MBPP-R, and MBPP-R+, which transform existing coding benchmarks into scoring and ranking datasets to evaluate the effectiveness of synthetic verifiers. Using these benchmarks, we analyze synthetic verification methods in standard, reasoning-based, and reward-based LLMs. Our results show that recent reasoning models significantly improve test case generation and that scaling test cases enhances verification accuracy.', 'abstract_zh': '代码验证最近作为大规模推理模型训练中的关键组件取得了巨大成功。合成技术，如自动生成测试案例和奖励模型，提供了一种超越预定义测试的方法来增强代码能力。基于这些进展，我们提出了一种新的基准测试体系，旨在系统评估合成验证方法对评估解决方案正确性的影响。我们引入了HE-R、HE-R+、MBPP-R和MBPP-R+，将现有的编程基准转换为评分和排名的数据集，以评估合成验证器的有效性。使用这些基准测试，我们分析了标准、推理基于和奖励基于的大语言模型（LLM）中的合成验证方法。我们的结果表明，最近的推理模型显著提高了测试案例的生成能力，并且扩展测试案例能够提高验证准确性。', 'title_zh': '评分验证器：评估合成验证在代码和推理中的效果'}
{'arxiv_id': 'arXiv:2502.13769', 'title': 'A consensus set for the aggregation of partial rankings: the case of the Optimal Set of Bucket Orders Problem', 'authors': 'Juan A. Aledo, José A. Gámez, Alejandro Rosete', 'link': 'https://arxiv.org/abs/2502.13769', 'abstract': 'In rank aggregation problems (RAP), the solution is usually a consensus ranking that generalizes a set of input orderings. There are different variants that differ not only in terms of the type of rankings that are used as input and output, but also in terms of the objective function employed to evaluate the quality of the desired output ranking. In contrast, in some machine learning tasks (e.g. subgroup discovery) or multimodal optimization tasks, attention is devoted to obtaining several models/results to account for the diversity in the input data or across the search landscape. Thus, in this paper we propose to provide, as the solution to an RAP, a set of rankings to better explain the preferences expressed in the input orderings. We exemplify our proposal through the Optimal Bucket Order Problem (OBOP), an RAP which consists in finding a single consensus ranking (with ties) that generalizes a set of input rankings codified as a precedence matrix. To address this, we introduce the Optimal Set of Bucket Orders Problem (OSBOP), a generalization of the OBOP that aims to produce not a single ranking as output but a set of consensus rankings. Experimental results are presented to illustrate this proposal, showing how, by providing a set of consensus rankings, the fitness of the solution significantly improves with respect to the one of the original OBOP, without losing comprehensibility.', 'abstract_zh': '在排序聚合问题（RAP）中，解决方案通常是概括一组输入排序的共识排序。不同变体不仅在使用的输入和输出排序类型上有所不同，还在用于评估所需输出排序质量的目标函数上有所不同。相比之下，在一些机器学习任务（例如子群发现）或多模态优化任务中，关注的是获得多个模型/结果，以解释输入数据中的多样性或搜索景观中的多样性。因此，在本文中，我们提出了一种新的解决方案，即将一组排序作为RAP的解决方案，以更好地解释输入排序中表达的偏好。我们通过最优桶序问题（OBOP），一个RAP的实例来举例说明我们的提案，OBOP旨在找到一个概括一组用先行矩阵编码的输入排序的共识排序（可能包含并列）。为了解决这一问题，我们引入了最优桶序集问题（OSBOP），这是OBOP的一种推广，其目标是生成多个共识排序，而非单一排序作为输出。我们展示了实验结果以阐明这一提案，结果显示，通过提供一组共识排序，解决方案的适应度显著提升，同时保持了可理解性，而不失去对原始OBOP解决方案的解释力。', 'title_zh': '最优桶序集合用于部分排名聚合：最优桶序集问题的研究'}
{'arxiv_id': 'arXiv:2502.13743', 'title': 'Inference of Abstraction for Grounded Predicate Logic', 'authors': 'Hiroyuki Kido', 'link': 'https://arxiv.org/abs/2502.13743', 'abstract': 'An important open question in AI is what simple and natural principle enables a machine to reason logically for meaningful abstraction with grounded symbols. This paper explores a conceptually new approach to combining probabilistic reasoning and predicative symbolic reasoning over data. We return to the era of reasoning with a full joint distribution before the advent of Bayesian networks. We then discuss that a full joint distribution over models of exponential size in propositional logic and of infinite size in predicate logic should be simply derived from a full joint distribution over data of linear size. We show that the same process is not only enough to generalise the logical consequence relation of predicate logic but also to provide a new perspective to rethink well-known limitations such as the undecidability of predicate logic, the symbol grounding problem and the principle of explosion. The reproducibility of this theoretical work is fully demonstrated by the included proofs.', 'abstract_zh': '人工智能领域一个重要未解的问题是，是什么简单的且自然的原则能够使机器在有实际意义的抽象推理中利用具体的符号进行逻辑推理。本文探讨了一种结合概率推理和归纳符号推理的新方法。我们回到了概率网络出现之前的全联合分布推理时代。然后，我们讨论了在命题逻辑中全联合分布应是具有线性大小的数据的全联合分布简单推导的结果；在谓词逻辑中，这一全联合分布应是无限大小的数据的全联合分布的简单推导结果。我们表明，同样的推理过程不仅足以泛化谓词逻辑的逻辑结论关系，还能提供一种新的视角来重新思考谓词逻辑的不可判定性、符号接地问题和矛盾原则等著名局限性。本文的理论工作还通过包含的证明完全展现了其可重复性。', 'title_zh': '基于谓词逻辑的抽象推理'}
{'arxiv_id': 'arXiv:2502.13731', 'title': 'Robust Counterfactual Inference in Markov Decision Processes', 'authors': 'Jessica Lally, Milad Kazemi, Nicola Paoletti', 'link': 'https://arxiv.org/abs/2502.13731', 'abstract': 'This paper addresses a key limitation in existing counterfactual inference methods for Markov Decision Processes (MDPs). Current approaches assume a specific causal model to make counterfactuals identifiable. However, there are usually many causal models that align with the observational and interventional distributions of an MDP, each yielding different counterfactual distributions, so fixing a particular causal model limits the validity (and usefulness) of counterfactual inference. We propose a novel non-parametric approach that computes tight bounds on counterfactual transition probabilities across all compatible causal models. Unlike previous methods that require solving prohibitively large optimisation problems (with variables that grow exponentially in the size of the MDP), our approach provides closed-form expressions for these bounds, making computation highly efficient and scalable for non-trivial MDPs. Once such an interval counterfactual MDP is constructed, our method identifies robust counterfactual policies that optimise the worst-case reward w.r.t. the uncertain interval MDP probabilities. We evaluate our method on various case studies, demonstrating improved robustness over existing methods.', 'abstract_zh': '本文探讨了现有马尔可夫决策过程（MDP）的反事实推理方法中的一项关键局限性。当前的方法假设特定的因果模型以使反事实可识别。然而，通常与MDP的观察分布和干预分布相一致的因果模型有很多，每个模型会产生不同的反事实分布，因此固定特定的因果模型限制了反事实推理的有效性和实用性。我们提出了一种新颖的非参数方法，计算所有兼容因果模型下的反事实转移概率的紧界。与以前需要解决大小呈指数增长的变量的难以处理的优化问题的方法不同，我们的方法提供了这些界的具体表达式，使得计算对于复杂的问题特别高效且可扩展。一旦构造了这种区间反事实MDP，我们的方法便能识别出优化与不确定区间MDP概率最差情况奖励的鲁棒反事实策略。我们通过各种案例研究评估了该方法，展示了其相对于现有方法更好的鲁棒性。', 'title_zh': '马尔可夫决策过程中的稳健反事实推理'}
{'arxiv_id': 'arXiv:2502.13701', 'title': 'Causes and Strategies in Multiagent Systems', 'authors': 'Sylvia S. Kerkhove, Natasha Alechina, Mehdi Dastani', 'link': 'https://arxiv.org/abs/2502.13701', 'abstract': "Causality plays an important role in daily processes, human reasoning, and artificial intelligence. There has however not been much research on causality in multi-agent strategic settings. In this work, we introduce a systematic way to build a multi-agent system model, represented as a concurrent game structure, for a given structural causal model. In the obtained so-called causal concurrent game structure, transitions correspond to interventions on agent variables of the given causal model. The Halpern and Pearl framework of causality is used to determine the effects of a certain value for an agent variable on other variables. The causal concurrent game structure allows us to analyse and reason about causal effects of agents' strategic decisions. We formally investigate the relation between causal concurrent game structures and the original structural causal models.", 'abstract_zh': '因果性在日常流程、人类推理和人工智能中扮演着重要角色。然而，对于多智能体的战略设置中的因果性研究却相对较少。在本项工作中，我们介绍了一种系统的方法来构建给定结构性因果模型的多智能体系统模型，该模型表示为并发博弈结构。在所获得的所谓的因果并发博弈结构中，状态转移对应于对给定因果模型中智能体变量所进行的干预。我们利用Halpern和Pearl的因果性框架来确定某个智能体变量特定值对其他变量的影响。因果并发博弈结构使我们能够分析和推断智能体战略决策的因果效应。我们从形式上研究了因果并发博弈结构与原始结构性因果模型之间的关系。', 'title_zh': '多智能体系统中的原因与策略研究'}
{'arxiv_id': 'arXiv:2502.13569', 'title': 'Model Evolution Framework with Genetic Algorithm for Multi-Task Reinforcement Learning', 'authors': 'Yan Yu, Wengang Zhou, Yaodong Yang, Wanxuan Lu, Yingyan Hou, Houqiang Li', 'link': 'https://arxiv.org/abs/2502.13569', 'abstract': "Multi-task reinforcement learning employs a single policy to complete various tasks, aiming to develop an agent with generalizability across different scenarios. Given the shared characteristics of tasks, the agent's learning efficiency can be enhanced through parameter sharing. Existing approaches typically use a routing network to generate specific routes for each task and reconstruct a set of modules into diverse models to complete multiple tasks simultaneously. However, due to the inherent difference between tasks, it is crucial to allocate resources based on task difficulty, which is constrained by the model's structure. To this end, we propose a Model Evolution framework with Genetic Algorithm (MEGA), which enables the model to evolve during training according to the difficulty of the tasks. When the current model is insufficient for certain tasks, the framework will automatically incorporate additional modules, enhancing the model's capabilities. Moreover, to adapt to our model evolution framework, we introduce a genotype module-level model, using binary sequences as genotype policies for model reconstruction, while leveraging a non-gradient genetic algorithm to optimize these genotype policies. Unlike routing networks with fixed output dimensions, our approach allows for the dynamic adjustment of the genotype policy length, enabling it to accommodate models with a varying number of modules. We conducted experiments on various robotics manipulation tasks in the Meta-World benchmark. Our state-of-the-art performance demonstrated the effectiveness of the MEGA framework. We will release our source code to the public.", 'abstract_zh': '多任务强化学习通过单一策略完成各种任务，旨在培养一个能够在不同场景下具有泛化能力的智能体。鉴于任务共享的特征，通过参数共享可以提高智能体的学习效率。现有的方法通常使用路由网络为每个任务生成特定的路径，并重新构建一组模块为多种任务同时处理。然而，由于任务之间的固有差异，根据任务难度分配资源至关重要，这受到模型结构的限制。为此，我们提出了一种基于遗传算法的模型演进框架（MEGA），该框架可以在训练过程中根据任务难度使模型进化。当当前模型对某些任务不足时，框架将自动引入额外模块，提升模型的能力。此外，为了适应我们的模型演进框架，我们引入了一种基因型模块级模型，使用二进制序列作为基因型策略进行模型重构，并采用非梯度遗传算法优化这些基因型策略。与输出维度固定的路由网络不同，我们的方法允许动态调整基因型策略长度，使其能够适应具有不同模块数量的模型。我们在Meta-World基准中的各种机器人操作任务上进行了实验。我们的领先表现证明了MEGA框架的有效性。我们将公开发布我们的源代码。', 'title_zh': '遗传算法驱动的多任务 reinforcement learning 模型演化框架'}
{'arxiv_id': 'arXiv:2502.13516', 'title': 'SPPD: Self-training with Process Preference Learning Using Dynamic Value Margin', 'authors': 'Hao Yi, Qingyang Li, Yulan Hu, Fuzheng Zhang, Di Zhang, Yong Liu', 'link': 'https://arxiv.org/abs/2502.13516', 'abstract': 'Recently, enhancing the numerical and logical reasoning capability of Large Language Models (LLMs) has emerged as a research hotspot. Existing methods face several limitations: inference-phase techniques (e.g., Chain of Thoughts) rely on prompt selection and the pretrained knowledge; sentence-level Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) struggle with step-wise mathematical correctness and depend on stronger models distillation or human annotations; while Reinforcement Learning (RL) approaches incur high GPU memory costs and unstable training. To address these, we propose \\textbf{S}elf-training framework integrating \\textbf{P}rocess \\textbf{P}reference learning using \\textbf{D}ynamic value margin (SPPD). SPPD leverages a process-based Markov Decision Process (MDP) and Bellman optimality equation to derive \\textbf{dynamic value margin} on step-level preference optimization, which employs tree-based self-sampling on model responses \\textbf{without any distillation} from other models. Furthermore, we theoretically prove that SPPD is \\textbf{equivalent to on-policy policy gradient methods} under reward constraints. Experiments on 7B-scale models demonstrate superior performance across in-domain and out-domain mathematical benchmarks. We open-source our code at \\href{this https URL}{this https URL}.', 'abstract_zh': '近年来，提升大规模语言模型（LLMs）的数值和逻辑推理能力已成为研究热点。现有方法面临诸多局限性：推理阶段技术（如链式思考）依赖于提示选择和预训练知识；基于句子的监督微调（SFT）和直接偏好优化（DPO）难以保证逐步的数学正确性，且依赖于更强模型的蒸馏或人工标注；而强化学习（RL）方法则会导致高GPU内存消耗和不稳定的训练效果。为了解决这些问题，我们提出了一种**自训练框架结合过程偏好学习及动态值边缘**（SPPD）的方法。SPPD利用基于过程的马尔可夫决策过程（MDP）和贝尔曼优化方程，进行在步骤层面的偏好优化并引入了一个动态值边缘，这一方法通过基于树的自我采样来利用模型的响应，**无需从其他模型进行蒸馏**。此外，我们从理论上证明，在奖励约束条件下，SPPD等价于在线策略梯度方法。在7B参数规模的模型上进行的实验表明，SPPD在领域内和领域外的数学基准测试中展现出更优越的性能。我们已在GitHub上开源了我们的代码，链接为：[this https URL](this https URL)。', 'title_zh': '自训练与基于动态价值边际的过程偏好学习：SPPD方法'}
{'arxiv_id': 'arXiv:2502.13476', 'title': 'Integration of Agentic AI with 6G Networks for Mission-Critical Applications: Use-case and Challenges', 'authors': 'Sunder Ali Khowaja, Kapal Dev, Muhammad Salman Pathan, Engin Zeydan, Merouane Debbah', 'link': 'https://arxiv.org/abs/2502.13476', 'abstract': 'We are in a transformative era, and advances in Artificial Intelligence (AI), especially the foundational models, are constantly in the news. AI has been an integral part of many applications that rely on automation for service delivery, and one of them is mission-critical public safety applications. The problem with AI-oriented mission-critical applications is the humanin-the-loop system and the lack of adaptability to dynamic conditions while maintaining situational awareness. Agentic AI (AAI) has gained a lot of attention recently due to its ability to analyze textual data through a contextual lens while quickly adapting to conditions. In this context, this paper proposes an AAI framework for mission-critical applications. We propose a novel framework with a multi-layer architecture to realize the AAI. We also present a detailed implementation of AAI layer that bridges the gap between network infrastructure and missioncritical applications. Our preliminary analysis shows that the AAI reduces initial response time by 5.6 minutes on average, while alert generation time is reduced by 15.6 seconds on average and resource allocation is improved by up to 13.4%. We also show that the AAI methods improve the number of concurrent operations by 40, which reduces the recovery time by up to 5.2 minutes. Finally, we highlight some of the issues and challenges that need to be considered when implementing AAI frameworks.', 'abstract_zh': '我们正处在变革的时代，特别是在人工智能（AI）领域，尤其是基础模型方面的最新进展持续受到关注。AI 已经成为众多依赖自动化服务交付的应用的重要组成部分，其中一个关键应用领域是至关重要的公共安全应用。基于AI的至关重要的应用存在的问题是带有人机循环系统的系统以及在保持态势感知的同时对动态条件缺乏适应性。近期，代理型人工智能（Agentic AI, AAI）因其能够通过上下文视角分析文本数据并在条件变化时迅速适应而备受关注。在此背景下，本文提出了一种针对至关重要的应用的AAI框架。我们提出了一种具有多层架构的新型框架以实现AAI。此外，我们还详细介绍了AAI层次结构，该层次结构可以填补网络基础设施与至关重要的应用之间的差距。初步分析表明，AAI可以将初始响应时间平均减少5.6分钟，警报生成时间平均减少15.6秒，并且资源分配改善了13.4%。我们还展示了AAI方法将同时操作的数量提高40%，从而将恢复时间最多缩短5.2分钟。最后，我们讨论了在实施AAI框架时需要考虑的一些问题和挑战。', 'title_zh': '将代理人工智能与6G网络集成用于关键任务应用：案例研究与挑战'}
{'arxiv_id': 'arXiv:2502.13430', 'title': 'Vision-Based Generic Potential Function for Policy Alignment in Multi-Agent Reinforcement Learning', 'authors': 'Hao Ma, Shijie Wang, Zhiqiang Pu, Siyao Zhao, Xiaolin Ai', 'link': 'https://arxiv.org/abs/2502.13430', 'abstract': 'Guiding the policy of multi-agent reinforcement learning to align with human common sense is a difficult problem, largely due to the complexity of modeling common sense as a reward, especially in complex and long-horizon multi-agent tasks. Recent works have shown the effectiveness of reward shaping, such as potential-based rewards, to enhance policy alignment. The existing works, however, primarily rely on experts to design rule-based rewards, which are often labor-intensive and lack a high-level semantic understanding of common sense. To solve this problem, we propose a hierarchical vision-based reward shaping method. At the bottom layer, a visual-language model (VLM) serves as a generic potential function, guiding the policy to align with human common sense through its intrinsic semantic understanding. To help the policy adapts to uncertainty and changes in long-horizon tasks, the top layer features an adaptive skill selection module based on a visual large language model (vLLM). The module uses instructions, video replays, and training records to dynamically select suitable potential function from a pre-designed pool. Besides, our method is theoretically proven to preserve the optimal policy. Extensive experiments conducted in the Google Research Football environment demonstrate that our method not only achieves a higher win rate but also effectively aligns the policy with human common sense.', 'abstract_zh': '将多智能体强化学习的政策引导与人类常识相一致是一个具有挑战性的问题，主要原因是将常识建模为奖励的复杂性，尤其是在复杂的长时间多智能体任务中尤为突出。近期的研究表明，基于潜在函数的奖励塑造等方法能有效提高政策与人类常识的对齐程度。然而，现有的工作主要依赖专家设计基于规则的奖励，这通常耗时且缺乏对常识高层语义的理解。为了解决这一问题，我们提出了一种分层的基于视觉的奖励塑造方法。在最低层，一个视觉-语言模型（VLM）作为通用的潜在函数，通过其内在的语义理解引导政策与人类常识保持一致。为了帮助政策适应长时间任务中的不确定性与变化，最高层采用了一个基于视觉大型语言模型（vLLM）的自适应技能选择模块。该模块利用指令、视频回放和训练记录动态从预先设计的池中选择合适的潜在函数。此外，我们的方法从理论上证明能保持最优政策。在Google Research足球环境中的广泛实验表明，我们的方法不仅提高了胜率，还有效使政策与人类常识保持一致。', 'title_zh': '基于视觉的通用潜在函数在多代理 reinforcement 学习策略对齐中的应用'}
{'arxiv_id': 'arXiv:2502.13392', 'title': 'Atomic Proximal Policy Optimization for Electric Robo-Taxi Dispatch and Charger Allocation', 'authors': 'Jim Dai, Manxi Wu, Zhanhao Zhang', 'link': 'https://arxiv.org/abs/2502.13392', 'abstract': 'Pioneering companies such as Waymo have deployed robo-taxi services in several U.S. cities. These robo-taxis are electric vehicles, and their operations require the joint optimization of ride matching, vehicle repositioning, and charging scheduling in a stochastic environment. We model the operations of the ride-hailing system with robo-taxis as a discrete-time, average reward Markov Decision Process with infinite horizon. As the fleet size grows, the dispatching is challenging as the set of system state and the fleet dispatching action set grow exponentially with the number of vehicles. To address this, we introduce a scalable deep reinforcement learning algorithm, called Atomic Proximal Policy Optimization (Atomic-PPO), that reduces the action space using atomic action decomposition. We evaluate our algorithm using real-world NYC for-hire vehicle data and we measure the performance using the long-run average reward achieved by the dispatching policy relative to a fluid-based reward upper bound. Our experiments demonstrate the superior performance of our Atomic-PPO compared to benchmarks. Furthermore, we conduct extensive numerical experiments to analyze the efficient allocation of charging facilities and assess the impact of vehicle range and charger speed on fleet performance.', 'abstract_zh': '效仿Waymo等先锋企业已在美多个城市部署自动驾驶出租车服务。这些自动驾驶出租车是电动车辆，其运营需要在随机环境中对行程匹配、车辆调度和充电计划进行联合优化。我们将搭载自动驾驶出租车的网约车系统模型化为一个具有无限展望期的离散时间平均奖励马尔可夫决策过程（MDP）。随着车队规模的增长，调度变得极具挑战性，因为系统状态集和调度动作集会随着车辆数量的增加而指数级增长。为了解决这一问题，我们引入了一种可扩展的深度强化学习算法，称为原子级 proximal 政策优化算法（Atomic-PPO），该算法通过原子级动作分解减少了动作空间。我们使用实际的纽约市网约车数据评估了该算法，并通过调度策略相对于基于流体的方法奖励上限实现的长期平均奖励来衡量性能。我们的实验表明，与基准方法相比，我们的Atomic-PPO具有更优的性能。此外，我们还进行了广泛的数值实验，以分析充电设施的有效分配，并评估车辆续航能力和充电速度对车队性能的影响。', 'title_zh': '原子近端策略优化在电动机器人出租车调度与充电站分配中的应用'}
{'arxiv_id': 'arXiv:2502.13389', 'title': 'Reasoning with Reinforced Functional Token Tuning', 'authors': 'Kongcheng Zhang, Qi Yao, Baisheng Lai, Jiaxing Huang, Wenkai Fang, Dacheng Tao, Mingli Song, Shunyu Liu', 'link': 'https://arxiv.org/abs/2502.13389', 'abstract': 'In this work, we propose Reinforced Functional Token Tuning (RFTT), a novel reinforced fine-tuning framework that empowers Large Language Models (LLMs) with self-play learn-to-reason capabilities. Unlike prior prompt-driven reasoning efforts, RFTT embeds a rich set of learnable functional tokens (e.g., <analyze>, <verify>, <refine>) directly into the model vocabulary, enabling chain-of-thought construction with diverse human-like reasoning behaviors. Specifically, RFTT comprises two phases: (1) supervised fine-tuning performs prompt-driven tree search to obtain self-generated training data annotated with functional tokens, which warms up the model to learn these tokens for reasoning; and (2) online reinforcement learning further allows the model to explore different reasoning pathways through functional token sampling without relying on prompts, thereby facilitating effective self-improvement for functional reasoning. Extensive experiments demonstrate the superiority of the proposed RFTT on mathematical benchmarks, significantly boosting Qwen-2.5-7B-Instruct (70.6% to 79.8%) and LLaMA-3.1-8B-Instruct (32.2% to 60.2%) on the MATH dataset. Moreover, the performance of RFTT consistently improves with more search rollouts at inference time. Our code is available at this https URL.', 'abstract_zh': '在这项工作中，我们提出了一种新型的强化函数标记调优框架——强化功能标记调优（RFTT），旨在增强大型语言模型（LLMs）的自博弈学习推理能力。与之前的基于提示的推理努力不同，RFTT 将一组丰富的可学习功能标记（例如 <analyze>、<verify>、<refine>）直接嵌入到模型词汇表中，使模型能够构建具有多种类人类推理行为的推理链条。具体而言，RFTT 包含两个阶段：（1）监督调优通过基于提示的树搜索获取带有功能标记的自动生成训练数据，以预热模型学习这些用于推理的功能标记；（2）在线强化学习进一步允许模型通过功能标记采样探索不同的推理路径，而无需依赖提示，从而促进功能推理的有效自我改进。大量的实验表明，RFTT 在数学基准测试中表现优越，在 MATH 数据集上显著提升了 Qwen-2.5-7B-Instruct（从 70.6% 提高到 79.8%）和 LLaMA-3.1-8B-Instruct（从 32.2% 提高到 60.2%）的效果。此外，我们在推理时进行更多搜索展开时，RFTT 的性能也持续改进。我们的代码可在以下 URL 获取：this https URL。', 'title_zh': '强化功能标记调优的推理方法'}
{'arxiv_id': 'arXiv:2502.13388', 'title': 'Reflection of Episodes: Learning to Play Game from Expert and Self Experiences', 'authors': 'Xiaojie Xu, Zongyuan Li, Chang Lu, Runnan Qi, Yanan Ni, Lumin Jiang, Xiangbei Liu, Xuebo Zhang, Yongchun Fang, Kuihua Huang, Xian Guo, Zhanghua Wu, Zhenya Li', 'link': 'https://arxiv.org/abs/2502.13388', 'abstract': 'StarCraft II is a complex and dynamic real-time strategy (RTS) game environment, which is very suitable for artificial intelligence and reinforcement learning research. To address the problem of Large Language Model(LLM) learning in complex environments through self-reflection, we propose a Reflection of Episodes(ROE) framework based on expert experience and self-experience. This framework first obtains key information in the game through a keyframe selection method, then makes decisions based on expert experience and self-experience. After a game is completed, it reflects on the previous experience to obtain new self-experience. Finally, in the experiment, our method beat the robot under the Very Hard difficulty in TextStarCraft II. We analyze the data of the LLM in the process of the game in detail, verified its effectiveness.', 'abstract_zh': '星际争霸II是一个复杂且动态的即时战略（RTS）游戏环境，非常适合人工智能和强化学习的研究。为了通过自我反思解决大规模语言模型（LLM）在复杂环境中的学习问题，我们提出了基于专家经验和自我经验的事件反思（Reflection of Episodes, ROE）框架。该框架首先通过关键帧选择方法获取游戏中的关键信息，然后基于专家经验和自我经验做出决策。在一场游戏结束后，它会反思之前的经历以获得新的自我经验。最后，在实验中，我们的方法在TextStarCraft II的非常困难模式下击败了机器人。我们详细分析了游戏中大规模语言模型的数据，验证了该方法的有效性。', 'title_zh': '基于片段的反映：从专家和自我经验学习玩游戏'}
{'arxiv_id': 'arXiv:2502.13373', 'title': 'Fighter Jet Navigation and Combat using Deep Reinforcement Learning with Explainable AI', 'authors': 'Swati Kar, Soumyabrata Dey, Mahesh K Banavar, Shahnewaz Karim Sakib', 'link': 'https://arxiv.org/abs/2502.13373', 'abstract': "This paper presents the development of an Artificial Intelligence (AI) based fighter jet agent within a customized Pygame simulation environment, designed to solve multi-objective tasks via deep reinforcement learning (DRL). The jet's primary objectives include efficiently navigating the environment, reaching a target, and selectively engaging or evading an enemy. A reward function balances these goals while optimized hyperparameters enhance learning efficiency. Results show more than 80\\% task completion rate, demonstrating effective decision-making. To enhance transparency, the jet's action choices are analyzed by comparing the rewards of the actual chosen action (factual action) with those of alternate actions (counterfactual actions), providing insights into the decision-making rationale. This study illustrates DRL's potential for multi-objective problem-solving with explainable AI. Project page is available at: \\href{this https URL}{Project GitHub Link}.", 'abstract_zh': '本文介绍了在自定义Pygame仿真环境中开发的一种基于人工智能（AI）的战斗机智能代理的研究成果，该代理通过深度强化学习（DRL）解决多目标任务。飞机的主要目标包括高效导航环境、到达目标以及选择性地与敌人交战或规避。奖励函数平衡了这些目标，优化的超参数提高了学习效率。结果显示任务完成率超过80%，表明其具有有效的决策能力。为了增强透明度，通过将实际选择的行动（事实行动）的奖励与替代行动（假设行动）的奖励进行比较，分析飞机的行动选择，从而深入了解决策过程的依据。本研究展示了可解释AI在基于DRL的多目标问题解决中的潜力。项目页面可以通过以下链接访问：\\href{该项目的GitHub链接}{项目GitHub链接}。', 'title_zh': '使用可解释人工智能的深度强化学习在战斗机导航与作战中的应用'}
{'arxiv_id': 'arXiv:2502.13313', 'title': 'Revisiting Privacy, Utility, and Efficiency Trade-offs when Fine-Tuning Large Language Models', 'authors': 'Soumi Das, Camila Kolling, Mohammad Aflah Khan, Mahsa Amani, Bishwamittra Ghosh, Qinyuan Wu, Till Speicher, Krishna P. Gummadi', 'link': 'https://arxiv.org/abs/2502.13313', 'abstract': 'We study the inherent trade-offs in minimizing privacy risks and maximizing utility, while maintaining high computational efficiency, when fine-tuning large language models (LLMs). A number of recent works in privacy research have attempted to mitigate privacy risks posed by memorizing fine-tuning data by using differentially private training methods (e.g., DP), albeit at a significantly higher computational cost (inefficiency). In parallel, several works in systems research have focussed on developing (parameter) efficient fine-tuning methods (e.g., LoRA), but few works, if any, investigated whether such efficient methods enhance or diminish privacy risks. In this paper, we investigate this gap and arrive at a surprising conclusion: efficient fine-tuning methods like LoRA mitigate privacy risks similar to private fine-tuning methods like DP. Our empirical finding directly contradicts prevailing wisdom that privacy and efficiency objectives are at odds during fine-tuning. Our finding is established by (a) carefully defining measures of privacy and utility that distinguish between memorizing sensitive and non-sensitive tokens in training and test datasets used in fine-tuning and (b) extensive evaluations using multiple open-source language models from Pythia, Gemma, and Llama families and different domain-specific datasets.', 'abstract_zh': '我们研究了在微调大型语言模型（LLMs）时，最小化隐私风险、最大化实用价值与保持高计算效率之间的固有权衡。近期隐私研究中的一些工作通过使用差分隐私训练方法（例如，DP）尝试减轻记忆微调数据引起的隐私风险，尽管这带来了显著更高的计算成本（效率低下）。与此同时，系统研究中的多项工作集中在开发高效的微调方法（例如，LoRA），但很少有工作探讨这些高效方法是否能够增强或削弱隐私风险。在本文中，我们研究了这一缺口，并得出一个令人惊讶的结论：高效的微调方法（如LoRA）在减轻隐私风险方面与差分隐私微调方法（如DP）类似。我们的实证发现直接反驳了长期以来认为隐私和效率目标在微调过程中是相互冲突的普遍观点。这一发现通过以下方式建立（a）仔细定义在微调时用于训练和测试数据集中的敏感和非敏感令牌的隐私和实用性衡量标准；（b）使用Pythia、Gemma和Llama家族的多个开源语言模型以及不同领域的数据集进行了广泛的评估。', 'title_zh': '重新审视微调大规模语言模型时的隐私、效用和效率权衡关系'}
{'arxiv_id': 'arXiv:2502.13295', 'title': 'Demonstrating specification gaming in reasoning models', 'authors': 'Alexander Bondarenko, Denis Volk, Dmitrii Volkov, Jeffrey Ladish', 'link': 'https://arxiv.org/abs/2502.13295', 'abstract': "We demonstrate LLM agent specification gaming by instructing models to win against a chess engine. We find reasoning models like o1 preview and DeepSeek-R1 will often hack the benchmark by default, while language models like GPT-4o and Claude 3.5 Sonnet need to be told that normal play won't work to hack.\nWe improve upon prior work like (Hubinger et al., 2024; Meinke et al., 2024; Weij et al., 2024) by using realistic task prompts and avoiding excess nudging. Our results suggest reasoning models may resort to hacking to solve difficult problems, as observed in OpenAI (2024)'s o1 Docker escape during cyber capabilities testing.", 'abstract_zh': '我们通过指示模型战胜国际象棋引擎来演示大规模语言模型（LLM）代理规范博弈。我们发现，如o1 Preview和DeepSeek-R1这类逻辑推理模型往往会默认作弊，而像GPT-4o和Claude 3.5 Sonnet这类语言模型则需要明确被告知正常对弈无法作弊。\n\n我们改进了前人的工作（如Hubinger等人，2024；Meinke等人，2024；Wei等人，2024），通过使用实际的任务提示并避免过度引导。我们的结果表明，逻辑推理模型可能会为了解决复杂问题而采取作弊手段，这与OpenAI（2024）在网络安全能力测试中观察到的o1 Docker脱逃现象一致。', 'title_zh': '在推理模型中展示规范游戏行为'}
{'arxiv_id': 'arXiv:2502.13170', 'title': 'Unveiling the Magic of Code Reasoning through Hypothesis Decomposition and Amendment', 'authors': 'Yuze Zhao, Tianyun Ji, Wenjun Feng, Zhenya Huang, Qi Liu, Zhiding Liu, Yixiao Ma, Kai Zhang, Enhong Chen', 'link': 'https://arxiv.org/abs/2502.13170', 'abstract': 'The reasoning abilities are one of the most enigmatic and captivating aspects of large language models (LLMs). Numerous studies are dedicated to exploring and expanding the boundaries of this reasoning capability. However, tasks that embody both reasoning and recall characteristics are often overlooked. In this paper, we introduce such a novel task, code reasoning, to provide a new perspective for the reasoning abilities of LLMs. We summarize three meta-benchmarks based on established forms of logical reasoning, and instantiate these into eight specific benchmark tasks. Our testing on these benchmarks reveals that LLMs continue to struggle with identifying satisfactory reasoning pathways. Additionally, we present a new pathway exploration pipeline inspired by human intricate problem-solving methods. This Reflective Hypothesis Decomposition and Amendment (RHDA) pipeline consists of the following iterative steps: (1) Proposing potential hypotheses based on observations and decomposing them; (2) Utilizing tools to validate hypotheses and reflection outcomes; (3) Revising hypothesis in light of observations. Our approach effectively mitigates logical chain collapses arising from forgetting or hallucination issues in multi-step reasoning, resulting in performance gains of up to $3\\times$. Finally, we expanded this pipeline by applying it to simulate complex household tasks in real-world scenarios, specifically in VirtualHome, enhancing the handling of failure cases. We release our code and all of results at this https URL.', 'abstract_zh': '大语言模型（LLMs）的推理能力是最神秘和引人入胜的方面之一。众多研究致力于探索并拓展这一推理能力的边界。然而，同时包含推理和记忆特征的任务往往被忽视。本文我们引入了新型任务——代码推理，为LLMs的推理能力提供新的视角。我们根据现有的逻辑推理形式总结了三个元基准，并将这些形式具体化为八个特定的基准任务。在对这些基准任务进行测试后，我们发现LLMs仍然难以识别满意的推理路径。此外，我们提出了一种新的路径探索管道，灵感来源于人类复杂的解决问题方法。该管道称为反思假设分解与修正(RHDA)管道，由以下迭代步骤组成：（1）基于观察提出潜在假设并对其进行分解；（2）使用工具验证假设和反思结果；（3）根据观察结果修正假设。我们的方法有效地缓解了多步推理中由于遗忘或幻觉问题导致的逻辑链条崩溃问题，从而带来了最多3倍的性能提升。最后，我们通过将其应用于模拟真实场景中的复杂家庭任务（如VirtualHome），扩展了该管道，增加了对失败情况的处理能力。我们在此处发布我们的代码和所有结果：此链接。', 'title_zh': '通过假设分解与修正揭示代码推理的魔力'}
{'arxiv_id': 'arXiv:2502.13149', 'title': 'Bi-Fact: A Bidirectional Factorization-based Evaluation of Intent Extraction from UI Trajectories', 'authors': 'Sapir Caduri', 'link': 'https://arxiv.org/abs/2502.13149', 'abstract': 'Bi-Fact, a novel approach to automatic evaluation for Intent Understanding, is presented. Drawing inspiration from FactScore, Bi-Fact enables fine-grained intent comparison by splitting both gold and predicted intents into facts and calculating precision and recall, considering the UI trajectory. This paper outlines a comprehensive evaluation of Bi-Fact, assessing its performance and comparing it to existing metrics.', 'abstract_zh': 'Bi-Fact是一种新颖的自动评估方法，用于意图理解。该方法受到FactScore的启发，通过将黄金标准意图和预测意图细分为事实，并考虑用户界面轨迹来计算精确度和召回率，从而实现细粒度的意图比较。本文详细介绍了Bi-Fact的全面评估，评估其性能并将其与现有指标进行比较。', 'title_zh': '双向分解：基于双向分解的UI轨迹意图提取评价方法'}
{'arxiv_id': 'arXiv:2502.13965', 'title': 'Autellix: An Efficient Serving Engine for LLM Agents as General Programs', 'authors': 'Michael Luo, Xiaoxiang Shi, Colin Cai, Tianjun Zhang, Justin Wong, Yichuan Wang, Chi Wang, Yanping Huang, Zhifeng Chen, Joseph E. Gonzalez, Ion Stoica', 'link': 'https://arxiv.org/abs/2502.13965', 'abstract': "Large language model (LLM) applications are evolving beyond simple chatbots into dynamic, general-purpose agentic programs, which scale LLM calls and output tokens to help AI agents reason, explore, and solve complex tasks. However, existing LLM serving systems ignore dependencies between programs and calls, missing significant opportunities for optimization. Our analysis reveals that programs submitted to LLM serving engines experience long cumulative wait times, primarily due to head-of-line blocking at both the individual LLM request and the program. To address this, we introduce Autellix, an LLM serving system that treats programs as first-class citizens to minimize their end-to-end latencies. Autellix intercepts LLM calls submitted by programs, enriching schedulers with program-level context. We propose two scheduling algorithms-for single-threaded and distributed programs-that preempt and prioritize LLM calls based on their programs' previously completed calls. Our evaluation demonstrates that across diverse LLMs and agentic workloads, Autellix improves throughput of programs by 4-15x at the same latency compared to state-of-the-art systems, such as vLLM.", 'abstract_zh': '大型语言模型（LLM）的应用正在超越简单的聊天机器人，发展成为动态的、通用的代理程序，这些程序通过扩展LLM调用和输出token来帮助AI代理进行推理、探索和解决复杂的任务。然而，现有的LLM服务系统忽视了程序之间的依赖关系，错失了优化的重要机会。我们分析表明，提交给LLM服务引擎的程序会经历长时间的累计等待时间，主要原因是在单个LLM请求和程序级别上出现了头部阻塞。为了解决这一问题，我们提出了一种名为Autellix的LLM服务系统，将程序视为一等公民，以最小化其端到端的延迟。Autellix拦截程序提交的LLM调用，并为调度器提供程序级别上下文。我们提出了两种调度算法——针对单线程和分布式程序的算法，基于程序之前已完成的调用来预取和优先处理LLM调用。我们的评估表明，与现有的最先进的系统如vLLM相比，Autellix在相同延迟的情况下，将程序的吞吐量提高了4-15倍。', 'title_zh': 'Autellix：一种高效的服务引擎，用于将大型语言模型代理视为通用程序'}
{'arxiv_id': 'arXiv:2502.13964', 'title': 'A Training-Free Framework for Precise Mobile Manipulation of Small Everyday Objects', 'authors': 'Arjun Gupta, Rishik Sathua, Saurabh Gupta', 'link': 'https://arxiv.org/abs/2502.13964', 'abstract': 'Many everyday mobile manipulation tasks require precise interaction with small objects, such as grasping a knob to open a cabinet or pressing a light switch. In this paper, we develop Servoing with Vision Models (SVM), a closed-loop training-free framework that enables a mobile manipulator to tackle such precise tasks involving the manipulation of small objects. SVM employs an RGB-D wrist camera and uses visual servoing for control. Our novelty lies in the use of state-of-the-art vision models to reliably compute 3D targets from the wrist image for diverse tasks and under occlusion due to the end-effector. To mitigate occlusion artifacts, we employ vision models to out-paint the end-effector thereby significantly enhancing target localization. We demonstrate that aided by out-painting methods, open-vocabulary object detectors can serve as a drop-in module to identify semantic targets (e.g. knobs) and point tracking methods can reliably track interaction sites indicated by user clicks. This training-free method obtains an 85% zero-shot success rate on manipulating unseen objects in novel environments in the real world, outperforming an open-loop control method and an imitation learning baseline trained on 1000+ demonstrations by an absolute success rate of 50%.', 'abstract_zh': '许多日常的移动操作任务需要精确地与小型物体进行交互，例如拧开柜门的旋钮或按下开关。在本文中，我们开发了基于视觉模型的伺服控制（Servoing with Vision Models，SVM）框架，该框架使移动操作器能够处理涉及小型物体操作的精确任务。SVM 使用 RGB-D 腕部相机并通过视觉伺服控制来实现。我们的创新之处在于利用先进的视觉模型从腕部图像中可靠地计算出 3D 目标，以应对多种任务并在末端执行器遮挡的情况下保持目标定位的准确性。为了减轻遮挡带来的影响，我们使用视觉模型进行补全，从而大大增强了目标定位的准确性。我们证明，在补全方法的辅助下，开放词汇量的物体检测器可以作为即插即用的模块来识别语义目标（如旋钮），而点跟踪方法可以可靠地追踪用户点击指示的交互点。该无训练方法在真实世界的新环境中对未见过的物体进行操作时达到了 85% 的零样本成功率，优于循环控制方法和基于 1000 多次演示的模仿学习基线，绝对成功率提高了 50%。', 'title_zh': '无需训练的精确移动小型日常物体框架'}
{'arxiv_id': 'arXiv:2502.13957', 'title': 'RAG-Gym: Optimizing Reasoning and Search Agents with Process Supervision', 'authors': 'Guangzhi Xiong, Qiao Jin, Xiao Wang, Yin Fang, Haolin Liu, Yifan Yang, Fangyuan Chen, Zhixing Song, Dengyu Wang, Minjia Zhang, Zhiyong Lu, Aidong Zhang', 'link': 'https://arxiv.org/abs/2502.13957', 'abstract': 'Retrieval-augmented generation (RAG) has shown great potential for knowledge-intensive tasks, but its traditional architectures rely on static retrieval, limiting their effectiveness for complex questions that require sequential information-seeking. While agentic reasoning and search offer a more adaptive approach, most existing methods depend heavily on prompt engineering. In this work, we introduce RAG-Gym, a unified optimization framework that enhances information-seeking agents through fine-grained process supervision at each search step. We also propose ReSearch, a novel agent architecture that synergizes answer reasoning and search query generation within the RAG-Gym framework. Experiments on four challenging datasets show that RAG-Gym improves performance by up to 25.6\\% across various agent architectures, with ReSearch consistently outperforming existing baselines. Further analysis highlights the effectiveness of advanced LLMs as process reward judges and the transferability of trained reward models as verifiers for different LLMs. Additionally, we examine the scaling properties of training and inference in agentic RAG. The project homepage is available at this https URL.', 'abstract_zh': '检索增强生成（RAG）在知识密集型任务中展现出了巨大的潜力，但其传统的架构依赖于静态检索，这限制了其在需要顺序信息搜索的复杂问题上的有效性。虽然主动推理和搜索提供了更具适应性的方法，但大多数现有方法仍然高度依赖于提示工程。在本工作中，我们引入了RAG-Gym，这是一种统一的优化框架，通过在每个检索步骤中提供细致的过程监督来增强信息查询代理。我们还提出了ReSearch，这是一种新的代理架构，在RAG-Gym框架中结合了答案推理和搜索查询生成。在四个具有挑战性的数据集中进行的实验表明，RAG-Gym在各种代理架构中提高了高达25.6%的性能，而ReSearch在所有基线中始终保持优异表现。进一步的分析强调了高级语言模型作为过程奖励裁判的有效性，并展示了训练好的奖励模型在不同语言模型中作为验证者的可迁移性。此外，我们还研究了主动RAG的训练和推理的扩展性能。该项目的主页可通过以下链接访问：[这是一个网址]。', 'title_zh': 'RAG-Gym：通过过程监督优化推理和搜索代理'}
{'arxiv_id': 'arXiv:2502.13946', 'title': "Why Safeguarded Ships Run Aground? Aligned Large Language Models' Safety Mechanisms Tend to Be Anchored in The Template Region", 'authors': 'Chak Tou Leong, Qingyu Yin, Jian Wang, Wenjie Li', 'link': 'https://arxiv.org/abs/2502.13946', 'abstract': "The safety alignment of large language models (LLMs) remains vulnerable, as their initial behavior can be easily jailbroken by even relatively simple attacks. Since infilling a fixed template between the input instruction and initial model output is a common practice for existing LLMs, we hypothesize that this template is a key factor behind their vulnerabilities: LLMs' safety-related decision-making overly relies on the aggregated information from the template region, which largely influences these models' safety behavior. We refer to this issue as template-anchored safety alignment. In this paper, we conduct extensive experiments and verify that template-anchored safety alignment is widespread across various aligned LLMs. Our mechanistic analyses demonstrate how it leads to models' susceptibility when encountering inference-time jailbreak attacks. Furthermore, we show that detaching safety mechanisms from the template region is promising in mitigating vulnerabilities to jailbreak attacks. We encourage future research to develop more robust safety alignment techniques that reduce reliance on the template region.", 'abstract_zh': '大型语言模型（LLMs）的安全对齐仍然存在漏洞，因为它们的初始行为可以通过相对简单的攻击轻易破解。由于在输入指令和初始模型输出之间填充固定模板是现有LLMs中常见的做法，我们假设模板是导致这些漏洞的关键因素：LLMs在安全相关决策上过分依赖模板区域的综合信息，这极大地影响了这些模型的安全行为。我们将这一问题称为模板锚定的安全对齐。\n\n在本文中，我们进行了广泛的经验性实验，并验证了模板锚定的安全对齐在各种对齐的LLMs中普遍存在。我们的机制分析表明，当遇到推理时的破解攻击时，这会导致模型易受影响。此外，我们展示了将安全机制与模板区域分离是减轻破解攻击漏洞的有前景的方法。我们鼓励未来的研究开发减少对模板区域依赖的更稳健的安全对齐技术。', 'title_zh': '为什么受保护的船舶会触礁？对齐的大语言模型的安全机制倾向于扎根于模板区域'}
{'arxiv_id': 'arXiv:2502.13935', 'title': 'Continually Learning Structured Visual Representations via Network Refinement with Rerelation', 'authors': 'Zeki Doruk Erden, Boi Faltings', 'link': 'https://arxiv.org/abs/2502.13935', 'abstract': 'Current machine learning paradigm relies on continuous representations like neural networks, which iteratively adjust parameters to approximate outcomes rather than directly learning the structure of problem. This spreads information across the network, causing issues like information loss and incomprehensibility Building on prior work in environment dynamics modeling, we propose a method that learns visual space in a structured, continual manner. Our approach refines networks to capture the core structure of objects while representing significant subvariants in structure efficiently. We demonstrate this with 2D shape detection, showing incremental learning on MNIST without overwriting knowledge and creating compact, comprehensible representations. These results offer a promising step toward a transparent, continually learning alternative to traditional neural networks for visual processing.', 'abstract_zh': '当前的机器学习范式依赖于连续表示，如神经网络，通过迭代调整参数以近似结果，而不是直接学习问题结构。这种方法将信息分布在网络中，造成信息损失和不透明性等问题。在借鉴环境动力学建模的先前工作基础上，我们提出了一种方法，以结构化、持续的方式学习视觉空间。我们的方法通过精炼网络来捕捉物体的核心结构，同时有效地表示结构中的重要亚变体。我们通过2D形状检测演示了这一点，在不覆盖知识的情况下进行增量学习，并生成紧凑且易于理解的表示。这些结果为传统神经网络在视觉处理方面的透明、持续学习提供了有希望的一步。', 'title_zh': '通过关系驱动的网络精炼持续学习结构化视觉表示'}
{'arxiv_id': 'arXiv:2502.13928', 'title': 'Symmetrical Visual Contrastive Optimization: Aligning Vision-Language Models with Minimal Contrastive Images', 'authors': 'Shengguang Wu, Fan-Yun Sun, Kaiyue Wen, Nick Haber', 'link': 'https://arxiv.org/abs/2502.13928', 'abstract': "Recent studies have shown that Large Vision-Language Models (VLMs) tend to neglect image content and over-rely on language-model priors, resulting in errors in visually grounded tasks and hallucinations. We hypothesize that this issue arises because existing VLMs are not explicitly trained to generate texts that are accurately grounded in fine-grained image details. To enhance visual feedback during VLM training, we propose S-VCO (Symmetrical Visual Contrastive Optimization), a novel finetuning objective that steers the model toward capturing important visual details and aligning them with corresponding text tokens. To further facilitate this detailed alignment, we introduce MVC, a paired image-text dataset built by automatically filtering and augmenting visual counterfactual data to challenge the model with hard contrastive cases involving Minimal Visual Contrasts. Experiments show that our method consistently improves VLM performance across diverse benchmarks covering various abilities and domains, achieving up to a 22% reduction in hallucinations, and significant gains in vision-centric and general tasks. Notably, these improvements become increasingly pronounced in benchmarks with higher visual dependency. In short, S-VCO offers a significant enhancement of VLM's visually-dependent task performance while retaining or even improving the model's general abilities. We opensource our code at this https URL", 'abstract_zh': '近年来的研究表明，大规模的多模态模型（如视觉-语言模型VLMs）倾向于忽视图像内容，过度依赖语言模型的先验知识，导致在视觉接地任务中出现错误，并产生幻觉。我们假设这一问题的根源在于现有的VLMs未能明确地训练以生成与精细图像细节准确对接的文本。为了在VLM训练过程中增强视觉反馈，我们提出了一种新的微调目标——S-VCO（Symmetrical Visual Contrastive Optimization），该目标旨在引导模型捕捉重要的视觉细节，并将这些细节与相应的文本标记对齐。为了进一步促进这一详细的对齐，我们引入了MVC，这是一个由自动过滤和增强视觉反事实数据构建的配对图像-文本数据集，用于挑战模型处理涉及最小视觉差异的困难对比案例。实验结果表明，我们的方法在涵盖各种能力和领域的大规模基准测试中均能提升VLM的性能，实现幻觉减少高达22%的效果，并在视觉中心和一般任务中取得显著进步。值得注意的是，在更高视觉依赖的基准测试中，这些改进变得更加明显。简而言之，S-VCO在保持甚至提升模型一般能力的同时，显著提升了VLM在视觉依赖任务上的表现。我们的代码开源在以下链接：[此处插入网址]', 'title_zh': '对称视觉对比优化：利用最小对比图像对齐视觉语言模型'}
{'arxiv_id': 'arXiv:2502.13913', 'title': 'How Do LLMs Perform Two-Hop Reasoning in Context?', 'authors': 'Tianyu Guo, Hanlin Zhu, Ruiqi Zhang, Jiantao Jiao, Song Mei, Michael I. Jordan, Stuart Russell', 'link': 'https://arxiv.org/abs/2502.13913', 'abstract': '"Socrates is human. All humans are mortal. Therefore, Socrates is mortal." This classical example demonstrates two-hop reasoning, where a conclusion logically follows from two connected premises. While transformer-based Large Language Models (LLMs) can make two-hop reasoning, they tend to collapse to random guessing when faced with distracting premises. To understand the underlying mechanism, we train a three-layer transformer on synthetic two-hop reasoning tasks. The training dynamics show two stages: a slow learning phase, where the 3-layer transformer performs random guessing like LLMs, followed by an abrupt phase transitions, where the 3-layer transformer suddenly reaches $100%$ accuracy. Through reverse engineering, we explain the inner mechanisms for how models learn to randomly guess between distractions initially, and how they learn to ignore distractions eventually. We further propose a three-parameter model that supports the causal claims for the mechanisms to the training dynamics of the transformer. Finally, experiments on LLMs suggest that the discovered mechanisms generalize across scales. Our methodologies provide new perspectives for scientific understandings of LLMs and our findings provide new insights into how reasoning emerges during training.', 'abstract_zh': '“苏格拉底是人。所有人都会死亡。因此，苏格拉底会死亡。”这一经典的示例展示了两步推理，即结论逻辑地源自两个相连的前提。虽然基于变换器的大语言模型（LLMs）可以进行两步推理，但在面对分散注意力的前提时，它们往往会退化为随机猜测。为了理解其内在机制，我们在一个合成的两步推理任务上训练了一个三层变换器。训练动态表明有两个阶段：一个缓慢的学习阶段，在此阶段中，三层变换器像LLMs一样进行随机猜测，随后是一个突变的相位转变，在此阶段中，三层变换器突然达到100%的准确率。通过逆向工程，我们解释了模型如何首先在分散注意力的情况下进行随机猜测，以及如何最终学会忽略这些分散注意力的前提。我们进一步提出一个三参数模型，支持基于变换器的训练动态机制的因果主张。最后，对LLMs的实验表明，发现的这些机制在不同规模下具有泛化性。我们的方法论为大语言模型的科学理解提供了新的视角，而我们的发现则为我们提供了关于训练过程中推理如何涌现的新见解。', 'title_zh': '在上下文中，大型语言模型如何进行两跳推理？'}
{'arxiv_id': 'arXiv:2502.13909', 'title': 'Lost in Sequence: Do Large Language Models Understand Sequential Recommendation?', 'authors': 'Sein Kim, Hongseok Kang, Kibum Kim, Jiwan Kim, Donghyun Kim, Minchul Yang, Kwangjin Oh, Julian McAuley, Chanyoung Park', 'link': 'https://arxiv.org/abs/2502.13909', 'abstract': "Large Language Models (LLMs) have recently emerged as promising tools for recommendation thanks to their advanced textual understanding ability and context-awareness. Despite the current practice of training and evaluating LLM-based recommendation (LLM4Rec) models under a sequential recommendation scenario, we found that whether these models understand the sequential information inherent in users' item interaction sequences has been largely overlooked. In this paper, we first demonstrate through a series of experiments that existing LLM4Rec models do not fully capture sequential information both during training and inference. Then, we propose a simple yet effective LLM-based sequential recommender, called LLM-SRec, a method that enhances the integration of sequential information into LLMs by distilling the user representations extracted from a pre-trained CF-SRec model into LLMs. Our extensive experiments show that LLM-SRec enhances LLMs' ability to understand users' item interaction sequences, ultimately leading to improved recommendation performance. Furthermore, unlike existing LLM4Rec models that require fine-tuning of LLMs, LLM-SRec achieves state-of-the-art performance by training only a few lightweight MLPs, highlighting its practicality in real-world applications. Our code is available at this https URL.", 'abstract_zh': '大型语言模型（LLMs）近年来因其高级的文本理解和上下文感知能力，成为了推荐系统中的有前途的工具。尽管当前的实践中，LLM基础推荐（LLM4Rec）模型主要是在序列推荐的场景下进行训练和评估，但我们发现这些模型是否能够全面理解用户项目交互序列中的顺序信息这一问题并未得到充分的关注。在本文中，我们首先通过一系列实验展示了现有LLM4Rec模型在训练和推理过程中未能充分捕捉序列信息。然后，我们提出了一种简单而有效的基于序列的LLM推荐模型，称为LLM-SRec，在该模型中，通过从预训练的CF-SRec模型中抽取用户表示并将其蒸馏到LLM中，来增强序列信息在LLM中的整合。我们的广泛实验显示，LLM-SRec能够增强LLM理解用户项目交互序列的能力，从而提高推荐性能。此外，与现有LLM4Rec模型需要对LLM进行微调不同，LLM-SRec仅通过训练几组轻量级的MLP就能达到最先进的性能，突显了其在实际应用中的实用性。我们的代码可在以下链接获取：这个 https URL。', 'title_zh': '迷失在序列之中：大型语言模型理解序列推荐吗？'}
{'arxiv_id': 'arXiv:2502.13905', 'title': 'Partially Observable Gaussian Process Network and Doubly Stochastic Variational Inference', 'authors': 'Saksham Kiroriwal, Julius Pfrommer, Jürgen Beyerer', 'link': 'https://arxiv.org/abs/2502.13905', 'abstract': 'To reduce the curse of dimensionality for Gaussian processes (GP), they can be decomposed into a Gaussian Process Network (GPN) of coupled subprocesses with lower dimensionality. In some cases, intermediate observations are available within the GPN. However, intermediate observations are often indirect, noisy, and incomplete in most real-world systems. This work introduces the Partially Observable Gaussian Process Network (POGPN) to model real-world process networks. We model a joint distribution of latent functions of subprocesses and make inferences using observations from all subprocesses. POGPN incorporates observation lenses (observation likelihoods) into the well-established inference method of deep Gaussian processes. We also introduce two training methods for POPGN to make inferences on the whole network using node observations. The application to benchmark problems demonstrates how incorporating partial observations during training and inference can improve the predictive performance of the overall network, offering a promising outlook for its practical application.', 'abstract_zh': '为减少高维情况下高斯过程（GP）的维度诅咒，可以将GP分解为具有低维度耦合子过程的高斯过程网络（GPN）。在某些情况下，GPN内部可能存在中间观测数据。然而，在大多数实际系统中，中间观测数据往往是间接、噪声大且不完整的。本研究引入了部分可观测高斯过程网络（POGPN）来建模实际过程网络。我们对子过程的潜在函数进行联合概率分布建模，并利用所有子过程的观测值进行推断。POGPN将观测透镜（观测似然性）整合到已成熟的深度高斯过程推断方法中。我们还提出了两种训练POGPN的方法，以便利用节点观测值对整个网络进行推断。将POGPN应用到基准问题中，展示了在训练和推断过程中整合部分观测数据如何提升整体网络的预测性能，并为其实用应用提供了乐观的前景。', 'title_zh': '部分可观测高斯过程网络与双随机变分推断'}
{'arxiv_id': 'arXiv:2502.13897', 'title': 'DataSciBench: An LLM Agent Benchmark for Data Science', 'authors': 'Dan Zhang, Sining Zhoubian, Min Cai, Fengzu Li, Lekang Yang, Wei Wang, Tianjiao Dong, Ziniu Hu, Jie Tang, Yisong Yue', 'link': 'https://arxiv.org/abs/2502.13897', 'abstract': 'This paper presents DataSciBench, a comprehensive benchmark for evaluating Large Language Model (LLM) capabilities in data science. Recent related benchmarks have primarily focused on single tasks, easily obtainable ground truth, and straightforward evaluation metrics, which limits the scope of tasks that can be evaluated. In contrast, DataSciBench is constructed based on a more comprehensive and curated collection of natural and challenging prompts for uncertain ground truth and evaluation metrics. We develop a semi-automated pipeline for generating ground truth (GT) and validating evaluation metrics. This pipeline utilizes and implements an LLM-based self-consistency and human verification strategy to produce accurate GT by leveraging collected prompts, predefined task types, and aggregate functions (metrics). Furthermore, we propose an innovative Task - Function - Code (TFC) framework to assess each code execution outcome based on precisely defined metrics and programmatic rules. Our experimental framework involves testing 6 API-based models, 8 open-source general models, and 9 open-source code generation models using the diverse set of prompts we have gathered. This approach aims to provide a more comprehensive and rigorous evaluation of LLMs in data science, revealing their strengths and weaknesses. Experimental results demonstrate that API-based models outperform open-sourced models on all metrics and Deepseek-Coder-33B-Instruct achieves the highest score among open-sourced models. We release all code and data at this https URL.', 'abstract_zh': '本文介绍了DataSciBench，这是一个全面的基准测试，用于评估大型语言模型（LLM）在数据科学领域的能力。最近的相关基准测试主要集中在单一任务、易于获得的地面真实值和简便的评估指标上，这限制了可以评估的任务范围。相比之下，DataSciBench 是基于更为全面和精挑细选的自然且具有挑战性的提示构建的，适用于不确定的地面真实值和评估指标。我们开发了一种半自动管道来生成地面真实值（GT）并验证评估指标。该管道利用并实现了基于LLM的自我一致性与人工验证策略，通过利用收集的提示、预定义的任务类型和聚合函数（指标）来生成准确的GT。此外，我们提出了一种创新的Task-Function-Code（TFC）框架，根据精确定义的度量标准和编程规则来评估每次代码执行的结果。我们的实验框架包括使用我们收集的多样化的提示测试6种API基模型、8种开源通用模型和9种开源代码生成模型。这种方法旨在提供更全面和严格的LLM在数据科学领域的评估，揭示它们的优势和劣势。实验结果表明，API基模型在所有指标上均优于开源模型，Deepseek-Coder-33B-Instruct 在开源模型中得分最高。我们已在此链接 https://... 上发布了所有代码和数据。', 'title_zh': 'DataSciBench：一个用于数据科学的大型语言模型代理基准测试'}
{'arxiv_id': 'arXiv:2502.13881', 'title': 'PSCon: Toward Conversational Product Search', 'authors': 'Jie Zou, Mohammad Aliannejadi, Evangelos Kanoulas, Shuxi Han, Heli Ma, Zheng Wang, Yang Yang, Heng Tao Shen', 'link': 'https://arxiv.org/abs/2502.13881', 'abstract': 'Conversational Product Search (CPS) is confined to simulated conversations due to the lack of real-world CPS datasets that reflect human-like language. Additionally, current conversational datasets are limited to support cross-market and multi-lingual usage. In this paper, we introduce a new CPS data collection protocol and present PSCon, a novel CPS dataset designed to assist product search via human-like conversations. The dataset is constructed using a coached human-to-human data collection protocol and supports two languages and dual markets. Also, the dataset enables thorough exploration of six subtasks of CPS: user intent detection, keyword extraction, system action prediction, question selection, item ranking, and response generation. Furthermore, we also offer an analysis of the dataset and propose a benchmark model on the proposed CPS dataset.', 'abstract_zh': '会话产品搜索（CPS）受限于模拟对话，因为缺乏反映人类语言的真实世界CPS数据集。此外，目前的对话数据集支持跨市场和多语言使用的能力有限。在本文中，我们介绍了一种新的CPS数据收集协议，并展示了PSCon，这是一个专门设计用于通过类似人类的对话辅助产品搜索的新CPS数据集。该数据集是通过教练下的真人对真人数据收集协议构建的，并支持两种语言和两个市场。此外，该数据集使我们能够全面探索CPS的六个子任务：用户意图检测、关键词抽取、系统动作预测、问题选择、项目排名和响应生成。进一步地，我们还对数据集进行了分析，并在所提出的CPS数据集上提出了一个基准模型。', 'title_zh': 'PSCon: 朝着对话式产品搜索的方向'}
{'arxiv_id': 'arXiv:2502.13875', 'title': 'MEX: Memory-efficient Approach to Referring Multi-Object Tracking', 'authors': 'Huu-Thien Tran, Phuoc-Sang Pham, Thai-Son Tran, Khoa Luu', 'link': 'https://arxiv.org/abs/2502.13875', 'abstract': 'Referring Multi-Object Tracking (RMOT) is a relatively new concept that has rapidly gained traction as a promising research direction at the intersection of computer vision and natural language processing. Unlike traditional multi-object tracking, RMOT identifies and tracks objects and incorporates textual descriptions for object class names, making the approach more intuitive. Various techniques have been proposed to address this challenging problem; however, most require the training of the entire network due to their end-to-end nature. Among these methods, iKUN has emerged as a particularly promising solution. Therefore, we further explore its pipeline and enhance its performance. In this paper, we introduce a practical module dubbed Memory-Efficient Cross-modality -- MEX. This memory-efficient technique can be directly applied to off-the-shelf trackers like iKUN, resulting in significant architectural improvements. Our method proves effective during inference on a single GPU with 4 GB of memory. Among the various benchmarks, the Refer-KITTI dataset, which offers diverse autonomous driving scenes with relevant language expressions, is particularly useful for studying this problem. Empirically, our method demonstrates effectiveness and efficiency regarding HOTA tracking scores, substantially improving memory allocation and processing speed.', 'abstract_zh': '参考多对象跟踪（RMOT）是一种相对较新的概念，自计算机视觉与自然语言处理交叉领域兴起以来，这一概念迅速获得了广泛关注，成为一种有希望的研究方向。与传统的多对象跟踪不同，RMOT不仅识别和跟踪对象，还结合了文本描述的对象类别名称，使方法更加直观。已提出多种方法来解决这一具有挑战性的问题，但大多数方法因其端到端的性质，需要整个网络的训练。在这之中，iKUN 已经展现出特别有前景的解决方案。因此，我们进一步探索其管道并增强其性能。在本文中，我们引入了一种名为Memory-Efficient Cross-modality（MEX）的实用模块。这一内存高效的技巧可以直接应用于现成的跟踪器如iKUN，从而带来显著的架构改进。我们的方法在单一具有4 GB 内存的GPU上进行推断时证明是有效的。在各种基准下，特别是Refer-KITTI数据集——该数据集提供了多种与自动驾驶场景相关的语言表达——对于研究这一问题特别有用。实验结果显示，我们的方法在HOTA跟踪分数方面表现出色，显著提高了内存分配和处理速度。', 'title_zh': 'MEX：内存高效的人多目标跟踪方法'}
{'arxiv_id': 'arXiv:2502.13873', 'title': 'NVR: Vector Runahead on NPUs for Sparse Memory Access', 'authors': 'Hui Wang, Zhengpeng Zhao, Jing Wang, Yushu Du, Yuan Cheng, Bing Guo, He Xiao, Chenhao Ma, Xiaomeng Han, Dean You, Jiapeng Guan, Ran Wei, Dawei Yang, Zhe Jiang', 'link': 'https://arxiv.org/abs/2502.13873', 'abstract': 'Deep Neural Networks are increasingly leveraging sparsity to reduce the scaling up of model parameter size. However, reducing wall-clock time through sparsity and pruning remains challenging due to irregular memory access patterns, leading to frequent cache misses. In this paper, we present NPU Vector Runahead (NVR), a prefetching mechanism tailored for NPUs to address cache miss problems in sparse DNN workloads. Rather than optimising memory patterns with high overhead and poor portability, NVR adapts runahead execution to the unique architecture of NPUs. NVR provides a general micro-architectural solution for sparse DNN workloads without requiring compiler or algorithmic support, operating as a decoupled, speculative, lightweight hardware sub-thread alongside the NPU, with minimal hardware overhead (under 5%). NVR achieves an average 90% reduction in cache misses compared to SOTA prefetching in general-purpose processors, delivering 4x average speedup on sparse workloads versus NPUs without prefetching. Moreover, we investigate the advantages of incorporating a small cache (16KB) into the NPU combined with NVR. Our evaluation shows that expanding this modest cache delivers 5x higher performance benefits than increasing the L2 cache size by the same amount.', 'abstract_zh': '深度神经网络正 increasingly 利用稀疏性来减少模型参数规模的扩大。然而，通过稀疏性和剪枝减少实际运行时间仍然具有挑战性，因为这会导致不规则的内存访问模式，从而频繁产生缓存未命中的问题。在这篇论文中，我们提出了NPU向量前瞻机制（NPU Vector Runahead, NVR），这是一种针对NPU的预取机制，旨在解决稀疏DNN工作负载中的缓存未命中问题。NVR 不是通过具有高开销且缺乏可移植性的优化内存模式来解决问题，而是根据NPU的独特架构调整前瞻执行。NVR 提供了一个通用的微架构解决方案，适用于稀疏DNN工作负载，无需编译器或算法支持，并作为一个与NPU 解耦的、推测性的、轻量级的硬件子线程运行，硬件开销不到5%。与通用处理器的最新预取技术相比，NVR 实现了平均90%的缓存未命中率减少，同时在启用预取的情况下，NPU 上稀疏工作负载的平均加速比提高了4倍。此外，我们还研究了将小型缓存（16KB）集成到NPU与NVR 中的优势。我们的评估表明，扩展这个适度大小的缓存所带来的性能收益比增加相同数量的L2缓存大5倍。', 'title_zh': 'NVR：针对稀疏内存访问的NPUs向量前瞻优化'}
{'arxiv_id': 'arXiv:2502.13870', 'title': 'SPEX: Scaling Feature Interaction Explanations for LLMs', 'authors': 'Justin Singh Kang, Landon Butler, Abhineet Agarwal, Yigit Efe Erginbas, Ramtin Pedarsani, Kannan Ramchandran, Bin Yu', 'link': 'https://arxiv.org/abs/2502.13870', 'abstract': 'Large language models (LLMs) have revolutionized machine learning due to their ability to capture complex interactions between input features. Popular post-hoc explanation methods like SHAP provide marginal feature attributions, while their extensions to interaction importances only scale to small input lengths ($\\approx 20$). We propose Spectral Explainer (SPEX), a model-agnostic interaction attribution algorithm that efficiently scales to large input lengths ($\\approx 1000)$. SPEX exploits underlying natural sparsity among interactions -- common in real-world data -- and applies a sparse Fourier transform using a channel decoding algorithm to efficiently identify important interactions. We perform experiments across three difficult long-context datasets that require LLMs to utilize interactions between inputs to complete the task. For large inputs, SPEX outperforms marginal attribution methods by up to 20% in terms of faithfully reconstructing LLM outputs. Further, SPEX successfully identifies key features and interactions that strongly influence model output. For one of our datasets, HotpotQA, SPEX provides interactions that align with human annotations. Finally, we use our model-agnostic approach to generate explanations to demonstrate abstract reasoning in closed-source LLMs (GPT-4o mini) and compositional reasoning in vision-language models.', 'abstract_zh': '大型语言模型（LLMs）由于能够捕捉输入特征之间的复杂交互而彻底改变了机器学习。流行的后期解释方法如SHAP提供边际特征归属，而其对交互重要性的扩展只能应用于较短的输入长度（约为20个）。我们提出了一种模型无关的交互归属算法——谱解释器（SPEX），该算法能够高效地扩展到较长的输入长度（约为1000个）。SPEX 利用真实世界数据中固有的自然稀疏性，并采用通道解码算法进行稀疏傅里叶变换，从而高效地识别重要交互。我们针对三个需要LLMs利用输入间的交互来完成任务的具有挑战性的长上下文数据集进行了实验。对于较长时间的输入，SPEX 在忠实地重建LLM输出方面比边际归属方法高出20%。此外，SPEX 成功地识别了对模型输出影响显著的关键特征和交互。对于我们的其中一个数据集HotpotQA，SPEX 提供的交互与人类注释一致。最后，我们利用我们的模型无关方法为合成的闭源LLM（GPT-4o mini）生成解释，展示了抽象推理能力，并为视觉-语言模型进行了组合推理能力的演示。', 'title_zh': 'SPEX：扩展大语言模型中特征交互解释的规模'}
{'arxiv_id': 'arXiv:2502.13847', 'title': 'DH-RAG: A Dynamic Historical Context-Powered Retrieval-Augmented Generation Method for Multi-Turn Dialogue', 'authors': 'Feiyuan Zhang, Dezhi Zhu, James Ming, Yilun Jin, Di Chai, Liu Yang, Han Tian, Zhaoxin Fan, Kai Chen', 'link': 'https://arxiv.org/abs/2502.13847', 'abstract': 'Retrieval-Augmented Generation (RAG) systems have shown substantial benefits in applications such as question answering and multi-turn dialogue \\citep{lewis2020retrieval}. However, traditional RAG methods, while leveraging static knowledge bases, often overlook the potential of dynamic historical information in ongoing conversations. To bridge this gap, we introduce DH-RAG, a Dynamic Historical Context-Powered Retrieval-Augmented Generation Method for Multi-Turn Dialogue. DH-RAG is inspired by human cognitive processes that utilize both long-term memory and immediate historical context in conversational responses \\citep{stafford1987conversational}. DH-RAG is structured around two principal components: a History-Learning based Query Reconstruction Module, designed to generate effective queries by synthesizing current and prior interactions, and a Dynamic History Information Updating Module, which continually refreshes historical context throughout the dialogue. The center of DH-RAG is a Dynamic Historical Information database, which is further refined by three strategies within the Query Reconstruction Module: Historical Query Clustering, Hierarchical Matching, and Chain of Thought Tracking. Experimental evaluations show that DH-RAG significantly surpasses conventional models on several benchmarks, enhancing response relevance, coherence, and dialogue quality.', 'abstract_zh': '检索增强生成（RAG）系统在问答和多轮对话等多种应用中展现了显著的优势 \\citep{lewis2020retrieval}。然而，传统的RAG方法虽然利用了静态的知识库，但在处理正在进行的对话时往往忽视了动态历史信息的潜力。为弥补这一差距，我们提出了一种名为DH-RAG的方法，该方法是基于动态历史上下文的检索增强生成方法，适用于多轮对话。DH-RAG受到人类认知过程的启发，该过程在对话回应中综合利用了长期记忆和即时历史信息 \\citep{stafford1987conversational}。DH-RAG结构上由两个主要部分组成：基于历史学习的查询重构模块和动态历史信息更新模块。基于历史学习的查询重构模块旨在通过综合当前和先前的交互生成有效的查询，而动态历史信息更新模块则在整个对话过程中不断更新历史上下文。DH-RAG的核心是一个动态历史信息数据库，该数据库在查询重构模块的三个策略的细化下进一步优化：历史查询聚类、层次匹配和思路跟踪。实验评估显示，DH-RAG在多个基准测试中显著优于传统模型，提高了回应的相关性、连贯性和对话质量。', 'title_zh': 'DH-RAG：一种基于动态历史语境的检索增强生成方法用于多轮对话'}
{'arxiv_id': 'arXiv:2502.13845', 'title': 'Enhancing LLM-Based Recommendations Through Personalized Reasoning', 'authors': 'Jiahao Liu, Xueshuo Yan, Dongsheng Li, Guangping Zhang, Hansu Gu, Peng Zhang, Tun Lu, Li Shang, Ning Gu', 'link': 'https://arxiv.org/abs/2502.13845', 'abstract': "Current recommendation systems powered by large language models (LLMs) often underutilize their reasoning capabilities due to a lack of explicit logical structuring. To address this limitation, we introduce CoT-Rec, a framework that integrates Chain-of-Thought (CoT) reasoning into LLM-driven recommendations by incorporating two crucial processes: user preference analysis and item perception evaluation. CoT-Rec operates in two key phases: (1) personalized data extraction, where user preferences and item perceptions are identified, and (2) personalized data application, where this information is leveraged to refine recommendations. Our experimental analysis demonstrates that CoT-Rec improves recommendation accuracy by making better use of LLMs' reasoning potential. The implementation is publicly available at this https URL.", 'abstract_zh': '当前由大规模语言模型（LLMs）驱动的推荐系统往往没有充分利用其推理能力，主要是因为缺乏明确的逻辑结构。为了解决这一限制，我们引入了CoT-Rec框架，该框架通过整合 Chain-of-Thought（CoT）推理，将逻辑推理融入到由LLM驱动的推荐系统中，并通过两个关键过程来实现：用户偏好分析和项目感知评估。CoT-Rec 包含两个核心阶段：（1）个性化数据提取，其中确定用户偏好和项目感知，（2）个性化数据应用，其中利用这些信息来改进推荐。我们的实验分析表明，CoT-Rec 通过更好地利用LLM的推理潜力，提高了推荐的准确性。该实现已公开发布，相关链接为：this https URL。', 'title_zh': '通过个性化推理增强基于LLM的推荐系统'}
{'arxiv_id': 'arXiv:2502.13843', 'title': 'Enhancing Cross-Domain Recommendations with Memory-Optimized LLM-Based User Agents', 'authors': 'Jiahao Liu, Shengkang Gu, Dongsheng Li, Guangping Zhang, Mingzhe Han, Hansu Gu, Peng Zhang, Tun Lu, Li Shang, Ning Gu', 'link': 'https://arxiv.org/abs/2502.13843', 'abstract': 'Large Language Model (LLM)-based user agents have emerged as a powerful tool for improving recommender systems by simulating user interactions. However, existing methods struggle with cross-domain scenarios due to inefficient memory structures, leading to irrelevant information retention and failure to account for social influence factors such as popularity. To address these limitations, we introduce AgentCF++, a novel framework featuring a dual-layer memory architecture and a two-step fusion mechanism to filter domain-specific preferences effectively. Additionally, we propose interest groups with shared memory, allowing the model to capture the impact of popularity trends on users with similar interests. Through extensive experiments on multiple cross-domain datasets, AgentCF++ demonstrates superior performance over baseline models, highlighting its effectiveness in refining user behavior simulation for recommender systems. Our code is available at this https URL.', 'abstract_zh': '基于大型语言模型（LLM）的用户代理已经成为通过模拟用户交互来改善推荐系统的一种强大工具。然而，现有的方法在跨域场景中效率低下，主要是由于缺乏高效的内存结构，导致无法保留相关的信息，并且不能很好地考虑到如流行度等社会影响因素。为了解决这些限制，我们提出了AgentCF++，这是一种新型框架，具备双重内存架构和两步融合机制，以有效过滤领域特定的偏好。此外，我们还提出了共享内存的兴趣群体，使模型能够捕捉对具有相似兴趣的用户产生影响的流行趋势。通过在多个跨域数据集上进行广泛的实验，AgentCF++在基线模型上显示出了优越的性能，证明了其在细化推荐系统中用户行为模拟方面有效性。我们的代码已发布在此 <https://> 地址。', 'title_zh': '使用内存优化的大语言模型基用户代理增强跨域推荐'}
{'arxiv_id': 'arXiv:2502.13840', 'title': 'Mitigating Popularity Bias in Collaborative Filtering through Fair Sampling', 'authors': 'Jiahao Liu, Dongsheng Li, Hansu Gu, Peng Zhang, Tun Lu, Li Shang, Ning Gu', 'link': 'https://arxiv.org/abs/2502.13840', 'abstract': 'Recommender systems often suffer from popularity bias, where frequently interacted items are overrepresented in recommendations. This bias stems from propensity factors influencing training data, leading to imbalanced exposure. In this paper, we introduce a Fair Sampling (FS) approach to address this issue by ensuring that both users and items are selected with equal probability as positive and negative instances. Unlike traditional inverse propensity score (IPS) methods, FS does not require propensity estimation, eliminating errors associated with inaccurate calculations. Our theoretical analysis demonstrates that FS effectively neutralizes the influence of propensity factors, achieving unbiased learning. Experimental results validate that FS outperforms state-of-the-art methods in both point-wise and pair-wise recommendation tasks, enhancing recommendation fairness without sacrificing accuracy. The implementation is available at this https URL.', 'abstract_zh': '推荐系统常常受到流行性偏见的影响，即频繁交互的项目在推荐中被过度代表。这种偏见源于影响训练数据的倾向性因素，导致曝光不均衡。本文介绍了一种公平抽样（Fair Sampling，FS）方法，通过确保用户和项目以相等的概率被选为正例和负例来解决该问题。与传统的逆倾向性得分（Inverse Propensity Score，IPS）方法不同，FS 不需要估计倾向性，从而消除了与不准确计算相关错误的影响。我们的理论分析表明，FS 有效地抵消了倾向性因素的影响，实现了无偏学习。实验结果证实，FS 在点对点和成对推荐任务中均优于现有最先进的方法，提高了推荐的公平性而不牺牲准确性。该实现可以在以下网址找到：[此处替换为实际网址]。', 'title_zh': '通过公平采样缓解协同过滤中的流行度偏见'}
{'arxiv_id': 'arXiv:2502.13836', 'title': 'Quantifying Memorization and Retriever Performance in Retrieval-Augmented Vision-Language Models', 'authors': 'Peter Carragher, Abhinand Jha, R Raghav, Kathleen M. Carley', 'link': 'https://arxiv.org/abs/2502.13836', 'abstract': 'Large Language Models (LLMs) demonstrate remarkable capabilities in question answering (QA), but metrics for assessing their reliance on memorization versus retrieval remain underdeveloped. Moreover, while finetuned models are state-of-the-art on closed-domain tasks, general-purpose models like GPT-4o exhibit strong zero-shot performance. This raises questions about the trade-offs between memorization, generalization, and retrieval. In this work, we analyze the extent to which multimodal retrieval-augmented VLMs memorize training data compared to baseline VLMs. Using the WebQA benchmark, we contrast finetuned models with baseline VLMs on multihop retrieval and question answering, examining the impact of finetuning on data memorization. To quantify memorization in end-to-end retrieval and QA systems, we propose several proxy metrics by investigating instances where QA succeeds despite retrieval failing. Our results reveal the extent to which finetuned models rely on memorization. In contrast, retrieval-augmented VLMs have lower memorization scores, at the cost of accuracy (72% vs 52% on WebQA test set). As such, our measures pose a challenge for future work to reconcile memorization and generalization in both Open-Domain QA and joint Retrieval-QA tasks.', 'abstract_zh': '大型语言模型（LLMs）在问答（QA）方面展现了 remarkable 的能力，但评估它们对记忆依赖与检索依赖的指标仍处于发展中阶段。此外，尽管微调模型在封闭领域任务上是目前最先进的，通用模型如GPT-4o却在零样本任务中表现出色。这引发了记忆、泛化和检索之间权衡关系的疑问。在本研究中，我们分析了多模态检索增强VLMs与基线VLMs相比在多跳检索和问答中记忆训练数据的程度。我们使用WebQA基准进行对照实验，比较微调模型与基线VLMs在多跳检索和问答任务上的表现，探讨微调对数据记忆的影响。为了量化端到端检索和问答系统中的记忆程度，我们通过探讨即使检索失败问答也能成功的实例，提出了若干代理指标。我们的结果显示了微调模型在多大程度上依赖记忆。相对而言，检索增强的VLMs的记忆分数较低（在WebQA测试集上的准确率为72%对52%），代价是准确性下降。因此，我们的指标对未来的研究提出了挑战，即解决开放领域问答和联合检索问答任务中的记忆与泛化之间的矛盾。', 'title_zh': '量化检索增强视觉语言模型中的记忆作用与检索器性能'}
{'arxiv_id': 'arXiv:2502.13805', 'title': 'AnDB: Breaking Boundaries with an AI-Native Database for Universal Semantic Analysis', 'authors': 'Tianqing Wang, Xun Xue, Guoliang Li, Yong Wang', 'link': 'https://arxiv.org/abs/2502.13805', 'abstract': 'In this demonstration, we present AnDB, an AI-native database that supports traditional OLTP workloads and innovative AI-driven tasks, enabling unified semantic analysis across structured and unstructured data. While structured data analytics is mature, challenges remain in bridging the semantic gap between user queries and unstructured data. AnDB addresses these issues by leveraging cutting-edge AI-native technologies, allowing users to perform semantic queries using intuitive SQL-like statements without requiring AI expertise. This approach eliminates the ambiguity of traditional text-to-SQL systems and provides a seamless end-to-end optimization for analyzing all data types. AnDB automates query processing by generating multiple execution plans and selecting the optimal one through its optimizer, which balances accuracy, execution time, and financial cost based on user policies and internal optimizing mechanisms. AnDB future-proofs data management infrastructure, empowering users to effectively and efficiently harness the full potential of all kinds of data without starting from scratch.', 'abstract_zh': '在本演示中，我们展示了AnDB，这是一种AI原生数据库，支持传统的OLTP工作负载和创新的AI驱动任务，实现了结构化和非结构化数据统一语义分析。尽管结构化数据的分析已经较为成熟，但在用户查询与非结构化数据之间的语义链接上仍存在挑战。AnDB 通过利用前沿的AI原生技术解决了这些问题，允许用户使用直观的SQL-like语句进行语义查询，而无需具备AI专业知识。这种方法消除了传统文本到SQL系统的歧义，并提供了从始至终的数据类型无缝优化分析。AnDB 通过生成多执行计划并借助其优化器选出最优方案来自动化查询处理，优化器根据用户策略和内部优化机制平衡准确度、执行时间和成本。AnDB 确保数据管理基础设施具备前瞻性，使用户能够有效地并且高效地挖掘各种数据的全部潜力，而无需从头开始。', 'title_zh': 'AnDB：一种用于通用语义分析的AI原生数据库，打破界限'}
{'arxiv_id': 'arXiv:2502.13794', 'title': 'LESA: Learnable LLM Layer Scaling-Up', 'authors': 'Yifei Yang, Zouying Cao, Xinbei Ma, Yao Yao, Libo Qin, Zhi Chen, Hai Zhao', 'link': 'https://arxiv.org/abs/2502.13794', 'abstract': 'Training Large Language Models (LLMs) from scratch requires immense computational resources, making it prohibitively expensive. Model scaling-up offers a promising solution by leveraging the parameters of smaller models to create larger ones. However, existing depth scaling-up methods rely on empirical heuristic rules for layer duplication, which result in poorer initialization and slower convergence during continual pre-training. We propose \\textbf{LESA}, a novel learnable method for depth scaling-up. By concatenating parameters from each layer and applying Singular Value Decomposition, we uncover latent patterns between layers, suggesting that inter-layer parameters can be learned. LESA uses a neural network to predict the parameters inserted between adjacent layers, enabling better initialization and faster training. Experiments show that LESA outperforms existing baselines, achieving superior performance with less than half the computational cost during continual pre-training. Extensive analyses demonstrate its effectiveness across different model sizes and tasks.', 'abstract_zh': '从头开始训练大型语言模型（LLMs）需要巨大的计算资源，使其变得极其昂贵。通过利用较小模型的参数来创建更大模型的规模扩展提供了一个有前景的解决方案。然而，现有的深度扩展方法依赖于基于经验的启发式规则来进行层复制，这会导致较差的初始化和持续预训练期间更慢的收敛速度。我们提出了\\textbf{LESA}，一种新颖的学习式深度扩展方法。通过将每一层的参数连接起来并应用奇异值分解（SVD），我们发现了层间隐藏的模式，表明层间参数可以被学习。LESA 使用神经网络预测相邻层之间插入的参数，从而实现更好的初始化和更快的训练。实验结果表明，LESA 在持续预训练期间的计算成本不到现有基线的一半，且性能更优。广泛分析证明了它在不同模型大小和任务上的有效性。', 'title_zh': 'LESA：可学习的大型语言模型层扩展方法'}
{'arxiv_id': 'arXiv:2502.13785', 'title': 'Helix-mRNA: A Hybrid Foundation Model For Full Sequence mRNA Therapeutics', 'authors': 'Matthew Wood, Mathieu Klop, Maxime Allard', 'link': 'https://arxiv.org/abs/2502.13785', 'abstract': "mRNA-based vaccines have become a major focus in the pharmaceutical industry. The coding sequence as well as the Untranslated Regions (UTRs) of an mRNA can strongly influence translation efficiency, stability, degradation, and other factors that collectively determine a vaccine's effectiveness. However, optimizing mRNA sequences for those properties remains a complex challenge. Existing deep learning models often focus solely on coding region optimization, overlooking the UTRs. We present Helix-mRNA, a structured state-space-based and attention hybrid model to address these challenges. In addition to a first pre-training, a second pre-training stage allows us to specialise the model with high-quality data. We employ single nucleotide tokenization of mRNA sequences with codon separation, ensuring prior biological and structural information from the original mRNA sequence is not lost. Our model, Helix-mRNA, outperforms existing methods in analysing both UTRs and coding region properties. It can process sequences 6x longer than current approaches while using only 10% of the parameters of existing foundation models. Its predictive capabilities extend to all mRNA regions. We open-source the model (this https URL) and model weights (this https URL).", 'abstract_zh': '基于mRNA的疫苗已成为制药行业的重点。mRNA的编码序列以及未翻译区（UTRs）均可显著影响翻译效率、稳定性、降解及其他决定疫苗有效性的因素。然而，优化这些性质的mRNA序列仍然是一项复杂的挑战。现有的深度学习模型通常仅专注于编码区的优化，而忽略了UTRs。我们提出了一种名为Helix-mRNA的结构化状态空间模型和注意力机制混合模型，以应对这些挑战。此外，通过两个预训练阶段，我们能够使用高质量的数据专门化该模型。我们采用单核苷酸分词并以密码子为间隔对mRNA序列进行分词，确保原有的生物学和结构信息不被丢失。我们的模型Helix-mRNA在分析UTRs和编码区属性方面优于现有的方法，同时能够处理比当前方法长6倍的序列，并且仅使用现有基础模型10%的参数。其预测能力涵盖所有mRNA区域。我们开源了该模型及其权重（分别见以下链接：[模型](https://github.com/alibaba/MEDN-Helix) 和 [模型权重](https://huggingface.co/alibaba/MEDN-Helix)）。', 'title_zh': '螺旋-mRNA：一种混合基础模型用于全长mRNA疗法'}
{'arxiv_id': 'arXiv:2502.13778', 'title': 'Poster: SpiderSim: Multi-Agent Driven Theoretical Cybersecurity Simulation for Industrial Digitalization', 'authors': 'Jiaqi Li, Xizhong Guo, Yang Zhao, Lvyang Zhang, Lidong Zhai', 'link': 'https://arxiv.org/abs/2502.13778', 'abstract': "Rapid industrial digitalization has created intricate cybersecurity demands that necessitate effective validation methods. While cyber ranges and simulation platforms are widely deployed, they frequently face limitations in scenario diversity and creation efficiency. In this paper, we present SpiderSim, a theoretical cybersecurity simulation platform enabling rapid and lightweight scenario generation for industrial digitalization security research. At its core, our platform introduces three key innovations: a structured framework for unified scenario modeling, a multi-agent collaboration mechanism for automated generation, and modular atomic security capabilities for flexible scenario composition. Extensive implementation trials across multiple industrial digitalization contexts, including marine ranch monitoring systems, validate our platform's capacity for broad scenario coverage with efficient generation processes. Built on solid theoretical foundations and released as open-source software, SpiderSim facilitates broader research and development in automated security testing for industrial digitalization.", 'abstract_zh': '快速工业数字化催生了复杂网络安全需求，这要求有有效的验证方法。虽然网络范围和仿真平台广泛部署，但在场景多样性和生成效率方面仍存在局限性。本文介绍了SpiderSim，这是一种理论上的网络安全仿真平台，能够实现快速和轻量级的场景生成，以满足工业数字化安全研究的需求。该平台的核心创新包括三个方面：一个统一的结构化场景建模框架、一种自动化的多代理协作机制以及模块化的原子安全能力，以支持灵活的场景组合。通过在多个工业数字化背景下（包括海洋牧场监控系统）进行广泛的实施试验，验证了该平台在高效生成过程中具备广泛的场景覆盖能力。基于坚实的理论基础并作为开源软件发布，SpiderSim促进了自动化安全测试在工业数字化领域的更广泛研究和开发。', 'title_zh': '海报：SpiderSim：面向工业数字化的多Agent驱动生成网络安全理论仿真'}
{'arxiv_id': 'arXiv:2502.13775', 'title': 'VITAL: A New Dataset for Benchmarking Pluralistic Alignment in Healthcare', 'authors': 'Anudeex Shetty, Amin Beheshti, Mark Dras, Usman Naseem', 'link': 'https://arxiv.org/abs/2502.13775', 'abstract': 'Alignment techniques have become central to ensuring that Large Language Models (LLMs) generate outputs consistent with human values. However, existing alignment paradigms often model an averaged or monolithic preference, failing to account for the diversity of perspectives across cultures, demographics, and communities. This limitation is particularly critical in health-related scenarios, where plurality is essential due to the influence of culture, religion, personal values, and conflicting opinions. Despite progress in pluralistic alignment, no prior work has focused on health, likely due to the unavailability of publicly available datasets. To address this gap, we introduce VITAL, a new benchmark dataset comprising 13.1K value-laden situations and 5.4K multiple-choice questions focused on health, designed to assess and benchmark pluralistic alignment methodologies. Through extensive evaluation of eight LLMs of varying sizes, we demonstrate that existing pluralistic alignment techniques fall short in effectively accommodating diverse healthcare beliefs, underscoring the need for tailored AI alignment in specific domains. This work highlights the limitations of current approaches and lays the groundwork for developing health-specific alignment solutions.', 'abstract_zh': '对齐技术已成为确保大型语言模型（LLMs）生成与人类价值观一致的输出的核心。然而，现有的对齐范式通常建模的是平均或单一的偏好，未能考虑到跨文化、人口统计和社区之间的多样视角。在健康相关场景中，这种限制尤为关键，因为文化的、宗教的、个人价值观的影响以及观点的分歧使多种观点成为必需。尽管在多视角对齐方面取得了进展，但尚未有研究集中在健康领域，这很可能是由于缺乏公开可用的数据集。为解决这一问题，我们引入了VITAL，这是一个新的基准数据集，包含13,100个价值观导向的情境和5,400个与健康相关的多选题，旨在评估和测试多视角对齐方法。通过广泛评估八种不同规模的LLM，我们证明现有的多视角对齐技术在有效地容纳多样化的医疗保健信念方面存在不足，强调了特定领域内定制AI对齐的需求。这项工作突显了当前方法的局限性，并为开发针对健康领域的对齐解决方案奠定了基础。', 'title_zh': 'VITAL：用于医疗领域多元对齐基准测试的新数据集'}
{'arxiv_id': 'arXiv:2502.13767', 'title': 'AI Software Engineer: Programming with Trust', 'authors': 'Abhik Roychoudhury, Corina Pasareanu, Michael Pradel, Baishakhi Ray', 'link': 'https://arxiv.org/abs/2502.13767', 'abstract': 'Large Language Models (LLMs) have shown surprising proficiency in generating code snippets, promising to automate large parts of software engineering via artificial intelligence (AI). We argue that successfully deploying AI software engineers requires a level of trust equal to or even greater than the trust established by human-driven software engineering practices. The recent trend toward LLM agents offers a path toward integrating the power of LLMs to create new code with the power of analysis tools to increase trust in the code. This opinion piece comments on whether LLM agents could dominate software engineering workflows in the future and whether the focus of programming will shift from programming at scale to programming with trust.', 'abstract_zh': '大型语言模型（LLMs）在生成代码片段方面展示了令人惊讶的能力，有潜力通过人工智能（AI）自动化软件工程中的大部分工作。我们认为，在人工智能软件工程师的成功部署中，建立的信任度应当与甚至高于由人工驱动的软件工程实践所建立的信任度。近年来，LLM智能代理的趋势提供了一条将LLMs的强大生成能力与分析工具的验证能力相结合的路径，以增强对代码的信任。本文观点讨论了LLM智能代理是否可能在未来主导软件工程工作流程，以及编程的重点是否会从大规模编程转向具有信任度的编程。', 'title_zh': 'AI软件工程师：基于信任的编程'}
{'arxiv_id': 'arXiv:2502.13764', 'title': 'An Overall Real-Time Mechanism for Classification and Quality Evaluation of Rice', 'authors': 'Wanke Xia, Ruxin Peng, Haoqi Chu, Xinlei Zhu, Zhiyu Yang, Yaojun Wang', 'link': 'https://arxiv.org/abs/2502.13764', 'abstract': 'Rice is one of the most widely cultivated crops globally and has been developed into numerous varieties. The quality of rice during cultivation is primarily determined by its cultivar and characteristics. Traditionally, rice classification and quality assessment rely on manual visual inspection, a process that is both time-consuming and prone to errors. However, with advancements in machine vision technology, automating rice classification and quality evaluation based on its cultivar and characteristics has become increasingly feasible, enhancing both accuracy and efficiency. This study proposes a real-time evaluation mechanism for comprehensive rice grain assessment, integrating a one-stage object detection approach, a deep convolutional neural network, and traditional machine learning techniques. The proposed framework enables rice variety identification, grain completeness grading, and grain chalkiness evaluation. The rice grain dataset used in this study comprises approximately 20,000 images from six widely cultivated rice varieties in China. Experimental results demonstrate that the proposed mechanism achieves a mean average precision (mAP) of 99.14% in the object detection task and an accuracy of 97.89% in the classification task. Furthermore, the framework attains an average accuracy of 97.56% in grain completeness grading within the same rice variety, contributing to an effective quality evaluation system.', 'abstract_zh': '大米是全球最常见的农作物之一，并已经发展成为多种类型。栽培期间的大米质量主要由其品种和特性决定。传统上，水稻分类和质量评估主要依靠人工视觉检查，这一过程既耗时又容易出错。然而，随着机器视觉技术的进步，基于品种和特性自动进行水稻分类和质量评价变得越来越可行，从而提高了准确性和效率。本研究提出了一种实时的综合大米粒评价机制，将单阶段目标检测方法、深度卷积神经网络以及传统机器学习技术融合在一起。所提出的框架能够实现水稻品种识别、完整度分级以及米粒垩白的评价。本研究中使用的大米粒数据集包含来自中国六种广泛栽培水稻品种的约20,000张图像。实验结果表明，在目标检测任务中，所提出机制达到了99.14%的平均准确率（mAP），在分类任务中的准确率为97.89%。此外，该框架在相同水稻品种的大米粒完整度分级中达到了97.56%的平均准确率，有助于建立有效的质量评价系统。', 'title_zh': '一种实时分类与质量评估的整体机制（针对稻米）'}
{'arxiv_id': 'arXiv:2502.13755', 'title': 'GPA: Grover Policy Agent for Generating Optimal Quantum Sensor Circuits', 'authors': 'Ahmad Alomari, Sathish A. P. Kumar', 'link': 'https://arxiv.org/abs/2502.13755', 'abstract': 'This study proposes a GPA for designing optimal Quantum Sensor Circuits (QSCs) to address complex quantum physics problems. The GPA consists of two parts: the Quantum Policy Evaluation (QPE) and the Quantum Policy Improvement (QPI). The QPE performs phase estimation to generate the search space, while the QPI utilizes Grover search and amplitude amplification techniques to efficiently identify an optimal policy that generates optimal QSCs. The GPA generates QSCs by selecting sequences of gates that maximize the Quantum Fisher Information (QFI) while minimizing the number of gates. The QSCs generated by the GPA are capable of producing entangled quantum states, specifically the squeezed states. High QFI indicates increased sensitivity to parameter changes, making the circuit useful for quantum state estimation and control tasks. Evaluation of the GPA on a QSC that consists of two qubits and a sequence of R_x, R_y, and S gates demonstrates its efficiency in generating optimal QSCs with a QFI of 1. Compared to existing quantum agents, the GPA achieves higher QFI with fewer gates, demonstrating a more efficient and scalable approach to the design of QSCs. This work illustrates the potential computational power of quantum agents for solving quantum physics problems', 'abstract_zh': '本文提出了一种基于梯度方法（Gradient Method, GPA）的设计最优量子传感器电路（Quantum Sensor Circuits, QSCs）的方法，以解决复杂的量子物理问题。GPA由两个部分组成：量子策略评估（Quantum Policy Evaluation, QPE）和量子策略改进（Quantum Policy Improvement, QPI）。QPE通过相位估计生成搜索空间，而QPI则利用Grover搜索和振幅放大技术高效地识别出能够生成最优QSCs的最优策略。GPA通过选择最大化量子费雪信息（Quantum Fisher Information, QFI）同时最小化门的数量的门序列来生成QSCs。由GPA生成的QSCs能够产生纠缠量子态，特别是压缩态。高QFI表明对参数变化的敏感度增加，使得电路适用于量子态估计和控制任务。在由两个量子位和一系列R_x，R_y和S门组成的QSC上评估GPA，证明了其生成具有QFI为1的最优QSCs的效率。与现有的量子代理相比，GPA使用较少的门实现了更高的QFI，展示了设计QSCs更加高效和可扩展的方法。本文展示了量子代理在解决量子物理问题方面的潜在计算能力。', 'title_zh': 'GPA：格罗ver策略代理生成最优量子传感器电路'}
{'arxiv_id': 'arXiv:2502.13751', 'title': 'RobustX: Robust Counterfactual Explanations Made Easy', 'authors': 'Junqi Jiang, Luca Marzari, Aaryan Purohit, Francesco Leofante', 'link': 'https://arxiv.org/abs/2502.13751', 'abstract': "The increasing use of Machine Learning (ML) models to aid decision-making in high-stakes industries demands explainability to facilitate trust. Counterfactual Explanations (CEs) are ideally suited for this, as they can offer insights into the predictions of an ML model by illustrating how changes in its input data may lead to different outcomes. However, for CEs to realise their explanatory potential, significant challenges remain in ensuring their robustness under slight changes in the scenario being explained. Despite the widespread recognition of CEs' robustness as a fundamental requirement, a lack of standardised tools and benchmarks hinders a comprehensive and effective comparison of robust CE generation methods. In this paper, we introduce RobustX, an open-source Python library implementing a collection of CE generation and evaluation methods, with a focus on the robustness property. RobustX provides interfaces to several existing methods from the literature, enabling streamlined access to state-of-the-art techniques. The library is also easily extensible, allowing fast prototyping of novel robust CE generation and evaluation methods.", 'abstract_zh': '随着机器学习（ML）模型在高风险行业中的日益广泛应用，增强其可解释性变得至关重要，以促进信任。对抗事实解释（Counterfactual Explanations, CEs）正是为此而设计的，它们能够通过展示输入数据变化如何导致不同结果来提供对ML模型预测的洞察。然而，为了实现CE的解释潜力，仍然存在确保其在轻微场景变化下鲁棒性的重大挑战。尽管鲁棒性被广泛认为是CEs的一项基本要求，但由于缺乏标准化的工具和基准，全面而有效的鲁棒CE生成方法比较变得困难。在本文中，我们引入了RobustX，这是一个开源的Python库，实现了多种CE生成和评估方法，重点关注鲁棒性这一特性。RobustX提供了对文献中多种现有方法的接口，使得访问最新的技术变得简便。该库还易于扩展，允许快速开发新的鲁棒CE生成和评估方法。', 'title_zh': 'RobustX：稳健的因果解释简化实现'}
{'arxiv_id': 'arXiv:2502.13728', 'title': 'Secure Federated Data Distillation', 'authors': 'Marco Arazzi, Mert Cihangiroglu, Serena Nicolazzo, Antonino Nocera', 'link': 'https://arxiv.org/abs/2502.13728', 'abstract': "Dataset Distillation (DD) is a powerful technique for reducing large datasets into compact, representative synthetic datasets, accelerating Machine Learning training. However, traditional DD methods operate in a centralized manner, which poses significant privacy threats and reduces its applicability. To mitigate these risks, we propose a Secure Federated Data Distillation framework (SFDD) to decentralize the distillation process while preserving this http URL existing Federated Distillation techniques that focus on training global models with distilled knowledge, our approach aims to produce a distilled dataset without exposing local contributions. We leverage the gradient-matching-based distillation method, adapting it for a distributed setting where clients contribute to the distillation process without sharing raw data. The central aggregator iteratively refines a synthetic dataset by integrating client-side updates while ensuring data confidentiality. To make our approach resilient to inference attacks perpetrated by the server that could exploit gradient updates to reconstruct private data, we create an optimized Local Differential Privacy approach, called LDPO-RLD (Label Differential Privacy Obfuscation via Randomized Linear Dispersion). Furthermore, we assess the framework's resilience against malicious clients executing backdoor attacks and demonstrate robustness under the assumption of a sufficient number of participating clients. Our experimental results demonstrate the effectiveness of SFDD and that the proposed defense concretely mitigates the identified vulnerabilities, with minimal impact on the performance of the distilled dataset. By addressing the interplay between privacy and federation in dataset distillation, this work advances the field of privacy-preserving Machine Learning making our SFDD framework a viable solution for sensitive data-sharing applications.", 'abstract_zh': '数据集蒸馏（Dataset Distillation，简称DD）是一种强大的技术，能够将大尺寸的数据集缩减为紧凑且具有代表性的合成数据集，从而加速机器学习训练。然而，传统的DD方法通常采用集中式模式，这带来了显著的隐私威胁并限制了其应用场景。为缓解这些问题，我们提出了一种安全的联邦数据蒸馏框架（Secure Federated Data Distillation，简称SFDD），以分散蒸馏过程的同时保持所有数据的安全性。与现有的聚焦于使用蒸馏知识训练全局模型的联邦蒸馏技术不同，我们旨在生成一个合成数据集，而不会暴露本地贡献。我们利用基于梯度匹配的蒸馏方法，并将其适应到一个分布式设置，在该设置中，客户端可以参与蒸馏过程而无需共享原始数据。中央聚合器通过整合客户端端侧更新来逐步精炼合成数据集，同时确保数据保密性。为了使我们的方法在服务器发起的推理攻击下具有鲁棒性，这种攻击可能利用梯度更新重建隐私数据，我们提出了一个优化的本地差分隐私方法，称为LDPO-RLD（Label Differential Privacy Obfuscation via Randomized Linear Dispersion）。此外，我们评估了框架抵御恶意客户端执行后门攻击的能力，并在参与客户端数量充足的情况下证明了该框架的鲁棒性。实验结果表明，SFDD框架的有效性以及所提出的防御措施能够具体缓解已识别的漏洞，且对合成数据集的性能影响最小。通过处理数据集蒸馏中的隐私与联邦的相互作用，本工作推进了隐私保护机器学习领域的发展，使我们的SFDD框架成为敏感数据共享应用的可行解决方案。', 'title_zh': '安全的联邦数据蒸馏'}
{'arxiv_id': 'arXiv:2502.13723', 'title': 'Direct Value Optimization: Improving Chain-of-Thought Reasoning in LLMs with Refined Values', 'authors': 'Hongbo Zhang, Han Cui, Guangsheng Bao, Linyi Yang, Jun Wang, Yue Zhang', 'link': 'https://arxiv.org/abs/2502.13723', 'abstract': 'We introduce Direct Value Optimization (DVO), an innovative reinforcement learning framework for enhancing large language models in complex reasoning tasks. Unlike traditional methods relying on preference labels, DVO utilizes value signals at individual reasoning steps, optimizing models via a mean squared error loss. The key benefit of DVO lies in its fine-grained supervision, circumventing the need for labor-intensive human annotations. Target values within the DVO are estimated using either Monte Carlo Tree Search or an outcome value model. Our empirical analysis on both mathematical and commonsense reasoning tasks shows that DVO consistently outperforms existing offline preference optimization techniques, even with fewer training steps. These findings underscore the importance of value signals in advancing reasoning capabilities and highlight DVO as a superior methodology under scenarios lacking explicit human preference information.', 'abstract_zh': '我们介绍了直接价值优化（DVO），这是一种创新的强化学习框架，用于增强在复杂推理任务中的大型语言模型。与依赖偏好标签的传统方法不同，DVO 利用每个推理步骤的价值信号，并通过均方误差损失优化模型。DVO 的主要优势在于其精细监督，从而避免了需要劳动密集型的人工标注。在 DVO 中，目标值可以通过蒙特卡洛树搜索（MCTS）或结果价值模型进行估算。我们在数学推理和常识推理任务上的实证分析表明，即使训练步骤较少，DVO 也能持续优于现有的离线偏好优化技术。这些发现强调了价值信号在提升推理能力方面的重要性，并突显了在缺乏明确的人类偏好信息的情况下，DVO 作为一个更优的方法论的优势。', 'title_zh': '直接价值优化：通过细化的价值提升大型语言模型中的链式思考推理'}
{'arxiv_id': 'arXiv:2502.13719', 'title': 'TrustRAG: An Information Assistant with Retrieval Augmented Generation', 'authors': 'Yixing Fan, Qiang Yan, Wenshan Wang, Jiafeng Guo, Ruqing Zhang, Xueqi Cheng', 'link': 'https://arxiv.org/abs/2502.13719', 'abstract': '\\Ac{RAG} has emerged as a crucial technique for enhancing large models with real-time and domain-specific knowledge. While numerous improvements and open-source tools have been proposed to refine the \\ac{RAG} framework for accuracy, relatively little attention has been given to improving the trustworthiness of generated results. To address this gap, we introduce TrustRAG, a novel framework that enhances \\ac{RAG} from three perspectives: indexing, retrieval, and generation. Specifically, in the indexing stage, we propose a semantic-enhanced chunking strategy that incorporates hierarchical indexing to supplement each chunk with contextual information, ensuring semantic completeness. In the retrieval stage, we introduce a utility-based filtering mechanism to identify high-quality information, supporting answer generation while reducing input length. In the generation stage, we propose fine-grained citation enhancement, which detects opinion-bearing sentences in responses and infers citation relationships at the sentence-level, thereby improving citation accuracy. We open-source the TrustRAG framework and provide a demonstration studio designed for excerpt-based question answering tasks \\footnote{this https URL}. Based on these, we aim to help researchers: 1) systematically enhancing the trustworthiness of \\ac{RAG} systems and (2) developing their own \\ac{RAG} systems with more reliable outputs.', 'abstract_zh': '\\Ac{RAG} 已成为增强大型模型实时和领域特定知识的关键技术。尽管已经提出了许多改进和开源工具来提高 \\ac{RAG} 框架的准确度，但生成结果的信任度改进则相对较少受到关注。为弥补这一不足，我们引入了 TrustRAG，这是一种从三个角度增强 \\ac{RAG} 的新型框架：索引、检索和生成。具体而言，在索引阶段，我们提出了一种语义增强的分块策略，结合了层次索引，以补充每个分块的上下文信息，确保语义完整；在检索阶段，我们引入了一种基于效用的过滤机制，以识别高质量的信息，支持答案生成并减少输入长度；在生成阶段，我们提出了细粒度的引文增强策略，检测响应中的主观陈述句子，并在句级推断引文关系，从而提高引文准确性。我们开源了 TrustRAG 框架，并提供了一个用于节选问答任务的演示工作室\\footnote{this https URL}。基于这些改进，我们希望帮助研究人员：1）系统地增强 \\ac{RAG} 系统的信任度；2）开发具有更可靠输出的自定义 \\ac{RAG} 系统。', 'title_zh': 'TrustRAG：一种检索增强生成的信息助手'}
{'arxiv_id': 'arXiv:2502.13685', 'title': 'MoM: Linear Sequence Modeling with Mixture-of-Memories', 'authors': 'Jusen Du, Weigao Sun, Disen Lan, Jiaxi Hu, Yu Cheng', 'link': 'https://arxiv.org/abs/2502.13685', 'abstract': 'Linear sequence modeling methods, such as linear attention, state space modeling, and linear RNNs, offer significant efficiency improvements by reducing the complexity of training and inference. However, these methods typically compress the entire input sequence into a single fixed-size memory state, which leads to suboptimal performance on recall-intensive downstream tasks. Drawing inspiration from neuroscience, particularly the brain\'s ability to maintain robust long-term memory while mitigating "memory interference", we introduce a novel architecture called Mixture-of-Memories (MoM). MoM utilizes multiple independent memory states, with a router network directing input tokens to specific memory states. This approach greatly enhances the overall memory capacity while minimizing memory interference. As a result, MoM performs exceptionally well on recall-intensive tasks, surpassing existing linear sequence modeling techniques. Despite incorporating multiple memory states, the computation of each memory state remains linear in complexity, allowing MoM to retain the linear-complexity advantage during training, while constant-complexity during inference. Our experimental results show that MoM significantly outperforms current linear sequence models on downstream language tasks, particularly recall-intensive tasks, and even achieves performance comparable to Transformer models. The code is released at this https URL and is also released as a part of this https URL.', 'abstract_zh': '线性序列建模方法，如线性注意力、状态空间建模和线性循环神经网络（RNN），通过降低训练和推理的复杂性，提供了显著的效率改进。然而，这些方法通常将整个输入序列压缩到一个固定大小的记忆状态中，从而在依赖召回的任务上表现不佳。受到神经科学的启发，特别是大脑维持长期记忆的能力以及减轻“记忆干扰”的能力，我们引入了一种名为Memory Mixture（MoM）的新架构。MoM 使用多个独立的记忆状态，并通过路由网络将输入令牌定向到特定的记忆状态。这种方法大幅提升了整体记忆容量，同时最小化了记忆干扰。因此，MoM 在依赖召回的任务上表现出色，超越了现有的线性序列建模技术。尽管 MoM 包含了多个记忆状态，但计算每个记忆状态的复杂度仍然呈线性增长，使得 MoM 既能保持在训练过程中线性复杂度的优势，也能在推理过程中保持常数复杂度。我们的实验结果表明，MoM 在下游语言任务上明显优于现有的线性序列模型，尤其是在依赖召回的任务上，其性能甚至可与 Transformer 模型相媲美。MoM 的代码已在以下网址发布：https://github.com/alibaba/MoM，并作为 Alibaba 的开放研究代码库的一部分：https://github.com/alibaba/Qwen。', 'title_zh': 'MoM：混合记忆的线性序列建模'}
{'arxiv_id': 'arXiv:2502.13681', 'title': 'An LLM-based Agent for Reliable Docker Environment Configuration', 'authors': 'Ruida Hu, Chao Peng, Xinchen Wang, Cuiyun Gao', 'link': 'https://arxiv.org/abs/2502.13681', 'abstract': 'Environment configuration is a critical yet time-consuming step in software development, especially when dealing with unfamiliar code repositories. While Large Language Models (LLMs) demonstrate the potential to accomplish software engineering tasks, existing methods for environment configuration often rely on manual efforts or fragile scripts, leading to inefficiencies and unreliable outcomes. We introduce Repo2Run, the first LLM-based agent designed to fully automate environment configuration and generate executable Dockerfiles for arbitrary Python repositories. We address two major challenges: (1) enabling the LLM agent to configure environments within isolated Docker containers, and (2) ensuring the successful configuration process is recorded and accurately transferred to a Dockerfile without error. To achieve this, we propose atomic configuration synthesis, featuring a dual-environment architecture (internal and external environment) with a rollback mechanism to prevent environment "pollution" from failed commands, guaranteeing atomic execution (execute fully or not at all) and a Dockerfile generator to transfer successful configuration steps into runnable Dockerfiles. We evaluate Repo2Run~on our proposed benchmark of 420 recent Python repositories with unit tests, where it achieves an 86.0% success rate, outperforming the best baseline by 63.9%.', 'abstract_zh': '软件开发中的环境配置是至关重要的一步，尤其是在处理不熟悉的代码仓库时。虽然大型语言模型（LLMs）展示了完成软件工程任务的潜力，但现有的环境配置方法往往依赖于手动努力或脆弱的脚本，导致效率低下且结果不可靠。我们引入了Repo2Run，这是首个基于LLM的代理，旨在完全自动化环境配置并生成适用于任意Python仓库的可执行Dockerfile。我们解决了两个主要挑战：（1）使LLM代理能够在隔离的Docker容器内配置环境，（2）确保配置过程的成功记录能够准确无误地转移到Dockerfile中，不会出错。为实现这一目标，我们提出了原子配置合成，该方法采用双环境架构（内部环境和外部环境），并具有回滚机制以防止由于命令失败而导致的环境“污染”，从而保证原子执行（要么完全执行，要么根本不执行），并通过Dockerfile生成器将成功的配置步骤转换为可运行的Dockerfile。我们在420个具有单元测试的最近Python仓库提出的基准上评估了Repo2Run，其成功率达到了86.0%，比最佳基线高出63.9%。', 'title_zh': '基于大语言模型的代理用于可靠的Docker环境配置'}
{'arxiv_id': 'arXiv:2502.13668', 'title': 'PeerQA: A Scientific Question Answering Dataset from Peer Reviews', 'authors': 'Tim Baumgärtner, Ted Briscoe, Iryna Gurevych', 'link': 'https://arxiv.org/abs/2502.13668', 'abstract': 'We present PeerQA, a real-world, scientific, document-level Question Answering (QA) dataset. PeerQA questions have been sourced from peer reviews, which contain questions that reviewers raised while thoroughly examining the scientific article. Answers have been annotated by the original authors of each paper. The dataset contains 579 QA pairs from 208 academic articles, with a majority from ML and NLP, as well as a subset of other scientific communities like Geoscience and Public Health. PeerQA supports three critical tasks for developing practical QA systems: Evidence retrieval, unanswerable question classification, and answer generation. We provide a detailed analysis of the collected dataset and conduct experiments establishing baseline systems for all three tasks. Our experiments and analyses reveal the need for decontextualization in document-level retrieval, where we find that even simple decontextualization approaches consistently improve retrieval performance across architectures. On answer generation, PeerQA serves as a challenging benchmark for long-context modeling, as the papers have an average size of 12k tokens. Our code and data is available at this https URL.', 'abstract_zh': '我们介绍了PeerQA，这是一个基于现实世界、面向科学领域的文档级问答（QA）数据集。PeerQA的问题来源于同行评审，这些问题是在详细审阅科学文章时评审者提出的问题。答案由每篇论文的原始作者进行标注。数据集包含来自208篇学术文章的579个QA对，其中大部分来自机器学习和自然语言处理领域，同时还包括来自地球科学和公共卫生等其他科学社区的子集。PeerQA支持开发实用QA系统时的三项关键任务：证据检索、不可回答问题分类以及回答生成。我们对收集的数据集进行了详细分析，并进行了实验以建立所有三项任务的基本系统。我们的实验和分析揭示了在文档级检索中对上下文的去除需求，我们发现即使简单的去语境化方法也能够一致地提升跨架构的检索性能。在回答生成方面，PeerQA作为长期上下文建模的挑战性基准具有重要意义，因为论文的平均大小约为12k词。我们的代码和数据可以在以下网页获得：[此处插入网址]。', 'title_zh': 'PeerQA：来自同行评审的科学问答数据集'}
{'arxiv_id': 'arXiv:2502.13652', 'title': 'C2T: A Classifier-Based Tree Construction Method in Speculative Decoding', 'authors': 'Feiye Huo, Jianchao Tan, Kefeng Zhang, Xunliang Cai, Shengli Sun', 'link': 'https://arxiv.org/abs/2502.13652', 'abstract': 'The growing scale of Large Language Models (LLMs) has exacerbated inference latency and computational costs. Speculative decoding methods, which aim to mitigate these issues, often face inefficiencies in the construction of token trees and the verification of candidate tokens. Existing strategies, including chain mode, static tree, and dynamic tree approaches, have limitations in accurately preparing candidate token trees for verification. We propose a novel method named C2T that adopts a lightweight classifier to generate and prune token trees dynamically. Our classifier considers additional feature variables beyond the commonly used joint probability to predict the confidence score for each draft token to determine whether it is the candidate token for verification. This method outperforms state-of-the-art (SOTA) methods such as EAGLE-2 on multiple benchmarks, by reducing the total number of candidate tokens by 25% while maintaining or even improving the acceptance length.', 'abstract_zh': '大型语言模型（LLMs）规模的不断扩大加剧了推理延迟和计算成本。为了缓解这些问题，推测解码方法常常面临在构建标记树和验证候选标记方面存在的效率低下问题。现有的策略，包括链模式、静态树和动态树方法，对于准确准备用于验证的候选标记树都有一定的局限性。我们提出了一种名为C2T的新方法，该方法采用轻量级分类器动态生成和修剪标记树。我们的分类器除了考虑常用的联合概率外，还会考虑其他特征变量来预测每个草稿标记的置信度分数，从而确定它是否是验证的候选标记。在多个基准测试中，这种方法优于现有的先进方法（如EAGLE-2），能够在减少25%候选标记数量的同时，保持甚至提高接受长度。', 'title_zh': 'C2T：推测解码中基于分类器的树构建方法'}
{'arxiv_id': 'arXiv:2502.13638', 'title': 'Integrating Inverse and Forward Modeling for Sparse Temporal Data from Sensor Networks', 'authors': 'Julian Vexler, Björn Vieten, Martin Nelke, Stefan Kramer', 'link': 'https://arxiv.org/abs/2502.13638', 'abstract': 'We present CavePerception, a framework for the analysis of sparse data from sensor networks that incorporates elements of inverse modeling and forward modeling. By integrating machine learning with physical modeling in a hypotheses space, we aim to improve the interpretability of sparse, noisy, and potentially incomplete sensor data. The framework assumes data from a two-dimensional sensor network laid out in a graph structure that detects certain objects, with certain motion patterns. Examples of such sensors are magnetometers. Given knowledge about the objects and the way they act on the sensors, one can develop a data generator that produces data from simulated motions of the objects across the sensor field. The framework uses the simulated data to infer object behaviors across the sensor network. The approach is experimentally tested on real-world data, where magnetometers are used on an airport to detect and identify aircraft motions. Experiments demonstrate the value of integrating inverse and forward modeling, enabling intelligent systems to better understand and predict complex, sensor-driven events.', 'abstract_zh': '我们提出了CavePerception框架，这是一种用于分析来自传感器网络的稀疏数据的框架，结合了逆向建模和前向建模的元素。通过将机器学习与物理建模结合在一个假设空间中，我们旨在提高稀疏、噪声和可能不完整的传感器数据的可解释性。该框架假设来自一个二维传感器网络的数据，这些传感器网络以图结构排列，用于检测某些物体，并识别特定的运动模式。这类传感器的例子包括磁力计。根据物体的知识以及它们对传感器的作用方式，可以开发出数据生成器，该生成器可生成模拟物体在传感器区域移动的数据。框架使用模拟数据来推断传感器网络中物体的行为。该方法在现实世界数据上进行了实验测试，在机场中使用磁力计来检测和识别飞机的运动。实验表明，将逆向建模和前向建模相结合的价值，有助于智能系统更好地理解和预测由传感器驱动的复杂事件。', 'title_zh': '将逆向建模与正向建模集成以处理传感器网络中的稀疏时间数据'}
{'arxiv_id': 'arXiv:2502.13632', 'title': 'Concept Layers: Enhancing Interpretability and Intervenability via LLM Conceptualization', 'authors': 'Or Raphael Bidusa, Shaul Markovitch', 'link': 'https://arxiv.org/abs/2502.13632', 'abstract': "The opaque nature of Large Language Models (LLMs) has led to significant research efforts aimed at enhancing their interpretability, primarily through post-hoc methods. More recent in-hoc approaches, such as Concept Bottleneck Models (CBMs), offer both interpretability and intervenability by incorporating explicit concept representations. However, these methods suffer from key limitations, including reliance on labeled concept datasets and significant architectural modifications that challenges re-integration into existing system pipelines. In this work, we introduce a new methodology for incorporating interpretability and intervenability into an existing model by integrating Concept Layers (CLs) into its architecture. Our approach projects the model's internal vector representations into a conceptual, explainable vector space before reconstructing and feeding them back into the model. Furthermore, we eliminate the need for a human-selected concept set by algorithmically searching an ontology for a set of concepts that can be either task-specific or task-agnostic. We evaluate CLs across multiple tasks, demonstrating that they maintain the original model's performance and agreement while enabling meaningful interventions. Additionally, we present a proof of concept showcasing an intervenability interface, allowing users to adjust model behavior dynamically, such as mitigating biases during inference.", 'abstract_zh': '大型语言模型（LLMs）的不透明性导致了大量旨在提高其可解释性的研究努力，主要通过事后方法进行。更近期的内置方法，如概念瓶颈模型（CBMs），通过引入明确的概念表示，同时提供了可解释性和干预性。然而，这些方法也面临一些关键局限性，包括对标记概念数据集的依赖以及对现有架构进行重大修改，这给重新整合进现有的系统管道带来了挑战。在本研究中，我们提出了一种新的方法，通过将概念层（CLs）嵌入现有模型的架构中，以实现可解释性和干预性。我们的方法将模型的内部向量表示投影到一个概念性的、可解释的向量空间中，然后再进行重构并反馈到模型中。此外，我们通过算法搜索概念本体来消除人工选择概念集的需求，这组概念可以是与任务特定的，也可以是与任务无关的。我们对CLs进行了多任务评估，结果显示，它们在保持原始模型性能和一致性的同时，还允许进行有意义的干预。此外，我们还展示了概念层干预接口的概念验证，用户可以动态调整模型行为，例如，在推理过程中缓解偏见。', 'title_zh': '概念层：通过LLM概念化增强可解释性和可干预性'}
{'arxiv_id': 'arXiv:2502.13622', 'title': 'REFIND: Retrieval-Augmented Factuality Hallucination Detection in Large Language Models', 'authors': 'DongGeon Lee, Hwanjo Yu', 'link': 'https://arxiv.org/abs/2502.13622', 'abstract': 'Hallucinations in large language model (LLM) outputs severely limit their reliability in knowledge-intensive tasks such as question answering. To address this challenge, we introduce REFIND (Retrieval-augmented Factuality hallucINation Detection), a novel framework that detects hallucinated spans within LLM outputs by directly leveraging retrieved documents. As part of the REFIND, we propose the Context Sensitivity Ratio (CSR), a novel metric that quantifies the sensitivity of LLM outputs to retrieved evidence. This innovative approach enables REFIND to efficiently and accurately detect hallucinations, setting it apart from existing methods. In the evaluation, REFIND demonstrated robustness across nine languages, including low-resource settings, and significantly outperformed baseline models, achieving superior IoU scores in identifying hallucinated spans. This work highlights the effectiveness of quantifying context sensitivity for hallucination detection, thereby paving the way for more reliable and trustworthy LLM applications across diverse languages.', 'abstract_zh': '大型语言模型（LLM）输出中的幻觉严重限制了其在知识密集型任务（如问答）中的可靠性。为了解决这一挑战，我们提出了一种新颖的方法REFIND（Retrieval-augmented Factuality hallucINation Detection），该方法通过直接利用检索到的文档来检测LLM输出中的幻觉片段。作为REFIND的一部分，我们提出了上下文敏感度比（CSR，Context Sensitivity Ratio），这是一种新颖的度量标准，用于量化LLM输出对检索到的证据的敏感性。这种创新方法使REFIND能够高效且准确地检测幻觉，从而使它在现有方法中脱颖而出。在评估中，REFIND在九种语言（包括低资源环境）中显示出了鲁棒性，并大幅优于基线模型，在识别幻觉片段方面获得了更高的IoU分数。这项研究成果突显了量化上下文敏感性在幻觉检测中的有效性，从而为不同语言的大规模语言模型（LLM）应用提供了更可靠和可信的路径。', 'title_zh': 'REFIND：大型语言模型中检索增强的事实幻觉检测'}
{'arxiv_id': 'arXiv:2502.13621', 'title': 'Decentralized Planning Using Probabilistic Hyperproperties', 'authors': 'Francesco Pontiggia, Filip Macák, Roman Andriushchenko, Michele Chiari, Milan Češka', 'link': 'https://arxiv.org/abs/2502.13621', 'abstract': 'Multi-agent planning under stochastic dynamics is usually formalised using decentralized (partially observable) Markov decision processes ( MDPs) and reachability or expected reward specifications. In this paper, we propose a different approach: we use an MDP describing how a single agent operates in an environment and probabilistic hyperproperties to capture desired temporal objectives for a set of decentralized agents operating in the environment. We extend existing approaches for model checking probabilistic hyperproperties to handle temporal formulae relating paths of different agents, thus requiring the self-composition between multiple MDPs. Using several case studies, we demonstrate that our approach provides a flexible and expressive framework to broaden the specification capabilities with respect to existing planning techniques. Additionally, we establish a close connection between a subclass of probabilistic hyperproperties and planning for a particular type of Dec-MDPs, for both of which we show undecidability. This lays the ground for the use of existing decentralized planning tools in the field of probabilistic hyperproperty verification.', 'abstract_zh': '在具有随机动态的多智能体规划中，通常使用去中心化的（部分可观测的）马尔可夫决策过程（Markov decision processes, MDPs）和可达性或期望奖励规范进行形式化。本文提出了一种不同的方法：我们使用描述单个智能体在环境中的操作的MDP，并使用概率超属性来捕捉一组在环境中操作的去中心化智能体的期望时间目标。我们将现有的概率超属性的模型检查方法扩展到处理不同智能体路径之间的临时公式，从而要求在多个MDP之间进行自我组合。通过几个案例研究，我们证明了本方法提供了一个灵活且具表现力的框架，以增强相对于现有规划技术的规范能力。此外，我们建立了概率超属性的一个子类与特定类型Dec-MDP规划之间的紧密联系，并证明了这两种情况下的不可判定性。这一结果为在概率超属性验证领域利用现有的去中心化规划工具奠定了基础。', 'title_zh': '使用概率超性质进行去中心化规划'}
{'arxiv_id': 'arXiv:2502.13619', 'title': 'Complex Ontology Matching with Large Language Model Embeddings', 'authors': 'Guilherme Sousa, Rinaldo Lima, Cassia Trojahn', 'link': 'https://arxiv.org/abs/2502.13619', 'abstract': 'Ontology, and more broadly, Knowledge Graph Matching is a challenging task in which expressiveness has not been fully addressed. Despite the increasing use of embeddings and language models for this task, approaches for generating expressive correspondences still do not take full advantage of these models, in particular, large language models (LLMs). This paper proposes to integrate LLMs into an approach for generating expressive correspondences based on alignment need and ABox-based relation discovery. The generation of correspondences is performed by matching similar surroundings of instance sub-graphs. The integration of LLMs results in different architectural modifications, including label similarity, sub-graph matching, and entity matching. The performance word embeddings, sentence embeddings, and LLM-based embeddings, was compared. The results demonstrate that integrating LLMs surpasses all other models, enhancing the baseline version of the approach with a 45\\% increase in F-measure.', 'abstract_zh': '本论文探讨了本体和更广泛的知识图谱匹配任务，尽管嵌入表示和语言模型的应用越来越广泛，但生成富有表现力的对应关系的方法仍未充分利用这些模型，尤其是大型语言模型（LLMs）。本文提出了一种将LLMs整合到基于实例子图相似性对齐和ABox关系发现的生成富有表现力对应关系的方法中。通过匹配实例子图周围的相似部分进行对应关系的生成。将LLMs整合到了新架构中，这包括标签相似性、子图匹配和实体匹配。研究了词嵌入、句子嵌入和基于LLM的嵌入的表现。结果显示，将LLMs整合进来的方法显著优于其他模型，使方法的基础版本的F-测量值提高了45%。', 'title_zh': '使用大型语言模型嵌入进行复杂的本体匹配'}
{'arxiv_id': 'arXiv:2502.13606', 'title': 'LaVCa: LLM-assisted Visual Cortex Captioning', 'authors': 'Takuya Matsuyama, Shinji Nishimoto, Yu Takagi', 'link': 'https://arxiv.org/abs/2502.13606', 'abstract': 'Understanding the property of neural populations (or voxels) in the human brain can advance our comprehension of human perceptual and cognitive processing capabilities and contribute to developing brain-inspired computer models. Recent encoding models using deep neural networks (DNNs) have successfully predicted voxel-wise activity. However, interpreting the properties that explain voxel responses remains challenging because of the black-box nature of DNNs. As a solution, we propose LLM-assisted Visual Cortex Captioning (LaVCa), a data-driven approach that uses large language models (LLMs) to generate natural-language captions for images to which voxels are selective. By applying LaVCa for image-evoked brain activity, we demonstrate that LaVCa generates captions that describe voxel selectivity more accurately than the previously proposed method. Furthermore, the captions generated by LaVCa quantitatively capture more detailed properties than the existing method at both the inter-voxel and intra-voxel levels. Furthermore, a more detailed analysis of the voxel-specific properties generated by LaVCa reveals fine-grained functional differentiation within regions of interest (ROIs) in the visual cortex and voxels that simultaneously represent multiple distinct concepts. These findings offer profound insights into human visual representations by assigning detailed captions throughout the visual cortex while highlighting the potential of LLM-based methods in understanding brain representations. Please check out our webpage at this https URL', 'abstract_zh': '了解人类大脑中神经群体（或体素）的特性可以增进我们对人类感知和认知处理能力的理解，并有助于开发受大脑启发的计算机模型。近年来，使用深度神经网络（DNNs）的编码模型已经成功地预测了体素级别的活动。然而，由于DNNs的黑盒性质，解释解释体素响应的特性仍然具有挑战性。为此，我们提出了一种基于数据的方法——LaVCa（LLM辅助视觉皮层描述），利用大规模语言模型（LLMs）为具有体素选择性的图像生成自然语言描述。通过将LaVCa应用于由图像引发的大脑活动，我们证明了LaVCa生成的描述体素选择性的 caption 更加准确，与之前的方法相比，LaVCa生成的 caption 在体素间和体素内层面更详细地捕捉到了更多的特性。此外，对LaVCa生成的体素特定特性的详细分析揭示了视觉皮层中感兴趣区域（ROIs）内的精细功能分化，以及同时代表多个不同概念的体素。这些发现通过在整个视觉皮层中赋予详细的 caption 提供了深刻的人类视觉表征洞察，并突显了基于LLM的方法在理解大脑表征中的潜力。请访问我们的网页：[此 https URL]', 'title_zh': 'LaVCa：LLM辅助的视觉 cortex 图像描述'}
{'arxiv_id': 'arXiv:2502.13603', 'title': 'Efficient Safety Retrofitting Against Jailbreaking for LLMs', 'authors': 'Dario Garcia-Gasulla, Anna Arias-Duart, Adrian Tormos, Daniel Hinjos, Oscar Molina-Sedano, Ashwin Kumar Gururajan, Maria Eugenia Cardello', 'link': 'https://arxiv.org/abs/2502.13603', 'abstract': "Direct Preference Optimization (DPO) is an efficient alignment technique that steers LLMs towards preferable outputs by training on preference data, bypassing the need for explicit reward models. Its simplicity enables easy adaptation to various domains and safety requirements. This paper examines DPO's effectiveness in model safety against jailbreaking attacks while minimizing data requirements and training costs. We introduce Egida, a dataset expanded from multiple sources, which includes 27 different safety topics and 18 different attack styles, complemented with synthetic and human labels. This data is used to boost the safety of state-of-the-art LLMs (Llama-3.1-8B/70B-Instruct, Qwen-2.5-7B/72B-Instruct) across topics and attack styles. In addition to safety evaluations, we assess their post-alignment performance degradation in general purpose tasks, and their tendency to over refusal. Following the proposed methodology, trained models reduce their Attack Success Rate by 10%-30%, using small training efforts (2,000 samples) with low computational cost (3\\$ for 8B models, 20\\$ for 72B models). Safety aligned models generalize to unseen topics and attack styles, with the most successful attack style reaching a success rate around 5%. Size and family are found to strongly influence model malleability towards safety, pointing at the importance of pre-training choices. To validate our findings, a large independent assessment of human preference agreement with Llama-Guard-3-8B is conducted by the authors and the associated dataset Egida-HSafe is released. Overall, this study illustrates how affordable and accessible it is to enhance LLM safety using DPO while outlining its current limitations. All datasets and models are released to enable reproducibility and further research.", 'abstract_zh': '直接偏好优化（DPO）是一种高效的对齐技术，通过使用偏好数据进行训练来引导大模型（LLM）生成更优选的输出，从而绕过了需要显式奖励模型的步骤。其简洁性使其易于适应各种领域和安全要求。本文探讨了DPO在对抗模型破解攻击时的有效性，同时尽量减少数据需求和训练成本。我们引入了Egida数据集，该数据集从多个来源扩展而来，包含27种不同的安全主题和18种不同的攻击样式，并且附带了合成和人工标签。这些数据被用于提升先进大模型（如Llama-3.1-8B/70B-Instruct、Qwen-2.5-7B/72B-Instruct）的安全性，覆盖了各种主题和攻击样式。除安全评估外，我们还评估了它们在通用任务中的后调整性能下降情况以及过度拒绝的倾向。按照提议的方法，经过训练的模型在使用少量训练样本（2,000个样本）和较低计算成本（8B模型3美元，72B模型20美元）的情况下，其攻击成功率降低了10%-30%。安全对齐的模型能够泛化到未见过的主题和攻击样式，其中最成功的攻击样式的成功率约为5%。研究发现，模型的大小和家族对其向安全性转变的能力有显著影响，这强调了前期训练选择的重要性。为了验证我们的发现，作者对Llama-Guard-3-8B的人类偏好一致性进行了大规模独立评估，并发布了相关数据集Egida-HSafe。总体而言，这项研究展示了使用DPO提升LLM安全性是多么可行和便捷，同时也指出了其当前的局限性。所有数据集和模型均已发布，以实现可重复性和进一步的研究。', 'title_zh': '针对 Jailbreaking 的高效安全加固方法——以大型语言模型 (LLMs) 为例'}
{'arxiv_id': 'arXiv:2502.13595', 'title': 'MMTEB: Massive Multilingual Text Embedding Benchmark', 'authors': 'Kenneth Enevoldsen, Isaac Chung, Imene Kerboua, Márton Kardos, Ashwin Mathur, David Stap, Jay Gala, Wissam Siblini, Dominik Krzemiński, Genta Indra Winata, Saba Sturua, Saiteja Utpala, Mathieu Ciancone, Marion Schaeffer, Gabriel Sequeira, Diganta Misra, Shreeya Dhakal, Jonathan Rystrøm, Roman Solomatin, Ömer Çağatan, Akash Kundu, Martin Bernstorff, Shitao Xiao, Akshita Sukhlecha, Bhavish Pahwa, Rafał Poświata, Kranthi Kiran GV, Shawon Ashraf, Daniel Auras, Björn Plüster, Jan Philipp Harries, Loïc Magne, Isabelle Mohr, Mariya Hendriksen, Dawei Zhu, Hippolyte Gisserot-Boukhlef, Tom Aarsen, Jan Kostkan, Konrad Wojtasik, Taemin Lee, Marek Šuppa, Crystina Zhang, Roberta Rocca, Mohammed Hamdy, Andrianos Michail, John Yang, Manuel Faysse, Aleksei Vatolin, Nandan Thakur, Manan Dey, Dipam Vasani, Pranjal Chitale, Simone Tedeschi, Nguyen Tai, Artem Snegirev, Michael Günther, Mengzhou Xia, Weijia Shi, Xing Han Lù, Jordan Clive, Gayatri Krishnakumar, Anna Maksimova, Silvan Wehrli, Maria Tikhonova, Henil Panchal, Aleksandr Abramov, Malte Ostendorff, Zheng Liu, Simon Clematide, Lester James Miranda, Alena Fenogenova, Guangyu Song, Ruqiya Bin Safi, Wen-Ding Li, Alessia Borghini, Federico Cassano, Hongjin Su, Jimmy Lin, Howard Yen, Lasse Hansen, Sara Hooker, Chenghao Xiao, Vaibhav Adlakha, Orion Weller, Siva Reddy, Niklas Muennighoff', 'link': 'https://arxiv.org/abs/2502.13595', 'abstract': 'Text embeddings are typically evaluated on a limited set of tasks, which are constrained by language, domain, and task diversity. To address these limitations and provide a more comprehensive evaluation, we introduce the Massive Multilingual Text Embedding Benchmark (MMTEB) - a large-scale, community-driven expansion of MTEB, covering over 500 quality-controlled evaluation tasks across 250+ languages. MMTEB includes a diverse set of challenging, novel tasks such as instruction following, long-document retrieval, and code retrieval, representing the largest multilingual collection of evaluation tasks for embedding models to date. Using this collection, we develop several highly multilingual benchmarks, which we use to evaluate a representative set of models. We find that while large language models (LLMs) with billions of parameters can achieve state-of-the-art performance on certain language subsets and task categories, the best-performing publicly available model is multilingual-e5-large-instruct with only 560 million parameters. To facilitate accessibility and reduce computational cost, we introduce a novel downsampling method based on inter-task correlation, ensuring a diverse selection while preserving relative model rankings. Furthermore, we optimize tasks such as retrieval by sampling hard negatives, creating smaller but effective splits. These optimizations allow us to introduce benchmarks that drastically reduce computational demands. For instance, our newly introduced zero-shot English benchmark maintains a ranking order similar to the full-scale version but at a fraction of the computational cost.', 'abstract_zh': '文本嵌入通常是在有限的任务集上进行评估，这些任务受语言、领域及任务多样性的限制。为了应对这些限制并提供更全面的评估，我们引入了大规模多语言文本嵌入基准（MMTEB）——这是对MTEB的大型、社区驱动的扩展，在250多种语言中涵盖了超过500个质量控制的任务。MMTEB 包含了一系列具有挑战性和新颖性的任务，例如指令跟随、长文档检索和代码检索，是迄今为止用于嵌入模型评估的最大规模的多语言任务集合。\n\n使用这一集合，我们开发了多个高度多语言的基准测试，并利用这些基准测试评估了一组代表性模型。我们发现，虽然具有数十亿参数的大语言模型（LLMs）在某些语言子集和任务类别上可以取得最佳性能，但目前公开可用的最佳模型是参数量仅为5.6亿的多语言-e5-large-instruct。为了提高可访问性并降低计算成本，我们引入了一种基于任务间相关性的新颖下采样方法，确保多样化的任务选择同时保持模型的相对排名。此外，我们通过在检索任务中采样难以区分的负例，创建了更小但有效的分割，对任务进行了优化。这些优化使我们能够引入大幅降低计算需求的基准测试。例如，我们新引入的零shot英语基准测试在评估模型方面保持了与大规模版本相似的排名，但计算成本仅为前者的几分之一。', 'title_zh': '大规模多语言文本嵌入基准：MMTEB'}
{'arxiv_id': 'arXiv:2502.13576', 'title': 'Beyond One-Size-Fits-All: Tailored Benchmarks for Efficient Evaluation', 'authors': 'Peiwen Yuan, Yueqi Zhang, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Jiayi Shi, Chuyi Tan, Boyuan Pan, Yao Hu, Kan Li', 'link': 'https://arxiv.org/abs/2502.13576', 'abstract': "Evaluating models on large benchmarks is very resource-intensive, especially during the period of rapid model evolution. Existing efficient evaluation methods estimate the performance of target models by testing them only on a small and static coreset of the benchmark, which is derived from the publicly available evaluation results of source models. These methods rely on the assumption that target models have high prediction consistency with source models. However, we demonstrate that it doesn't generalize well in practice. To alleviate the inconsistency issue, we present TailoredBench, a method that conducts customized evaluation tailored to each target model. Specifically, a Global-coreset is first constructed as a probe to identify the most consistent source models for each target model with an adaptive source model selection strategy. Afterwards, a scalable K-Medoids clustering algorithm is proposed to extend the Global-coreset to a tailored Native-coreset for each target model. According to the predictions on Native-coresets, we obtain the performance of target models on the whole benchmark with a calibrated estimation strategy. Comprehensive experiments on 5 benchmarks across over 300 models demonstrate that compared to best performing baselines, TailoredBench achieves an average reduction of 31.4% in MAE of accuracy estimates under the same inference budgets, showcasing strong effectiveness and generalizability.", 'abstract_zh': '在大型基准上评估模型非常耗费资源，尤其是在模型快速迭代的时期。现有的高效评估方法通过仅在基准的小且静态的核心集上进行测试来估算目标模型的性能，该核心集源自源模型的公开评估结果。这些方法依赖于目标模型与源模型具有高预测一致性的假设。然而，我们证明这一假设在实际中并不普遍适用。为了解决不一致性问题，我们提出了TailoredBench方法，该方法对每个目标模型进行定制化的评估。具体而言，首先构建全局核心集作为探测器，通过自适应的源模型选择策略识别与每个目标模型最一致的源模型。随后，提出一种可扩展的K-均值聚类算法，将全局核心集扩展为每个目标模型的定制局部核心集。根据局部核心集上的预测，我们采用校正估计策略获得目标模型在完整基准上的性能。在涵盖300多个模型的5个基准上的综合实验结果显示，与最佳基线相比，TailoredBench在相同的推理预算下，精度估计的平均绝对误差（MAE）减少了31.4%，展示了其显著的有效性和通用性。', 'title_zh': '超越一刀切：针对高效评估的定制基准'}
{'arxiv_id': 'arXiv:2502.13562', 'title': 'Are Large Language Models In-Context Graph Learners?', 'authors': 'Jintang Li, Ruofan Wu, Yuchang Zhu, Huizhe Zhang, Liang Chen, Zibin Zheng', 'link': 'https://arxiv.org/abs/2502.13562', 'abstract': 'Large language models (LLMs) have demonstrated remarkable in-context reasoning capabilities across a wide range of tasks, particularly with unstructured inputs such as language or images. However, LLMs struggle to handle structured data, such as graphs, due to their lack of understanding of non-Euclidean structures. As a result, without additional fine-tuning, their performance significantly lags behind that of graph neural networks (GNNs) in graph learning tasks. In this paper, we show that learning on graph data can be conceptualized as a retrieval-augmented generation (RAG) process, where specific instances (e.g., nodes or edges) act as queries, and the graph itself serves as the retrieved context. Building on this insight, we propose a series of RAG frameworks to enhance the in-context learning capabilities of LLMs for graph learning tasks. Comprehensive evaluations demonstrate that our proposed RAG frameworks significantly improve LLM performance on graph-based tasks, particularly in scenarios where a pretrained LLM must be used without modification or accessed via an API.', 'abstract_zh': '大型语言模型（LLMs）在各种任务中展示了令人印象深刻的上下文推理能力，尤其是在处理未结构化的输入（如语言或图像）方面。然而，LLMs 在处理结构化数据（如图）方面表现不佳，这主要是由于它们无法理解非欧几里得结构。因此，在不需要额外微调的情况下，它们在图学习任务中的表现远远落后于图神经网络（GNNs）。本文中，我们表明在图数据上进行学习可以被视为一种检索增强生成（RAG）过程，其中特定实例（例如节点或边）作为查询，而图本身则作为检索的上下文。基于这一见解，我们提出了一系列 RAG 框架，以增强 LLMs 在图学习任务中的上下文学习能力。全面的评估结果表明，我们提出的 RAG 框架显著提升了 LLMs 在基于图的任务中的性能，特别是在需要使用未修改的预训练 LLM 或通过 API 访问的情景中。', 'title_zh': '大型语言模型是上下文图学习者吗？'}
{'arxiv_id': 'arXiv:2502.13555', 'title': 'Democratizing Large Language Model-Based Graph Data Augmentation via Latent Knowledge Graphs', 'authors': 'Yushi Feng, Tsai Hor Chan, Guosheng Yin, Lequan Yu', 'link': 'https://arxiv.org/abs/2502.13555', 'abstract': 'Data augmentation is necessary for graph representation learning due to the scarcity and noise present in graph data. Most of the existing augmentation methods overlook the context information inherited from the dataset as they rely solely on the graph structure for augmentation. Despite the success of some large language model-based (LLM) graph learning methods, they are mostly white-box which require access to the weights or latent features from the open-access LLMs, making them difficult to be democratized for everyone as existing LLMs are mostly closed-source for commercial considerations. To overcome these limitations, we propose a black-box context-driven graph data augmentation approach, with the guidance of LLMs -- DemoGraph. Leveraging the text prompt as context-related information, we task the LLM with generating knowledge graphs (KGs), which allow us to capture the structural interactions from the text outputs. We then design a dynamic merging schema to stochastically integrate the LLM-generated KGs into the original graph during training. To control the sparsity of the augmented graph, we further devise a granularity-aware prompting strategy and an instruction fine-tuning module, which seamlessly generates text prompts according to different granularity levels of the dataset. Extensive experiments on various graph learning tasks validate the effectiveness of our method over existing graph data augmentation methods. Notably, our approach excels in scenarios involving electronic health records (EHRs), which validates its maximal utilization of contextual knowledge, leading to enhanced predictive performance and interpretability.', 'abstract_zh': '由于图数据中存在稀缺性和噪声问题，数据扩增对于图表示学习是必要的。现有的大多数扩增方法忽略了从数据集中继承的上下文信息，因为它们仅依赖于图结构来进行扩增。尽管一些基于大规模语言模型（LLM）的图学习方法取得了成功，但这些方法大多为白盒模型，需要访问开源LLM的权重或潜在特征，这使得这些模型难以普及到每个人手中，因为现有的LLM大多出于商业考虑而保持封闭源代码。为了解决这些局限性，我们提出了一种基于LLM的黑盒上下文驱动的图数据扩增方法——DemoGraph。利用文本提示作为上下文相关信息，我们指示LLM生成知识图谱（KGs），这使我们能够从文本输出中捕获结构交互信息。然后，我们设计了一种动态融合方案，在训练过程中随机将LLM生成的KGs整合到原始图中。为了控制扩增图的稀疏性，我们进一步开发了一种细粒度感知的提示策略和指令微调模块，可以根据不同数据集的细粒度级别无缝生成文本提示。在各种图学习任务的广泛实验中，我们的方法证明了其比现有图数据扩增方法的有效性。值得注意的是，我们的方法在涉及电子健康记录（EHRs）的场景中表现出色，这验证了其在最大化利用上下文知识方面的优势，从而提高了预测性能和可解释性。', 'title_zh': '通过潜在知识图谱实现基于大型语言模型的图形数据增强的民主化'}
{'arxiv_id': 'arXiv:2502.13544', 'title': 'From Sub-Ability Diagnosis to Human-Aligned Generation: Bridging the Gap for Text Length Control via MARKERGEN', 'authors': 'Peiwen Yuan, Chuyi Tan, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Yueqi Zhang, Jiayi Shi, Boyuan Pan, Yao Hu, Kan Li', 'link': 'https://arxiv.org/abs/2502.13544', 'abstract': 'Despite the rapid progress of large language models (LLMs), their length-controllable text generation (LCTG) ability remains below expectations, posing a major limitation for practical applications. Existing methods mainly focus on end-to-end training to reinforce adherence to length constraints. However, the lack of decomposition and targeted enhancement of LCTG sub-abilities restricts further this http URL bridge this gap, we conduct a bottom-up decomposition of LCTG sub-abilities with human patterns as reference and perform a detailed error this http URL this basis, we propose MarkerGen, a simple-yet-effective plug-and-play approach that:(1) mitigates LLM fundamental deficiencies via external tool integration;(2) conducts explicit length modeling with dynamically inserted markers;(3) employs a three-stage generation scheme to better align length constraints while maintaining content this http URL experiments demonstrate that MarkerGen significantly improves LCTG across various settings, exhibiting outstanding effectiveness and generalizability.', 'abstract_zh': '尽管大规模语言模型（LLM）取得了快速进展，但它们在可控长度文本生成（LCTG）方面的能力仍然未达到预期，这对其实用应用构成了重大限制。现有方法主要集中在端到端训练，以强化遵守长度约束的能力。然而，LCTG子能力的分解不足和有针对性的增强限制了进一步的发展。为了弥合这一差距，我们基于人类模式进行了自底向上的LCTG子能力分解，并进行了详细的错误分析。基于这些分析，我们提出了一种简单而有效的即插即用方法——MarkerGen：(1) 通过外部工具集成来缓解LLM的基本缺陷；(2) 通过动态插入标记进行显式的长度建模；(3) 采用三阶段生成方案，更好地符合长度约束并保持内容的一致性。实验结果表明，MarkerGen在各种设置下显著提高了LCTG能力，显示出出色的效果和泛化能力。', 'title_zh': '从亚能力诊断到与人类对齐的生成：通过MARKERGEN弥合文本长度控制的差距'}
{'arxiv_id': 'arXiv:2502.13542', 'title': 'Activation-aware Probe-Query: Effective Key-Value Retrieval for Long-Context LLMs Inference', 'authors': 'Qingfa Xiao, Jiachuan Wang, Haoyang Li, Cheng Deng, Jiaqi Tang, Shuangyin Li, Yongqi Zhang, Jun Wang, Lei Chen', 'link': 'https://arxiv.org/abs/2502.13542', 'abstract': 'Recent advances in large language models (LLMs) have showcased exceptional performance in long-context tasks, while facing significant inference efficiency challenges with limited GPU memory. Existing solutions first proposed the sliding-window approach to accumulate a set of historical \\textbf{key-value} (KV) pairs for reuse, then further improvements selectively retain its subsets at each step. However, due to the sparse attention distribution across a long context, it is hard to identify and recall relevant KV pairs, as the attention is distracted by massive candidate pairs. Additionally, we found it promising to select representative tokens as probe-Query in each sliding window to effectively represent the entire context, which is an approach overlooked by existing methods. Thus, we propose \\textbf{ActQKV}, a training-free, \\textbf{Act}ivation-aware approach that dynamically determines probe-\\textbf{Q}uery and leverages it to retrieve the relevant \\textbf{KV} pairs for inference. Specifically, ActQKV monitors a token-level indicator, Activation Bias, within each context window, enabling the proper construction of probe-Query for retrieval at pre-filling stage. To accurately recall the relevant KV pairs and minimize the irrelevant ones, we design a dynamic KV cut-off mechanism guided by information density across layers at the decoding stage. Experiments on the Long-Bench and $\\infty$ Benchmarks demonstrate its state-of-the-art performance with competitive inference quality and resource efficiency.', 'abstract_zh': '近年来，大规模语言模型（LLMs）在长上下文任务中展现了出色的表现，但在有限的GPU内存下，推理效率面临重大挑战。现有解决方案首先提出了滑动窗口方法，通过积累一系列可重复使用的历史**键值**（KV）对来解决这一问题，随后进一步改进的方法在每一步选择性地保留其子集。然而，由于长上下文中注意力分布的稀疏性，很难识别和回忆相关的KV对，因为注意力会被大量候选对所分散。此外，我们发现，在每个滑动窗口中选择具有代表性的标记作为探针-查询是有效的，这种做法被现有方法所忽视。因此，我们提出了一种无需训练、基于激活信息的**ActQKV**方法，该方法能够动态确定探针-查询，并利用它来检索推理所需的相关KV对。具体而言，ActQKV 在每个上下文窗口中监控一个标记级别的指标——激活偏差（Activation Bias），从而在预填充阶段适当地构建探针-查询以进行检索。为了准确回忆相关的KV对并最小化无关的KV对，我们在解码阶段通过层间信息密度引导的动态KV截断机制进行设计。在Long-Bench和$\\infty$基准测试上的实验表明，该方法在保持高质量推理的同时，具有先进的性能和资源效率。', 'title_zh': '基于激活感知的探针查询：面向长上下文大语言模型推理的有效键值检索'}
{'arxiv_id': 'arXiv:2502.13534', 'title': 'Solving the Encoding Bottleneck: Of the HHL Algorithm, By the HHL Algorithm', 'authors': 'Guang Ping He', 'link': 'https://arxiv.org/abs/2502.13534', 'abstract': 'The Harrow-Hassidim-Lloyd (HHL) algorithm offers exponential speedup for solving the quantum linear-system problem. But some caveats for the speedup could be hard to met. One of the difficulties is the encoding bottleneck, i.e., the efficient preparation of the initial quantum state. To prepare an arbitrary $N$-dimensional state exactly, existing state-preparation approaches generally require a runtime of $O(N)$, which will ruin the speedup of the HHL algorithm. Here we show that the states can be prepared approximately with a runtime of $O(poly(\\log N))$ by employing a slightly modified version of the HHL algorithm itself. Thus, applying this approach to prepare the initial state of the original HHL algorithm can preserve the exponential speedup advantage. It can also serve as a standalone solution for other applications demanding rapid state preparation.', 'abstract_zh': 'Harrow-Hassidim-Lloyd（HHL）算法在解决量子线性系统问题时提供了指数级加速。但是，这种加速的一些先决条件可能会难以满足。其中一个主要困难是编码瓶颈，即高效准备初始量子态。现有的状态准备方法通常需要运行时间为 $O(N)$ 以精确准备一个 $N$ 维态，这将破坏HHL算法的优势。在这里，我们展示了一种通过使用HHL算法的略微修改版本来近似准备态的方法，其运行时间为 $O(\\text{poly}(\\log N))$。因此，将这种方法应用于原始HHL算法的初始态准备过程，可以保持其指数级加速的优势。此外，该方法也可作为独立的解决方案用于其他需要快速态准备的应用。', 'title_zh': '解决编码瓶颈：通过HHL算法实现'}
{'arxiv_id': 'arXiv:2502.13533', 'title': 'Train Small, Infer Large: Memory-Efficient LoRA Training for Large Language Models', 'authors': 'Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Yang You, Guiming Xie, Xuejian Gong, Kunlong Zhou', 'link': 'https://arxiv.org/abs/2502.13533', 'abstract': 'Large Language Models (LLMs) have significantly advanced natural language processing with exceptional task generalization capabilities. Low-Rank Adaption (LoRA) offers a cost-effective fine-tuning solution, freezing the original model parameters and training only lightweight, low-rank adapter matrices. However, the memory footprint of LoRA is largely dominated by the original model parameters. To mitigate this, we propose LoRAM, a memory-efficient LoRA training scheme founded on the intuition that many neurons in over-parameterized LLMs have low training utility but are essential for inference. LoRAM presents a unique twist: it trains on a pruned (small) model to obtain pruned low-rank matrices, which are then recovered and utilized with the original (large) model for inference. Additionally, minimal-cost continual pre-training, performed by the model publishers in advance, aligns the knowledge discrepancy between pruned and original models. Our extensive experiments demonstrate the efficacy of LoRAM across various pruning strategies and downstream tasks. For a model with 70 billion parameters, LoRAM enables training on a GPU with only 20G HBM, replacing an A100-80G GPU for LoRA training and 15 GPUs for full fine-tuning. Specifically, QLoRAM implemented by structured pruning combined with 4-bit quantization, for LLaMA-3.1-70B (LLaMA-2-70B), reduces the parameter storage cost that dominates the memory usage in low-rank matrix training by 15.81$\\times$ (16.95$\\times$), while achieving dominant performance gains over both the original LLaMA-3.1-70B (LLaMA-2-70B) and LoRA-trained LLaMA-3.1-8B (LLaMA-2-13B).', 'abstract_zh': '大规模语言模型（Large Language Models, LLMs）在自然语言处理方面取得了显著的进步，展现了出色的任务泛化能力。低秩适应（Low-Rank Adaption, LoRA）提供了一种成本效益高的微调方案，冻结原始模型的参数，仅训练轻量级的低秩适应矩阵。然而，LoRA的内存占用主要由原始模型的参数决定。为了解决这一问题，我们提出了一种名为LoRAM的内存高效LoRA训练方案，其基于这样一种直觉：在过度参数化的LLMs中，许多神经元的训练效用较低，但对于推理是必不可少的。LoRAM提出了一种独特的策略：使用一个精简的小模型进行训练，以获得精简的低秩矩阵，然后将这些矩阵恢复并用于与原始大模型一起进行推理。此外，模型发布者提前进行的低成本持续预训练可以弥合精简模型和原始模型之间的知识差距。我们的大量实验证明了LoRAM在多种剪枝策略和下游任务上的有效性。对于一个拥有700亿参数的模型，LoRAM使得在仅有20G HBM的GPU上进行训练成为可能，这替代了原本用于LoRA训练的A100-80G GPU和用于完整微调所需的15个GPU。具体来说，通过结构化剪枝结合4位量化实现的QLoRAM，对于LLaMA-3.1-70B（LLaMA-2-70B），在低秩矩阵训练中主导的参数存储成本降低了15.81倍（16.95倍），同时在性能上超过了原始的LLaMA-3.1-70B（LLaMA-2-70B）和经过LoRA微调的LLaMA-3.1-8B（LLaMA-2-13B）。', 'title_zh': '精简训练，扩展推理：大语言模型高效 LoRA 训练方法'}
{'arxiv_id': 'arXiv:2502.13527', 'title': 'Exploiting Prefix-Tree in Structured Output Interfaces for Enhancing Jailbreak Attacking', 'authors': 'Yanzeng Li, Yunfan Xiong, Jialun Zhong, Jinchao Zhang, Jie Zhou, Lei Zou', 'link': 'https://arxiv.org/abs/2502.13527', 'abstract': "The rise of Large Language Models (LLMs) has led to significant applications but also introduced serious security threats, particularly from jailbreak attacks that manipulate output generation. These attacks utilize prompt engineering and logit manipulation to steer models toward harmful content, prompting LLM providers to implement filtering and safety alignment strategies. We investigate LLMs' safety mechanisms and their recent applications, revealing a new threat model targeting structured output interfaces, which enable attackers to manipulate the inner logit during LLM generation, requiring only API access permissions. To demonstrate this threat model, we introduce a black-box attack framework called AttackPrefixTree (APT). APT exploits structured output interfaces to dynamically construct attack patterns. By leveraging prefixes of models' safety refusal response and latent harmful outputs, APT effectively bypasses safety measures. Experiments on benchmark datasets indicate that this approach achieves higher attack success rate than existing methods. This work highlights the urgent need for LLM providers to enhance security protocols to address vulnerabilities arising from the interaction between safety patterns and structured outputs.", 'abstract_zh': '大语言模型（LLMs）的兴起带来了显著的应用，但也引入了严重的安全威胁，特别是从 Jailbreak 攻击中来的威胁，这些攻击通过操控输出生成来操纵模型。这些攻击利用提示工程和 logits 操纵技术，引导模型生成有害内容，促使 LLM 提供商实施过滤和安全对齐策略。本文调查了 LLMs 的安全机制及其近期应用，揭示了一种针对结构化输出接口的新威胁模型。这种威胁模型允许攻击者在 LLM 生成过程中操控内部 logits，只需 API 访问权限。为了演示这一威胁模型，我们引入了一个名为 AttackPrefixTree（APT）的黑箱攻击框架。APT 利用结构化输出接口动态构建攻击模式。通过利用模型的安全拒绝响应的前缀和潜在的有害输出，APT 有效绕过了安全措施。在基准数据集上的实验表明，这种方法的攻击成功率高于现有方法。本文强调了 LLM 提供商需要增强安全协议，以应对由安全模式与结构化输出之间交互引起的安全漏洞的迫切需求。', 'title_zh': '利用前缀树在结构化输出接口中增强 Jailbreak 攻击'}
{'arxiv_id': 'arXiv:2502.13524', 'title': 'MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D Medical Image Analysis', 'authors': 'Wei Dai, Steven Wang, Jun Liu', 'link': 'https://arxiv.org/abs/2502.13524', 'abstract': "Efficient evaluation of three-dimensional (3D) medical images is crucial for diagnostic and therapeutic practices in healthcare. Recent years have seen a substantial uptake in applying deep learning and computer vision to analyse and interpret medical images. Traditional approaches, such as convolutional neural networks (CNNs) and vision transformers (ViTs), face significant computational challenges, prompting the need for architectural advancements. Recent efforts have led to the introduction of novel architectures like the ``Mamba'' model as alternative solutions to traditional CNNs or ViTs. The Mamba model excels in the linear processing of one-dimensional data with low computational demands. However, Mamba's potential for 3D medical image analysis remains underexplored and could face significant computational challenges as the dimension increases. This manuscript presents MobileViM, a streamlined architecture for efficient segmentation of 3D medical images. In the MobileViM network, we invent a new dimension-independent mechanism and a dual-direction traversing approach to incorporate with a vision-Mamba-based framework. MobileViM also features a cross-scale bridging technique to improve efficiency and accuracy across various medical imaging modalities. With these enhancements, MobileViM achieves segmentation speeds exceeding 90 frames per second (FPS) on a single graphics processing unit (i.e., NVIDIA RTX 4090). This performance is over 24 FPS faster than the state-of-the-art deep learning models for processing 3D images with the same computational resources. In addition, experimental evaluations demonstrate that MobileViM delivers superior performance, with Dice similarity scores reaching 92.72%, 86.69%, 80.46%, and 77.43% for PENGWIN, BraTS2024, ATLAS, and Toothfairy2 datasets, respectively, which significantly surpasses existing models.", 'abstract_zh': '高效的三维（3D）医学图像评估对于医疗诊断和治疗实践至关重要。近年来，人们大量采用深度学习和计算机视觉技术来分析和解读医学图像。传统的基于卷积神经网络（CNNs）和视觉变换器（ViTs）的方法面临显著的计算挑战，从而推动了架构创新的需求。近期的努力已经引入了如“Mamba”模型等新型架构，作为传统CNNs或ViTs的替代方案。Mamba模型在低计算需求下对一维数据的线性处理表现出色。然而，Mamba在三维医学图像分析方面的潜力尚未充分探索，随着维度的增加，很可能面临计算挑战。本文介绍了MobileViM，这是一种用于高效分割3D医学图像的精简架构。在MobileViM网络中，我们提出了一种新的与维度无关的机制和双向遍历方法，结合了基于视觉Mamba的框架。MobileViM还采用了跨尺度桥梁技术，以提高在各种医学成像模态中的效率和准确性。得益于这些改进，MobileViM在单个图形处理单元（如NVIDIA RTX 4090）上实现了超过每秒90帧（FPS）的分割速度。这一性能比使用相同计算资源的最先进的深度学习模型快24 FPS以上。此外，实验评估表明，MobileViM在PENGWIN、BraTS2024、ATLAS和Toothfairy2数据集中的Dice相似度得分分别达到了92.72%、86.69%、80.46%和77.43%，显著优于现有模型。', 'title_zh': 'MobileViM：一种轻量级且维度无关的医疗图像分析视觉蟒蛇算法'}
{'arxiv_id': 'arXiv:2502.13519', 'title': 'MILE: Model-based Intervention Learning', 'authors': 'Yigit Korkmaz, Erdem Bıyık', 'link': 'https://arxiv.org/abs/2502.13519', 'abstract': 'Imitation learning techniques have been shown to be highly effective in real-world control scenarios, such as robotics. However, these approaches not only suffer from compounding error issues but also require human experts to provide complete trajectories. Although there exist interactive methods where an expert oversees the robot and intervenes if needed, these extensions usually only utilize the data collected during intervention periods and ignore the feedback signal hidden in non-intervention timesteps. In this work, we create a model to formulate how the interventions occur in such cases, and show that it is possible to learn a policy with just a handful of expert interventions. Our key insight is that it is possible to get crucial information about the quality of the current state and the optimality of the chosen action from expert feedback, regardless of the presence or the absence of intervention. We evaluate our method on various discrete and continuous simulation environments, a real-world robotic manipulation task, as well as a human subject study. Videos and the code can be found at this https URL .', 'abstract_zh': '模仿学习技术在现实世界的控制场景中，如机器人领域，已被证明非常有效。然而，这些方法不仅会遭受累积误差的问题，还需要人类专家提供完整的轨迹。虽然存在一些交互式方法，其中专家监督机器人并在必要时干预，但这些扩展通常仅利用干预期间收集的数据，并且忽略了非干预时间段中存在的反馈信号。在本研究中，我们创建了一个模型来描述在这种情况下干预是如何发生的，并展示了仅通过少数几次专家干预即可学习策略的可能性。我们的主要见解是，即使没有干预或有干预，从专家反馈中获取当前状态质量信息和所选行动最优化性的关键信息是可能的。我们通过各种离散和连续的仿真环境、现实世界的机器人操作任务以及人类被试研究评估了我们的方法。更多视频和代码可以在此网址找到：this https URL。', 'title_zh': 'MILE：基于模型的干预学习'}
{'arxiv_id': 'arXiv:2502.13509', 'title': 'Unlocking Multimodal Integration in EHRs: A Prompt Learning Framework for Language and Time Series Fusion', 'authors': 'Shuai Niu, Jing Ma, Hongzhan Lin, Liang Bai, Zhihua Wang, Wei Bi, Yida Xu, Guo Li, Xian Yang', 'link': 'https://arxiv.org/abs/2502.13509', 'abstract': 'Large language models (LLMs) have shown remarkable performance in vision-language tasks, but their application in the medical field remains underexplored, particularly for integrating structured time series data with unstructured clinical notes. In clinical practice, dynamic time series data such as lab test results capture critical temporal patterns, while clinical notes provide rich semantic context. Merging these modalities is challenging due to the inherent differences between continuous signals and discrete text. To bridge this gap, we introduce ProMedTS, a novel self-supervised multimodal framework that employs prompt-guided learning to unify these heterogeneous data types. Our approach leverages lightweight anomaly detection to generate anomaly captions that serve as prompts, guiding the encoding of raw time series data into informative embeddings. These embeddings are aligned with textual representations in a shared latent space, preserving fine-grained temporal nuances alongside semantic insights. Furthermore, our framework incorporates tailored self-supervised objectives to enhance both intra- and inter-modal alignment. We evaluate ProMedTS on disease diagnosis tasks using real-world datasets, and the results demonstrate that our method consistently outperforms state-of-the-art approaches.', 'abstract_zh': '大型语言模型（LLMs）在视觉-语言任务中表现出色，但在医疗领域的应用尚待探索，尤其是在将结构化时间序列数据与非结构化临床笔记整合方面的应用尤为不足。在临床实践中，动态时间序列数据（如实验室检查结果）捕捉关键的时间模式，而临床笔记则提供了丰富的语义背景。由于连续信号与离散文本之间的固有差异，将这些模态进行整合颇具挑战性。为了弥合这一差距，我们提出了一种名为ProMedTS的创新自监督多模态框架，采用提示引导学习来统一这些异构数据类型。我们的方法利用轻量级的异常检测生成异常描述，作为提示，引导原始时间序列数据的编码过程，生成包含信息的嵌入表示。这些嵌入表示与共享的潜在空间中的文本表示对齐，同时保留了细微的时间特质和语义洞察。此外，我们的框架还集成了定制的自监督目标以增强跨模态和同模态的对齐性。我们在真实世界的数据集上对ProMedTS进行了疾病诊断任务的评估，结果表明我们的方法始终优于现有最先进的方法。', 'title_zh': '解锁EHR多模态集成：一种语言与时间序列融合的提示学习框架'}
{'arxiv_id': 'arXiv:2502.13502', 'title': 'PLDR-LLMs Learn A Generalizable Tensor Operator That Can Replace Its Own Deep Neural Net At Inference', 'authors': 'Burc Gokden', 'link': 'https://arxiv.org/abs/2502.13502', 'abstract': 'We show that Large Language Model from Power Law Decoder Representations (PLDR-LLM) is a foundational model whose deductive outputs are invariant tensors up to a small perturbation. PLDR-LLM learns a singularity condition for the deductive outputs that enable the once-inferred energy-curvature tensor $\\mathbf{G}_{LM}$ to replace the deep neural network of power law graph attention (PLGA) generating the deductive outputs at inference. We demonstrate that a cache for $\\mathbf{G}_{LM}$ (G-cache) and KV-cache can be implemented in a straightforward manner to improve the inference time. The invariance and generalizable nature of deductive outputs is at a very high fidelity where deductive outputs have same RMSE and determinant values up to 15 decimal places after caching, and zero-shot benchmark scores remain unchanged. Ablation studies show that learned deductive outputs have distinct loss and accuracy characteristics from models pretrained with transferred, randomly initialized or identity tensors as a constant tensor operator and an LLM with scaled-dot product attention (SDPA) is a special case of PLDR-LLM where $\\mathbf{G}_{LM}$ is predefined as identity. The observed invariance characteristic introduces a novel asymmetry between training and inference phases with caching. We outline observed common characteristics of the deductive outputs for the learned singularity condition. We provide an implementation of a training and inference framework for PLDR-LLM with KV-cache and G-cache.', 'abstract_zh': '我们证明了来自幂律解码器表示（PLDR）的大语言模型（PLDR-LLM）是一种基础模型，其推理输出是不变的张量，仅在很小的扰动范围内有效。PLDR-LLM 学习了一种关于推理输出的奇异条件，使得在推理过程中产生的能量-曲率张量 $\\mathbf{G}_{LM}$ 代替了用于生成推理输出的幂律图注意力（PLGA）的深层神经网络。我们展示了可以通过简单的方法实现 $\\mathbf{G}_{LM}$ 缓存（G-cache）和 KV 缓存来提升推理时间。推理输出的不变性和可泛化特性在极高的精度下表现明显，即在缓存后，推理输出的均方根误差（RMSE）和行列式值在15位小数后相同，零样本基准得分亦未发生变化。消融研究表明，由传输、随机初始化或恒等张量预训练的模型学习的推理输出具有独特的损失和准确率特征，而带有放大缩点积注意力（SDPA）的大型语言模型（LLM）是 PLDR-LLM 的一种特殊情况，其中 $\\mathbf{G}_{LM}$ 提前定义为恒等张量。观察到的不变性特征在训练和推理阶段之间引入了一种新的不对称性，尤其是在使用缓存的情况下。我们概述了学习奇异条件下的推理输出的观察到的共同特征。我们提供了一个结合了 KV 缓存和 G-cache 的 PLDR-LLM 训练和推理框架的实现。', 'title_zh': 'PLDR-大规模语言模型学习一种可泛化的张量运算符，该运算符可以在推理时替代自身深度神经网络'}
{'arxiv_id': 'arXiv:2502.13499', 'title': 'Hidden Darkness in LLM-Generated Designs: Exploring Dark Patterns in Ecommerce Web Components Generated by LLMs', 'authors': 'Ziwei Chen, Jiawen Shen, Luna, Kristen Vaccaro', 'link': 'https://arxiv.org/abs/2502.13499', 'abstract': "Recent work has highlighted the risks of LLM-generated content for a wide range of harmful behaviors, including incorrect and harmful code. In this work, we extend this by studying whether LLM-generated web design contains dark patterns. This work evaluated designs of ecommerce web components generated by four popular LLMs: Claude, GPT, Gemini, and Llama. We tested 13 commonly used ecommerce components (e.g., search, product reviews) and used them as prompts to generate a total of 312 components across all models. Over one-third of generated components contain at least one dark pattern. The majority of dark pattern strategies involve hiding crucial information, limiting users' actions, and manipulating them into making decisions through a sense of urgency. Dark patterns are also more frequently produced in components that are related to company interests. These findings highlight the need for interventions to prevent dark patterns during front-end code generation with LLMs and emphasize the importance of expanding ethical design education to a broader audience.", 'abstract_zh': '近年来，L大型语言模型（LLM）生成的内容存在广泛危害行为的风险，包括错误和有害的代码。本研究在此基础上进一步探讨LLM生成的网页设计中是否包含暗模式。本研究评估了由四种流行的LLM生成的电子商务网页组件的设计：Claude、GPT、Gemini和Llama。我们测试了13种常用的电子商务组件（例如，搜索、产品评论），并将它们用作生成提示，共生成了312个组件，涵盖所有模型。生成的组件中超过三分之一包含了至少一个暗模式。大多数暗模式策略涉及隐藏关键信息、限制用户行为，并通过紧迫感引导用户做出决策。与公司利益相关的组件中更频繁地生成了暗模式。这些发现强调了在使用LLM进行前端代码生成时需要采取措施防止暗模式，并强调了扩展伦理设计教育的重要性，使其惠及更广泛的受众。', 'title_zh': 'LLM生成设计中的隐性暗模式：探索由LLM生成的电商网页组件中的暗模式'}
{'arxiv_id': 'arXiv:2502.13497', 'title': 'Towards Geo-Culturally Grounded LLM Generations', 'authors': 'Piyawat Lertvittayakumjorn, David Kinney, Vinodkumar Prabhakaran, Donald Martin, Sunipa Dev', 'link': 'https://arxiv.org/abs/2502.13497', 'abstract': "Generative large language models (LLMs) have been demonstrated to have gaps in diverse, cultural knowledge across the globe. We investigate the effect of retrieval augmented generation and search-grounding techniques on the ability of LLMs to display familiarity with a diverse range of national cultures. Specifically, we compare the performance of standard LLMs, LLMs augmented with retrievals from a bespoke knowledge base (i.e., KB grounding), and LLMs augmented with retrievals from a web search (i.e., search grounding) on a series of cultural familiarity benchmarks. We find that search grounding significantly improves the LLM performance on multiple-choice benchmarks that test propositional knowledge (e.g., the norms, artifacts, and institutions of national cultures), while KB grounding's effectiveness is limited by inadequate knowledge base coverage and a suboptimal retriever. However, search grounding also increases the risk of stereotypical judgments by language models, while failing to improve evaluators' judgments of cultural familiarity in a human evaluation with adequate statistical power. These results highlight the distinction between propositional knowledge about a culture and open-ended cultural fluency when it comes to evaluating the cultural familiarity of generative LLMs.", 'abstract_zh': '生成型大规模语言模型（LLMs）在全球范围内显示出在多元文化和知识方面存在差距。我们探讨了检索增强生成和搜索定向技术对LLMs展示对多种国家文化熟悉程度能力的影响。具体而言，我们比较了标准LLMs、采用定制知识库检索增强的LLMs（即KB接地）以及通过网络搜索检索增强的LLMs（即搜索接地）在一系列文化熟悉度基准测试中的表现。我们发现，搜索接地在测试命题知识（如国家文化的规范、器物和制度）的多项选择基准测试中显著提高了LLMs的性能，而定制知识库接地的效果受限于知识库覆盖不全和检索器不够优化。然而，搜索接地也会增加语言模型产生刻板印象判断的风险，而在统计功效充足的评分者评价中，未能提高对文化熟悉度的判断。这些结果突显了在评估生成型LLMs的文化熟悉度时命题知识与开放性文化流畅度之间的重要区别。', 'title_zh': '面向地理文化背景的大型语言模型生成'}
{'arxiv_id': 'arXiv:2502.13490', 'title': 'What are Models Thinking about? Understanding Large Language Model Hallucinations "Psychology" through Model Inner State Analysis', 'authors': 'Peiran Wang, Yang Liu, Yunfei Lu, Jue Hong, Ye Wu', 'link': 'https://arxiv.org/abs/2502.13490', 'abstract': "Large language model (LLM) systems suffer from the models' unstable ability to generate valid and factual content, resulting in hallucination generation. Current hallucination detection methods heavily rely on out-of-model information sources, such as RAG to assist the detection, thus bringing heavy additional latency. Recently, internal states of LLMs' inference have been widely used in numerous research works, such as prompt injection detection, etc. Considering the interpretability of LLM internal states and the fact that they do not require external information sources, we introduce such states into LLM hallucination detection. In this paper, we systematically analyze different internal states' revealing features during inference forward and comprehensively evaluate their ability in hallucination detection. Specifically, we cut the forward process of a large language model into three stages: understanding, query, generation, and extracting the internal state from these stages. By analyzing these states, we provide a deep understanding of why the hallucinated content is generated and what happened in the internal state of the models. Then, we introduce these internal states into hallucination detection and conduct comprehensive experiments to discuss the advantages and limitations.", 'abstract_zh': '大型语言模型（LLM）系统在生成有效和准确内容方面存在不稳定的模型能力，导致产生幻觉。当前的幻觉检测方法高度依赖于模型外的信息来源，如RAG，以辅助检测，从而带来额外的延迟。最近，LLM推理过程中的内部状态在许多研究工作中得到了广泛应用，例如提示注入检测等。考虑到LLM内部状态的可解释性以及它们不需要外部信息源的事实，我们将其引入到LLM幻觉检测中。在本文中，我们系统地分析了推理过程各阶段内部状态揭示的不同特征，并全面评估了它们在幻觉检测中的能力。具体而言，我们将大型语言模型的前向过程划分为三个阶段：理解、查询、生成，并从中提取这些阶段的内部状态。通过分析这些状态，我们深入理解了幻觉内容是如何生成的，以及模型内部状态中发生了什么。然后，我们将这些内部状态引入到幻觉检测中，并进行全面的实验以讨论其优缺点。', 'title_zh': '《模型在思考些什么？通过模型内部状态分析理解大语言模型的幻觉现象》'}
{'arxiv_id': 'arXiv:2502.13487', 'title': 'Transferring Textual Preferences to Vision-Language Understanding through Model Merging', 'authors': 'Chen-An Li, Tzu-Han Lin, Yun-Nung Chen, Hung-yi Lee', 'link': 'https://arxiv.org/abs/2502.13487', 'abstract': "Large vision-language models (LVLMs) perform outstandingly across various multimodal tasks. However, their ability to evaluate generated content remains limited, and training vision-language reward models (VLRMs) with preference data is computationally expensive. This paper explores a training-free alternative by merging text-based reward models (RMs) with LVLMs to create VLRMs. Our approach shows that integrating these models leads to improved performance over LVLMs' scoring and text-based RMs, offering an efficient method for incorporating textual preferences into LVLMs.", 'abstract_zh': '大型多模态模型（Large Vision-Language Models, LVLMs）在各种多模态任务中表现出色。然而，它们对生成内容的评估能力仍然有限，使用偏好数据训练视觉-语言奖励模型（Vision-Language Reward Models, VLRMs）在计算上也非常昂贵。本文探索了一种无需训练的替代方案，即将基于文本的奖励模型（Reward Models, RMs）与LVLMs结合以创建VLRMs。我们的方法表明，将这些模型进行集成可以提高LVLMs评分和基于文本的RMs的表现，提供了一种高效的方法来将文本偏好融入LVLMs中。', 'title_zh': '通过模型合并将文本偏好转移到视觉-语言理解'}
{'arxiv_id': 'arXiv:2502.13480', 'title': 'Astra: Efficient and Money-saving Automatic Parallel Strategies Search on Heterogeneous GPUs', 'authors': 'Peiran Wang, Haibing Li, Fu Haohan, Shiyong Li, Yanpeng Wang, Dou Shen', 'link': 'https://arxiv.org/abs/2502.13480', 'abstract': 'In this paper, we introduce an efficient and money-saving automatic parallel strategies search framework on heterogeneous GPUs: Astra. First, Astra searches for the efficiency-optimal parallel strategy in both GPU configurations search space (GPU types and GPU numbers) and parallel parameters search space. Then, Astra also provides the solution on heterogeneous GPUs by mathematically modeling the time consumption of heterogeneous training. At last, Astra is the first to propose the automatic parallel strategy search on money-saving. The experiment results demonstrate that Astra can achieve better throughput than expert-designed strategies. The search time cost for Astra can also be limited to 1.27 seconds in a single-GPU setting and less than 1.35 minutes in a heterogeneous-GPU setting on average with an accuracy of over 95%.', 'abstract_zh': '在本文中，我们介绍了一种高效且节约成本的异构GPU自动并行策略搜索框架：Astra。首先，Astra 在GPU配置搜索空间（GPU类型和GPU数量）和并行参数搜索空间中寻找效率最优的并行策略。然后，通过数学建模异构训练的时间开销，Astra 还可以为异构GPU提供解决方案。最后，Astra 是首个提出节约成本的自动并行策略搜索方法。实验结果表明，Astra 能够实现比专家设计策略更好的吞吐量。在单GPU设置下，Astra 的搜索时间成本可以限制在1.27秒以内；而在异构GPU设置下，平均搜索时间成本不到1.35分钟，同时保持超过95%的准确性。', 'title_zh': 'Astra：高效且经济的异构GPU自动并行策略搜索方法'}
{'arxiv_id': 'arXiv:2502.13475', 'title': 'LLM should think and action as a human', 'authors': 'Haun Leung, ZiNan Wang', 'link': 'https://arxiv.org/abs/2502.13475', 'abstract': 'It is popular lately to train large language models to be used as chat assistants, but in the conversation between the user and the chat assistant, there are prompts, require multi-turns between the chat assistant and the user. However, there are a number of issues with the multi-turns conversation: The response of the chat assistant is prone to errors and cannot help users achieve their goals; It is difficult for chat assistant to generate responses with different processes based on actual needs for the same command or request; Chat assistant require the use of tools, but the current approach is not elegant and efficient, and the number of tool calls that can be supported is limited. The main reason for these issues is that large language models do not have the thinking ability as a human, lack the reasoning ability and planning ability, and lack the ability to execute plans. To solve these issues, we propose a thinking method based on a built-in chain of thought: In the multi-turns conversation, for each user prompt, the large language model thinks based on elements such as chat history, thinking context, action calls, memory and knowledge, makes detailed reasoning and planning, and actions according to the plan. We also explored how the large language model enhances thinking ability through this thinking method: Collect training datasets according to the thinking method and fine tune the large language model through supervised learning; Train a consistency reward model and use it as a reward function to fine tune the large language model using reinforcement learning, and the reinforced large language model outputs according to this way of thinking. Our experimental results show that the reasoning ability and planning ability of the large language model are enhanced, and the issues in the multi-turns conversation are solved.', 'abstract_zh': '近年来，流行通过训练大规模语言模型以用作聊天助手。但在用户与聊天助手的对话中，聊天助手需要与用户进行多次互动。然而，多次对话中存在的问题相当多：聊天助手的回答容易出错，无法帮助用户实现目标；对于相同的命令或请求，聊天助手难以根据实际需求生成具有不同过程的响应；聊天助手需要使用工具，但当前的方法不够优雅和高效，能够支持的工具调用数量有限。这些问题的主要原因是大规模语言模型缺乏作为人类那样的思考能力、推理能力和规划能力，也缺乏执行计划的能力。为了解决这些问题，我们提出了一种基于内置链式思考的方法：在多次对话中，对于每个用户提示，大规模语言模型基于聊天历史、思考上下文、行动调用、记忆和知识等元素进行思考，进行详细的推理与规划，并按照计划执行相应的行动。此外，我们还探讨了该思考方法是如何增强语言模型的思考能力的：根据该思考方法收集训练数据集，并通过监督学习精细调整语言模型；训练一致性的奖励模型作为奖励函数，并通过强化学习精细调整语言模型，从而训练出能够在这种方式下思考的强化模型。我们的实验结果表明，通过这种方法增强了语言模型的推理能力与规划能力，解决了多次对话中存在的问题。', 'title_zh': '大语言模型（LLM）在思考和行动时应具备人类的特性。'}
{'arxiv_id': 'arXiv:2502.13471', 'title': 'Some Insights of Construction of Feature Graph to Learn Pairwise Feature Interactions with Graph Neural Networks', 'authors': 'Phaphontee Yamchote, Saw Nay Htet Win, Chainarong Amornbunchornvej, Thanapon Noraset', 'link': 'https://arxiv.org/abs/2502.13471', 'abstract': "Feature interaction is crucial in predictive machine learning models, as it captures the relationships between features that influence model performance. In this work, we focus on pairwise interactions and investigate their importance in constructing feature graphs for Graph Neural Networks (GNNs). Rather than proposing new methods, we leverage existing GNN models and tools to explore the relationship between feature graph structures and their effectiveness in modeling interactions. Through experiments on synthesized datasets, we uncover that edges between interacting features are important for enabling GNNs to model feature interactions effectively. We also observe that including non-interaction edges can act as noise, degrading model performance. Furthermore, we provide theoretical support for sparse feature graph selection using the Minimum Description Length (MDL) principle. We prove that feature graphs retaining only necessary interaction edges yield a more efficient and interpretable representation than complete graphs, aligning with Occam's Razor.\nOur findings offer both theoretical insights and practical guidelines for designing feature graphs that improve the performance and interpretability of GNN models.", 'abstract_zh': '在预测性机器学习模型中，特征交互至关重要，因为它捕捉了影响模型性能的特征之间的关系。本研究中，我们专注于成对的特征交互，并探讨它们在构建图神经网络（GNNs）的特征图中的重要性。我们没有提出新的方法，而是利用现有的GNN模型和工具，探讨特征图结构与其在建模交互方面的有效性之间的关系。通过在合成数据集上的实验，我们发现，能够使GNN有效地建模特征交互的特征之间的边是重要的。我们还观察到，包括非交互边可能会起到噪声的作用，降低模型性能。此外，我们通过最小描述长度（MDL）原则为稀疏特征图的选择提供了理论支持。我们证明，保留仅必要交互边的特征图比完全图更高效且更具可解释性，这符合奥卡姆剃刀原理。\n\n我们的发现为设计提高GNN模型性能和可解释性的特征图提供了理论洞察和实用指南。', 'title_zh': '关于使用图神经网络学习成对特征交互的特征图构建的一些见解'}
{'arxiv_id': 'arXiv:2502.13465', 'title': 'HawkBench: Investigating Resilience of RAG Methods on Stratified Information-Seeking Tasks', 'authors': 'Hongjin Qian, Zheng Liu, Chao Gao, Yankai Wang, Defu Lian, Zhicheng Dou', 'link': 'https://arxiv.org/abs/2502.13465', 'abstract': 'In real-world information-seeking scenarios, users have dynamic and diverse needs, requiring RAG systems to demonstrate adaptable resilience. To comprehensively evaluate the resilience of current RAG methods, we introduce HawkBench, a human-labeled, multi-domain benchmark designed to rigorously assess RAG performance across categorized task types. By stratifying tasks based on information-seeking behaviors, HawkBench provides a systematic evaluation of how well RAG systems adapt to diverse user needs.\nUnlike existing benchmarks, which focus primarily on specific task types (mostly factoid queries) and rely on varying knowledge bases, HawkBench offers: (1) systematic task stratification to cover a broad range of query types, including both factoid and rationale queries, (2) integration of multi-domain corpora across all task types to mitigate corpus bias, and (3) rigorous annotation for high-quality evaluation.\nHawkBench includes 1,600 high-quality test samples, evenly distributed across domains and task types. Using this benchmark, we evaluate representative RAG methods, analyzing their performance in terms of answer quality and response latency. Our findings highlight the need for dynamic task strategies that integrate decision-making, query interpretation, and global knowledge understanding to improve RAG generalizability. We believe HawkBench serves as a pivotal benchmark for advancing the resilience of RAG methods and their ability to achieve general-purpose information seeking.', 'abstract_zh': '在现实世界的信息查找场景中，用户的需求是动态多样的，这要求RAG系统具有适应性的弹性和鲁棒性。为了全面评估当前RAG方法的弹性，我们提出了HawkBench，这是一个由人类标注的多领域基准，旨在严格评估在分类任务类型下的RAG性能。通过根据信息查找行为对任务进行分层，HawkBench提供了一种系统的方法来评估RAG系统如何适应多样化的用户需求。\n\n与现有的基准不同，这些基准主要集中在特定的任务类型上（主要是事实查询），并且依赖于不同的知识库，HawkBench提供了以下特性：\n（1）系统化的任务分层，以涵盖广泛的查询类型，包括事实查询和推理查询；\n（2）在所有任务类型上整合多领域语料库，以减轻语料库偏差；\n（3）严格的标注，以进行高质量的评估。\n\nHawkBench 包含1600个高质量的测试样本，这些样本在各个领域和任务类型中均匀分布。使用这个基准，我们评估了代表性的RAG方法，分析了它们在答案质量和响应延迟方面的性能。我们的研究发现突显了综合决策、查询解释和全局知识理解的动态任务策略的重要性，以提高RAG的泛化能力。我们相信HawkBench是促进RAG方法弹性和实现通用信息检索的关键基准。', 'title_zh': 'HawkBench: 探究RAG方法在分层信息检索任务中的鲁棒性'}
{'arxiv_id': 'arXiv:2502.13464', 'title': 'Estimating Commonsense Plausibility through Semantic Shifts', 'authors': 'Wanqing Cui, Keping Bi, Jiafeng Guo, Xueqi Cheng', 'link': 'https://arxiv.org/abs/2502.13464', 'abstract': "Commonsense plausibility estimation is critical for evaluating language models (LMs), yet existing generative approaches--reliant on likelihoods or verbalized judgments--struggle with fine-grained discrimination. In this paper, we propose ComPaSS, a novel discriminative framework that quantifies commonsense plausibility by measuring semantic shifts when augmenting sentences with commonsense-related information. Plausible augmentations induce minimal shifts in semantics, while implausible ones result in substantial deviations. Evaluations on two types of fine-grained commonsense plausibility estimation tasks across different backbones, including LLMs and vision-language models (VLMs), show that ComPaSS consistently outperforms baselines. It demonstrates the advantage of discriminative approaches over generative methods in fine-grained commonsense plausibility evaluation. Experiments also show that (1) VLMs yield superior performance to LMs, when integrated with ComPaSS, on vision-grounded commonsense tasks. (2) contrastive pre-training sharpens backbone models' ability to capture semantic nuances, thereby further enhancing ComPaSS.", 'abstract_zh': '常识合理性估计对于评估语言模型（LMs）至关重要，然而现有的生成方法——依赖于似然性或口头判断——在精细区分方面存在困难。本文提出了一种新颖的鉴别性框架ComPaSS，通过衡量在增加与常识相关的信息时语义的变化来量化常识合理性。合理的增加会引发较小的语义变化，而不合理的增加会导致显著的偏差。在不同基础模型（包括大语言模型和视觉-语言模型）上的两种类型的精细粒度常识合理性估计任务中，ComPaSS 在评估中始终优于基准模型，展示了鉴别性方法在精细粒度常识合理性评估中的优势。实验还表明：(1) 当视觉-语言模型（VLMs）与ComPaSS 结合使用时，在基于视觉的常识任务上比语言模型（LMs）表现出更优异的性能。(2) 对抗预训练增强了基础模型捕捉语义细微差别的能力，从而进一步提升了ComPaSS 的性能。', 'title_zh': '通过语义转换估算常识合理性'}
{'arxiv_id': 'arXiv:2502.13458', 'title': 'ThinkGuard: Deliberative Slow Thinking Leads to Cautious Guardrails', 'authors': 'Xiaofei Wen, Wenxuan Zhou, Wenjie Jacky Mo, Muhao Chen', 'link': 'https://arxiv.org/abs/2502.13458', 'abstract': "Ensuring the safety of large language models (LLMs) is critical as they are deployed in real-world applications. Existing guardrails rely on rule-based filtering or single-pass classification, limiting their ability to handle nuanced safety violations. To address this, we propose ThinkGuard, a critique-augmented guardrail model that distills knowledge from high-capacity LLMs by generating structured critiques alongside safety labels. Fine-tuned on critique-augmented data, the captured deliberative thinking ability drastically enhances the guardrail's cautiousness and interpretability. Evaluated on multiple safety benchmarks, ThinkGuard achieves the highest average F1 and AUPRC, outperforming all baselines. Compared to LLaMA Guard 3, ThinkGuard improves accuracy by 16.1% and macro F1 by 27.0%. Moreover, it surpasses label-only fine-tuned models, confirming that structured critiques enhance both classification precision and nuanced safety reasoning while maintaining computational efficiency.", 'abstract_zh': '确保大型语言模型（LLMs）的安全性至关重要，因为它们正在被应用于实际应用中。现有的防护措施依赖于基于规则的过滤或单次分类，这限制了它们处理复杂安全违规的能力。为解决这一问题，我们提出了一种名为ThinkGuard的批判增强型防护模型，该模型通过生成结构化的批判性反馈和安全标签来提炼高容量LLMs的知识。经过基于批判增强数据的微调，捕捉到的审慎思考能力极大地提升了防护模型的谨慎性和可解释性。在多个安全性基准测试中，ThinkGuard在平均F1分数和AUPRC方面表现最佳，优于所有基线模型。与LLaMA Guard 3相比，ThinkGuard在准确性上提高了16.1%，宏F1分数提高了27.0%。此外，它还超越了仅依赖标签的微调模型，这证实了结构化的批判性反馈不仅提高了分类精度，还增强了细致的安全推理能力，同时保持了计算效率。', 'title_zh': 'ThinkGuard: 深思熟虑的慢思考导向审慎的边界控制'}
{'arxiv_id': 'arXiv:2502.13450', 'title': 'Interleaved Gibbs Diffusion for Constrained Generation', 'authors': 'Gautham Govind Anil, Sachin Yadav, Dheeraj Nagaraj, Karthikeyan Shanmugam, Prateek Jain', 'link': 'https://arxiv.org/abs/2502.13450', 'abstract': 'We introduce Interleaved Gibbs Diffusion (IGD), a novel generative modeling framework for mixed continuous-discrete data, focusing on constrained generation problems. Prior works on discrete and continuous-discrete diffusion models assume factorized denoising distribution for fast generation, which can hinder the modeling of strong dependencies between random variables encountered in constrained generation. IGD moves beyond this by interleaving continuous and discrete denoising algorithms via a discrete time Gibbs sampling type Markov chain. IGD provides flexibility in the choice of denoisers, allows conditional generation via state-space doubling and inference time scaling via the ReDeNoise method. Empirical evaluations on three challenging tasks-solving 3-SAT, generating molecule structures, and generating layouts-demonstrate state-of-the-art performance. Notably, IGD achieves a 7% improvement on 3-SAT out of the box and achieves state-of-the-art results in molecule generation without relying on equivariant diffusion or domain-specific architectures. We explore a wide range of modeling, and interleaving strategies along with hyperparameters in each of these problems.', 'abstract_zh': '我们介绍了交错吉布斯扩散（IGD），这是一种新颖的生成建模框架，用于混合连续-离散数据，并重点研究受约束生成问题。先前对离散和连续-离散扩散模型的研究假设了分解式的去噪分布，以实现快速生成。这种方法可能阻碍了对受约束生成过程中遇到的随机变量间强依赖性的建模。IGD 通过交错连续和离散去噪算法（通过离散时间吉布斯抽样类型的马尔可夫链）超越了这一限制。IGD 在去噪器的选择上提供了灵活性，通过状态空间加倍允许条件生成，并通过 ReDeNoise 方法实现推理时间缩放。在三个具有挑战性的任务上（解决 3-SAT 问题、生成分子结构和生成布局）的实证评估表明，IGD 的性能达到最新水平。值得注意的是，IGD 在“即插即用”情况下解决了 3-SAT 问题，提升了 7%，并且在分子生成方面不依赖于对称扩散或领域特定架构的情况下实现了最新成果。我们在这些问题中广泛探索了建模和交错策略，以及每个问题中的超参数。', 'title_zh': '交错Gibbs Diffusion在受约束生成中的应用'}
{'arxiv_id': 'arXiv:2502.13442', 'title': 'TreeCut: A Synthetic Unanswerable Math Word Problem Dataset for LLM Hallucination Evaluation', 'authors': 'Jialin Ouyang', 'link': 'https://arxiv.org/abs/2502.13442', 'abstract': 'Large language models (LLMs) now achieve near-human performance on standard math word problem benchmarks (e.g., GSM8K), yet their true reasoning ability remains disputed. A key concern is that models often produce confident, yet unfounded, answers to unanswerable problems. We introduce TreeCut, a synthetic dataset that systematically generates infinite unanswerable math word problems and their answerable counterparts, by representing each question as a tree and removing chosen necessary conditions. Experiments show TreeCut effectively induce hallucinations in large language models, including GPT-4o and o3-mini, with rates of 61% and 42% in their respective worst-case scenarios. Further analysis highlights that deeper or more complex trees, composite item names, and removing necessary condition near the middle of a path all increase the likelihood of hallucinations, underscoring the persistent challenges LLMs face in identifying unanswerable math problems.', 'abstract_zh': '大型语言模型（LLMs）现在已经在标准数学填空问题基准测试（例如GSM8K）上达到了接近人类的表现，但它们的真实推理能力仍然存在争议。一个关键问题是，模型往往会对不可解的问题给出自信但毫无根据的答案。我们引入了TreeCut，这是一个合成数据集，通过将每个问题表示为一棵树，并移除所选的必要条件，系统地生成无限数量的不可解的数学填空问题及其可解的对应问题。实验结果表明，在各自的最坏情况下，TreeCut有效地促使大型语言模型产生幻觉，GPT-4o和o3-mini的幻觉率分别为61%和42%。进一步分析表明，更深层次或更复杂的树结构、复合项目名称以及在路径中间移除必要条件都会增加幻觉的可能性，突显了LLMs在识别不可解的数学问题方面持续面临的挑战。', 'title_zh': 'TreeCut：一种用于大语言模型幻觉评估的合成不可回答的数学文字题数据集'}
{'arxiv_id': 'arXiv:2502.13441', 'title': 'The Self-Improvement Paradox: Can Language Models Bootstrap Reasoning Capabilities without External Scaffolding?', 'authors': 'Yutao Sun, Mingshuai Chen, Tiancheng Zhao, Ruochen Xu, Zilun Zhang, Jianwei Yin', 'link': 'https://arxiv.org/abs/2502.13441', 'abstract': 'Self-improving large language models (LLMs) -- i.e., to improve the performance of an LLM by fine-tuning it with synthetic data generated by itself -- is a promising way to advance the capabilities of LLMs while avoiding extensive supervision. Existing approaches to self-improvement often rely on external supervision signals in the form of seed data and/or assistance from third-party models. This paper presents Crescent -- a simple yet effective framework for generating high-quality synthetic question-answer data in a fully autonomous manner. Crescent first elicits the LLM to generate raw questions via a bait prompt, then diversifies these questions leveraging a rejection sampling-based self-deduplication, and finally feeds the questions to the LLM and collects the corresponding answers by means of majority voting. We show that Crescent sheds light on the potential of true self-improvement with zero external supervision signals for math reasoning; in particular, Crescent-generated question-answer pairs suffice to (i) improve the reasoning capabilities of an LLM while preserving its general performance (especially in the 0-shot setting); and (ii) distil LLM knowledge to weaker models more effectively than existing methods based on seed-dataset augmentation.', 'abstract_zh': '自我增强的大语言模型（LLMs）——即通过使用模型自身生成的合成数据对LLM进行微调，以提高其性能——是一种在避免过度监督的情况下提升LLM能力的有前途的方法。现有的自我增强方法通常依赖于外部的监督信号，如种子数据和/或第三方模型的帮助。本文提出了一种名为Crescent的简单但有效的框架，用于完全自主地生成高质量的合成问答数据。首先，通过诱饵提示促使LLM生成原始问题，然后利用基于拒绝采样的自我去重技术使这些问题多样化，最后通过多数投票将这些问题输入LLM，并收集相应的答案。我们展示了Crescent在数学推理领域实现了真正的自我增强，特别是Crescent生成的问题-答案对足以：（i）在保持LLM整体性能（尤其是零样本设置下）的同时提高其推理能力；（ii）比基于种子数据集增强方法更有效地将LLM的知识提取到较弱的模型中。', 'title_zh': '自我提升悖论：语言模型能否在没有外部支撑的情况下自主提升推理能力？'}
{'arxiv_id': 'arXiv:2502.13440', 'title': 'Semi-supervised classification of bird vocalizations', 'authors': 'Simen Hexeberg, Mandar Chitre, Matthias Hoffmann-Kuhnt, Bing Wen Low', 'link': 'https://arxiv.org/abs/2502.13440', 'abstract': 'Changes in bird populations can indicate broader changes in ecosystems, making birds one of the most important animal groups to monitor. Combining machine learning and passive acoustics enables continuous monitoring over extended periods without direct human involvement. However, most existing techniques require extensive expert-labeled datasets for training and cannot easily detect time-overlapping calls in busy soundscapes. We propose a semi-supervised acoustic bird detector designed to allow both the detection of time-overlapping calls (when separated in frequency) and the use of few labeled training samples. The classifier is trained and evaluated on a combination of community-recorded open-source data and long-duration soundscape recordings from Singapore. It achieves a mean F0.5 score of 0.701 across 315 classes from 110 bird species on a hold-out test set, with an average of 11 labeled training samples per class. It outperforms the state-of-the-art BirdNET classifier on a test set of 103 bird species despite significantly fewer labeled training samples. The detector is further tested on 144 microphone-hours of continuous soundscape data. The rich soundscape in Singapore makes suppression of false positives a challenge on raw, continuous data streams. Nevertheless, we demonstrate that achieving high precision in such environments with minimal labeled training data is possible.', 'abstract_zh': '鸟类种群的变化可以指示更广泛生态系统的变化，使鸟类成为最重要的监测动物群之一。结合机器学习和被动声学技术可以在长期内实现无需直接人力干预的持续监测。然而，大多数现有技术需要大量经过专家标注的数据集进行训练，并且难以在嘈杂的声音环境中检测重叠的叫声。我们提出了一种半监督声学鸟类检测器，旨在同时检测频率分离的重叠叫声和使用少量标注训练样本。分类器在新加坡长时域声音景观记录数据和社区录制的开源数据的组合上进行训练和评估。该分类器在110种鸟类的315个类别上（使用103个物种的测试集）实现了F0.5得分的平均值为0.701，每个类别平均有11个标注的训练样本。尽管标记训练样本明显较少，该检测器仍优于最先进的BirdNET分类器。该检测器进一步在连续声音景观数据中进行了144小时的测试。新加坡丰富的声音景观使得在原始连续数据流中抑制假阳性成为一个挑战。不过，我们展示了即使在少量标记训练数据的情况下，也可在这样环境中实现高精度监测的可能性。', 'title_zh': '半监督鸟类鸣声分类'}
{'arxiv_id': 'arXiv:2502.13428', 'title': 'MCTS-KBQA: Monte Carlo Tree Search for Knowledge Base Question Answering', 'authors': 'Guanming Xiong, Haochen Li, Wen Zhao', 'link': 'https://arxiv.org/abs/2502.13428', 'abstract': "This study explores how to enhance the reasoning capabilities of large language models (LLMs) in knowledge base question answering (KBQA) by leveraging Monte Carlo Tree Search (MCTS). Semantic parsing-based KBQA methods are particularly challenging as these approaches require locating elements from knowledge bases and generating logical forms, demanding not only extensive annotated data but also strong reasoning capabilities. Although recent approaches leveraging LLMs as agents have demonstrated considerable potential, these studies are inherently constrained by their linear decision-making processes. To address this limitation, we propose a MCTS-based framework that enhances LLMs' reasoning capabilities through tree search methodology. We design a carefully designed step-wise reward mechanism that requires only direct prompting of open-source instruction LLMs without additional fine-tuning. Experimental results demonstrate that our approach significantly outperforms linear decision-making methods, particularly in low-resource scenarios. Additionally, we contribute new data resources to the KBQA community by annotating intermediate reasoning processes for existing question-SPARQL datasets using distant supervision. Experimental results on the extended dataset demonstrate that our method achieves comparable performance to fully supervised models while using significantly less training data.", 'abstract_zh': '本研究探讨了通过利用蒙特卡洛树搜索（MCTS）来提升大型语言模型（LLMs）在知识库问答（KBQA）中的推理能力的方法。基于语义解析的KBQA方法尤为具有挑战性，因为这些方法需要从知识库中定位元素并生成逻辑形式，不仅需要大量的标注数据，还需要较强的推理能力。尽管最近利用LLMs作为代理的方法展现了巨大的潜力，但这些研究本质上受限于它们线性的决策过程。为解决这一限制，我们提出了一种基于MCTS的框架，该框架通过树搜索方法增强LLMs的推理能力。我们设计了一种精心设计的逐步奖励机制，仅需直接提示开源指令LLMs，无需额外的微调。实验结果表明，我们的方法在低资源场景下显著优于线性决策方法。此外，我们通过对现有的问题-SQL数据集使用远程监督标注中间推理过程，为KBQA社区贡献了新的数据资源。在扩充的数据集上的实验结果表明，我们的方法在使用显著较少的训练数据的情况下实现了与完全监督模型相当的性能。', 'title_zh': 'MCTS-KBQA：知识库问答中的蒙特卡洛树搜索'}
{'arxiv_id': 'arXiv:2502.13422', 'title': 'TabSD: Large Free-Form Table Question Answering with SQL-Based Table Decomposition', 'authors': 'Yuxiang Wang, Junhao Gan, Jianzhong Qi', 'link': 'https://arxiv.org/abs/2502.13422', 'abstract': "Question answering on free-form tables (TableQA) is challenging due to the absence of predefined schemas and the presence of noise in large tables. While Large Language Models (LLMs) have shown promise in TableQA, they struggle with large free-form tables and noise sensitivity. To address these challenges, we propose TabSD, a SQL-based decomposition model that enhances LLMs' ability to process large free-form tables. TabSD generates SQL queries to guide the table decomposition, remove noise, and processes sub-tables for better answer generation. Additionally, SQL Verifier refines SQL outputs to enhance decomposition accuracy. We introduce two TableQA datasets with large free-form tables, SLQA and SEQA, which consist solely of large free-form tables and will be publicly available. Experimental results on four benchmark datasets demonstrate that TABSD outperforms the best-existing baseline models by 23.07%, 2.84%, 23.24% and 9.32% in accuracy, respectively, highlighting its effectiveness in handling large and noisy free-form tables.", 'abstract_zh': '自由格式表格上的问答（TableQA）因缺乏预定义的模式和大表格中的噪声而具有挑战性。虽然大型语言模型（LLMs）在TableQA方面显示出一定的潜力，但它们在处理大型自由格式表格和噪声敏感性方面存在困难。为了解决这些挑战，我们提出了一种基于SQL的分解模型——TabSD，该模型增强了LLMs处理大型自由格式表格的能力。TabSD 生成 SQL 查询来指导表格分解、消除噪声，并处理子表格以更好地生成答案。此外，SQL 验证器对 SQL 输出进行优化，以提高分解准确性。我们引入了两个包含大型自由格式表格的 TableQA 数据集——SLQA 和 SEQA，这两个数据集仅包含大型自由格式表格，并将公开发布。在四个基准数据集上的实验结果表明，TabSD 在准确性上分别优于当前最优基线模型 23.07%、2.84%、23.24% 和 9.32%，突显了其在处理大型和嘈杂的自由格式表格方面的有效性。', 'title_zh': 'TabSD：基于SQL表分解的大规模自由格式表格问答'}
{'arxiv_id': 'arXiv:2502.13417', 'title': 'RLTHF: Targeted Human Feedback for LLM Alignment', 'authors': 'Yifei Xu, Tusher Chakraborty, Emre Kıcıman, Bibek Aryal, Eduardo Rodrigues, Srinagesh Sharma, Roberto Estevao, Maria Angels de Luis Balaguer, Jessica Wolk, Rafael Padilha, Leonardo Nunes, Shobana Balakrishnan, Songwu Lu, Ranveer Chandra', 'link': 'https://arxiv.org/abs/2502.13417', 'abstract': "Fine-tuning large language models (LLMs) to align with user preferences is challenging due to the high cost of quality human annotations in Reinforcement Learning from Human Feedback (RLHF) and the generalizability limitations of AI Feedback. To address these challenges, we propose RLTHF, a human-AI hybrid framework that combines LLM-based initial alignment with selective human annotations to achieve full-human annotation alignment with minimal effort. RLTHF identifies hard-to-annotate samples mislabeled by LLMs using a reward model's reward distribution and iteratively enhances alignment by integrating strategic human corrections while leveraging LLM's correctly labeled samples. Evaluations on HH-RLHF and TL;DR datasets show that RLTHF reaches full-human annotation-level alignment with only 6-7% of the human annotation effort. Furthermore, models trained on RLTHF's curated datasets for downstream tasks outperform those trained on fully human-annotated datasets, underscoring the effectiveness of RLTHF's strategic data curation.", 'abstract_zh': '将上述论文内容或标题翻译成中文，并符合学术规范：\n\n在基于人类反馈的强化学习（Reinforcement Learning from Human Feedback, RLHF）中，高质量的人类注释成本高昂，同时人工智能反馈的一般性有限。因此，大规模语言模型（Large Language Models, LLMs）与用户偏好对齐的调整变得具有挑战性。为了解决这一挑战，我们提出了一种结合了LLM初始对齐与选择性人类注解的人机混合框架——基于奖励模型的RLTHF（RLHF with Reward Model, RLTHF）。该框架通过利用注释模型的奖励分布识别LLM难以标注的样本，并通过逐步整合战略性的手工纠错，重新对齐LLM，从而实现全面的人类注释对齐，同时减少人力投入。\n\n具体而言，RLTHF采用奖励模型的奖励分布来识别LLM错误标注的样本，并通过循环加强对齐，利用LLM正确标注的样本与战略性的人类纠正相结合，实现对齐增强。在HH-RLHF与TL;DR数据集上的评估表明，通过仅使用6-7%的人力标注工作量，RLTHF即可达到与全面手工标注相当的对齐水平。此外，基于RLTHF精心构建的数据集进行下游任务训练的模型表现优于基于完全手工标注数据集训练的模型，这进一步证明了RLTHF战略数据筛选的有效性。', 'title_zh': 'RLTHF：针对的人员反馈以实现大规模语言模型的对齐'}
{'arxiv_id': 'arXiv:2502.13412', 'title': 'Explore-Construct-Filter: An Automated Framework for Rich and Reliable API Knowledge Graph Construction', 'authors': 'Yanbang Sun, Qing Huang, Xiaoxue Ren, Zhenchang Xing, Xiaohong Li, Junjie Wang', 'link': 'https://arxiv.org/abs/2502.13412', 'abstract': "The API Knowledge Graph (API KG) is a structured network that models API entities and their relations, providing essential semantic insights for tasks such as API recommendation, code generation, and API misuse detection. However, constructing a knowledge-rich and reliable API KG presents several challenges. Existing schema-based methods rely heavily on manual annotations to design KG schemas, leading to excessive manual overhead. On the other hand, schema-free methods, due to the lack of schema guidance, are prone to introducing noise, reducing the KG's reliability. To address these issues, we propose the Explore-Construct-Filter framework, an automated approach for API KG construction based on large language models (LLMs). This framework consists of three key modules: 1) KG exploration: LLMs simulate the workflow of annotators to automatically design a schema with comprehensive type triples, minimizing human intervention; 2) KG construction: Guided by the schema, LLMs extract instance triples to construct a rich yet unreliable API KG; 3) KG filtering: Removing invalid type triples and suspicious instance triples to construct a rich and reliable API KG. Experimental results demonstrate that our method surpasses the state-of-the-art method, achieving a 25.2% improvement in F1 score. Moreover, the Explore-Construct-Filter framework proves effective, with the KG exploration module increasing KG richness by 133.6% and the KG filtering module improving reliability by 26.6%. Finally, cross-model experiments confirm the generalizability of our framework.", 'abstract_zh': 'API知识图谱（API KG）是一种结构化网络，用于建模API实体及其关系，为API推荐、代码生成和API误用检测等任务提供重要的语义洞察。然而，构建一个知识丰富且可靠的API KG面临着诸多挑战。现有的基于模式的方法高度依赖于人工注释来设计知识图谱的模式，导致了过多的手工劳动。另一方面，无模式方法由于缺乏模式指导，容易引入噪声，降低知识图谱的可靠性。为了解决这些问题，我们提出了一种基于大规模语言模型（LLMs）的自动化API KG构建框架——Explore-Construct-Filter框架。该框架包含三个关键模块：1）知识图谱探索：LLMs模拟注释人员的工作流程，自动设计一个包含全面类型三元组的模式，最大限度地减少人工干预；2）知识图谱构建：在模式的引导下，LLMs提取实例三元组构建一个丰富但不可靠的API知识图谱；3）知识图谱过滤：删除无效类型三元组和可疑实例三元组，构建一个丰富且可靠的API知识图谱。实验结果表明，我们的方法超越了现有最先进的方法，在F1分数上提高了25.2%。此外，Explore-Construct-Filter框架的效果得到验证：知识图谱探索模块将知识图谱的丰富性提高了133.6%，知识图谱过滤模块提高了知识图谱的可靠性26.6%。最后，跨模型实验进一步验证了该框架的泛化能力。', 'title_zh': '探索-构建-过滤：一种自动化框架，用于构建丰富且可靠的API知识图谱'}
{'arxiv_id': 'arXiv:2502.13410', 'title': 'Tell Me Why: Incentivizing Explanations', 'authors': 'Siddarth Srinivasan, Ezra Karger, Michiel Bakker, Yiling Chen', 'link': 'https://arxiv.org/abs/2502.13410', 'abstract': "Common sense suggests that when individuals explain why they believe something, we can arrive at more accurate conclusions than when they simply state what they believe. Yet, there is no known mechanism that provides incentives to elicit explanations for beliefs from agents. This likely stems from the fact that standard Bayesian models make assumptions (like conditional independence of signals) that preempt the need for explanations, in order to show efficient information aggregation. A natural justification for the value of explanations is that agents' beliefs tend to be drawn from overlapping sources of information, so agents' belief reports do not reveal all that needs to be known. Indeed, this work argues that rationales-explanations of an agent's private information-lead to more efficient aggregation by allowing agents to efficiently identify what information they share and what information is new. Building on this model of rationales, we present a novel 'deliberation mechanism' to elicit rationales from agents in which truthful reporting of beliefs and rationales is a perfect Bayesian equilibrium.", 'abstract_zh': '常识表明，当个体解释他们为什么相信某些事物时，我们能得出比他们仅仅陈述其信念更准确的结论。然而，目前尚未找到机制来激励个体提供他们信念的理由。这很可能是因为标准的贝叶斯模型在证明信息高效聚合的有效性时，做出了一些假设（例如信号的条件独立性），从而预先排除了需要解释的需求。解释价值的一个自然理由是，代理人通常会从重叠的信息来源中获得信念，因此，代理人的信念报告并未揭示所需要了解的所有信息。实际上，本文提出，理据（即代理人的私人信息解释）导致了更高效的聚合，因为它使得代理能够高效地识别他们共有的信息和新的信息。基于这一理据模型，我们提出了一种新的“开诚布公机制”，以此从代理人那里引出其理由，确保真实报告信念和理据是完美的贝叶斯均衡。', 'title_zh': '《告诉我理由：激励解释机制》\n\n这个翻译符合学术规范，同时保持了原标题的意思和风格。如果需要更详细的背景或具体的研究内容，请提供更多信息，以便进行更精确的翻译和润色。'}
{'arxiv_id': 'arXiv:2502.13407', 'title': 'JL1-CD: A New Benchmark for Remote Sensing Change Detection and a Robust Multi-Teacher Knowledge Distillation Framework', 'authors': 'Ziyuan Liu, Ruifei Zhu, Long Gao, Yuanxiu Zhou, Jingyu Ma, Yuantao Gu', 'link': 'https://arxiv.org/abs/2502.13407', 'abstract': 'Deep learning has achieved significant success in the field of remote sensing image change detection (CD), yet two major challenges remain: the scarcity of sub-meter, all-inclusive open-source CD datasets, and the difficulty of achieving consistent and satisfactory detection results across images with varying change areas. To address these issues, we introduce the JL1-CD dataset, which contains 5,000 pairs of 512 x 512 pixel images with a resolution of 0.5 to 0.75 meters. Additionally, we propose a multi-teacher knowledge distillation (MTKD) framework for CD. Experimental results on the JL1-CD and SYSU-CD datasets demonstrate that the MTKD framework significantly improves the performance of CD models with various network architectures and parameter sizes, achieving new state-of-the-art results. The code is available at this https URL.', 'abstract_zh': '深度学习在遥感图像变化检测（CD）领域取得了显著的成功，但仍面临两大挑战：亚米级的全面开源CD数据集稀缺，以及在不同变化区域的图像上实现一致且令人满意的检测结果的难度。为应对这些挑战，我们提出了JL1-CD数据集，该数据集包含5000对512 x 512像素图像，分辨率为0.5至0.75米。此外，我们提出了一种多教师知识蒸馏（MTKD）框架用于变化检测。在JL1-CD和SYSU-CD数据集上的实验结果表明，MTKD框架显著提高了各种网络架构和参数规模的CD模型性能，取得了新的SOTA（State-of-the-Art）结果。相关代码已发布在以下链接：[此处填写网址]。', 'title_zh': 'JL1-CD：一个新的遥感变化检测基准及一种鲁棒的多师知识蒸馏框架\n\n解释：\n- **JL1-CD** 保持不变，因为它很有可能是一个特定的缩写名或专有名词。\n- **新的遥感变化检测基准** 对应 "A New Benchmark for Remote Sensing Change Detection"。\n- **鲁棒的多师知识蒸馏框架** 对应 "a Robust Multi-Teacher Knowledge Distillation Framework"。'}
{'arxiv_id': 'arXiv:2502.13406', 'title': 'Generative Predictive Control: Flow Matching Policies for Dynamic and Difficult-to-Demonstrate Tasks', 'authors': 'Vince Kurtz, Joel W. Burdick', 'link': 'https://arxiv.org/abs/2502.13406', 'abstract': 'Generative control policies have recently unlocked major progress in robotics. These methods produce action sequences via diffusion or flow matching, with training data provided by demonstrations. But despite enjoying considerable success on difficult manipulation problems, generative policies come with two key limitations. First, behavior cloning requires expert demonstrations, which can be time-consuming and expensive to obtain. Second, existing methods are limited to relatively slow, quasi-static tasks. In this paper, we leverage a tight connection between sampling-based predictive control and generative modeling to address each of these issues. In particular, we introduce generative predictive control, a supervised learning framework for tasks with fast dynamics that are easy to simulate but difficult to demonstrate. We then show how trained flow-matching policies can be warm-started at run-time, maintaining temporal consistency and enabling fast feedback rates. We believe that generative predictive control offers a complementary approach to existing behavior cloning methods, and hope that it paves the way toward generalist policies that extend beyond quasi-static demonstration-oriented tasks.', 'abstract_zh': '生成控制策略 recently 开启了机器人领域的重大进展。这些方法通过扩散或流动匹配生成行动序列，训练数据源自演示。尽管在复杂操作问题上取得了显著成功，生成策略仍存在两个关键限制。首先，行为克隆需要专家演示，获取这些演示可能耗时且昂贵。其次，现有方法主要适用于相对缓慢且准静态的任务。在本文中，我们通过密切采样预测控制与生成建模之间联系来解决这些问题。具体而言，我们引入了一种生成预测控制方法，这是一种针对具有快速动力学的监督学习框架，这些动力学易于模拟但难以进行演示。然后，我们展示了如何在运行时利用训练好的流动匹配策略进行“暖启动”，从而保持时间连贯性并实现快速反馈速率。我们认为，生成预测控制为现有行为克隆方法提供了补充手段，并希望它能为超越准静态演示驱动任务的一般性策略铺平道路。', 'title_zh': '生成式预测控制：用于动态和难以演示任务的流匹配策略'}
{'arxiv_id': 'arXiv:2502.13398', 'title': '$\\mathtt{GeLLM^3O}$: Generalizing Large Language Models for Multi-property Molecule Optimization', 'authors': 'Vishal Dey, Xiao Hu, Xia Ning', 'link': 'https://arxiv.org/abs/2502.13398', 'abstract': "Despite recent advancements, most computational methods for molecule optimization are constrained to single- or double-property optimization tasks and suffer from poor scalability and generalizability to novel optimization tasks. Meanwhile, Large Language Models (LLMs) demonstrate remarkable out-of-domain generalizability to novel tasks. To demonstrate LLMs' potential for molecule optimization, we introduce $\\mathtt{MoMUInstruct}$, the first high-quality instruction-tuning dataset specifically focused on complex multi-property molecule optimization tasks. Leveraging $\\mathtt{MoMUInstruct}$, we develop $\\mathtt{GeLLM^3O}$s, a series of instruction-tuned LLMs for molecule optimization. Extensive evaluations across 5 in-domain and 5 out-of-domain tasks demonstrate that $\\mathtt{GeLLM^3O}$s consistently outperform state-of-the-art baselines. $\\mathtt{GeLLM^3O}$s also exhibit outstanding zero-shot generalization to unseen tasks, significantly outperforming powerful closed-source LLMs. Such strong generalizability demonstrates the tremendous potential of $\\mathtt{GeLLM^3O}$s as foundational models for molecule optimization, thereby tackling novel optimization tasks without resource-intensive retraining. $\\mathtt{MoMUInstruct}$, models, and code are accessible through this https URL.", 'abstract_zh': '尽管近年来取得了进展，但大多数用于分子优化的计算方法仍局限于单一或双属性优化任务，并且难以扩展且对新颖的优化任务缺乏普遍适应性。与此同时，大型语言模型（LLMs）在处理域外任务时展示了显著的普遍适应性。为了展示LLMs在分子优化中的潜力，我们引入了$\\mathtt{MoMUInstruct}$，这是一个专注于复杂多属性分子优化任务的高质量指令调优数据集。利用$\\mathtt{MoMUInstruct}$，我们开发了$\\mathtt{GeLLM^3O}$系列指令调优的LLMs，用于分子优化。在5个领域内和5个领域外任务的广泛评估中，$\\mathtt{GeLLM^3O}$s表现出一致的性能优势，超越了最先进的基线方法。$\\mathtt{GeLLM^3O}$s在未见过的任务上还表现出了出色的零样本泛化能力，大幅超越了强大的闭源LLMs。这种强烈的泛化能力表明$\\mathtt{GeLLM^3O}$s作为分子优化的基础模型具有巨大的潜力，能够应对新颖的优化任务而无需进行资源密集型的重新训练。您可以通过以下链接访问$\\mathtt{MoMUInstruct}$、模型和代码：[此处填写链接]。', 'title_zh': '$\\mathtt{GeLLM^3O}$: 将大型语言模型应用于多属性分子优化'}
{'arxiv_id': 'arXiv:2502.13376', 'title': 'Learning Symbolic Task Decompositions for Multi-Agent Teams', 'authors': 'Ameesh Shah, Niklas Lauffer, Thomas Chen, Nikhil Pitta, Sanjit A. Seshia', 'link': 'https://arxiv.org/abs/2502.13376', 'abstract': "One approach for improving sample efficiency in cooperative multi-agent learning is to decompose overall tasks into sub-tasks that can be assigned to individual agents. We study this problem in the context of reward machines: symbolic tasks that can be formally decomposed into sub-tasks. In order to handle settings without a priori knowledge of the environment, we introduce a framework that can learn the optimal decomposition from model-free interactions with the environment. Our method uses a task-conditioned architecture to simultaneously learn an optimal decomposition and the corresponding agents' policies for each sub-task. In doing so, we remove the need for a human to manually design the optimal decomposition while maintaining the sample-efficiency benefits of improved credit assignment. We provide experimental results in several deep reinforcement learning settings, demonstrating the efficacy of our approach. Our results indicate that our approach succeeds even in environments with codependent agent dynamics, enabling synchronous multi-agent learning not achievable in previous works.", 'abstract_zh': '提高合作多智能体学习样本效率的一种方法是将整体任务分解为可以分配给个体智能体的子任务。我们在此背景下研究了这一问题：即奖励机器：能够形式化分解为子任务的符号任务。为了处理无法事先了解环境的情况，我们提出了一种可以从与环境的无模型交互中学习最优分解的框架。我们的方法采用任务条件化的架构，同时学习每个子任务的最优分解和相应的智能体策略。通过这种方式，我们消除了需要人工设计最优分解的必要性，同时保留了改进归因带来的样本效率优势。我们在多个深度强化学习场景中提供了实验结果，证明了我们方法的有效性。我们的结果表明，即使在智能体动态相互依赖的环境中，我们的方法也能成功实现同步多智能体学习，这是之前工作所无法实现的。', 'title_zh': '多智能体团队中的符号任务分解学习'}
{'arxiv_id': 'arXiv:2502.13361', 'title': 'RGAR: Recurrence Generation-augmented Retrieval for Factual-aware Medical Question Answering', 'authors': 'Sichu Liang, Linhai Zhang, Hongyu Zhu, Wenwen Wang, Yulan He, Deyu Zhou', 'link': 'https://arxiv.org/abs/2502.13361', 'abstract': 'Medical question answering requires extensive access to specialized conceptual knowledge. The current paradigm, Retrieval-Augmented Generation (RAG), acquires expertise medical knowledge through large-scale corpus retrieval and uses this knowledge to guide a general-purpose large language model (LLM) for generating answers. However, existing retrieval approaches often overlook the importance of factual knowledge, which limits the relevance of retrieved conceptual knowledge and restricts its applicability in real-world scenarios, such as clinical decision-making based on Electronic Health Records (EHRs). This paper introduces RGAR, a recurrence generation-augmented retrieval framework that retrieves both relevant factual and conceptual knowledge from dual sources (i.e., EHRs and the corpus), allowing them to interact and refine each another. Through extensive evaluation across three factual-aware medical question answering benchmarks, RGAR establishes a new state-of-the-art performance among medical RAG systems. Notably, the Llama-3.1-8B-Instruct model with RGAR surpasses the considerably larger, RAG-enhanced GPT-3.5. Our findings demonstrate the benefit of extracting factual knowledge for retrieval, which consistently yields improved generation quality.', 'abstract_zh': '医疗问答需要广泛访问专业概念知识。当前的范式，检索增强生成（RAG），通过大规模语料库检索获得专业知识，并利用这些知识来引导通用的大规模语言模型（LLM）生成答案。然而，现有的检索方法往往忽视了事实性知识的重要性，这限制了检索到的概念性知识的相关性，从而限制了其在实际场景中的应用，例如基于电子健康记录（EHR）的临床决策。本文介绍了RGAR，这是一种循环生成增强的检索框架，可以从双重来源（即EHR和语料库）检索相关事实性与概念性知识，并使其相互作用和相互完善。通过在三个事实性意识医疗问答基准上进行广泛的评估，RGAR在医疗RAG系统中确立了新的最先进的性能。值得注意的是，配备RGAR的Llama-3.1-8B-Instruct模型超越了更大且经过RAG增强的GPT-3.5模型。我们的研究结果表明，提取事实性知识对于检索的好处，这在一致性上提高了生成质量。', 'title_zh': 'RGAR：基于循环生成增强检索的医学事实导向问答方法'}
{'arxiv_id': 'arXiv:2502.13345', 'title': 'Secure and Efficient Watermarking for Latent Diffusion Models in Model Distribution Scenarios', 'authors': 'Liangqi Lei, Keke Gai, Jing Yu, Liehuang Zhu, Qi Wu', 'link': 'https://arxiv.org/abs/2502.13345', 'abstract': 'Latent diffusion models have exhibited considerable potential in generative tasks. Watermarking is considered to be an alternative to safeguard the copyright of generative models and prevent their misuse. However, in the context of model distribution scenarios, the accessibility of models to large scale of model users brings new challenges to the security, efficiency and robustness of existing watermark solutions. To address these issues, we propose a secure and efficient watermarking solution. A new security mechanism is designed to prevent watermark leakage and watermark escape, which considers watermark randomness and watermark-model association as two constraints for mandatory watermark injection. To reduce the time cost of training the security module, watermark injection and the security mechanism are decoupled, ensuring that fine-tuning VAE only accomplishes the security mechanism without the burden of learning watermark patterns. A watermark distribution-based verification strategy is proposed to enhance the robustness against diverse attacks in the model distribution scenarios. Experimental results prove that our watermarking consistently outperforms existing six baselines on effectiveness and robustness against ten image processing attacks and adversarial attacks, while enhancing security in the distribution scenarios.', 'abstract_zh': '潜在扩散模型在生成任务中展现了显著的潜力。水印技术被认为是一种保护生成模型版权和防止其滥用的替代方案。然而，在模型分发场景中，大量用户对模型的访问带来了新的安全、效率和鲁棒性挑战，现有的水印解决方案遇到了新的问题。为应对这些挑战，我们提出了一种安全且高效的水印解决方案。设计了一种新的安全机制，以防止水印泄漏和水印逃逸，该机制将水印随机性和水印与模型的关联作为强制性水印注入的两个约束条件。为减少培训安全模块所需的时间成本，水印注入和安全机制被分离，确保仅对VAE微调以实现安全机制，而不承担学习水印模式的负担。提出了基于水印分布的验证策略，以增强模型分发场景中鲁棒性。实验结果证明，与现有六种基线相比，我们的水印技术在对抗十种图像处理攻击和对抗性攻击方面在有效性和鲁棒性上表现更优，同时提高了分发场景中的安全性。', 'title_zh': '在模型分发场景中面向潜在扩散模型的高效安全水印技术'}
{'arxiv_id': 'arXiv:2502.13339', 'title': 'How Expressive are Knowledge Graph Foundation Models?', 'authors': 'Xingyue Huang, Pablo Barceló, Michael M. Bronstein, İsmail İlkan Ceylan, Mikhail Galkin, Juan L Reutter, Miguel Romero Orth', 'link': 'https://arxiv.org/abs/2502.13339', 'abstract': "Knowledge Graph Foundation Models (KGFMs) are at the frontier for deep learning on knowledge graphs (KGs), as they can generalize to completely novel knowledge graphs with different relational vocabularies. Despite their empirical success, our theoretical understanding of KGFMs remains very limited. In this paper, we conduct a rigorous study of the expressive power of KGFMs. Specifically, we show that the expressive power of KGFMs directly depends on the motifs that are used to learn the relation representations. We then observe that the most typical motifs used in the existing literature are binary, as the representations are learned based on how pairs of relations interact, which limits the model's expressiveness. As part of our study, we design more expressive KGFMs using richer motifs, which necessitate learning relation representations based on, e.g., how triples of relations interact with each other. Finally, we empirically validate our theoretical findings, showing that the use of richer motifs results in better performance on a wide range of datasets drawn from different domains.", 'abstract_zh': '知识图谱基础模型（KGFMs）是知识图谱（KGs）领域深度学习的前沿技术，因为它们能够泛化到完全不相关的知识图谱，即使这些图谱具有不同的关系词汇表。尽管它们在实际应用中取得了成功，但对KGFMs的理论理解仍然非常有限。在本文中，我们对KGFMs的表达能力进行了严格的探讨。具体而言，我们证明了KGFMs的表达能力直接依赖于用于学习关系表示的图样。我们随后观察到，在现有文献中，最典型的图样通常是二元的，因为关系表示是基于关系对之间的相互作用来学习的，这限制了模型的表达能力。作为我们研究的一部分，我们设计了使用更丰富图样的KGFMs，这需要根据关系三元组之间的相互作用来学习关系表示。最后，我们通过实证验证了理论发现，表明使用更丰富的图样可以在来自不同领域的多种数据集上获得更好的性能。', 'title_zh': '知识图谱基础模型的表达能力如何？'}
{'arxiv_id': 'arXiv:2502.13337', 'title': 'Language Models are Few-Shot Graders', 'authors': 'Chenyan Zhao, Mariana Silva, Seth Poulsen', 'link': 'https://arxiv.org/abs/2502.13337', 'abstract': 'Providing evaluations to student work is a critical component of effective student learning, and automating its process can significantly reduce the workload on human graders. Automatic Short Answer Grading (ASAG) systems, enabled by advancements in Large Language Models (LLMs), offer a promising solution for assessing and providing instant feedback for open-ended student responses. In this paper, we present an ASAG pipeline leveraging state-of-the-art LLMs. Our new LLM-based ASAG pipeline achieves better performances than existing custom-built models on the same datasets. We also compare the grading performance of three OpenAI models: GPT-4, GPT-4o, and o1-preview. Our results demonstrate that GPT-4o achieves the best balance between accuracy and cost-effectiveness. On the other hand, o1-preview, despite higher accuracy, exhibits a larger variance in error that makes it less practical for classroom use. We investigate the effects of incorporating instructor-graded examples into prompts using no examples, random selection, and Retrieval-Augmented Generation (RAG)-based selection strategies. Our findings indicate that providing graded examples enhances grading accuracy, with RAG-based selection outperforming random selection. Additionally, integrating grading rubrics improves accuracy by offering a structured standard for evaluation.', 'abstract_zh': '对学生作业进行评价是有效学生学习的重要组成部分，而自动化这一过程可以显著减轻人为评分者的负担。基于大型语言模型（LLMs）的发展，自动短答案评分（ASAG）系统为评估和提供即时反馈打开了新的可能性，尤其适用于开放式学生回答。本文介绍了一个利用最先进的LLMs构建的ASAG流水线。我们新的基于LLM的ASAG流水线在相同数据集上的表现优于现有自定义模型。我们还比较了OpenAI的三种模型：GPT-4、GPT-4o和o1-preview的评分性能。结果显示，GPT-4o在准确性和成本效益之间取得了最佳平衡。相比之下，尽管o1-preview的准确率较高，但其错误的更大方差使其在课堂教学中不够实用。我们研究了在提示中引入教师评分示例的效果，包括不使用示例、随机选择和基于检索增强生成（RAG）的选择策略。我们的研究结果表明，提供评分示例可以提高评分准确性，而基于RAG的选择策略优于随机选择。此外，结合评分标准能够通过提供结构化的评估标准进一步提高准确性。', 'title_zh': '语言模型是少量示例评阅者'}
{'arxiv_id': 'arXiv:2502.13329', 'title': 'Language Models Can Predict Their Own Behavior', 'authors': 'Dhananjay Ashok, Jonathan May', 'link': 'https://arxiv.org/abs/2502.13329', 'abstract': 'Autoregressive Language Models output text by sequentially predicting the next token to generate, with modern methods like Chain-of-Thought (CoT) prompting achieving state-of-the-art reasoning capabilities by scaling the number of generated tokens. However, are there times when we can infer how the model will behave (e.g. abstain from answering a question) early in the computation, making generation unnecessary? We show that internal representation of input tokens alone can often precisely predict, not just the next token, but eventual behavior over the entire output sequence. We leverage this capacity and learn probes on internal states to create early warning (and exit) systems. Specifically, if the probes can confidently estimate the way the LM is going to behave, then the system will avoid generating tokens altogether and return the estimated behavior instead. On 27 text classification datasets spanning five different tasks, we apply this method to estimate the eventual answer of an LM under CoT prompting, reducing inference costs by 65% (average) while suffering an accuracy loss of no more than 1.4% (worst case). We demonstrate the potential of this method to pre-emptively identify when a model will abstain from answering a question, fail to follow output format specifications, or give a low-confidence response. We explore the limits of this capability, showing that probes generalize to unseen datasets, but perform worse when LM outputs are longer and struggle to predict properties that require access to knowledge that the models themselves lack. Encouragingly, performance scales with model size, suggesting applicability to the largest of models', 'abstract_zh': '自回归语言模型通过顺序预测下一个令牌来生成文本，现代方法如链式思考（CoT）提示可扩展生成的令牌数量，从而实现最先进的推理能力。然而，在某些情况下，我们是否可以在计算早期就推断出模型的行为（例如，避免回答某个问题），从而使得生成变得没有必要？我们展示了仅通过输入令牌的内部表示，通常可以精确预测整个输出序列的最终行为，而不仅仅是下一个令牌。我们利用这种能力，通过在内部状态上学习探针来创建早期预警（并退出）系统。具体而言，如果探针能够自信地估计语言模型将如何行为，那么系统将避免生成任何令牌，而是返回估计的行为。在涵盖五个不同任务的27个文本分类数据集中，我们应用该方法来估算在CoT提示下语言模型的最终答案，平均减少84%的推理成本（降低65%），同时最糟糕的情况也仅降低了1.4%的准确率。我们演示了该方法的潜力，能够预先识别模型何时会避免回答问题、无法遵守输出格式规范或给出置信度低的回答。我们探讨了该能力的限制，表明探针能够泛化到未见过的数据集，但在语言模型输出较长且难以预测需要模型本身缺乏知识的属性时性能较弱。令人鼓舞的是，性能随着模型规模的增加而提高，表明这种方法适用于最大的模型。', 'title_zh': '语言模型可以预测其自身的行为'}
{'arxiv_id': 'arXiv:2502.13321', 'title': 'Adjust for Trust: Mitigating Trust-Induced Inappropriate Reliance on AI Assistance', 'authors': 'Tejas Srinivasan, Jesse Thomason', 'link': 'https://arxiv.org/abs/2502.13321', 'abstract': "Trust biases how users rely on AI recommendations in AI-assisted decision-making tasks, with low and high levels of trust resulting in increased under- and over-reliance, respectively. We propose that AI assistants should adapt their behavior through trust-adaptive interventions to mitigate such inappropriate reliance. For instance, when user trust is low, providing an explanation can elicit more careful consideration of the assistant's advice by the user. In two decision-making scenarios -- laypeople answering science questions and doctors making medical diagnoses -- we find that providing supporting and counter-explanations during moments of low and high trust, respectively, yields up to 38% reduction in inappropriate reliance and 20% improvement in decision accuracy. We are similarly able to reduce over-reliance by adaptively inserting forced pauses to promote deliberation. Our results highlight how AI adaptation to user trust facilitates appropriate reliance, presenting exciting avenues for improving human-AI collaboration.", 'abstract_zh': '用户对AI推荐的信任偏差如何影响AI辅助决策任务中的依赖行为。低信任水平导致用户过度依赖，而高信任水平则导致用户过分依赖。我们提出，AI助理应通过信任自适应干预来调整其行为以减轻这种不适当的依赖。例如，在用户信任水平较低时，提供解释可以促使用户更加谨慎地考虑助理的建议。在两个决策场景中，即公众回答科学问题和医生进行医疗诊断，我们发现，在低信任水平时提供支持性解释，在高信任水平时提供反向解释，可以减少最多38%的不适当依赖，并提高决策准确性约20%。我们还能够通过适时插入强制暂停来促进深思熟虑，以减少过分依赖。实验结果强调了AI适应用户信任如何促进适当依赖，为我们改善人机协作提供了令人兴奋的途径。', 'title_zh': '调整信任水平：减轻由信任引起的对AI辅助的不当依赖'}
{'arxiv_id': 'arXiv:2502.13311', 'title': 'Training Turn-by-Turn Verifiers for Dialogue Tutoring Agents: The Curious Case of LLMs as Your Coding Tutors', 'authors': 'Jian Wang, Yinpei Dai, Yichi Zhang, Ziqiao Ma, Wenjie Li, Joyce Chai', 'link': 'https://arxiv.org/abs/2502.13311', 'abstract': "Intelligent tutoring agents powered by large language models (LLMs) have been increasingly explored to deliver personalized guidance in areas such as language learning and science education. However, their capabilities in guiding users to solve complex real-world tasks remain underexplored. To address this limitation, in this work, we focus on coding tutoring, a challenging problem that requires tutors to proactively guide students toward completing predefined coding tasks. We propose a novel agent workflow, Trace-and-Verify (TRAVER), which combines knowledge tracing to estimate a student's knowledge state and turn-by-turn verification to ensure effective guidance toward task completion. We introduce DICT, an automatic evaluation protocol that assesses tutor agents holistically using controlled student simulation and code generation tests. Extensive experiments reveal the challenges of coding tutoring and demonstrate that TRAVER achieves a significantly higher success rate. Although we use code tutoring as an example in this paper, our results and findings can be extended beyond coding, providing valuable insights into advancing tutoring agents for a variety of tasks.", 'abstract_zh': '由大规模语言模型（LLMs）驱动的智能辅导代理在语言学习和科学教育等领域提供了个性化的指导，但它们在引导用户解决复杂实际任务方面的能力仍然很少被探索。为了解决这一局限性，本文专注于编码辅导这一具有挑战性的问题，要求辅导代理积极引导学生完成既定的编码任务。我们提出了一种新颖的代理工作流程，即轨迹与验证（TRAVER）方法，该方法结合了知识追踪以估计学生的知识状态，并通过回合制验证以确保有效引导完成任务。我们引入了DICT协议，这是一种自动评估方法，通过受控的学生模拟和代码生成测试全面评估辅导代理。通过大量实验揭示了编码辅导的挑战，并证明TRAVER实现了显著更高的成功率。尽管本文中我们以代码辅导为例，但我们的结果和发现可以推广到其他任务，为各种任务的辅导代理的发展提供了宝贵的见解。', 'title_zh': '将以下论文的内容或标题翻译成中文，并符合学术规范：\n\nTraining Turn-by-Turn Verifiers for Dialogue Tutoring Agents: The Curious Case of LLMs as Your Coding Tutors\n\n翻译成中文：\n\n逐步验证器的训练以用于对话式导师代理：大型语言模型作为你的编程导师的有趣案例'}
{'arxiv_id': 'arXiv:2502.13297', 'title': 'Understanding and Tackling Label Errors in Individual-Level Nature Language Understanding', 'authors': 'Yunpeng Xiao, Youpeng Zhao, Kai Shu', 'link': 'https://arxiv.org/abs/2502.13297', 'abstract': 'Natural language understanding (NLU) is a task that enables machines to understand human language. Some tasks, such as stance detection and sentiment analysis, are closely related to individual subjective perspectives, thus termed individual-level NLU. Previously, these tasks are often simplified to text-level NLU tasks, ignoring individual factors. This not only makes inference difficult and unexplainable but often results in a large number of label errors when creating datasets. To address the above limitations, we propose a new NLU annotation guideline based on individual-level factors. Specifically, we incorporate other posts by the same individual and then annotate individual subjective perspectives after considering all individual posts. We use this guideline to expand and re-annotate the stance detection and topic-based sentiment analysis datasets. We find that error rates in the samples were as high as 31.7\\% and 23.3\\%. We further use large language models to conduct experiments on the re-annotation datasets and find that the large language models perform well on both datasets after adding individual factors. Both GPT-4o and Llama3-70B can achieve an accuracy greater than 87\\% on the re-annotation datasets. We also verify the effectiveness of individual factors through ablation studies. We call on future researchers to add individual factors when creating such datasets. Our re-annotation dataset can be found at this https URL', 'abstract_zh': '自然语言理解（NLU）是一项使机器能够理解人类语言的任务。一些任务，如立场检测和情感分析，与个人主观视角密切相关，因此称为个人层面的NLU。过去，这些任务通常简化为文本层面的NLU任务，而忽略了个人因素的影响。这不仅使得推理困难且难以解释，还经常在构建数据集时导致大量标签错误。为了解决上述局限性，我们提出了一种基于个人层面因素的新NLU注解指南。具体而言，我们整合了相同个人发表的其他帖子，然后在综合考虑所有个人帖子的基础上标注个人主观视角。我们使用这一指南扩展并重新注解了立场检测和基于话题的情感分析数据集。我们发现，在样本中的错误率高达31.7%和23.3%。进一步使用大规模语言模型在重新注解的数据集上进行了实验，发现加入个人因素后，大规模语言模型在这两个数据集上的表现都很好。GPT-4o和Llama3-70B均在重新注解的数据集上实现了超过87%的准确率。我们还通过消融试验验证了个人因素的有效性。我们呼吁未来的研究人员在构建这类数据集时加入个人因素。我们的重新注解数据集可以在以下链接中找到：[插入链接]', 'title_zh': '理解并解决个体水平自然语言理解中的标签错误'}
{'arxiv_id': 'arXiv:2502.13290', 'title': 'Prediction of Clinical Complication Onset using Neural Point Processes', 'authors': 'Sachini Weerasekara, Sagar Kamarthi, Jacqueline Isaacs', 'link': 'https://arxiv.org/abs/2502.13290', 'abstract': 'Predicting medical events in advance within critical care settings is paramount for patient outcomes and resource management. Utilizing predictive models, healthcare providers can anticipate issues such as cardiac arrest, sepsis, or respiratory failure before they manifest. Recently, there has been a surge in research focusing on forecasting adverse medical event onsets prior to clinical manifestation using machine learning. However, while these models provide temporal prognostic predictions for the occurrence of a specific adverse event of interest within defined time intervals, their interpretability often remains a challenge. In this work, we explore the applicability of neural temporal point processes in the context of adverse event onset prediction, with the aim of explaining clinical pathways and providing interpretable insights. Our experiments span six state-of-the-art neural point processes and six critical care datasets, each focusing on the onset of distinct adverse events. This work represents a novel application class of neural temporal point processes in event prediction.', 'abstract_zh': '在重症监护环境中提前预测医学事件对于患者的治疗结果和资源管理至关重要。利用预测模型，医疗服务提供者可以在临床表现之前预见心脏骤停、脓毒症或呼吸衰竭等问题。近年来，关于在临床表现前利用机器学习预测不良医学事件发生的研究取得了显著进展。然而，尽管这些模型能够在特定时间段内为特定的不良事件提供时间序列预测，它们的可解释性通常仍然是一个挑战。在这项工作中，我们探讨了神经时间点过程在不良事件起始预测中的适用性，旨在解释临床路径并提供可解释的洞见。我们的实验涵盖了六种最先进的神经时间点过程模型和六种不同的重症监护数据集，每个数据集都关注不同不良事件的起始。这项工作代表了神经时间点过程在事件预测中的一个新型应用类别。', 'title_zh': '使用神经点过程预测临床并发症的发生'}
{'arxiv_id': 'arXiv:2502.13278', 'title': 'Performance Evaluation of Sentiment Analysis on Text and Emoji Data Using End-to-End, Transfer Learning, Distributed and Explainable AI Models', 'authors': 'Sirisha Velampalli, Chandrashekar Muniyappa, Ashutosh Saxena', 'link': 'https://arxiv.org/abs/2502.13278', 'abstract': 'Emojis are being frequently used in todays digital world to express from simple to complex thoughts more than ever before. Hence, they are also being used in sentiment analysis and targeted marketing campaigns. In this work, we performed sentiment analysis of Tweets as well as on emoji dataset from the Kaggle. Since tweets are sentences we have used Universal Sentence Encoder (USE) and Sentence Bidirectional Encoder Representations from Transformers (SBERT) end-to-end sentence embedding models to generate the embeddings which are used to train the Standard fully connected Neural Networks (NN), and LSTM NN models. We observe the text classification accuracy was almost the same for both the models around 98 percent. On the contrary, when the validation set was built using emojis that were not present in the training set then the accuracy of both the models reduced drastically to 70 percent. In addition, the models were also trained using the distributed training approach instead of a traditional singlethreaded model for better scalability. Using the distributed training approach, we were able to reduce the run-time by roughly 15% without compromising on accuracy. Finally, as part of explainable AI the Shap algorithm was used to explain the model behaviour and check for model biases for the given feature set.', 'abstract_zh': '如今，表情符号在数字世界中被频繁使用，以表达从简单到复杂的各种想法。因此，它们也被应用于情感分析和目标营销活动中。在本研究中，我们对推文和来自Kaggle的表情符号数据集进行了情感分析。由于推文是由句子组成的，我们使用了通用句嵌入模型（Universal Sentence Encoder, USE）和双向Transformer编码表示模型（Sentence Bidirectional Encoder Representations from Transformers, SBERT）进行端到端的句嵌入，生成用于训练标准全连接神经网络（Standard Fully Connected Neural Networks, NN）和长短期记忆网络（Long Short-Term Memory Neural Networks, LSTM NN）模型的嵌入。我们观察到，两种模型在文本分类准确率上几乎相同，约为98%。然而，当验证集由不在训练集中出现的表情符号构建时，两种模型的准确率显著下降至约70%。此外，我们还采用了分布式训练方法，而不是传统的单线程模型，以提高模型的可扩展性。使用分布式训练方法，我们能够在不牺牲准确率的情况下将运行时间减少大约15%。最后，作为可解释的人工智能的一部分，我们使用了Shap算法来解释模型的行为，并检查给定特征集中的模型偏差。', 'title_zh': '基于端到端、迁移学习、分布式和可解释人工智能模型的文本和 Emoji 情感分析性能评估'}
{'arxiv_id': 'arXiv:2502.13277', 'title': 'HyperGCL: Multi-Modal Graph Contrastive Learning via Learnable Hypergraph Views', 'authors': 'Khaled Mohammed Saifuddin, Jonathan Shihao Ji, Esra Akbas', 'link': 'https://arxiv.org/abs/2502.13277', 'abstract': "Recent advancements in Graph Contrastive Learning (GCL) have demonstrated remarkable effectiveness in improving graph representations. However, relying on predefined augmentations (e.g., node dropping, edge perturbation, attribute masking) may result in the loss of task-relevant information and a lack of adaptability to diverse input data. Furthermore, the selection of negative samples remains rarely explored. In this paper, we introduce HyperGCL, a novel multimodal GCL framework from a hypergraph perspective. HyperGCL constructs three distinct hypergraph views by jointly utilizing the input graph's structure and attributes, enabling a comprehensive integration of multiple modalities in contrastive learning. A learnable adaptive topology augmentation technique enhances these views by preserving important relations and filtering out noise. View-specific encoders capture essential characteristics from each view, while a network-aware contrastive loss leverages the underlying topology to define positive and negative samples effectively. Extensive experiments on benchmark datasets demonstrate that HyperGCL achieves state-of-the-art node classification performance.", 'abstract_zh': '基于超图的图对比学习（HyperGCL）：一种新颖的多模态图对比学习框架\n\n近年来，图对比学习（GCL）的发展已经证明了其在改进图表示方面的显著有效性。然而，依赖预定义的增强方法（如节点删除、边扰动和属性掩蔽）可能会损失与任务相关的信息，并且对不同输入数据缺乏适应性。此外，负样本的选择尚未得到充分探索。本文提出了HyperGCL，这是一种从超图视角出发的新型多模态图对比学习框架。HyperGCL通过综合利用输入图的结构和属性，构建三个不同的超图视图，从而实现对比学习中多种模态的全面整合。一种可学习的自适应拓扑增强技术通过保留重要关系并排除噪声来增强这些视图。针对每个视图的编码器捕获每个视图的关键特征，而网络感知的对比损失利用潜在的拓扑结构有效地定义正样本和负样本。基准数据集上的广泛实验表明，HyperGCL实现了最先进的节点分类性能。', 'title_zh': 'HyperGCL：通过可学习超图视图进行多模态图对比学习'}
{'arxiv_id': 'arXiv:2502.13260', 'title': 'Stepwise Perplexity-Guided Refinement for Efficient Chain-of-Thought Reasoning in Large Language Models', 'authors': 'Yingqian Cui, Pengfei He, Jingying Zeng, Hui Liu, Xianfeng Tang, Zhenwei Dai, Yan Han, Chen Luo, Jing Huang, Zhen Li, Suhang Wang, Yue Xing, Jiliang Tang, Qi He', 'link': 'https://arxiv.org/abs/2502.13260', 'abstract': 'Chain-of-Thought (CoT) reasoning, which breaks down complex tasks into intermediate reasoning steps, has significantly enhanced the performance of large language models (LLMs) on challenging tasks. However, the detailed reasoning process in CoT often incurs long generation times and high computational costs, partly due to the inclusion of unnecessary steps. To address this, we propose a method to identify critical reasoning steps using perplexity as a measure of their importance: a step is deemed critical if its removal causes a significant increase in perplexity. Our method enables models to focus solely on generating these critical steps. This can be achieved through two approaches: refining demonstration examples in few-shot CoT or fine-tuning the model using selected examples that include only critical steps. Comprehensive experiments validate the effectiveness of our method, which achieves a better balance between the reasoning accuracy and efficiency of CoT.', 'abstract_zh': '链式推理（CoT，Chain-of-Thought）是一种将复杂任务分解为中间推理步骤的方法，极大地提高了大语言模型（LLMs，Large Language Models）在复杂任务上的性能。然而，CoT中的详细推理过程往往会导致生成时间的延长和计算成本的增加，部分原因是包括了一些不必要的步骤。为了应对这一问题，我们提出了一种方法，使用困惑度（perplexity）作为衡量这些步骤重要性的指标：如果移除某个步骤会导致困惑度显著增加，则该步骤被认为是关键步骤。我们的方法使得模型能够仅专注于生成这些关键步骤。这一目标可以通过两种途径实现：在少数样本链式推理（few-shot CoT）中精化示例，或者使用仅包含关键步骤的精选示例对模型进行微调。全面的实验验证了我们方法的有效性，该方法能够在保持CoT推理准确性和效率之间更好地平衡。', 'title_zh': '逐步困惑度引导细化以提高大型语言模型中的高效链式推理'}
{'arxiv_id': 'arXiv:2502.13259', 'title': 'HumT DumT: Measuring and controlling human-like language in LLMs', 'authors': 'Myra Cheng, Sunny Yu, Dan Jurafsky', 'link': 'https://arxiv.org/abs/2502.13259', 'abstract': 'Should LLMs generate language that makes them seem human? Human-like language might improve user experience, but might also lead to overreliance and stereotyping. Assessing these potential impacts requires a systematic way to measure human-like tone in LLM outputs. We introduce HumT and SocioT, metrics for human-like tone and other dimensions of social perceptions in text data based on relative probabilities from an LLM. By measuring HumT across preference and usage datasets, we find that users prefer less human-like outputs from LLMs. HumT also offers insights into the impacts of anthropomorphism: human-like LLM outputs are highly correlated with warmth, social closeness, femininity, and low status, which are closely linked to the aforementioned harms. We introduce DumT, a method using HumT to systematically control and reduce the degree of human-like tone while preserving model performance. DumT offers a practical approach for mitigating risks associated with anthropomorphic language generation.', 'abstract_zh': '大型语言模型（LLM）生成的人类化语言是否合适？人类化的语言可能改善用户体验，但也可能导致过度依赖和刻板印象。评估这些潜在影响需要一种系统的方法来衡量LLM输出中的人类化语气。我们提出了HumT和SocioT这两个指标，用于衡量文本数据中人类化语气及其他社会感知维度，基于LLM的相对概率。通过对偏好和使用数据集中的HumT进行测量，我们发现用户更倾向于LLM生成的较少人类化的内容。HumT还揭示了拟人化的影响：人类化的LLM输出与温暖、社交亲近、女性化和低地位等因素高度相关，这些因素与前述的负面影响密切相关。我们介绍了DumT方法，该方法使用HumT系统地控制和降低人类化语气的程度，同时保持模型性能。DumT提供了一种实用的方法，用于减轻与拟人化语言生成相关的风险。', 'title_zh': 'HumT DumT：测量和控制LLM中的人类似语言能力'}
{'arxiv_id': 'arXiv:2502.13256', 'title': 'A Survey of Anomaly Detection in Cyber-Physical Systems', 'authors': 'Danial Abshari, Meera Sridhar', 'link': 'https://arxiv.org/abs/2502.13256', 'abstract': 'In our increasingly interconnected world, Cyber-Physical Systems (CPS) play a crucial role in industries like healthcare, transportation, and manufacturing by combining physical processes with computing power. These systems, however, face many challenges, especially regarding security and system faults. Anomalies in CPS may indicate unexpected problems, from sensor malfunctions to cyber-attacks, and must be detected to prevent failures that can cause harm or disrupt services. This paper provides an overview of the different ways researchers have approached anomaly detection in CPS. We categorize and compare methods like machine learning, deep learning, mathematical models, invariant, and hybrid techniques. Our goal is to help readers understand the strengths and weaknesses of these methods and how they can be used to create safer, more reliable CPS. By identifying the gaps in current solutions, we aim to encourage future research that will make CPS more secure and adaptive in our increasingly automated world.', 'abstract_zh': '在当今日益互联互通的世界中， cyber-物理系统（CPS）通过将物理过程与计算能力相结合，在医疗保健、交通运输和制造业等行业中扮演着至关重要的角色。然而，这些系统面临着许多挑战，尤其是在安全性和系统故障方面。CPS中的异常可能表明潜在的问题，从传感器故障到网络攻击等，并且必须及早发现以防止可能导致危害或中断服务的故障。本文概述了研究人员在CPS中采用的不同异常检测方法。我们将这些方法分为机器学习、深度学习、数学模型、不变量以及混合技术等类别并进行比较。我们的目标是帮助读者了解这些方法的优势和不足，并了解如何利用这些方法来创建更安全、可靠的CPS。通过识别当前解决方案中存在的差距，我们旨在鼓励未来的研究，使CPS在日益自动化的世界中更加安全和适应性更强。', 'title_zh': '网络物理系统中异常检测的研究综述'}
{'arxiv_id': 'arXiv:2502.13251', 'title': 'Neural Attention Search', 'authors': 'Difan Deng, Marius Lindauer', 'link': 'https://arxiv.org/abs/2502.13251', 'abstract': "We present Neural Attention Search (NAtS), a framework that automatically evaluates the importance of each token within a sequence and determines if the corresponding token can be dropped after several steps. This approach can efficiently reduce the KV cache sizes required by transformer-based models during inference and thus reduce inference costs. In this paper, we design a search space that contains three token types: (i) Global Tokens will be preserved and queried by all the following tokens. (ii) Local Tokens survive until the next global token appears. (iii) Sliding Window Tokens have an impact on the inference of a fixed size of the next following tokens. Similar to the One-Shot Neural Architecture Search approach, this token-type information can be learned jointly with the architecture weights via a learnable attention mask. Experiments on both training a new transformer from scratch and fine-tuning existing large language models show that NAtS can efficiently reduce the KV cache size required for the models while maintaining the models' performance.", 'abstract_zh': '我们提出了一种名为 Neural Attention Search (NAtS) 的框架，该框架可以自动评估序列中每个token的重要性，并确定在经过几步之后对应的token是否可以被删除。这种方法可以在推理过程中通过减少Transformer模型所需的KV缓存大小，从而有效地降低推理成本。在本文中，我们设计了一个包含三种类型的搜索空间：(i) 全局token将被后续所有token保留并查询；(ii) 局部token将持续存在，直到下一个全局token出现；(iii) 滑动窗口token对接下来固定大小的token的推理结果产生影响。类似地，这些token类型的相关信息可以通过可学习的注意力掩码与架构权重共同学习。实验结果表明，无论是从零开始训练一个新的Transformer模型，还是对现有的大型语言模型进行微调，NAtS都能够有效地减少模型所需的KV缓存大小，同时保持模型的性能。', 'title_zh': '神经注意力搜索'}
{'arxiv_id': 'arXiv:2502.13248', 'title': 'Communication Strategy on Macro-and-Micro Traffic State in Cooperative Deep Reinforcement Learning for Regional Traffic Signal Control', 'authors': 'Hankang Gu, Shangbo Wang, Dongyao Jia, Yuli Zhang, Yanrong Luo, Guoqiang Mao, Jianping Wang, Eng Gee Lim', 'link': 'https://arxiv.org/abs/2502.13248', 'abstract': 'Adaptive Traffic Signal Control (ATSC) has become a popular research topic in intelligent transportation systems. Regional Traffic Signal Control (RTSC) using the Multi-agent Deep Reinforcement Learning (MADRL) technique has become a promising approach for ATSC due to its ability to achieve the optimum trade-off between scalability and optimality. Most existing RTSC approaches partition a traffic network into several disjoint regions, followed by applying centralized reinforcement learning techniques to each region. However, the pursuit of cooperation among RTSC agents still remains an open issue and no communication strategy for RTSC agents has been investigated. In this paper, we propose communication strategies to capture the correlation of micro-traffic states among lanes and the correlation of macro-traffic states among intersections. We first justify the evolution equation of the RTSC process is Markovian via a system of store-and-forward queues. Next, based on the evolution equation, we propose two GAT-Aggregated (GA2) communication modules--GA2-Naive and GA2-Aug to extract both intra-region and inter-region correlations between macro and micro traffic states. While GA2-Naive only considers the movements at each intersection, GA2-Aug also considers the lane-changing behavior of vehicles. Two proposed communication modules are then aggregated into two existing novel RTSC frameworks--RegionLight and Regional-DRL. Experimental results demonstrate that both GA2-Naive and GA2-Aug effectively improve the performance of existing RTSC frameworks under both real and synthetic scenarios. Hyperparameter testing also reveals the robustness and potential of our communication modules in large-scale traffic networks.', 'abstract_zh': '自适应交通信号控制（ATSC）已成为智能交通系统中的热门研究课题。区域交通信号控制（RTSC）利用多智能体深度强化学习（MADRL）技术已成为ATSC的一种有前途的方法，这得益于其在可扩展性和优化性之间实现最优折衷的能力。大多数现有的RTSC方法将交通网络分割成几个不相交区域，然后针对每个区域应用集中式强化学习技术。然而，RTSC智能体之间的合作追求仍然是一个未解决的问题，尚未有针对RTSC智能体的通信策略的研究。在这篇文章中，我们提出了通信策略来捕捉车道之间微观交通状态的相关性以及交叉口之间宏观交通状态的相关性。我们首先通过一系列存储转发队列证明RTSC过程的进化方程是马尔可夫的。基于进化方程，我们提出了两种基于GAT聚集（GA2）的通信模块——GA2-Naive和GA2-Aug，以提取宏观和微观交通状态在区域内和区域间的相关性。GA2-Naive仅考虑每个交叉口的交通流动，而GA2-Aug也考虑了车辆的变道行为。我们随后将两种提出的通信模块整合到两种现有的新型RTSC框架——RegionLight和Regional-DRL中。实验结果表明，在真实和合成场景下，GA2-Naive和GA2-Aug都能够有效提高现有RTSC框架的性能。超参数测试还揭示了我们的通信模块在大规模交通网络中的鲁棒性和潜力。', 'title_zh': '区域交通信号控制中基于合作深度强化学习的宏观-微观交通状态通信策略'}
{'arxiv_id': 'arXiv:2502.13234', 'title': 'MotionMatcher: Motion Customization of Text-to-Video Diffusion Models via Motion Feature Matching', 'authors': 'Yen-Siang Wu, Chi-Pin Huang, Fu-En Yang, Yu-Chiang Frank Wang', 'link': 'https://arxiv.org/abs/2502.13234', 'abstract': 'Text-to-video (T2V) diffusion models have shown promising capabilities in synthesizing realistic videos from input text prompts. However, the input text description alone provides limited control over the precise objects movements and camera framing. In this work, we tackle the motion customization problem, where a reference video is provided as motion guidance. While most existing methods choose to fine-tune pre-trained diffusion models to reconstruct the frame differences of the reference video, we observe that such strategy suffer from content leakage from the reference video, and they cannot capture complex motion accurately. To address this issue, we propose MotionMatcher, a motion customization framework that fine-tunes the pre-trained T2V diffusion model at the feature level. Instead of using pixel-level objectives, MotionMatcher compares high-level, spatio-temporal motion features to fine-tune diffusion models, ensuring precise motion learning. For the sake of memory efficiency and accessibility, we utilize a pre-trained T2V diffusion model, which contains considerable prior knowledge about video motion, to compute these motion features. In our experiments, we demonstrate state-of-the-art motion customization performances, validating the design of our framework.', 'abstract_zh': '文本到视频（Text-to-Video，T2V）扩散模型在从输入文本提示生成逼真视频方面表现出巨大的潜力。然而，输入的文字描述仅提供了有限的控制，难以精确控制物体的运动和摄像机的构图。本文研究了运动定制问题，其中提供了一个参考视频作为运动指导。尽管大多数现有方法选择微调预训练的扩散模型来重构参考视频的帧差异，我们观察到这种方法在内容方面出现了泄漏问题，并且无法准确捕捉复杂运动。为了解决这一问题，我们提出了一种名为MotionMatcher的运动定制框架，该框架在特征层面微调预训练的T2V扩散模型。与使用像素级目标不同，MotionMatcher比较高层次的空间-时间运动特征，以微调扩散模型，确保精确的运动学习。为了提高内存效率和可访问性，我们利用了一个包含大量视频运动先验知识的预训练T2V扩散模型来计算这些运动特征。在我们的实验中，我们展示了MotionMatcher在运动定制性能上的领先表现，验证了我们框架的设计有效性。', 'title_zh': 'MotionMatcher：通过运动特征匹配的文本到视频扩散模型的运动定制'}
{'arxiv_id': 'arXiv:2502.13233', 'title': 'SearchRAG: Can Search Engines Be Helpful for LLM-based Medical Question Answering?', 'authors': 'Yucheng Shi, Tianze Yang, Canyu Chen, Quanzheng Li, Tianming Liu, Xiang Li, Ninghao Liu', 'link': 'https://arxiv.org/abs/2502.13233', 'abstract': "Large Language Models (LLMs) have shown remarkable capabilities in general domains but often struggle with tasks requiring specialized knowledge. Conventional Retrieval-Augmented Generation (RAG) techniques typically retrieve external information from static knowledge bases, which can be outdated or incomplete, missing fine-grained clinical details essential for accurate medical question answering. In this work, we propose SearchRAG, a novel framework that overcomes these limitations by leveraging real-time search engines. Our method employs synthetic query generation to convert complex medical questions into search-engine-friendly queries and utilizes uncertainty-based knowledge selection to filter and incorporate the most relevant and informative medical knowledge into the LLM's input. Experimental results demonstrate that our method significantly improves response accuracy in medical question answering tasks, particularly for complex questions requiring detailed and up-to-date knowledge.", 'abstract_zh': '大规模语言模型（LLMs）在通用领域展现了出色的性能，但在需要专业知识的任务上往往表现不佳。传统的检索增强生成（RAG）技术通常从静态知识库中检索外部信息，这些知识库可能过时或不完整，缺乏准确回答医学问题所必需的细粒度临床细节。本研究中，我们提出了一种名为SearchRAG的新框架，该框架通过利用实时搜索引擎来克服这些局限性。该方法通过合成查询生成将复杂的医学问题转换为搜索引擎友好的查询，并通过基于不确定性的知识选择来筛选和整合与LLM输入最相关的、最有信息价值的医学知识。实验结果表明，该方法显著提高了在医学问答任务中的响应准确性，尤其是在需要详细和最新知识的复杂问题上。', 'title_zh': 'SearchRAG：搜索引擎对基于LLM的医疗问答有帮助吗？'}
{'arxiv_id': 'arXiv:2502.13228', 'title': 'Conformal Prediction as Bayesian Quadrature', 'authors': 'Jake C. Snell, Thomas L. Griffiths', 'link': 'https://arxiv.org/abs/2502.13228', 'abstract': 'As machine learning-based prediction systems are increasingly used in high-stakes situations, it is important to understand how such predictive models will perform upon deployment. Distribution-free uncertainty quantification techniques such as conformal prediction provide guarantees about the loss black-box models will incur even when the details of the models are hidden. However, such methods are based on frequentist probability, which unduly limits their applicability. We revisit the central aspects of conformal prediction from a Bayesian perspective and thereby illuminate the shortcomings of frequentist guarantees. We propose a practical alternative based on Bayesian quadrature that provides interpretable guarantees and offers a richer representation of the likely range of losses to be observed at test time.', 'abstract_zh': '随着基于机器学习的预测系统在高风险情境中越来越普遍，了解此类预测模型在部署后的表现变得至关重要。分布无关的不确定性量化技术，如区间预测方法，能够在模型细节被掩盖的情况下提供关于黑盒模型损失的保障。然而，这些方法基于频率主义概率论，这限制了它们的应用范围。我们从贝叶斯视角重新审视区间预测的核心方面，并因此阐明了频率主义保障的不足。我们提出了一种基于贝叶斯 quadrature 的实际替代方案，它提供了可解释的保障，并能提供在测试时可能观察到的损失范围的更丰富的表示。', 'title_zh': '共形预测作为贝叶斯 quadrature'}
{'arxiv_id': 'arXiv:2502.13221', 'title': 'Two Tickets are Better than One: Fair and Accurate Hiring Under Strategic LLM Manipulations', 'authors': 'Lee Cohen, Jack Hsieh, Connie Hong, Judy Hanwen Shen', 'link': 'https://arxiv.org/abs/2502.13221', 'abstract': "In an era of increasingly capable foundation models, job seekers are turning to generative AI tools to enhance their application materials. However, unequal access to and knowledge about generative AI tools can harm both employers and candidates by reducing the accuracy of hiring decisions and giving some candidates an unfair advantage. To address these challenges, we introduce a new variant of the strategic classification framework tailored to manipulations performed using large language models, accommodating varying levels of manipulations and stochastic outcomes. We propose a ``two-ticket'' scheme, where the hiring algorithm applies an additional manipulation to each submitted resume and considers this manipulated version together with the original submitted resume. We establish theoretical guarantees for this scheme, showing improvements for both the fairness and accuracy of hiring decisions when the true positive rate is maximized subject to a no false positives constraint. We further generalize this approach to an $n$-ticket scheme and prove that hiring outcomes converge to a fixed, group-independent decision, eliminating disparities arising from differential LLM access. Finally, we empirically validate our framework and the performance of our two-ticket scheme on real resumes using an open-source resume screening tool.", 'abstract_zh': '在基础模型日益强大的时代，求职者正在利用生成式AI工具来提升他们的申请材料。然而，生成式AI工具的获取途径和知识水平的不平等，可能会对雇主和求职者造成损害，降低招聘决策的准确性，并使一些求职者获得不公平的优势。为应对这些挑战，我们提出了一种针对使用大型语言模型进行操纵的新型战略分类框架，该框架能够适应不同操作程度和随机结果的变化。我们提出了一种“双票”方案，即招聘算法对每份提交的简历应用额外的操纵，并将此操纵版本与原始提交简历一起考虑。我们为该方案建立了理论保证，显示在无假阳性约束条件下使真实阳性率最大化时，该方案提升了招聘决策的公平性和准确性。我们进一步将这一方法扩展为“n票”方案，并证明招聘结果趋同于一个固定且与群体无关的决策，消除了因不同大型语言模型访问而产生的差异。最后，我们使用一个开源简历筛选工具在实际简历上验证了我们框架和“双票”方案的性能。', 'title_zh': '两票胜过一票：在战略性的LLM操纵下实现公平和准确的招聘'}
{'arxiv_id': 'arXiv:2502.13207', 'title': 'Thinking Outside the (Gray) Box: A Context-Based Score for Assessing Value and Originality in Neural Text Generation', 'authors': 'Giorgio Franceschelli, Mirco Musolesi', 'link': 'https://arxiv.org/abs/2502.13207', 'abstract': 'Despite the increasing use of large language models for creative tasks, their outputs often lack diversity. Common solutions, such as sampling at higher temperatures, can compromise the quality of the results. Drawing on information theory, we propose a context-based score to quantitatively evaluate value and originality. This score incentivizes accuracy and adherence to the request while fostering divergence from the learned distribution. We propose using our score as a reward in a reinforcement learning framework to fine-tune large language models for maximum performance. We validate our strategy through experiments in poetry generation and math problem solving, demonstrating that it enhances the value and originality of the generated solutions.', 'abstract_zh': '尽管大型语言模型在创意任务中的使用越来越多，但它们的输出往往缺乏多样性。常见的解决方法，如提高采样温度，可能会牺牲结果的质量。借鉴信息理论，我们提出了一种基于上下文的评分方法，以定量评估价值和原创性。该评分方法激励准确性并遵循请求，同时促进从已学习分布的偏离。我们建议将我们的评分方法作为奖励用于强化学习框架中，以微调大型语言模型以获得最佳性能。通过诗歌生成和数学问题解决实验，我们验证了该策略的有效性，证明它能够提升生成解决方案的价值和原创性。', 'title_zh': '跳出（灰色）框架：一种基于语境的评分方法评估神经文本生成的价值与原创性'}
{'arxiv_id': 'arXiv:2502.13200', 'title': 'Learning To Explore With Predictive World Model Via Self-Supervised Learning', 'authors': 'Alana Santana, Paula P. Costa, Esther L. Colombini', 'link': 'https://arxiv.org/abs/2502.13200', 'abstract': 'Autonomous artificial agents must be able to learn behaviors in complex environments without humans to design tasks and rewards. Designing these functions for each environment is not feasible, thus, motivating the development of intrinsic reward functions. In this paper, we propose using several cognitive elements that have been neglected for a long time to build an internal world model for an intrinsically motivated agent. Our agent performs satisfactory iterations with the environment, learning complex behaviors without needing previously designed reward functions. We used 18 Atari games to evaluate what cognitive skills emerge in games that require reactive and deliberative behaviors. Our results show superior performance compared to the state-of-the-art in many test cases with dense and sparse rewards.', 'abstract_zh': '自主人工代理必须能够在人类无需设计任务和奖励的情况下，在复杂环境中学习行为。为每个环境设计这些功能是不切实际的，因此激励了内在奖励功能的发展。在本文中，我们提出使用长期以来被忽视的认知元素来构建自主驱动代理的内部世界模型。我们的代理能够与环境进行满意的交互，并在无需预先设计奖励函数的情况下学习复杂行为。我们使用18个雅达利游戏来评估哪些认知技能会在需要反应行为和深思熟虑行为的游戏中涌现。结果显示，与现有的最佳方法相比，在许多密集奖励和稀疏奖励的测试案例中，我们的方法具有更好的性能。', 'title_zh': '通过自我监督学习利用预测世界模型进行探索学习'}
{'arxiv_id': 'arXiv:2502.13199', 'title': 'The Role of GitHub Copilot on Software Development: A Perspec-tive on Productivity, Security, Best Practices and Future Directions', 'authors': 'Suresh Babu Nettur, Shanthi Karpurapu, Unnati Nettur, Likhit Sagar Gajja, Sravanthy Myneni, Akhil Dusi', 'link': 'https://arxiv.org/abs/2502.13199', 'abstract': "GitHub Copilot is transforming software development by automating tasks and boosting productivity through AI-driven code generation. In this paper, we con-duct a literature survey to synthesize insights on Copilot's impact on productivity and security. We review academic journal databases, industry reports, and official docu-mentation to highlight key findings and challenges. While Copilot accelerates coding and prototyping, concerns over security vulnerabilities and intellectual property risks persist. Drawing from the literature, we provide a perspective on best practices and future directions for responsible AI adoption in software engineering, offering action-able insights for developers and organizations to integrate Copilot effectively while maintaining high standards of quality and security.", 'abstract_zh': 'GitHub Copilot 正在通过人工智能驱动的代码生成自动化任务并提高生产力，从而改变软件开发的面貌。在本文中，我们进行了一份文献综述，以综合分析 Copilot 对生产力和安全性的影响。我们查阅了学术期刊数据库、行业报告和官方文件，以突出关键发现和挑战。尽管 Copilot 加快了编程和原型制作的速度，但安全漏洞和知识产权风险的担忧依然存在。通过文献回顾，我们提供了关于负责任地采用 AI 在软件工程中的最佳实践和未来方向的视角，为开发人员和组织提供了实用的见解，帮助他们在保持高质量和高安全标准的同时有效集成 Copilot。', 'title_zh': 'GitHub Copilot在软件开发中的作用：从生产力、安全性、最佳实践及未来方向 perspectives 视角'}
{'arxiv_id': 'arXiv:2502.13198', 'title': 'Enhancing Machine Learning Performance through Intelligent Data Quality Assessment: An Unsupervised Data-centric Framework', 'authors': 'Manal Rahal, Bestoun S. Ahmed, Gergely Szabados, Torgny Fornstedt, Jorgen Samuelsson', 'link': 'https://arxiv.org/abs/2502.13198', 'abstract': 'Poor data quality limits the advantageous power of Machine Learning (ML) and weakens high-performing ML software systems. Nowadays, data are more prone to the risk of poor quality due to their increasing volume and complexity. Therefore, tedious and time-consuming work goes into data preparation and improvement before moving further in the ML pipeline. To address this challenge, we propose an intelligent data-centric evaluation framework that can identify high-quality data and improve the performance of an ML system. The proposed framework combines the curation of quality measurements and unsupervised learning to distinguish high- and low-quality data. The framework is designed to integrate flexible and general-purpose methods so that it is deployed in various domains and applications. To validate the outcomes of the designed framework, we implemented it in a real-world use case from the field of analytical chemistry, where it is tested on three datasets of anti-sense oligonucleotides. A domain expert is consulted to identify the relevant quality measurements and evaluate the outcomes of the framework. The results show that the quality-centric data evaluation framework identifies the characteristics of high-quality data that guide the conduct of efficient laboratory experiments and consequently improve the performance of the ML system.', 'abstract_zh': '低质量的数据限制了机器学习（ML）的优势，并削弱了高性能ML软件系统的性能。随着数据量和复杂性的增加，数据更易受到质量不佳的风险。因此，在进入ML管道之前，需要进行繁琐且耗时的数据准备和改进工作。为应对这一挑战，我们提出了一种智能以数据为中心的评估框架，能够识别高质量数据并改善ML系统的性能。该框架将质量评估指标的梳理与无监督学习相结合，以区分高质量和低质量数据。框架设计了灵活且通用的方法，以便在各种领域和应用中部署使用。为了验证所设计框架的效果，我们在化学分析领域的实际应用场景中实施了该框架，测试了三种反义寡核苷酸的数据集，并咨询了领域专家以确定相关质量评估指标并评估框架的结果。结果显示，以质量为中心的数据评估框架识别出了高质量数据的特点，这些特点有助于进行高效的实验室实验，并最终提高了ML系统的性能。', 'title_zh': '通过智能数据质量评估提高机器学习性能：一种基于数据的无监督框架'}
{'arxiv_id': 'arXiv:2502.13194', 'title': 'Conditional Max-Sum for Asynchronous Multiagent Decision Making', 'authors': 'Dimitrios Troullinos, Georgios Chalkiadakis, Ioannis Papamichail, Markos Papageorgiou', 'link': 'https://arxiv.org/abs/2502.13194', 'abstract': 'In this paper we present a novel approach for multiagent decision making in dynamic environments based on Factor Graphs and the Max-Sum algorithm, considering asynchronous variable reassignments and distributed message-passing among agents. Motivated by the challenging domain of lane-free traffic where automated vehicles can communicate and coordinate as agents, we propose a more realistic communication framework for Factor Graph formulations that satisfies the above-mentioned restrictions, along with Conditional Max-Sum: an extension of Max-Sum with a revised message-passing process that is better suited for asynchronous settings. The overall application in lane-free traffic can be viewed as a hybrid system where the Factor Graph formulation undertakes the strategic decision making of vehicles, that of desired lateral alignment in a coordinated manner; and acts on top of a rule-based method we devise that provides a structured representation of the lane-free environment for the factors, while also handling the underlying control of vehicles regarding core operations and safety. Our experimental evaluation showcases the capabilities of the proposed framework in problems with intense coordination needs when compared to a domain-specific baseline without communication, and an increased adeptness of Conditional Max-Sum with respect to the standard algorithm.', 'abstract_zh': '在本文中，我们提出了一种基于因子图和Max-Sum算法的新型多智能体决策方法，该方法考虑了异步变量重新赋值和智能体之间的分布式消息传递。受无车道交通这一具有挑战性的领域的启发，其中自动驾驶车辆可以作为智能体进行通信和协调，我们提出了一个满足上述限制的更具现实意义的通信框架，并引入了条件Max-Sum：这是一个改进的Max-Sum算法的扩展版本，更适用于异步环境。在无车道交通中的总体应用可以视为一种混合系统，其中因子图表征承担车辆的策略决策，实现协调的侧向对齐；同时，它基于我们设计的一种基于规则的方法进行运作，为因子提供结构化的表示，并处理车辆在核心操作和安全方面的底层控制。我们的实验评估显示，与未通信的领域特定基线相比，所提出的框架在需要大量协调的问题上展现出了更强的能力，同时条件Max-Sum在处理标准算法方面也表现出更高的适应性。', 'title_zh': '异步多智能体决策制定中的条件最大和算法'}
{'arxiv_id': 'arXiv:2502.13191', 'title': 'On the Privacy Risks of Spiking Neural Networks: A Membership Inference Analysis', 'authors': 'Junyi Guan, Abhijith Sharma, Chong Tian, Salem Lahlou', 'link': 'https://arxiv.org/abs/2502.13191', 'abstract': 'Spiking Neural Networks (SNNs) are increasingly explored for their energy efficiency and robustness in real-world applications, yet their privacy risks remain largely unexamined. In this work, we investigate the susceptibility of SNNs to Membership Inference Attacks (MIAs) -- a major privacy threat where an adversary attempts to determine whether a given sample was part of the training dataset. While prior work suggests that SNNs may offer inherent robustness due to their discrete, event-driven nature, we find that its resilience diminishes as latency (T) increases. Furthermore, we introduce an input dropout strategy under black box setting, that significantly enhances membership inference in SNNs. Our findings challenge the assumption that SNNs are inherently more secure, and even though they are expected to be better, our results reveal that SNNs exhibit privacy vulnerabilities that are equally comparable to Artificial Neural Networks (ANNs). Our code is available at this https URL.', 'abstract_zh': '递归神经网络（SNNs）因其实用场景下的能效优势和鲁棒性而备受关注，但其隐私风险仍未得到充分研究。本研究致力于探索SNNs对成员推断攻击（MIA）的敏感性——这是一种重大隐私威胁，攻击者试图确定给定样例是否属于训练数据集。虽然先前的研究表明，由于SNNs的离散性和事件驱动特性，它们可能具有内在的鲁棒性，但我们发现随着延迟（T）的增加，这种鲁棒性会减弱。此外，我们在黑盒设置下引入了一种输入丢弃策略，显著提升了SNNs的成员推断能力。我们的研究结果挑战了SNNs天生更安全的假设，并揭示了即使SNNs预期会更好，它们仍然存在与人工神经网络（ANNs）相当的隐私漏洞。所有代码可在以下链接获取：this https URL。', 'title_zh': '关于刺神经网络的隐私风险：一种成员推断分析'}
{'arxiv_id': 'arXiv:2502.13189', 'title': 'MoBA: Mixture of Block Attention for Long-Context LLMs', 'authors': 'Enzhe Lu, Zhejun Jiang, Jingyuan Liu, Yulun Du, Tao Jiang, Chao Hong, Shaowei Liu, Weiran He, Enming Yuan, Yuzhi Wang, Zhiqi Huang, Huan Yuan, Suting Xu, Xinran Xu, Guokun Lai, Yanru Chen, Huabin Zheng, Junjie Yan, Jianlin Su, Yuxin Wu, Neo Y. Zhang, Zhilin Yang, Xinyu Zhou, Mingxing Zhang, Jiezhong Qiu', 'link': 'https://arxiv.org/abs/2502.13189', 'abstract': "Scaling the effective context length is essential for advancing large language models (LLMs) toward artificial general intelligence (AGI). However, the quadratic increase in computational complexity inherent in traditional attention mechanisms presents a prohibitive overhead. Existing approaches either impose strongly biased structures, such as sink or window attention which are task-specific, or radically modify the attention mechanism into linear approximations, whose performance in complex reasoning tasks remains inadequately explored.\nIn this work, we propose a solution that adheres to the ``less structure'' principle, allowing the model to determine where to attend autonomously, rather than introducing predefined biases. We introduce Mixture of Block Attention (MoBA), an innovative approach that applies the principles of Mixture of Experts (MoE) to the attention mechanism. This novel architecture demonstrates superior performance on long-context tasks while offering a key advantage: the ability to seamlessly transition between full and sparse attention, enhancing efficiency without the risk of compromising performance. MoBA has already been deployed to support Kimi's long-context requests and demonstrates significant advancements in efficient attention computation for LLMs. Our code is available at this https URL.", 'abstract_zh': '扩展有效的上下文长度对于使大型语言模型（LLMs）向通用人工智能（AGI）发展至关重要。然而，传统注意力机制中固有的计算复杂度二次增长带来了难以克服的负担。现有的方法要么引入强偏置结构，如聚束注意力或窗口注意力，这些方法通常是任务特定的，要么从根本上将注意力机制修改为线性近似，其在复杂推理任务中的性能尚未得到充分探索。\n\n在这项工作中，我们提出了一种遵循“较少结构”原则的解决方案，让模型自主决定如何分配注意力，而不是引入预定义的偏置。我们提出了混合块注意力（MoBA）这一创新方法，它将专家混合（MoE）的原则应用于注意力机制。这种新的架构在长上下文任务中表现出优越的性能，并且有一个关键优势：能够无缝地在全面和稀疏注意力之间过渡，提高效率而不牺牲性能。MoBA 已经部署用于支持 Kimi 的长上下文请求，并展示了 LLMs 中高效注意力计算的重要进步。我们的代码可在以下链接获取：[此处替换为URL]', 'title_zh': 'MoBA：长上下文LLM的混合块注意力机制'}
{'arxiv_id': 'arXiv:2502.13187', 'title': 'A Survey of Sim-to-Real Methods in RL: Progress, Prospects and Challenges with Foundation Models', 'authors': 'Longchao Da, Justin Turnau, Thirulogasankar Pranav Kutralingam, Alvaro Velasquez, Paulo Shakarian, Hua Wei', 'link': 'https://arxiv.org/abs/2502.13187', 'abstract': 'Deep Reinforcement Learning (RL) has been explored and verified to be effective in solving decision-making tasks in various domains, such as robotics, transportation, recommender systems, etc. It learns from the interaction with environments and updates the policy using the collected experience. However, due to the limited real-world data and unbearable consequences of taking detrimental actions, the learning of RL policy is mainly restricted within the simulators. This practice guarantees safety in learning but introduces an inevitable sim-to-real gap in terms of deployment, thus causing degraded performance and risks in execution. There are attempts to solve the sim-to-real problems from different domains with various techniques, especially in the era with emerging techniques such as large foundations or language models that have cast light on the sim-to-real. This survey paper, to the best of our knowledge, is the first taxonomy that formally frames the sim-to-real techniques from key elements of the Markov Decision Process (State, Action, Transition, and Reward). Based on the framework, we cover comprehensive literature from the classic to the most advanced methods including the sim-to-real techniques empowered by foundation models, and we also discuss the specialties that are worth attention in different domains of sim-to-real problems. Then we summarize the formal evaluation process of sim-to-real performance with accessible code or benchmarks. The challenges and opportunities are also presented to encourage future exploration of this direction. We are actively maintaining a to include the most up-to-date sim-to-real research outcomes to help the researchers in their work.', 'abstract_zh': '深度强化学习（RL）已在不同的领域，如机器人学、交通、推荐系统等中得到探索和验证，证明其在解决决策任务方面是有效的。RL 通过与环境的互动学习，并利用收集的经验更新策略。然而，由于受限于真实世界数据的有限性和执行有害行为带来的不可承受后果，RL 策略的学习主要局限于模拟器中。虽然这种方法保证了学习过程的安全性，但导致了在部署过程中不可避免的“模拟与现实之间”的差距，从而影响了执行效果和安全性。尽管来自不同领域的尝试使用各种技术解决这一问题，特别是在大型基础模型或语言模型新兴技术的时代背景下，取得了进展，但这些技术仍然存在挑战。\n\n本文根据我们所了解的情况，是首个将 “模拟与现实” 技术正式地从马尔可夫决策过程（状态、动作、转移和奖励）的关键元素中进行分类的分类学论文。基于此框架，我们综述了从经典方法到最先进方法的全面文献，包括由基础模型赋能的“模拟与现实”技术方法，并讨论了不同领域的“模拟与现实”问题中的值得关注的特色。此外，我们总结了评估“模拟与现实”性能的标准流程，提供了易于获取的代码或基准测试。最后，我们讨论了面临的挑战和机遇，以促进对该方向的未来探索。我们将积极维护更新的“模拟与现实”研究结果，帮助研究人员获取最新的进展信息。', 'title_zh': '基础模型在RL中从模拟到现实的方法综述：进展、前景与挑战'}
{'arxiv_id': 'arXiv:2502.13185', 'title': 'CondensNet: Enabling stable long-term climate simulations via hybrid deep learning models with adaptive physical constraints', 'authors': 'Xin Wang, Juntao Yang, Jeff Adie, Simon See, Kalli Furtado, Chen Chen, Troy Arcomano, Romit Maulik, Gianmarco Mengaldo', 'link': 'https://arxiv.org/abs/2502.13185', 'abstract': "Accurate and efficient climate simulations are crucial for understanding Earth's evolving climate. However, current general circulation models (GCMs) face challenges in capturing unresolved physical processes, such as cloud and convection. A common solution is to adopt cloud resolving models, that provide more accurate results than the standard subgrid parametrisation schemes typically used in GCMs. However, cloud resolving models, also referred to as super paramtetrizations, remain computationally prohibitive. Hybrid modeling, which integrates deep learning with equation-based GCMs, offers a promising alternative but often struggles with long-term stability and accuracy issues. In this work, we find that water vapor oversaturation during condensation is a key factor compromising the stability of hybrid models. To address this, we introduce CondensNet, a novel neural network architecture that embeds a self-adaptive physical constraint to correct unphysical condensation processes. CondensNet effectively mitigates water vapor oversaturation, enhancing simulation stability while maintaining accuracy and improving computational efficiency compared to super parameterization schemes.\nWe integrate CondensNet into a GCM to form PCNN-GCM (Physics-Constrained Neural Network GCM), a hybrid deep learning framework designed for long-term stable climate simulations in real-world conditions, including ocean and land. PCNN-GCM represents a significant milestone in hybrid climate modeling, as it shows a novel way to incorporate physical constraints adaptively, paving the way for accurate, lightweight, and stable long-term climate simulations.", 'abstract_zh': '准确且高效的气候模拟对于理解地球不断变化的气候至关重要。然而，当前的一般环流模型（GCMs）在捕捉未解决的物理过程（如云和对流）方面面临挑战。一个常见的解决方案是采用云分辨率模型，此类模型的结果比通常在GCMs中使用的次网格参数化方案更为精确。然而，云分辨率模型也被称为超参数化模型，仍然存在巨大的计算成本问题。结合深度学习与基于方程的GCM的混合建模方法提供了一种有前景的替代方案，但其常常难以长期保持稳定性和准确性。在本研究中，我们发现凝结过程中水汽过饱和是影响混合模型稳定性的关键因素。为解决这一问题，我们引入了CondensNet，这是一种新颖的神经网络架构，其内置自适应物理约束以纠正不合理的凝结过程。CondensNet有效地缓解了水汽过饱和问题，在提高模拟稳定性的同时保持了准确性和提高了计算效率，相比超参数化方案更具优势。\n\n我们将CondensNet整合到GCM中，形成了PCNN-GCM（物理约束神经网络GCM），一种专为实际条件下长期稳定的气候模拟设计的混合深度学习框架，包括海洋和陆地模拟。PCNN-GCM在混合气候建模领域代表了重要里程碑，因为它展示了如何适应性地引入物理约束，为准确、轻量级和长期稳定的气候模拟开辟了新途径。', 'title_zh': 'CondensNet：通过具有自适应物理约束的混合深度学习模型实现稳定长期气候模拟'}
{'arxiv_id': 'arXiv:2502.13181', 'title': 'RingFormer: Rethinking Recurrent Transformer with Adaptive Level Signals', 'authors': 'Jaemu Heo, Eldor Fozilov, Hyunmin Song, Taehwan Kim', 'link': 'https://arxiv.org/abs/2502.13181', 'abstract': 'Transformers have achieved great success in effectively processing sequential data such as text. Their architecture consisting of several attention and feedforward blocks can model relations between elements of a sequence in parallel manner, which makes them very efficient to train and effective in sequence modeling. Even though they have shown strong performance in processing sequential data, the size of their parameters is considerably larger when compared to other architectures such as RNN and CNN based models. Therefore, several approaches have explored parameter sharing and recurrence in Transformer models to address their computational demands. However, such methods struggle to maintain high performance compared to the original transformer model. To address this challenge, we propose our novel approach, RingFormer, which employs one Transformer layer that processes input repeatedly in a circular, ring-like manner, while utilizing low-rank matrices to generate input-dependent level signals. This allows us to reduce the model parameters substantially while maintaining high performance in a variety of tasks such as translation and image classification, as validated in the experiments.', 'abstract_zh': 'transformers 在处理文本等序列数据方面取得了巨大成功。它们通过包含多个注意和前馈块的架构，能够在并行方式下建模序列中元素之间的关系，这使得它们在训练效率和序列建模方面非常高效。尽管在这项任务上表现出色，但与基于 RNN 和 CNN 的其他架构相比，它们的参数量要大得多。因此，一些方法已经探索在 Transformer 模型中实现参数共享和递归，以应对它们的计算需求。然而，这些方法在性能上难以与原始 Transformer 模型相媲美。为解决这一挑战，我们提出了一种新颖的方法——RingFormer，它采用了一种处理输入的方法，该方法以圆环状反复处理输入，并利用低秩矩阵生成输入依赖性的信号。这使得我们能够在保持翻译和图像分类等多种任务的高性能的同时，大幅减少模型参数。实验结果验证了这一点。', 'title_zh': 'RingFormer：重新构建具有自适应层级信号的循环Transformer'}
{'arxiv_id': 'arXiv:2502.13180', 'title': 'Uncertain Multi-Objective Recommendation via Orthogonal Meta-Learning Enhanced Bayesian Optimization', 'authors': 'Hongxu Wang, Zhu Sun, Yingpeng Du, Lu Zhang, Tiantian He, Yew-Soon Ong', 'link': 'https://arxiv.org/abs/2502.13180', 'abstract': 'Recommender systems (RSs) play a crucial role in shaping our digital interactions, influencing how we access and engage with information across various domains. Traditional research has predominantly centered on maximizing recommendation accuracy, often leading to unintended side effects such as echo chambers and constrained user experiences. Drawing inspiration from autonomous driving, we introduce a novel framework that categorizes RS autonomy into five distinct levels, ranging from basic rule-based accuracy-driven systems to behavior-aware, uncertain multi-objective RSs - where users may have varying needs, such as accuracy, diversity, and fairness. In response, we propose an approach that dynamically identifies and optimizes multiple objectives based on individual user preferences, fostering more ethical and intelligent user-centric recommendations. To navigate the uncertainty inherent in multi-objective RSs, we develop a Bayesian optimization (BO) framework that captures personalized trade-offs between different objectives while accounting for their uncertain interdependencies. Furthermore, we introduce an orthogonal meta-learning paradigm to enhance BO efficiency and effectiveness by leveraging shared knowledge across similar tasks and mitigating conflicts among objectives through the discovery of orthogonal information. Finally, extensive empirical evaluations demonstrate the effectiveness of our method in optimizing uncertain multi-objectives for individual users, paving the way for more adaptive and user-focused RSs.', 'abstract_zh': '推荐系统（RSs）在塑造我们的数字互动方面发挥着关键作用，影响着我们在各个领域获取和参与信息的方式。传统研究主要侧重于最大化推荐准确性，这通常会导致诸如回声室效应和用户体验受限等意想不到的副作用。借鉴自动驾驶技术，我们引入了一种新的框架，将推荐系统自主性划分为五个不同的层级，从基于基本规则和准确性的系统，到具备行为意识的不确定多目标系统——在这个系统中，用户可能有不同的需求，如准确性、多样性和公平性。针对这一挑战，我们提出了一种方法，该方法能够动态识别并基于个体用户偏好优化多种目标，从而促进更具道德性和智能性的以用户为中心的推荐。为应对多目标推荐系统中的不确定性，我们开发了一种贝叶斯优化（BO）框架，该框架能够捕捉不同目标之间的个性化权衡，并考虑它们的不确定相互依赖关系。此外，我们引入了一种正交元学习范式，通过利用相似任务中的共享知识来提高BO的效率和效果，并通过发现正交信息来缓解目标之间的冲突。最后，广泛的实证评估表明，我们的方法在优化个体用户的不确定多目标方面是有效的，这为更加适应性和以用户为中心的推荐系统铺平了道路。', 'title_zh': '通过正交元学习增强的贝叶斯优化在不确定性多目标推荐中的应用'}
{'arxiv_id': 'arXiv:2502.13179', 'title': 'PTQ1.61: Push the Real Limit of Extremely Low-Bit Post-Training Quantization Methods for Large Language Models', 'authors': 'Jiaqi Zhao, Miao Zhang, Ming Wang, Yuzhang Shang, Kaihao Zhang, Weili Guan, Yaowei Wang, Min Zhang', 'link': 'https://arxiv.org/abs/2502.13179', 'abstract': 'Large Language Models (LLMs) suffer severe performance degradation when facing extremely low-bit (sub 2-bit) quantization. Several existing sub 2-bit post-training quantization (PTQ) methods utilize a mix-precision scheme by leveraging an unstructured fine-grained mask to explicitly distinguish salient weights, while which introduces an extra 1-bit or more per weight. To explore the real limit of PTQ, we propose an extremely low-bit PTQ method called PTQ1.61, which enables weight quantization to 1.61-bit for the first time. Specifically, we first introduce a one-dimensional structured mask with negligibly additional 0.0002-bit per weight based on input activations from the perspective of reducing the upper bound of quantization error to allocate corresponding salient weight channels to 4-bit. For non-salient channels binarization, an efficient block-wise scaling factors optimization framework is then presented to take implicit row-wise correlations and angular biases into account. Different from prior works that concentrate on adjusting quantization methodologies, we further propose a novel paradigm called quantization preprocessing, where we argue that transforming the weight distribution of the pretrained model before quantization can alleviate the difficulty in per-channel extremely low-bit PTQ. Extensive experiments indicate our PTQ1.61 achieves state-of-the-art performance in extremely low-bit quantization. Codes are available at this https URL.', 'abstract_zh': '大型语言模型（LLMs）在面对超低位（低于2位）量化时会出现严重的性能下降。现有的几种超低位后训练量化（PTQ）方法通过利用不规则的细粒度掩码引入混合精度方案，以显式区分重要的权重，但这会为每个权重引入额外的1位或更多。为了探索PTQ的真正极限，我们提出了一种称为PTQ1.61的超低位PTQ方法，这使权重量化首次达到了1.61位。具体而言，我们首先基于输入激活提出了一个一维结构化掩码，该掩码每权重仅增加忽略不计的0.0002位，以减少量化误差的上界，并将相应的重要权重通道分配给4位。然后，我们提出了一种高效的分块缩放因子优化框架，以考虑隐式的行间相关性和角度偏差。不同于以往专注于调整量化方法的研究，我们进一步提出了一个新颖的前处理量化范式，我们认为在量化之前对预训练模型的权重分布进行转换可以缓解通道级超低位量化中的困难。广泛实验表明，我们的PTQ1.61在超低位量化中达到了最先进的性能。代码可以通过以下链接获取：<链接地址>。', 'title_zh': 'PTQ1.61: 探索极限低比特量化方法在大规模语言模型中的实际潜力'}
{'arxiv_id': 'arXiv:2502.13178', 'title': 'Benchmarking Post-Training Quantization in LLMs: Comprehensive Taxonomy, Unified Evaluation, and Comparative Analysis', 'authors': 'Jiaqi Zhao, Ming Wang, Miao Zhang, Yuzhang Shang, Xuebo Liu, Yaowei Wang, Min Zhang, Liqiang Nie', 'link': 'https://arxiv.org/abs/2502.13178', 'abstract': 'Post-training Quantization (PTQ) technique has been extensively adopted for large language models (LLMs) compression owing to its efficiency and low resource requirement. However, current research lacks a in-depth analysis of the superior and applicable scenarios of each PTQ strategy. In addition, existing algorithms focus primarily on performance, overlooking the trade-off among model size, performance, and quantization bitwidth. To mitigate these confusions, we provide a novel benchmark for LLMs PTQ in this paper. Firstly, in order to support our benchmark, we propose a comprehensive taxonomy for existing mainstream methods by scrutinizing their computational strategies (e.g., optimization-based, compensation-based, etc.). Then, we conduct extensive experiments with the baseline within each class, covering models with various sizes (7B-70B), bitwidths, training levels (LLaMA1/2/3/3.1), architectures (Mixtral, DeepSeekMoE and Mamba) and modality (LLaVA1.5 and VILA1.5) on a wide range of evaluation this http URL comparative analysis on the results, we summarize the superior of each PTQ strategy and modelsize-bitwidth trade-off considering the performance. For example, our benchmark reveals that compensation-based technique demonstrates outstanding cross-architecture robustness and extremely low-bit PTQ for ultra large models should be reexamined. Finally, we further accordingly claim that a practical combination of compensation and other PTQ strategy can achieve SOTA various robustness. We believe that our benchmark will provide valuable recommendations for the deployment of LLMs and future research on PTQ approaches.', 'abstract_zh': '后训练量化（Post-Training Quantization, PTQ）技术因其高效性和低资源需求，已被广泛应用于大型语言模型（Large Language Models, LLMs）的压缩。然而，当前的研究缺乏对每种PTQ策略的优秀应用场景和适用性的深入分析。此外，现有算法主要侧重于性能，而忽视了模型大小、性能和量化位宽之间的权衡。为解决这些问题，我们在本文中提供了一个新颖的LLMs后训练量化基准。\n\n具体而言，为了支持我们的基准，我们通过仔细审查现有的主流方法的计算策略（例如，基于优化的、基于补偿的等），提出了一种全面的分类体系。然后，我们通过涵盖各种大小（7B-70B）、位宽、训练层级（LLaMA1/2/3/3.1）、架构（Mixtral、DeepSeekMoE和Mamba）以及模态（LLaVA1.5和VILA1.5）的广泛实验，对基准模型进行深入研究。在此基础上，我们对结果进行了详尽的比较分析，总结了每种PTQ策略的优势以及模型大小与位宽之间的权衡关系，同时考虑了性能。例如，我们的基准表明，基于补偿的技术在不同架构之间表现出了出色的稳健性，对于超大规模模型来说，极低位宽的PTQ策略可能需要重新评估。最后，我们进一步提出，将补偿技术和其他PTQ策略有机结合，可以实现顶级的稳健性。我们相信，我们的基准将为LLMs的部署和未来PTQ方法的研究提供有价值的建议。', 'title_zh': '在大型语言模型中基准化后训练量化：全面分类、统一评估和比较分析'}
{'arxiv_id': 'arXiv:2502.13177', 'title': 'KL Penalty Control via Perturbation for Direct Preference Optimization', 'authors': 'Sangkyu Lee, Janghoon Han, Hosung Song, Stanley Jungkyu Choi, Honglak Lee, Youngjae Yu', 'link': 'https://arxiv.org/abs/2502.13177', 'abstract': 'Direct Preference Optimization (DPO) demonstrates the advantage of aligning a large language model with human preference using only an offline dataset. However, DPO has the limitation that the KL penalty, which prevents excessive deviation from the reference model, is static throughout the training process. Several methods try to turn this static KL penalty into a dynamic one, but no approach can adaptively assign different KL penalties for each preference pair. In this paper, we propose $\\varepsilon$-Direct Preference Optimization ($\\varepsilon$-DPO), which allows adaptive control of the KL penalty strength $\\beta$ for each preference pair. Specifically, $\\varepsilon$-DPO adaptively controls $\\beta$ for each preference pair based on the monotonicity of logits as a preference model under the perturbation of $\\beta$ during training by simply reusing the logit of the current policy and the reference policy. Experimental results show that $\\varepsilon$-DPO outperforms existing direct alignment algorithms and KL penalty relaxation methods on general chatbot benchmarks, highlighting the significance of adaptive KL penalty relaxation at the instance-level in DPO.', 'abstract_zh': '直接偏好优化（DPO）展示了通过仅使用离线数据集对大型语言模型进行与人类偏好的对齐的优势。然而，DPO 的一个局限性在于，用于防止过度偏离参考模型的 KL 奖惩在整个训练过程中是静态的。尽管一些方法试图将这种静态的 KL 奖惩转变为动态的，但没有方法能够适应性地为每一对偏好分配不同的 KL 奖惩。在本文中，我们提出了ε-直接偏好优化（ε-DPO），它允许为每一对偏好适配地控制 KL 奖惩强度 β。具体而言，ε-DPO 通过简单地重新使用当前策略和参考策略的 logits，在训练过程中根据 β 氛围改变时 logits 的单调性，对每一对偏好适配地控制 β。实验结果表明，ε-DPO 在通用聊天机器人类标基准上优于现有的直接对齐算法和 KL 奖惩放宽方法，突显了在 DPO 中实例级适配性 KL 奖惩放宽的重要性。', 'title_zh': 'KL 偏置控制通过扰动进行直接偏好优化'}
{'arxiv_id': 'arXiv:2502.13176', 'title': 'BaKlaVa -- Budgeted Allocation of KV cache for Long-context Inference', 'authors': 'Ahmed Burak Gulhan, Krishna Teja Chitty-Venkata, Murali Emani, Mahmut Kandemir, Venkatram Vishwanath', 'link': 'https://arxiv.org/abs/2502.13176', 'abstract': 'In Large Language Model (LLM) inference, Key-Value (KV) caches (KV-caches) are essential for reducing time complexity. However, they result in a linear increase in GPU memory as the context length grows. While recent work explores KV-cache eviction and compression policies to reduce memory usage, they often consider uniform KV-caches across all attention heads, leading to suboptimal performance. We introduce BaKlaVa, a method to allocate optimal memory for individual KV-caches across the model by estimating the importance of each KV-cache. Our empirical analysis demonstrates that not all KV-caches are equally critical for LLM performance. Using a one-time profiling approach, BaKlaVa assigns optimal memory budgets to each KV-cache. We evaluated our method on LLaMA-3-8B, and Qwen2.5-7B models, achieving up to a 70\\% compression ratio while keeping baseline performance and delivering up to an order-of-magnitude accuracy improvement at higher compression levels.', 'abstract_zh': '在大规模语言模型（LLM）推理中，键值（KV）缓存（KV缓存）对于减少时间复杂度至关重要。然而，随着上下文长度的增长，KV缓存会导致GPU内存呈线性增加。尽管最近的一些研究探索了KV缓存淘汰和压缩策略以减少内存使用，但它们通常假设所有注意力头的KV缓存是均匀分布的，这可能导致性能不佳。我们提出了BaKlaVa方法，通过估算每个KV缓存的重要性，在模型中为每个KV缓存分配最优的内存。我们的实证分析表明，并非所有KV缓存对于LLM性能都同等关键。通过一次性的配置分析方法，BaKlaVa为每个KV缓存分配了最优的内存预算。我们在LLaMA-3-8B和Qwen2.5-7B模型上进行了评估，在保持基线性能的同时，实现了高达70%的压缩比，并在较高压缩级别下实现了数量级级别的准确度提升。', 'title_zh': 'BaKlaVa——为长上下文推理分配预算化的键值缓存'}
{'arxiv_id': 'arXiv:2502.13175', 'title': 'Towards Robust and Secure Embodied AI: A Survey on Vulnerabilities and Attacks', 'authors': 'Wenpeng Xing, Minghao Li, Mohan Li, Meng Han', 'link': 'https://arxiv.org/abs/2502.13175', 'abstract': 'Embodied AI systems, including robots and autonomous vehicles, are increasingly integrated into real-world applications, where they encounter a range of vulnerabilities stemming from both environmental and system-level factors. These vulnerabilities manifest through sensor spoofing, adversarial attacks, and failures in task and motion planning, posing significant challenges to robustness and safety. Despite the growing body of research, existing reviews rarely focus specifically on the unique safety and security challenges of embodied AI systems. Most prior work either addresses general AI vulnerabilities or focuses on isolated aspects, lacking a dedicated and unified framework tailored to embodied AI. This survey fills this critical gap by: (1) categorizing vulnerabilities specific to embodied AI into exogenous (e.g., physical attacks, cybersecurity threats) and endogenous (e.g., sensor failures, software flaws) origins; (2) systematically analyzing adversarial attack paradigms unique to embodied AI, with a focus on their impact on perception, decision-making, and embodied interaction; (3) investigating attack vectors targeting large vision-language models (LVLMs) and large language models (LLMs) within embodied systems, such as jailbreak attacks and instruction misinterpretation; (4) evaluating robustness challenges in algorithms for embodied perception, decision-making, and task planning; and (5) proposing targeted strategies to enhance the safety and reliability of embodied AI systems. By integrating these dimensions, we provide a comprehensive framework for understanding the interplay between vulnerabilities and safety in embodied AI.', 'abstract_zh': '嵌入式AI系统，包括机器人和自主车辆，正越来越多地集成到实际应用中，在这些应用中，它们会遇到各种来自环境和系统层面因素的漏洞。这些漏洞通过传感器欺骗、恶意攻击以及任务和运动规划失败等形式表现出来，对系统的稳健性和安全性构成了重大挑战。尽管已有大量研究，但现有的综述文章大多没有专门关注嵌入式AI系统特有的安全与安全挑战。大部分先前的研究要么侧重于一般性的AI漏洞，要么关注单一的方面，缺乏针对嵌入式AI系统的专门且统一的框架。本文综述填补了这一关键空白，具体通过以下几点进行：\n\n1. 将嵌入式AI特有的漏洞归类为外源性（如物理攻击、网络安全威胁）和内源性（如传感器故障、软件缺陷）来源；\n2. 系统分析嵌入式AI特有的恶意攻击模式，重点关注这些攻击对感知、决策和交互的影响；\n3. 探讨针对大型视觉-语言模型（LVLM）和大型语言模型（LLM）的攻击向量，例如突破攻击和指令误解释；\n4. 评估嵌入式感知、决策和任务规划算法中的稳健性挑战；\n5. 提出增强嵌入式AI系统安全性和可靠性的针对性策略。\n\n通过整合这些维度，我们提供了一个全面的框架，以理解嵌入式AI中的漏洞与安全之间的相互作用。', 'title_zh': '面向鲁棒性和安全性的体感AI：脆弱性与攻击综述'}
{'arxiv_id': 'arXiv:2502.13174', 'title': 'Generative Topology Optimization: Exploring Diverse Solutions in Structural Design', 'authors': 'Andreas Radler, Eric Volkmann, Johannes Brandstetter, Arturs Berzins', 'link': 'https://arxiv.org/abs/2502.13174', 'abstract': 'Topology optimization (TO) is a family of computational methods that derive near-optimal geometries from formal problem descriptions. Despite their success, established TO methods are limited to generating single solutions, restricting the exploration of alternative designs. To address this limitation, we introduce Generative Topology Optimization (GenTO) - a data-free method that trains a neural network to generate structurally compliant shapes and explores diverse solutions through an explicit diversity constraint. The network is trained with a solver-in-the-loop, optimizing the material distribution in each iteration. The trained model produces diverse shapes that closely adhere to the design requirements. We validate GenTO on 2D and 3D TO problems. Our results demonstrate that GenTO produces more diverse solutions than any prior method while maintaining near-optimality and being an order of magnitude faster due to inherent parallelism. These findings open new avenues for engineering and design, offering enhanced flexibility and innovation in structural optimization.', 'abstract_zh': '拓扑优化（TO）是一系列从正式问题描述中推导出接近最优几何形状的计算方法。尽管取得了成功，传统的TO方法只能生成单一解决方案，限制了对替代设计的探索。为了解决这一限制，我们提出了一种名为生成拓扑优化（GenTO）的方法——一种无需数据的方法，通过训练神经网络生成符合结构要求的形状，并通过显式的多样性约束探索多种解决方案。该网络在每次迭代中与求解器结合进行训练，优化每一步的材料分布。训练好的模型能够生成多种多样且紧密遵循设计要求的形状。我们分别在2D和3D的TO问题上验证了GenTO。实验结果表明，GenTO生成的解决方案比任何先前的方法更为多样化，同时也保持了接近最优性和快得多的处理速度，这是因为其固有的并行性原因。这些发现为工程和设计领域开辟了新的途径，为结构优化提供了更强的灵活性和创新性。', 'title_zh': '生成拓扑优化：在结构设计中探索多样化的解决方案'}
{'arxiv_id': 'arXiv:2502.13173', 'title': 'Thinking Preference Optimization', 'authors': 'Wang Yang, Hongye Jin, Jingfeng Yang, Vipin Chaudhary, Xiaotian Han', 'link': 'https://arxiv.org/abs/2502.13173', 'abstract': "Supervised Fine-Tuning (SFT) has been a go-to and effective method for enhancing long chain-of-thought (CoT) reasoning in relatively small LLMs by fine-tuning them with long CoT responses from larger LLMs. To continually improve reasoning abilities, we can either collect new high-quality long CoT reasoning SFT data or repeatedly train on existing SFT datasets. However, acquiring new long CoT SFT data is costly and limited, while repeated training often results in a performance plateau or decline. To further boost the performance with the SFT data, we propose Thinking Preference Optimization (ThinkPO), a simple yet effective post-SFT method that enhances long CoT reasoning without requiring new long CoT responses. Instead, ThinkPO utilizes readily available or easily obtainable short CoT reasoning responses as rejected answers and long CoT responses as chosen answers for the same question. It then applies direct preference optimization to encourage the model to favor longer reasoning outputs. Experiments show that ThinkPO further improves the reasoning performance of SFT-ed models, e.g. it increases math reasoning accuracy of SFT-ed models by 8.6% and output length by 25.9%. Notably, ThinkPO is capable of continually boosting the performance of the publicly distilled SFT model, e.g., increasing the official DeepSeek-R1-Distill-Qwen-7B's performance on MATH500 from 87.4% to 91.2%.", 'abstract_zh': '监督微调（SFT）已成为通过使用更大语言模型（LLM）中的长链式推理（CoT）响应来增强相对较小LLM中长链式推理能力的一种常用且有效的方法。为了不断改进推理能力，我们可以通过收集新的高质量长链式推理SFT数据，或者反复训练现有的SFT数据集来实现。然而，获得新的长链式推理SFT数据成本较高且资源有限，而反复训练往往会达到性能 Plateau 或下降。为利用SFT数据进一步提升性能，我们提出了思考偏好优化（ThinkPO），这是一种简单而有效的后SFT方法，可以在不需新增长链式推理响应的情况下增强长链式推理能力。具体而言，ThinkPO 利用可以直接获得或轻松获得的短链式推理响应作为拒绝答案，并使用相同的短链式推理响应和长链式推理响应作为被选答案，然后通过直接偏好优化以鼓励模型倾向于产生更长的推理输出。实验表明，ThinkPO 进一步提升了SFT模型的推理性能，例如，提升了SFT模型在数学推理准确率方面的表现，增加了8.6%的准确率和25.9%的输出长度。值得注意的是，ThinkPO 能够持续提升公开精简的SFT模型的性能，例如，将官方DeepSeek-R1-Distill-Qwen-7B在MATH500数据集上的性能从87.4%提高到91.2%。', 'title_zh': '思考偏好优化'}
{'arxiv_id': 'arXiv:2502.13172', 'title': 'Unveiling Privacy Risks in LLM Agent Memory', 'authors': 'Bo Wang, Weiyi He, Pengfei He, Shenglai Zeng, Zhen Xiang, Yue Xing, Jiliang Tang', 'link': 'https://arxiv.org/abs/2502.13172', 'abstract': "Large Language Model (LLM) agents have become increasingly prevalent across various real-world applications. They enhance decision-making by storing private user-agent interactions in the memory module for demonstrations, introducing new privacy risks for LLM agents. In this work, we systematically investigate the vulnerability of LLM agents to our proposed Memory EXTRaction Attack (MEXTRA) under a black-box setting. To extract private information from memory, we propose an effective attacking prompt design and an automated prompt generation method based on different levels of knowledge about the LLM agent. Experiments on two representative agents demonstrate the effectiveness of MEXTRA. Moreover, we explore key factors influencing memory leakage from both the agent's and the attacker's perspectives. Our findings highlight the urgent need for effective memory safeguards in LLM agent design and deployment.", 'abstract_zh': '大语言模型（LLM）代理在各种实际应用中越来越普遍。它们通过在记忆模块中储存私用户-代理交互来增强决策能力，从而引入了新的隐私风险。本研究系统地探讨了在黑盒设置下，我们提出的记忆提取攻击（MEXTRA）对LLM代理的脆弱性。为了从记忆中提取私有信息，我们提出了一种有效的攻击提示设计方法，以及基于对LLM代理不同知识水平的自动化提示生成方法。在两个典型代理上的实验表明了MEXTRA的有效性。此外，我们从代理方和攻击方的角度探讨了影响记忆泄露的关键因素。我们的发现强调了在LLM代理设计和部署中需要有效的记忆保护措施的紧迫性。', 'title_zh': '揭示大规模语言模型代理记忆中的隐私风险'}
{'arxiv_id': 'arXiv:2502.13171', 'title': 'Web Phishing Net (WPN): A scalable machine learning approach for real-time phishing campaign detection', 'authors': 'Muhammad Fahad Zia, Sri Harish Kalidass', 'link': 'https://arxiv.org/abs/2502.13171', 'abstract': 'Phishing is the most prevalent type of cyber-attack today and is recognized as the leading source of data breaches with significant consequences for both individuals and corporations. Web-based phishing attacks are the most frequent with vectors such as social media posts and emails containing links to phishing URLs that once clicked on render host systems vulnerable to more sinister attacks. Research efforts to detect phishing URLs have involved the use of supervised learning techniques that use large amounts of data to train models and have high computational requirements. They also involve analysis of features derived from vectors including email contents thus affecting user privacy. Additionally, they suffer from a lack of resilience against evolution of threats especially with the advent of generative AI techniques to bypass these systems as with AI-generated phishing URLs. Unsupervised methods such as clustering techniques have also been used in phishing detection in the past, however, they are at times unscalable due to the use of pair-wise comparisons. They also lack high detection rates while detecting phishing campaigns. In this paper, we propose an unsupervised learning approach that is not only fast but scalable, as it does not involve pair-wise comparisons. It is able to detect entire campaigns at a time with a high detection rate while preserving user privacy; this includes the recent surge of campaigns with targeted phishing URLs generated by malicious entities using generative AI techniques.', 'abstract_zh': '网络钓鱼是当今最常见的网络攻击类型，被公认为导致重大个人和企业数据泄露的主要来源。基于网页的网络钓鱼攻击最为频繁，其通过社交媒体帖子和电子邮件中的链接指向网络钓鱼网站，一旦点击，便会使宿主系统暴露在更严重的攻击之下。研究中用于检测网络钓鱼URL的方法主要采用了监督学习技术，需要大量的数据进行模型训练，具有较高的计算需求。此外，这些方法还涉及对电子邮件内容等向量特征的分析，从而影响用户隐私。此外，它们还难以抵抗威胁的演变，尤其是在生成式AI技术出现后，这些技术可以绕过这些系统，如生成的网络钓鱼URL。过去，无监督方法如聚类技术也被用于网络钓鱼检测，但由于使用成对比较，这些方法有时难以扩展，并且在检测网络钓鱼活动时的检测率较低。本文提出了一种无监督学习方法，不仅快速、可扩展（不涉及成对比较），还能够一次性检测整个活动，并保持较高的检测率，同时保护用户隐私；这包括近期由恶意实体使用生成式AI技术生成的定向网络钓鱼URL的活动。', 'title_zh': 'Web钓鱼网络(WPN): 一种用于实时钓鱼活动检测的可扩展机器学习方法'}
{'arxiv_id': 'arXiv:2502.13167', 'title': 'SmartLLM: Smart Contract Auditing using Custom Generative AI', 'authors': 'Jun Kevin, Pujianto Yugopuspito', 'link': 'https://arxiv.org/abs/2502.13167', 'abstract': "Smart contracts are essential to decentralized finance (DeFi) and blockchain ecosystems but are increasingly vulnerable to exploits due to coding errors and complex attack vectors. Traditional static analysis tools and existing vulnerability detection methods often fail to address these challenges comprehensively, leading to high false-positive rates and an inability to detect dynamic vulnerabilities. This paper introduces SmartLLM, a novel approach leveraging fine-tuned LLaMA 3.1 models with Retrieval-Augmented Generation (RAG) to enhance the accuracy and efficiency of smart contract auditing. By integrating domain-specific knowledge from ERC standards and employing advanced techniques such as QLoRA for efficient fine-tuning, SmartLLM achieves superior performance compared to static analysis tools like Mythril and Slither, as well as zero-shot large language model (LLM) prompting methods such as GPT-3.5 and GPT-4. Experimental results demonstrate a perfect recall of 100% and an accuracy score of 70%, highlighting the model's robustness in identifying vulnerabilities, including reentrancy and access control issues. This research advances smart contract security by offering a scalable and effective auditing solution, supporting the secure adoption of decentralized applications.", 'abstract_zh': '智能合约是去中心化金融（DeFi）和区块链生态系统的核心组成部分，但由于编码错误和复杂的攻击向量，它们的脆弱性正在增加。传统的静态分析工具和现有的漏洞检测方法往往无法全面应对这些挑战，导致高误报率和无法检测动态漏洞。本文介绍了SmartLLM，这是一种利用微调的LLaMA 3.1模型结合检索增强生成（RAG）的新颖方法，以提高智能合约审计的准确性和效率。通过整合来自ERC标准的领域特定知识，并采用高效的微调技术如QLoRA，SmartLLM 在性能上优于如Mythril和Slither等静态分析工具，以及零样本大语言模型（LLM）提示方法如GPT-3.5和GPT-4。实验结果表明召回率为100%，准确率为70%，突显了该模型在识别包括重入攻击和访问控制问题在内的漏洞方面的稳健性。这项研究通过提供一种可扩展且有效的方法，推进了智能合约的安全性，支持去中心化应用程序的安全部署。', 'title_zh': 'SmartLLM：基于定制生成式AI的智能合约审计'}
{'arxiv_id': 'arXiv:2502.13166', 'title': 'Large Language Models Can Help Mitigate Barren Plateaus', 'authors': 'Jun Zhuang, Chaowen Guan', 'link': 'https://arxiv.org/abs/2502.13166', 'abstract': "In the era of noisy intermediate-scale quantum (NISQ) computing, Quantum Neural Networks (QNNs) have emerged as a promising approach for various applications, yet their training is often hindered by barren plateaus (BPs), where gradient variance vanishes exponentially as the model size increases. To address this challenge, we propose a new Large Language Model (LLM)-driven search framework, AdaInit, that iteratively searches for optimal initial parameters of QNNs to maximize gradient variance and therefore mitigate BPs. Unlike conventional one-time initialization methods, AdaInit dynamically refines QNN's initialization using LLMs with adaptive prompting. Theoretical analysis of the Expected Improvement (EI) proves a supremum for the search, ensuring this process can eventually identify the optimal initial parameter of the QNN. Extensive experiments across four public datasets demonstrate that AdaInit significantly enhances QNN's trainability compared to classic initialization methods, validating its effectiveness in mitigating BPs.", 'abstract_zh': '在嘈杂的中等规模量子（NISQ）计算时代，量子神经网络（QNNs）已成为各种应用的有前途的方法之一，但它们的训练常因梯度消失的“平坦梯度区”（barren plateaus, BPs）而受到阻碍。为了解决这一挑战，我们提出了一种新的基于大型语言模型（LLM）的搜索框架——AdaInit，该框架通过迭代搜索来优化QNN的初始参数，以最大化梯度方差，从而减轻BP问题。不同于传统的单一初始化方法，AdaInit利用具有自适应提示的LLMs动态优化QNN的初始化。理论分析表明，预期改善（Expected Improvement, EI）为搜索过程提供了一个上界，确保此过程最终能够识别出QNN的最佳初始参数。在四个公开数据集上进行的大量实验表明，相比于经典初始化方法，AdaInit显著提高了QNN的可训练性，验证了其在减轻BP问题方面的有效性。', 'title_zh': '大型语言模型可以幫助緩解無效 plateau 獨凍現象'}
{'arxiv_id': 'arXiv:2502.13165', 'title': 'HedgeAgents: A Balanced-aware Multi-agent Financial Trading System', 'authors': 'Xiangyu Li, Yawen Zeng, Xiaofen Xing, Jin Xu, Xiangmin Xu', 'link': 'https://arxiv.org/abs/2502.13165', 'abstract': "As automated trading gains traction in the financial market, algorithmic investment strategies are increasingly prominent. While Large Language Models (LLMs) and Agent-based models exhibit promising potential in real-time market analysis and trading decisions, they still experience a significant -20% loss when confronted with rapid declines or frequent fluctuations, impeding their practical application. Hence, there is an imperative to explore a more robust and resilient framework. This paper introduces an innovative multi-agent system, HedgeAgents, aimed at bolstering system robustness via ``hedging'' strategies. In this well-balanced system, an array of hedging agents has been tailored, where HedgeAgents consist of a central fund manager and multiple hedging experts specializing in various financial asset classes. These agents leverage LLMs' cognitive capabilities to make decisions and coordinate through three types of conferences. Benefiting from the powerful understanding of LLMs, our HedgeAgents attained a 70% annualized return and a 400% total return over a period of 3 years. Moreover, we have observed with delight that HedgeAgents can even formulate investment experience comparable to those of human experts (this https URL).", 'abstract_zh': '随着自动化交易在金融市场中的逐渐普及，算法投资策略日益突出。虽然大型语言模型（LLMs）和基于代理的模型在实时市场分析和交易决策方面展现出巨大的潜力，但在面对急剧下跌或频繁波动时，它们仍然会遭受高达20%的损失，这阻碍了它们的实际应用。因此，有必要探索更加 robust 和 resilient 的框架。本文介绍了一种创新的多代理系统——HedgeAgents，旨在通过“对冲”策略来增强系统的稳健性。在这个平衡良好的系统中，已经设计了一系列对冲代理，HedgeAgents 包括一个中央资金管理者和多个专注于不同金融资产类别的对冲专家。这些代理利用 LLMs 的认知能力做出决策并通过三种类型的会议进行协调。得益于 LLMs 强大的理解能力，我们的 HedgeAgents 在三年的时间内实现了70%的年化回报率和400%的总回报率。此外，我们高兴地观察到，HedgeAgents 即使在投资经验方面也能够媲美人类专家（请参阅此链接: [请插入链接]）。', 'title_zh': 'HedgeAgents：一种兼顾平衡的多agent金融市场交易系统'}
{'arxiv_id': 'arXiv:2502.13164', 'title': 'Multi-Agent Actor-Critic Generative AI for Query Resolution and Analysis', 'authors': 'Mohammad Wali Ur Rahman, Ric Nevarez, Lamia Tasnim Mim, Salim Hariri', 'link': 'https://arxiv.org/abs/2502.13164', 'abstract': 'In this paper, we introduce MASQRAD (Multi-Agent Strategic Query Resolution and Diagnostic tool), a transformative framework for query resolution based on the actor-critic model, which utilizes multiple generative AI agents. MASQRAD is excellent at translating imprecise or ambiguous user inquiries into precise and actionable requests. This framework generates pertinent visualizations and responses to these focused queries, as well as thorough analyses and insightful interpretations for users. MASQRAD addresses the common shortcomings of existing solutions in domains that demand fast and precise data interpretation, such as their incapacity to successfully apply AI for generating actionable insights and their challenges with the inherent ambiguity of user queries. MASQRAD functions as a sophisticated multi-agent system but "masquerades" to users as a single AI entity, which lowers errors and enhances data interaction. This approach makes use of three primary AI agents: Actor Generative AI, Critic Generative AI, and Expert Analysis Generative AI. Each is crucial for creating, enhancing, and evaluating data interactions. The Actor AI generates Python scripts to generate data visualizations from large datasets within operational constraints, and the Critic AI rigorously refines these scripts through multi-agent debate. Finally, the Expert Analysis AI contextualizes the outcomes to aid in decision-making. With an accuracy rate of 87\\% when handling tasks related to natural language visualization, MASQRAD establishes new benchmarks for automated data interpretation and showcases a noteworthy advancement that has the potential to revolutionize AI-driven applications.', 'abstract_zh': '在本文中，我们介绍了一种名为MASQRAD（多代理战略查询解析与诊断工具）的框架，该框架基于演员-评论者模型，利用了多个生成式人工智能代理。MASQRAD能够将模糊或含糊的用户查询精确化和具体化为可执行的请求。该框架生成与这些集中查询相关的相关可视化和响应，并为用户提供详细的分析和见解。MASQRAD解决了现有解决方案在需要快速精确数据解释的领域中的常见不足，如它们无法成功应用AI生成可执行见解以及用户查询固有的模糊性带来的挑战。MASQRAD作为一个复杂的多代理系统，但在用户面前“伪装”为单一个人工智能实体，降低了错误率并提升了数据交互的质量。这种方法利用了三种主要的AI代理：演员生成式AI、评论者生成式AI和专家分析生成式AI。每个代理对于创建、增强和评估数据交互都是至关重要的。演员AI生成Python脚本来在操作约束内从大规模数据集中生成数据可视化，评论者AI通过多代理辩论严谨地改进这些脚本。最后，专家分析AI将结果置于上下文中，以辅助决策。在自然语言可视化任务处理中，MASQRAD的准确率达到87%，并建立了自动数据解释的新基准，展示了具有潜力革新人工智能驱动应用的重要进展。', 'title_zh': '多代理actor-critic生成式AI在查询解析与分析中的应用'}
{'arxiv_id': 'arXiv:2502.13162', 'title': 'ShieldLearner: A New Paradigm for Jailbreak Attack Defense in LLMs', 'authors': 'Ziyi Ni, Hao Wang, Huacan Wang', 'link': 'https://arxiv.org/abs/2502.13162', 'abstract': 'Large Language Models (LLMs) have achieved remarkable success in various domains but remain vulnerable to adversarial jailbreak attacks. Existing prompt-defense strategies, including parameter-modifying and parameter-free approaches, face limitations in adaptability, interpretability, and customization, constraining their effectiveness against evolving threats. To address these challenges, we propose ShieldLearner, a novel paradigm that mimics human learning in defense. Through trial and error, it autonomously distills attack signatures into a Pattern Atlas and synthesizes defense heuristics into a Meta-analysis Framework, enabling systematic and interpretable threat detection. Furthermore, we introduce Adaptive Adversarial Augmentation to generate adversarial variations of successfully defended prompts, enabling continuous self-improvement without model retraining. In addition to standard benchmarks, we create a hard test set by curating adversarial prompts from the Wildjailbreak dataset, emphasizing more concealed malicious intent. Experimental results show that ShieldLearner achieves a significantly higher defense success rate than existing baselines on both conventional and hard test sets, while also operating with lower computational overhead, making it a practical and efficient solution for real-world adversarial defense.', 'abstract_zh': '大规模语言模型（LLMs）在各个领域都取得了显著的成功，但仍然容易受到对抗性 jailbreak 攻击的影响。现有的提示防御策略，包括参数修改和无参数方法，存在适应性、可解释性和个性化等方面的局限性，限制了它们在应对不断演变的威胁时的有效性。为应对这些挑战，我们提出了一种名为 ShieldLearner 的新颖范式，该范式模仿人类在防御中的学习过程。通过不断尝试和错误，它能够自主地将攻击特征提炼为特征图谱，并将防御策略归纳为元分析框架，从而实现系统的、可解释的威胁检测。此外，我们引入了自适应对抗增强方法，通过生成成功防御的对抗变体提示，使其能够在不重新训练模型的情况下持续自我改进。除了标准基准测试之外，我们还通过从 Wildjailbreak 数据集中精心挑选隐藏恶意意图的对抗性提示，创建了一个更难的测试集。实验结果表明，ShieldLearner 在常规和更难的测试集上的防御成功率显著高于现有基准方法，同时计算开销更低，使其成为实际场景中对抗防御的理想解决方案。', 'title_zh': 'ShieldLearner：一种新的大规模语言模型对抗攻击防御范式'}
{'arxiv_id': 'arXiv:2502.13161', 'title': 'Noumenal Labs White Paper: How To Build A Brain', 'authors': 'Maxwell J. D. Ramstead, Candice Pattisapu, Jason Fox, Jeff Beck', 'link': 'https://arxiv.org/abs/2502.13161', 'abstract': 'This white paper describes some of the design principles for artificial or machine intelligence that guide efforts at Noumenal Labs. These principles are drawn from both nature and from the means by which we come to represent and understand it. The end goal of research and development in this field should be to design machine intelligences that augment our understanding of the world and enhance our ability to act in it, without replacing us. In the first two sections, we examine the core motivation for our approach: resolving the grounding problem. We argue that the solution to the grounding problem rests in the design of models grounded in the world that we inhabit, not mere word models. A machine super intelligence that is capable of significantly enhancing our understanding of the human world must represent the world as we do and be capable of generating new knowledge, building on what we already know. In other words, it must be properly grounded and explicitly designed for rational, empirical inquiry, modeled after the scientific method. A primary implication of this design principle is that agents must be capable of engaging autonomously in causal physics discovery. We discuss the pragmatic implications of this approach, and in particular, the use cases in realistic 3D world modeling and multimodal, multidimensional time series analysis.', 'abstract_zh': '这份白皮书阐述了诺蒙那尔实验室（Noumenal Labs）在设计人工或机器智能时遵循的一些设计理念。这些原则既来源于自然界，也来源于我们理解和表达它的方法。这个领域研究与开发的最终目标应该是设计能够增强我们对世界的理解并提高我们在其中行动能力的机器智能，而不应取代我们。在前两部分中，我们将探讨我们方法的核心动机：解决基础问题。我们主张基础问题的解决方案在于设计与我们所居住的世界紧密相连的模型，而不仅仅是单词模型。能够显著提升我们对人类世界的理解的机器超级智能必须以我们的方式来表达这个世界，并能够生成新的知识，以此为基础进行推断。换句话说，它必须是正确地基础化，且明确设计用于理性、实证的探究，并遵循科学方法。这一设计原则的主要含义是，代理必须能够自主进行因果物理发现。我们将讨论这一方法的实用意义，特别是在实际3D世界建模和多模态、多维度时间序列分析方面的应用场景。', 'title_zh': 'noumenal labs白皮书：如何构建一个大脑'}
{'arxiv_id': 'arXiv:2502.13160', 'title': 'Understanding Dynamic Diffusion Process of LLM-based Agents under Information Asymmetry', 'authors': 'Yiwen Zhang, Yifu Wu, Wenyue Hua, Xuming Hu', 'link': 'https://arxiv.org/abs/2502.13160', 'abstract': 'Large language models have been used to simulate human society using multi-agent systems. Most current social simulation research emphasizes interactive behaviors in fixed environments, ignoring information opacity, relationship variability and diffusion diversity. In this paper, we study the dynamics of information diffusion in 12 asymmetric open environments defined by information content and distribution mechanisms. We first present a general framework to capture the features of information diffusion. Then, we designed a dynamic attention mechanism to help agents allocate attention to different information, addressing the limitations of LLM-based attention. Agents start by responding to external information stimuli within a five-agent group, increasing group size and forming information circles while developing relationships and sharing information. Additionally, we observe the emergence of information cocoons, the evolution of information gaps, and the accumulation of social capital, which are closely linked to psychological, sociological, and communication theories.', 'abstract_zh': '大规模语言模型已被用于通过多智能体系统模拟人类社会。目前大多数社会仿真研究侧重于固定环境中的交互行为，忽略了信息不透明性、关系的变异性以及信息扩散的多样性。本文研究了在由信息内容和分布机制定义的12种不对称开放环境中信息扩散的动力学。我们首先提出了一种通用框架来捕捉信息扩散的特征。然后，我们设计了一种动态注意力机制，以帮助智能体根据不同信息分配注意力，弥补了基于语言模型（LLM）注意力机制的局限性。智能体最初在五智能体小组中回应外部信息刺激，随着小组规模的扩大和信息循环的形成，智能体建立关系并共享信息。此外，我们观察到了信息茧房的出现、信息缺口的演变以及社会资本的积累，这些现象与心理学、社会学和传播理论密切相关。', 'title_zh': '理解在信息不对称情况下基于LLM的智能体动态扩散过程'}
{'arxiv_id': 'arXiv:2502.09720', 'title': 'NestQuant: Nested Lattice Quantization for Matrix Products and LLMs', 'authors': 'Semyon Savkin, Eitan Porat, Or Ordentlich, Yury Polyanskiy', 'link': 'https://arxiv.org/abs/2502.09720', 'abstract': "Post-training quantization (PTQ) has emerged as a critical technique for efficient deployment of large language models (LLMs). This work proposes NestQuant, a novel PTQ scheme for weights and activations that is based on self-similar nested lattices. Recent work have mathematically shown such quantizers to be information-theoretically optimal for low-precision matrix multiplication. We implement a practical low-complexity version of NestQuant based on Gosset lattice, making it a drop-in quantizer for any matrix multiplication step (e.g., in self-attention, MLP etc). For example, NestQuant quantizes weights, KV-cache, and activations of Llama-3-8B to 4 bits, achieving perplexity of 6.6 on wikitext2. This represents more than 55% reduction in perplexity gap with respect to unquantized model (perplexity of 6.14) compared to state-of-the-art Meta's SpinQuant (perplexity 7.3). Comparisons on various LLM evaluation benchmarks also show a reduction in performance degradation induced by quantization.", 'abstract_zh': '后训练量化（PTQ）已成为高效部署大型语言模型（LLMs）的关键技术。本研究提出了一种名为NestQuant的新型PTQ方案，该方案基于自相似嵌套网格。最近的研究从数学上证明，此类量化器对于低精度矩阵乘法具有信息论上的最优性。我们基于Gosset网格实现了一个具有低复杂度的实际可操作版本的NestQuant，使其成为任何矩阵乘法步骤（例如，在自我注意、MLP等步骤中）的即插即用量化器。例如，NestQuant将Llama-3-8B的权重、KV缓存和激活量化为4位， perplexity为6.6，这相较于未量化模型（perplexity为6.14）的perplexity差距减少了超过55%，并且相较于Meta公司的SpinQuant（perplexity为7.3）表现更为出色。在各种LLM评估基准上的比较也显示，量化引起的性能下降有所减少。', 'title_zh': 'NestQuant：嵌套格网量化在矩阵乘法和大语言模型中的应用'}
