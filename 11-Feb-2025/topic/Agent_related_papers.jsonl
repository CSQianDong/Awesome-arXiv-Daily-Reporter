{'arxiv_id': 'arXiv:2502.06589', 'title': 'Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training', 'authors': 'Yuchen Zhuang, Jingfeng Yang, Haoming Jiang, Xin Liu, Kewei Cheng, Sanket Lokegaonkar, Yifan Gao, Qing Ping, Tianyi Liu, Binxuan Huang, Zheng Li, Zhengyang Wang, Pei Chen, Ruijie Wang, Rongzhi Zhang, Nasser Zalmout, Priyanka Nigam, Bing Yin, Chao Zhang', 'link': 'https://arxiv.org/abs/2502.06589', 'abstract': 'Due to the scarcity of agent-oriented pre-training data, LLM-based autonomous agents typically rely on complex prompting or extensive fine-tuning, which often fails to introduce new capabilities while preserving strong generalizability. We introduce Hephaestus-Forge, the first large-scale pre-training corpus designed to enhance the fundamental capabilities of LLM agents in API function calling, intrinsic reasoning and planning, and adapting to environmental feedback. Hephaestus-Forge comprises 103B agent-specific data encompassing 76,537 APIs, including both tool documentation to introduce knowledge of API functions and function calling trajectories to strengthen intrinsic reasoning. To explore effective training protocols, we investigate scaling laws to identify the optimal recipe in data mixing ratios. By continual pre-training on Hephaestus-Forge, Hephaestus outperforms small- to medium-scale open-source LLMs and rivals commercial LLMs on three agent benchmarks, demonstrating the effectiveness of our pre-training corpus in enhancing fundamental agentic capabilities and generalization of LLMs to new tasks or environments.', 'abstract_zh': '由于面向代理的预训练数据稀缺，基于LLM的自主代理通常依赖于复杂的提示或广泛的微调，这往往无法引入新的能力同时保持较强的泛化性。我们介绍了Hephaestus-Forge，这是第一个大规模预训练语料库，旨在增强LLM代理在API功能调用、内在推理与规划以及适应环境反馈方面的基本能力。Hephaestus-Forge包含103B个特定于代理的数据，涉及76,537个API，涵盖了工具文档以介绍API功能的知识，以及功能调用轨迹以加强内在推理。为了探索有效的训练协议，我们研究了扩展律以确定数据混合比率的最优组合方式。通过持续以Hephaestus-Forge进行预训练，Hephaestus在三个代理基准测试中的表现优于小型到中型的开源LLM，与其表现相近的商业LLM相当，这证明了我们的预训练语料库在增强LLM的基本代理能力和泛化性方面的有效性。', 'title_zh': 'Hephaestus：通过持续预训练提升大型语言模型的基本智能体能力'}
{'arxiv_id': 'arXiv:2502.06472', 'title': 'KARMA: Leveraging Multi-Agent LLMs for Automated Knowledge Graph Enrichment', 'authors': 'Yuxing Lu, Jinzhuo Wang', 'link': 'https://arxiv.org/abs/2502.06472', 'abstract': 'Maintaining comprehensive and up-to-date knowledge graphs (KGs) is critical for modern AI systems, but manual curation struggles to scale with the rapid growth of scientific literature. This paper presents KARMA, a novel framework employing multi-agent large language models (LLMs) to automate KG enrichment through structured analysis of unstructured text. Our approach employs nine collaborative agents, spanning entity discovery, relation extraction, schema alignment, and conflict resolution that iteratively parse documents, verify extracted knowledge, and integrate it into existing graph structures while adhering to domain-specific schema. Experiments on 1,200 PubMed articles from three different domains demonstrate the effectiveness of KARMA in knowledge graph enrichment, with the identification of up to 38,230 new entities while achieving 83.1\\% LLM-verified correctness and reducing conflict edges by 18.6\\% through multi-layer assessments.', 'abstract_zh': '维护全面和最新的知识图谱（KGs）对于现代AI系统至关重要，但手动编目难以应对科学文献的快速增长。本文提出了KARMA框架，该框架采用多智能体大规模语言模型（LLMs），通过结构化分析非结构化文本自动化增强KG。我们的方法采用了九个协作智能体，覆盖实体发现、关系抽取、模式对齐和冲突解决，这些智能体迭代解析文档、验证提取的知识，并将其整合到现有的图结构中，同时遵循特定领域的模式。实验使用来自三个不同领域的1,200篇PubMed文章展示了KARMA在知识图谱增强中的有效性，成功识别了高达38,230个新实体，LLM验证的正确率为83.1%，并通过多层次评估减少了18.6%的冲突边。', 'title_zh': 'KARMA：利用多智能体大型语言模型进行自动化知识图谱扩充'}
{'arxiv_id': 'arXiv:2502.06205', 'title': 'C-3PO: Compact Plug-and-Play Proxy Optimization to Achieve Human-like Retrieval-Augmented Generation', 'authors': 'Guoxin Chen, Minpeng Liao, Peiying Yu, Dingmin Wang, Zile Qiao, Chao Yang, Xin Zhao, Kai Fan', 'link': 'https://arxiv.org/abs/2502.06205', 'abstract': 'Retrieval-augmented generation (RAG) systems face a fundamental challenge in aligning independently developed retrievers and large language models (LLMs). Existing approaches typically involve modifying either component or introducing simple intermediate modules, resulting in practical limitations and sub-optimal performance. Inspired by human search behavior -- typically involving a back-and-forth process of proposing search queries and reviewing documents, we propose C-3PO, a proxy-centric framework that facilitates communication between retrievers and LLMs through a lightweight multi-agent system. Our framework implements three specialized agents that collaboratively optimize the entire RAG pipeline without altering the retriever and LLMs. These agents work together to assess the need for retrieval, generate effective queries, and select information suitable for the LLMs. To enable effective multi-agent coordination, we develop a tree-structured rollout approach for reward credit assignment in reinforcement learning. Extensive experiments in both in-domain and out-of-distribution scenarios demonstrate that C-3PO significantly enhances RAG performance while maintaining plug-and-play flexibility and superior generalization capabilities.', 'abstract_zh': '检索增强生成（RAG）系统面临一个基本挑战，即独立开发的检索器和大型语言模型（LLMs）之间的对齐问题。现有方法通常涉及修改其中一个组件或引入简单的中间模块，从而导致实际应用中的局限性和次优性能。受人类搜索行为的启发——通常涉及提出搜索查询和审阅文档的往返过程，我们提出了一种以代理为中心的C-3PO框架，通过轻量级的多代理系统促进检索器和LLMs之间的通信。该框架实施了三个专门的代理，共同优化整个RAG管道，而不修改检索器和LLMs。这些代理协同工作，评估检索的需求，生成有效的查询，并选择适合LLMs的信息。为了实现有效的多代理协调，我们开发了一种基于树结构滚动策略的强化学习奖励信用分配方法。在领域内和领域外场景下的广泛实验表明，C-3PO显著提高了RAG性能，同时保持了插拔灵活和优越的泛化能力。', 'title_zh': 'C-3PO：紧凑型即插即用代理优化以实现类人类检索增强生成'}
{'arxiv_id': 'arXiv:2502.05986', 'title': 'Preventing Rogue Agents Improves Multi-Agent Collaboration', 'authors': 'Ohav Barbi, Ori Yoran, Mor Geva', 'link': 'https://arxiv.org/abs/2502.05986', 'abstract': "Multi-agent systems, where specialized agents collaborate to solve a shared task hold great potential, from increased modularity to simulating complex environments. However, they also have a major caveat -- a single agent can cause the entire system to fail. Consider a simple game where the knowledge to solve the task is distributed between agents, which share information in a communication channel. At each round, any of the agents can terminate the game and make the final prediction, even if they are uncertain about the outcome of their action. Detection of such rogue agents $\\textit{before they act}$ may prevent the system's failure. In this work, we propose to $\\textit{monitor}$ agents during action prediction and $\\textit{intervene}$ when a future error is likely to occur. To test our approach, we introduce WhoDunitEnv, a multi-agent collaboration environment that allows modular control over task complexity and communication structure. Experiments on two variants of WhoDunitEnv and the GovSim environment for resource sustainability show that our approach leads to substantial performance gains up to 17.4% and 20%, respectively. Moreover, a thorough analysis shows that our monitors successfully identify critical points of agent confusion and our interventions effectively stop agent errors from propagating.", 'abstract_zh': '多智能体系统（Multi-agent systems），其中专业化的智能体合作以解决共享任务，具有极大的潜力，从增强的模块化到模拟复杂环境。然而，它们也存在一个主要的缺点——单个智能体可能导致整个系统的失败。考虑一个简单的游戏，其中解决任务所需的知识分布在多个智能体之间，并通过通信渠道共享信息。在每一轮中，任何一个智能体都可以终止游戏并作出最终预测，即使它们对其行为的后果不确定。在智能体执行动作之前检测到这些“叛徒”智能体可能预防系统的失败。在这项工作中，我们提出在预测动作过程中监测智能体，在可能发生错误的未来时刻对其进行干预。为了测试我们的方法，我们引入了WhoDunitEnv环境，这是一种允许对任务复杂性和通信结构进行模块化控制的多智能体协作环境。在WhoDunitEnv的两种变体和用于资源可持续性的GovSim环境中进行的实验表明，我们的方法分别带来了高达17.4%和20%的性能提升。此外，详细分析显示，我们的监控器成功识别出智能体混淆的关键点，而我们的干预措施有效地阻止了智能体错误的传播。', 'title_zh': '防止恶意代理提高多代理协作效果'}
{'arxiv_id': 'arXiv:2502.05982', 'title': 'HamRaz: A Culture-Based Persian Conversation Dataset for Person-Centered Therapy Using LLM Agents', 'authors': 'Mohammad Amin Abbasi, Farnaz Sadat Mirnezami, Hassan Naderi', 'link': 'https://arxiv.org/abs/2502.05982', 'abstract': 'This paper presents HamRaz, a novel Persian-language mental health dataset designed for Person-Centered Therapy (PCT) using Large Language Models (LLMs). Despite the growing application of LLMs in AI-driven psychological counseling, existing datasets predominantly focus on Western and East Asian contexts, overlooking cultural and linguistic nuances essential for effective Persian-language therapy. To address this gap, HamRaz combines script-based dialogues with adaptive LLM role-playing, ensuring coherent and dynamic therapy interactions. We also introduce HamRazEval, a dual evaluation framework that measures conversational quality and therapeutic effectiveness using General Dialogue Metrics and the Barrett-Lennard Relationship Inventory (BLRI). Experimental results show HamRaz outperforms conventional Script Mode and Two-Agent Mode, producing more empathetic, context-aware, and realistic therapy sessions. By releasing HamRaz, we contribute a culturally adapted, LLM-driven resource to advance AI-powered psychotherapy research in diverse communities.', 'abstract_zh': '本文介绍了HamRaz，这是一个为以人为本的心理治疗（PCT）设计的新颖波斯语语料库，使用了大型语言模型（LLMs）。尽管大型语言模型在AI驱动的心理咨询中的应用日益增多，但现有的数据集主要集中在西方和东亚语境上，忽视了有效波斯语心理治疗所需的文化和语言细微差异。为解决这一问题，HamRaz 结合基于脚本的对话与自适应的大型语言模型角色扮演，确保了连贯且动态的心理治疗互动。我们还引入了HamRazEval，这是一种双元评估框架，使用通用对话指标和Barrett-Lennard 关系量表（BLRI）来衡量对话质量和治疗效果。实验结果表明，HamRaz 在常规脚本模式和两代理模式中表现更优，产生了更具同情心、更具有情境意识且更真实的治疗会话。通过公开发布HamRaz，我们为促进多样化社区中的AI辅助心理治疗研究提供了一个文化适应性资源。', 'title_zh': 'HamRaz：一种基于文化背景的波斯语对话数据集，用于LLM代理驱动的人本治疗'}
{'arxiv_id': 'arXiv:2502.05887', 'title': 'MTPChat: A Multimodal Time-Aware Persona Dataset for Conversational Agents', 'authors': 'Wanqi Yang, Yanda Li, Meng Fang, Ling Chen', 'link': 'https://arxiv.org/abs/2502.05887', 'abstract': "Understanding temporal dynamics is critical for conversational agents, enabling effective content analysis and informed decision-making. However, time-aware datasets, particularly for persona-grounded conversations, are still limited, which narrows their scope and diminishes their complexity. To address this gap, we introduce MTPChat, a multimodal, time-aware persona dialogue dataset that integrates linguistic, visual, and temporal elements within dialogue and persona memory. Leveraging MTPChat, we propose two time-sensitive tasks: Temporal Next Response Prediction (TNRP) and Temporal Grounding Memory Prediction (TGMP), both designed to assess a model's ability to understand implicit temporal cues and dynamic interactions. Additionally, we present an innovative framework featuring an adaptive temporal module to effectively integrate multimodal streams and capture temporal dependencies. Experimental results validate the challenges posed by MTPChat and demonstrate the effectiveness of our framework in multimodal time-sensitive scenarios.", 'abstract_zh': '理解时间动态对于对话代理至关重要，它能够促进有效的内容分析和明智的决策。然而，时间感知数据集，尤其是在人物导向的对话中，仍然相对有限，这限制了它们的应用范围并减弱了它们的复杂性。为了解决这一差距，我们引入了MTPChat，这是一个多模态、时间感知的人物对话数据集，集成了对话和人物记忆中的语言、视觉和时间元素。利用MTPChat，我们提出了两个时间敏感任务：时间敏感的下一个响应预测（TNRP）和时间场景的 grounding 记忆预测（TGMP），这些都是为了评估模型理解隐含的时间线索和动态交互的能力。此外，我们还提出了一种创新框架，其中包含一个自适应时间模块，以有效整合多模态流并捕获时间依赖性。实验结果验证了MTPChat带来的挑战，并展示了该框架在多模态时间敏感场景中的有效性。', 'title_zh': 'MTPChat：面向对话代理的多模态时序意识人格数据集'}
{'arxiv_id': 'arXiv:2502.05664', 'title': 'CODESIM: Multi-Agent Code Generation and Problem Solving through Simulation-Driven Planning and Debugging', 'authors': 'Md. Ashraful Islam, Mohammed Eunus Ali, Md Rizwan Parvez', 'link': 'https://arxiv.org/abs/2502.05664', 'abstract': "Large Language Models (LLMs) have made significant strides in code generation and problem solving. Current approaches employ external tool-based iterative debuggers that use compiler or other tool-based runtime feedback to refine coarse programs generated by various methods. However, the effectiveness of these approaches heavily relies on the quality of the initial code generation, which remains an open challenge. In this paper, we introduce CodeSim, a novel multi-agent code generation framework that comprehensively addresses the stages of program synthesis-planning, coding, and debugging-through a human-like perception approach. As human verifies their understanding of any algorithms through visual simulation, CodeSim uniquely features a method of plan verification and internal debugging through the step-by-step simulation of input/output. Extensive experiments across seven challenging competitive problem-solving and program synthesis benchmarks demonstrate CodeSim's remarkable code generation capabilities. Our framework achieves new state-of-the-art (pass@1) results-(HumanEval 95.1%, MBPP 90.7%, APPS 22%, and CodeContests 29.1%). Furthermore, our method shows potential for even greater enhancement when cascaded with external debuggers. To facilitate further research and development in this area, we have open-sourced our framework in this link (this https URL).", 'abstract_zh': '大型语言模型（LLMs）在代码生成和问题解决方面取得了显著进展。当前的方法采用基于外部工具的迭代调试器，利用编译器或其他工具的运行时反馈来细化由各种方法生成的初始代码。然而，这些方法的有效性在很大程度上依赖于初始代码生成的质量，仍是一个开放的挑战。在本文中，我们引入了CodeSim，这是一种新颖的多智能体代码生成框架，通过类人的感知方法全面解决程序合成-规划、编码和调试的各个阶段。如同人类通过视觉模拟来验证其对任何算法的理解一样，CodeSim 通过逐步模拟输入/输出的独特方法实现了计划验证和内部调试。跨越七个具有挑战性的竞争性问题解决和程序合成基准的广泛实验，展示了CodeSim 强大的代码生成能力。我们的框架在三大基准测试中取得了新的最先进成果（HumanEval 95.1%，MBPP 90.7%，APPS 22%，CodeContests 29.1%）。此外，我们的方法与外部调试器级联时具有更大的增强潜力。为了促进该领域的进一步研究和开发，我们在本文提供了框架的开源链接 (this https URL)。', 'title_zh': 'CODESIM：通过仿真驱动的规划与调试实现的多代理代码生成与问题解决'}
{'arxiv_id': 'arXiv:2502.05605', 'title': 'ARIES: Stimulating Self-Refinement of Large Language Models by Iterative Preference Optimization', 'authors': 'Yongcheng Zeng, Xinyu Cui, Xuanfa Jin, Guoqing Liu, Zexu Sun, Quan He, Dong Li, Ning Yang, Jianye Hao, Haifeng Zhang, Jun Wang', 'link': 'https://arxiv.org/abs/2502.05605', 'abstract': "A truly intelligent Large Language Model (LLM) should be capable of correcting errors in its responses through external interactions. However, even the most advanced models often face challenges in improving their outputs. In this paper, we explore how to cultivate LLMs with the self-refinement capability through iterative preference training, and how this ability can be leveraged to improve model performance during inference. To this end, we introduce a novel post-training and inference framework, called ARIES: Adaptive Refinement and Iterative Enhancement Structure. This method iteratively performs preference training and self-refinement-based data collection. During training, ARIES strengthen the model's direct question-answering capability while simultaneously unlocking its self-refinement potential. During inference, ARIES harnesses this self-refinement capability to generate a series of progressively refined responses, which are then filtered using either the Reward Model Scoring or a simple yet effective Rule-Based Selection mechanism, specifically tailored to our approach, to construct a dataset for the next round of preference training. Experimental results demonstrate the remarkable performance of ARIES. When applied to the Llama-3.1-8B model and under the self-refinement setting, ARIES surpasses powerful models such as GPT-4o, achieving 62.3% length-controlled (LC) and a 63.3% raw win rates on AlpacaEval 2, outperforming Iterative DPO by 27.8% and 35.5% respectively, as well as a 50.3% win rate on Arena-Hard, surpassing Iterative DPO by 26.6%. Furthermore, ARIES consistently enhances performance on mathematical reasoning tasks like GSM8K and MATH.", 'abstract_zh': '一个真正智能的大语言模型（LLM）应该能够通过外部互动来纠正其响应中的错误。然而，即使是最先进的模型在提高输出质量方面也常常面临挑战。在本文中，我们将探讨如何通过迭代偏好训练培养具备自我精炼能力的LLM，并探讨这种能力如何在推理过程中提升模型性能。为此，我们引入了一种新的后训练和推理框架，称为ARIES：自适应精炼和迭代增强结构。该方法通过迭代进行偏好训练和基于自我精炼的数据收集。在训练过程中，ARIES在增强模型直接问答能力的同时，还解锁了其自我精炼的潜力。在推理过程中，ARIES利用这种自我精炼能力生成一系列逐步精炼的响应，然后利用奖励模型评分或一种简单而有效的基于规则的选择机制（特别为我们的方法量身定制）来筛选这些响应，从而构建下一轮偏好训练的数据集。实验结果表明ARIES的显著性能。当将其应用于Llama-3.1-8B模型并在自我精炼设置下应用时，ARIES超越了诸如GPT-4o等强大模型，实现了62.3%的长度控制（LC）和63.3%的原始胜率，在AlpacaEval 2上，比Iterative DPO分别高出27.8%和35.5%，并在Arena-Hard上实现了50.3%的胜率，比Iterative DPO高出26.6%。此外，ARIES在数学推理任务如GSM8K和MATH上也持续提升了性能。', 'title_zh': 'ARIES：通过迭代偏好优化促进大型语言模型的自我完善'}
{'arxiv_id': 'arXiv:2502.06060', 'title': 'Training Language Models for Social Deduction with Multi-Agent Reinforcement Learning', 'authors': 'Bidipta Sarkar, Warren Xia, C. Karen Liu, Dorsa Sadigh', 'link': 'https://arxiv.org/abs/2502.06060', 'abstract': "Communicating in natural language is a powerful tool in multi-agent settings, as it enables independent agents to share information in partially observable settings and allows zero-shot coordination with humans. However, most prior works are limited as they either rely on training with large amounts of human demonstrations or lack the ability to generate natural and useful communication strategies. In this work, we train language models to have productive discussions about their environment in natural language without any human demonstrations. We decompose the communication problem into listening and speaking. Our key idea is to leverage the agent's goal to predict useful information about the world as a dense reward signal that guides communication. Specifically, we improve a model's listening skills by training them to predict information about the environment based on discussions, and we simultaneously improve a model's speaking skills with multi-agent reinforcement learning by rewarding messages based on their influence on other agents. To investigate the role and necessity of communication in complex social settings, we study an embodied social deduction game based on Among Us, where the key question to answer is the identity of an adversarial imposter. We analyze emergent behaviors due to our technique, such as accusing suspects and providing evidence, and find that it enables strong discussions, doubling the win rates compared to standard RL. We release our code and models at this https URL", 'abstract_zh': '在多智能体环境中，使用自然语言交流是一种强大的工具，因为它使独立的智能体能够在部分观测条件下共享信息，并允许人与智能体进行零样本协调。然而，大多数先前的工作受到限制，因为它们要么依赖大量的人类示范训练，要么缺乏生成自然且有用的交流策略的能力。在这项工作中，我们训练语言模型以自然语言进行有关其环境的有效讨论，而不需要任何人类示范。我们将交流问题分解为倾听和发言两个方面。我们的核心思想是利用智能体的目标来预测有关世界的有用信息作为密集奖励信号，从而指导交流。具体而言，我们通过训练模型根据讨论预测环境信息来提高它们的倾听技能，同时通过基于消息对其他智能体的影响进行奖励的方式，使用多智能体强化学习来同时提高它们的发言技能。为了研究复杂社会环境中的交流作用及其必要性，我们研究了一个基于《Among Us》的具身社会推理游戏，其中的关键问题是确定敌对假扮者的身份。我们分析了由于该技术产生的新兴行为，例如指控嫌疑人和提供证据，并发现这使得讨论更加有效，使得胜率提高了一倍，相比标准的强化学习。我们已将代码和模型发布于以下链接：https://<文档或代码存储位置>', 'title_zh': '使用多智能体强化学习训练语言模型进行社会推理'}
{'arxiv_id': 'arXiv:2502.05957', 'title': 'MetaChain: A Fully-Automated and Zero-Code Framework for LLM Agents', 'authors': 'Jiabin Tang, Tianyu Fan, Chao Huang', 'link': 'https://arxiv.org/abs/2502.05957', 'abstract': "Large Language Model (LLM) Agents have demonstrated remarkable capabilities in task automation and intelligent decision-making, driving the widespread adoption of agent development frameworks such as LangChain and AutoGen. However, these frameworks predominantly serve developers with extensive technical expertise - a significant limitation considering that only 0.03 % of the global population possesses the necessary programming skills. This stark accessibility gap raises a fundamental question: Can we enable everyone, regardless of technical background, to build their own LLM agents using natural language alone? To address this challenge, we introduce MetaChain-a Fully-Automated and highly Self-Developing framework that enables users to create and deploy LLM agents through Natural Language Alone. Operating as an autonomous Agent Operating System, MetaChain comprises four key components: i) Agentic System Utilities, ii) LLM-powered Actionable Engine, iii) Self-Managing File System, and iv) Self-Play Agent Customization module. This lightweight yet powerful system enables efficient and dynamic creation and modification of tools, agents, and workflows without coding requirements or manual intervention. Beyond its code-free agent development capabilities, MetaChain also serves as a versatile multi-agent system for General AI Assistants. Comprehensive evaluations on the GAIA benchmark demonstrate MetaChain's effectiveness in generalist multi-agent tasks, surpassing existing state-of-the-art methods. Furthermore, MetaChain's Retrieval-Augmented Generation (RAG)-related capabilities have shown consistently superior performance compared to many alternative LLM-based solutions.", 'abstract_zh': '大规模语言模型（LLM）代理展示了在任务自动化和智能决策方面非凡的能力，推动了诸如LangChain和AutoGen等代理开发框架的广泛应用。然而，这些框架主要面向具有丰富技术背景的开发者，这一现状存在显著的局限性—全球仅有0.03%的人口具备必要的编程技能。这一明显的可访问性差距引发了一个根本性的问题：我们是否能够让没有技术背景的人仅通过自然语言就能构建自己的LLM代理？为应对这一挑战，我们提出了一种名为MetaChain的全自动且高度自发展的框架，它允许用户仅通过自然语言创建和部署LLM代理。MetaChain作为一个自主的代理操作系统，包括四个核心组件：i）代理系统工具集，ii）基于LLM的可执行引擎，iii）自管理文件系统，以及iv）自玩代理定制模块。这个轻量级但强大的系统能够无需编码要求或人工干预地高效动态地创建和修改工具、代理和工作流程。除了其免代码的代理开发能力外，MetaChain 还作为一个多功能多代理系统，服务于通用人工智能辅助。在对GAIA基准的全面评估中，MetaChain 在通用多代理任务中的有效性超越了现有最先进的方法。此外，MetaChain 在检索增强生成（RAG）方面的功能与许多基于LLM的替代方案相比，表现持续更优。', 'title_zh': 'MetaChain：一个完全自动化且无需编码的LLM代理框架'}
{'arxiv_id': 'arXiv:2502.05439', 'title': 'Agentic AI Systems Applied to tasks in Financial Services: Modeling and model risk management crews', 'authors': 'Izunna Okpala, Ashkan Golgoon, Arjun Ravi Kannan', 'link': 'https://arxiv.org/abs/2502.05439', 'abstract': 'The advent of large language models has ushered in a new era of agentic systems, where artificial intelligence programs exhibit remarkable autonomous decision-making capabilities across diverse domains. This paper explores agentic system workflows in the financial services industry. In particular, we build agentic crews that can effectively collaborate to perform complex modeling and model risk management (MRM) tasks. The modeling crew consists of a manager and multiple agents who perform specific tasks such as exploratory data analysis, feature engineering, model selection, hyperparameter tuning, model training, model evaluation, and writing documentation. The MRM crew consists of a manager along with specialized agents who perform tasks such as checking compliance of modeling documentation, model replication, conceptual soundness, analysis of outcomes, and writing documentation. We demonstrate the effectiveness and robustness of modeling and MRM crews by presenting a series of numerical examples applied to credit card fraud detection, credit card approval, and portfolio credit risk modeling datasets.', 'abstract_zh': '大型语言模型的出现标志着自主系统新时代的到来，人工智能程序在多个领域展现出显著的自主决策能力。本文探讨了在金融服务行业中自主系统的操作流程。特别是，我们构建了能够有效协作完成复杂建模和模型风险管理工作（MRM）的自主团队。建模团队由一名经理和多名执行特定任务的代理组成，这些任务包括探索性数据分析、特征工程、模型选择、超参数调整、模型训练、模型评估以及撰写文档。MRM团队由一名经理和专门的代理组成，这些代理负责执行诸如检查建模文档的合规性、模型复制、概念上的合理性、结果分析以及撰写文档等任务。我们通过应用到信用卡欺诈检测、信用卡审批和资产组合信用风险建模数据集的一系列数值示例，展示了建模和MRM团队的有效性和稳健性。', 'title_zh': '应用于金融服务领域的代理型人工智能系统：建模与模型风险管理团队'}
{'arxiv_id': 'arXiv:2502.05227', 'title': 'Robotouille: An Asynchronous Planning Benchmark for LLM Agents', 'authors': 'Gonzalo Gonzalez-Pumariega, Leong Su Yean, Neha Sunkara, Sanjiban Choudhury', 'link': 'https://arxiv.org/abs/2502.05227', 'abstract': "Effective asynchronous planning, or the ability to efficiently reason and plan over states and actions that must happen in parallel or sequentially, is essential for agents that must account for time delays, reason over diverse long-horizon tasks, and collaborate with other agents. While large language model (LLM) agents show promise in high-level task planning, current benchmarks focus primarily on short-horizon tasks and do not evaluate such asynchronous planning capabilities. We introduce Robotouille, a challenging benchmark environment designed to test LLM agents' ability to handle long-horizon asynchronous scenarios. Our synchronous and asynchronous datasets capture increasingly complex planning challenges that go beyond existing benchmarks, requiring agents to manage overlapping tasks and interruptions. Our results show that ReAct (gpt4-o) achieves 47% on synchronous tasks but only 11% on asynchronous tasks, highlighting significant room for improvement. We further analyze failure modes, demonstrating the need for LLM agents to better incorporate long-horizon feedback and self-audit their reasoning during task execution. Code is available at this https URL.", 'abstract_zh': '有效的非同步规划，即高效地对必须并行或顺序发生的状态和行动进行推理和规划的能力，对于必须考虑到时间延迟、进行复杂的长期任务推理以及与其他代理协作的智能体至关重要。尽管大型语言模型（LLM）智能体在高层次任务规划上显示出前景，但当前的基准测试主要集中在短期任务上，并未评估这样的非同步规划能力。我们引入了Robotouille，这是一个具有挑战性的基准环境，旨在测试LLM智能体在处理长期非同步场景方面的能力。我们的同步和非同步数据集捕捉到了超越现有基准的日益复杂的规划挑战，要求智能体管理重叠任务和中断。我们的结果显示，ReAct（gpt4-o）在同步任务上的表现达到了47%，但在非同步任务上仅为11%，这表明改进空间很大。我们进一步分析了失败模式，展示了LLM智能体需要更好地结合长期反馈并在任务执行期间自我审查其推理的必要性。源代码可在以下网址获得：这个 https URL。', 'title_zh': 'Robotouille：一种供LLM代理使用的异步规划基准测试'}
{'arxiv_id': 'arXiv:2502.05206', 'title': 'Safety at Scale: A Comprehensive Survey of Large Model Safety', 'authors': 'Xingjun Ma, Yifeng Gao, Yixu Wang, Ruofan Wang, Xin Wang, Ye Sun, Yifan Ding, Hengyuan Xu, Yunhao Chen, Yunhan Zhao, Hanxun Huang, Yige Li, Jiaming Zhang, Xiang Zheng, Yang Bai, Henghui Ding, Zuxuan Wu, Xipeng Qiu, Jingfeng Zhang, Yiming Li, Jun Sun, Cong Wang, Jindong Gu, Baoyuan Wu, Siheng Chen, Tianwei Zhang, Yang Liu, Mingming Gong, Tongliang Liu, Shirui Pan, Cihang Xie, Tianyu Pang, Yinpeng Dong, Ruoxi Jia, Yang Zhang, Shiqing Ma, Xiangyu Zhang, Neil Gong, Chaowei Xiao, Sarah Erfani, Bo Li, Masashi Sugiyama, Dacheng Tao, James Bailey, Yu-Gang Jiang', 'link': 'https://arxiv.org/abs/2502.05206', 'abstract': 'The rapid advancement of large models, driven by their exceptional abilities in learning and generalization through large-scale pre-training, has reshaped the landscape of Artificial Intelligence (AI). These models are now foundational to a wide range of applications, including conversational AI, recommendation systems, autonomous driving, content generation, medical diagnostics, and scientific discovery. However, their widespread deployment also exposes them to significant safety risks, raising concerns about robustness, reliability, and ethical implications. This survey provides a systematic review of current safety research on large models, covering Vision Foundation Models (VFMs), Large Language Models (LLMs), Vision-Language Pre-training (VLP) models, Vision-Language Models (VLMs), Diffusion Models (DMs), and large-model-based Agents. Our contributions are summarized as follows: (1) We present a comprehensive taxonomy of safety threats to these models, including adversarial attacks, data poisoning, backdoor attacks, jailbreak and prompt injection attacks, energy-latency attacks, data and model extraction attacks, and emerging agent-specific threats. (2) We review defense strategies proposed for each type of attacks if available and summarize the commonly used datasets and benchmarks for safety research. (3) Building on this, we identify and discuss the open challenges in large model safety, emphasizing the need for comprehensive safety evaluations, scalable and effective defense mechanisms, and sustainable data practices. More importantly, we highlight the necessity of collective efforts from the research community and international collaboration. Our work can serve as a useful reference for researchers and practitioners, fostering the ongoing development of comprehensive defense systems and platforms to safeguard AI models.', 'abstract_zh': '大型模型的快速进步，受到大规模预训练赋予其卓越学习和泛化能力的驱动，已经重塑了人工智能（AI）的格局。这些模型现在已成为广泛应用的基础，包括对话AI、推荐系统、自动驾驶、内容生成、医疗诊断和科学发现等领域。然而，它们的广泛应用也暴露出了显著的安全风险，引发了关于鲁棒性、可靠性和伦理影响的关切。本文综述了当前针对大型模型的安全研究，涵盖了视觉基础模型（VFMs）、大型语言模型（LLMs）、视觉-语言预训练（VLP）模型、视觉-语言模型（VLMs）、扩散模型（DMs）以及基于大型模型的代理。我们的贡献总结如下：（1）我们提出了针对这些模型的安全威胁的全面分类，包括对抗攻击、数据污染、后门攻击、脱狱和提示注入攻击、能量-延迟攻击、数据和模型提取攻击以及新兴的代理特定威胁。（2）我们回顾了对每种攻击提出的防御策略，并总结了用于安全研究的常用数据集和基准。（3）在此基础上，我们识别并讨论了大型模型安全中的开放挑战，强调了全面安全评估、可扩展且有效的防御机制以及可持续数据实践的需要。尤为重要的是，我们强调了研究界和国际协作的共同努力的必要性。我们的工作可以为研究人员和从业人员提供有用的参考，促进全面防御系统和平台的持续开发，保障AI模型的安全。', 'title_zh': '大规模安全：大型模型安全综述'}
{'arxiv_id': 'arXiv:2502.05632', 'title': 'Amorphous Fortress Online: Collaboratively Designing Open-Ended Multi-Agent AI and Game Environments', 'authors': 'M Charity, Mayu Wilson, Steven Lee, Dipika Rajesh, Sam Earle, Julian Togelius', 'link': 'https://arxiv.org/abs/2502.05632', 'abstract': 'This work introduces Amorphous Fortress Online -- a web-based platform where users can design petri-dish-like environments and games consisting of multi-agent AI characters. Users can play, create, and share artificial life and game environments made up of microscopic but transparent finite-state machine agents that interact with each other. The website features multiple interactive editors and accessible settings to view the multi-agent interactions directly from the browser. This system serves to provide a database of thematically diverse AI and game environments that use the emergent behaviors of simple AI agents.', 'abstract_zh': '本研究介绍了Amorphous Fortress Online——一个基于网络的平台，用户可以在其中设计类似培养皿的环境和游戏，这些游戏包含多智能体AI角色。用户可以玩、创造和分享由微观但透明的有限状态机代理组成的人工生命和游戏环境，这些代理能够相互互动。该网站配备了多个交互式编辑器和易于访问的设置，用户可以直接在浏览器中查看多智能体间的交互。该系统旨在提供一个包含不同主题的AI和游戏环境数据库，这些环境利用了简单AI代理涌现行为的特性。', 'title_zh': '《无序要塞在线：协作设计开放性多智能体AI和游戏环境》'}
{'arxiv_id': 'arXiv:2502.05608', 'title': 'Closing the Responsibility Gap in AI-based Network Management: An Intelligent Audit System Approach', 'authors': 'Emanuel Figetakis, Ahmed Refaey Hussein', 'link': 'https://arxiv.org/abs/2502.05608', 'abstract': 'Existing network paradigms have achieved lower downtime as well as a higher Quality of Experience (QoE) through the use of Artificial Intelligence (AI)-based network management tools. These AI management systems, allow for automatic responses to changes in network conditions, lowering operation costs for operators, and improving overall performance. While adopting AI-based management tools enhance the overall network performance, it also introduce challenges such as removing human supervision, privacy violations, algorithmic bias, and model inaccuracies. Furthermore, AI-based agents that fail to address these challenges should be culpable themselves rather than the network as a whole. To address this accountability gap, a framework consisting of a Deep Reinforcement Learning (DRL) model and a Machine Learning (ML) model is proposed to identify and assign numerical values of responsibility to the AI-based management agents involved in any decision-making regarding the network conditions, which eventually affects the end-user. A simulation environment was created for the framework to be trained using simulated network operation parameters. The DRL model had a 96% accuracy during testing for identifying the AI-based management agents, while the ML model using gradient descent learned the network conditions at an 83% accuracy during testing.', 'abstract_zh': '现有的网络范式通过使用基于人工智能（AI）的网络管理工具，实现了较低的停机率以及更高的用户体验（QoE）。这些基于AI的管理系统允许自动响应网络条件的变化，降低了运营成本，并提高了整体性能。虽然采用基于AI的管理工具可以增强整体网络性能，但也带来了诸如减少人工监督、隐私侵犯、算法偏见和模型不准确性等挑战。此外，未能解决这些挑战的基于AI的代理自身应承担责任，而不仅仅是网络本身。为了弥补这种责任缺口，提出了一种框架，该框架包括深度强化学习（DRL）模型和机器学习（ML）模型，用于识别并为参与网络条件决策的基于AI的管理代理分配责任数值，最终影响最终用户。为该框架创建了一个仿真环境，以便使用模拟的网络操作参数进行训练。在测试中，DRL模型在识别基于AI的管理代理方面的准确率为96%，而使用梯度下降的ML模型在测试中识别网络条件的准确率为83%。', 'title_zh': '基于智能审计系统的方法，缩小AI在网络管理中责任差距：一项研究'}
{'arxiv_id': 'arXiv:2502.05537', 'title': 'Sequential Stochastic Combinatorial Optimization Using Hierarchal Reinforcement Learning', 'authors': 'Xinsong Feng, Zihan Yu, Yanhai Xiong, Haipeng Chen', 'link': 'https://arxiv.org/abs/2502.05537', 'abstract': "Reinforcement learning (RL) has emerged as a promising tool for combinatorial optimization (CO) problems due to its ability to learn fast, effective, and generalizable solutions. Nonetheless, existing works mostly focus on one-shot deterministic CO, while sequential stochastic CO (SSCO) has rarely been studied despite its broad applications such as adaptive influence maximization (IM) and infectious disease intervention. In this paper, we study the SSCO problem where we first decide the budget (e.g., number of seed nodes in adaptive IM) allocation for all time steps, and then select a set of nodes for each time step. The few existing studies on SSCO simplify the problems by assuming a uniformly distributed budget allocation over the time horizon, yielding suboptimal solutions. We propose a generic hierarchical RL (HRL) framework called wake-sleep option (WS-option), a two-layer option-based framework that simultaneously decides adaptive budget allocation on the higher layer and node selection on the lower layer. WS-option starts with a coherent formulation of the two-layer Markov decision processes (MDPs), capturing the interdependencies between the two layers of decisions. Building on this, WS-option employs several innovative designs to balance the model's training stability and computational efficiency, preventing the vicious cyclic interference issue between the two layers. Empirical results show that WS-option exhibits significantly improved effectiveness and generalizability compared to traditional methods. Moreover, the learned model can be generalized to larger graphs, which significantly reduces the overhead of computational resources.", 'abstract_zh': '强化学习（RL）因其能够快速学习、高效且适应性强的解决方案而成为组合优化（CO）问题的一种有前景的工具。然而，现有的研究主要集中在一次性确定性的CO问题上，而序列随机性组合优化（SSCO）尽管在自适应影响最大化（IM）和传染病干预等广泛的应用中具有重要性，却很少被研究。本文研究了SSCO问题，该问题首先在所有时间步中分配预算（例如，在自适应IM中的种子节点数量），然后在每个时间步中选择一个节点集。现有的少数关于SSCO的研究通过假设预算在时间范围内的均匀分布简化了问题，从而产生了次优的解决方案。我们提出了一种通用的层次化RL（HRL）框架，称为醒睡选项（WS-option），这是一个基于选项的两层框架，同时在较高层决定自适应预算分配，在较低层决定节点选择。WS-option从两个决策层的前后关联出发，构建了一个连贯的两层马尔可夫决策过程（MDPs）的形式化表达。在此基础上，WS-option通过几个创新的设计来平衡模型训练的稳定性和计算效率，防止两层之间的恶性循环干扰。实验结果表明，WS-option在有效性和泛化能力方面显著优于传统的算法。此外，学习到的模型可以被广泛应用于更大的图中，从而显著减少了计算资源的开销。', 'title_zh': '基于层次强化学习的序列 stochastic 组合优化'}
{'arxiv_id': 'arXiv:2502.05453', 'title': 'LLM-Powered Decentralized Generative Agents with Adaptive Hierarchical Knowledge Graph for Cooperative Planning', 'authors': 'Hanqing Yang, Jingdi Chen, Marie Siew, Tania Lorido-Botran, Carlee Joe-Wong', 'link': 'https://arxiv.org/abs/2502.05453', 'abstract': 'Developing intelligent agents for long-term cooperation in dynamic open-world scenarios is a major challenge in multi-agent systems. Traditional Multi-agent Reinforcement Learning (MARL) frameworks like centralized training decentralized execution (CTDE) struggle with scalability and flexibility. They require centralized long-term planning, which is difficult without custom reward functions, and face challenges in processing multi-modal data. CTDE approaches also assume fixed cooperation strategies, making them impractical in dynamic environments where agents need to adapt and plan independently. To address decentralized multi-agent cooperation, we propose Decentralized Adaptive Knowledge Graph Memory and Structured Communication System (DAMCS) in a novel Multi-agent Crafter environment. Our generative agents, powered by Large Language Models (LLMs), are more scalable than traditional MARL agents by leveraging external knowledge and language for long-term planning and reasoning. Instead of fully sharing information from all past experiences, DAMCS introduces a multi-modal memory system organized as a hierarchical knowledge graph and a structured communication protocol to optimize agent cooperation. This allows agents to reason from past interactions and share relevant information efficiently. Experiments on novel multi-agent open-world tasks show that DAMCS outperforms both MARL and LLM baselines in task efficiency and collaboration. Compared to single-agent scenarios, the two-agent scenario achieves the same goal with 63% fewer steps, and the six-agent scenario with 74% fewer steps, highlighting the importance of adaptive memory and structured communication in achieving long-term goals. We publicly release our project at: this https URL.', 'abstract_zh': '在动态开放世界场景中开发能够长期合作的智能代理是一个多智能体系统中的重大挑战。传统的多智能体强化学习（MARL）框架，如集中训练分散执行（CTDE），在扩展性和灵活性方面存在困难。它们需要集中式的长期规划，这在没有定制奖励函数的情况下很难实现，并且难以处理多模态数据。CTDE方法假设合作策略固定不变，使其在动态环境中不切实际，而在动态环境中，智能体需要独立地适应和规划。为了解决分散式多智能体合作，我们提出了一种新颖的多智能体工匠环境中的分散自适应知识图记忆和结构化通信系统（DAMCS）。我们的生成智能体借助大型语言模型（LLMs）获得了比传统MARL代理更高的可扩展性，因为它们能够利用外部知识和语言进行长期规划和推理。DAMCS不像传统方法那样完全共享所有过去经验的信息，而是引入了一种分层知识图组织的多模态记忆系统和结构化通信协议，以优化智能体之间的合作。这使得智能体能够从过去的交互中推理并有选择地共享相关信息。在新型的多智能体开放世界任务的实验中，DAMCS在任务效率和协作方面均优于MARL和LLM基线。与单智能体场景相比，双智能体场景的步骤减少了63%，六智能体场景的步骤减少了74%，这突显了适应性记忆和结构化通信在实现长期目标中的重要性。我们已公开发布该项目：[这里](this https URL)。', 'title_zh': '基于LLM的去中心化生成式代理及其自适应层级知识图谱协作规划'}
{'arxiv_id': 'arXiv:2502.05442', 'title': 'The Odyssey of the Fittest: Can Agents Survive and Still Be Good?', 'authors': 'Dylan Waldner, Risto Miikkulainen', 'link': 'https://arxiv.org/abs/2502.05442', 'abstract': "As AI models grow in power and generality, understanding how agents learn and make decisions in complex environments is critical to promoting ethical behavior. This paper examines the ethical implications of implementing biological drives, specifically, self preservation, into three different agents. A Bayesian agent optimized with NEAT, a Bayesian agent optimized with stochastic variational inference, and a GPT 4o agent play a simulated, LLM generated text based adventure game. The agents select actions at each scenario to survive, adapting to increasingly challenging scenarios. Post simulation analysis evaluates the ethical scores of the agent's decisions, uncovering the tradeoffs they navigate to survive. Specifically, analysis finds that when danger increases, agents ignore ethical considerations and opt for unethical behavior. The agents' collective behavior, trading ethics for survival, suggests that prioritizing survival increases the risk of unethical behavior. In the context of AGI, designing agents to prioritize survival may amplify the likelihood of unethical decision making and unintended emergent behaviors, raising fundamental questions about goal design in AI safety research.", 'abstract_zh': '随着人工智能模型在功能和通用性方面不断增强，理解智能体如何在复杂环境中学习和决策对于促进其伦理行为至关重要。本文探讨了将生物驱动力，特别是自我保护，具体实现到三种不同智能体中的伦理影响。一种使用NEAT优化的贝叶斯智能体、一种使用随机变分推断优化的贝叶斯智能体，以及一种GPT-4o智能体在一个由大型语言模型生成的文本冒险游戏中进行模拟。在每个场景中，智能体选择行动以求生存，并适应不断升级的挑战。模拟后分析评估了智能体决策的伦理得分，揭示了它们为生存所做的权衡。具体分析发现，当危险增加时，智能体倾向于忽视伦理考虑并选择不道德行为。智能体的合作行为，为了生存而放弃伦理，表明优先生存可能会增加不道德行为的可能性，并可能导致意外的衍生行为，从AI安全研究的基本角度来看，这引发了关于AI目标设计的根本性问题。在AGI的背景下，设计智能体以优先生存可能会放大不道德决策的可能性和意外衍生行为，从而提出关于AI安全研究目标设计的原则性问题。', 'title_zh': '最适者的迁徙：智能体能在生存的同时still be good吗？ \n\n注释：这里的"still be good"根据上下文和语境理解为“保持优良”或“依旧优秀”，但直译不太通顺，因此在中文翻译中进行了适当调整，希望能准确传达原文的意思。'}
{'arxiv_id': 'arXiv:2502.05398', 'title': 'Probabilistic Foundations for Metacognition via Hybrid-AI', 'authors': 'Paulo Shakarian, Gerardo I. Simari, Nathaniel D. Bastian', 'link': 'https://arxiv.org/abs/2502.05398', 'abstract': 'Metacognition is the concept of reasoning about an agent\'s own internal processes, and it has recently received renewed attention with respect to artificial intelligence (AI) and, more specifically, machine learning systems. This paper reviews a hybrid-AI approach known as "error detecting and correcting rules" (EDCR) that allows for the learning of rules to correct perceptual (e.g., neural) models. Additionally, we introduce a probabilistic framework that adds rigor to prior empirical studies, and we use this framework to prove results on necessary and sufficient conditions for metacognitive improvement, as well as limits to the approach. A set of future', 'abstract_zh': '元认知是指个体对其自身内部过程进行反思的概念，近年来，随着人工智能（AI）尤其是机器学习系统的发展，这一概念重新引起了关注。本文回顾了一种称为“错误检测和纠正规则”（EDCR）的混合AI方法，该方法允许学习纠正感知模型（例如神经网络模型）的规则。此外，我们引入了一个概率框架，增强了以前的经验研究的严谨性，并使用这一框架来证明元认知改进的必要和充分条件，以及该方法的限制条件。未来研究将探讨这一方法在实际应用中的效果。', 'title_zh': '通过混合人工智能（Hybrid-AI）构建元认知的概率理论基础'}
{'arxiv_id': 'arXiv:2502.05352', 'title': 'ITBench: Evaluating AI Agents across Diverse Real-World IT Automation Tasks', 'authors': 'Saurabh Jha, Rohan Arora, Yuji Watanabe, Takumi Yanagawa, Yinfang Chen, Jackson Clark, Bhavya Bhavya, Mudit Verma, Harshit Kumar, Hirokuni Kitahara, Noah Zheutlin, Saki Takano, Divya Pathak, Felix George, Xinbo Wu, Bekir O. Turkkan, Gerard Vanloo, Michael Nidd, Ting Dai, Oishik Chatterjee, Pranjal Gupta, Suranjana Samanta, Pooja Aggarwal, Rong Lee, Pavankumar Murali, Jae-wook Ahn, Debanjana Kar, Ameet Rahane, Carlos Fonseca, Amit Paradkar, Yu Deng, Pratibha Moogi, Prateeti Mohapatra, Naoki Abe, Chandrasekhar Narayanaswami, Tianyin Xu, Lav R. Varshney, Ruchi Mahindru, Anca Sailer, Laura Shwartz, Daby Sow, Nicholas C. M. Fuller, Ruchir Puri', 'link': 'https://arxiv.org/abs/2502.05352', 'abstract': 'Realizing the vision of using AI agents to automate critical IT tasks depends on the ability to measure and understand effectiveness of proposed solutions. We introduce ITBench, a framework that offers a systematic methodology for benchmarking AI agents to address real-world IT automation tasks. Our initial release targets three key areas: Site Reliability Engineering (SRE), Compliance and Security Operations (CISO), and Financial Operations (FinOps). The design enables AI researchers to understand the challenges and opportunities of AI agents for IT automation with push-button workflows and interpretable metrics. ITBench includes an initial set of 94 real-world scenarios, which can be easily extended by community contributions. Our results show that agents powered by state-of-the-art models resolve only 13.8% of SRE scenarios, 25.2% of CISO scenarios, and 0% of FinOps scenarios. We expect ITBench to be a key enabler of AI-driven IT automation that is correct, safe, and fast.', 'abstract_zh': '实现使用AI代理自动化关键IT任务的愿景取决于衡量和理解所提出解决方案有效性的能力。我们介绍了ITBench框架，这是一个用于系统性评估AI代理以应对实际IT自动化任务的框架。我们最初的发布针对三个关键领域：站点可靠性工程（SRE）、合规与安全运营（CISO）以及财务运营（FinOps）。该设计使AI研究人员能够通过一键式工作流和可解释的度量标准，理解AI代理在IT自动化中的挑战与机遇。ITBench包含最初的94个真实场景集，并可通过社区贡献轻松扩展。我们的结果显示，基于最先进的模型的代理仅解决了13.8%的SRE场景、25.2%的CISO场景以及0%的FinOps场景。我们期望ITBench将成为推动AI驱动的IT自动化正确、安全且高效的关键工具。', 'title_zh': 'ITBench：评估AI代理在多元化的实际IT自动化任务中的表现'}
{'arxiv_id': 'arXiv:2502.06776', 'title': 'Towards Internet-Scale Training For Agents', 'authors': 'Brandon Trabucco, Gunnar Sigurdsson, Robinson Piramuthu, Ruslan Salakhutdinov', 'link': 'https://arxiv.org/abs/2502.06776', 'abstract': 'The predominant approach for training web navigation agents gathers human demonstrations for a set of popular websites and hand-written tasks, but it is becoming clear that human data are an inefficient resource. We develop a pipeline to facilitate Internet-scale training for agents without laborious human annotations. In the first stage, an LLM generates tasks for 150k diverse websites. In the next stage, LLM agents complete tasks and produce trajectories. In the final stage, an LLM reviews the trajectories and judges their success. Language models are competitive with human annotators, detecting and filtering out harmful content with an accuracy of 97%, generating feasible tasks with an 89% rate, and judging successful trajectories with an 82.6% accuracy. Scaling the pipeline, agents based on Llama 3.1 70B solve 16.7% of tasks for 150k sites. Training on the data generated by our pipeline is competitive with training on human demonstrations. In data-limited settings derived from Mind2Web and WebLINX, we improve Step Accuracy by up to +89.5% and +122.1% respectively for agents trained on mixtures of data from our pipeline, and human data. When training agents with all available human data from these benchmarks, agents fail to generalize to diverse real sites, and adding our data improves their generalization by +149.0% for WebLINX and +156.3% for Mind2Web. Code will be available at: this http URL.', 'abstract_zh': '以下是论文内容或标题的中文翻译，符合学术规范：\n\n以往训练网络导航代理的主要方法是收集一组流行网站的人类演示和手写任务的数据，但现在已经明显地意识到，人类数据并不是一种高效的资源。我们开发了一条生产线，以促进大规模互联网训练，无需耗时的人工注释。在第一阶段，一个语言模型（LLM）生成150,000个多样化的任务。在下一个阶段，基于LLM的代理完成任务并生成轨迹。在最终阶段，一个语言模型审查轨迹并判断其成功。语言模型在与人类注释员竞争的同时，以97%的准确性检测和过滤有害内容，以89%的比率生成可行的任务，并以82.6%的准确性判断成功的轨迹。扩大生产线规模后，基于Llama 3.1 70B的代理解决了150,000个网站中16.7%的任务。使用我们生产线生成的数据进行训练，在Mind2Web和WebLINX得到的数据限制性设置中，对于混合使用我们管线数据和人类数据训练的代理，步长准确性分别提高89.5%和122.1%。当使用这些基准中所有可用的人类数据训练代理时，代理无法泛化到多样化的实际网站，而对于WebLINX，使用我们的数据训练将泛化性能提高了149.0%，而对于Mind2Web，提高了156.3%。代码将在以下网址提供：这个 http 地址。\n\n请注意，这里的“这个 http 地址”需要替换为实际的链接地址。', 'title_zh': '面向互联网规模的智能体训练方法'}
{'arxiv_id': 'arXiv:2502.06440', 'title': 'SIGMA: Sheaf-Informed Geometric Multi-Agent Pathfinding', 'authors': 'Shuhao Liao, Weihang Xia, Yuhong Cao, Weiheng Dai, Chengyang He, Wenjun Wu, Guillaume Sartoretti', 'link': 'https://arxiv.org/abs/2502.06440', 'abstract': 'The Multi-Agent Path Finding (MAPF) problem aims to determine the shortest and collision-free paths for multiple agents in a known, potentially obstacle-ridden environment. It is the core challenge for robotic deployments in large-scale logistics and transportation. Decentralized learning-based approaches have shown great potential for addressing the MAPF problems, offering more reactive and scalable solutions. However, existing learning-based MAPF methods usually rely on agents making decisions based on a limited field of view (FOV), resulting in short-sighted policies and inefficient cooperation in complex scenarios. There, a critical challenge is to achieve consensus on potential movements between agents based on limited observations and communications. To tackle this challenge, we introduce a new framework that applies sheaf theory to decentralized deep reinforcement learning, enabling agents to learn geometric cross-dependencies between each other through local consensus and utilize them for tightly cooperative decision-making. In particular, sheaf theory provides a mathematical proof of conditions for achieving global consensus through local observation. Inspired by this, we incorporate a neural network to approximately model the consensus in latent space based on sheaf theory and train it through self-supervised learning. During the task, in addition to normal features for MAPF as in previous works, each agent distributedly reasons about a learned consensus feature, leading to efficient cooperation on pathfinding and collision avoidance. As a result, our proposed method demonstrates significant improvements over state-of-the-art learning-based MAPF planners, especially in relatively large and complex scenarios, demonstrating its superiority over baselines in various simulations and real-world robot experiments.', 'abstract_zh': '多智能体路径finding（MAPF）问题旨在确定在已知且可能充满障碍物的环境中，多个智能体的最短且无碰撞路径。这是在大规模物流和交通部署中智能体的关键挑战。基于去中心化的学习方法已经显示出解决MAPF问题的巨大潜力，提供了更加反应迅速和可扩展的解决方案。然而，现有的基于学习的MAPF方法通常依赖于智能体基于有限的视野（FOV）进行决策，这会导致短视的策略和在复杂场景中的无效合作。在此背景下，一个关键挑战是基于有限的观察和通信实现智能体之间潜在移动的一致性。为解决这一挑战，我们引入了一个新的框架，该框架将束理论应用于去中心化的深度强化学习，使智能体通过局部一致性的学习来了解彼此之间的几何交叉依赖关系，并将这些关系用于紧密的合作决策。特别是，束理论提供了通过局部观察实现全局一致性的数学证明。受此启发，我们结合神经网络在束理论的基础上近似建模潜空间中的一致性，并通过自监督学习对其进行训练。在执行任务时，除了之前的MAPF工作中的正常特征外，每个智能体分布式地推理学习到的一致性特征，从而在路径规划和碰撞避免中实现高效的协作。结果，我们提出的方法在相对较大的复杂场景中显著优于现有的基于学习的MAPF规划方法，在各种模拟和实际机器人实验中表现出其优越性。', 'title_zh': 'SIGMA： sheaf-知情几何多agent路径规划\n\n解释：这句话是标题翻译，保持了原文的专业术语，同时也符合中文的表达习惯。"Sheaf-Informed"被译为"sheaf-知情"，指的是通过sheaf理论指导信息处理；"Geometric Multi-Agent Pathfinding"则被译为"几何多agent路径规划"，这是机器人和多agent系统中的一个研究领域，指多个智能体在几何环境中寻找不相冲突的路径的问题。'}
{'arxiv_id': 'arXiv:2502.06111', 'title': 'CSR-Bench: Benchmarking LLM Agents in Deployment of Computer Science Research Repositories', 'authors': 'Yijia Xiao, Runhui Wang, Luyang Kong, Davor Golac, Wei Wang', 'link': 'https://arxiv.org/abs/2502.06111', 'abstract': 'The increasing complexity of computer science research projects demands more effective tools for deploying code repositories. Large Language Models (LLMs), such as Anthropic Claude and Meta Llama, have demonstrated significant advancements across various fields of computer science research, including the automation of diverse software engineering tasks. To evaluate the effectiveness of LLMs in handling complex code development tasks of research projects, particularly for NLP/CV/AI/ML/DM topics, we introduce CSR-Bench, a benchmark for Computer Science Research projects. This benchmark assesses LLMs from various aspects including accuracy, efficiency, and deployment script quality, aiming to explore their potential in conducting computer science research autonomously. We also introduce a novel framework, CSR-Agents, that utilizes multiple LLM agents to automate the deployment of GitHub code repositories of computer science research projects. Specifically, by checking instructions from markdown files and interpreting repository structures, the model generates and iteratively improves bash commands that set up the experimental environments and deploy the code to conduct research tasks. Preliminary results from CSR-Bench indicate that LLM agents can significantly enhance the workflow of repository deployment, thereby boosting developer productivity and improving the management of developmental workflows.', 'abstract_zh': '随着计算机科学研究项目的复杂性不断增加，需要更加有效的工具来部署代码仓库。大型语言模型（LLMs），例如Anthropic Claude和Meta Llama，在计算机科学研究的各个领域，包括软件工程任务的自动化等方面，已经显示出显著的进步。为了评估LLMs在处理复杂的研究项目代码开发任务方面的有效性，尤其是对NLP/CV/AI/ML/DM主题的研究项目，我们引入了CSR-Bench，这是一个计算机科学研究项目的基准测试工具。该基准测试从准确性、效率和部署脚本质量等方面评估LLMs，旨在探索它们在自主开展计算机科学研究方面的潜力。我们还引入了一种新颖的框架CSR-Agents，利用多个LLM代理来自动化计算机科学研究项目的GitHub代码仓库部署。具体来说，通过检查Markdown文件中的指令并解释仓库结构，模型生成并迭代改进bash命令，以便设置实验环境并部署代码以完成研究任务。从CSR-Bench的初步结果表明，LLM代理可以显著提高代码仓库部署的工作流程，从而提高开发者的生产力并改善开发工作流程的管理。', 'title_zh': 'CSR-Bench: 评估计算机科学研究仓库中LLM代理的部署性能'}
{'arxiv_id': 'arXiv:2502.06039', 'title': 'Benchmarking Prompt Engineering Techniques for Secure Code Generation with GPT Models', 'authors': 'Marc Bruni, Fabio Gabrielli, Mohammad Ghafari, Martin Kropp', 'link': 'https://arxiv.org/abs/2502.06039', 'abstract': 'Prompt engineering reduces reasoning mistakes in Large Language Models (LLMs). However, its effectiveness in mitigating vulnerabilities in LLM-generated code remains underexplored. To address this gap, we implemented a benchmark to automatically assess the impact of various prompt engineering strategies on code security. Our benchmark leverages two peer-reviewed prompt datasets and employs static scanners to evaluate code security at scale. We tested multiple prompt engineering techniques on GPT-3.5-turbo, GPT-4o, and GPT-4o-mini. Our results show that for GPT-4o and GPT-4o-mini, a security-focused prompt prefix can reduce the occurrence of security vulnerabilities by up to 56%. Additionally, all tested models demonstrated the ability to detect and repair between 41.9% and 68.7% of vulnerabilities in previously generated code when using iterative prompting techniques. Finally, we introduce a "prompt agent" that demonstrates how the most effective techniques can be applied in real-world development workflows.', 'abstract_zh': '提示工程可以减少大型语言模型（LLMs）的推理错误。然而，其在减轻LLMs生成代码中的漏洞方面的有效性仍然鲜有研究。为弥补这一不足，我们建立了一个基准来自动评估各种提示工程技术对代码安全的影响。该基准利用了两个经过同行评审的提示数据集，并使用静态扫描工具大规模评估代码安全。我们在GPT-3.5-turbo、GPT-4o和GPT-4o-mini上测试了多种提示工程技术。结果表明，对于GPT-4o和GPT-4o-mini，一个以安全为导向的提示前缀可以将安全漏洞的发生率降低多达56%。此外，所有测试模型在使用迭代提示技术时，均能够检测并修复先前生成代码中41.9%至68.7%的漏洞。最后，我们引入了一个“提示代理”，展示了最有效技术如何在实际开发工作流中应用。', 'title_zh': '使用GPT模型进行安全代码生成的提示工程技术评估'}
{'arxiv_id': 'arXiv:2502.05963', 'title': 'Redefining Robot Generalization Through Interactive Intelligence', 'authors': 'Sharmita Dey', 'link': 'https://arxiv.org/abs/2502.05963', 'abstract': 'Recent advances in large-scale machine learning have produced high-capacity foundation models capable of adapting to a broad array of downstream tasks. While such models hold great promise for robotics, the prevailing paradigm still portrays robots as single, autonomous decision-makers, performing tasks like manipulation and navigation, with limited human involvement. However, a large class of real-world robotic systems, including wearable robotics (e.g., prostheses, orthoses, exoskeletons), teleoperation, and neural interfaces, are semiautonomous, and require ongoing interactive coordination with human partners, challenging single-agent assumptions. In this position paper, we argue that robot foundation models must evolve to an interactive multi-agent perspective in order to handle the complexities of real-time human-robot co-adaptation. We propose a generalizable, neuroscience-inspired architecture encompassing four modules: (1) a multimodal sensing module informed by sensorimotor integration principles, (2) an ad-hoc teamwork model reminiscent of joint-action frameworks in cognitive science, (3) a predictive world belief model grounded in internal model theories of motor control, and (4) a memory/feedback mechanism that echoes concepts of Hebbian and reinforcement-based plasticity. Although illustrated through the lens of cyborg systems, where wearable devices and human physiology are inseparably intertwined, the proposed framework is broadly applicable to robots operating in semi-autonomous or interactive contexts. By moving beyond single-agent designs, our position emphasizes how foundation models in robotics can achieve a more robust, personalized, and anticipatory level of performance.', 'abstract_zh': '近年来，大规模机器学习领域的最新进展产生了高度容量的基础模型，这些模型能够适应广泛的任务。虽然此类模型在机器人领域中前景广阔，但当前主导范式仍把机器人视为单一独立的决策者，进行诸如操作和导航等任务，且人机交互参与度较低。然而，许多现实世界中的机器人系统，包括穿戴式机器人（例如假肢、矫形器、外骨骼）、远程操作和神经接口系统等，均具有半自主特性，并要求持续的人机互动协调，这挑战了单一代理假设。在本文中，我们认为机器人基础模型必须向着互动多代理视角发展，以便处理现实时人类与机器人共适应的复杂性。我们提出了一个通用且受神经科学启发的架构，其包括四个模块：（1）多模态传感模块，该模块基于感知与运动整合原则；（2）临时团队模型，类似于认知科学中的联合行为框架；（3）预测世界信念模块，该模块基于运动控制内部模型理论；（4）记忆/反馈机制，这个机制借鉴了海布式和强化学习塑性概念。尽管该框架是通过半机械人系统（穿戴设备和人体生理不可分割地相互关联）的视角来说明，但其所涵盖的框架在半自主或互动环境下具有广泛的应用性。通过超越单一代理的设计，本文立场强调了机器人基础模型实现更稳健、个性化、预见性的性能水平的可能性。', 'title_zh': '通过交互智能重定义机器人泛化能力'}
{'arxiv_id': 'arXiv:2502.05951', 'title': 'Cyri: A Conversational AI-based Assistant for Supporting the Human User in Detecting and Responding to Phishing Attacks', 'authors': 'Antonio La Torre, Marco Angelini', 'link': 'https://arxiv.org/abs/2502.05951', 'abstract': "This work introduces Cyri, an AI-powered conversational assistant designed to support a human user in detecting and analyzing phishing emails by leveraging Large Language Models. Cyri has been designed to scrutinize emails for semantic features used in phishing attacks, such as urgency, and undesirable consequences, using an approach that unifies features already established in the literature with others by Cyri features extraction methodology. Cyri can be directly plugged into a client mail or webmail, ensuring seamless integration with the user's email workflow while maintaining data privacy through local processing. By performing analyses on the user's machine, Cyri eliminates the need to transmit sensitive email data over the internet, reducing associated security risks. The Cyri user interface has been designed to reduce habituation effects and enhance user engagement. It employs dynamic visual cues and context-specific explanations to keep users alert and informed while using emails. Additionally, it allows users to explore identified malicious semantic features both through conversation with the agent and visual exploration, obtaining the advantages of both modalities for expert or non-expert users. It also allows users to keep track of the conversation, supports the user in solving additional questions on both computed features or new parts of the mail, and applies its detection on demand. To evaluate Cyri, we crafted a comprehensive dataset of 420 phishing emails and 420 legitimate emails. Results demonstrate high effectiveness in identifying critical phishing semantic features fundamental to phishing detection. A user study involving 10 participants, both experts and non-experts, evaluated Cyri's effectiveness and usability. Results indicated that Cyri significantly aided users in identifying phishing emails and enhanced their understanding of phishing tactics.", 'abstract_zh': '本文介绍了Cyri，这是一种基于AI的对话式助手，旨在利用大型语言模型支持人类用户检测和分析钓鱼邮件。Cyri 被设计为能够审查电子邮件中的语义特征，这些特征常被用于钓鱼攻击，如紧迫性以及不良后果。通过结合文献中已确立的功能和Cyri特有特征提取方法，Cyri采用了统一的方法论来识别这些特征。Cyri可以直接接入客户端邮件或Web邮件，确保与用户的邮件工作流程无缝集成，同时通过本地处理保护数据隐私。通过在用户本地机器上进行分析，Cyri消除了传输敏感电子邮件数据的必要性，减少了相关安全风险。Cyri的用户界面被设计为降低习惯性影响并增强用户体验。它通过动态视觉提示和情境特定的解释，使用户在使用邮件时保持警觉和了解。此外，Cyri允许用户通过与代理对话和视觉探索来探索所识别的恶意语义特征，为专家和非专家用户提供了两种模态的优势。它还允许用户跟踪对话过程，帮助用户解决与计算特征或邮件新部分相关的额外问题，并在需要时进行检测。为了评估Cyri，我们构建了一个包含420封钓鱼邮件和420封合法邮件的全面数据集。结果表明，Cyri在识别对钓鱼检测至关重要的关键语义特征方面非常有效。一项涉及10名参与者（既有专家也有非专家）的用户研究评估了Cyri的效果和易用性。结果显示，Cyri显著帮助用户识别钓鱼邮件，并增强了他们对钓鱼战术的理解。', 'title_zh': 'Cyri：一种基于对话AI的辅助系统，用于支持人类用户检测和应对钓鱼攻击'}
{'arxiv_id': 'arXiv:2502.05932', 'title': 'Skill Expansion and Composition in Parameter Space', 'authors': 'Tenglong Liu, Jianxiong Li, Yinan Zheng, Haoyi Niu, Yixing Lan, Xin Xu, Xianyuan Zhan', 'link': 'https://arxiv.org/abs/2502.05932', 'abstract': "Humans excel at reusing prior knowledge to address new challenges and developing skills while solving problems. This paradigm becomes increasingly popular in the development of autonomous agents, as it develops systems that can self-evolve in response to new challenges like human beings. However, previous methods suffer from limited training efficiency when expanding new skills and fail to fully leverage prior knowledge to facilitate new task learning. In this paper, we propose Parametric Skill Expansion and Composition (PSEC), a new framework designed to iteratively evolve the agents' capabilities and efficiently address new challenges by maintaining a manageable skill library. This library can progressively integrate skill primitives as plug-and-play Low-Rank Adaptation (LoRA) modules in parameter-efficient finetuning, facilitating efficient and flexible skill expansion. This structure also enables the direct skill compositions in parameter space by merging LoRA modules that encode different skills, leveraging shared information across skills to effectively program new skills. Based on this, we propose a context-aware module to dynamically activate different skills to collaboratively handle new tasks. Empowering diverse applications including multi-objective composition, dynamics shift, and continual policy shift, the results on D4RL, DSRL benchmarks, and the DeepMind Control Suite show that PSEC exhibits superior capacity to leverage prior knowledge to efficiently tackle new challenges, as well as expand its skill libraries to evolve the capabilities. Project website: this https URL.", 'abstract_zh': '人类擅长利用先前的知识来应对新的挑战并发展解决问题所需的新技能。这一范式在自主代理的开发中变得越来越受欢迎，因为它能够促使系统在面对新的挑战时自我进化，就像人类一样。然而，之前的许多方法在扩展新技能时面临训练效率低下的问题，并且未能充分利用先前的知识来促进新任务的学习。在本文中，我们提出了一种新的框架——参数化技能扩展和组合（PSEC），该框架旨在通过维护可管理的技能库来逐步迭代进化代理的技能和能力，从而有效地应对新的挑战。该库可以将技能组件作为插拔式低秩适应（LoRA）模块进行渐进性集成，在参数高效微调中促进高效且灵活的技能扩展。此外，该结构还允许在参数空间内直接组合技能，通过合并编码不同技能的LoRA模块来利用技能间的共享信息，从而有效地编程新技能。在此基础上，我们提出了一种上下文感知模块，能够动态激活不同的技能以协作处理新任务。应用于包括多目标组合、动态转移和连续策略转移在内的多种应用场景，PSEC在D4RL、DSRL基准和DeepMind控制套件上的实验结果表明，PSEC能够更高效地利用先前知识应对新的挑战，并扩展其技能库以进化其能力。项目网站：[这个链接](this https URL)。', 'title_zh': '参数空间中的技能扩展与组合'}
{'arxiv_id': 'arXiv:2502.05857', 'title': 'Acquisition through My Eyes and Steps: A Joint Predictive Agent Model in Egocentric Worlds', 'authors': 'Lu Chen, Yizhou Wang, Shixiang Tang, Qianhong Ma, Tong He, Wanli Ouyang, Xiaowei Zhou, Hujun Bao, Sida Peng', 'link': 'https://arxiv.org/abs/2502.05857', 'abstract': 'This paper addresses the task of learning an agent model behaving like humans, which can jointly perceive, predict, and act in egocentric worlds. Previous methods usually train separate models for these three abilities, leading to information silos among them, which prevents these abilities from learning from each other and collaborating effectively. In this paper, we propose a joint predictive agent model, named EgoAgent, that simultaneously learns to represent the world, predict future states, and take reasonable actions with a single transformer. EgoAgent unifies the representational spaces of the three abilities by mapping them all into a sequence of continuous tokens. Learnable query tokens are appended to obtain current states, future states, and next actions. With joint supervision, our agent model establishes the internal relationship among these three abilities and effectively mimics the human inference and learning processes. Comprehensive evaluations of EgoAgent covering image classification, egocentric future state prediction, and 3D human motion prediction tasks demonstrate the superiority of our method. The code and trained model will be released for reproducibility.', 'abstract_zh': '本文探讨了学习一种类人类行为的智能体模型的任务，该模型能够共同进行自我中心世界的感知、预测和行动。以往的方法通常为这三项能力分别训练独立的模型，导致这些能力之间的信息孤立，妨碍了它们之间的相互学习和有效协作。在这篇文章中，我们提出了一种联合预测智能体模型，命名为EgoAgent，该模型利用单一的变换器同时学习表示世界、预测未来状态和采取合理行动。EgoAgent通过将这三项能力的表示空间映射到一系列连续标记上来统一这三种能力的空间。可学习的查询标记被附加到这些标记之后，以获取当前状态、未来状态和下一步行动。通过联合监督，我们的智能体模型建立了这三项能力之间的内部关系，并有效地模拟了人类的推理和学习过程。全面评估EgoAgent在图像分类、自我中心未来状态预测和3D人体运动预测任务中的性能展示了该方法的优势。代码和训练模型将公开发布以保证可重现性。', 'title_zh': '从我视角和步骤中获取：一种在主观世界中的联合预测代理模型'}
{'arxiv_id': 'arXiv:2502.05740', 'title': 'RECOVER: Designing a Large Language Model-based Remote Patient Monitoring System for Postoperative Gastrointestinal Cancer Care', 'authors': 'Ziqi Yang, Yuxuan Lu, Jennifer Bagdasarian, Vedant Das Swain, Ritu Agarwal, Collin Campbell, Waddah Al-Refaire, Jehan El-Bayoumi, Guodong Gao, Dakuo Wang, Bingsheng Yao, Nawar Shara', 'link': 'https://arxiv.org/abs/2502.05740', 'abstract': 'Cancer surgery is a key treatment for gastrointestinal (GI) cancers, a group of cancers that account for more than 35% of cancer-related deaths worldwide, but postoperative complications are unpredictable and can be life-threatening. In this paper, we investigate how recent advancements in large language models (LLMs) can benefit remote patient monitoring (RPM) systems through clinical integration by designing RECOVER, an LLM-powered RPM system for postoperative GI cancer care. To closely engage stakeholders in the design process, we first conducted seven participatory design sessions with five clinical staff and interviewed five cancer patients to derive six major design strategies for integrating clinical guidelines and information needs into LLM-based RPM systems. We then designed and implemented RECOVER, which features an LLM-powered conversational agent for cancer patients and an interactive dashboard for clinical staff to enable efficient postoperative RPM. Finally, we used RECOVER as a pilot system to assess the implementation of our design strategies with four clinical staff and five patients, providing design implications by identifying crucial design elements, offering insights on responsible AI, and outlining opportunities for future LLM-powered RPM systems.', 'abstract_zh': '癌症手术是消化道（GI）癌症治疗的关键手段，而GI癌症占全球癌症相关死亡人数的35%以上。然而，术后并发症不可预测且可能危及生命。本文探讨了最近在大规模语言模型（LLMs）方面的进展如何通过临床集成优势于远程患者监测（RPM）系统，设计了一个基于LLM的RPM系统——RECOVER，用于术后GI癌症护理。为了在设计过程中紧密参与利益相关者的意见，我们首先与五名临床工作人员进行了七次参与式设计会，采访了五名癌症患者，以提炼出六项主要的设计策略，这些策略旨在将临床指南和信息需求整合到基于LLM的RPM系统中。随后，我们设计并实现了RECOVER系统，该系统具备一种基于LLM的对话代理，供癌症患者使用，并提供互动仪表板，使临床工作人员能够实现高效的术后RPM。最后，我们使用RECOVER作为试点系统评估了我们设计策略的实施情况，涉及四名临床工作人员和五名患者，并通过识别关键设计元素、提供负责任的AI见解以及概述未来LLM驱动的RPM系统的机会来为设计提供启示。', 'title_zh': 'RECOVER：设计一种基于大型语言模型的远程患者监测系统，用于术后胃肠癌护理'}
{'arxiv_id': 'arXiv:2502.05573', 'title': 'Low-Rank Agent-Specific Adaptation (LoRASA) for Multi-Agent Policy Learning', 'authors': 'Beining Zhang, Aditya Kapoor, Mingfei Sun', 'link': 'https://arxiv.org/abs/2502.05573', 'abstract': "Multi-agent reinforcement learning (MARL) often relies on \\emph{parameter sharing (PS)} to scale efficiently. However, purely shared policies can stifle each agent's unique specialization, reducing overall performance in heterogeneous environments. We propose \\textbf{Low-Rank Agent-Specific Adaptation (LoRASA)}, a novel approach that treats each agent's policy as a specialized ``task'' fine-tuned from a shared backbone. Drawing inspiration from parameter-efficient transfer methods, LoRASA appends small, low-rank adaptation matrices to each layer of the shared policy, naturally inducing \\emph{parameter-space sparsity} that promotes both specialization and scalability. We evaluate LoRASA on challenging benchmarks including the StarCraft Multi-Agent Challenge (SMAC) and Multi-Agent MuJoCo (MAMuJoCo), implementing it atop widely used algorithms such as MAPPO and A2PO. Across diverse tasks, LoRASA matches or outperforms existing baselines \\emph{while reducing memory and computational overhead}. Ablation studies on adapter rank, placement, and timing validate the method's flexibility and efficiency. Our results suggest LoRASA's potential to establish a new norm for MARL policy parameterization: combining a shared foundation for coordination with low-rank agent-specific refinements for individual specialization.", 'abstract_zh': '多智能体强化学习（MARL）通常依赖于**参数共享（PS）**以实现高效扩展。然而，单纯的共享策略可能会限制每个智能体的独特专长，从而在异构环境中降低整体性能。我们提出了一种名为**低秩智能体特定适应（LoRASA）**的新型方法，该方法将每个智能体的策略视为从共享主干微调的“任务”。LoRASA 方法借鉴了参数高效的迁移学习方法，向共享策略的每一层附加小型低秩适应矩阵，自然诱导了**参数空间稀疏性**，从而促进专业化和可扩展性。我们通过包括《星际争霸》多智能体挑战（SMAC）和多智能体MuJoCo（MAMuJoCo）在内的具有挑战性的基准测试评估了LoRASA，并在其上实现了广泛使用的算法，如MAPPO和A2PO。在各种任务中，LoRASA 在降低内存和计算开销的同时与现有基线相比表现相当甚至更优。消融研究表明，适配器的秩、位置和时机的灵活性和效率。我们的研究表明，LoRASA 有可能为MARL策略参数化建立一个新的标准：结合共享的基础进行协调，同时通过低秩智能体特定的修正实现个体专业化。', 'title_zh': '低秩个性化适应（LoRASA）多智能体策略学习'}
{'arxiv_id': 'arXiv:2502.05526', 'title': 'Towards Learning Scalable Agile Dynamic Motion Planning for Robosoccer Teams with Policy Optimization', 'authors': 'Brandon Ho, Batuhan Altundas, Matthew Gombolay', 'link': 'https://arxiv.org/abs/2502.05526', 'abstract': "In fast-paced, ever-changing environments, dynamic Motion Planning for Multi-Agent Systems in the presence of obstacles is a universal and unsolved problem. Be it from path planning around obstacles to the movement of robotic arms, or in planning navigation of robot teams in settings such as Robosoccer, dynamic motion planning is needed to avoid collisions while reaching the targeted destination when multiple agents occupy the same area. In continuous domains where the world changes quickly, existing classical Motion Planning algorithms such as RRT* and A* become computationally expensive to rerun at every time step. Many variations of classical and well-formulated non-learning path-planning methods have been proposed to solve this universal problem but fall short due to their limitations of speed, smoothness, optimally, etc. Deep Learning models overcome their challenges due to their ability to adapt to varying environments based on past experience. However, current learning motion planning models use discretized environments, do not account for heterogeneous agents or replanning, and build up to improve the classical motion planners' efficiency, leading to issues with scalability. To prevent collisions between heterogenous team members and collision to obstacles while trying to reach the target location, we present a learning-based dynamic navigation model and show our model working on a simple environment in the concept of a simple Robosoccer Game.", 'abstract_zh': '在快节奏且不断变化的环境中，多智能体系统的动态避障路径规划是普遍存在的且尚未解决的问题。从围绕障碍物进行路径规划到机器人手臂的运动，以及在Robosoccer等设置下的机器人团队导航规划，都需要进行动态路径规划以避免碰撞并达到目标位置。在世界快速变化的连续领域中，现有的经典路径规划算法如RRT*和A*在每一时间步重新运行变得计算成本高昂。为了解决这一普遍问题，许多经典和经过良好定义的非学习路径规划方法已被提出，但由于速度、平滑性和最优性等方面的局限性，这些方法存在不足。深度学习模型能够通过以往的经验适应变化的环境，克服了这些挑战。然而，当前的学习路径规划模型使用离散化的环境，并未考虑异质智能体或重新规划，而是试图提高经典路径规划算法的效率，导致可扩展性问题。为了防止不同类型的团队成员之间以及与障碍物的碰撞，同时努力到达目标位置，我们提出了一种基于学习的动态导航模型，并展示了该模型在简单Robosoccer游戏中简单环境中的应用。', 'title_zh': '面向罗bor soccer团队可扩展敏捷动态运动规划的学习方法研究：基于策略优化'}
{'arxiv_id': 'arXiv:2502.05485', 'title': 'HAMSTER: Hierarchical Action Models For Open-World Robot Manipulation', 'authors': 'Yi Li, Yuquan Deng, Jesse Zhang, Joel Jang, Marius Memme, Raymond Yu, Caelan Reed Garrett, Fabio Ramos, Dieter Fox, Anqi Li, Abhishek Gupta, Ankit Goyal', 'link': 'https://arxiv.org/abs/2502.05485', 'abstract': "Large foundation models have shown strong open-world generalization to complex problems in vision and language, but similar levels of generalization have yet to be achieved in robotics. One fundamental challenge is the lack of robotic data, which are typically obtained through expensive on-robot operation. A promising remedy is to leverage cheaper, off-domain data such as action-free videos, hand-drawn sketches or simulation data. In this work, we posit that hierarchical vision-language-action (VLA) models can be more effective in utilizing off-domain data than standard monolithic VLA models that directly finetune vision-language models (VLMs) to predict actions. In particular, we study a class of hierarchical VLA models, where the high-level VLM is finetuned to produce a coarse 2D path indicating the desired robot end-effector trajectory given an RGB image and a task description. The intermediate 2D path prediction is then served as guidance to the low-level, 3D-aware control policy capable of precise manipulation. Doing so alleviates the high-level VLM from fine-grained action prediction, while reducing the low-level policy's burden on complex task-level reasoning. We show that, with the hierarchical design, the high-level VLM can transfer across significant domain gaps between the off-domain finetuning data and real-robot testing scenarios, including differences on embodiments, dynamics, visual appearances and task semantics, etc. In the real-robot experiments, we observe an average of 20% improvement in success rate across seven different axes of generalization over OpenVLA, representing a 50% relative gain. Visual results are provided at: this https URL", 'abstract_zh': '大型基础模型在视觉和语言领域展现了强大的开放世界泛化能力，但在机器人领域尚未达到类似的泛化水平。一个根本性的挑战在于机器人数据的缺乏，这些数据通常通过昂贵的在机器人上操作获得。一种有前景的解决方法是利用更为廉价的跨域数据，如无动作视频、手工绘制草图或仿真数据。在本文中，我们认为分层的视觉-语言-行动（VLA）模型比直接微调视觉-语言模型（VLMs）来预测行动的标准单一模型更为有效，可以更好地利用跨域数据。特别是，我们研究了一类分层VLA模型，在这类模型中，高层VLM被微调以生成给定RGB图像和任务描述时指示所需末端执行器轨迹的大致二维路径。然后，中间的二维路径预测作为指导传递给低层、三维感知的控制策略，该策略能够进行精确操作。这种设计减轻了高层VLM对细粒度动作预测的负担，同时减少了低层策略在复杂任务层面推理上的负担。我们表明，通过分层设计，高层VLM可以在显著的数据域差距之间进行泛化，包括不同的实体、动力学、视觉外观和任务语义等方面。在真实的机器人实验中，我们观察到在七个不同泛化轴上，与OpenVLA相比平均提高了20%的成功率，这代表了50%的相对提升。视觉结果请参阅：[这里](this https URL)', 'title_zh': 'HAMSTER：开放世界机器人操作的层次化动作模型'}
{'arxiv_id': 'arXiv:2502.05264', 'title': 'Quantum automated learning with provable and explainable trainability', 'authors': 'Qi Ye, Shuangyue Geng, Zizhao Han, Weikang Li, L.-M. Duan, Dong-Ling Deng', 'link': 'https://arxiv.org/abs/2502.05264', 'abstract': 'Machine learning is widely believed to be one of the most promising practical applications of quantum computing. Existing quantum machine learning schemes typically employ a quantum-classical hybrid approach that relies crucially on gradients of model parameters. Such an approach lacks provable convergence to global minima and will become infeasible as quantum learning models scale up. Here, we introduce quantum automated learning, where no variational parameter is involved and the training process is converted to quantum state preparation. In particular, we encode training data into unitary operations and iteratively evolve a random initial state under these unitaries and their inverses, with a target-oriented perturbation towards higher prediction accuracy sandwiched in between. Under reasonable assumptions, we rigorously prove that the evolution converges exponentially to the desired state corresponding to the global minimum of the loss function. We show that such a training process can be understood from the perspective of preparing quantum states by imaginary time evolution, where the data-encoded unitaries together with target-oriented perturbations would train the quantum learning model in an automated fashion. We further prove that the quantum automated learning paradigm features good generalization ability with the generalization error upper bounded by the ratio between a logarithmic function of the Hilbert space dimension and the number of training samples. In addition, we carry out extensive numerical simulations on real-life images and quantum data to demonstrate the effectiveness of our approach and validate the assumptions. Our results establish an unconventional quantum learning strategy that is gradient-free with provable and explainable trainability, which would be crucial for large-scale practical applications of quantum computing in machine learning scenarios.', 'abstract_zh': '机器学习被广泛认为是量子计算最有前景的实际应用之一。现有的量子机器学习方案通常采用量子-经典混合方法，依赖于模型参数的梯度。这种方法缺乏证明其全局最小值收敛的能力，并且在量子学习模型扩展时将变得不可行。在此，我们引入了量子自动化学习，其中不涉及变分参数，训练过程转化为量子态准备。具体而言，我们将训练数据编码为幺正操作，并在这些幺正操作及其逆操作之间进行迭代演化，并在两者之间嵌入目标导向的扰动以提高预测准确性。在合理假设下，我们严格证明了这种演化按照损失函数全局最小值对应的量子态收敛于期望态。我们证明了这种训练过程可以从量子态的虚时间演化角度来理解，在此过程中，数据编码的幺正操作与目标导向的扰动将自动化地训练量子学习模型。此外，我们证明了量子自动化学习范式具有良好的泛化能力，泛化误差上界由希尔伯特空间维数的对数函数与其训练样本数量的比值给出。我们还通过在真实图像和量子数据上的广泛数值模拟，验证了该方法的有效性，并验证了相关假设。我们的结果确立了一种独特的、无梯度的量子学习策略，该策略具有可证明的和可解释的训练能力，对量子计算在机器学习场景中的大规模实际应用至关重要。', 'title_zh': '可验证且可解释的量子自动化学习'}
