{'arxiv_id': 'arXiv:2501.13080', 'title': 'Refining Input Guardrails: Enhancing LLM-as-a-Judge Efficiency Through Chain-of-Thought Fine-Tuning and Alignment', 'authors': 'Melissa Kazemi Rad, Huy Nghiem, Andy Luo, Sahil Wadhwa, Mohammad Sorower, Stephen Rawls', 'link': 'https://arxiv.org/abs/2501.13080', 'abstract': 'Large Language Models (LLMs) have demonstrated powerful capabilities that render them valuable in different applications, including conversational AI products. It is paramount to ensure the security and reliability of these products by mitigating their vulnerabilities towards malicious user interactions, which can lead to the exposure of great risks and reputational repercussions. In this work, we present a comprehensive study on the efficacy of fine-tuning and aligning Chain-of-Thought (CoT) responses of different LLMs that serve as input moderation guardrails. We systematically explore various tuning methods by leveraging a small set of training data to adapt these models as proxy defense mechanisms to detect malicious inputs and provide a reasoning for their verdicts, thereby preventing the exploitation of conversational agents. We rigorously evaluate the efficacy and robustness of different tuning strategies to generalize across diverse adversarial and malicious query types. Our experimental results outline the potential of alignment processes tailored to a varied range of harmful input queries, even with constrained data resources. These techniques significantly enhance the safety of conversational AI systems and provide a feasible framework for deploying more secure and trustworthy AI-driven interactions.', 'abstract_zh': '大型语言模型（LLMs）展示出了强大的能力，使其在不同的应用场景中变得非常有价值，包括对话型人工智能产品。确保这些产品的安全性和可靠性至关重要，这要求通过减轻其对恶意用户交互的脆弱性来加以防范，否则可能会引发严重风险和声誉损失。在本研究中，我们对不同LLMs的链式推理（Chain-of-Thought, CoT）响应进行微调和对齐的有效性进行了全面研究，这些响应可以用作输入规范的防护措施。我们通过利用少量训练数据系统地探索各种调优方法，将这些模型作为代理防御机制，以检测恶意输入并为其判决提供推理依据，从而防止对话代理的滥用。我们严格评估了不同调优策略的效用和鲁棒性，使其能够适应多样化的对抗性及恶意查询类型。实验结果表明，即使在数据资源有限的情况下，针对不同类型有害输入进行对齐的过程也具有潜在的效果。这些技术极大地增强了对话型人工智能系统的安全性，并为部署更安全和可信赖的AI驱动交互提供了可行框架。', 'title_zh': '优化输入边界：通过链式思考微调和对齐提高LLM作为仲裁者的效率'}
