{'arxiv_id': 'arXiv:2501.16150', 'title': 'AI Agents for Computer Use: A Review of Instruction-based Computer Control, GUI Automation, and Operator Assistants', 'authors': 'Pascal J. Sager, Benjamin Meyer, Peng Yan, Rebekka von Wartburg-Kottler, Layan Etaiwi, Aref Enayati, Gabriel Nobel, Ahmed Abdulkadir, Benjamin F. Grewe, Thilo Stadelmann', 'link': 'https://arxiv.org/abs/2501.16150', 'abstract': 'Instruction-based computer control agents (CCAs) execute complex action sequences on personal computers or mobile devices to fulfill tasks using the same graphical user interfaces as a human user would, provided instructions in natural language. This review offers a comprehensive overview of the emerging field of instruction-based computer control, examining available agents -- their taxonomy, development, and respective resources -- and emphasizing the shift from manually designed, specialized agents to leveraging foundation models such as large language models (LLMs) and vision-language models (VLMs). We formalize the problem and establish a taxonomy of the field to analyze agents from three perspectives: (a) the environment perspective, analyzing computer environments; (b) the interaction perspective, describing observations spaces (e.g., screenshots, HTML) and action spaces (e.g., mouse and keyboard actions, executable code); and (c) the agent perspective, focusing on the core principle of how an agent acts and learns to act. Our framework encompasses both specialized and foundation agents, facilitating their comparative analysis and revealing how prior solutions in specialized agents, such as an environment learning step, can guide the development of more capable foundation agents. Additionally, we review current CCA datasets and CCA evaluation methods and outline the challenges to deploying such agents in a productive setting. In total, we review and classify 86 CCAs and 33 related datasets. By highlighting trends, limitations, and future research directions, this work presents a comprehensive foundation to obtain a broad understanding of the field and push its future development.', 'abstract_zh': '基于指令的计算机控制代理（CCAs）执行个人计算机或移动设备上的复杂操作序列，使用与人类用户相同的图形用户界面，根据自然语言提供的指令完成任务。本文综述了基于指令的计算机控制这一新兴领域，对现有的代理进行了全面的审查，包括它们的分类、开发及其相应的资源，并强调从手动设计的专业代理向利用基础模型（如大型语言模型LLMs和视觉语言模型VLMs）的转变。我们形式化了这一问题，并建立了该领域的分类框架，从三个视角分析代理：（a）环境视角，分析计算机环境；（b）交互视角，描述观察空间（例如屏幕截图、HTML）和动作空间（例如鼠标和键盘操作、可执行代码）；（c）代理视角，专注于代理如何行动和学习行动的核心原理。我们的框架包括专门的和基础的代理，便于它们的比较分析，并揭示了专门代理中的先前解决方案，如环境学习步骤，可以指导更强大基础代理的发展。此外，我们还回顾了现有的CCA数据集和CCA评估方法，并概述了在生产环境中部署此类代理所面临的挑战。总体而言，我们审查并分类了86个CCAs和33个相关数据集。通过突出显示趋势、限制和未来研究方向，本文提供了一个全面的基础，有助于全面理解该领域并推动其未来的发展。', 'title_zh': '基于指令的计算机控制、GUI自动化的AI代理及操作助理：一个综述'}
{'arxiv_id': 'arXiv:2501.15791', 'title': 'Harnessing Diverse Perspectives: A Multi-Agent Framework for Enhanced Error Detection in Knowledge Graphs', 'authors': 'Yu Li, Yi Huang, Guilin Qi, Junlan Feng, Nan Hu, Songlin Zhai, Haohan Xue, Yongrui Chen, Ruoyan Shen, Tongtong Wu', 'link': 'https://arxiv.org/abs/2501.15791', 'abstract': 'Knowledge graphs are widely used in industrial applications, making error detection crucial for ensuring the reliability of downstream applications. Existing error detection methods often fail to effectively leverage fine-grained subgraph information and rely solely on fixed graph structures, while also lacking transparency in their decision-making processes, which results in suboptimal detection performance. In this paper, we propose a novel Multi-Agent framework for Knowledge Graph Error Detection (MAKGED) that utilizes multiple large language models (LLMs) in a collaborative setting. By concatenating fine-grained, bidirectional subgraph embeddings with LLM-based query embeddings during training, our framework integrates these representations to produce four specialized agents. These agents utilize subgraph information from different dimensions to engage in multi-round discussions, thereby improving error detection accuracy and ensuring a transparent decision-making process. Extensive experiments on FB15K and WN18RR demonstrate that MAKGED outperforms state-of-the-art methods, enhancing the accuracy and robustness of KG evaluation. For specific industrial scenarios, our framework can facilitate the training of specialized agents using domain-specific knowledge graphs for error detection, which highlights the potential industrial application value of our framework. Our code and datasets are available at this https URL.', 'abstract_zh': '知识图谱在工业应用中广泛应用，因此错误检测对于确保下游应用的可靠性至关重要。现有错误检测方法往往未能有效利用细粒度的子图信息，而是依赖于固定的图结构，同时在决策过程中缺乏透明性，导致检测性能不佳。本文提出了一种名为多代理框架的知识图谱错误检测（MAKGED）方法，该方法利用多个大型语言模型（LLMs）在协作环境中进行工作。通过在训练过程中将细粒度的双向子图嵌入与基于LLM的查询嵌入进行连接，该框架将这些表示整合成四种专门的代理。这些代理利用来自不同维度的子图信息进行多轮讨论，从而提高错误检测精度并确保决策过程的透明性。在FB15K和WN18RR上的 extensive 实验表明，MAKGED 在错误检测精度和鲁棒性方面优于最先进的方法。对于特定的工业场景，该框架可以根据专业知识图谱训练专门的代理进行错误检测，突显了该框架的潜在工业应用价值。我们的代码和数据集可以在此处访问：<此网址>。', 'title_zh': '利用多元视角：一种增强知识图谱错误检测的多代理框架'}
{'arxiv_id': 'arXiv:2501.15749', 'title': 'LLM-powered Multi-agent Framework for Goal-oriented Learning in Intelligent Tutoring System', 'authors': 'Tianfu Wang, Yi Zhan, Jianxun Lian, Zhengyu Hu, Nicholas Jing Yuan, Qi Zhang, Xing Xie, Hui Xiong', 'link': 'https://arxiv.org/abs/2501.15749', 'abstract': "Intelligent Tutoring Systems (ITSs) have revolutionized education by offering personalized learning experiences. However, as goal-oriented learning, which emphasizes efficiently achieving specific objectives, becomes increasingly important in professional contexts, existing ITSs often struggle to deliver this type of targeted learning experience. In this paper, we propose GenMentor, an LLM-powered multi-agent framework designed to deliver goal-oriented, personalized learning within ITS. GenMentor begins by accurately mapping learners' goals to required skills using a fine-tuned LLM trained on a custom goal-to-skill dataset. After identifying the skill gap, it schedules an efficient learning path using an evolving optimization approach, driven by a comprehensive and dynamic profile of learners' multifaceted status. Additionally, GenMentor tailors learning content with an exploration-drafting-integration mechanism to align with individual learner needs. Extensive automated and human evaluations demonstrate GenMentor's effectiveness in learning guidance and content quality. Furthermore, we have deployed it in practice and also implemented it as an application. Practical human study with professional learners further highlights its effectiveness in goal alignment and resource targeting, leading to enhanced personalization. Supplementary resources are available at this https URL.", 'abstract_zh': '智能辅导系统（ITSs）通过提供个性化的学习体验，彻底改变了教育领域。然而，随着目标导向学习——强调高效达成具体目标——在专业环境中的重要性日益提高，现有的ITSs往往难以提供这种针对性的学习体验。本文提出了一种名为GenMentor的框架，该框架由大语言模型（LLM）驱动，旨在为ITS提供目标导向的个性化学习体验。GenMentor首先通过微调在自定义目标到技能数据集上训练的LLM，准确地将学习者的目标与所需的技能相匹配。在识别出技能缺口后，它利用一种不断演化的优化方法，根据学习者多维度状态的全面且动态的概况，规划一条高效的学习路径。此外，GenMentor采用了探索-草拟-整合机制来定制学习内容，以满足个体学习者的需求。广泛的自动化和人工评估表明，GenMentor在学习指导和内容质量方面具有显著效果。此外，我们已在实践中部署了GenMentor，并将其作为应用程序进行实施。对专业学习者的实际人类研究进一步突显了其在目标对齐和资源分配方面的有效性，从而增强了个性化水平。有关补充资源，请参阅此链接：[提供的链接]。', 'title_zh': '基于大型语言模型的多智能体框架：面向目标学习的智能辅导系统'}
{'arxiv_id': 'arXiv:2501.15495', 'title': 'Expert-Free Online Transfer Learning in Multi-Agent Reinforcement Learning', 'authors': 'Alberto Castagna', 'link': 'https://arxiv.org/abs/2501.15495', 'abstract': 'Reinforcement Learning (RL) enables an intelligent agent to optimise its performance in a task by continuously taking action from an observed state and receiving a feedback from the environment in form of rewards. RL typically uses tables or linear approximators to map state-action tuples that maximises the reward. Combining RL with deep neural networks (DRL) significantly increases its scalability and enables it to address more complex problems than before. However, DRL also inherits downsides from both RL and deep learning. Despite DRL improves generalisation across similar state-action pairs when compared to simpler RL policy representations like tabular methods, it still requires the agent to adequately explore the state-action space. Additionally, deep methods require more training data, with the volume of data escalating with the complexity and size of the neural network. As a result, deep RL requires a long time to collect enough agent-environment samples and to successfully learn the underlying policy. Furthermore, often even a slight alteration to the task invalidates any previous acquired knowledge. To address these shortcomings, Transfer Learning (TL) has been introduced, which enables the use of external knowledge from other tasks or agents to enhance a learning process. The goal of TL is to reduce the learning complexity for an agent dealing with an unfamiliar task by simplifying the exploration process. This is achieved by lowering the amount of new information required by its learning model, resulting in a reduced overall convergence time...', 'abstract_zh': '强化学习（RL）使智能代理能够通过不断从观察到的状态采取行动并从环境中获得反馈（奖励）来优化其在任务中的表现。RL 通常使用表格或线性近似来映射能最大化奖励的状态-动作元组。将 RL 与深度神经网络相结合（深度强化学习，DRL）极大地提高了其可扩展性，并使其能够解决比以往更复杂的问题。然而，DRL 也从 RL 和深度学习中继承了一些缺点。尽管 DRL 在面对相似的状态-动作对时与简单 RL 策略表示（如表征方法）相比在泛化方面有所改进，但它仍然需要智能代理充分探索状态-动作空间。此外，深度方法需要更多的训练数据，数据量随着神经网络的复杂性和规模而增加。因此，DRL 需要较长时间收集足够的智能代理-环境样本，并成功学习底层策略。此外，往往即使是任务的轻微改动也会使得之前获得的知识失效。为解决这些缺点，引入了元学习（Transfer Learning，TL），它允许利用其他任务或代理的外部知识来增强学习过程。TL 的目标是通过简化探索过程来降低智能代理处理陌生任务的学习复杂性。这通过减少学习模型所需的新信息量来实现，从而降低总体收敛时间……', 'title_zh': '专家无需参与的多智能体强化学习中的在线转移学习'}
{'arxiv_id': 'arXiv:2501.15001', 'title': 'What if Eye...? Computationally Recreating Vision Evolution', 'authors': 'Kushagra Tiwary, Aaron Young, Zaid Tasneem, Tzofi Klinghoffer, Akshat Dave, Tomaso Poggio, Dan Nilsson, Brian Cheung, Ramesh Raskar', 'link': 'https://arxiv.org/abs/2501.15001', 'abstract': 'Vision systems in nature show remarkable diversity, from simple light-sensitive patches to complex camera eyes with lenses. While natural selection has produced these eyes through countless mutations over millions of years, they represent just one set of realized evolutionary paths. Testing hypotheses about how environmental pressures shaped eye evolution remains challenging since we cannot experimentally isolate individual factors. Computational evolution offers a way to systematically explore alternative trajectories. Here we show how environmental demands drive three fundamental aspects of visual evolution through an artificial evolution framework that co-evolves both physical eye structure and neural processing in embodied agents. First, we demonstrate computational evidence that task specific selection drives bifurcation in eye evolution - orientation tasks like navigation in a maze leads to distributed compound-type eyes while an object discrimination task leads to the emergence of high-acuity camera-type eyes. Second, we reveal how optical innovations like lenses naturally emerge to resolve fundamental tradeoffs between light collection and spatial precision. Third, we uncover systematic scaling laws between visual acuity and neural processing, showing how task complexity drives coordinated evolution of sensory and computational capabilities. Our work introduces a novel paradigm that illuminates evolutionary principles shaping vision by creating targeted single-player games where embodied agents must simultaneously evolve visual systems and learn complex behaviors. Through our unified genetic encoding framework, these embodied agents serve as next-generation hypothesis testing machines while providing a foundation for designing manufacturable bio-inspired vision systems.', 'abstract_zh': '自然界中的视觉系统显示出巨大的多样性，从简单的光感受斑点到具有透镜的复杂照相机眼睛。尽管自然选择在过去数百万年中通过无数次的突变产生了这些眼睛，但它们仅代表了一种进化路径。由于我们无法单独隔离环境压力对眼睛进化的各个因素进行实验性研究，因此验证这些假说是具有挑战性的。计算演化为系统地探索替代进化路径提供了一种方法。在这里，我们展示了通过一个综合演化框架，该框架不仅共同演化身体代理的物理眼睛结构和神经处理方式，还能如何通过环境需求驱动视觉进化的三个基本方面。首先，我们展示了计算证据表明，任务特异性选择驱动眼睛进化的分歧——例如在迷宫中的导航任务导致分分布式复合式眼睛的出现，而物体识别任务则导致高分辨率照相机式眼睛的出现。其次，我们揭示了如何通过光学创新（如透镜）自然地解决光线收集与空间精度之间的根本性权衡问题。第三，我们发现了视觉敏锐度与神经处理之间系统的规模律，表明任务复杂性如何驱动感觉能力和计算能力的协调进化。我们的研究引入了一种新的范式，通过创建目标明确的单人游戏来阐明塑造视觉的进化原理，这些在游戏中，身体代理必须同时进化视觉系统并学习复杂行为。通过我们统一的遗传编码框架，这些身体代理成为新一代的假设检验机器，并为设计制造可实现的生物启发式视觉系统提供了基础。', 'title_zh': '《如果眼睛...？计算再现视觉进化》\n\n这个标题是一个类似于科幻作品中提问的形式，尝试以科幻的方式探讨视觉进化的计算模拟。在翻译时，尽可能保留原文的疑问性和创新思维，同时使其符合中文的学术表达习惯。'}
{'arxiv_id': 'arXiv:2501.16288', 'title': 'Upside Down Reinforcement Learning with Policy Generators', 'authors': 'Jacopo Di Ventura, Dylan R. Ashley, Francesco Faccio, Vincent Herrmann, Jürgen Schmidhuber', 'link': 'https://arxiv.org/abs/2501.16288', 'abstract': 'Upside Down Reinforcement Learning (UDRL) is a promising framework for solving reinforcement learning problems which focuses on learning command-conditioned policies. In this work, we extend UDRL to the task of learning a command-conditioned generator of deep neural network policies. We accomplish this using Hypernetworks - a variant of Fast Weight Programmers, which learn to decode input commands representing a desired expected return into command-specific weight matrices. Our method, dubbed Upside Down Reinforcement Learning with Policy Generators (UDRLPG), streamlines comparable techniques by removing the need for an evaluator or critic to update the weights of the generator. To counteract the increased variance in last returns caused by not having an evaluator, we decouple the sampling probability of the buffer from the absolute number of policies in it, which, together with a simple weighting strategy, improves the empirical convergence of the algorithm. Compared with existing algorithms, UDRLPG achieves competitive performance and high returns, sometimes outperforming more complex architectures. Our experiments show that a trained generator can generalize to create policies that achieve unseen returns zero-shot. The proposed method appears to be effective in mitigating some of the challenges associated with learning highly multimodal functions. Altogether, we believe that UDRLPG represents a promising step forward in achieving greater empirical sample efficiency in RL. A full implementation of UDRLPG is publicly available at this https URL', 'abstract_zh': '倒置强化学习（UDRL）是一种解决强化学习问题的有前景的框架，它侧重于学习命令条件下的策略。在本工作中，我们扩展了UDRL，使其能够学习一个命令条件下的深度神经网络策略生成器。我们通过使用Hypernetworks（一种快速权重编程器的变体）来实现这一点，Hypernetworks能够学习将表示期望回报的输入命令解码为特定于命令的权重矩阵。我们的方法被称为“倒置强化学习与策略生成器”（UDRLPG），通过消除需要评估器或评论家来更新生成器权重的需要，简化了相关技术。为了解决因缺乏评估器引起的最后一轮回报方差增加的问题，我们从缓冲区的采样概率中解耦绝对数量的策略，这与一个简单的权重策略结合，改善了算法的经验收敛性。与现有算法相比，UDRLPG实现了具有竞争力的性能和高回报，有时甚至优于更复杂的架构。我们的实验表明，训练后的生成器可以泛化以创建实现未见过的回报的策略，这是一种零样本的效果。所提出的方法似乎有助于缓解学习高度多模态函数的一些挑战。总的来说，我们认为UDRLPG代表了实现强化学习中更高经验样本效率的一个有前景的进步。完整的UDRLPG实现可以在此 <https://> 地址公开获取。', 'title_zh': '倒置强化学习中的策略生成器'}
{'arxiv_id': 'arXiv:2501.16224', 'title': 'Language-Based Bayesian Optimization Research Assistant (BORA)', 'authors': 'Abdoulatif Cissé, Xenophon Evangelopoulos, Vladimir V. Gusev, Andrew I. Cooper', 'link': 'https://arxiv.org/abs/2501.16224', 'abstract': 'Many important scientific problems involve multivariate optimization coupled with slow and laborious experimental measurements. These complex, high-dimensional searches can be defined by non-convex optimization landscapes that resemble needle-in-a-haystack surfaces, leading to entrapment in local minima. Contextualizing optimizers with human domain knowledge is a powerful approach to guide searches to localized fruitful regions. However, this approach is susceptible to human confirmation bias and it is also challenging for domain experts to keep track of the rapidly expanding scientific literature. Here, we propose the use of Large Language Models (LLMs) for contextualizing Bayesian optimization (BO) via a hybrid optimization framework that intelligently and economically blends stochastic inference with domain knowledge-based insights from the LLM, which is used to suggest new, better-performing areas of the search space for exploration. Our method fosters user engagement by offering real-time commentary on the optimization progress, explaining the reasoning behind the search strategies. We validate the effectiveness of our approach on synthetic benchmarks with up to 15 independent variables and demonstrate the ability of LLMs to reason in four real-world experimental tasks where context-aware suggestions boost optimization performance substantially.', 'abstract_zh': '许多重要的科学问题涉及多变量优化与缓慢且繁琐的实验测量相结合。这类复杂且高维度的搜索可以由非凸优化景观定义，其类似于针尖在干草堆上的表面，这可能导致陷入局部极小值。利用人类领域知识来上下文化优化器是一种强大的方法，可以引导搜索到局部具有成果的区域。然而，这种方法容易受到人类确认偏见的影响，并且对于领域专家来说，跟踪迅速扩展的科学文献也极具挑战性。在此，我们提出使用大型语言模型（LLMs）通过将随机推理与来自LLM的基于领域知识的见解智能而经济地结合的混合优化框架，来上下文化贝叶斯优化（BO）。LLM用于建议搜索空间中新的、表现更好的区域以进行探索。我们的方法通过提供实时的优化进展评论来促进用户的参与，并解释搜索策略背后的推理。我们在多达15个独立变量的合成基准上验证了我们方法的有效性，并在四个真实世界的实验任务中展示了LLM能够基于上下文提供建议以大大提升优化性能的能力。', 'title_zh': '语言驱动的贝叶斯优化研究助手（BORA）'}
{'arxiv_id': 'arXiv:2501.15695', 'title': 'Contextual Knowledge Sharing in Multi-Agent Reinforcement Learning with Decentralized Communication and Coordination', 'authors': 'Hung Du, Srikanth Thudumu, Hy Nguyen, Rajesh Vasa, Kon Mouzakis', 'link': 'https://arxiv.org/abs/2501.15695', 'abstract': "Decentralized Multi-Agent Reinforcement Learning (Dec-MARL) has emerged as a pivotal approach for addressing complex tasks in dynamic environments. Existing Multi-Agent Reinforcement Learning (MARL) methodologies typically assume a shared objective among agents and rely on centralized control. However, many real-world scenarios feature agents with individual goals and limited observability of other agents, complicating coordination and hindering adaptability. Existing Dec-MARL strategies prioritize either communication or coordination, lacking an integrated approach that leverages both. This paper presents a novel Dec-MARL framework that integrates peer-to-peer communication and coordination, incorporating goal-awareness and time-awareness into the agents' knowledge-sharing processes. Our framework equips agents with the ability to (i) share contextually relevant knowledge to assist other agents, and (ii) reason based on information acquired from multiple agents, while considering their own goals and the temporal context of prior knowledge. We evaluate our approach through several complex multi-agent tasks in environments with dynamically appearing obstacles. Our work demonstrates that incorporating goal-aware and time-aware knowledge sharing significantly enhances overall performance.", 'abstract_zh': '去中心化多智能体强化学习（Decentralized Multi-Agent Reinforcement Learning, Dec-MARL）已成为解决动态环境中复杂任务的关键方法。现有的多智能体强化学习（Multi-Agent Reinforcement Learning, MARL）方法通常假定智能体之间共享目标，并依赖于中心化的控制。然而，许多实际场景中，智能体具有独立的目标，并且对其他智能体的可观测性有限，这使得协调变得复杂，并阻碍了适应性。现有的去中心化多智能体强化学习策略更侧重于通信或协调，缺乏一个既能利用两者优势的综合方法。本文提出了一种新的Dec-MARL框架，该框架将点对点通信与协调相结合，并将目标意识和时间意识融入智能体的知识共享过程中。该框架使得智能体能够：\n(i) 共享上下文相关知识以帮助其他智能体；\n(ii) 基于从多个智能体获取的信息进行推理，同时考虑自身目标和先前知识的时间背景。\n\n我们通过在动态障碍环境中执行的多种复杂多智能体任务来评估该方法。我们的研究表明，结合目标意识和时间意识的知识共享显著提高了整体性能。', 'title_zh': '基于分散通信与协调的多智能体强化学习中的上下文知识共享'}
{'arxiv_id': 'arXiv:2501.15564', 'title': 'Diffusion-Based Planning for Autonomous Driving with Flexible Guidance', 'authors': 'Yinan Zheng, Ruiming Liang, Kexin Zheng, Jinliang Zheng, Liyuan Mao, Jianxiong Li, Weihao Gu, Rui Ai, Shengbo Eben Li, Xianyuan Zhan, Jingjing Liu', 'link': 'https://arxiv.org/abs/2501.15564', 'abstract': 'Achieving human-like driving behaviors in complex open-world environments is a critical challenge in autonomous driving. Contemporary learning-based planning approaches such as imitation learning methods often struggle to balance competing objectives and lack of safety assurance,due to limited adaptability and inadequacy in learning complex multi-modal behaviors commonly exhibited in human planning, not to mention their strong reliance on the fallback strategy with predefined rules. We propose a novel transformer-based Diffusion Planner for closed-loop planning, which can effectively model multi-modal driving behavior and ensure trajectory quality without any rule-based refinement. Our model supports joint modeling of both prediction and planning tasks under the same architecture, enabling cooperative behaviors between vehicles. Moreover, by learning the gradient of the trajectory score function and employing a flexible classifier guidance mechanism, Diffusion Planner effectively achieves safe and adaptable planning behaviors. Evaluations on the large-scale real-world autonomous planning benchmark nuPlan and our newly collected 200-hour delivery-vehicle driving dataset demonstrate that Diffusion Planner achieves state-of-the-art closed-loop performance with robust transferability in diverse driving styles.', 'abstract_zh': '在复杂开放世界环境中实现类人的驾驶行为是自动驾驶领域的一项关键挑战。当前基于学习的规划方法，如模仿学习方法，往往难以平衡竞争性目标，缺乏安全性保证，这是由于其适应性有限以及在学习人类规划中常见的复杂多模态行为方面能力不足，更不用说它们对预先定义规则的强烈依赖。我们提出了一种新型的基于变换器的扩散规划器，该规划器可以在闭环规划中有效地建模多模态驾驶行为，并在不依赖任何基于规则的细化的情况下确保轨迹质量。我们的模型支持在同一架构下同时建模预测和规划任务，从而实现车辆之间的协同行为。此外，通过学习轨迹得分函数的梯度并采用灵活的分类器指导机制，扩散规划器有效实现了安全和适应性强的规划行为。在大规模真实世界的自主规划基准nuPlan和我们新收集的200小时的配送车辆驾驶数据集上的评估显示，扩散规划器在不同的驾驶风格下表现出强大的泛化能力，实现了最先进的闭环性能。', 'title_zh': '基于扩散模型的自主驾驶灵活指引规划方法'}
{'arxiv_id': 'arXiv:2501.15355', 'title': 'Large Language Models as Theory of Mind Aware Generative Agents with Counterfactual Reflection', 'authors': 'Bo Yang, Jiaxian Guo, Yusuke Iwasawa, Yutaka Matsuo', 'link': 'https://arxiv.org/abs/2501.15355', 'abstract': "Recent studies have increasingly demonstrated that large language models (LLMs) possess significant theory of mind (ToM) capabilities, showing the potential for simulating the tracking of mental states in generative agents. In this study, we propose a novel paradigm called ToM-agent, designed to empower LLMs-based generative agents to simulate ToM in open-domain conversational interactions. ToM-agent disentangles the confidence from mental states, facilitating the emulation of an agent's perception of its counterpart's mental states, such as beliefs, desires, and intentions (BDIs). Using past conversation history and verbal reflections, ToM-Agent can dynamically adjust counterparts' inferred BDIs, along with related confidence levels. We further put forth a counterfactual intervention method that reflects on the gap between the predicted responses of counterparts and their real utterances, thereby enhancing the efficiency of reflection. Leveraging empathetic and persuasion dialogue datasets, we assess the advantages of implementing the ToM-agent with downstream tasks, as well as its performance in both the first-order and the \\textit{second-order} ToM. Our findings indicate that the ToM-agent can grasp the underlying reasons for their counterpart's behaviors beyond mere semantic-emotional supporting or decision-making based on common sense, providing new insights for studying large-scale LLMs-based simulation of human social behaviors.", 'abstract_zh': '近年来，大量研究表明大型语言模型（LLMs）具备显著的理论心智（ToM）能力，显示出在生成代理中模拟追踪心智状态的潜在可能性。在此研究中，我们提出了一种名为ToM-agent的新范式，旨在赋予基于LLMs的生成代理模拟ToM的能力，特别是在开放式领域对话交互中的应用。ToM-agent将信心与心智状态分离，促进代理对其对应方的心智状态（如信念、欲望和意图，BDIs）感知的模拟。利用过去的对话历史和言语反思，ToM-Agent可以动态调整对对应方的推断BDIs及其相关信心水平进行调整。我们还提出了一个假设干预方法，通过反映预测响应与实际言辞之间的差距，从而增强反思效率。借助同理心和说服性对话数据集，我们评估了实施ToM-agent在下游任务中的优势，以及其在一级和二级ToM中的性能表现。我们的研究表明，ToM-agent能够把握对应方行为背后的根本原因，而不仅仅依赖于语义情感支撑或基于常识的决策制定，为研究大规模LLMs基于的心智模型模拟人类社会行为提供了新的视角。', 'title_zh': '大型语言模型作为具备反事实反思能力的理论理解生成代理'}
{'arxiv_id': 'arXiv:2501.15198', 'title': 'Towards Conscious Service Robots', 'authors': 'Sven Behnke', 'link': 'https://arxiv.org/abs/2501.15198', 'abstract': "Deep learning's success in perception, natural language processing, etc. inspires hopes for advancements in autonomous robotics. However, real-world robotics face challenges like variability, high-dimensional state spaces, non-linear dependencies, and partial observability. A key issue is non-stationarity of robots, environments, and tasks, leading to performance drops with out-of-distribution data. Unlike current machine learning models, humans adapt quickly to changes and new tasks due to a cognitive architecture that enables systematic generalization and meta-cognition. Human brain's System 1 handles routine tasks unconsciously, while System 2 manages complex tasks consciously, facilitating flexible problem-solving and self-monitoring. For robots to achieve human-like learning and reasoning, they need to integrate causal models, working memory, planning, and metacognitive processing. By incorporating human cognition insights, the next generation of service robots will handle novel situations and monitor themselves to avoid risks and mitigate errors.", 'abstract_zh': '深度学习在感知、自然语言处理等方面的成功激发了对自主机器人技术进步的希望。然而，现实中的机器人面临着变异性、高维状态空间、非线性依赖性和部分可观测性的挑战。一个关键问题是机器人、环境和任务的非稳定性，这会导致在非分布数据下的性能下降。与当前的机器学习模型不同，人类能够迅速适应变化和新任务，这得益于一种认知架构，使人类能够进行系统化泛化和元认知。人类的大脑中的系统1无意识地处理常规任务，而系统2则有意识地处理复杂任务，从而促进灵活的问题解决和自我监控。为了使机器人具备类似人类的学习和推理能力，它们需要结合因果模型、工作记忆、规划和元认知处理。通过融合人类的认知洞察，下一代服务机器人将能够应对新型情境并自我监控以避免风险、减少错误。', 'title_zh': '朝向有意识的服务机器人'}
{'arxiv_id': 'arXiv:2501.14844', 'title': 'Unmasking Conversational Bias in AI Multiagent Systems', 'authors': 'Erica Coppolillo, Giuseppe Manco, Luca Maria Aiello', 'link': 'https://arxiv.org/abs/2501.14844', 'abstract': 'Detecting biases in the outputs produced by generative models is essential to reduce the potential risks associated with their application in critical settings. However, the majority of existing methodologies for identifying biases in generated text consider the models in isolation and neglect their contextual applications. Specifically, the biases that may arise in multi-agent systems involving generative models remain under-researched. To address this gap, we present a framework designed to quantify biases within multi-agent systems of conversational Large Language Models (LLMs). Our approach involves simulating small echo chambers, where pairs of LLMs, initialized with aligned perspectives on a polarizing topic, engage in discussions. Contrary to expectations, we observe significant shifts in the stance expressed in the generated messages, particularly within echo chambers where all agents initially express conservative viewpoints, in line with the well-documented political bias of many LLMs toward liberal positions. Crucially, the bias observed in the echo-chamber experiment remains undetected by current state-of-the-art bias detection methods that rely on questionnaires. This highlights a critical need for the development of a more sophisticated toolkit for bias detection and mitigation for AI multi-agent systems. The code to perform the experiments is publicly available at this https URL.', 'abstract_zh': '检测生成模型输出中的偏见对于降低其在关键应用场景中的潜在风险至关重要。然而，大多数现有的偏见检测方法仅在孤立状态下分析这些模型，忽视了它们的上下文应用。特别是，在涉及生成模型的多智能体系统中可能出现的偏见仍未得到充分研究。为填补这一空白，我们提出了一种框架，用于量化多智能体系统中的对话型大型语言模型（LLMs）中的偏见。我们的方法涉及模拟小规模的回声室，在这种回声室中，以一个极化的主题为基础，以具有相同观点的两个LLM对进行互动交流。出人意料的是，我们在回声室中观察到生成消息所表达立场的显著变化，特别是在所有智能体最初都表达保守观点的回声室中，这与许多LLM已充分记录的政治偏见（指向更自由的政治立场）相符。更重要的是，目前依赖问卷的最先进的偏见检测方法无法检测回声室实验中的这种偏见。这凸显了为AI多智能体系统开发更强大的偏见检测和缓解工具的重要性。实验代码已在以下网址公开：[这个 https URL](这个 https URL)。', 'title_zh': '揭示AI多智能体系统中的对话偏见'}
{'arxiv_id': 'arXiv:2501.14772', 'title': 'DropMicroFluidAgents (DMFAs): Autonomous Droplet Microfluidic Research Framework Through Large Language Model Agents', 'authors': 'Dinh-Nguyen Nguyen, Raymond Kai-Yu Tong, Ngoc-Duy Dinh', 'link': 'https://arxiv.org/abs/2501.14772', 'abstract': 'Applying Large language models (LLMs) within specific domains requires substantial adaptation to account for the unique terminologies, nuances, and context-specific challenges inherent to those areas. Here, we introduce DropMicroFluidAgents (DMFAs), an advanced language-driven framework leveraging state-of-the-art pre-trained LLMs. DMFAs employs LLM agents to perform two key functions: (1) delivering focused guidance, answers, and suggestions specific to droplet microfluidics and (2) generating machine learning models to optimise and automate the design of droplet microfluidic devices, including the creation of code-based computer-aided design (CAD) scripts to enable rapid and precise design execution. Experimental evaluations demonstrated that the integration of DMFAs with the LLAMA3.1 model yielded the highest accuracy of 76.15%, underscoring the significant performance enhancement provided by agent integration. This effect was particularly pronounced when DMFAs were paired with the GEMMA2 model, resulting in a 34.47% improvement in accuracy compared to the standalone GEMMA2 configuration. This study demonstrates the effective use of LLM agents in droplet microfluidics research as powerful tools for automating workflows, synthesising knowledge, optimising designs, and interacting with external systems. These capabilities enable their application across education and industrial support, driving greater efficiency in scientific discovery and innovation.', 'abstract_zh': '将下面的论文内容或标题翻译成中文，符合学术规范：\n\n在特定领域应用大型语言模型（LLMs）需要进行大量的适应，以应对这些领域内独特的术语、细微差别和情境特定的挑战。本文介绍了DropMicroFluidAgents（DMFAs），这是一种利用最新预训练LLMs的先进语言驱动框架。DMFAs 通过LLMs代理执行两个关键功能：（1）提供针对微液滴微流控领域的集中指导、回答和建议；（2）生成机器学习模型以优化和自动化微液滴微流控装置的设计，包括生成基于代码的计算机辅助设计（CAD）脚本，以实现快速和精确的设计执行。实验评估表明，将DMFAs 与LLAMA3.1模型结合使用，能够获得最高的准确率76.15%，突显了代理集成提供的显著性能提升。当DMFAs 与GEMMA2模型配对时，其准确率提高了34.47%，超过了仅使用GEMMA2配置的情况。研究证明了在微液滴微流控研究中有效使用LLMs代理作为自动化工序的强大工具，能够整合知识、优化设计，并与外部系统交互。这些能力使得它们能够在教育和工业支持中得到应用，促进科学研究和创新效率的提升。', 'title_zh': 'DropMicroFluidAgents (DMFAs): 通过大型语言模型代理实现的自主液滴微流控研究框架'}
{'arxiv_id': 'arXiv:2501.14737', 'title': 'EvalSVA: Multi-Agent Evaluators for Next-Gen Software Vulnerability Assessment', 'authors': 'Xin-Cheng Wen, Jiaxin Ye, Cuiyun Gao, Lianwei Wu, Qing Liao', 'link': 'https://arxiv.org/abs/2501.14737', 'abstract': 'Software Vulnerability (SV) assessment is a crucial process of determining different aspects of SVs (e.g., attack vectors and scope) for developers to effectively prioritize efforts in vulnerability mitigation. It presents a challenging and laborious process due to the complexity of SVs and the scarcity of labeled data. To mitigate the above challenges, we introduce EvalSVA, a multi-agent evaluators team to autonomously deliberate and evaluate various aspects of SV assessment. Specifically, we propose a multi-agent-based framework to simulate vulnerability assessment strategies in real-world scenarios, which employs multiple Large Language Models (LLMs) into an integrated group to enhance the effectiveness of SV assessment in the limited data. We also design diverse communication strategies to autonomously discuss and assess different aspects of SV. Furthermore, we construct a multi-lingual SV assessment dataset based on the new standard of CVSS, comprising 699, 888, and 1,310 vulnerability-related commits in C++, Python, and Java, respectively. Our experimental results demonstrate that EvalSVA averagely outperforms the 44.12\\% accuracy and 43.29\\% F1 for SV assessment compared with the previous methods. It shows that EvalSVA offers a human-like process and generates both reason and answer for SV assessment. EvalSVA can also aid human experts in SV assessment, which provides more explanation and details for SV assessment.', 'abstract_zh': '软件漏洞（SV）评估是确定不同方面漏洞（例如攻击向量和影响范围）的重要过程，旨在帮助开发者有效优先考虑漏洞缓解工作。这一过程由于漏洞的复杂性和标注数据的稀缺性而变得具有挑战性和繁琐。为了应对上述挑战，我们引入了EvalSVA，这是一个自主讨论和评估漏洞评估各种方面的一组多智能体评价者团队。具体而言，我们提出了一种基于多智能体的框架，在实际场景中模拟漏洞评估策略，该框架通过将多个大型语言模型（LLMs）整合到一个小组中，增强了在数据有限情况下的漏洞评估效果。我们还设计了多种通信策略，以自主讨论和评估不同方面漏洞。此外，我们根据新的CVSS标准构建了一个多语言漏洞评估数据集，其中包含C++、Python和Java语言中分别共计699,888个和1,310个漏洞相关提交记录。实验结果显示，EvalSVA相比之前的评估方法，在漏洞评估准确性和F1分数上平均高出44.12%和43.29%。这表明EvalSVA提供了类似人类的过程，并为漏洞评估生成了合理性和答案。同时，EvalSVA也可以帮助人类专家进行漏洞评估，提供更详细的解释和信息。', 'title_zh': 'EvalSVA：面向下一代软件漏洞评估的多agent评估器'}
{'arxiv_id': 'arXiv:2501.14734', 'title': 'Research on the Application of Spark Streaming Real-Time Data Analysis System and large language model Intelligent Agents', 'authors': 'Jialin Wang, Zhihua Duan', 'link': 'https://arxiv.org/abs/2501.14734', 'abstract': "This study explores the integration of Agent AI with LangGraph to enhance real-time data analysis systems in big data environments. The proposed framework overcomes limitations of static workflows, inefficient stateful computations, and lack of human intervention by leveraging LangGraph's graph-based workflow construction and dynamic decision-making capabilities. LangGraph allows large language models (LLMs) to dynamically determine control flows, invoke tools, and assess the necessity of further actions, improving flexibility and efficiency.\nThe system architecture incorporates Apache Spark Streaming, Kafka, and LangGraph to create a high-performance sentiment analysis system. LangGraph's capabilities include precise state management, dynamic workflow construction, and robust memory checkpointing, enabling seamless multi-turn interactions and context retention. Human-in-the-loop mechanisms are integrated to refine sentiment analysis, particularly in ambiguous or high-stakes scenarios, ensuring greater reliability and contextual relevance.\nKey features such as real-time state streaming, debugging via LangGraph Studio, and efficient handling of large-scale data streams make this framework ideal for adaptive decision-making. Experimental results confirm the system's ability to classify inquiries, detect sentiment trends, and escalate complex issues for manual review, demonstrating a synergistic blend of LLM capabilities and human oversight.\nThis work presents a scalable, adaptable, and reliable solution for real-time sentiment analysis and decision-making, advancing the use of Agent AI and LangGraph in big data applications.", 'abstract_zh': '本研究探讨了在大数据环境中通过将代理AI与LangGraph结合来增强实时数据分析系统的可能性。所提出的框架克服了静态工作流、低效的状态计算以及缺乏人工干预的限制，通过利用LangGraph基于图的工作流构建能力和动态决策能力。LangGraph使大型语言模型（LLMs）能够动态确定控制流、调用工具并评估进一步行动的必要性，从而提高灵活性和效率。\n\n该系统架构集成了Apache Spark Streaming、Kafka和LangGraph，以创建高性能的情绪分析系统。LangGraph的功能包括精确的状态管理、动态工作流构建和强大的内存快照功能，能够实现无缝的多轮交互和上下文保留。将人工干预机制融入系统，尤其是在含义模糊或高风险的情景下，进一步细化情绪分析，确保更高的可靠性和相关性。\n\n系统的关键功能包括实时状态流、通过LangGraph Studio进行调试以及高效处理大规模数据流，使该框架成为适应性决策的理想选择。实验结果证实了该系统的分类查询、检测情绪趋势以及将复杂问题提交人工审查的能力，展示了LLMs能力和人工监督的协同作用。\n\n本研究提出了一个可扩展、适应性强且可靠的情绪分析及决策解决方案，推动了代理AI和LangGraph在大数据应用中的应用。', 'title_zh': '研究Spark Streaming实时数据分析系统与大型语言模型智能代理的应用'}
{'arxiv_id': 'arXiv:2501.15228', 'title': 'Improving Retrieval-Augmented Generation through Multi-Agent Reinforcement Learning', 'authors': 'Yiqun Chen, Lingyong Yan, Weiwei Sun, Xinyu Ma, Yi Zhang, Shuaiqiang Wang, Dawei Yin, Yiming Yang, Jiaxin Mao', 'link': 'https://arxiv.org/abs/2501.15228', 'abstract': "Retrieval-augmented generation (RAG) is extensively utilized to incorporate external, current knowledge into large language models, thereby minimizing hallucinations. A standard RAG pipeline may comprise several components, such as query rewriting, document retrieval, document filtering, and answer generation. However, these components are typically optimized separately through supervised fine-tuning, which can lead to misalignments between the objectives of individual modules and the overarching aim of generating accurate answers in question-answering (QA) tasks. Although recent efforts have explored reinforcement learning (RL) to optimize specific RAG components, these approaches often focus on overly simplistic pipelines with only two components or do not adequately address the complex interdependencies and collaborative interactions among the modules. To overcome these challenges, we propose treating the RAG pipeline as a multi-agent cooperative task, with each component regarded as an RL agent. Specifically, we present MMOA-RAG, a Multi-Module joint Optimization Algorithm for RAG, which employs multi-agent reinforcement learning to harmonize all agents' goals towards a unified reward, such as the F1 score of the final answer. Experiments conducted on various QA datasets demonstrate that MMOA-RAG improves the overall pipeline performance and outperforms existing baselines. Furthermore, comprehensive ablation studies validate the contributions of individual components and the adaptability of MMOA-RAG across different RAG components and datasets. The code of MMOA-RAG is on this https URL.", 'abstract_zh': '检索增强生成（RAG）被广泛应用于将外部和最新的知识整合到大型语言模型中，从而减少幻觉的产生。标准的RAG管道可能包括多个组件，如查询重写、文档检索、文档过滤和答案生成。然而，这些组件通常通过有监督微调分别优化，这可能导致各个模块的目标与生成准确答案的整体目标之间的对齐问题。尽管最近的研究尝试使用强化学习（RL）来优化特定的RAG组件，但这些方法往往集中在过于简单的管道设计上，只包含两个组件，或者未能充分解决模块之间复杂相互依赖性和协作交互的问题。为了克服这些挑战，我们提出将RAG管道视为多智能体协作任务，并将每个组件视为一个RL智能体。具体而言，我们提出了MMOA-RAG，这是一种用于RAG的多模块联合优化算法，利用多智能体强化学习将所有智能体的目标协调至统一的奖励，例如最终答案的F1分数。在多个问答数据集上的实验表明，MMOA-RAG提高了整个管道的性能，并优于现有基线。进一步的消融研究验证了各组件的贡献以及MMOA-RAG在不同RAG组件和数据集上的适应性。MMOA-RAG的代码请参见此链接：[此处的链接]。', 'title_zh': '通过多智能体强化学习提升检索增强生成'}
{'arxiv_id': 'arXiv:2501.16327', 'title': 'LUCY: Linguistic Understanding and Control Yielding Early Stage of Her', 'authors': 'Heting Gao, Hang Shao, Xiong Wang, Chaofan Qiu, Yunhang Shen, Siqi Cai, Yuchen Shi, Zihan Xu, Zuwei Long, Yike Zhang, Shaoqi Dong, Chaoyou Fu, Ke Li, Long Ma, Xing Sun', 'link': 'https://arxiv.org/abs/2501.16327', 'abstract': "The film Her features Samantha, a sophisticated AI audio agent who is capable of understanding both linguistic and paralinguistic information in human speech and delivering real-time responses that are natural, informative and sensitive to emotional subtleties. Moving one step toward more sophisticated audio agent from recent advancement in end-to-end (E2E) speech systems, we propose LUCY, a E2E speech model that (1) senses and responds to user's emotion, (2) deliver responses in a succinct and natural style, and (3) use external tool to answer real-time inquiries. Experiment results show that LUCY is better at emotion control than peer models, generating emotional responses based on linguistic emotional instructions and responding to paralinguistic emotional cues. Lucy is also able to generate responses in a more natural style, as judged by external language models, without sacrificing much performance on general question answering. Finally, LUCY can leverage function calls to answer questions that are out of its knowledge scope.", 'abstract_zh': '电影《她》中的萨曼莎是一个复杂的AI语音代理，能够理解人类语言和副语言信息，并提供自然、信息丰富且对情感细微变化敏感的即时回应。从近年来端到端（E2E）语音系统的发展中进一步提升语音代理的复杂性，我们提出了一种E2E语音模型LUCY，该模型具有以下特征：（1）感知并响应用户的情感；（2）以简洁且自然的方式提供回应；（3）使用外部工具即时回答查询。实验结果表明，LUCY在情感控制方面优于其他模型，能够根据语言情感指令生成相应的情感回应，并响应副语言情感提示。LUCY还能在不牺牲一般问题回答性能的情况下，以更自然的风格生成回应。最后，LUCY可以通过功能调用回答超出其知识范围的问题。', 'title_zh': 'LUCY：语言理解和控制在她早期阶段的作用'}
{'arxiv_id': 'arXiv:2501.15826', 'title': 'MADP: Multi-Agent Deductive Planning for Enhanced Cognitive-Behavioral Mental Health Question Answer', 'authors': 'Qi Chen, Dexi Liu', 'link': 'https://arxiv.org/abs/2501.15826', 'abstract': "The Mental Health Question Answer (MHQA) task requires the seeker and supporter to complete the support process in one-turn dialogue. Given the richness of help-seeker posts, supporters must thoroughly understand the content and provide logical, comprehensive, and well-structured responses. Previous works in MHQA mostly focus on single-agent approaches based on the cognitive element of Cognitive Behavioral Therapy (CBT), but they overlook the interactions among various CBT elements, such as emotion and cognition. This limitation hinders the models' ability to thoroughly understand the distress of help-seekers. To address this, we propose a framework named Multi-Agent Deductive Planning (MADP), which is based on the interactions between the various psychological elements of CBT. This method guides Large Language Models (LLMs) to achieve a deeper understanding of the seeker's context and provide more personalized assistance based on individual circumstances. Furthermore, we construct a new dataset based on the MADP framework and use it to fine-tune LLMs, resulting in a specialized model named MADP-LLM. We conduct extensive experiments, including comparisons with multiple LLMs, human evaluations, and automatic evaluations, to validate the effectiveness of the MADP framework and MADP-LLM.", 'abstract_zh': '认知行为疗法（CBT）要素下的心理卫生问答（MHQA）任务要求求助者和支持者在一次对话中完成支持过程。鉴于求助者的帖子内容丰富，支持者必须全面理解内容并提供逻辑性强、系统全面且结构良好的回复。以前的MHQA研究主要集中在基于CBT认知要素的单智能体方法上，但它们忽略了CBT中各种要素之间的交互，如情绪和认知。这一限制妨碍了模型全面理解求助者的困扰能力。为解决这一问题，我们提出了一种名为多智能体演绎规划（MADP）的框架，该框架基于CBT的各种心理要素之间的交互。该方法引导大规模语言模型（LLMs）更深入地理解求助者的背景，并根据个人情况提供更加个性化的帮助。此外，我们基于MADP框架构建了一个新的数据集，并使用该数据集对LLMs进行微调，从而创建了一种专门的模型MADP-LLM。我们进行了广泛实证研究，包括与多种LLMs的对比、人工评估和自动评估，以验证MADP框架和MADP-LLM的有效性。', 'title_zh': 'MADP：增强认知行为心理健康问答的多智能体演绎规划'}
{'arxiv_id': 'arXiv:2501.15283', 'title': 'Are Human Interactions Replicable by Generative Agents? A Case Study on Pronoun Usage in Hierarchical Interactions', 'authors': 'Naihao Deng, Rada Mihalcea', 'link': 'https://arxiv.org/abs/2501.15283', 'abstract': "As Large Language Models (LLMs) advance in their capabilities, researchers have increasingly employed them for social simulation. In this paper, we investigate whether interactions among LLM agents resemble those of humans. Specifically, we focus on the pronoun usage difference between leaders and non-leaders, examining whether the simulation would lead to human-like pronoun usage patterns during the LLMs' interactions. Our evaluation reveals the significant discrepancies between LLM-based simulations and human pronoun usage, with prompt-based or specialized agents failing to demonstrate human-like pronoun usage patterns. In addition, we reveal that even if LLMs understand the human pronoun usage patterns, they fail to demonstrate them in the actual interaction process. Our study highlights the limitations of social simulations based on LLM agents, urging caution in using such social simulation in practitioners' decision-making process.", 'abstract_zh': '随着大型语言模型（LLMs）能力的不断提升，研究人员越来越多地利用它们进行社会仿真。在本文中，我们探讨LLM代理之间的互动是否类似于人类的互动。具体而言，我们关注领导者和非领导者在代词使用上的差异，研究社会仿真是否会促使LLMs在互动过程中表现出类似人类的代词使用模式。我们的评估揭示了基于LLM的社会仿真的代词使用模式与人类代词使用模式之间存在显著差异，以提示为基础或专门化的代理未能表现出类似人类的代词使用模式。此外，我们还发现即使LLM理解了人类的代词使用模式，它们在实际互动过程中也无法表现出这种模式。本研究强调了基于LLM代理的社会仿真的局限性，提醒在实际应用中应谨慎使用此类社会仿真辅助决策过程。', 'title_zh': '生成代理能否重现人类互动？层级互动中代词使用案例研究'}
