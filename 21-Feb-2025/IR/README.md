# A Survey of Model Architectures in Information Retrieval 

**Title (ZH)**: 信息检索中模型架构的综述 

**Authors**: Zhichao Xu, Fengran Mo, Zhiqi Huang, Crystina Zhang, Puxuan Yu, Bei Wang, Jimmy Lin, Vivek Srikumar  

**Link**: [PDF](https://arxiv.org/pdf/2502.14822)  

**Abstract**: This survey examines the evolution of model architectures in information retrieval (IR), focusing on two key aspects: backbone models for feature extraction and end-to-end system architectures for relevance estimation. The review intentionally separates architectural considerations from training methodologies to provide a focused analysis of structural innovations in IR this http URL trace the development from traditional term-based methods to modern neural approaches, particularly highlighting the impact of transformer-based models and subsequent large language models (LLMs). We conclude by discussing emerging challenges and future directions, including architectural optimizations for performance and scalability, handling of multimodal, multilingual data, and adaptation to novel application domains beyond traditional search paradigms. 

**Abstract (ZH)**: 这篇综述探讨了信息检索（IR）中模型架构的发展演变，重点关注两个关键方面：用于特征提取的骨干模型和用于相关性评估的端到端系统架构。回顾特意将架构考虑与训练方法分开，以提供对IR中结构创新的重点分析。本文追溯了从传统基于词的方法到现代神经方法的发展，特别是突出了基于变压器的模型及其后续的大规模语言模型（LLMs）的影响。我们最后讨论了新兴挑战和未来方向，包括提高性能和扩展性的架构优化、跨模态和多语言数据的处理，以及适应传统搜索范式之外的新应用领域。 

---
# A Multi-Agent Perspective on Modern Information Retrieval 

**Title (ZH)**: 现代信息检索的多agent视角 

**Authors**: Haya Nachimovsky, Moshe Tennenholtz, Oren Kurland  

**Link**: [PDF](https://arxiv.org/pdf/2502.14796)  

**Abstract**: The rise of large language models (LLMs) has introduced a new era in information retrieval (IR), where queries and documents that were once assumed to be generated exclusively by humans can now also be created by automated agents. These agents can formulate queries, generate documents, and perform ranking. This shift challenges some long-standing IR paradigms and calls for a reassessment of both theoretical frameworks and practical methodologies. We advocate for a multi-agent perspective to better capture the complex interactions between query agents, document agents, and ranker agents. Through empirical exploration of various multi-agent retrieval settings, we reveal the significant impact of these interactions on system performance. Our findings underscore the need to revisit classical IR paradigms and develop new frameworks for more effective modeling and evaluation of modern retrieval systems. 

**Abstract (ZH)**: 大型语言模型（LLMs）的兴起为信息检索（IR）引入了一个新时代，其中原本认为仅由人类生成的查询和文档现在也可以由自动化代理生成。这些代理可以构建查询、生成文档并进行排序。这一转变挑战了一些长期存在的IR范式，并要求重新评估理论框架和实践方法。我们提倡从多代理视角出发，以更好地捕捉查询代理、文档代理和排序代理之间的复杂交互。通过探索各种多代理检索设置的实证研究，我们揭示了这些交互对系统性能的影响。我们的研究强调了重新审视经典IR范式和为现代检索系统的更有效建模和评估开发新框架的必要性。 

---
# EAGER-LLM: Enhancing Large Language Models as Recommenders through Exogenous Behavior-Semantic Integration 

**Title (ZH)**: EAGER-LLM：通过外生行为语义集成增强大型语言模型的推荐能力 

**Authors**: Minjie Hong, Yan Xia, Zehan Wang, Jieming Zhu, Ye Wang, Sihang Cai, Xiaoda Yang, Quanyu Dai, Zhenhua Dong, Zhimeng Zhang, Zhou Zhao  

**Link**: [PDF](https://arxiv.org/pdf/2502.14735)  

**Abstract**: Large language models (LLMs) are increasingly leveraged as foundational backbones in the development of advanced recommender systems, offering enhanced capabilities through their extensive knowledge and reasoning. Existing llm-based recommender systems (RSs) often face challenges due to the significant differences between the linguistic semantics of pre-trained LLMs and the collaborative semantics essential for RSs. These systems use pre-trained linguistic semantics but learn collaborative semantics from scratch via the llm-Backbone. However, LLMs are not designed for recommendations, leading to inefficient collaborative learning, weak result correlations, and poor integration of traditional RS features. To address these challenges, we propose EAGER-LLM, a decoder-only llm-based generative recommendation framework that integrates endogenous and exogenous behavioral and semantic information in a non-intrusive manner. Specifically, we propose 1)dual-source knowledge-rich item indices that integrates indexing sequences for exogenous signals, enabling efficient link-wide processing; 2)non-invasive multiscale alignment reconstruction tasks guide the model toward a deeper understanding of both collaborative and semantic signals; 3)an annealing adapter designed to finely balance the model's recommendation performance with its comprehension capabilities. We demonstrate EAGER-LLM's effectiveness through rigorous testing on three public benchmarks. 

**Abstract (ZH)**: 大型语言模型（LLMs）在先进推荐系统的发展中越来越多地被用作基础架构，通过其广泛的知识和推理能力提供了增强的功能。现有的基于LLM的推荐系统（RSs）往往面临挑战，因为预训练LLMs的语义与RSs所需的协作语义之间存在显著差异。这些系统利用预训练的语义，但通过LLM骨干重新学习协作语义。然而，LLMs并非为推荐设计，导致协作学习效率低下、结果相关性弱，传统RS特征的整合也不理想。为了解决这些挑战，我们提出了一种名为EAGER-LLM的解码器仅基于LLM的生成推荐框架，该框架以非侵入性的方式整合了内在和外在的行为和语义信息。具体而言，我们提出1）双源知识丰富的物品索引，不仅整合了对外部信号的索引序列，还使其能够高效地进行全局链接处理；2）非侵入性的多尺度对齐重建任务引导模型更深入地理解协作和语义信号；3）热化适配器，旨在精细平衡模型的推荐性能与理解能力。我们通过在三个公开基准上的严格测试展示了EAGER-LLM的有效性。 

---
# Efficient AI in Practice: Training and Deployment of Efficient LLMs for Industry Applications 

**Title (ZH)**: 高效人工智能在实践中的应用：面向工业应用的高效大型语言模型的训练与部署 

**Authors**: Kayhan Behdin, Yun Dai, Ata Fatahibaarzi, Aman Gupta, Qingquan Song, Shao Tang, Hejian Sang, Gregory Dexter, Sirou Zhu, Siyu Zhu, Tejas Dharamsi, Maziar Sanjabi, Vignesh Kothapalli, Hamed Firooz, Zhoutong Fu, Yihan Cao, Pin-Lun Hsu, Fedor Borisyuk, Zhipeng Wang, Rahul Mazumder, Natesh Pillai, Luke Simon  

**Link**: [PDF](https://arxiv.org/pdf/2502.14305)  

**Abstract**: Large language models (LLMs) have demonstrated remarkable performance across a wide range of industrial applications, from search and recommendations to generative tasks. Although scaling laws indicate that larger models generally yield better generalization and performance, their substantial computational requirements often render them impractical for many real-world scenarios at scale. In this paper, we present methods and insights for training small language models (SLMs) that deliver high performance and efficiency in deployment. We focus on two key techniques: (1) knowledge distillation and (2) model compression via quantization and pruning. These approaches enable SLMs to retain much of the quality of their larger counterparts while significantly reducing training, serving costs, and latency. We detail the impact of these techniques on a variety of use cases at a large professional social network platform and share deployment lessons - including hardware optimization strategies that enhance speed and throughput for both predictive and reasoning-based applications. 

**Abstract (ZH)**: 大规模语言模型（LLMs）已在搜索、推荐以及生成任务等多种工业应用场景中展示了出色的性能。尽管规模法则表明，更大的模型通常能提供更好的泛化能力和性能，但它们的计算需求往往使得它们在大规模实际应用中变得不切实际。在本文中，我们提出了训练小型语言模型（SLMs）的方法和见解，这些小型模型在部署中能够保持高性能和高效率。我们重点关注两种关键技术：（1）知识蒸馏和（2）通过量化和剪枝进行的模型压缩。这些方法使小型语言模型能够保留与其大型对应模型相当的质量，同时显著降低训练、服务成本和延迟。我们详细探讨了这些技术在一家大型专业社交网络平台上各种应用场景中的影响，并分享了部署经验——包括提高预测和推理应用中速度和吞吐量的硬件优化策略。 

---
# An Evaluation of Sakana's AI Scientist for Autonomous Research: Wishful Thinking or an Emerging Reality Towards 'Artificial General Research Intelligence' (AGRI)? 

**Title (ZH)**: 对Sakana的AI科学家进行自主研究评估：憧憬还是“通用人工智能研究智能”（AGRI）的新兴现实？ 

**Authors**: Joeran Beel, Min-Yen Kan, Moritz Baumgart  

**Link**: [PDF](https://arxiv.org/pdf/2502.14297)  

**Abstract**: A major step toward Artificial General Intelligence (AGI) and Super Intelligence is AI's ability to autonomously conduct research - what we term Artificial General Research Intelligence (AGRI). If machines could generate hypotheses, conduct experiments, and write research papers without human intervention, it would transform science. Recently, this http URL introduced the AI Scientist, a system claiming to automate the research lifecycle, generating both excitement and skepticism.
We evaluated the AI Scientist and found it a milestone in AI-driven research. While it streamlines some aspects, it falls short of expectations. Literature reviews are weak, nearly half the experiments failed, and manuscripts sometimes contain hallucinated results. Most notably, users must provide an experimental pipeline, limiting the AI Scientist's autonomy in research design and execution.
Despite its limitations, the AI Scientist advances research automation. Many reviewers or instructors who assess work superficially may not recognize its output as AI-generated. The system produces research papers with minimal human effort and low cost. Our analysis suggests a paper costs a few USD with a few hours of human involvement, making it significantly faster than human researchers. Compared to AI capabilities from a few years ago, this marks progress toward AGRI.
The rise of AI-driven research systems requires urgent discussion within Information Retrieval (IR) and broader scientific communities. Enhancing literature retrieval, citation validation, and evaluation benchmarks could improve AI-generated research reliability. We propose concrete steps, including AGRI-specific benchmarks, refined peer review, and standardized attribution frameworks. Whether AGRI becomes a stepping stone to AGI depends on how the academic and AI communities shape its development. 

**Abstract (ZH)**: 向通用人工智能（AGI）和超级智能迈出的重大一步是人工智能能够自主进行研究——我们称之为人工智能通用科研智能（AGRI）。如果机器能够在没有人类干预的情况下生成假设、进行实验并撰写研究论文，这将彻底改变科学研究的面貌。最近，这个问题链接介绍了一种称为“AI科学家”的系统，该系统声称能够自动化科研生命周期，引起了人们对该系统的兴趣和怀疑。

我们评估了AI科学家，并认为它在AI驱动的研究领域是一个重大里程碑。尽管它在某些方面简化了流程，但仍未能满足预期。文献综述能力较弱，几乎有一半的实验未成功，而部分文稿中还包含虚构的结果。最值得注意的是，用户必须提供实验管道，这限制了AI科学家在研究设计和执行方面的自主性。

尽管存在这些限制，AI科学家仍推动了科研自动化。很多仅对工作进行表面评估的审阅人或导师可能不会认识到其输出为人工智能生成。系统能够以较低的人力成本和成本快速生成研究论文。我们的分析显示，一篇论文仅需几小时的人力投入，成本在几美元左右，这比人类研究人员要快得多。相比于几年前的人工智能能力，这标志着向AGRI迈进了一步。

人工智能驱动的科研系统的发展要求信息检索（IR）和更广泛的科学界立即进行讨论。通过改进文献检索、引用验证和评价标准等，可以提高人工智能生成研究的可靠性。我们提出了一些具体的步骤，包括针对AGRI的特定基准、精炼的同行评审以及标准化的归因框架。AGRI是否成为通向AGI的一步，取决于学术界和人工智能社区如何塑造其发展。 

---
# Collaborative Retrieval for Large Language Model-based Conversational Recommender Systems 

**Title (ZH)**: 基于大型语言模型的对话推荐系统中的协作检索方法 

**Authors**: Yaochen Zhu, Chao Wan, Harald Steck, Dawen Liang, Yesu Feng, Nathan Kallus, Jundong Li  

**Link**: [PDF](https://arxiv.org/pdf/2502.14137)  

**Abstract**: Conversational recommender systems (CRS) aim to provide personalized recommendations via interactive dialogues with users. While large language models (LLMs) enhance CRS with their superior understanding of context-aware user preferences, they typically struggle to leverage behavioral data, which have proven to be important for classical collaborative filtering (CF)-based approaches. For this reason, we propose CRAG, Collaborative Retrieval Augmented Generation for LLM-based CRS. To the best of our knowledge, CRAG is the first approach that combines state-of-the-art LLMs with CF for conversational recommendations. Our experiments on two publicly available movie conversational recommendation datasets, i.e., a refined Reddit dataset (which we name Reddit-v2) as well as the Redial dataset, demonstrate the superior item coverage and recommendation performance of CRAG, compared to several CRS baselines. Moreover, we observe that the improvements are mainly due to better recommendation accuracy on recently released movies. The code and data are available at this https URL. 

**Abstract (ZH)**: 对话推荐系统（CRS）旨在通过与用户的交互对话提供个性化推荐。大型语言模型（LLMs）通过对其上下文感知用户偏好的深刻理解，增强了CRS的能力，但通常难以利用行为数据，而这些行为数据对于基于协作过滤（CF）的经典方法来说是非常重要的。鉴于此，我们提出了CRAG方法，即结合了大型语言模型与协作过滤的对话推荐增强生成方法。据我们所知，CRAG是第一个将最先进的大型语言模型与CF相结合以进行对话推荐的方法。我们在两个公开的电影对话推荐数据集上进行了实验，即经过精炼的Reddit数据集（我们命名为Reddit-v2）以及Redial数据集，结果显示，CRAG在项目覆盖范围和推荐性能方面显著优于几种基准对话推荐系统。此外，我们观察到，这些改进主要归因于在最近上映的电影上的推荐准确性提高。代码和数据可从以下链接获取：[这里提供的链接]。 

---
# Interpretable Text Embeddings and Text Similarity Explanation: A Primer 

**Title (ZH)**: 可解释的文本嵌入与文本相似性解释：一种入门指南 

**Authors**: Juri Opitz, Lucas Möller, Andrianos Michail, Simon Clematide  

**Link**: [PDF](https://arxiv.org/pdf/2502.14862)  

**Abstract**: Text embeddings and text embedding models are a backbone of many AI and NLP systems, particularly those involving search. However, interpretability challenges persist, especially in explaining obtained similarity scores, which is crucial for applications requiring transparency. In this paper, we give a structured overview of interpretability methods specializing in explaining those similarity scores, an emerging research area. We study the methods' individual ideas and techniques, evaluating their potential for improving interpretability of text embeddings and explaining predicted similarities. 

**Abstract (ZH)**: 文本嵌入和文本嵌入模型是许多AI和自然语言处理（NLP）系统的基础，尤其是在涉及搜索的应用中。然而，可解释性问题仍然存在，尤其是在解释获取的相似度分数方面尤为突出，这对于需要透明性的应用至关重要。在这篇论文中，我们给出了一个条理清晰的概述，专门探讨解释这些相似度分数的可解释性方法，这是新兴的研究领域。我们研究了这些方法的个体思想和技巧，并评估它们在提高文本嵌入的可解释性和解释预测相似度方面的潜力。 

---
# From Knowledge Generation to Knowledge Verification: Examining the BioMedical Generative Capabilities of ChatGPT 

**Title (ZH)**: 从知识生成到知识验证：考察ChatGPT在生物医药领域的生成能力 

**Authors**: Ahmed Abdeen Hamed, Byung Suk Lee  

**Link**: [PDF](https://arxiv.org/pdf/2502.14714)  

**Abstract**: The generative capabilities of LLM models present opportunities in accelerating tasks and concerns with the authenticity of the knowledge it produces. To address the concerns, we present a computational approach that systematically evaluates the factual accuracy of biomedical knowledge that an LLM model has been prompted to generate. Our approach encompasses two processes: the generation of disease-centric associations and the verification of them using the semantic knowledge of the biomedical ontologies. Using ChatGPT as the select LLM model, we designed a set of prompt-engineering processes to generate linkages between diseases, drugs, symptoms, and genes to establish grounds for assessments. Experimental results demonstrate high accuracy in identifying disease terms (88%-97%), drug names (90%-91%), and genetic information (88%-98%). The symptom term identification accuracy was notably lower (49%-61%), as verified against the DOID, ChEBI, SYMPTOM, and GO ontologies accordingly. The verification of associations reveals literature coverage rates of (89%-91%) among disease-drug and disease-gene associations. The low identification accuracy for symptom terms also contributed to the verification of symptom-related associations (49%-62%). 

**Abstract (ZH)**: 大型语言模型（LLM）的生成能力为加速任务提供了机会，同时也引发了对其生成知识真实性的关注。为了解决这些担忧，我们提出了一种计算方法，系统地评估LLM模型在受到提示后生成的生物医学知识的事实准确性。该方法包含两个过程：疾病中心关联的生成和通过生物医学本体的语义知识验证这些关联。

我们选择了ChatGPT作为LLM模型，设计了一组提示工程过程，在疾病、药物、症状和基因之间建立联系，以奠定评估基础。实验结果表明，在疾病术语（88%-97%）、药物名称（90%-91%）和遗传信息（88%-98%）的识别方面具有高度准确性。症状术语的识别准确率较低（49%-61%），这在DOID、ChEBI、SYMPTOM和GO本体中得到了验证。关联的验证显示，疾病-药物和疾病-基因关联的文献覆盖率分别为89%-91%。症状术语识别准确率较低也影响了症状相关关联的验证（49%-62%）。 

---
# InstructAgent: Building User Controllable Recommender via LLM Agent 

**Title (ZH)**: 《InstructAgent：通过LLM代理构建用户可控的推荐系统》

在这个翻译中，“InstructAgent”被保留为专有名词，“LLM”代表“大型语言模型”（Large Language Model），符合学术翻译的规范。 

**Authors**: Wujiang Xu, Yunxiao Shi, Zujie Liang, Xuying Ning, Kai Mei, Kun Wang, Xi Zhu, Min Xu, Yongfeng Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2502.14662)  

**Abstract**: Traditional recommender systems usually take the user-platform paradigm, where users are directly exposed under the control of the platform's recommendation algorithms. However, the defect of recommendation algorithms may put users in very vulnerable positions under this paradigm. First, many sophisticated models are often designed with commercial objectives in mind, focusing on the platform's benefits, which may hinder their ability to protect and capture users' true interests. Second, these models are typically optimized using data from all users, which may overlook individual user's preferences. Due to these shortcomings, users may experience several disadvantages under the traditional user-platform direct exposure paradigm, such as lack of control over the recommender system, potential manipulation by the platform, echo chamber effects, or lack of personalization for less active users due to the dominance of active users during collaborative learning. Therefore, there is an urgent need to develop a new paradigm to protect user interests and alleviate these issues. Recently, some researchers have introduced LLM agents to simulate user behaviors, these approaches primarily aim to optimize platform-side performance, leaving core issues in recommender systems unresolved. To address these limitations, we propose a new user-agent-platform paradigm, where agent serves as the protective shield between user and recommender system that enables indirect exposure. To this end, we first construct four recommendation datasets, denoted as $\dataset$, along with user instructions for each record. 

**Abstract (ZH)**: 传统的推荐系统通常采取用户-平台范式，用户直接在平台的推荐算法控制下接收推荐内容。然而，在这种范式下，推荐算法的缺陷可能会使用户处于非常脆弱的位置。首先，许多复杂模型往往旨在追求商业目标，关注平台的利益，这可能削弱它们保护和捕捉用户真实兴趣的能力。其次，这些模型通常使用所有用户的数据进行优化，这可能会忽略个别用户的偏好。由于这些缺陷，用户在传统用户-平台直接暴露范式下可能会经历多种不利影响，如对推荐系统的控制力薄弱、平台可能进行操控、回音室效应，或者由于活跃用户主导协作学习过程而导致的个性化不足。因此，迫切需要开发一种新范式来保护用户利益并缓解这些问题。近期，一些研究人员提出了使用大语言模型（LLM）代理来模拟用户行为的方法，这些方法主要旨在优化平台侧的表现，但未能解决推荐系统的根本问题。为了解决这些局限性，我们提出了一种新的用户-代理-平台范式，其中代理作为用户和推荐系统之间的防护屏障，实现了间接暴露。为此，我们首先构建了四个推荐数据集，分别标记为$\dataset$，并为每个记录提供用户指令。 

---
# Multi-Record Web Page Information Extraction From News Websites 

**Title (ZH)**: 从新闻网站提取多记录网页信息 

**Authors**: Alexander Kustenkov, Maksim Varlamov, Alexander Yatskov  

**Link**: [PDF](https://arxiv.org/pdf/2502.14625)  

**Abstract**: In this paper, we focused on the problem of extracting information from web pages containing many records, a task of growing importance in the era of massive web data. Recently, the development of neural network methods has improved the quality of information extraction from web pages. Nevertheless, most of the research and datasets are aimed at studying detailed pages. This has left multi-record "list pages" relatively understudied, despite their widespread presence and practical significance.
To address this gap, we created a large-scale, open-access dataset specifically designed for list pages. This is the first dataset for this task in the Russian language. Our dataset contains 13,120 web pages with news lists, significantly exceeding existing datasets in both scale and complexity. Our dataset contains attributes of various types, including optional and multi-valued, providing a realistic representation of real-world list pages. These features make our dataset a valuable resource for studying information extraction from pages containing many records.
Furthermore, we proposed our own multi-stage information extraction methods. In this work, we explore and demonstrate several strategies for applying MarkupLM to the specific challenges of multi-record web pages. Our experiments validate the advantages of our methods.
By releasing our dataset to the public, we aim to advance the field of information extraction from multi-record pages. 

**Abstract (ZH)**: 在这篇论文中，我们重点关注了从包含大量记录的网页中提取信息的问题，这是一个在大数据时代日益重要的任务。近年来，神经网络方法的发展提高了从网页中提取信息的质量。然而，大多数的研究和数据集主要关注详细页面，而忽视了多记录“列表页面”的研究，尽管这些列表页面普遍存在且具有实际意义。

为了弥补这一空白，我们创建了一个大规模、开源的数据集，专门用于列表页面的研究。这是首个针对此类任务的俄语数据集。我们的数据集包含13,120个包含新闻列表的网页，规模和复杂性远超现有数据集。我们的数据集包含了各种类型的数据属性，包括可选和多值属性，提供了对实际世界列表页面的现实代表。这些特征使我们的数据集成为研究包含多记录的网页信息提取的宝贵资源。

此外，我们还提出了自己的多阶段信息提取方法。在此项工作中，我们探索并展示了将 MarkupLM 应用于多记录网页特定挑战的多种策略。我们的实验验证了我们方法的优势。

通过向公众发布我们的数据集，我们旨在推动多记录页面信息提取领域的研究进展。 

---
# Unstructured Evidence Attribution for Long Context Query Focused Summarization 

**Title (ZH)**: 长上下文查询聚焦摘要中的无结构证据归因 

**Authors**: Dustin Wright, Zain Muhammad Mujahid, Lu Wang, Isabelle Augenstein, David Jurgens  

**Link**: [PDF](https://arxiv.org/pdf/2502.14409)  

**Abstract**: Large language models (LLMs) are capable of generating coherent summaries from very long contexts given a user query. Extracting and properly citing evidence spans could help improve the transparency and reliability of these summaries. At the same time, LLMs suffer from positional biases in terms of which information they understand and attend to, which could affect evidence citation. Whereas previous work has focused on evidence citation with predefined levels of granularity (e.g. sentence, paragraph, document, etc.), we propose the task of long-context query focused summarization with unstructured evidence citation. We show how existing systems struggle to generate and properly cite unstructured evidence from their context, and that evidence tends to be "lost-in-the-middle". To help mitigate this, we create the Summaries with Unstructured Evidence Text dataset (SUnsET), a synthetic dataset generated using a novel domain-agnostic pipeline which can be used as supervision to adapt LLMs to this task. We demonstrate across 5 LLMs of different sizes and 4 datasets with varying document types and lengths that LLMs adapted with SUnsET data generate more relevant and factually consistent evidence than their base models, extract evidence from more diverse locations in their context, and can generate more relevant and consistent summaries. 

**Abstract (ZH)**: 大型语言模型（LLMs）能够根据用户查询从非常长的上下文中生成连贯的摘要。提取并正确引用来自上下文的证据段落有助于提高这些摘要的透明度和可靠性。与此同时，LLMs 在信息理解和注意力上存在位置偏见，这也可能影响证据的引用。虽然以前的工作主要集中在具有预定义粒度级别（例如句子、段落、文档等）的证据引用上，但我们提出了一个长上下文查询聚焦摘要与无结构证据引用相结合的任务。我们展示了现有系统在生成并正确引用未结构化证据方面的困难，发现证据倾向于“丢失在中间”。为了缓解这一问题，我们创建了带有未结构化证据文本的数据集（SUnsET），该合成数据集采用了一种新颖的领域无关管道生成，可以用作监督信号，以适应LLMs完成此任务。我们在5种不同规模的大型语言模型和4种不同文档类型与长度的数据集上展示了结果，结果显示利用SUnsET数据适应的模型生成了更相关且事实更一致的证据，从更多种类的上下文位置提取证据，并生成了更相关且一致的摘要。 

---
# Retrieval-Augmented Process Reward Model for Generalizable Mathematical Reasoning 

**Title (ZH)**: 增强检索过程奖励模型以实现通用数学推理 

**Authors**: Jiachen Zhu, Congmin Zheng, Jianghao Lin, Kounianhua Du, Ying Wen, Yong Yu, Jun Wang, Weinan Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2502.14361)  

**Abstract**: While large language models (LLMs) have significantly advanced mathematical reasoning, Process Reward Models (PRMs) have been developed to evaluate the logical validity of reasoning steps. However, PRMs still struggle with out-of-distribution (OOD) challenges. This paper identifies key OOD issues, including step OOD, caused by differences in reasoning patterns across model types and sizes, and question OOD, which arises from dataset shifts between training data and real-world problems. To address these issues, we introduce Retrieval-Augmented Process Reward Model (RetrievalPRM), a novel framework designed to tackle these OOD issues. By utilizing a two-stage retrieval-enhanced mechanism, RetrievalPRM retrieves semantically similar questions and steps as a warmup, enhancing PRM's ability to evaluate target steps and improving generalization and reasoning consistency across different models and problem types. Our extensive experiments demonstrate that RetrievalPRM outperforms existing baselines across multiple real-world datasets. Our open-source contributions include a retrieval-enhanced dataset, a tuning framework for PRM training, and the RetrievalPRM model, establishing a new standard for PRM performance. 

**Abstract (ZH)**: 尽管大规模语言模型（LLMs）在数学推理方面取得了显著进展，过程奖励模型（PRMs）已经发展起来，用于评估推理步骤的逻辑有效性。然而，PRMs 仍然难以应对分布外（OOD）挑战。本文识别了关键的 OOD 问题，包括由于不同模型类型和规模的推理模式差异导致的步骤 OOD 问题，以及由于训练数据集与实际问题之间的偏移导致的问题 OOD 问题。为了应对这些问题，我们引入了检索增强过程奖励模型（RetrievalPRM），这是一种新的框架，旨在解决这些 OOD 问题。通过利用两阶段的检索增强机制，RetrievalPRM 在预热阶段检索语义上相似的问题和步骤，从而增强 PRM 评估目标步骤的能力，并在不同模型和问题类型之间提高泛化能力和推理一致性。广泛实验表明，RetrievalPRM 在多个实际数据集上优于现有基线。我们的开源贡献包括一个检索增强数据集、一个 PRM 训练的调优框架和 RetrievalPRM 模型，从而确立了 PRM 性能的新标准。 

---
# A Collaborative Jade Recognition System for Mobile Devices Based on Lightweight and Large Models 

**Title (ZH)**: 基于轻量化与大规模模型的移动设备协作型mpprh鉴别系统 

**Authors**: Zhenyu Wang, Wenjia Li, Pengyu Zhu  

**Link**: [PDF](https://arxiv.org/pdf/2502.14332)  

**Abstract**: With the widespread adoption and development of mobile devices, vision-based recognition applications have become a hot topic in research. Jade, as an important cultural heritage and artistic item, has significant applications in fields such as jewelry identification and cultural relic preservation. However, existing jade recognition systems still face challenges in mobile implementation, such as limited computing resources, real-time requirements, and accuracy issues. To address these challenges, this paper proposes a jade recognition system based on size model collaboration, aiming to achieve efficient and accurate jade identification using mobile devices such as this http URL, we design a size model based on multi-scale image processing, extracting key visual information by analyzing jade's dimensions, shapes, and surface textures. Then, a collaborative multi-model classification framework is built by combining deep learning and traditional computer vision algorithms. This framework can effectively select and adjust models based on different jade characteristics, providing high accuracy results across various environments and this http URL results show that the proposed system can provide high recognition accuracy and fast processing time on mobile devices, while consuming relatively low computational resources. The system not only holds great application potential but also provides new ideas and technical support for the intelligent development of jade identification. 

**Abstract (ZH)**: 随着移动设备的广泛应用和发展，基于视觉识别的应用已成为研究热点。翡翠作为一种重要的文化遗产和艺术品，在珠宝鉴定和文物保存等领域有着显著的应用价值。然而，现有的翡翠识别系统在移动设备上的实现仍面临诸如计算资源有限、实时性要求高以及准确性不足等挑战。为应对这些挑战，本文提出了一种基于尺寸模型协作的翡翠识别系统，旨在利用移动设备如智能手机等实现高效准确的翡翠识别。我们基于多尺度图像处理设计了一个尺寸模型，通过分析翡翠的尺寸、形状和表面纹理提取关键视觉信息。然后，通过结合深度学习和传统计算机视觉算法构建了一个协作的多模型分类框架。该框架可以根据不同翡翠的特点有效地选择和调整模型，提供跨环境的高精度结果。实验结果表明，所提出系统能够在移动设备上提供高识别准确性和快速处理时间，同时消耗相对较低的计算资源。该系统不仅具有广阔的应用前景，还为翡翠识别的智能化发展提供了新的思路和技术支持。 

---
# Less is More: On the Importance of Data Quality for Unit Test Generation 

**Title (ZH)**: 少即是多：数据质量对单元测试生成的重要性 

**Authors**: Junwei Zhang, Xing Hu, Shan Gao, Xin Xia, David Lo, Shanping Li  

**Link**: [PDF](https://arxiv.org/pdf/2502.14212)  

**Abstract**: Unit testing is crucial for software development and maintenance. Effective unit testing ensures and improves software quality, but writing unit tests is time-consuming and labor-intensive. Recent studies have proposed deep learning (DL) techniques or large language models (LLMs) to automate unit test generation. These models are usually trained or fine-tuned on large-scale datasets. Despite growing awareness of the importance of data quality, there has been limited research on the quality of datasets used for test generation. To bridge this gap, we systematically examine the impact of noise on the performance of learning-based test generation models. We first apply the open card sorting method to analyze the most popular and largest test generation dataset, Methods2Test, to categorize eight distinct types of noise. Further, we conduct detailed interviews with 17 domain experts to validate and assess the importance, reasonableness, and correctness of the noise taxonomy. Then, we propose CleanTest, an automated noise-cleaning framework designed to improve the quality of test generation datasets. CleanTest comprises three filters: a rule-based syntax filter, a rule-based relevance filter, and a model-based coverage filter. To evaluate its effectiveness, we apply CleanTest on two widely-used test generation datasets, i.e., Methods2Test and Atlas. Our findings indicate that 43.52% and 29.65% of datasets contain noise, highlighting its prevalence. Finally, we conduct comparative experiments using four LLMs (i.e., CodeBERT, AthenaTest, StarCoder, and CodeLlama7B) to assess the impact of noise on test generation performance. The results show that filtering noise positively influences the test generation ability of the models. 

**Abstract (ZH)**: 单元测试对于软件开发和维护至关重要。有效的单元测试能够确保并提高软件质量，但编写单元测试耗费时间和劳动。近年来，一些研究提出了深度学习（DL）技术或大规模语言模型（LLMs）以自动进行单元测试生成。这些模型通常在大规模数据集上进行训练或微调。尽管人们对数据质量的重要性认识不断增长，但有关用于测试生成的数据集质量的研究却相对有限。为解决这一问题，我们系统地探讨了噪声对基于学习的测试生成模型性能的影响。首先，我们使用开放式卡片归类法对最受欢迎和最大的测试生成数据集Methods2Test进行分析，将其划分为八种不同的噪声类型。随后，我们对17名领域专家进行详细访谈，以验证并评估噪声分类的有效性、合理性和准确性。接着，我们提出了CleanTest，这是一种自动化的噪声清理框架，旨在提高测试生成数据集的质量。CleanTest包含三个过滤器：基于规则的语法过滤器、基于规则的相关性过滤器以及基于模型的覆盖率过滤器。为了评估其有效性，我们在两个广泛使用的测试生成数据集Methods2Test和Atlas上应用了CleanTest。我们的研究结果表明，数据集中有43.52%和29.65%包含噪声，这突显了噪声的普遍存在。最后，我们使用四种LLM（CodeBERT、AthenaTest、StarCoder和CodeLlama7B）进行比较实验，以评估噪声对测试生成性能的影响。结果表明，过滤噪声对模型的测试生成能力有积极影响。 

---
# Towards Context-Robust LLMs: A Gated Representation Fine-tuning Approach 

**Title (ZH)**: 面向上下文鲁棒性的大语言模型：一种门控表示微调方法 

**Authors**: Shenglai Zeng, Pengfei He, Kai Guo, Tianqi Zheng, Hanqing Lu, Yue Xing, Hui Liu  

**Link**: [PDF](https://arxiv.org/pdf/2502.14100)  

**Abstract**: Large Language Models (LLMs) enhanced with external contexts, such as through retrieval-augmented generation (RAG), often face challenges in handling imperfect evidence. They tend to over-rely on external knowledge, making them vulnerable to misleading and unhelpful contexts. To address this, we propose the concept of context-robust LLMs, which can effectively balance internal knowledge with external context, similar to human cognitive processes. Specifically, context-robust LLMs should rely on external context only when lacking internal knowledge, identify contradictions between internal and external knowledge, and disregard unhelpful contexts. To achieve this goal, we introduce Grft, a lightweight and plug-and-play gated representation fine-tuning approach. Grft consists of two key components: a gating mechanism to detect and filter problematic inputs, and low-rank representation adapters to adjust hidden representations. By training a lightweight intervention function with only 0.0004\% of model size on fewer than 200 examples, Grft can effectively adapt LLMs towards context-robust behaviors. 

**Abstract (ZH)**: 增强外部上下文的大型语言模型（LLMs），如通过检索增强生成（RAG）技术，往往在处理不完美的证据时面临挑战。这类模型倾向于过度依赖外部知识，使其容易受到误导性和无用上下文的影响。为解决这一问题，我们提出了上下文鲁棒大型语言模型的概念，这种模型能够有效地平衡内部知识与外部上下文，类似于人类认知过程。具体来说，上下文鲁棒大型语言模型应该仅在缺乏内部知识时依赖外部上下文，识别内部知识与外部知识之间的矛盾，并忽略无用的上下文。

为了实现这一目标，我们引入了Grft，一种轻量级且即插即用的门控表示微调方法。Grft 包括两个关键组件：一种门控机制用于检测和过滤问题输入，以及低秩表示适配器用于调整隐藏表示。通过在少于200个示例上训练仅占模型大小0.0004%的轻量级干预函数，Grft 能够有效使大型语言模型朝向上下文鲁棒的行为转变。 

---
