{'arxiv_id': 'arXiv:2502.08356', 'title': 'Systematic Knowledge Injection into Large Language Models via Diverse Augmentation for Domain-Specific RAG', 'authors': 'Kushagra Bhushan, Yatin Nandwani, Dinesh Khandelwal, Sonam Gupta, Gaurav Pandey, Dinesh Raghu, Sachindra Joshi', 'link': 'https://arxiv.org/abs/2502.08356', 'abstract': "Retrieval-Augmented Generation (RAG) has emerged as a prominent method for incorporating domain knowledge into Large Language Models (LLMs). While RAG enhances response relevance by incorporating retrieved domain knowledge in the context, retrieval errors can still lead to hallucinations and incorrect answers. To recover from retriever failures, domain knowledge is injected by fine-tuning the model to generate the correct response, even in the case of retrieval errors. However, we observe that without systematic knowledge augmentation, fine-tuned LLMs may memorize new information but still fail to extract relevant domain knowledge, leading to poor performance. In this work, we present a novel framework that significantly enhances the fine-tuning process by augmenting the training data in two ways -- context augmentation and knowledge paraphrasing. In context augmentation, we create multiple training samples for a given QA pair by varying the relevance of the retrieved information, teaching the model when to ignore and when to rely on retrieved content. In knowledge paraphrasing, we fine-tune with multiple answers to the same question, enabling LLMs to better internalize specialized knowledge. To mitigate catastrophic forgetting due to fine-tuning, we add a domain-specific identifier to a question and also utilize a replay buffer containing general QA pairs. Experimental results demonstrate the efficacy of our method over existing techniques, achieving up to 10\\% relative gain in token-level recall while preserving the LLM's generalization capabilities.", 'abstract_zh': '检索增强生成（RAG）已成为将领域知识整合到大型语言模型（LLMs）中的一个重要方法。虽然RAG通过结合检索到的领域知识增强了响应的相关性，但检索错误仍然可能导致生成错误的答案或幻觉。为解决检索器失败的问题，通过微调模型以生成正确答案，即使在检索错误的情况下也能注入领域知识。然而，我们观察到，在系统性的知识增强缺失的情况下，微调后的LLMs可能记住新信息，但仍无法提取相关领域的知识，导致性能不佳。在本文中，我们提出了一种新的框架，通过两种方式增强训练数据，显著提升微调过程的效果——上下文增强和知识重述。在上下文增强中，我们通过改变检索信息的相关性为给定的问答对创建多个训练样本，从而教会模型何时忽略检索内容，何时依赖检索内容。在知识重述中，我们使用相同的问答对的多个答案进行微调，使LLMs更好地内化专门知识。为了缓解因微调而导致的灾难性遗忘，我们为一个问题添加了一个领域特定的标识符，并利用包含一般性问答对的回放缓冲区。实验结果表明，我们的方法相较于现有技术更为有效，在保持LLM的一般泛化能力的同时，单词水平的召回率提高了最多10%。', 'title_zh': '通过多样增强将系统性知识注入到大型语言模型中以适用于特定领域的情景检索生成系统'}
{'arxiv_id': 'arXiv:2502.08178', 'title': 'ParetoRAG: Leveraging Sentence-Context Attention for Robust and Efficient Retrieval-Augmented Generation', 'authors': 'Ruobing Yao, Yifei Zhang, Shuang Song, Yuhua Liu, Neng Gao, Chenyang Tu', 'link': 'https://arxiv.org/abs/2502.08178', 'abstract': 'While Retrieval-Augmented Generation (RAG) systems enhance Large Language Models (LLMs) by incorporating external knowledge, they still face persistent challenges in retrieval inefficiency and the inability of LLMs to filter out irrelevant information. We present ParetoRAG, an unsupervised framework that optimizes RAG systems through sentence-level refinement guided by the Pareto principle. By decomposing paragraphs into sentences and dynamically re-weighting core content while preserving contextual coherence, ParetoRAG achieves dual improvements in both retrieval precision and generation quality without requiring additional training or API resources. This framework has been empirically validated across various datasets, LLMs, and retrievers.', 'abstract_zh': '尽管检索增强生成（RAG）系统通过引入外部知识来增强大型语言模型（LLMs），它们仍然面临着检索效率低下以及LLMs筛选无关信息能力不足的持续挑战。我们提出了一种名为ParetoRAG的无监督框架，通过基于帕累托原则的句子级优化来改进RAG系统。该框架将段落分解为句子，并动态重新加权核心内容以保持上下文一致性，在无需额外训练或API资源的情况下实现了检索精度和生成质量的双重提升。该框架已在多种数据集、LLMs和检索器上进行了经验验证。', 'title_zh': '帕累托RAG：利用句子-上下文注意力机制实现稳健高效的知识增强生成'}
{'arxiv_id': 'arXiv:2502.08056', 'title': 'Cognify: Supercharging Gen-AI Workflows With Hierarchical Autotuning', 'authors': 'Zijian He, Reyna Abhyankar, Vikranth Srivatsa, Yiying Zhang', 'link': 'https://arxiv.org/abs/2502.08056', 'abstract': "Today's gen-AI workflows that involve multiple ML model calls, tool/API calls, data retrieval, or generic code execution are often tuned manually in an ad-hoc way that is both time-consuming and error-prone. In this paper, we propose a systematic approach for automatically tuning gen-AI workflows. Our key insight is that gen-AI workflows can benefit from structure, operator, and prompt changes, but unique properties of gen-AI workflows require new optimization techniques. We propose AdaSeek, an adaptive hierarchical search algorithm for autotuning gen-AI workflows. AdaSeek organizes workflow tuning methods into different layers based on the user-specified total search budget and distributes the budget across different layers based on the complexity of each layer. During its hierarchical search, AdaSeek redistributes the search budget from less useful to more promising tuning configurations based on workflow-level evaluation results. We implement AdaSeek in a workflow autotuning framework called Cognify and evaluate Cognify using six types of workflows such as RAG-based QA and text-to-SQL transformation. Overall, Cognify improves these workflows' generation quality by up to 2.8x, reduces execution monetary cost by up to 10x, and reduces end-to-end latency by 2.7x.", 'abstract_zh': '当今涉及多个机器学习模型调用、工具/API 调用、数据检索或通用代码执行的生成型人工智能（gen-AI）工作流通常通过非系统的方式手动调整，这种方式既耗时又易出错。在本文中，我们提出了一种系统的方法来自动调整生成型人工智能工作流。我们的主要见解是：生成型人工智能工作流可以从结构、操作符和提示的更改中受益，但生成型人工智能工作流的独特性质需要新的优化技术。我们提出了一种适应性的分层搜索算法AdaSeek，用于自动生成调整生成型人工智能工作流的方法。AdaSeek 根据用户指定的总搜索预算将工作流调整方法分为不同的层次，并根据每层的复杂度分配预算。在其分层搜索过程中，AdaSeek 根据工作流级评估结果重新分配搜索预算，从不太有用的配置重新分配到更有前景的配置。我们实现了 AdaSeek 在一个工作流自动生成调整框架 Cognify 中，并使用六种类型的工作流（如基于 RAG 的问答和文本到 SQL 转换）评估 Cognify。总体而言，Cognify 将这些工作流的生成质量提高了最多 2.8 倍，降低了最多 10 倍的执行成本，并将端到端延迟减少了 2.7 倍。', 'title_zh': 'Cognify: 通过分层自动调优增强生成式AI工作流'}
