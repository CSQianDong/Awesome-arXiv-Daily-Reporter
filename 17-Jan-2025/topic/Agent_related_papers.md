# Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG 

**Title (ZH)**: 代理检索增强生成：关于代理RAG的研究综述

在这个翻译中，“Agentic Retrieval-Augmented Generation”被翻译为“代理检索增强生成”，“Survey on Agentic RAG”翻译为“关于代理RAG的研究综述”。这样的翻译既保留了原文的意思，又符合中文的表达习惯和学术规范。 

**Authors**: Aditi Singh, Abul Ehtesham, Saket Kumar, Tala Talaei Khoei  

**Link**: [PDF](https://arxiv.org/pdf/2501.09136)  

**Abstract**: Large Language Models (LLMs) have revolutionized artificial intelligence (AI) by enabling human like text generation and natural language understanding. However, their reliance on static training data limits their ability to respond to dynamic, real time queries, resulting in outdated or inaccurate outputs. Retrieval Augmented Generation (RAG) has emerged as a solution, enhancing LLMs by integrating real time data retrieval to provide contextually relevant and up-to-date responses. Despite its promise, traditional RAG systems are constrained by static workflows and lack the adaptability required for multistep reasoning and complex task management.
Agentic Retrieval-Augmented Generation (Agentic RAG) transcends these limitations by embedding autonomous AI agents into the RAG pipeline. These agents leverage agentic design patterns reflection, planning, tool use, and multiagent collaboration to dynamically manage retrieval strategies, iteratively refine contextual understanding, and adapt workflows to meet complex task requirements. This integration enables Agentic RAG systems to deliver unparalleled flexibility, scalability, and context awareness across diverse applications.
This survey provides a comprehensive exploration of Agentic RAG, beginning with its foundational principles and the evolution of RAG paradigms. It presents a detailed taxonomy of Agentic RAG architectures, highlights key applications in industries such as healthcare, finance, and education, and examines practical implementation strategies. Additionally, it addresses challenges in scaling these systems, ensuring ethical decision making, and optimizing performance for real-world applications, while providing detailed insights into frameworks and tools for implementing Agentic RAG 

**Abstract (ZH)**: 大型语言模型（LLMs）通过实现类人的文本生成和自然语言理解，极大地革新了人工智能（AI）。然而，它们依赖于静态训练数据，限制了它们对动态、实时查询的响应能力，导致输出过时或不准确。检索增强生成（RAG）作为一种解决方案已经出现，通过集成实时数据检索来增强LLMs，提供上下文相关且最新的响应。尽管具有潜力，传统的RAG系统受到了静态工作流程的限制，缺乏为多步骤推理和复杂任务管理所需的适应性。

自主检索增强生成（Agentic RAG）超越了这些限制，通过将自主AI代理嵌入到RAG管道中来实现。这些代理利用自主设计模式中的反思、规划、工具使用和多智能体协作，动态管理检索策略，迭代细化上下文理解，并根据复杂任务需求适应工作流程。这种整合使得Agentic RAG系统在各种应用中提供无与伦比的灵活性、可扩展性和上下文感知能力。

本文综述了Agentic RAG的全面探索，从其基础原理和RAG范式的演变开始。详细介绍了Agentic RAG架构的分类，突出了其在医疗、金融和教育等行业中的关键应用，并探讨了实施策略。此外，本文还讨论了这些系统扩展时面临的挑战、确保伦理决策以及优化实际应用中的性能，同时提供了实施Agentic RAG的框架和工具的详细见解。 

---
# Solving the unsolvable: Translating case law in Hong Kong 

**Title (ZH)**: 解决不可解之题：香港判例法的翻译 

**Authors**: King-kui Sin, Xi Xuan, Chunyu Kit, Clara Ho-yan Chan, Honic Ho-kin Ip  

**Link**: [PDF](https://arxiv.org/pdf/2501.09444)  

**Abstract**: This paper addresses the challenges translating case law under Hong Kong's bilingual legal system. It highlights the initial success of translating all written statutes into Chinese before the 1997 handover, a task mandated by the Basic Law. The effort involved significant collaboration among legal, linguistic, and translation experts, resulting in a comprehensive and culturally appropriate bilingual legal system. However, translating case law remains a significant challenge due to the sheer volume and continuous growth of judicial decisions. The paper critiques the governments and judiciarys sporadic and uncoordinated efforts to translate case law, contrasting it with the thorough approach previously taken for statute translation. Although the government acknowledges the importance of legal bilingualism, it lacks a sustainable strategy for translating case law. The Judiciarys position that translating all judgments is unnecessary, unrealistic, and not cost-effectiveis analyzed and critiqued for its impact on legal transparency and public trust. A proposed solution involves leveraging machine translation technology through a human-machine interactive translation platform, which undergoes two major transitions. Initially based on a neural model, the platform transitions to using a large language model for improved translation accuracy. Furthermore, it evolves from a single-agent system to a multi-agent system, incorporating Translator, Annotator, and Proofreader agents. This multi-agent approach, supported by a grant, aims to facilitate efficient, high-quality translation of judicial judgments by integrating advanced artificial intelligence and continuous feedback mechanisms, thus better meeting the needs of a bilingual legal system. 

**Abstract (ZH)**: 本文探讨了在港英文双语法律体系下进行案例法翻译所面临的挑战。在1997年主权移交前，所有书面法例均已成功翻译成中文，这是根据基本法的要求完成的任务。这项工作涉及法律、语言和翻译专家的密切合作，形成了全面且文化适应性的双语法律体系。然而，由于司法判决的数量庞大且持续增长，翻译案例法仍然是一项重大挑战。文章批评了政府和司法机构在翻译案例法方面反复无常且缺乏协调的努力，与早期对法例翻译的全面方法形成了对比。尽管政府承认法律双语化的重要性，但仍缺乏一种可持续的案例法翻译策略。司法机构认为，将所有判决翻译成中文是不必要的、不现实且不经济的做法，这一观点被分析并批评，认为这将对司法透明度和公众信任产生负面影响。本文提出的一项解决方案是通过人机交互翻译平台利用机器翻译技术，该平台经历了两大转变。最初基于神经模型，平台转向使用大型语言模型以提高翻译准确性。此外，它从单个代理系统演变为多代理系统，加入了翻译代理、注释代理和审校代理。在资助下，这种多代理方法旨在通过整合先进的人工智能技术和持续反馈机制，促进高质量的司法判决翻译，更好地满足双语法律体系的需求。 

---
# AutoCBT: An Autonomous Multi-agent Framework for Cognitive Behavioral Therapy in Psychological Counseling 

**Title (ZH)**: 自动认知行为疗法（AutoCBT）：一种用于心理辅导的认知行为疗法自主多智能体框架 

**Authors**: Ancheng Xu, Di Yang, Renhao Li, Jingwei Zhu, Minghuan Tan, Min Yang, Wanxin Qiu, Mingchen Ma, Haihong Wu, Bingyu Li, Feng Sha, Chengming Li, Xiping Hu, Qiang Qu, Derek F.Wong, Ruifeng Xu  

**Link**: [PDF](https://arxiv.org/pdf/2501.09426)  

**Abstract**: Traditional in-person psychological counseling remains primarily niche, often chosen by individuals with psychological issues, while online automated counseling offers a potential solution for those hesitant to seek help due to feelings of shame. Cognitive Behavioral Therapy (CBT) is an essential and widely used approach in psychological counseling. The advent of large language models (LLMs) and agent technology enables automatic CBT diagnosis and treatment. However, current LLM-based CBT systems use agents with a fixed structure, limiting their self-optimization capabilities, or providing hollow, unhelpful suggestions due to redundant response patterns. In this work, we utilize Quora-like and YiXinLi single-round consultation models to build a general agent framework that generates high-quality responses for single-turn psychological consultation scenarios. We use a bilingual dataset to evaluate the quality of single-response consultations generated by each framework. Then, we incorporate dynamic routing and supervisory mechanisms inspired by real psychological counseling to construct a CBT-oriented autonomous multi-agent framework, demonstrating its general applicability. Experimental results indicate that AutoCBT can provide higher-quality automated psychological counseling services. 

**Abstract (ZH)**: 传统的面对面心理辅导仍然主要针对有特定需求的人群，通常由遇到心理问题的个人选择；而在线自动化心理辅导为因羞耻感而犹豫不寻求帮助的人提供了一种潜在的解决方案。认知行为疗法（CBT）是心理辅导中广泛应用且至关重要的一种方法。大型语言模型（LLMs）和代理技术的出现使得自动化的CBT诊断和治疗成为可能。然而，当前基于LLM的CBT系统使用具有固定结构的代理，这限制了它们的自我优化能力，或者由于重复的响应模式提供了空洞且无用的建议。在本工作中，我们利用类似于Quora和YiXinLi的一轮咨询模型构建了一个通用的代理框架，用于生成高质量的心理咨询服务单轮场景的响应。我们使用双语数据集评估每个框架生成的单轮咨询质量。随后，我们借鉴实际心理辅导中的动态路由和监督机制，构建了一个面向CBT的自主多代理框架，展示了其普遍适用性。实验结果表明，AutoCBT能够提供更高质量的自动化心理咨询服务。 

---
# FineMedLM-o1: Enhancing the Medical Reasoning Ability of LLM from Supervised Fine-Tuning to Test-Time Training 

**Title (ZH)**: FineMedLM-o1：从监督微调到测试时训练，增强大语言模型的医学推理能力 

**Authors**: Hongzhou Yu, Tianhao Cheng, Ying Cheng, Rui Feng  

**Link**: [PDF](https://arxiv.org/pdf/2501.09213)  

**Abstract**: Recent advancements in large language models (LLMs) have shown promise in medical applications such as disease diagnosis and treatment planning. However, most existing medical LLMs struggle with the advanced reasoning required for complex clinical scenarios, such as differential diagnosis or personalized treatment suggestions. We proposed FineMedLM-o1, which leverages high-quality synthetic medical data and long-form reasoning data for Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO), enabling advanced dialogue and deep reasoning capabilities. Additionally, we introduced Test-Time Training (TTT) in the medical domain for the first time, facilitating domain adaptation and ensuring reliable, accurate reasoning. Experimental results demonstrate that FineMedLM-o1 achieves a 23% average performance improvement over prior models on key medical benchmarks. Furthermore, the introduction of TTT provides an additional 14% performance boost, highlighting its effectiveness in enhancing medical reasoning capabilities. To support this process, we also proposed a novel method for synthesizing medical dialogue. Compared to other open-source datasets, our dataset stands out as superior in both quality and complexity. The project and data will be released on GitHub. 

**Abstract (ZH)**: 近年来，大型语言模型（LLMs）在医学应用方面取得了进展，如疾病诊断和治疗规划。然而，现有的大多数医学LLMs在处理复杂临床场景所需的高级推理方面存在不足，例如鉴别诊断或个性化治疗建议。我们提出了FineMedLM-o1，它利用高质量的合成医学数据和长篇推理数据进行监督微调（SFT）和直接偏好优化（DPO），从而实现高级对话和深入的推理能力。此外，我们首次在医学领域引入了测试时训练（TTT），促进领域适应并确保可靠的准确推理。实验结果表明，FineMedLM-o1在关键医学基准测试上的平均性能改进达到了23%，而TTT的引入又额外提供了14%的性能提升，突显其在增强医学推理能力方面的有效性。为了支持这一过程，我们还提出了一种新的合成医学对话方法。与现有的开源数据集相比，我们的数据集在质量和复杂性方面都更为优越。该项目和数据将发布在GitHub上。 

---
# CarMem: Enhancing Long-Term Memory in LLM Voice Assistants through Category-Bounding 

**Title (ZH)**: CarMem：通过类别限定增强大型语言模型语音助手的长期记忆 

**Authors**: Johannes Kirmayr, Lukas Stappen, Phillip Schneider, Florian Matthes, Elisabeth André  

**Link**: [PDF](https://arxiv.org/pdf/2501.09645)  

**Abstract**: In today's assistant landscape, personalisation enhances interactions, fosters long-term relationships, and deepens engagement. However, many systems struggle with retaining user preferences, leading to repetitive user requests and disengagement. Furthermore, the unregulated and opaque extraction of user preferences in industry applications raises significant concerns about privacy and trust, especially in regions with stringent regulations like Europe. In response to these challenges, we propose a long-term memory system for voice assistants, structured around predefined categories. This approach leverages Large Language Models to efficiently extract, store, and retrieve preferences within these categories, ensuring both personalisation and transparency. We also introduce a synthetic multi-turn, multi-session conversation dataset (CarMem), grounded in real industry data, tailored to an in-car voice assistant setting. Benchmarked on the dataset, our system achieves an F1-score of .78 to .95 in preference extraction, depending on category granularity. Our maintenance strategy reduces redundant preferences by 95% and contradictory ones by 92%, while the accuracy of optimal retrieval is at .87. Collectively, the results demonstrate the system's suitability for industrial applications. 

**Abstract (ZH)**: 在当今的辅助助理环境中，个性化可以增强互动、促进长期关系，并加深参与度。然而，许多系统在保留用户偏好方面存在困难，导致用户重复请求和参与度下降。此外，在行业应用中未经规范和透明地提取用户偏好引发了关于隐私和信任的重大关切，特别是在像欧洲这样有严格法规的地区。为应对这些挑战，我们提出了一种基于预定义类别的长期记忆系统，该系统利用大型语言模型高效地提取、存储和检索这些类别的偏好，确保了个性化和透明度。我们还引入了一个基于实际行业数据的合成多轮多会话对话数据集（CarMem），适用于车载语音助手的环境。在该数据集上测试，我们的系统在偏好提取上的F1分数范围为0.78到0.95，具体取决于类别的细度。我们的维护策略将重复的偏好减少了95%，矛盾的偏好减少了92%，而最优检索的准确性达到了0.87。整体而言，实验结果表明该系统适用于工业应用。 

---
# Artificial Intelligence-Driven Clinical Decision Support Systems 

**Title (ZH)**: 人工智能驱动的临床决策支持系统 

**Authors**: Muhammet Alkan, Idris Zakariyya, Samuel Leighton, Kaushik Bhargav Sivangi, Christos Anagnostopoulos, Fani Deligianni  

**Link**: [PDF](https://arxiv.org/pdf/2501.09628)  

**Abstract**: As artificial intelligence (AI) becomes increasingly embedded in healthcare delivery, this chapter explores the critical aspects of developing reliable and ethical Clinical Decision Support Systems (CDSS). Beginning with the fundamental transition from traditional statistical models to sophisticated machine learning approaches, this work examines rigorous validation strategies and performance assessment methods, including the crucial role of model calibration and decision curve analysis. The chapter emphasizes that creating trustworthy AI systems in healthcare requires more than just technical accuracy; it demands careful consideration of fairness, explainability, and privacy. The challenge of ensuring equitable healthcare delivery through AI is stressed, discussing methods to identify and mitigate bias in clinical predictive models. The chapter then delves into explainability as a cornerstone of human-centered CDSS. This focus reflects the understanding that healthcare professionals must not only trust AI recommendations but also comprehend their underlying reasoning. The discussion advances in an analysis of privacy vulnerabilities in medical AI systems, from data leakage in deep learning models to sophisticated attacks against model explanations. The text explores privacy-preservation strategies such as differential privacy and federated learning, while acknowledging the inherent trade-offs between privacy protection and model performance. This progression, from technical validation to ethical considerations, reflects the multifaceted challenges of developing AI systems that can be seamlessly and reliably integrated into daily clinical practice while maintaining the highest standards of patient care and data protection. 

**Abstract (ZH)**: 随着人工智能（AI）在医疗保健领域的日益嵌入，本章探讨了开发可靠且伦理的临床决策支持系统（CDSS）的关键方面。从传统的统计模型过渡到复杂的机器学习方法入手，本研究探讨了严格的验证策略和性能评估方法，包括模型校准和决策曲线分析中至关重要的作用。本章强调，在医疗保健中创建可信赖的AI系统不仅需要技术准确性，还需要仔细考虑公平性、可解释性和隐私保护。确保通过AI实现医疗服务的公平性是一项挑战，本章讨论了如何识别和缓解临床预测模型中的偏差。随后，本章深入探讨了以人为中心的CDSS中的可解释性作为基石。这一重点反映了这样一种理解：医疗保健专业人员不仅应信任AI推荐，还应理解其背后的推理。讨论进一步深入到对医疗AI系统中隐私漏洞的分析，从深度学习模型中的数据泄露到针对模型解释的复杂攻击。本文探讨了差异隐私和联邦学习等隐私保护策略，同时认识到隐私保护与模型性能之间固有的权衡。从技术验证到伦理考量的逐步推进，反映了在保持最高标准的患者护理和数据保护的同时，无缝且可靠地将AI系统整合到临床实践中所面临的多方面挑战。 

---
# YETI (YET to Intervene) Proactive Interventions by Multimodal AI Agents in Augmented Reality Tasks 

**Title (ZH)**: YETI（尚未干预）：多模态AI代理在增强现实任务中的主动干预 

**Authors**: Saptarashmi Bandyopadhyay, Vikas Bahirwani, Lavisha Aggarwal, Bhanu Guda, Lin Li, Andrea Colaco  

**Link**: [PDF](https://arxiv.org/pdf/2501.09355)  

**Abstract**: Multimodal AI Agents are AI models that have the capability of interactively and cooperatively assisting human users to solve day-to-day tasks. Augmented Reality (AR) head worn devices can uniquely improve the user experience of solving procedural day-to-day tasks by providing egocentric multimodal (audio and video) observational capabilities to AI Agents. Such AR capabilities can help AI Agents see and listen to actions that users take which can relate to multimodal capabilities of human users. Existing AI Agents, either Large Language Models (LLMs) or Multimodal Vision-Language Models (VLMs) are reactive in nature, which means that models cannot take an action without reading or listening to the human user's prompts. Proactivity of AI Agents on the other hand can help the human user detect and correct any mistakes in agent observed tasks, encourage users when they do tasks correctly or simply engage in conversation with the user - akin to a human teaching or assisting a user. Our proposed YET to Intervene (YETI) multimodal agent focuses on the research question of identifying circumstances that may require the agent to intervene proactively. This allows the agent to understand when it can intervene in a conversation with human users that can help the user correct mistakes on tasks, like cooking, using AR. Our YETI Agent learns scene understanding signals based on interpretable notions of Structural Similarity (SSIM) on consecutive video frames. We also define the alignment signal which the AI Agent can learn to identify if the video frames corresponding to the user's actions on the task are consistent with expected actions. These signals are used by our AI Agent to determine when it should proactively intervene. We compare our results on the instances of proactive intervention in the HoloAssist multimodal benchmark for an expert agent guiding a user to complete procedural tasks. 

**Abstract (ZH)**: 多模态AI代理是能够交互和协作帮助人类用户解决日常任务的AI模型。增强现实（AR）头戴设备通过为AI代理提供以自我为中心的多模态（音频和视频）观察能力，能够独特地提升解决程序性日常任务的用户体验。这些AR能力可以帮助AI代理看到并听到用户进行的动作，从而与人类用户的多模态能力相关联。现有的AI代理，无论是大型语言模型（LLM）还是多模态视觉语言模型（VLM），本质上是反应性的，这意味着模型在执行动作之前需要读取或听取人类用户的提示。另一方面，AI代理的主动性可以帮助人类用户检测并纠正代理观察到的任务中的错误、鼓励用户正确完成任务，或者简单地与用户进行对话，如同人类在指导用户或帮助用户一样。我们提出的YET to Intervene（YETI）多模态代理专注于研究识别需要代理主动干预的情况。这使代理能够理解何时在与人类用户的对话中可以主动干预，以帮助用户纠正任务中的错误，比如烹饪，在AR的帮助下。我们的YETI代理基于连续视频帧的可解释结构相似性（SSIM）学习场景理解信号。我们还定义了对齐信号，该信号使AI代理能够识别出与任务中用户动作对应的视频帧是否与预期动作一致。这些信号被我们的AI代理用于决定何时应主动干预。我们在HoloAssist多模态基准数据集上比较了主动干预实例的实验结果，该基准数据集用于专家代理指导用户完成程序性任务。 

---
# SOP-Agent: Empower General Purpose AI Agent with Domain-Specific SOPs 

**Title (ZH)**: SOP-Agent：赋予通用人工智能代理领域特定的工作流程规范 

**Authors**: Anbang Ye, Qianran Ma, Jia Chen, Muqi Li, Tong Li, Fujiao Liu, Siqi Mai, Meichen Lu, Haitao Bao, Yang You  

**Link**: [PDF](https://arxiv.org/pdf/2501.09316)  

**Abstract**: Despite significant advancements in general-purpose AI agents, several challenges still hinder their practical application in real-world scenarios. First, the limited planning capabilities of Large Language Models (LLM) restrict AI agents from effectively solving complex tasks that require long-horizon planning. Second, general-purpose AI agents struggle to efficiently utilize domain-specific knowledge and human expertise. In this paper, we introduce the Standard Operational Procedure-guided Agent (SOP-agent), a novel framework for constructing domain-specific agents through pseudocode-style Standard Operational Procedures (SOPs) written in natural language. Formally, we represent a SOP as a decision graph, which is traversed to guide the agent in completing tasks specified by the SOP. We conduct extensive experiments across tasks in multiple domains, including decision-making, search and reasoning, code generation, data cleaning, and grounded customer service. The SOP-agent demonstrates excellent versatility, achieving performance superior to general-purpose agent frameworks and comparable to domain-specific agent systems. Additionally, we introduce the Grounded Customer Service Benchmark, the first benchmark designed to evaluate the grounded decision-making capabilities of AI agents in customer service scenarios based on SOPs. 

**Abstract (ZH)**: 尽管通用人工智能代理在技术上取得了显著进展，但在实际应用场景中仍面临着几个挑战。首先，大型语言模型（LLM）的有限规划能力限制了代理在需要长期规划的复杂任务中的有效解决。其次，通用人工智能代理难以高效利用特定领域的知识和人类的专业技能。在本文中，我们提出了标准操作规程引导代理（SOP-agent），这是一种通过自然语言编写的伪代码形式的标准操作规程（SOPs）来构建特定领域代理的新框架。具体而言，我们将SOP表示为决策图，该图在执行过程中引导代理完成由SOP指定的任务。我们在多个领域的任务中进行了广泛的实验，包括决策制定、搜索与推理、代码生成、数据清洗和基于SOP的地面客服。SOP-agent表现出了极高的灵活性，其性能优于通用代理框架，并与特定领域代理系统相当。此外，我们还提出了基于SOP的地面客服基准，这是首个旨在评估AI代理在客户服务场景中基于SOP的决策能力的标准。 

---
# Authenticated Delegation and Authorized AI Agents 

**Title (ZH)**: 认证委托与授权人工智能代理 

**Authors**: Tobin South, Samuele Marro, Thomas Hardjono, Robert Mahari, Cedric Deslandes Whitney, Dazza Greenwood, Alan Chan, Alex Pentland  

**Link**: [PDF](https://arxiv.org/pdf/2501.09674)  

**Abstract**: The rapid deployment of autonomous AI agents creates urgent challenges around authorization, accountability, and access control in digital spaces. New standards are needed to know whom AI agents act on behalf of and guide their use appropriately, protecting online spaces while unlocking the value of task delegation to autonomous agents. We introduce a novel framework for authenticated, authorized, and auditable delegation of authority to AI agents, where human users can securely delegate and restrict the permissions and scope of agents while maintaining clear chains of accountability. This framework builds on existing identification and access management protocols, extending OAuth 2.0 and OpenID Connect with agent-specific credentials and metadata, maintaining compatibility with established authentication and web infrastructure. Further, we propose a framework for translating flexible, natural language permissions into auditable access control configurations, enabling robust scoping of AI agent capabilities across diverse interaction modalities. Taken together, this practical approach facilitates immediate deployment of AI agents while addressing key security and accountability concerns, working toward ensuring agentic AI systems perform only appropriate actions and providing a tool for digital service providers to enable AI agent interactions without risking harm from scalable interaction. 

**Abstract (ZH)**: 自主AI代理的快速部署在数字空间中引发了授权、问责和访问控制方面的紧迫挑战。为了了解AI代理代表谁行事，并适当指导其使用，同时保护在线空间并充分利用任务委派给自主代理的价值，需要新的标准。我们提出了一种新的框架，用于对AI代理进行身份验证、授权和审计委托，使人类用户能够安全地分配并限制代理的权限和范围，同时保持清晰的责任链条。该框架基于现有的身份验证和访问管理协议，扩展了OAuth 2.0和OpenID Connect，添加了针对代理特定的凭证和元数据，保持了与现有认证和网络基础设施的兼容性。此外，我们提出了一种框架，用于将灵活、自然语言的权限翻译成可审计的访问控制配置，从而使AI代理的能力能够在多种交互模式下进行有效的限定。综合起来，这一实用方法可促进AI代理的即时部署，同时解决关键的安全和问责问题，确保自主AI系统仅执行适当的操作，并为数字服务提供商提供工具，使其能够在不冒大规模交互风险的情况下实现AI代理的交互。 

---
# ADAGE: A generic two-layer framework for adaptive agent based modelling 

**Title (ZH)**: ADAGE：一种通用的两层框架，用于自适应代理基于的建模 

**Authors**: Benjamin Patrick Evans, Sihan Zeng, Sumitra Ganesh, Leo Ardon  

**Link**: [PDF](https://arxiv.org/pdf/2501.09429)  

**Abstract**: Agent-based models (ABMs) are valuable for modelling complex, potentially out-of-equilibria scenarios. However, ABMs have long suffered from the Lucas critique, stating that agent behaviour should adapt to environmental changes. Furthermore, the environment itself often adapts to these behavioural changes, creating a complex bi-level adaptation problem. Recent progress integrating multi-agent reinforcement learning into ABMs introduces adaptive agent behaviour, beginning to address the first part of this critique, however, the approaches are still relatively ad hoc, lacking a general formulation, and furthermore, do not tackle the second aspect of simultaneously adapting environmental level characteristics in addition to the agent behaviours. In this work, we develop a generic two-layer framework for ADaptive AGEnt based modelling (ADAGE) for addressing these problems. This framework formalises the bi-level problem as a Stackelberg game with conditional behavioural policies, providing a consolidated framework for adaptive agent-based modelling based on solving a coupled set of non-linear equations. We demonstrate how this generic approach encapsulates several common (previously viewed as distinct) ABM tasks, such as policy design, calibration, scenario generation, and robust behavioural learning under one unified framework. We provide example simulations on multiple complex economic and financial environments, showing the strength of the novel framework under these canonical settings, addressing long-standing critiques of traditional ABMs. 

**Abstract (ZH)**: 基于代理的模型（Agent-Based Models，ABMs）在模拟复杂、可能偏离均衡的场景方面具有重要价值。然而，ABMs长期以来一直受到卢卡斯批判的影响，该批判指出代理行为应适应环境变化。此外，环境本身也往往会对这些行为变化作出调整，从而产生一个复杂的双向适应问题。近期通过将多代理强化学习整合到ABMs中取得了进展，引进入适应性代理行为，开始解决了这一批判的第一部分。然而，目前的方法仍相对粗糙，缺乏通用形式，并且不解决环境特征需要同时适应的问题。在本文中，我们开发了一个通用的双层框架，用于解决这些问题，该框架称为ADaptive AGEnt based modelling（ADAGE）。该框架将双向问题形式化为条件行为策略的斯塔克尔贝格博弈，提供了一个基于求解非线性方程组合的统一框架，用于适应性代理建模。我们展示了这种通用方法如何将几个常见的（曾视为独立的）ABM任务，如政策设计、参数校准、情景生成以及在统一框架下的鲁棒行为学习，统一起来。我们提供了在多种复杂经济和金融环境中的示例模拟，证明了该新型框架在这些经典设置下的优势，并解决了传统ABMs长期存在的批判。 

---
# Attention is All You Need Until You Need Retention 

**Title (ZH)**: "直到需要保留注意力之前，一切只需注意力" 

**Authors**: M. Murat Yaslioglu  

**Link**: [PDF](https://arxiv.org/pdf/2501.09166)  

**Abstract**: This work introduces a novel Retention Layer mechanism for Transformer based architectures, addressing their inherent lack of intrinsic retention capabilities. Unlike human cognition, which can encode and dynamically recall symbolic templates, Generative Pretrained Transformers rely solely on fixed pretrained weights and ephemeral context windows, limiting their adaptability. The proposed Retention Layer incorporates a persistent memory module capable of real time data population, dynamic recall, and guided output generation. This enhancement allows models to store, update, and reuse observed patterns across sessions, enabling incremental learning and bridging the gap between static pretraining and dynamic, context sensitive adaptation. The Retention Layer design parallels social learning processes, encompassing attention, retention, reproduction, and motivation stages. Technically, it integrates a memory attention mechanism and episodic buffers to manage memory scalability, mitigate overfitting, and ensure efficient recall. Applications span adaptive personal assistants, real time fraud detection, autonomous robotics, content moderation, and healthcare diagnostics. In each domain, the retention mechanism enables systems to learn incrementally, personalize outputs, and respond to evolving real world challenges effectively. By emulating key aspects of human learning, this retention enhanced architecture fosters a more fluid and responsive AI paradigm, paving the way for dynamic, session aware models that extend the capabilities of traditional Transformers into domains requiring continual adaptation. 

**Abstract (ZH)**: 本文介绍了一种新颖的保留层机制，用于基于Transformer的架构中，解决了它们固有的内在保留能力不足的问题。与人类认知能够编码并动态回忆符号模板不同，生成预训练Transformer模型依赖于固定的预训练权重和短暂的上下文窗口，这限制了它们的适应性。所提出的保留层集成了一个持久性记忆模块，该模块能够实时数据填充、动态回忆以及引导输出生成。这种增强使得模型能够在不同会话中存储、更新和重用观察到的模式，从而实现增量学习，并弥补静态预训练与动态、上下文敏感适应之间的差距。保留层的设计借鉴了社会学习过程，包括注意力、保留、再现和动机阶段。技术上，该设计集成了记忆注意力机制和情境缓冲区，以管理内存的扩展性、缓解过拟合并确保高效回忆。其应用范围广泛，包括自适应个人助手、实时欺诈检测、自主机器人、内容审核以及医疗诊断。在每个领域中，保留机制使系统能够实现增量学习，个性化输出，并有效应对动态变化的实际挑战。通过模拟人类学习的关键方面，这种增强保留能力的架构促进了更具流动性和响应性的AI范式，开辟了动态、会话感知模型的道路，这些模型将传统Transformer的能力扩展到需要持续适应的领域。 

---
# AutoLoop: Fast Visual SLAM Fine-tuning through Agentic Curriculum Learning 

**Title (ZH)**: 自引导环：通过代理性和课程学习快速进行视觉SLAM微调 

**Authors**: Assaf Lahiany, Oren Gal  

**Link**: [PDF](https://arxiv.org/pdf/2501.09160)  

**Abstract**: Current visual SLAM systems face significant challenges in balancing computational efficiency with robust loop closure handling. Traditional approaches require careful manual tuning and incur substantial computational overhead, while learning-based methods either lack explicit loop closure capabilities or implement them through computationally expensive methods. We present AutoLoop, a novel approach that combines automated curriculum learning with efficient fine-tuning for visual SLAM systems. Our method employs a DDPG (Deep Deterministic Policy Gradient) agent to dynamically adjust loop closure weights during training, eliminating the need for manual hyperparameter search while significantly reducing the required training steps. The approach pre-computes potential loop closure pairs offline and leverages them through an agent-guided curriculum, allowing the model to adapt efficiently to new scenarios. Experiments conducted on TartanAir for training and validated across multiple benchmarks including KITTI, EuRoC, ICL-NUIM and TUM RGB-D demonstrate that AutoLoop achieves comparable or superior performance while reducing training time by an order of magnitude compared to traditional approaches. AutoLoop provides a practical solution for rapid adaptation of visual SLAM systems, automating the weight tuning process that traditionally requires multiple manual iterations. Our results show that this automated curriculum strategy not only accelerates training but also maintains or improves the model's performance across diverse environmental conditions. 

**Abstract (ZH)**: 当前的视觉SLAM系统在平衡计算效率与鲁棒环视匹配处理方面面临重大挑战。传统方法需要精心的手动调参，并且会带来显著的计算开销，而基于学习的方法要么缺乏明确的环视匹配能力，要么通过计算密集型的方法实现。我们提出了AutoLoop，这是一种结合自动化课程学习与高效微调的新型方法，适用于视觉SLAM系统。该方法采用DDPG（深度确定策略梯度）代理，在训练过程中动态调整环视匹配权重，从而消除手动超参数搜索的需要，同时显著减少所需的训练步骤。该方法预先计算潜在的环视匹配对，并通过代理引导的课程学习利用这些对，使模型能够高效适应新的场景。在TartanAir上进行训练，并在多种基准测试中进行验证，包括KITTI、EuRoC、ICL-NUIM和TUM RGB-D，实验结果显示，AutoLoop在训练时间降低一个数量级的同时，可实现类似或优于传统方法的性能。AutoLoop为视觉SLAM系统的快速适应提供了一个实用的解决方案，自动化了传统方法中需要多次手动迭代的权重调整过程。我们的结果表明，这种自动化的课程学习策略不仅加速了训练过程，还能够在各种环境条件下维持或提高模型的性能。 

---
# SteLLA: A Structured Grading System Using LLMs with RAG 

**Title (ZH)**: SteLLA：一种基于LLM和RAG的结构化评分系统

注释：在这句话中，“SteLLA”看起来像是一个专有名词或系统名称，因此保持不变。"LLM"是指大型语言模型（Large Language Model），"RAG"是指检索增强生成（Retrieval-Augmented Generation），这些都是当前学术和工业界讨论的热点话题。 

**Authors**: Hefei Qiu, Brian White, Ashley Ding, Reinaldo Costa, Ali Hachem, Wei Ding, Ping Chen  

**Link**: [PDF](https://arxiv.org/pdf/2501.09092)  

**Abstract**: Large Language Models (LLMs) have shown strong general capabilities in many applications. However, how to make them reliable tools for some specific tasks such as automated short answer grading (ASAG) remains a challenge. We present SteLLA (Structured Grading System Using LLMs with RAG) in which a) Retrieval Augmented Generation (RAG) approach is used to empower LLMs specifically on the ASAG task by extracting structured information from the highly relevant and reliable external knowledge based on the instructor-provided reference answer and rubric, b) an LLM performs a structured and question-answering-based evaluation of student answers to provide analytical grades and feedback. A real-world dataset that contains students' answers in an exam was collected from a college-level Biology course. Experiments show that our proposed system can achieve substantial agreement with the human grader while providing break-down grades and feedback on all the knowledge points examined in the problem. A qualitative and error analysis of the feedback generated by GPT4 shows that GPT4 is good at capturing facts while may be prone to inferring too much implication from the given text in the grading task which provides insights into the usage of LLMs in the ASAG system. 

**Abstract (ZH)**: 大规模语言模型（LLMs）在许多应用中展示了强大的通用能力。然而，如何使它们成为某些特定任务（如自动化简答评分，ASAG）的可靠工具仍然是一个挑战。我们提出了SteLLA（基于LLM与RAG的结构化评分系统），其中：
a) 使用检索增强生成（RAG）方法，通过从与参考答案和评分标准高度相关且可靠的外部知识中提取结构化信息，具体提升LLM在ASAG任务上的能力；
b) 一个LLM通过结构化和基于问题的答案评估来对学生答案进行评分和反馈，从而提供分析性评分和反馈。
我们从一门大学生物学课程的考试中收集了一个包含学生答案的现实世界数据集。实验结果表明，我们提出系统的评分结果与人类评分者之间具有显著的一致性，同时提供了所有知识点的详细评分和反馈。对GPT4生成的反馈进行定性和错误分析后发现，GPT4在捕捉事实方面表现良好，但在评分任务中可能会从给定文本中过分推断含义，这为LLMs在ASAG系统中的应用提供了见解。 

---
