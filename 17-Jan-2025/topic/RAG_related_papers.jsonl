{'arxiv_id': 'arXiv:2501.09292', 'title': 'To Retrieve or Not to Retrieve? Uncertainty Detection for Dynamic Retrieval Augmented Generation', 'authors': 'Kaustubh D. Dhole', 'link': 'https://arxiv.org/abs/2501.09292', 'abstract': 'Retrieval-Augmented Generation equips large language models with the capability to retrieve external knowledge, thereby mitigating hallucinations by incorporating information beyond the model\'s intrinsic abilities. However, most prior works have focused on invoking retrieval deterministically, which makes it unsuitable for tasks such as long-form question answering. Instead, dynamically performing retrieval by invoking it only when the underlying LLM lacks the required knowledge can be more efficient. In this context, we delve deeper into the question, "To Retrieve or Not to Retrieve?" by exploring multiple uncertainty detection methods. We evaluate these methods for the task of long-form question answering, employing dynamic retrieval, and present our comparisons. Our findings suggest that uncertainty detection metrics, such as Degree Matrix Jaccard and Eccentricity, can reduce the number of retrieval calls by almost half, with only a slight reduction in question-answering accuracy.', 'abstract_zh': '检索增强生成使大规模语言模型具备检索外部知识的能力，从而通过结合模型内在能力之外的信息来减轻幻觉现象。然而，大多数前期工作都集中在以确定性方式触发检索上，这使其不适合长文本问答等任务。相反，仅在基础语言模型缺乏所需知识时动态地触发检索可能是更有效的。在此背景下，我们深入探讨了“检索还是不检索？”这一问题，探索了多种不确定性检测方法。我们使用动态检索对长文本问答任务进行了评估，并展示了我们的比较结果。我们的研究发现，诸如度矩阵雅卡尔距离和偏心率等不确定性检测指标，可以将检索调用次数减少近一半，同时仅轻微降低问答准确性。', 'title_zh': '是取用还是不取用？动态检索增强生成中的不确定性检测'}
{'arxiv_id': 'arXiv:2501.09092', 'title': 'SteLLA: A Structured Grading System Using LLMs with RAG', 'authors': 'Hefei Qiu, Brian White, Ashley Ding, Reinaldo Costa, Ali Hachem, Wei Ding, Ping Chen', 'link': 'https://arxiv.org/abs/2501.09092', 'abstract': "Large Language Models (LLMs) have shown strong general capabilities in many applications. However, how to make them reliable tools for some specific tasks such as automated short answer grading (ASAG) remains a challenge. We present SteLLA (Structured Grading System Using LLMs with RAG) in which a) Retrieval Augmented Generation (RAG) approach is used to empower LLMs specifically on the ASAG task by extracting structured information from the highly relevant and reliable external knowledge based on the instructor-provided reference answer and rubric, b) an LLM performs a structured and question-answering-based evaluation of student answers to provide analytical grades and feedback. A real-world dataset that contains students' answers in an exam was collected from a college-level Biology course. Experiments show that our proposed system can achieve substantial agreement with the human grader while providing break-down grades and feedback on all the knowledge points examined in the problem. A qualitative and error analysis of the feedback generated by GPT4 shows that GPT4 is good at capturing facts while may be prone to inferring too much implication from the given text in the grading task which provides insights into the usage of LLMs in the ASAG system.", 'abstract_zh': '大规模语言模型（LLMs）在许多应用中展示了强大的通用能力。然而，如何使它们成为某些特定任务（如自动化简答评分，ASAG）的可靠工具仍然是一个挑战。我们提出了SteLLA（基于LLM与RAG的结构化评分系统），其中：\na) 使用检索增强生成（RAG）方法，通过从与参考答案和评分标准高度相关且可靠的外部知识中提取结构化信息，具体提升LLM在ASAG任务上的能力；\nb) 一个LLM通过结构化和基于问题的答案评估来对学生答案进行评分和反馈，从而提供分析性评分和反馈。\n我们从一门大学生物学课程的考试中收集了一个包含学生答案的现实世界数据集。实验结果表明，我们提出系统的评分结果与人类评分者之间具有显著的一致性，同时提供了所有知识点的详细评分和反馈。对GPT4生成的反馈进行定性和错误分析后发现，GPT4在捕捉事实方面表现良好，但在评分任务中可能会从给定文本中过分推断含义，这为LLMs在ASAG系统中的应用提供了见解。', 'title_zh': 'SteLLA：一种基于LLM和RAG的结构化评分系统\n\n注释：在这句话中，“SteLLA”看起来像是一个专有名词或系统名称，因此保持不变。"LLM"是指大型语言模型（Large Language Model），"RAG"是指检索增强生成（Retrieval-Augmented Generation），这些都是当前学术和工业界讨论的热点话题。'}
