{'arxiv_id': 'arXiv:2412.12509', 'title': 'Can You Trust LLM Judgments? Reliability of LLM-as-a-Judge', 'authors': 'Kayla Schroeder, Zach Wood-Doughty', 'link': 'https://arxiv.org/abs/2412.12509', 'abstract': "Large Language Models (LLMs) have become increasingly powerful and ubiquitous, but their stochastic nature poses challenges to the reliability of their outputs. While deterministic settings can improve consistency, they do not guarantee reliability, as a single sample from the model's probability distribution can still be misleading. Building upon the concept of LLM-as-a-judge, we introduce a novel framework for rigorously evaluating the reliability of LLM judgments, leveraging McDonald's omega. We evaluate the reliability of LLMs when judging the outputs of other LLMs on standard single-turn and multi-turn benchmarks, simultaneously investigating the impact of temperature on reliability. By analyzing these results, we demonstrate the limitations of fixed randomness and the importance of considering multiple samples, which we show has significant implications for downstream applications. Our findings highlight the need for a nuanced understanding of LLM reliability and the potential risks associated with over-reliance on single-shot evaluations. This work provides a crucial step towards building more trustworthy and reliable LLM-based systems and applications.", 'abstract_zh': '大型语言模型（LLMs）越来越强大且普及，但它们的随机性给输出的可靠性带来了挑战。虽然确定性设置可以提高一致性，但无法确保可靠性，因为模型概率分布中的单一样本仍然可能误导性。基于LLM作为裁判的概念，我们提出了一种新的框架来严格评估LLM判决的可靠性，并利用麦当劳的ω系数进行评估。我们对LLM在评估其他LLM输出的标准单轮和多轮基准上的可靠性进行了评估，同时探讨了温度对可靠性的潜在影响。通过对这些结果的分析，我们展示了固定随机性限制和考虑多个样本的重要性，这些发现对于下游应用程序具有重要影响。我们的研究结果突显了对LLM可靠性需要精微理解的必要性以及过度依赖单次评估可能带来的潜在风险。这项工作为构建更值得信赖的LLM基础系统和应用程序提供了关键步骤。', 'title_zh': '你能否信任大语言模型的判断？大语言模型作为法官的可靠性探究'}
