# From An LLM Swarm To A PDDL-Empowered HIVE: Planning Self-Executed Instructions In A Multi-Modal Jungle 

**Title (ZH)**: 从LLM群 Swarm 到PDDL赋能的HIVE：在多模态环境中规划自执行指令 

**Authors**: Kaustubh Vyas, Damien Graux, Yijun Yang, Sébastien Montella, Chenxin Diao, Wendi Zhou, Pavlos Vougiouklis, Ruofei Lai, Yang Ren, Keshuang Li, Jeff Z. Pan  

**Link**: [PDF](https://arxiv.org/pdf/2412.12839)  

**Abstract**: In response to the call for agent-based solutions that leverage the ever-increasing capabilities of the deep models' ecosystem, we introduce Hive -- a comprehensive solution for selecting appropriate models and subsequently planning a set of atomic actions to satisfy the end-users' instructions. Hive operates over sets of models and, upon receiving natural language instructions (i.e. user queries), schedules and executes explainable plans of atomic actions. These actions can involve one or more of the available models to achieve the overall task, while respecting end-users specific constraints. Notably, Hive handles tasks that involve multi-modal inputs and outputs, enabling it to handle complex, real-world queries. Our system is capable of planning complex chains of actions while guaranteeing explainability, using an LLM-based formal logic backbone empowered by PDDL operations. We introduce the MuSE benchmark in order to offer a comprehensive evaluation of the multi-modal capabilities of agent systems. Our findings show that our framework redefines the state-of-the-art for task selection, outperforming other competing systems that plan operations across multiple models while offering transparency guarantees while fully adhering to user constraints. 

**Abstract (ZH)**: 为了应对利用深度模型生态系统日益增强的能力而呼吁的代理解决方案需求，我们引入了Hive——一种全面的解决方案，用于选择合适模型，并随后规划一系列原子动作以满足最终用户的需求。Hive能够在多个模型集合上操作，并在接收自然语言指令（即用户查询）后，调度并执行可解释的原子动作计划。这些动作可以涉及可用模型中的一个或多个，以完成整体任务，同时遵守最终用户的特定约束。值得注意的是，Hive能够处理涉及多模态输入和输出的任务，从而能够处理复杂的、现实世界中的查询。我们的系统利用基于大语言模型的形式逻辑基础架构并通过PDDL操作确保可解释性，可以规划复杂的动作链。我们引入了MuSE基准测试，以提供对代理系统多模态能力的全面评估。我们的研究结果表明，我们的框架重新定义了任务选择的最新技术，优于其他在多个模型上规划操作的竞争系统，同时还提供了透明性保证，严格遵守用户约束。 

---
# A Scalable Approach to Benchmarking the In-Conversation Differential Diagnostic Accuracy of a Health AI 

**Title (ZH)**: 一种可扩展的方法，用于benchmarking 健康AI在对话过程中的鉴别诊断准确性 

**Authors**: Deep Bhatt, Surya Ayyagari, Anuruddh Mishra  

**Link**: [PDF](https://arxiv.org/pdf/2412.12538)  

**Abstract**: Diagnostic errors in healthcare persist as a critical challenge, with increasing numbers of patients turning to online resources for health information. While AI-powered healthcare chatbots show promise, there exists no standardized and scalable framework for evaluating their diagnostic capabilities. This study introduces a scalable benchmarking methodology for assessing health AI systems and demonstrates its application through August, an AI-driven conversational chatbot. Our methodology employs 400 validated clinical vignettes across 14 medical specialties, using AI-powered patient actors to simulate realistic clinical interactions. In systematic testing, August achieved a top-one diagnostic accuracy of 81.8% (327/400 cases) and a top-two accuracy of 85.0% (340/400 cases), significantly outperforming traditional symptom checkers. The system demonstrated 95.8% accuracy in specialist referrals and required 47% fewer questions compared to conventional symptom checkers (mean 16 vs 29 questions), while maintaining empathetic dialogue throughout consultations. These findings demonstrate the potential of AI chatbots to enhance healthcare delivery, though implementation challenges remain regarding real-world validation and integration of objective clinical data. This research provides a reproducible framework for evaluating healthcare AI systems, contributing to the responsible development and deployment of AI in clinical settings. 

**Abstract (ZH)**: 医疗领域的诊断错误仍是一个关键性的挑战，不断增加的患者开始转向网络资源寻求健康信息。尽管基于人工智能（AI）的医疗聊天机器人展现出了潜力，但目前尚无标准化且可扩展的框架来评估其诊断能力。本研究介绍了一种可扩展的基准测试方法，用于评估健康AI系统，并通过案例“August”——一个基于AI的对话聊天机器人——演示了该方法的应用。我们的方法使用了涵盖14个医学专科的400个经验证的临床案例，通过AI驱动的虚拟患者模拟真实的临床互动。在系统测试中，August在81.8%（327/400）的案例中实现了顶级诊断准确率，在85.0%（340/400）的案例中实现了前两位的准确率，显著优于传统的症状检查工具。该系统在专科转诊上的准确率达到95.8%，所需问题数量比传统症状检查工具少了47%（平均16对29个问题），同时在咨询过程中保持了同理心对话。这些研究结果表明，AI聊天机器人的使用有可能改善医疗服务，但实施过程中仍面临真实世界验证和客观临床数据整合的挑战。本研究提供了一种可重現的框架，用于评估健康AI系统，有助于负责任地开发和部署AI在临床环境中的使用。 

---
# How Different AI Chatbots Behave? Benchmarking Large Language Models in Behavioral Economics Games 

**Title (ZH)**: 不同AI聊天机器人表现出怎样的行为？大型语言模型在行为经济学游戏中的基准测试 

**Authors**: Yutong Xie, Yiyao Liu, Zhuang Ma, Lin Shi, Xiyuan Wang, Walter Yuan, Matthew O. Jackson, Qiaozhu Mei  

**Link**: [PDF](https://arxiv.org/pdf/2412.12362)  

**Abstract**: The deployment of large language models (LLMs) in diverse applications requires a thorough understanding of their decision-making strategies and behavioral patterns. As a supplement to a recent study on the behavioral Turing test, this paper presents a comprehensive analysis of five leading LLM-based chatbot families as they navigate a series of behavioral economics games. By benchmarking these AI chatbots, we aim to uncover and document both common and distinct behavioral patterns across a range of scenarios. The findings provide valuable insights into the strategic preferences of each LLM, highlighting potential implications for their deployment in critical decision-making roles. 

**Abstract (ZH)**: 将大型语言模型（LLMs）应用于各种不同的领域需要对其决策机制和行为模式有全面的理解。作为对近期关于行为图灵测试研究的补充，本文对五种领先的大语言模型（LLM）基聊天机器人家族在一系列行为经济学游戏中表现出的行为进行了综合分析。通过对比这些AI聊天机器人的表现，我们旨在揭示和记录在不同情境下它们的共同和独特的行为模式。这些发现为理解每个LLM的战略偏好提供了宝贵的洞见，并凸显了它们在关键决策角色中部署的潜在影响。 

---
# Proposer-Agent-Evaluator(PAE): Autonomous Skill Discovery For Foundation Model Internet Agents 

**Title (ZH)**: 提案者-代理者-评估者(PAE): 基础模型互联网代理的自主技能发现方法 

**Authors**: Yifei Zhou, Qianlan Yang, Kaixiang Lin, Min Bai, Xiong Zhou, Yu-Xiong Wang, Sergey Levine, Erran Li  

**Link**: [PDF](https://arxiv.org/pdf/2412.13194)  

**Abstract**: The vision of a broadly capable and goal-directed agent, such as an Internet-browsing agent in the digital world and a household humanoid in the physical world, has rapidly advanced, thanks to the generalization capability of foundation models. Such a generalist agent needs to have a large and diverse skill repertoire, such as finding directions between two travel locations and buying specific items from the Internet. If each skill needs to be specified manually through a fixed set of human-annotated instructions, the agent's skill repertoire will necessarily be limited due to the quantity and diversity of human-annotated instructions. In this work, we address this challenge by proposing Proposer-Agent-Evaluator, an effective learning system that enables foundation model agents to autonomously discover and practice skills in the wild. At the heart of PAE is a context-aware task proposer that autonomously proposes tasks for the agent to practice with context information of the environment such as user demos or even just the name of the website itself for Internet-browsing agents. Then, the agent policy attempts those tasks with thoughts and actual grounded operations in the real world with resulting trajectories evaluated by an autonomous VLM-based success evaluator. The success evaluation serves as the reward signal for the agent to refine its policies through RL. We validate PAE on challenging vision-based web navigation, using both real-world and self-hosted websites from WebVoyager and this http URL the best of our knowledge, this work represents the first effective learning system to apply autonomous task proposal with RL for agents that generalizes real-world human-annotated benchmarks with SOTA performances. Our open-source checkpoints and code can be found in this https URL 

**Abstract (ZH)**: 本研究探讨了在数字世界中的互联网浏览代理和在物理世界中的家庭类人机器人等广泛能力和目标导向代理的长远愿景，得益于基础模型的泛化能力，这一领域的技术正在迅速发展。这类通用代理需要拥有广泛的技能组合，例如在两个旅行地点之间寻找路线和从互联网上购买特定物品。如果每个技能都需要通过固定的人标注指令集手动指定，由于人标注指令的数量和多样性限制，代理的技能组合必然会受到限制。

为了解决这一挑战，我们提出了一种有效的学习系统——Proposer-Agent-Evaluator（PAE），使基础模型代理能够在现实环境中自主发现和练习技能。PAE的核心是一个基于环境上下文（如用户示例或网站名称本身）的信息感知任务发起者，能够自动为代理提出任务。接着，代理策略尝试这些任务，并通过实际操作在真实世界中进行，最终由一个自主的基于VLM的成功评估器来评估任务的结果轨迹。成功评估器提供的奖励信号促使代理通过强化学习（RL）来改进其策略。我们使用WebVoyager等真实世界和自托管网站验证了PAE在视觉基础上的网络导航任务中的有效性。据我们所知，这项工作代表了首次利用自主任务提议与RL相结合的方法，使代理能够泛化实际世界中的人标注基准，并实现最先进的性能。有关开源的模型检查点和代码，您可以在以下链接中找到：[此处链接]。 

---
# SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents 

**Title (ZH)**: SafeAgentBench：实体化大语言模型代理安全任务规划的基准测试 

**Authors**: Sheng Yin, Xianghe Pang, Yuanzhuo Ding, Menglan Chen, Yutong Bi, Yichen Xiong, Wenhao Huang, Zhen Xiang, Jing Shao, Siheng Chen  

**Link**: [PDF](https://arxiv.org/pdf/2412.13178)  

**Abstract**: With the integration of large language models (LLMs), embodied agents have strong capabilities to execute complicated instructions in natural language, paving a way for the potential deployment of embodied robots. However, a foreseeable issue is that those embodied agents can also flawlessly execute some hazardous tasks, potentially causing damages in real world. To study this issue, we present SafeAgentBench -- a new benchmark for safety-aware task planning of embodied LLM agents. SafeAgentBench includes: (1) a new dataset with 750 tasks, covering 10 potential hazards and 3 task types; (2) SafeAgentEnv, a universal embodied environment with a low-level controller, supporting multi-agent execution with 17 high-level actions for 8 state-of-the-art baselines; and (3) reliable evaluation methods from both execution and semantic perspectives. Experimental results show that the best-performing baseline gets 69% success rate for safe tasks, but only 5% rejection rate for hazardous tasks, indicating significant safety risks. More details and codes are available at this https URL. 

**Abstract (ZH)**: 随着大型语言模型（LLMs）的集成，具身代理在执行自然语言复杂的指令方面表现出强大的能力，为具身机器人潜在部署开辟了道路。然而，一个可预见的问题是，这些具身代理也可能完美地执行某些危险任务，从而在现实世界中造成损害。为研究这一问题，我们提出了SafeAgentBench——一个新的安全感知任务规划基准，用于具身LLM代理。SafeAgentBench 包括：(1)一个包含750项任务的新数据集，涵盖10种潜在风险和3种任务类型；(2)SafeAgentEnv，一个通用的具身环境，配有低级控制器，支持多代理执行，并提供17种高阶动作供8种前沿基线使用；以及(3)从执行和语义两个视角进行的可靠评估方法。实验结果显示，表现最好的基线在安全任务上的成功率为69%，而在危险任务上的拒识率为5%，表明存在显著的安全风险。更多详细信息和代码可访问以下链接：[请在此处插入链接]。 

---
# AI PERSONA: Towards Life-long Personalization of LLMs 

**Title (ZH)**: AI 人格：走向大规模语言模型的终身个性化 

**Authors**: Tiannan Wang, Meiling Tao, Ruoyu Fang, Huilin Wang, Shuai Wang, Yuchen Eleanor Jiang, Wangchunshu Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2412.13103)  

**Abstract**: In this work, we introduce the task of life-long personalization of large language models. While recent mainstream efforts in the LLM community mainly focus on scaling data and compute for improved capabilities of LLMs, we argue that it is also very important to enable LLM systems, or language agents, to continuously adapt to the diverse and ever-changing profiles of every distinct user and provide up-to-date personalized assistance. We provide a clear task formulation and introduce a simple, general, effective, and scalable framework for life-long personalization of LLM systems and language agents. To facilitate future research on LLM personalization, we also introduce methods to synthesize realistic benchmarks and robust evaluation metrics. We will release all codes and data for building and benchmarking life-long personalized LLM systems. 

**Abstract (ZH)**: 在本文中，我们探讨了大型语言模型终身个性化这一任务。尽管语言模型（LLM）社区近期的主要努力主要集中在通过扩大数据和计算资源来提高语言模型的能力，我们认为同样重要的是使语言模型系统或语言代理能够持续适应每个独特用户的多样且不断变化的特征，并提供及时个性化的辅助。我们提供了一个明确的任务定义，并引入了一个简单、通用、有效且可扩展的框架，用于终身个性化语言模型系统和语言代理。为了促进未来在语言模型个性化方面的研究，我们还介绍了合成现实基准和稳健评估指标的方法。我们将提供构建和基准测试终身个性化语言模型系统所需的所有代码和数据。 

---
# SMOSE: Sparse Mixture of Shallow Experts for Interpretable Reinforcement Learning in Continuous Control Tasks 

**Title (ZH)**: SMOSE：稀疏混合浅专家模型在连续控制任务中的可解释强化学习 

**Authors**: Mátyás Vincze, Laura Ferrarotti, Leonardo Lucio Custode, Bruno Lepri, Giovanni Iacca  

**Link**: [PDF](https://arxiv.org/pdf/2412.13053)  

**Abstract**: Continuous control tasks often involve high-dimensional, dynamic, and non-linear environments. State-of-the-art performance in these tasks is achieved through complex closed-box policies that are effective, but suffer from an inherent opacity. Interpretable policies, while generally underperforming compared to their closed-box counterparts, advantageously facilitate transparent decision-making within automated systems. Hence, their usage is often essential for diagnosing and mitigating errors, supporting ethical and legal accountability, and fostering trust among stakeholders. In this paper, we propose SMOSE, a novel method to train sparsely activated interpretable controllers, based on a top-1 Mixture-of-Experts architecture. SMOSE combines a set of interpretable decisionmakers, trained to be experts in different basic skills, and an interpretable router that assigns tasks among the experts. The training is carried out via state-of-the-art Reinforcement Learning algorithms, exploiting load-balancing techniques to ensure fair expert usage. We then distill decision trees from the weights of the router, significantly improving the ease of interpretation. We evaluate SMOSE on six benchmark environments from MuJoCo: our method outperforms recent interpretable baselines and narrows the gap with noninterpretable state-of-the-art algorithms 

**Abstract (ZH)**: 连续控制任务通常涉及高维度、动态和非线性的环境。在这些任务中，最先进的性能是由复杂的黑盒策略实现的，这些策略虽然有效，但具有固有的不透明性。可解释的策略虽然通常在性能上不如其黑盒对应物，但其优点在于能够促进自动化系统中的透明决策过程。因此，它们在诊断和缓解错误、支持伦理和法律责任以及增强利益相关者的信任方面往往是必不可少的。本文提出了一种名为SMOSE的新方法，该方法基于Top-1 Mixture-of-Experts架构来训练稀疏激活的可解释控制器。SMOSE结合了一组可解释的决策者，它们分别擅长不同的基本技能，以及一个可解释的路由器，用于分配任务给专家。通过利用负载均衡技术进行训练，确保公平地使用专家。然后，我们从路由器的权重中提取决策树，显著提高了解释的简便性。我们将在MuJoCo的六个基准环境中评估SMOSE，结果显示我们的方法优于最近的可解释基线，并缩小了与不可解释的最先进的非基线算法之间的性能差距。 

---
# Neural-Network-Driven Reward Prediction as a Heuristic: Advancing Q-Learning for Mobile Robot Path Planning 

**Title (ZH)**: 基于神经网络驱动的奖励预测作为启发式方法：推进用于移动机器人路径规划的Q学习 

**Authors**: Yiming Ji, Kaijie Yun, Yang Liu, Zongwu Xie, Hong Liu  

**Link**: [PDF](https://arxiv.org/pdf/2412.12650)  

**Abstract**: Q-learning is a widely used reinforcement learning technique for solving path planning problems. It primarily involves the interaction between an agent and its environment, enabling the agent to learn an optimal strategy that maximizes cumulative rewards. Although many studies have reported the effectiveness of Q-learning, it still faces slow convergence issues in practical applications. To address this issue, we propose the NDR-QL method, which utilizes neural network outputs as heuristic information to accelerate the convergence process of Q-learning. Specifically, we improved the dual-output neural network model by introducing a start-end channel separation mechanism and enhancing the feature fusion process. After training, the proposed NDR model can output a narrowly focused optimal probability distribution, referred to as the guideline, and a broadly distributed suboptimal distribution, referred to as the region. Subsequently, based on the guideline prediction, we calculate the continuous reward function for the Q-learning method, and based on the region prediction, we initialize the Q-table with a bias. We conducted training, validation, and path planning simulation experiments on public datasets. The results indicate that the NDR model outperforms previous methods by up to 5\% in prediction accuracy. Furthermore, the proposed NDR-QL method improves the convergence speed of the baseline Q-learning method by 90\% and also surpasses the previously improved Q-learning methods in path quality metrics. 

**Abstract (ZH)**: Q-learning 是一种广泛应用于解决路径规划问题的强化学习技术。它主要涉及智能体与环境之间的互动，使智能体能够学会一种最大化累积奖励的最优策略。尽管许多研究已经报告了 Q-learning 的有效性，但在实际应用中它仍然面临收敛速度慢的问题。为解决这一问题，我们提出了 NDR-QL 方法，该方法利用神经网络输出作为启发式信息，以加速 Q-learning 的收敛过程。具体而言，我们通过引入起终点通道分离机制和增强特征融合过程改进了双输出神经网络模型。经过训练后，提出的 NDR 模型可以输出一个狭窄且聚焦的最优概率分布，称为指导分布，以及一个广泛分布的次优分布，称为区域。随后，基于指导分布的预测，我们计算 Q-learning 方法的连续奖励函数；基于区域的预测，我们为 Q-table 初始化一个偏向。我们在公开数据集上进行了训练、验证和路径规划模拟实验。结果显示，NDR 模型在预测精度上比之前的方法高了 5%。此外，提出的 NDR-QL 方法将基线 Q-learning 方法的收敛速度提高了 90%，同时也在路径质量指标上超过了之前改进的 Q-learning 方法。 

---
# Subversion Strategy Eval: Evaluating AI's stateless strategic capabilities against control protocols 

**Title (ZH)**: 潜伏策略评估：评估AI在无状态策略能力方面与控制协议的对比优势 

**Authors**: Alex Mallen, Charlie Griffin, Alessandro Abate, Buck Shlegeris  

**Link**: [PDF](https://arxiv.org/pdf/2412.12480)  

**Abstract**: AI control protocols are plans for usefully deploying AI systems in a way that is safe, even if the AI intends to subvert the protocol. Previous work evaluated protocols by subverting them with a human-AI red team, where an AI follows the human-written strategy. This paper investigates how well AI systems can generate and act on strategies for subverting control protocols whilst operating without private memory. Usually, decision-makers only need the ability to generate optimal plans. However, to subvert a protocol, an AI system must be able to reliably generate optimal plans in each context; coordinate plans with other instances of itself without communicating; and take actions with well-calibrated probabilities. We develop evaluations for a model's ability to generate subversion strategies and develop affordance experiments that help isolate component capabilities. Our initial evaluations with Claude-3.5-sonnet highlight reasons why statelessly strategizing to subvert control protocols might be hard. We hope that our work can serve as a starting point for evaluations aimed at assessing whether a model is capable of strategizing to subvert control protocols. 

**Abstract (ZH)**: AI控制协议是指一种有效部署AI系统的方法，即使AI有意颠覆该协议也能确保安全。先前的研究通过由人类-AI红队实施颠覆来评估这些协议，即AI遵循人类编写的策略执行颠覆行为。本文探讨了AI系统在没有私有记忆的情况下生成并执行颠覆控制协议策略的能力。通常，决策者仅需要具备生成最优计划的能力。然而，要颠覆一个协议，AI系统必须在每个上下文中可靠地生成最优计划；不通过通信就能与其他自身实例协调计划；并且采取精确概率的动作。我们开发了评估模型生成颠覆策略能力的标准，并设计了功能实验以分离出各个组成部分的能力。我们对Claude-3.5-Sonnet的初步评估指出了为何在没有状态的情况下制定颠覆控制协议策略可能是困难的。我们希望我们的研究能够成为评估模型是否能够制定颠覆控制协议策略标准的基础。 

---
# RareAgents: Autonomous Multi-disciplinary Team for Rare Disease Diagnosis and Treatment 

**Title (ZH)**: RareAgents：自主多学科团队在罕见病诊断与治疗中的应用 

**Authors**: Xuanzhong Chen, Ye Jin, Xiaohao Mao, Lun Wang, Shuyang Zhang, Ting Chen  

**Link**: [PDF](https://arxiv.org/pdf/2412.12475)  

**Abstract**: Rare diseases, despite their low individual incidence, collectively impact around 300 million people worldwide due to the huge number of diseases. The complexity of symptoms and the shortage of specialized doctors with relevant experience make diagnosing and treating rare diseases more challenging than common diseases. Recently, agents powered by large language models (LLMs) have demonstrated notable improvements across various domains. In the medical field, some agent methods have outperformed direct prompts in question-answering tasks from medical exams. However, current agent frameworks lack adaptation for real-world clinical scenarios, especially those involving the intricate demands of rare diseases. To address these challenges, we present RareAgents, the first multi-disciplinary team of LLM-based agents tailored to the complex clinical context of rare diseases. RareAgents integrates advanced planning capabilities, memory mechanisms, and medical tools utilization, leveraging Llama-3.1-8B/70B as the base model. Experimental results show that RareAgents surpasses state-of-the-art domain-specific models, GPT-4o, and existing agent frameworks in both differential diagnosis and medication recommendation for rare diseases. Furthermore, we contribute a novel dataset, MIMIC-IV-Ext-Rare, derived from MIMIC-IV, to support further advancements in this field. 

**Abstract (ZH)**: 稀有疾病尽管单个疾病的发病率较低，但由于疾病种类繁多，全球约有3亿人受到这些疾病的集体影响。症状复杂性和缺乏相关经验的专业医生使得诊断和治疗稀有疾病比常见疾病更加具有挑战性。最近，由大规模语言模型（LLMs）驱动的代理已经在多个领域展示出了显著的进步。在医疗领域，一些代理方法在医学考试中的问答任务中已经超越了直接提示。然而，当前的代理框架缺乏针对真实临床场景的适应性，特别是那些涉及稀有疾病复杂需求的场景。为了解决这些挑战，我们提出了RareAgents，这是第一个针对稀有疾病复杂临床环境的多学科团队，基于LLM的代理。RareAgents集成了先进的规划能力、记忆机制和医疗工具的应用，以LLama-3.1-8B/70B作为基础模型。实验结果表明，RareAgents在稀有疾病的鉴别诊断和药物推荐方面优于现有的领域特定模型GPT-4o和现有的代理框架。此外，我们贡献了一个新的数据集MIMIC-IV-Ext-Rare，该数据集源自MIMIC-IV，以支持该领域进一步的发展。 

---
# BioRAGent: A Retrieval-Augmented Generation System for Showcasing Generative Query Expansion and Domain-Specific Search for Scientific Q&A 

**Title (ZH)**: BioRAGent：一种用于展示生成性查询扩展和领域特定搜索的检索增强生成系统 

**Authors**: Samy Ateia, Udo Kruschwitz  

**Link**: [PDF](https://arxiv.org/pdf/2412.12358)  

**Abstract**: We present BioRAGent, an interactive web-based retrieval-augmented generation (RAG) system for biomedical question answering. The system uses large language models (LLMs) for query expansion, snippet extraction, and answer generation while maintaining transparency through citation links to the source documents and displaying generated queries for further editing. Building on our successful participation in the BioASQ 2024 challenge, we demonstrate how few-shot learning with LLMs can be effectively applied for a professional search setting. The system supports both direct short paragraph style responses and responses with inline citations. Our demo is available online, and the source code is publicly accessible through GitHub. 

**Abstract (ZH)**: 我们提出了BioRAGent，这是一个基于网页的交互式检索增强生成（RAG）系统，用于生物医学问题回答。该系统利用大规模语言模型（LLM）进行查询扩展、片段提取和答案生成，并通过引用链接透明地显示源文档，同时展示生成的查询以便进一步编辑。基于我们在BioASQ 2024挑战赛中的成功参与，我们展示了如何有效地将少量示例学习应用于专业搜索场景中。该系统支持直接简洁段落样式回复和包含内联引文的回复。我们的演示已在线提供，并且源代码可通过GitHub公开访问。 

---
# Achieving Collective Welfare in Multi-Agent Reinforcement Learning via Suggestion Sharing 

**Title (ZH)**: 通过建议共享实现多智能体强化学习中的集体福利 

**Authors**: Yue Jin, Shuangqing Wei, Giovanni Montana  

**Link**: [PDF](https://arxiv.org/pdf/2412.12326)  

**Abstract**: In human society, the conflict between self-interest and collective well-being often obstructs efforts to achieve shared welfare. Related concepts like the Tragedy of the Commons and Social Dilemmas frequently manifest in our daily lives. As artificial agents increasingly serve as autonomous proxies for humans, we propose using multi-agent reinforcement learning (MARL) to address this issue - learning policies to maximise collective returns even when individual agents' interests conflict with the collective one. Traditional MARL solutions involve sharing rewards, values, and policies or designing intrinsic rewards to encourage agents to learn collectively optimal policies. We introduce a novel MARL approach based on Suggestion Sharing (SS), where agents exchange only action suggestions. This method enables effective cooperation without the need to design intrinsic rewards, achieving strong performance while revealing less private information compared to sharing rewards, values, or policies. Our theoretical analysis establishes a bound on the discrepancy between collective and individual objectives, demonstrating how sharing suggestions can align agents' behaviours with the collective objective. Experimental results demonstrate that SS performs competitively with baselines that rely on value or policy sharing or intrinsic rewards. 

**Abstract (ZH)**: 在人类社会中，个体利益与集体福祉之间的冲突常阻碍共享福利目标的实现。相关概念如“公地悲剧”和社会困境在日常生活中频繁出现。随着人工代理越来越多地作为自主代表为人类服务，我们提出使用多智能体强化学习（MARL）来解决这一问题——即使个体代理的个人利益与集体利益相冲突时，学习能够最大化集体收益的策略。传统MARL解决方案涉及共享奖励、价值或策略，或者设计内在奖励以促使智能体学习集体最优策略。我们提出了一种基于建议共享（SS）的新型MARL方法，其中智能体仅交换行动建议。这种方法可以在无需设计内在奖励的情况下实现有效的合作，相较于共享奖励、价值或策略，这种做法能较少泄露私人信息，同时表现出优异的性能。我们的理论分析建立了集体目标与个体目标之间差异的界限，展示了如何通过共享建议来使智能体的行为与集体目标更加一致。实验结果表明，SS在基线方法（依赖于价值或策略共享或内在奖励）中表现出了竞争力。 

---
# RAG Playground: A Framework for Systematic Evaluation of Retrieval Strategies and Prompt Engineering in RAG Systems 

**Title (ZH)**: RAG游乐场：一种评估RAG系统中检索策略和提示工程系统的框架 

**Authors**: Ioannis Papadimitriou, Ilias Gialampoukidis, Stefanos Vrochidis, Ioannis, Kompatsiaris  

**Link**: [PDF](https://arxiv.org/pdf/2412.12322)  

**Abstract**: We present RAG Playground, an open-source framework for systematic evaluation of Retrieval-Augmented Generation (RAG) systems. The framework implements and compares three retrieval approaches: naive vector search, reranking, and hybrid vector-keyword search, combined with ReAct agents using different prompting strategies. We introduce a comprehensive evaluation framework with novel metrics and provide empirical results comparing different language models (Llama 3.1 and Qwen 2.5) across various retrieval configurations. Our experiments demonstrate significant performance improvements through hybrid search methods and structured self-evaluation prompting, achieving up to 72.7% pass rate on our multi-metric evaluation framework. The results also highlight the importance of prompt engineering in RAG systems, with our custom-prompted agents showing consistent improvements in retrieval accuracy and response quality. 

**Abstract (ZH)**: 我们介绍了一种开源框架RAG Playground，用于系统评估检索增强生成（RAG）系统。该框架实现了并对比了三种检索方法：朴素向量搜索、再排序和混合向量-关键词搜索，并结合使用了不同的ReAct代理和提示策略。我们引入了一个全面的评估框架，并提供了新的评估指标，比较了不同语言模型（Llama 3.1和Qwen 2.5）在各种检索配置下的性能。实验结果表明，通过混合检索方法和结构化自我评估提示，能够取得显著的性能提升，在我们的多指标评估框架中，混合搜索方法的通过率达到了72.7%。结果还强调了在RAG系统中提示工程的重要性，我们自定义提示的代理在检索准确性和响应质量方面表现出持续的改进。 

---
# Equivariant Action Sampling for Reinforcement Learning and Planning 

**Title (ZH)**: 等变动作采样在强化学习与规划中的应用 

**Authors**: Linfeng Zhao, Owen Howell, Xupeng Zhu, Jung Yeon Park, Zhewen Zhang, Robin Walters, Lawson L.S. Wong  

**Link**: [PDF](https://arxiv.org/pdf/2412.12237)  

**Abstract**: Reinforcement learning (RL) algorithms for continuous control tasks require accurate sampling-based action selection. Many tasks, such as robotic manipulation, contain inherent problem symmetries. However, correctly incorporating symmetry into sampling-based approaches remains a challenge. This work addresses the challenge of preserving symmetry in sampling-based planning and control, a key component for enhancing decision-making efficiency in RL. We introduce an action sampling approach that enforces the desired symmetry. We apply our proposed method to a coordinate regression problem and show that the symmetry aware sampling method drastically outperforms the naive sampling approach. We furthermore develop a general framework for sampling-based model-based planning with Model Predictive Path Integral (MPPI). We compare our MPPI approach with standard sampling methods on several continuous control tasks. Empirical demonstrations across multiple continuous control environments validate the effectiveness of our approach, showcasing the importance of symmetry preservation in sampling-based action selection. 

**Abstract (ZH)**: 强化学习（RL）算法在连续控制任务中需要准确的基于采样的行动选择。许多任务，如机器人操作，包含固有的问题对称性。然而，正确地将对称性融入基于采样的方法仍然是一个挑战。本研究旨在解决在采样规划和控制中保持对称性的挑战，这是提高强化学习决策效率的关键组成部分。我们提出了一个强制执行所需对称性的行动采样方法。我们将所提出的方法应用于坐标回归问题，并展示了对称性意识采样方法远优于简单的采样方法。此外，我们进一步开发了一个基于模型的计划的一般框架，该框架结合了模型预测路径积分（MPPI）。我们将我们的MPPI方法与标准采样方法在多个连续控制任务上进行了比较。在多个连续控制环境中的实证演示验证了我们方法的有效性，突显了在基于采样的行动选择中保持对称性的的重要性。 

---
# TrendSim: Simulating Trending Topics in Social Media Under Poisoning Attacks with LLM-based Multi-agent System 

**Title (ZH)**: TrendSim：基于大型语言模型的多代理系统在中毒攻击下的社会媒体热门话题模拟研究 

**Authors**: Zeyu Zhang, Jianxun Lian, Chen Ma, Yaning Qu, Ye Luo, Lei Wang, Rui Li, Xu Chen, Yankai Lin, Le Wu, Xing Xie, Ji-Rong Wen  

**Link**: [PDF](https://arxiv.org/pdf/2412.12196)  

**Abstract**: Trending topics have become a significant part of modern social media, attracting users to participate in discussions of breaking events. However, they also bring in a new channel for poisoning attacks, resulting in negative impacts on society. Therefore, it is urgent to study this critical problem and develop effective strategies for defense. In this paper, we propose TrendSim, an LLM-based multi-agent system to simulate trending topics in social media under poisoning attacks. Specifically, we create a simulation environment for trending topics that incorporates a time-aware interaction mechanism, centralized message dissemination, and an interactive system. Moreover, we develop LLM-based human-like agents to simulate users in social media, and propose prototype-based attackers to replicate poisoning attacks. Besides, we evaluate TrendSim from multiple aspects to validate its effectiveness. Based on TrendSim, we conduct simulation experiments to study four critical problems about poisoning attacks on trending topics for social benefit. 

**Abstract (ZH)**: 趋势话题已成为现代社交媒体的重要组成部分，吸引了用户参与对时事的讨论。然而，它们也为注入式攻击提供了新的渠道，对社会产生了负面影响。因此，研究这一关键问题并发展有效的防御策略迫在眉睫。在本文中，我们提出了一种基于大语言模型（LLM）的多智能体系统——TrendSim，以模拟在注入式攻击下的社交媒体趋势话题。具体而言，我们创建了一个包含时间意识交互机制、集中式消息传播和交互系统的趋势话题模拟环境。此外，我们开发了基于大语言模型的人类智能体来模拟社交媒体上的用户，并提出了基于原型的攻击者以模拟注入式攻击。通过从多个方面评估TrendSim，我们验证了其有效性。基于TrendSim，我们进行了模拟实验，旨在从社会利益出发，研究四个关键的注入式攻击问题。 

---
# Performance of a large language model-Artificial Intelligence based chatbot for counseling patients with sexually transmitted infections and genital diseases 

**Title (ZH)**: 基于人工智能的聊天机器人在咨询性传播感染和生殖器疾病患者方面的表现研究 

**Authors**: Nikhil Mehta, Sithira Ambepitiya, Thanveer Ahamad, Dinuka Wijesundara, Yudara Kularathne  

**Link**: [PDF](https://arxiv.org/pdf/2412.12166)  

**Abstract**: Introduction: Global burden of sexually transmitted infections (STIs) is rising out of proportion to specialists. Current chatbots like ChatGPT are not tailored for handling STI-related concerns out of the box. We developed Otiz, an Artificial Intelligence-based (AI-based) chatbot platform designed specifically for STI detection and counseling, and assessed its performance. Methods: Otiz employs a multi-agent system architecture based on GPT4-0613, leveraging large language model (LLM) and Deterministic Finite Automaton principles to provide contextually relevant, medically accurate, and empathetic responses. Its components include modules for general STI information, emotional recognition, Acute Stress Disorder detection, and psychotherapy. A question suggestion agent operates in parallel. Four STIs (anogenital warts, herpes, syphilis, urethritis/cervicitis) and 2 non-STIs (candidiasis, penile cancer) were evaluated using prompts mimicking patient language. Each prompt was independently graded by two venereologists conversing with Otiz as patient actors on 6 criteria using Numerical Rating Scale ranging from 0 (poor) to 5 (excellent). Results: Twenty-three venereologists did 60 evaluations of 30 prompts. Across STIs, Otiz scored highly on diagnostic accuracy (4.1-4.7), overall accuracy (4.3-4.6), correctness of information (5.0), comprehensibility (4.2-4.4), and empathy (4.5-4.8). However, relevance scores were lower (2.9-3.6), suggesting some redundancy. Diagnostic scores for non-STIs were lower (p=0.038). Inter-observer agreement was strong, with differences greater than 1 point occurring in only 12.7% of paired evaluations. Conclusions: AI conversational agents like Otiz can provide accurate, correct, discrete, non-judgmental, readily accessible and easily understandable STI-related information in an empathetic manner, and can alleviate the burden on healthcare systems. 

**Abstract (ZH)**: 介绍：性传播感染（STI）的全球负担正在不成比例地增加，而现有的聊天机器人（如ChatGPT）并未针对处理STI相关问题进行定制。我们开发了Otiz，一种基于人工智能的（AI）聊天机器人平台，专为STI检测和咨询而设计，并对其性能进行了评估。

方法：Otiz采用了基于GPT4-0613的多智能体系统架构，结合大型语言模型（LLM）和确定性有限自动机（DFA）原理，提供上下文相关、医学准确且富有同理心的响应。其模块包括一般性STI信息、情绪识别、急性应激障碍检测和心理治疗等。一个问题建议代理在同一时间运行。利用模拟患者语言的提示，对生殖器疣、梅毒、淋病/宫颈炎、念珠菌感染和阴茎癌这4种STI和2种非STI（念珠菌感染、阴茎癌）进行了评估。每次提示由两位性病专家分别以患者身份与Otiz进行交互，根据6个标准（使用0-5的数值评分等级，其中0表示“差”，5表示“优秀”）进行了独立评分。

结果：共有23位性病专家对30个提示进行了60次评估。在评估的STI中，Otiz在诊断准确性（4.1-4.7）、综合准确性（4.3-4.6）、信息准确性（5.0）、易理解性（4.2-4.4）以及同理心（4.5-4.8）等方面得分较高。然而，相关性评分较低（2.9-3.6），表明存在一定冗余。非STI的诊断评分较低（p=0.038）。观察者间的一致性很强，仅12.7%的配对评估差异大于1分。

结论：像Otiz这样的AI对话代理可以以同理心的方式提供准确、正确、简洁、非评判性的、易于获取且易于理解的STI相关信息，并有助于减轻医疗保健系统的负担。 

---
# Meta-Controller: Few-Shot Imitation of Unseen Embodiments and Tasks in Continuous Control 

**Title (ZH)**: 元控制器：在连续控制中对未见过的身体和任务的少量示例模仿 

**Authors**: Seongwoong Cho, Donggyun Kim, Jinwoo Lee, Seunghoon Hong  

**Link**: [PDF](https://arxiv.org/pdf/2412.12147)  

**Abstract**: Generalizing across robot embodiments and tasks is crucial for adaptive robotic systems. Modular policy learning approaches adapt to new embodiments but are limited to specific tasks, while few-shot imitation learning (IL) approaches often focus on a single embodiment. In this paper, we introduce a few-shot behavior cloning framework to simultaneously generalize to unseen embodiments and tasks using a few (\emph{e.g.,} five) reward-free demonstrations. Our framework leverages a joint-level input-output representation to unify the state and action spaces of heterogeneous embodiments and employs a novel structure-motion state encoder that is parameterized to capture both shared knowledge across all embodiments and embodiment-specific knowledge. A matching-based policy network then predicts actions from a few demonstrations, producing an adaptive policy that is robust to over-fitting. Evaluated in the DeepMind Control suite, our framework termed \modelname{} demonstrates superior few-shot generalization to unseen embodiments and tasks over modular policy learning and few-shot IL approaches. Codes are available at \href{this https URL}{this https URL}. 

**Abstract (ZH)**: 跨不同机器人载体和任务的一般化对于自适应机器人系统至关重要。模块化的策略学习方法能够适应新的载体，但局限于特定任务，而少样本模仿学习（IL）方法往往专注于单一的载体。在本文中，我们提出了一种少样本行为克隆框架，能够在少数几项（例如五项）无奖励示范的基础上同时泛化到未见过的载体和任务。该框架采用关节级输入输出表示来统一不同载体的状态和动作空间，并采用一种新颖的结构-运动状态编码器，该编码器参数化以捕捉所有载体的共享知识和特定于每个载体的知识。然后，基于匹配的策略网络从少数示范中预测动作，从而生成一个能够抵御过拟合的自适应策略。在DeepMind Control套件中评估，我们提出的框架\textbf{模型名称}在未见过的载体和任务上的少样本泛化性能显著优于模块化策略学习和少样本IL方法。代码可在[此链接]获取。 

---
# Empathic Coupling of Homeostatic States for Intrinsic Prosociality 

**Title (ZH)**: 自调节状态的同理耦合与内在利他行为 

**Authors**: Naoto Yoshida, Kingson Man  

**Link**: [PDF](https://arxiv.org/pdf/2412.12103)  

**Abstract**: When regarding the suffering of others, we often experience personal distress and feel compelled to help. Inspired by living systems, we investigate the emergence of prosocial behavior among autonomous agents that are motivated by homeostatic self-regulation. We perform multi-agent reinforcement learning, treating each agent as a vulnerable homeostat charged with maintaining its own well-being. We introduce an empathy-like mechanism to share homeostatic states between agents: an agent can either \emph{observe} their partner's internal state (cognitive empathy) or the agent's internal state can be \emph{directly coupled} to that of their partner's (affective empathy). In three simple multi-agent environments, we show that prosocial behavior arises only under homeostatic coupling - when the distress of a partner can affect one's own well-being. Our findings specify the type and role of empathy in artificial agents capable of prosocial behavior. 

**Abstract (ZH)**: 当我们面对他人的痛苦时，往往会感到个人的困扰，并感到有必要提供帮助。受生命系统启发，我们研究自主代理在以稳态自我调节为动机的情况下，表现出亲社会行为的机制。我们采用了多代理强化学习的方法，将每个代理视为一个负责维持自身福祉的脆弱稳态系统。我们引入了一种类似于移情的机制，用于在代理之间共享稳态状态：一个代理可以“观察”其伙伴的内部状态（认知移情），或者其内部状态可以直接耦合到伙伴的内部状态（情感移情）。在三个简单的多代理环境中，我们证明只有在通过稳态耦合时，才会出现亲社会行为——即伙伴的痛苦可以影响自身的福祉。我们的研究结果明确了人工代理中移情的作用类型和角色，这种代理能够表现出亲社会行为。 

---
# An Agentic Approach to Automatic Creation of P&ID Diagrams from Natural Language Descriptions 

**Title (ZH)**: 基于代理视角的自然语言描述自动创建管道仪表图的方法 

**Authors**: Shreeyash Gowaikar, Srinivasan Iyengar, Sameer Segal, Shivkumar Kalyanaraman  

**Link**: [PDF](https://arxiv.org/pdf/2412.12898)  

**Abstract**: The Piping and Instrumentation Diagrams (P&IDs) are foundational to the design, construction, and operation of workflows in the engineering and process industries. However, their manual creation is often labor-intensive, error-prone, and lacks robust mechanisms for error detection and correction. While recent advancements in Generative AI, particularly Large Language Models (LLMs) and Vision-Language Models (VLMs), have demonstrated significant potential across various domains, their application in automating generation of engineering workflows remains underexplored. In this work, we introduce a novel copilot for automating the generation of P&IDs from natural language descriptions. Leveraging a multi-step agentic workflow, our copilot provides a structured and iterative approach to diagram creation directly from Natural Language prompts. We demonstrate the feasibility of the generation process by evaluating the soundness and completeness of the workflow, and show improved results compared to vanilla zero-shot and few-shot generation approaches. 

**Abstract (ZH)**: 工艺和仪表图（P&IDs）在工程和过程行业中对于流程的设计、建设和运营至关重要。然而，其手工绘制常常耗时且容易出错，并且缺乏有效的错误检测与修正机制。尽管最近生成型人工智能（Generative AI）的进展，特别是大型语言模型（LLMs）和视觉-语言模型（VLMs）在各个领域中展现出了巨大的潜力，但其在自动生成工程流程图方面的应用仍待探索。本文中，我们提出了一种新的辅助工具，用于从自然语言描述自动生成P&IDs。通过多步代理工作流程，该辅助工具提供了一种结构化和迭代的图表创建方法，直接从自然语言提示开始。我们通过评估流程的完整性和有效性来证明生成过程的可能性，并展示了与零样本和少量样本生成方法相比，改进的结果。 

---
