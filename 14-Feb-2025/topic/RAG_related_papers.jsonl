{'arxiv_id': 'arXiv:2502.09156', 'title': 'Improving TCM Question Answering through Tree-Organized Self-Reflective Retrieval with LLMs', 'authors': 'Chang Liu, Ying Chang, Jianmin Li, Yiqian Qu, Yu Li, Lingyong Cao, Shuyuan Lin', 'link': 'https://arxiv.org/abs/2502.09156', 'abstract': "Objectives: Large language models (LLMs) can harness medical knowledge for intelligent question answering (Q&A), promising support for auxiliary diagnosis and medical talent cultivation. However, there is a deficiency of highly efficient retrieval-augmented generation (RAG) frameworks within the domain of Traditional Chinese Medicine (TCM). Our purpose is to observe the effect of the Tree-Organized Self-Reflective Retrieval (TOSRR) framework on LLMs in TCM Q&A tasks.\nMaterials and Methods: We introduce the novel approach of knowledge organization, constructing a tree structure knowledge base with hierarchy. At inference time, our self-reflection framework retrieves from this knowledge base, integrating information across chapters. Questions from the TCM Medical Licensing Examination (MLE) and the college Classics Course Exam (CCE) were randomly selected as benchmark datasets.\nResults: By coupling with GPT-4, the framework can improve the best performance on the TCM MLE benchmark by 19.85% in absolute accuracy, and improve recall accuracy from 27% to 38% on CCE datasets. In manual evaluation, the framework improves a total of 18.52 points across dimensions of safety, consistency, explainability, compliance, and coherence.\nConclusion: The TOSRR framework can effectively improve LLM's capability in Q&A tasks of TCM.", 'abstract_zh': '研究目的：大型语言模型（LLM）可以利用医学知识进行智能问答（Q&A），为辅助诊断和医学人才的培养提供支持。然而，在中医药（TCM）领域，高效的检索增强生成（RAG）框架存在不足。本文旨在观察Tree-Organized Self-Reflective Retrieval（TOSRR）框架在TCM问答任务中的效果。\n\n材料与方法：我们引入了一种新型的知识组织方法，构建了具有层次结构的树状知识库。在推理过程中，我们的自省框架从该知识库中检索信息，整合跨章节的信息。我们选择了中医执业医师资格考试（MLE）和大学古典课程考试（CCE）中的随机问题作为基准数据集。\n\n结果：与GPT-4相结合后，该框架在TCM MLE基准测试中的绝对准确率提高了19.85%，在CCE数据集上的召回准确率从27%提高到38%。在手动评估中，该框架在安全性、一致性、可解释性、合规性和连贯性等多个维度上提高了总共18.52分。\n\n结论：TOSRR框架可以有效提高LLM在中医药问答任务中的能力。', 'title_zh': '通过基于树组织的自我反思检索提升中医问答性能'}
{'arxiv_id': 'arXiv:2502.09073', 'title': 'Enhancing RAG with Active Learning on Conversation Records: Reject Incapables and Answer Capables', 'authors': 'Xuzhao Geng, Haozhao Wang, Jun Wang, Wei Liu, Ruixuan Li', 'link': 'https://arxiv.org/abs/2502.09073', 'abstract': 'Retrieval-augmented generation (RAG) is a key technique for leveraging external knowledge and reducing hallucinations in large language models (LLMs). However, RAG still struggles to fully prevent hallucinated responses. To address this, it is essential to identify samples prone to hallucination or guide LLMs toward correct responses, which experts then annotate to develop high-quality datasets for refining LLMs. However, the growing scarcity of such datasets makes their creation challenging. This paper proposes using the vast amount of conversations from widespread LLM usage to build these datasets, training LLMs to avoid hallucination-prone questions while accurately responding to manageable ones. Given the impracticality of expert-annotating all conversation records, the paper introduces AL4RAG, which uses active learning to select the most suitable conversation samples for annotation, optimizing performance within an annotation budget. Additionally, recognizing that traditional active learning methods are not fully compatible with RAG due to unsuitable distance metrics, we develop a novel sample distance measurement for RAG active learning. Extensive experiments show that our method consistently outperforms baselines across multiple metrics.', 'abstract_zh': '检索增强生成（RAG）是一种利用外部知识并减少大型语言模型（LLMs）幻觉的关键技术。然而，RAG 仍然难以完全防止生成幻觉的响应。为解决这一问题，重要的是要识别出易产生幻觉的样本，或者引导 LLMs 提供正确的响应，然后由专家对其进行标注以开发高质量的数据集进一步优化 LLMs。然而，这类数据集正在变得越来越稀缺，使得它们的创建变得具有挑战性。本文提出利用广泛使用的 LLM 会话交流的庞大数量来构建这些数据集，训练 LLMs 避免提出幻觉倾向的问题，同时准确回答可管理的问题。鉴于专家标注所有会话记录是不切实际的，本文介绍了 AL4RAG，该方法使用主动学习来选择最适合标注的交流样本，优化在标注预算内的性能。此外，我们认识到传统的主动学习方法不完全适用于 RAG，因为它们不适合的度量标准不适当，因此开发了一种新的样本距离测量方法来适应 RAG 的主动学习。广泛实验表明，相比于基线方法，我们的方法在多个评价指标上表现更优异。', 'title_zh': '利用对话记录上的主动学习增强RAAG：拒绝不合格的回答者，保留合格的回答者'}
{'arxiv_id': 'arXiv:2502.08826', 'title': 'Ask in Any Modality: A Comprehensive Survey on Multimodal Retrieval-Augmented Generation', 'authors': 'Mohammad Mahdi Abootorabi, Amirhosein Zobeiri, Mahdi Dehghani, Mohammadali Mohammadkhani, Bardia Mohammadi, Omid Ghahroodi, Mahdieh Soleymani Baghshah, Ehsaneddin Asgari', 'link': 'https://arxiv.org/abs/2502.08826', 'abstract': 'Large Language Models (LLMs) struggle with hallucinations and outdated knowledge due to their reliance on static training data. Retrieval-Augmented Generation (RAG) mitigates these issues by integrating external dynamic information enhancing factual and updated grounding. Recent advances in multimodal learning have led to the development of Multimodal RAG, incorporating multiple modalities such as text, images, audio, and video to enhance the generated outputs. However, cross-modal alignment and reasoning introduce unique challenges to Multimodal RAG, distinguishing it from traditional unimodal RAG. This survey offers a structured and comprehensive analysis of Multimodal RAG systems, covering datasets, metrics, benchmarks, evaluation, methodologies, and innovations in retrieval, fusion, augmentation, and generation. We precisely review training strategies, robustness enhancements, and loss functions, while also exploring the diverse Multimodal RAG scenarios. Furthermore, we discuss open challenges and future research directions to support advancements in this evolving field. This survey lays the foundation for developing more capable and reliable AI systems that effectively leverage multimodal dynamic external knowledge bases. Resources are available at this https URL.', 'abstract_zh': '大语言模型（LLMs）由于依赖静态训练数据，面临着幻觉和过时知识的问题。检索增强生成（RAG）通过整合外部动态信息来缓解这些问题，从而增强事实性和更新的信息支持。最近在多模态学习方面的进展导致了多模态RAG的发展，它整合了文本、图像、音频和视频等多种模态，以增强生成的输出。然而，跨模态对齐和推理引入了多模态RAG特有的挑战，使其区别于传统的单模态RAG。本文综述了多模态RAG系统，涵盖了数据集、指标、基准测试、评估、方法论以及检索、融合、增强和生成方面的创新。我们详细审查了训练策略、鲁棒性增强和损失函数，同时探讨了多样的多模态RAG应用场景。此外，我们讨论了该领域的开放挑战和未来研究方向，以支持这一不断发展领域的进步。本文为基础开发更强大且可靠的AI系统提供了支持，这些系统能够有效地利用多模态动态外部知识库奠定了基础。更多资源可以在以下链接获取：[此https URL]', 'title_zh': '任何形式的提问：多模态检索增强生成综述'}
