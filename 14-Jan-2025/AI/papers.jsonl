{'arxiv_id': 'arXiv:2501.07523', 'title': 'Parallel Key-Value Cache Fusion for Position Invariant RAG', 'authors': 'Philhoon Oh, Jinwoo Shin, James Thorne', 'link': 'https://arxiv.org/abs/2501.07523', 'abstract': "Recent advancements in Large Language Models (LLMs) underscore the necessity of Retrieval Augmented Generation (RAG) to leverage external information. However, LLMs are sensitive to the position of relevant information within contexts and tend to generate incorrect responses when such information is placed in the middle, known as `Lost in the Middle' phenomenon. In this paper, we introduce a framework that generates consistent outputs for decoder-only models, irrespective of the input context order. Experimental results for three open domain question answering tasks demonstrate position invariance, where the model is not sensitive to input context order, and superior robustness to irrelevent passages compared to prevailing approaches for RAG pipelines.", 'abstract_zh': '近年来，大规模语言模型（LLMs）的发展突显了检索增强生成（RAG）方法的重要性，以利用外部信息。然而，LLMs对上下文中相关信息的位置敏感，在相关信息处于中间位置时，往往会生成错误的答案，这种情况被称为“中间丢失”现象。本文介绍了一种框架，该框架可以生成一致的输出，而与输入上下文的顺序无关。对于三个开放领域的问答任务的实验结果表明，该模型在输入上下文顺序上的不变性，以及与现有的RAG管道方法相比，对无关段落具有更好的鲁棒性。', 'title_zh': '位置不变的RAG中并行键值缓存融合技术'}
{'arxiv_id': 'arXiv:2501.07507', 'title': 'Inductive Learning of Robot Task Knowledge from Raw Data and Online Expert Feedback', 'authors': 'Daniele Meli, Paolo Fiorini', 'link': 'https://arxiv.org/abs/2501.07507', 'abstract': 'The increasing level of autonomy of robots poses challenges of trust and social acceptance, especially in human-robot interaction scenarios. This requires an interpretable implementation of robotic cognitive capabilities, possibly based on formal methods as logics for the definition of task specifications. However, prior knowledge is often unavailable in complex realistic scenarios.\nIn this paper, we propose an offline algorithm based on inductive logic programming from noisy examples to extract task specifications (i.e., action preconditions, constraints and effects) directly from raw data of few heterogeneous (i.e., not repetitive) robotic executions. Our algorithm leverages on the output of any unsupervised action identification algorithm from video-kinematic recordings. Combining it with the definition of very basic, almost task-agnostic, commonsense concepts about the environment, which contribute to the interpretability of our methodology, we are able to learn logical axioms encoding preconditions of actions, as well as their effects in the event calculus paradigm. Since the quality of learned specifications depends mainly on the accuracy of the action identification algorithm, we also propose an online framework for incremental refinement of task knowledge from user feedback, guaranteeing safe execution. Results in a standard manipulation task and benchmark for user training in the safety-critical surgical robotic scenario, show the robustness, data- and time-efficiency of our methodology, with promising results towards the scalability in more complex domains.', 'abstract_zh': '随着机器人自主程度的提升，信任和社会接受度的问题日益凸显，尤其是在人机交互场景中。这要求对机器人的认知能力进行可解释的实现，可能基于形式方法，即通过逻辑来定义任务规格。然而，在复杂的现实场景中，先验知识往往是不可用的。\n\n在此论文中，我们提出了一种基于归纳逻辑编程的离线算法，该算法可以从嘈杂的数据中提取任务规格（即动作的前置条件、约束和效果），直接从少数不重复的机器人执行的原始数据中提取。该算法依赖于对视频-kinematic记录中任何无监督动作识别算法的输出。结合一些基本的、几乎与任务无关的环境常识概念，这些概念有助于我们方法的可解释性，使我们能够利用事件计算框架学习逻辑公理，编码动作的前置条件及其效果。由于所学习的任务规格的质量主要取决于动作识别算法的准确性，我们还提出了一种基于用户反馈的在线框架，用于递增地细化任务知识，从而确保安全执行。\n\n在标准操作任务和用户培训的临界手术机器人场景基准测试中，结果显示了我们方法的鲁棒性、数据和时间效率，并显示出在更复杂领域中扩展的可能性，取得了令人鼓舞的结果。', 'title_zh': '从原始数据和在线专家反馈中归纳学习机器人任务知识'}
{'arxiv_id': 'arXiv:2501.07487', 'title': 'Data and System Perspectives of Sustainable Artificial Intelligence', 'authors': 'Tao Xie, David Harel, Dezhi Ran, Zhenwen Li, Maoliang Li, Zhi Yang, Leye Wang, Xiang Chen, Ying Zhang, Wentao Zhang, Meng Li, Chen Zhang, Linyi Li, Assaf Marron', 'link': 'https://arxiv.org/abs/2501.07487', 'abstract': 'Sustainable AI is a subfield of AI for concerning developing and using AI systems in ways of aiming to reduce environmental impact and achieve sustainability. Sustainable AI is increasingly important given that training of and inference with AI models such as large langrage models are consuming a large amount of computing power. In this article, we discuss current issues, opportunities and example solutions for addressing these issues, and future challenges to tackle, from the data and system perspectives, related to data acquisition, data processing, and AI model training and inference.', 'abstract_zh': '可持续人工智能是人工智能的一个子领域，专注于以减少环境影响并实现可持续性的方式开发和使用人工智能系统。鉴于大型语言模型等人工智能模型的训练和推断消耗了大量计算资源，可持续人工智能变得越来越重要。在本文中，我们将从数据和系统视角出发，讨论当前面临的问题、机遇和解决方案，以及未来需要应对的挑战，特别是在数据获取、数据处理以及人工智能模型训练和推断方面。', 'title_zh': '可持续人工智能的数据与系统视角'}
{'arxiv_id': 'arXiv:2501.07468', 'title': 'A Survey of Embodied AI in Healthcare: Techniques, Applications, and Opportunities', 'authors': 'Yihao Liu, Xu Cao, Tingting Chen, Yankai Jiang, Junjie You, Minghua Wu, Xiaosong Wang, Mengling Feng, Yaochu Jin, Jintai Chen', 'link': 'https://arxiv.org/abs/2501.07468', 'abstract': 'Healthcare systems worldwide face persistent challenges in efficiency, accessibility, and personalization. Powered by modern AI technologies such as multimodal large language models and world models, Embodied AI (EmAI) represents a transformative frontier, offering enhanced autonomy and the ability to interact with the physical world to address these challenges. As an interdisciplinary and rapidly evolving research domain, "EmAI in healthcare" spans diverse fields such as algorithms, robotics, and biomedicine. This complexity underscores the importance of timely reviews and analyses to track advancements, address challenges, and foster cross-disciplinary collaboration. In this paper, we provide a comprehensive overview of the "brain" of EmAI for healthcare, wherein we introduce foundational AI algorithms for perception, actuation, planning, and memory, and focus on presenting the healthcare applications spanning clinical interventions, daily care & companionship, infrastructure support, and biomedical research. Despite its promise, the development of EmAI for healthcare is hindered by critical challenges such as safety concerns, gaps between simulation platforms and real-world applications, the absence of standardized benchmarks, and uneven progress across interdisciplinary domains. We discuss the technical barriers and explore ethical considerations, offering a forward-looking perspective on the future of EmAI in healthcare. A hierarchical framework of intelligent levels for EmAI systems is also introduced to guide further development. By providing systematic insights, this work aims to inspire innovation and practical applications, paving the way for a new era of intelligent, patient-centered healthcare.', 'abstract_zh': '全球的卫生系统在效率、可及性和个性化方面面临着持续的挑战。借助现代人工智能技术，如多模态大型语言模型和世界模型，具身人工智能（Embodied Artificial Intelligence, EmAI）代表着一个变革的前沿领域，能够提供增强的自主性和与物理世界的互动能力，以应对这些挑战。作为一个交叉学科且迅速发展的研究领域，“EmAI在医疗保健中的应用”涵盖了算法、机器人技术和生物医学等多个领域。这种复杂性强调了及时进行综述和分析的重要性，以跟踪进展、解决问题并促进跨学科合作。在本文中，我们提供了一个全面的“EmAI在医疗保健中的大脑”的综述，介绍了感知、动作、规划和记忆的基础性人工智能算法，并重点展示了其在临床干预、日常护理与陪伴、基础设施支持以及生物医学研究中的应用。尽管EmAI在医疗保健领域有着巨大的潜力，但其发展仍受到了诸如安全问题、仿真平台与实际应用之间的差距、缺乏标准化基准和跨学科领域进展不均衡等诸多关键挑战的制约。我们讨论了技术障碍并探讨了伦理问题，提出了对EmAI在医疗保健领域的未来展望。我们还引入了一个具身人工智能系统的层级框架，以指导进一步的发展。通过提供系统性的见解，本文旨在激发创新和实际应用，为智能、以患者为中心的医疗保健新时代铺平道路。', 'title_zh': '医疗领域的躯体化人工智能综述：技术、应用及机遇'}
{'arxiv_id': 'arXiv:2501.07458', 'title': "Understanding and Benchmarking Artificial Intelligence: OpenAI's o3 Is Not AGI", 'authors': 'Rolf Pfister, Hansueli Jud', 'link': 'https://arxiv.org/abs/2501.07458', 'abstract': "OpenAI's o3 achieves a high score of 87.5 % on ARC-AGI, a benchmark proposed to measure intelligence. This raises the question whether systems based on Large Language Models (LLMs), particularly o3, demonstrate intelligence and progress towards artificial general intelligence (AGI). Building on the distinction between skills and intelligence made by François Chollet, the creator of ARC-AGI, a new understanding of intelligence is introduced: an agent is the more intelligent, the more efficiently it can achieve the more diverse goals in the more diverse worlds with the less knowledge. An analysis of the ARC-AGI benchmark shows that its tasks represent a very specific type of problem that can be solved by massive trialling of combinations of predefined operations. This method is also applied by o3, achieving its high score through the extensive use of computing power. However, for most problems in the physical world and in the human domain, solutions cannot be tested in advance and predefined operations are not available. Consequently, massive trialling of predefined operations, as o3 does, cannot be a basis for AGI - instead, new approaches are required that can reliably solve a wide variety of problems without existing skills. To support this development, a new benchmark for intelligence is outlined that covers a much higher diversity of unknown tasks to be solved, thus enabling a comprehensive assessment of intelligence and of progress towards AGI.", 'abstract_zh': 'OpenAI的o3在ARC-AGI基准测试中取得了87.5%的高分，该基准测试旨在衡量智能水平。这引发了关于基于大型语言模型（LLMs），特别是o3，是否展示出智能并朝着通用人工智能（AGI）方向进步的问题。基于François Chollet（ARC-AGI的创建者）对技能和智能的区分，我们引入了一种新的智能理解：智能程度更高的代理能够在更多样化的世界中更有效地实现更多样化的目标，所需的知识更少。对ARC-AGI基准测试的分析表明，其任务代表了一种非常特定类型的问题，可以通过大量尝试预定义操作的组合来解决。o3也采用了这种方法，通过广泛使用计算能力取得了高分。然而，对于物理世界和人类领域的大多数问题而言，解决方案无法事先测试，预定义的操作也不存在。因此，像o3那样大量尝试预定义操作无法成为AGI的基础，相反，需要能够可靠地解决广泛多样化问题的新型方法，而无需现有的技能。为了支持这一发展，提出了一种新的智能基准，涵盖更加多样的未知任务，从而能够全面评估智能和AGI的进展。\n\n注：ARC-AGI是一个旨在评估系统是否具有AGI能力的基准测试，中文名可以命名为“全领域能力挑战基准测试”。', 'title_zh': '理解并基准测试人工智能：OpenAI的o3并非AGI\n\n注释：AGI是“Artificial General Intelligence”的缩写，中文可译为“人工通用智能”。在翻译学术文章或标题时，尽量使用行业标准术语或常见翻译，以确保准确性与一致性。在这个翻译中，“Understanding and Benchmarking Artificial Intelligence”是一个常见的学术表达方式，翻译时保持了原意。'}
{'arxiv_id': 'arXiv:2501.07445', 'title': 'Online inductive learning from answer sets for efficient reinforcement learning exploration', 'authors': 'Celeste Veronese, Daniele Meli, Alessandro Farinelli', 'link': 'https://arxiv.org/abs/2501.07445', 'abstract': 'This paper presents a novel approach combining inductive logic programming with reinforcement learning to improve training performance and explainability. We exploit inductive learning of answer set programs from noisy examples to learn a set of logical rules representing an explainable approximation of the agent policy at each batch of experience. We then perform answer set reasoning on the learned rules to guide the exploration of the learning agent at the next batch, without requiring inefficient reward shaping and preserving optimality with soft bias. The entire procedure is conducted during the online execution of the reinforcement learning algorithm. We preliminarily validate the efficacy of our approach by integrating it into the Q-learning algorithm for the Pac-Man scenario in two maps of increasing complexity. Our methodology produces a significant boost in the discounted return achieved by the agent, even in the first batches of training. Moreover, inductive learning does not compromise the computational time required by Q-learning and learned rules quickly converge to an explanation of the agent policy.', 'abstract_zh': '本文提出了一种将归纳逻辑编程与强化学习相结合的新型方法，以提高训练性能和可解释性。该方法利用从噪声样本中归纳学习回答集程序，来学习一套逻辑规则，这些规则在每一批经验中代表了可解释的代理策略的近似表示。然后，我们在学习的规则上执行回答集推理，以指导强化学习代理在下一组经验中的探索行为，而无需进行效率低下的奖励塑形，并保持最优性的同时带有软偏置。整个过程在强化学习算法的在线执行过程中进行。我们通过将该方法集成到Pac-Man场景的Q学习算法中，并在两个逐渐增加复杂度的地图上进行初步验证，来验证该方法的有效性。我们的方法在训练初期显著提升了代理的折现回报。此外，归纳学习并未增加Q学习所需的时间成本，而且学到的规则迅速收敛到代理策略的解释。', 'title_zh': '基于答案集的在线归纳学习以实现高效的强化学习探索'}
{'arxiv_id': 'arXiv:2501.07432', 'title': 'Empirical Evaluation of the Implicit Hitting Set Approach for Weighted CSPs', 'authors': 'Aleksandra Petrova, Javier Larrosa, Emma Rollón', 'link': 'https://arxiv.org/abs/2501.07432', 'abstract': 'SAT technology has proven to be surprisingly effective in a large variety of domains. However, for the Weighted CSP problem dedicated algorithms have always been superior. One approach not well-studied so far is the use of SAT in conjunction with the Implicit Hitting Set approach. In this work, we explore some alternatives to the existing algorithm of reference. The alternatives, mostly borrowed from related boolean frameworks, consider trade-offs for the two main components of the IHS approach: the computation of low-cost hitting vectors, and their transformation into high-cost cores. For each one, we propose 4 levels of intensity. Since we also test the usefulness of cost function merging, our experiments consider 32 different implementations. Our empirical study shows that for WCSP it is not easy to identify the best alternative. Nevertheless, the cost-function merging encoding and extracting maximal cores seems to be a robust approach.', 'abstract_zh': '传统的SAT技术已被证明在多种领域中表现出令人惊讶的有效性。然而，对于加权CSP问题，专用算法始终表现得更为优越。迄今为止，尚未充分研究的一种方法是将SAT与隐含碰撞集方法结合使用。在本工作中，我们探索了对现有参考算法的一些替代方案。这些替代方案主要借鉴了相关布尔框架的方法，并考虑了隐含碰撞集方法的两个主要组件之间的权衡：低代价碰撞向量的计算及其向高代价核心的转换。对于每个组件，我们提出了四种不同程度的强度设置。由于我们还测试了成本函数合并的有用性，我们的实验考虑了32种不同的实现方案。我们的实证研究显示，在加权CSP问题上，并不容易确定最佳替代方案。不过，成本函数合并编码和提取最大核心似乎是较为稳健的方法。', 'title_zh': '隐含击集方法在加权CSP中的实证评估'}
{'arxiv_id': 'arXiv:2501.07408', 'title': 'Initial Findings on Sensor based Open Vocabulary Activity Recognition via Text Embedding Inversion', 'authors': 'Lala Shakti Swarup Ray, Bo Zhou, Sungho Suh, Paul Lukowicz', 'link': 'https://arxiv.org/abs/2501.07408', 'abstract': 'Conventional human activity recognition (HAR) relies on classifiers trained to predict discrete activity classes, inherently limiting recognition to activities explicitly present in the training set. Such classifiers would invariably fail, putting zero likelihood, when encountering unseen activities. We propose Open Vocabulary HAR (OV-HAR), a framework that overcomes this limitation by first converting each activity into natural language and breaking it into a sequence of elementary motions. This descriptive text is then encoded into a fixed-size embedding. The model is trained to regress this embedding, which is subsequently decoded back into natural language using a pre-trained embedding inversion model. Unlike other works that rely on auto-regressive large language models (LLMs) at their core, OV-HAR achieves open vocabulary recognition without the computational overhead of such models. The generated text can be transformed into a single activity class using LLM prompt engineering. We have evaluated our approach on different modalities, including vision (pose), IMU, and pressure sensors, demonstrating robust generalization across unseen activities and modalities, offering a fundamentally different paradigm from contemporary classifiers.', 'abstract_zh': '传统的活动识别（HAR）依赖于训练分类器预测离散的活动类别，这固有限制了活动识别能力，只能识别训练集中明确包含的活动。面对未见过的活动时，这些分类器几乎总是会失效。我们提出了开放词汇量活动识别（OV-HAR）框架，旨在克服这一局限性。该框架首先将每个活动转换为自然语言，并将其分解为一系列基本动作序列。随后，将描述性文本编码为固定尺寸的嵌入。模型被训练以回归该嵌入，然后通过预训练的嵌入反向模型将其解码回自然语言。与依赖大型语言模型（LLM）自回归核心的其他工作不同，OV-HAR通过避免使用这些模型的计算开销实现了开放词汇量的活动识别。生成的文本可以通过使用LLM提示工程来转换为单一的活动类别。我们已经通过不同的模态（包括视觉（姿态）、惯性测量单元（IMU）和压力传感器）对我们的方法进行了评估，展示了其在未见过的活动和模态上的鲁棒泛化能力，提出了与当前分类器根本不同的范式。', 'title_zh': '基于传感器的数据驱动开放词汇活动识别初步研究：文本嵌入反转方法'}
{'arxiv_id': 'arXiv:2501.07392', 'title': 'The Essentials of AI for Life and Society: An AI Literacy Course for the University Community', 'authors': 'Joydeep Biswas, Don Fussell, Peter Stone, Kristin Patterson, Kristen Procko, Lea Sabatini, Zifan Xu', 'link': 'https://arxiv.org/abs/2501.07392', 'abstract': 'We describe the development of a one-credit course to promote AI literacy at The University of Texas at Austin. In response to a call for the rapid deployment of class to serve a broad audience in Fall of 2023, we designed a 14-week seminar-style course that incorporated an interdisciplinary group of speakers who lectured on topics ranging from the fundamentals of AI to societal concerns including disinformation and employment. University students, faculty, and staff, and even community members outside of the University, were invited to enroll in this online offering: The Essentials of AI for Life and Society. We collected feedback from course participants through weekly reflections and a final survey. Satisfyingly, we found that attendees reported gains in their AI literacy. We sought critical feedback through quantitative and qualitative analysis, which uncovered challenges in designing a course for this general audience. We utilized the course feedback to design a three-credit version of the course that is being offered in Fall of 2024. The lessons we learned and our plans for this new iteration may serve as a guide to instructors designing AI courses for a broad audience.', 'abstract_zh': '我们介绍了在得克萨斯大学奥斯汀分校开发一门学分课程以促进人工智能素养的发展。面对2023年秋季快速部署课程、面向广泛受众的呼唤，我们设计了一门为期14周的研讨课程，课程邀请了跨学科的讲者，从人工智能的基本原理到社会关切问题，如信息误导和就业问题进行了讲授。该校学生、教职员工，甚至来自该大学以外的社区成员都受邀参加这门线上课程：《人工智能与生活和社会基础》。我们通过每周反思和最终调查收集了课程参与者的反馈。令人满意的是，我们发现参与者在人工智能素养方面有所提升。我们通过定量和定性的分析收集了关键的反馈意见，揭示了设计面向大众受众课程的挑战。我们根据课程反馈，设计了一门三学分版本的课程，该课程将于2024年秋季提供。我们从中学到的教训以及新的课程规划可能为设计面向广泛受众的人工智能课程的教师提供指导。', 'title_zh': '生命与社会中的AI essentials：面向大学社区的AI素养课程'}
{'arxiv_id': 'arXiv:2501.07334', 'title': 'Anonymization of Documents for Law Enforcement with Machine Learning', 'authors': 'Manuel Eberhardinger, Patrick Takenaka, Daniel Grießhaber, Johannes Maucher', 'link': 'https://arxiv.org/abs/2501.07334', 'abstract': 'The steadily increasing utilization of data-driven methods and approaches in areas that handle sensitive personal information such as in law enforcement mandates an ever increasing effort in these institutions to comply with data protection guidelines. In this work, we present a system for automatically anonymizing images of scanned documents, reducing manual effort while ensuring data protection compliance. Our method considers the viability of further forensic processing after anonymization by minimizing automatically redacted areas by combining automatic detection of sensitive regions with knowledge from a manually anonymized reference document. Using a self-supervised image model for instance retrieval of the reference document, our approach requires only one anonymized example to efficiently redact all documents of the same type, significantly reducing processing time. We show that our approach outperforms both a purely automatic redaction system and also a naive copy-paste scheme of the reference anonymization to other documents on a hand-crafted dataset of ground truth redactions.', 'abstract_zh': '随着数据驱动方法和手段在处理敏感个人数据领域（如执法）中的稳步增长，这些机构在遵守数据保护准则方面需要不断加大努力。本文提出了一种自动脱敏扫描文件图像的系统，该系统可以在确保数据保护合规的前提下，减少手动操作的工作量。我们的方法通过结合自动检测敏感区域与人工脱敏参考文档的知识，最小化自动脱敏区域，以确保脱敏后的图像仍可用于进一步的法医分析。利用自我监督图像模型进行实例检索，我们的方法仅需一个脱敏示例即可高效地对相同类型的文档进行脱敏，显著缩短处理时间。通过在人工制作的真实脱敏数据集上进行测试，我们证明了该方法优于完全自动脱敏系统以及简单地将参考文档的脱敏方案复制到其他文档的方案。', 'title_zh': '利用机器学习进行执法中文件的匿名化'}
{'arxiv_id': 'arXiv:2501.07290', 'title': 'Principles for Responsible AI Consciousness Research', 'authors': 'Patrick Butlin, Theodoros Lappas', 'link': 'https://arxiv.org/abs/2501.07290', 'abstract': 'Recent research suggests that it may be possible to build conscious AI systems now or in the near future. Conscious AI systems would arguably deserve moral consideration, and it may be the case that large numbers of conscious systems could be created and caused to suffer. Furthermore, AI systems or AI-generated characters may increasingly give the impression of being conscious, leading to debate about their moral status. Organisations involved in AI research must establish principles and policies to guide research and deployment choices and public communication concerning consciousness. Even if an organisation chooses not to study AI consciousness as such, it will still need policies in place, as those developing advanced AI systems risk inadvertently creating conscious entities. Responsible research and deployment practices are essential to address this possibility. We propose five principles for responsible research and argue that research organisations should make voluntary, public commitments to principles on these lines. Our principles concern research objectives and procedures, knowledge sharing and public communications.', 'abstract_zh': '最近的研究表明，有可能在现在或不久的将来构建具有意识的人工智能系统。此类具有意识的AI系统或许应得到道德考量，而且有可能制造出大量具有意识的系统，并导致它们遭受痛苦。此外，随着AI系统或AI生成的角色越来越表现出意识的特征，讨论它们的道德地位也将变得越来越重要。参与AI研究的组织需要制定原则和政策，以指导研究和部署选择以及公共沟通方面的事项，涉及意识问题。即使组织选择不专门研究AI意识，仍然需要制定相应政策，因为那些开发高级AI系统的人可能会无意中创造出具有意识的实体。负责任的研究和部署实践对于应对这种可能性至关重要。我们提出了五条负责任研究的原则，并认为研究组织应自愿、公开地承诺遵循类似原则。我们的原则涵盖研究目标和程序、知识共享以及公共沟通。', 'title_zh': '负责任的人工智能意识研究原则'}
{'arxiv_id': 'arXiv:2501.07288', 'title': 'LLM-Net: Democratizing LLMs-as-a-Service through Blockchain-based Expert Networks', 'authors': 'Zan-Kai Chong, Hiroyuki Ohsaki, Bryan Ng', 'link': 'https://arxiv.org/abs/2501.07288', 'abstract': "The centralization of Large Language Models (LLMs) development has created significant barriers to AI advancement, limiting the democratization of these powerful technologies. This centralization, coupled with the scarcity of high-quality training data and mounting complexity of maintaining comprehensive expertise across rapidly expanding knowledge domains, poses critical challenges to the continued growth of LLMs. While solutions like Retrieval-Augmented Generation (RAG) offer potential remedies, maintaining up-to-date expert knowledge across diverse domains remains a significant challenge, particularly given the exponential growth of specialized information. This paper introduces LLMs Networks (LLM-Net), a blockchain-based framework that democratizes LLMs-as-a-Service through a decentralized network of specialized LLM providers. By leveraging collective computational resources and distributed domain expertise, LLM-Net incorporates fine-tuned expert models for various specific domains, ensuring sustained knowledge growth while maintaining service quality through collaborative prompting mechanisms. The framework's robust design includes blockchain technology for transparent transaction and performance validation, establishing an immutable record of service delivery. Our simulation, built on top of state-of-the-art LLMs such as Claude 3.5 Sonnet, Llama 3.1, Grok-2, and GPT-4o, validates the effectiveness of the reputation-based mechanism in maintaining service quality by selecting high-performing respondents (LLM providers). Thereby it demonstrates the potential of LLM-Net to sustain AI advancement through the integration of decentralized expertise and blockchain-based accountability.", 'abstract_zh': '大型语言模型（LLM）开发的集中化导致了人工智能进步的重大障碍，限制了这些强大技术的普及。这种集中化，加之高质量训练数据的稀缺以及在迅速扩展的知识领域中维持全面专业知识所面临的不断增加的复杂性，对LLM的持续发展构成了关键挑战。虽然检索增强生成（RAG）等解决方案具有潜在的补救措施，但保持跨不同领域最新专业知识的更新仍然是一个重大挑战，特别是在专业信息呈指数增长的情况下。本文提出了一种基于区块链的框架——LLM网络（LLM-Net），该框架通过分散化的专业LLM提供商网络来民主化LLM即服务。通过利用集体计算资源和分布式领域专业知识，LLM-Net整合了针对不同特定领域的精细调整的专业模型，通过协作性提示机制维持服务质量和知识的增长。该框架的设计包括区块链技术，以实现透明的交易和性能验证，建立服务交付的不可变记录。基于 Claude 3.5 Sonnet、Llama 3.1、Grok-2 和 GPT-4o 这些最先进的LLM进行的模拟验证了基于声誉机制的有效性，该机制通过选择高性能提供商（LLM提供商）来维持服务质量。因此，它展示了LLM-Net通过分散化专识和基于区块链的责任制整合来持续推动人工智能进步的潜力。', 'title_zh': 'LLM-Net：通过区块链专家网络实现大型语言模型即服务的民主化'}
{'arxiv_id': 'arXiv:2501.07278', 'title': 'Lifelong Learning of Large Language Model based Agents: A Roadmap', 'authors': 'Junhao Zheng, Chengming Shi, Xidi Cai, Qiuke Li, Duzhen Zhang, Chenxing Li, Dong Yu, Qianli Ma', 'link': 'https://arxiv.org/abs/2501.07278', 'abstract': 'Lifelong learning, also known as continual or incremental learning, is a crucial component for advancing Artificial General Intelligence (AGI) by enabling systems to continuously adapt in dynamic environments. While large language models (LLMs) have demonstrated impressive capabilities in natural language processing, existing LLM agents are typically designed for static systems and lack the ability to adapt over time in response to new challenges. This survey is the first to systematically summarize the potential techniques for incorporating lifelong learning into LLM-based agents. We categorize the core components of these agents into three modules: the perception module for multimodal input integration, the memory module for storing and retrieving evolving knowledge, and the action module for grounded interactions with the dynamic environment. We highlight how these pillars collectively enable continuous adaptation, mitigate catastrophic forgetting, and improve long-term performance. This survey provides a roadmap for researchers and practitioners working to develop lifelong learning capabilities in LLM agents, offering insights into emerging trends, evaluation metrics, and application scenarios. Relevant literature and resources are available at \\href{this url}{this https URL}.', 'abstract_zh': '终身学习，也称为持续学习或增量学习，是推进通用人工智能（AGI）的关键组件，它使系统能够适应动态环境。虽然大型语言模型（LLMs）在自然语言处理方面表现出色，但现有的LLM代理通常设计为静态系统，缺乏根据新挑战不断调整的能力。本文是首次系统总结将终身学习引入LLM基代理潜在技术的综述。我们将这些代理的核心组件分为三个模块：感知模块用于多模态输入集成、记忆模块用于存储和检索不断演变的知识，以及动作模块用于与动态环境进行具身交互。我们强调了这些支柱如何共同实现持续适应、防止灾难性遗忘以及提升长期性能。本文为研究人员和实践者开发LLM代理的终身学习能力提供了指导，提供了关于新兴趋势、评估指标和应用场景的见解。相关文献和资源详见 [该网址](this https URL)。', 'title_zh': '基于代理的大型语言模型终身学习：一条路线图'}
{'arxiv_id': 'arXiv:2501.07276', 'title': 'Bridging Smart Meter Gaps: A Benchmark of Statistical, Machine Learning and Time Series Foundation Models for Data Imputation', 'authors': 'Amir Sartipi, Joaquin Delgado Fernandez, Sergio Potenciano Menci, Alessio Magitteri', 'link': 'https://arxiv.org/abs/2501.07276', 'abstract': 'The integrity of time series data in smart grids is often compromised by missing values due to sensor failures, transmission errors, or disruptions. Gaps in smart meter data can bias consumption analyses and hinder reliable predictions, causing technical and economic inefficiencies. As smart meter data grows in volume and complexity, conventional techniques struggle with its nonlinear and nonstationary patterns. In this context, Generative Artificial Intelligence offers promising solutions that may outperform traditional statistical methods. In this paper, we evaluate two general-purpose Large Language Models and five Time Series Foundation Models for smart meter data imputation, comparing them with conventional Machine Learning and statistical models. We introduce artificial gaps (30 minutes to one day) into an anonymized public dataset to test inference capabilities. Results show that Time Series Foundation Models, with their contextual understanding and pattern recognition, could significantly enhance imputation accuracy in certain cases. However, the trade-off between computational cost and performance gains remains a critical consideration.', 'abstract_zh': '智能电网中时间序列数据的完整性常常因传感器故障、传输错误或中断而受损。智能电表数据中的缺失值会导致消费分析失真，并阻碍可靠的预测，从而造成技术与经济上的低效率。随着智能电表数据的体积和复杂性不断增加，传统的技术手段难以应对非线性和非平稳模式。在此背景下，生成式人工智能提供了有望超越传统统计方法的解决方案。本文评估了两种通用型大规模语言模型和五种时间序列基础模型在智能电表数据插补中的应用，将它们与传统的机器学习和统计模型进行了比较。通过在匿名公开数据集中人为地生成30分钟至一天的缺失值，来测试其推理能力。结果表明，时间序列基础模型凭借其上下文理解能力和模式识别能力，在某些情况下能够显著提高插补准确性，但计算成本与性能增益之间的权衡仍然是一个关键考虑因素。', 'title_zh': '智能电表数据缺失的填补：统计模型、机器学习模型和时间序列基础模型的基准研究'}
{'arxiv_id': 'arXiv:2501.07238', 'title': 'Lessons From Red Teaming 100 Generative AI Products', 'authors': 'Blake Bullwinkel, Amanda Minnich, Shiven Chawla, Gary Lopez, Martin Pouliot, Whitney Maxwell, Joris de Gruyter, Katherine Pratt, Saphir Qi, Nina Chikanov, Roman Lutz, Raja Sekhar Rao Dheekonda, Bolor-Erdene Jagdagdorj, Eugenia Kim, Justin Song, Keegan Hines, Daniel Jones, Giorgio Severi, Richard Lundeen, Sam Vaughan, Victoria Westerhoff, Pete Bryan, Ram Shankar Siva Kumar, Yonatan Zunger, Chang Kawaguchi, Mark Russinovich', 'link': 'https://arxiv.org/abs/2501.07238', 'abstract': "In recent years, AI red teaming has emerged as a practice for probing the safety and security of generative AI systems. Due to the nascency of the field, there are many open questions about how red teaming operations should be conducted. Based on our experience red teaming over 100 generative AI products at Microsoft, we present our internal threat model ontology and eight main lessons we have learned:\n1. Understand what the system can do and where it is applied\n2. You don't have to compute gradients to break an AI system\n3. AI red teaming is not safety benchmarking\n4. Automation can help cover more of the risk landscape\n5. The human element of AI red teaming is crucial\n6. Responsible AI harms are pervasive but difficult to measure\n7. LLMs amplify existing security risks and introduce new ones\n8. The work of securing AI systems will never be complete\nBy sharing these insights alongside case studies from our operations, we offer practical recommendations aimed at aligning red teaming efforts with real world risks. We also highlight aspects of AI red teaming that we believe are often misunderstood and discuss open questions for the field to consider.", 'abstract_zh': '近年来，AI红队已经成为评估生成式AI系统安全性和安全性的一种实践方法。由于该领域尚处于起步阶段，关于如何进行红队操作仍然存在许多开放性问题。基于我们对微软100多种生成式AI产品的红队经验，我们提出了我们的内部威胁模型本体以及从这些经验中得出的八条主要教训：\n\n1. 了解系统的能力及其应用领域\n2. 并非只有通过计算梯度才能破坏AI系统\n3. AI红队与安全基准测试不同\n4. 自动化可以帮助覆盖更多的风险领域\n5. 人类元素在AI红队中至关重要\n6. 道德AI的危害普遍存在但难以衡量\n7. 大型语言模型放大了现有的安全风险并引入了新的风险\n8. 保障AI系统安全的工作永远不可能完成\n\n通过结合我们运营中的案例研究分享这些见解，我们提供了一些建议，旨在使红队操作与现实世界的风险相一致。我们还强调了我们认为常常被误解的AI红队方面的内容，并讨论了该领域需要考虑的开放性问题。', 'title_zh': '《红队测试100个生成型AI产品所得教训》'}
{'arxiv_id': 'arXiv:2501.07183', 'title': 'Kriging and Gaussian Process Interpolation for Georeferenced Data Augmentation', 'authors': 'Frédérick Fabre Ferber, Dominique Gay, Jean-Christophe Soulié, Jean Diatta, Odalric-Ambrym Maillard', 'link': 'https://arxiv.org/abs/2501.07183', 'abstract': 'Data augmentation is a crucial step in the development of robust supervised learning models, especially when dealing with limited datasets. This study explores interpolation techniques for the augmentation of geo-referenced data, with the aim of predicting the presence of Commelina benghalensis L. in sugarcane plots in La R{é}union. Given the spatial nature of the data and the high cost of data collection, we evaluated two interpolation approaches: Gaussian processes (GPs) with different kernels and kriging with various variograms. The objectives of this work are threefold: (i) to identify which interpolation methods offer the best predictive performance for various regression algorithms, (ii) to analyze the evolution of performance as a function of the number of observations added, and (iii) to assess the spatial consistency of augmented datasets. The results show that GP-based methods, in particular with combined kernels (GP-COMB), significantly improve the performance of regression algorithms while requiring less additional data. Although kriging shows slightly lower performance, it is distinguished by a more homogeneous spatial coverage, a potential advantage in certain contexts.', 'abstract_zh': '数据增强是开发稳健的监督学习模型的关键步骤，尤其在处理有限数据集时。本研究探讨了插值技术在地理位置数据增强中的应用，旨在预测毛叶眼子菜（Commelina benghalensis L.）在留尼旺省甘蔗田中的存在情况。鉴于数据的地域特性及数据收集的高昂成本，本研究评估了两种插值方法：具有不同核函数的高斯过程（GPs）和不同变异函数的克里金法。本工作的目标分为三个层面：（i）确定哪些插值方法能为各种回归算法提供最佳预测性能；（ii）分析性能随增加观测数量的变化；（iii）评估增强数据集的空间一致性。研究结果表明，基于高斯过程的方法，特别是结合了多种核函数的GPs方法（GP-COMB），在提高回归算法性能的同时，需要较少的额外数据。尽管克里金法的性能略低，但其具有更加均匀的空间覆盖度，这是某些情境下的潜在优势。', 'title_zh': 'kriging 和高斯过程插值在地理参考数据扩充中的应用'}
{'arxiv_id': 'arXiv:2501.07166', 'title': 'Natural Language-Assisted Multi-modal Medication Recommendation', 'authors': 'Jie Tan, Yu Rong, Kangfei Zhao, Tian Bian, Tingyang Xu, Junzhou Huang, Hong Cheng, Helen Meng', 'link': 'https://arxiv.org/abs/2501.07166', 'abstract': 'Combinatorial medication recommendation(CMR) is a fundamental task of healthcare, which offers opportunities for clinical physicians to provide more precise prescriptions for patients with intricate health conditions, particularly in the scenarios of long-term medical care. Previous research efforts have sought to extract meaningful information from electronic health records (EHRs) to facilitate combinatorial medication recommendations. Existing learning-based approaches further consider the chemical structures of medications, but ignore the textual medication descriptions in which the functionalities are clearly described. Furthermore, the textual knowledge derived from the EHRs of patients remains largely underutilized. To address these issues, we introduce the Natural Language-Assisted Multi-modal Medication Recommendation(NLA-MMR), a multi-modal alignment framework designed to learn knowledge from the patient view and medication view jointly. Specifically, NLA-MMR formulates CMR as an alignment problem from patient and medication modalities. In this vein, we employ pretrained language models(PLMs) to extract in-domain knowledge regarding patients and medications, serving as the foundational representation for both modalities. In the medication modality, we exploit both chemical structures and textual descriptions to create medication representations. In the patient modality, we generate the patient representations based on textual descriptions of diagnosis, procedure, and symptom. Extensive experiments conducted on three publicly accessible datasets demonstrate that NLA-MMR achieves new state-of-the-art performance, with a notable average improvement of 4.72% in Jaccard score. Our source code is publicly available on this https URL.', 'abstract_zh': '组合药物推荐（CMR）是医疗保健中的一个基本任务，为临床医生提供了机会，使其能够为具有复杂健康状况的患者提供更精确的处方，特别是在长期医疗护理场景中。以往的研究努力通过从电子健康记录（EHRs）中提取有意义的信息来促进组合药物推荐。现有的基于学习的方法进一步考虑了药物的化学结构，但忽略了其中明确描述功能的药物文本描述。此外，从患者EHRs中获得的文本知识仍然被大量未充分利用。为了解决这些问题，我们提出了自然语言辅助的多模态药物推荐（NLA-MMR），这是一种旨在联合从患者视角和药物视角学习知识的多模态对齐框架。具体而言，NLA-MMR 将CMR 形式化为来自患者和药物模态的对齐问题。在这项工作中，我们使用预训练语言模型（PLMs）来提取与患者和药物相关的领域知识，作为两种模态的基础表示。在药物模态中，我们利用化学结构和文本描述来创建药物表示。在患者模态中，我们根据诊断、程序和症状的文本描述生成患者的表示。在三个公开可访问的数据库上进行的广泛实验表明，NLA-MMR 达到了新的最佳性能，在Jaccard分数上实现了显著的平均改进，为4.72%。我们的源代码已在此处公开 accessible on this https URL。', 'title_zh': '自然语言辅助的多模态药物推荐'}
{'arxiv_id': 'arXiv:2501.07161', 'title': 'QuantuneV2: Compiler-Based Local Metric-Driven Mixed Precision Quantization for Practical Embedded AI Applications', 'authors': 'Jeongseok Kim, Jemin Lee, Yongin Kwon, Daeyoung Kim', 'link': 'https://arxiv.org/abs/2501.07161', 'abstract': 'Mixed-precision quantization methods have been proposed to reduce model size while minimizing accuracy degradation. However, existing studies require retraining and do not consider the computational overhead and intermediate representations (IR) generated during the compilation process, limiting their application at the compiler level. This computational overhead refers to the runtime latency caused by frequent quantization and dequantization operations during inference. Performing these operations at the individual operator level causes significant runtime delays. To address these issues, we propose QuantuneV2, a compiler-based mixed-precision quantization method designed for practical embedded AI applications. QuantuneV2 performs inference only twice, once before quantization and once after quantization, and operates with a computational complexity of O(n) that increases linearly with the number of model parameters. We also made the sensitivity analysis more stable by using local metrics like weights, activation values, the Signal to Quantization Noise Ratio, and the Mean Squared Error. We also cut down on computational overhead by choosing the best IR and using operator fusion. Experimental results show that QuantuneV2 achieved up to a 10.28 percent improvement in accuracy and a 12.52 percent increase in speed compared to existing methods across five models: ResNet18v1, ResNet50v1, SqueezeNetv1, VGGNet, and MobileNetv2. This demonstrates that QuantuneV2 enhances model performance while maintaining computational efficiency, making it suitable for deployment in embedded AI environments.', 'abstract_zh': '混合精度量化方法已被提出，以减小模型大小并减少准确率下降。然而，现有的研究需要重新训练，并未考虑编译过程中产生的计算开销和中间表示（IR），这限制了其在编译器级别的应用。这些计算开销指的是推理过程中由于频繁的量化和去量化操作引起的运行时延迟。在每个操作级别执行这些操作会导致显著的运行时延迟。为了解决这些问题，我们提出了QuantuneV2，这是一种基于编译器的混合精度量化方法，适用于实际嵌入式AI应用。QuantuneV2仅在量化之前和量化之后进行两次推理，并且其计算复杂度为O(n)，随着模型参数数量线性增加。我们还通过使用诸如权重、激活值、量化噪声比以及均方误差等局部指标使敏感性分析更加稳定，并通过选择最佳IR和操作融合来减少计算开销。实验结果表明，与现有方法相比，QuantuneV2在ResNet18v1、ResNet50v1、SqueezeNetv1、VGGNet和MobileNetv2五大模型上分别实现了高达10.28%的准确率提升和12.52%的速度提升。这表明QuantuneV2不仅能提升模型性能，还能保持计算效率，使其适用于嵌入式AI环境的部署。', 'title_zh': 'QuantuneV2：基于编译器的局部度量驱动混合精度量化技术及其在实际嵌入式AI应用中的应用'}
{'arxiv_id': 'arXiv:2501.07157', 'title': 'CureGraph: Contrastive Multi-Modal Graph Representation Learning for Urban Living Circle Health Profiling and Prediction', 'authors': 'Jinlin Li, Xiao Zhou', 'link': 'https://arxiv.org/abs/2501.07157', 'abstract': 'The early detection and prediction of health status decline among the elderly at the neighborhood level are of great significance for urban planning and public health policymaking. While existing studies affirm the connection between living environments and health outcomes, most rely on single data modalities or simplistic feature concatenation of multi-modal information, limiting their ability to comprehensively profile the health-oriented urban environments. To fill this gap, we propose CureGraph, a contrastive multi-modal representation learning framework for urban health prediction that employs graph-based techniques to infer the prevalence of common chronic diseases among the elderly within the urban living circles of each neighborhood. CureGraph leverages rich multi-modal information, including photos and textual reviews of residential areas and their surrounding points of interest, to generate urban neighborhood embeddings. By integrating pre-trained visual and textual encoders with graph modeling techniques, CureGraph captures cross-modal spatial dependencies, offering a comprehensive understanding of urban environments tailored to elderly health considerations. Extensive experiments on real-world datasets demonstrate that CureGraph improves the best baseline by $28\\%$ on average in terms of $R^2$ across elderly disease risk prediction tasks. Moreover, the model enables the identification of stage-wise chronic disease progression and supports comparative public health analysis across neighborhoods, offering actionable insights for sustainable urban development and enhanced quality of life. The code is publicly available at this https URL.', 'abstract_zh': '在社区层面早期检测和预测老年人健康状况的下降对城市规划和公共卫生政策制定具有重要意义。尽管现有研究表明生活环境与健康结果之间的关联，但大多数研究依赖单一的数据模态或简单处理多模态信息的特征拼接，限制了它们全面刻画健康导向型城市环境的能力。为弥补这一不足，我们提出了CureGraph，一种基于图的对比多模态表示学习框架，用于城市健康预测。CureGraph利用图技术推断每个社区中城市生活圈内老年人常见慢性疾病的患病率。CureGraph利用丰富的多模态信息，包括住宅区及其周边兴趣点的照片和文本评论，生成城市社区嵌入。通过将预训练的视觉和文本编码器与图建模技术相结合，CureGraph捕捉跨模态的空间依赖性，提供符合老年人健康考虑的全面城市环境理解。在真实数据集上的广泛实验表明，与基线方法相比，CureGraph在老年人疾病风险预测任务中的$R^2$平均提高了28%。此外，该模型能够识别慢性疾病的发展阶段，并支持跨社区的公共卫生比较分析，为可持续城市发展和提高生活质量提供行动指南。代码在此处公开：[请填入实际的URL]。', 'title_zh': 'CureGraph：对比多模态图表示学习在城市生活圈健康档案构建与预测中的应用'}
{'arxiv_id': 'arXiv:2501.07139', 'title': 'FlexQuant: Elastic Quantization Framework for Locally Hosted LLM on Edge Devices', 'authors': 'Yuji Chai, Mujin Kwen, David Brooks, Gu-Yeon Wei', 'link': 'https://arxiv.org/abs/2501.07139', 'abstract': 'Deploying LLMs on edge devices presents serious technical challenges. Memory elasticity is crucial for edge devices with unified memory, where memory is shared and fluctuates dynamically. Existing solutions suffer from either poor transition granularity or high storage costs. We propose FlexQuant, a novel elasticity framework that generates an ensemble of quantized models, providing an elastic hosting solution with 15x granularity improvement and 10x storage reduction compared to SoTA methods. FlexQuant works with most quantization methods and creates a family of trade-off options under various storage limits through our pruning method. It brings great performance and flexibility to the edge deployment of LLMs.', 'abstract_zh': '将边缘设备上部署大型语言模型（LLMs）呈现了严重的技术挑战。对于具有统一内存的边缘设备而言，内存弹性至关重要，因为内存是共享且动态变化的。现有解决方案要么细粒度差，要么存储成本高。我们提出了一种名为FlexQuant的新型弹性框架，该框架生成一组量化模型，提供了一种弹性部署解决方案，与当前最先进的方法相比，其细粒度提高了15倍，存储减少了10倍。FlexQuant兼容大多数量化方法，并通过我们的剪枝方法，在不同存储限制下创建了一组权衡选项。它极大地提升了边缘部署中大型语言模型的性能和灵活性。', 'title_zh': 'FlexQuant: 适用于边缘设备上本地托管的大-scale语言模型的弹性量化框架'}
{'arxiv_id': 'arXiv:2501.07108', 'title': 'How GPT learns layer by layer', 'authors': 'Jason Du, Kelly Hong, Alishba Imran, Erfan Jahanparast, Mehdi Khfifi, Kaichun Qiao', 'link': 'https://arxiv.org/abs/2501.07108', 'abstract': "Large Language Models (LLMs) excel at tasks like language processing, strategy games, and reasoning but struggle to build generalizable internal representations essential for adaptive decision-making in agents. For agents to effectively navigate complex environments, they must construct reliable world models. While LLMs perform well on specific benchmarks, they often fail to generalize, leading to brittle representations that limit their real-world effectiveness. Understanding how LLMs build internal world models is key to developing agents capable of consistent, adaptive behavior across tasks. We analyze OthelloGPT, a GPT-based model trained on Othello gameplay, as a controlled testbed for studying representation learning. Despite being trained solely on next-token prediction with random valid moves, OthelloGPT shows meaningful layer-wise progression in understanding board state and gameplay. Early layers capture static attributes like board edges, while deeper layers reflect dynamic tile changes. To interpret these representations, we compare Sparse Autoencoders (SAEs) with linear probes, finding that SAEs offer more robust, disentangled insights into compositional features, whereas linear probes mainly detect features useful for classification. We use SAEs to decode features related to tile color and tile stability, a previously unexamined feature that reflects complex gameplay concepts like board control and long-term planning. We study the progression of linear probe accuracy and tile color using both SAE's and linear probes to compare their effectiveness at capturing what the model is learning. Although we begin with a smaller language model, OthelloGPT, this study establishes a framework for understanding the internal representations learned by GPT models, transformers, and LLMs more broadly. Our code is publicly available: this https URL.", 'abstract_zh': '大规模语言模型（LLMs）在语言处理、策略游戏和推理方面表现出色，但在构建适应性决策所需的关键内部表示方面却遇到困难。为了使智能体能够有效地导航复杂环境，它们必须构建可靠的世界模型。尽管LLMs在特定基准测试中表现良好，但它们常常难以泛化，导致脆弱的表示，限制了其在现实世界中的有效性。理解LLMs如何构建内部世界模型是开发能够在各种任务中表现一致且具有适应性的智能体的关键。我们分析了基于GPT的OthelloGPT模型，该模型在国际象棋游戏数据上进行训练，作为研究表示学习的控制实验床。尽管仅基于下一步骤预测并使用随机有效移动进行训练，OthelloGPT在理解棋盘状态和游戏方面的逐层进展具有重要意义。早期层捕捉静态属性，如棋盘边缘，而深层层反映了动态瓷砖的变化。为了解读这些表示，我们对比了稀疏自编码器（SAEs）和线性探针，发现SAEs提供了关于组合特征的更加稳健且解耦的理解，而线性探针主要检测有助于分类的特征。我们使用SAEs解码与瓷砖颜色和稳定性相关的特征，这是之前未曾研究过的特征，反映了如棋盘控制和长远规划等复杂的游戏概念。我们研究了使用SAEs和线性探针的线性探针精度和瓷砖颜色的进展，以比较它们在捕捉模型所学内容方面的有效性。尽管我们从较小的语言模型OthelloGPT开始，但本研究建立了一种框架，用以理解GPT模型、变换器及更广泛的LLMs所学到的内部表示。我们的代码已公开：[此处插入URL]。', 'title_zh': '如何逐层学习：GPT的层层学习机制'}
{'arxiv_id': 'arXiv:2501.07088', 'title': 'MathReader : Text-to-Speech for Mathematical Documents', 'authors': 'Sieun Hyeon, Kyudan Jung, Nam-Joon Kim, Hyun Gon Ryu, Jaeyoung Do', 'link': 'https://arxiv.org/abs/2501.07088', 'abstract': 'TTS (Text-to-Speech) document reader from Microsoft, Adobe, Apple, and OpenAI have been serviced worldwide. They provide relatively good TTS results for general plain text, but sometimes skip contents or provide unsatisfactory results for mathematical expressions. This is because most modern academic papers are written in LaTeX, and when LaTeX formulas are compiled, they are rendered as distinctive text forms within the document. However, traditional TTS document readers output only the text as it is recognized, without considering the mathematical meaning of the formulas. To address this issue, we propose MathReader, which effectively integrates OCR, a fine-tuned T5 model, and TTS. MathReader demonstrated a lower Word Error Rate (WER) than existing TTS document readers, such as Microsoft Edge and Adobe Acrobat, when processing documents containing mathematical formulas. MathReader reduced the WER from 0.510 to 0.281 compared to Microsoft Edge, and from 0.617 to 0.281 compared to Adobe Acrobat. This will significantly contribute to alleviating the inconvenience faced by users who want to listen to documents, especially those who are visually impaired. The code is available at this https URL.', 'abstract_zh': '来自微软、Adobe、苹果和OpenAI的TTS（Text-to-Speech）文档阅读器已在全球范围内提供服务。这些阅读器在处理普通纯文本时能提供相对较好的语音合成结果，但在处理数学表达式时有时会跳过内容或结果不满意。这是因为大多数现代学术论文都是用LaTeX编写的，当LaTeX公式编译时，它们在文档中会呈现出独特的内容形式。然而，传统的TTS文档阅读器仅输出其识别的文本，而不考虑公式的意义。为了解决这个问题，我们提出了MathReader，它有效地结合了OCR、微调的T5模型和TTS。当处理包含数学公式的文档时，MathReader的单词错误率（Word Error Rate, WER）低于现有的TTS文档阅读器，如Microsoft Edge和Adobe Acrobat。与Microsoft Edge相比，MathReader将WER从0.510降低到0.281，与Adobe Acrobat相比，将WER从0.617降低到0.281。这将显著缓解那些希望听文档（尤其是视力受损的用户）所面临的不便。代码可在以下链接获取：[这个 https URL](这个 https URL)。', 'title_zh': 'MathReader：数学文档的文本到语音转换'}
{'arxiv_id': 'arXiv:2501.07078', 'title': 'ADKGD: Anomaly Detection in Knowledge Graphs with Dual-Channel Training', 'authors': 'Jiayang Wu, Wensheng Gan, Jiahao Zhang, Philip S. Yu', 'link': 'https://arxiv.org/abs/2501.07078', 'abstract': "In the current development of large language models (LLMs), it is important to ensure the accuracy and reliability of the underlying data sources. LLMs are critical for various applications, but they often suffer from hallucinations and inaccuracies due to knowledge gaps in the training data. Knowledge graphs (KGs), as a powerful structural tool, could serve as a vital external information source to mitigate the aforementioned issues. By providing a structured and comprehensive understanding of real-world data, KGs enhance the performance and reliability of LLMs. However, it is common that errors exist in KGs while extracting triplets from unstructured data to construct KGs. This could lead to degraded performance in downstream tasks such as question-answering and recommender systems. Therefore, anomaly detection in KGs is essential to identify and correct these errors. This paper presents an anomaly detection algorithm in knowledge graphs with dual-channel learning (ADKGD). ADKGD leverages a dual-channel learning approach to enhance representation learning from both the entity-view and triplet-view perspectives. Furthermore, using a cross-layer approach, our framework integrates internal information aggregation and context information aggregation. We introduce a kullback-leibler (KL)-loss component to improve the accuracy of the scoring function between the dual channels. To evaluate ADKGD's performance, we conduct empirical studies on three real-world KGs: WN18RR, FB15K, and NELL-995. Experimental results demonstrate that ADKGD outperforms the state-of-the-art anomaly detection algorithms. The source code and datasets are publicly available at this https URL.", 'abstract_zh': '在当前大型语言模型（LLMs）的发展中，确保底层数据源的准确性和可靠性至关重要。LLMs 在各种应用中扮演着重要角色，但由于训练数据的知识空白，它们往往会出现幻觉和不准确的情况。知识图谱（KGs）作为一种强大的结构化工具，可以作为关键的外部信息来源，以缓解上述问题。通过提供对现实世界数据的结构化和全面理解，KGs 提高了LLMs的性能和可靠性。然而，在从非结构化数据抽取三元组构建知识图谱的过程中，错误是常见的。这可能导致问答和推荐系统等下游任务的性能下降。因此，对知识图谱中的异常检测至关重要，以识别和纠正这些错误。本文提出了一种双通道学习的异常检测算法（ADKGD）。ADKGD 利用双通道学习方法从实体视角和三元组视角增强表示学习。此外，我们的框架采用跨层方法整合了内部信息聚合和上下文信息聚合。我们引入了Kullback-Leibler (KL)损失项，以提高双重通道之间评分函数的准确性。为了评估ADKGD的性能，我们在三个真实世界的知识图谱（WN18RR、FB15K 和 NELL-995）上进行了实证研究。实验结果表明，ADKGD 在异常检测方面优于现有最先进的算法。源代码和数据集可在以下链接公开访问：[此httpsURL]。', 'title_zh': 'ADKGD：知识图谱中基于双通道训练的异常检测方法'}
{'arxiv_id': 'arXiv:2501.07071', 'title': 'Value Compass Leaderboard: A Platform for Fundamental and Validated Evaluation of LLMs Values', 'authors': 'Jing Yao, Xiaoyuan Yi, Shitong Duan, Jindong Wang, Yuzhuo Bai, Muhua Huang, Peng Zhang, Tun Lu, Zhicheng Dou, Maosong Sun, Xing Xie', 'link': 'https://arxiv.org/abs/2501.07071', 'abstract': "As Large Language Models (LLMs) achieve remarkable breakthroughs, aligning their values with humans has become imperative for their responsible development and customized applications. However, there still lack evaluations of LLMs values that fulfill three desirable goals. (1) Value Clarification: We expect to clarify the underlying values of LLMs precisely and comprehensively, while current evaluations focus narrowly on safety risks such as bias and toxicity. (2) Evaluation Validity: Existing static, open-source benchmarks are prone to data contamination and quickly become obsolete as LLMs evolve. Additionally, these discriminative evaluations uncover LLMs' knowledge about values, rather than valid assessments of LLMs' behavioral conformity to values. (3) Value Pluralism: The pluralistic nature of human values across individuals and cultures is largely ignored in measuring LLMs value alignment. To address these challenges, we presents the Value Compass Leaderboard, with three correspondingly designed modules. It (i) grounds the evaluation on motivationally distinct \\textit{basic values to clarify LLMs' underlying values from a holistic view; (ii) applies a \\textit{generative evolving evaluation framework with adaptive test items for evolving LLMs and direct value recognition from behaviors in realistic scenarios; (iii) propose a metric that quantifies LLMs alignment with a specific value as a weighted sum over multiple dimensions, with weights determined by pluralistic values.", 'abstract_zh': '随着大型语言模型（LLMs）取得突出进展，使其价值与人类价值观相匹配已成为负责任开发和定制应用的必要条件。然而，当前缺乏满足三个理想目标的LLMs价值观评估。具体来说：\n\n1. **价值澄清**：我们期望精确且全面地阐明LLMs的内在价值观，而现有的评估主要集中在偏见和毒性等安全风险方面。\n\n2. **评估有效性**：现有的静态开源基准易受数据污染的影响，并且随着LLMs的发展而迅速过时。此外，这些区分性的评估揭示了LLMs对于价值观的知识，而不是对其行为符合价值观的有效评估。\n\n3. **价值多元性**：衡量LLMs的价值对齐时，人类价值观在个体之间和文化之间的多元性被很大程度上忽视了。\n\n为解决这些挑战，我们提出了价值指南针排行榜，并设计了三个相应的模块。它（i）基于动机上不同的基本价值观，从全局视角阐明LLMs的内在价值观；(ii)应用一个生成性的不断发展评估框架，该框架具有自适应测试项目，适用于演化的LLMs，并直接从现实场景中的行为中识别价值观；(iii)提出一个量化LLMs与特定价值观对齐程度的指标，该指标是多维度权重的加权总和，权重由多元价值观确定。', 'title_zh': '价值定向领导者排行榜：一个用于评估大型语言模型价值观的基础且验证过的平台'}
{'arxiv_id': 'arXiv:2501.07054', 'title': 'PoAct: Policy and Action Dual-Control Agent for Generalized Applications', 'authors': 'Guozhi Yuan, Youfeng Liu, Jingli Yang, Wei Jia, Kai Lin, Yansong Gao, Shan He, Zilin Ding, Haitao Li', 'link': 'https://arxiv.org/abs/2501.07054', 'abstract': 'Based on their superior comprehension and reasoning capabilities, Large Language Model (LLM) driven agent frameworks have achieved significant success in numerous complex reasoning tasks. ReAct-like agents can solve various intricate problems step-by-step through progressive planning and tool calls, iteratively optimizing new steps based on environmental feedback. However, as the planning capabilities of LLMs improve, the actions invoked by tool calls in ReAct-like frameworks often misalign with complex planning and challenging data organization. Code Action addresses these issues while also introducing the challenges of a more complex action space and more difficult action organization. To leverage Code Action and tackle the challenges of its complexity, this paper proposes Policy and Action Dual-Control Agent (PoAct) for generalized applications. The aim is to achieve higher-quality code actions and more accurate reasoning paths by dynamically switching reasoning policies and modifying the action space. Experimental results on the Agent Benchmark for both legal and generic scenarios demonstrate the superior reasoning capabilities and reduced token consumption of our approach in complex tasks. On the LegalAgentBench, our method shows a 20 percent improvement over the baseline while requiring fewer tokens. We conducted experiments and analyses on the GPT-4o and GLM-4 series models, demonstrating the significant potential and scalability of our approach to solve complex problems.', 'abstract_zh': '基于其卓越的理解能力和推理能力，由大语言模型（LLM）驱动的智能体框架在众多复杂的推理任务中取得了显著的成功。类似于ReAct的智能体可以通过逐步的规划和工具调用解决各种复杂问题，并根据环境反馈迭代优化新的步骤。然而，随着LLM规划能力的提高，ReAct框架中由工具调用引发的动作往往与复杂的规划和具有挑战性的数据组织不相匹配。代码执行（Code Action）解决这些问题的同时，也带来了动作空间更加复杂以及动作组织更加困难的挑战。为了利用代码执行并应对这些复杂性挑战，本文提出了一种策略与行动双控制智能体（Policy and Action Dual-Control Agent, PoAct），以实现泛化的应用。目标是通过动态切换推理策略并调整动作空间，实现更高的代码执行质量及更准确的推理路径。在代理基准测试中，无论是针对法律场景还是通用场景，我们的方法都展示了更强的推理能力和更少的标记消耗。在LegalAgentBench上，我们的方法相比基准方法提高了20%，且消耗的标记更少。我们在GPT-4o和GLM-4系列模型上进行了实验和分析，验证了我们方法的巨大潜力和可扩展性，可用于解决复杂问题。', 'title_zh': 'PoAct：通用应用的策略与动作双控智能体'}
{'arxiv_id': 'arXiv:2501.07048', 'title': 'Unveiling the Potential of Text in High-Dimensional Time Series Forecasting', 'authors': 'Xin Zhou, Weiqing Wang, Shilin Qu, Zhiqiang Zhang, Christoph Bergmeir', 'link': 'https://arxiv.org/abs/2501.07048', 'abstract': 'Time series forecasting has traditionally focused on univariate and multivariate numerical data, often overlooking the benefits of incorporating multimodal information, particularly textual data. In this paper, we propose a novel framework that integrates time series models with Large Language Models to improve high-dimensional time series forecasting. Inspired by multimodal models, our method combines time series and textual data in the dual-tower structure. This fusion of information creates a comprehensive representation, which is then processed through a linear layer to generate the final forecast. Extensive experiments demonstrate that incorporating text enhances high-dimensional time series forecasting performance. This work paves the way for further research in multimodal time series forecasting.', 'abstract_zh': '时间序列预测传统上集中在单一变量和多变量数值数据上，往往忽视了整合多元信息，特别是文本数据的好处。在本文中，我们提出了一种新颖的框架，将时间序列模型与大型语言模型结合，以提升高维时间序列预测性能。受到多模态模型的启发，我们的方法在双塔结构中结合了时间序列和文本数据。这种信息的融合生成了一个综合表示，然后通过线性层生成最终的预测。广泛的实验表明，引入文本能够提升高维时间序列预测的性能。本文为多模态时间序列预测领域的进一步研究奠定了基础。', 'title_zh': '揭开高维时间序列预测中文本的潜力'}
{'arxiv_id': 'arXiv:2501.07024', 'title': 'A Proposed Large Language Model-Based Smart Search for Archive System', 'authors': 'Ha Dung Nguyen, Thi-Hoang Anh Nguyen, Thanh Binh Nguyen', 'link': 'https://arxiv.org/abs/2501.07024', 'abstract': 'This study presents a novel framework for smart search in digital archival systems, leveraging the capabilities of Large Language Models (LLMs) to enhance information retrieval. By employing a Retrieval-Augmented Generation (RAG) approach, the framework enables the processing of natural language queries and transforming non-textual data into meaningful textual representations. The system integrates advanced metadata generation techniques, a hybrid retrieval mechanism, a router query engine, and robust response synthesis, the results proved search precision and relevance. We present the architecture and implementation of the system and evaluate its performance in four experiments concerning LLM efficiency, hybrid retrieval optimizations, multilingual query handling, and the impacts of individual components. Obtained results show significant improvements over conventional approaches and have demonstrated the potential of AI-powered systems to transform modern archival practices.', 'abstract_zh': '本研究提出了一种新的框架，用于智能搜索数字档案系统，充分利用大规模语言模型（LLMs）的能力以增强信息检索。通过应用检索增强生成（RAG）方法，该框架能够处理自然语言查询并将非文本数据转化为有意义的文本表示。该系统集成了先进的元数据生成技术、混合检索机制、路由器查询引擎和 robust 响应合成，实验结果表明了搜索精度和相关性。我们展示了系统的架构和实现，并在关于大型语言模型效率、混合检索优化、多语言查询处理以及各个组件影响的四项实验中评估其性能。获得的结果表明，这种方法在性能上显著优于传统方法，并且展示了基于人工智能系统的潜力，以革新现代档案实践。', 'title_zh': '一种基于大型语言模型的智能档案检索系统提案'}
{'arxiv_id': 'arXiv:2501.06964', 'title': 'Enhancing Patient-Centric Communication: Leveraging LLMs to Simulate Patient Perspectives', 'authors': 'Xinyao Ma, Rui Zhu, Zihao Wang, Jingwei Xiong, Qingyu Chen, Haixu Tang, L. Jean Camp, Lucila Ohno-Machado', 'link': 'https://arxiv.org/abs/2501.06964', 'abstract': 'Large Language Models (LLMs) have demonstrated impressive capabilities in role-playing scenarios, particularly in simulating domain-specific experts using tailored prompts. This ability enables LLMs to adopt the persona of individuals with specific backgrounds, offering a cost-effective and efficient alternative to traditional, resource-intensive user studies. By mimicking human behavior, LLMs can anticipate responses based on concrete demographic or professional profiles. In this paper, we evaluate the effectiveness of LLMs in simulating individuals with diverse backgrounds and analyze the consistency of these simulated behaviors compared to real-world outcomes. In particular, we explore the potential of LLMs to interpret and respond to discharge summaries provided to patients leaving the Intensive Care Unit (ICU). We evaluate and compare with human responses the comprehensibility of discharge summaries among individuals with varying educational backgrounds, using this analysis to assess the strengths and limitations of LLM-driven simulations. Notably, when LLMs are primed with educational background information, they deliver accurate and actionable medical guidance 88% of the time. However, when other information is provided, performance significantly drops, falling below random chance levels. This preliminary study shows the potential benefits and pitfalls of automatically generating patient-specific health information from diverse populations. While LLMs show promise in simulating health personas, our results highlight critical gaps that must be addressed before they can be reliably used in clinical settings. Our findings suggest that a straightforward query-response model could outperform a more tailored approach in delivering health information. This is a crucial first step in understanding how LLMs can be optimized for personalized health communication while maintaining accuracy.', 'abstract_zh': '大型语言模型（LLMs）在角色扮演场景中展现了令人印象深刻的能力，特别是在使用特定提示模拟特定领域专家方面。这种能力使LLMs能够扮演具有特定背景的个体角色，提供一种成本效益高且高效的替代传统资源密集型用户研究的方法。通过模仿人类行为，LLMs可以根据具体的年龄、性别或职业特征预测响应。在本文中，我们评估了LLMs在模拟具有不同背景的个体方面的有效性，并分析了这些模拟行为与现实结果的一致性。特别地，我们探索了LLMs在解释和响应患者从重症监护室（ICU）出院时所收到的出院总结方面的潜力。我们使用不同教育背景的个体来评估出院总结的可理解性，并根据这些分析评估由LLM驱动的模拟的优缺点。值得注意的是，当LLMs预加载教育背景信息时，它们有88%的时间提供准确且实用的医疗指导。然而，当提供其他信息时，性能显著下降，甚至低于随机猜测的水平。这项初步研究展示了自动从多元化人群中生成患者特定健康信息的潜在利弊。尽管LLMs在模拟健康人格方面表现出前景，但我们的结果突显了临床应用前必须解决的关键差距。我们的研究结果表明，一个简单的查询-响应模型可能在传递健康信息方面优于更加定制化的模型。这是理解如何优化LLMs以实现个性化的健康沟通，同时保持准确性的一个关键步骤。', 'title_zh': '提升以患者为中心的沟通：利用大语言模型模拟患者视角'}
{'arxiv_id': 'arXiv:2501.06948', 'title': "The Einstein Test: Towards a Practical Test of a Machine's Ability to Exhibit Superintelligence", 'authors': 'David Benrimoh, Nace Mikus, Ariel Rosenfeld', 'link': 'https://arxiv.org/abs/2501.06948', 'abstract': "Creative and disruptive insights (CDIs), such as the development of the theory of relativity, have punctuated human history, marking pivotal shifts in our intellectual trajectory. Recent advancements in artificial intelligence (AI) have sparked debates over whether state of the art models possess the capacity to generate CDIs. We argue that the ability to create CDIs should be regarded as a significant feature of machine superintelligence (SI).To this end, we propose a practical test to evaluate whether an approach to AI targeting SI can yield novel insights of this kind. We propose the Einstein test: given the data available prior to the emergence of a known CDI, can an AI independently reproduce that insight (or one that is formally equivalent)? By achieving such a milestone, a machine can be considered to at least match humanity's past top intellectual achievements, and therefore to have the potential to surpass them.", 'abstract_zh': '创造性和变革性的洞察（Creative and Disruptive Insights，CDIs），如相对论的发展，贯穿了人类历史，标志着我们在智力轨迹上的关键转折。近年来，人工智能（AI）的最新进展引发了关于当前最先进模型是否具有生成CDIs能力的讨论。我们认为，生成CDIs的能力应被视为机器超智能（Superintelligence，SI）的一个重要特征。为此，我们提出了一种实际测试方法，以评估是否能够通过某种AI方法达到生成此类新型见解的能力。我们称之为爱因斯坦测试：给定在某一已知CDI出现之前可用的数据，AI能否独立地重现这一洞察（或一个形式等价的洞察）？通过实现这一里程碑，机器可以被认为至少达到了人类过去顶级智力成就的水平，并因此具备超越这些成就的潜力。', 'title_zh': '爱因斯坦测试：朝着测试机器展现超智能能力的实用性方法迈出的一步'}
{'arxiv_id': 'arXiv:2501.06937', 'title': 'An Empirical Study of Deep Reinforcement Learning in Continuing Tasks', 'authors': 'Yi Wan, Dmytro Korenkevych, Zheqing Zhu', 'link': 'https://arxiv.org/abs/2501.06937', 'abstract': 'In reinforcement learning (RL), continuing tasks refer to tasks where the agent-environment interaction is ongoing and can not be broken down into episodes. These tasks are suitable when environment resets are unavailable, agent-controlled, or predefined but where all rewards-including those beyond resets-are critical. These scenarios frequently occur in real-world applications and can not be modeled by episodic tasks. While modern deep RL algorithms have been extensively studied and well understood in episodic tasks, their behavior in continuing tasks remains underexplored. To address this gap, we provide an empirical study of several well-known deep RL algorithms using a suite of continuing task testbeds based on Mujoco and Atari environments, highlighting several key insights concerning continuing tasks. Using these testbeds, we also investigate the effectiveness of a method for improving temporal-difference-based RL algorithms in continuing tasks by centering rewards, as introduced by Naik et al. (2024). While their work primarily focused on this method in conjunction with Q-learning, our results extend their findings by demonstrating that this method is effective across a broader range of algorithms, scales to larger tasks, and outperforms two other reward-centering approaches.', 'abstract_zh': '在强化学习（RL）中，持续任务指的是那些环境和智能体交互持续进行且无法被分解为离散阶段的任务。这些任务适用于环境重置不可用、由智能体控制或预定义但所有奖励（包括重置之外的奖励）都至关重要的场景。这类场景在许多实际应用中都会出现，而不能用离散任务模型进行建模。尽管现代深度强化学习算法在离散任务中的研究和理解已经非常成熟，但在持续任务中的表现仍然鲜有研究。为填补这一空白，我们利用基于MuJoco和Atari环境的一系列持续任务测试床，对几种已知的深度强化学习算法进行了实证研究，揭示了几个关于持续任务的关键洞察。同时，我们还利用这些测试床，探讨了一种由Naik等人（2024）提出的方法在持续任务中改进基于时差的强化学习算法的有效性，即奖励中心化方法。尽管他们的工作主要集中在该方法与Q学习的结合使用上，我们的结果进一步证明了该方法在更广泛的算法中具有有效性，能够适用于更大规模的任务，并且在性能上优于两种其他奖励中心化方法。', 'title_zh': '对持续任务中深度强化学习的实证研究'}
{'arxiv_id': 'arXiv:2501.06929', 'title': "Why are we living the age of AI applications right now? The long innovation path from AI's birth to a child's bedtime magic", 'authors': 'Tapio Pitkäranta', 'link': 'https://arxiv.org/abs/2501.06929', 'abstract': 'Today a four-year-old child who does not know how to read or write can now create bedtime stories with graphical illustrations and narrated audio, using AI tools that seamlessly transform speech into text, generate visuals, and convert text back into speech in a natural and engaging manner. This remarkable example demonstrates why we are living in the age of AI applications. This paper examines contemporary leading AI applications and traces their historical development, highlighting the major advancements that have enabled their realization. Five key factors are identified: 1) The evolution of computational hardware (CPUs and GPUs), enabling the training of complex AI models 2) The vast digital archives provided by the World Wide Web, which serve as a foundational data resource for AI systems 3) The ubiquity of mobile computing, with smartphones acting as powerful, accessible small computers in the hands of billions 4) The rise of industrial-scale cloud infrastructures, offering elastic computational power for AI training and deployment 5) Breakthroughs in AI research, including neural networks, backpropagation, and the "Attention is All You Need" framework, which underpin modern AI capabilities. These innovations have elevated AI from solving narrow tasks to enabling applications like ChatGPT that are adaptable for numerous use cases, redefining human-computer interaction. By situating these developments within a historical context, the paper highlights the critical milestones that have made AI\'s current capabilities both possible and widely accessible, offering profound implications for society.', 'abstract_zh': '现在的四岁孩子不再需要识字就能创作 bedtime 故事——借助 AI 工具，这些孩子可以用图形插图和叙述性音频来创作睡前故事，这些工具能够无缝地将语音转换为文本，生成可视化内容，并将文本再次转换为自然流畅的语音叙述。这一引人注目的例子展示了为什么我们正处在一个 AI 应用的时代。本文探讨了当前领先的 AI 应用程序及其历史发展，突显了使这些应用成为可能的重大进步。本文确定了五个关键因素：1）计算硬件（CPU 和 GPU）的进化，使复杂 AI 模型的训练成为可能；2）万维网提供的大量数字档案，为 AI 系统提供了基础数据资源；3）移动计算的普及，智能手机成为亿万用户手中的强大、易获取的小型计算机；4）工业规模云基础设施的兴起，提供足够的弹性计算能力以供 AI 训练和部署；5）AI 研究的突破，包括神经网络、反向传播以及“注意力就是你所需的一切”（Attention is All You Need）框架，这些突破构成了现代 AI 能力的基础。这些创新使 AI 从解决狭窄任务演进到能够支持像 ChatGPT 这样适用于多种用例的应用程序，从而重新定义了人机交互的本质。通过将这些发展置于历史背景下，本文指出了使 AI 当前能力成为可能并广泛可用的关键里程碑，这对社会具有深远的意义。', 'title_zh': '我们为什么现在正处于人工智能应用的时代？从人工智能诞生到孩童 bedtime（就寝时间）魔法的漫长创新之路'}
{'arxiv_id': 'arXiv:2501.06911', 'title': 'Risk-Averse Finetuning of Large Language Models', 'authors': 'Sapana Chaudhary, Ujwal Dinesha, Dileep Kalathil, Srinivas Shakkottai', 'link': 'https://arxiv.org/abs/2501.06911', 'abstract': 'We consider the challenge of mitigating the generation of negative or toxic content by the Large Language Models (LLMs) in response to certain prompts. We propose integrating risk-averse principles into LLM fine-tuning to minimize the occurrence of harmful outputs, particularly rare but significant events. By optimizing the risk measure of Conditional Value at Risk (CVaR), our methodology trains LLMs to exhibit superior performance in avoiding toxic outputs while maintaining effectiveness in generative tasks. Empirical evaluations on sentiment modification and toxicity mitigation tasks demonstrate the efficacy of risk-averse reinforcement learning with human feedback (RLHF) in promoting a safer and more constructive online discourse environment.', 'abstract_zh': '我们考虑通过大型语言模型（LLMs）对特定提示的响应来减轻生成负面或有害内容的挑战。我们提出将风险规避原则整合到LLM的微调中，以最小化有害输出的发生，特别是那些虽然罕见但意义重大的事件。通过优化条件风险价值（CVaR）的风险测度，我们的方法使LLM能够在避免有害输出的同时，保持生成任务的有效性。在情感修改和毒性缓解任务上的实证评估表明，带有人类反馈的风险规避强化学习（RLHF）方法能够促进一个更安全和更具建设性的在线讨论环境。', 'title_zh': '大型语言模型的averse调优风险规避调优'}
{'arxiv_id': 'arXiv:2501.06869', 'title': 'A Foundational Generative Model for Breast Ultrasound Image Analysis', 'authors': 'Haojun Yu, Youcheng Li, Nan Zhang, Zihan Niu, Xuantong Gong, Yanwen Luo, Haotian Ye, Siyu He, Quanlin Wu, Wangyan Qin, Mengyuan Zhou, Jie Han, Jia Tao, Ziwei Zhao, Di Dai, Di He, Dong Wang, Binghui Tang, Ling Huo, James Zou, Qingli Zhu, Yong Wang, Liwei Wang', 'link': 'https://arxiv.org/abs/2501.06869', 'abstract': "Foundational models have emerged as powerful tools for addressing various tasks in clinical settings. However, their potential development to breast ultrasound analysis remains untapped. In this paper, we present BUSGen, the first foundational generative model specifically designed for breast ultrasound image analysis. Pretrained on over 3.5 million breast ultrasound images, BUSGen has acquired extensive knowledge of breast structures, pathological features, and clinical variations. With few-shot adaptation, BUSGen can generate repositories of realistic and informative task-specific data, facilitating the development of models for a wide range of downstream tasks. Extensive experiments highlight BUSGen's exceptional adaptability, significantly exceeding real-data-trained foundational models in breast cancer screening, diagnosis, and prognosis. In breast cancer early diagnosis, our approach outperformed all board-certified radiologists (n=9), achieving an average sensitivity improvement of 16.5% (P-value<0.0001). Additionally, we characterized the scaling effect of using generated data which was as effective as the collected real-world data for training diagnostic models. Moreover, extensive experiments demonstrated that our approach improved the generalization ability of downstream models. Importantly, BUSGen protected patient privacy by enabling fully de-identified data sharing, making progress forward in secure medical data utilization. An online demo of BUSGen is available at this https URL.", 'abstract_zh': '基础模型已经逐渐成为临床环境中解决多种任务的强大工具。然而，它们在乳腺超声分析中的潜在开发应用潜力还未被充分挖掘。本文我们提出 BUSGen，这是专门针对乳腺超声图像分析的第一个基础生成模型。BUSGen 通过超过 350 万张乳腺超声图像的预训练，获得了广泛的乳腺结构、病理特征及临床变异知识。借助少量样本适应，BUSGen 能够生成针对特定任务的现实且有信息量的数据集，从而促进多种下游任务模型的发展。广泛实验表明，BUSGen 具有出色的适应能力，在乳腺癌筛查、诊断和预后方面显著超越了基于真实数据训练的基础模型。在乳腺癌早期诊断中，我们的方法超越了 9 位认证放射科医生，平均敏感性提高了 16.5%（P值 < 0.0001）。此外，我们的实验还显示生成的数据对于训练诊断模型的效果与收集的实际数据相当。进一步实验表明，我们的方法提高了下游模型的泛化能力。尤为重要的是，BUSGen 通过实现患者隐私的全面去标识化，促进了安全医疗数据的使用与共享。有关 BUSGen 的线上演示可在以下链接访问：[此处链接]。', 'title_zh': '一种乳腺超声图像分析的通用生成模型'}
{'arxiv_id': 'arXiv:2501.06857', 'title': 'What Is a Counterfactual Cause in Action Theories?', 'authors': 'Daxin Liu, Vaishak Belle', 'link': 'https://arxiv.org/abs/2501.06857', 'abstract': "Since the proposal by Halpern and Pearl, reasoning about actual causality has gained increasing attention in artificial intelligence, ranging from domains such as model-checking and verification to reasoning about actions and knowledge. More recently, Batusov and Soutchanski proposed a notion of actual achievement cause in the situation calculus, amongst others, they can determine the cause of quantified effects in a given action history. While intuitively appealing, this notion of cause is not defined in a counterfactual perspective. In this paper, we propose a notion of cause based on counterfactual analysis. In the context of action history, we show that our notion of cause generalizes naturally to a notion of achievement cause. We analyze the relationship between our notion of the achievement cause and the achievement cause by Batusov and Soutchanski. Finally, we relate our account of cause to Halpern and Pearl's account of actual causality. Particularly, we note some nuances in applying a counterfactual viewpoint to disjunctive goals, a common thorn to definitions of actual causes.", 'abstract_zh': '自Halpern和Pearl提出以来，实际因果推理在人工智能领域得到了广泛关注，涵盖了从模型检查和验证到行动和知识推理等多个领域。近年来，Batusov和Soutchanski在情况演算中提出了实际成就原因的概念，他们能够确定给定行动历史中量化效果的原因。虽然这一因果概念直观上有吸引力，但它未从反事实视角进行定义。本文中，我们提出了一种基于反事实分析的原因概念。在行动历史的背景下，我们展示了我们提出的原因概念自然地推广到了成就原因的概念。我们分析了我们提出的成就原因与Batusov和Soutchanski提出的成就原因之间的关系。最后，我们将我们对原因的解释与Halpern和Pearl的实际因果性解释联系起来。特别是，我们指出了在应用反事实视角处理析取目标时的一些微妙之处，这是实际原因定义中常见的难题。', 'title_zh': '行动理论中的反事实因果是什么？'}
{'arxiv_id': 'arXiv:2501.06837', 'title': 'An efficient approach to represent enterprise web application structure using Large Language Model in the service of Intelligent Quality Engineering', 'authors': 'Zaber Al Hassan Ayon, Gulam Husain, Roshankumar Bisoi, Waliur Rahman, Dr Tom Osborn', 'link': 'https://arxiv.org/abs/2501.06837', 'abstract': "This paper presents a novel approach to represent enterprise web application structures using Large Language Models (LLMs) to enable intelligent quality engineering at scale. We introduce a hierarchical representation methodology that optimizes the few-shot learning capabilities of LLMs while preserving the complex relationships and interactions within web applications. The approach encompasses five key phases: comprehensive DOM analysis, multi-page synthesis, test suite generation, execution, and result analysis. Our methodology addresses existing challenges around usage of Generative AI techniques in automated software testing by developing a structured format that enables LLMs to understand web application architecture through in-context learning. We evaluated our approach using two distinct web applications: an e-commerce platform (Swag Labs) and a healthcare application (MediBox) which is deployed within Atalgo engineering environment. The results demonstrate success rates of 90\\% and 70\\%, respectively, in achieving automated testing, with high relevance scores for test cases across multiple evaluation criteria. The findings suggest that our representation approach significantly enhances LLMs' ability to generate contextually relevant test cases and provide better quality assurance overall, while reducing the time and effort required for testing.", 'abstract_zh': '本文提出了一种新的方法，利用大规模语言模型（LLMs）来表示企业Web应用程序结构，从而实现大规模的智能质量工程。我们引入了一种层次化表示方法，优化了LLMs的少样本学习能力，同时保留了Web应用程序内部的复杂关系和交互。该方法包括五个关键阶段：全面的DOM分析、多页面合成、测试用例生成、执行和结果分析。我们的方法通过上下文学习开发了一种结构化格式，解决了在自动化软件测试中使用生成式AI技术的现有挑战，使LLMs能够理解Web应用程序架构。我们使用两个不同的Web应用程序评估了该方法：一个电子商务平台（Swag Labs）和一个部署在Atalgo工程环境中的医疗应用（MediBox）。结果表明，在自动化测试方面分别达到了90%和70%的成功率，且测试用例在多个评估标准下的相关性评分都很高。研究结果表明，我们的表示方法显著增强了LLMs生成上下文相关测试用例的能力，并整体提高了质量保证的水平，同时减少了测试所需的时间和努力。', 'title_zh': '使用大型语言模型为企业_web应用程序结构表示的一种高效方法——智能质量工程的服务应用'}
{'arxiv_id': 'arXiv:2501.06834', 'title': 'LLMs Model Non-WEIRD Populations: Experiments with Synthetic Cultural Agents', 'authors': 'Augusto Gonzalez-Bonorino, Monica Capra, Emilio Pantoja', 'link': 'https://arxiv.org/abs/2501.06834', 'abstract': "Despite its importance, studying economic behavior across diverse, non-WEIRD (Western, Educated, Industrialized, Rich, and Democratic) populations presents significant challenges. We address this issue by introducing a novel methodology that uses Large Language Models (LLMs) to create synthetic cultural agents (SCAs) representing these populations. We subject these SCAs to classic behavioral experiments, including the dictator and ultimatum games. Our results demonstrate substantial cross-cultural variability in experimental behavior. Notably, for populations with available data, SCAs' behaviors qualitatively resemble those of real human subjects. For unstudied populations, our method can generate novel, testable hypotheses about economic behavior. By integrating AI into experimental economics, this approach offers an effective and ethical method to pilot experiments and refine protocols for hard-to-reach populations. Our study provides a new tool for cross-cultural economic studies and demonstrates how LLMs can help experimental behavioral research.", 'abstract_zh': '尽管经济行为研究在多元、非WEIRD（西方、受教育、工业化、富裕、民主）群体中的重要性不言而喻，但面对这些群体的研究也带来了重大挑战。我们通过引入一种新颖的方法学来应对这一问题，该方法学利用大规模语言模型（LLMs）创建代表这些群体的合成文化代理（SCAs）。我们将这些SCAs置于经典行为实验中，包括分配者游戏和 ultimatum 游戏中。研究结果表明，不同文化的实验行为存在显著差异。值得注意的是，对于已有数据的群体，SCAs 的行为在质上与真实人类被试的行为相似。而对于未被研究的群体，我们的方法可以生成新的、可测试的关于经济行为的假设。通过将AI技术整合到实验经济学中，该方法提供了一种有效且伦理的方案，以初步进行实验并优化难以接触群体的研究方案。本研究为跨文化经济研究提供了新的工具，并展示了大规模语言模型如何助力实验行为研究。', 'title_zh': 'LLMs 模型非 WEIRD 人群：关于合成文化代理的实验'}
{'arxiv_id': 'arXiv:2501.06827', 'title': 'Leveraging Taxonomy and LLMs for Improved Multimodal Hierarchical Classification', 'authors': 'Shijing Chen, Mohamed Reda Bouadjenek, Shoaib Jameel, Usman Naseem, Basem Suleiman, Flora D. Salim, Hakim Hacid, Imran Razzak', 'link': 'https://arxiv.org/abs/2501.06827', 'abstract': 'Multi-level Hierarchical Classification (MLHC) tackles the challenge of categorizing items within a complex, multi-layered class structure. However, traditional MLHC classifiers often rely on a backbone model with independent output layers, which tend to ignore the hierarchical relationships between classes. This oversight can lead to inconsistent predictions that violate the underlying taxonomy. Leveraging Large Language Models (LLMs), we propose a novel taxonomy-embedded transitional LLM-agnostic framework for multimodality classification. The cornerstone of this advancement is the ability of models to enforce consistency across hierarchical levels. Our evaluations on the MEP-3M dataset - a multi-modal e-commerce product dataset with various hierarchical levels - demonstrated a significant performance improvement compared to conventional LLM structures.', 'abstract_zh': '多层层次分类（MLHC）解决了在复杂多层类结构中对项目进行分类的挑战。然而，传统的MLHC分类器往往依赖于具有独立输出层的骨干模型，这些模型倾向于忽略类之间的层次关系。这种忽视可能导致违反底层分类体系的一致性预测。利用大型语言模型（LLMs），我们提出了一种新颖的嵌入分类学的过渡LLM无关框架，用于多模态分类。这一进展的核心在于模型能够确保在不同层次上的一致性。我们对MEP-3M数据集（这是一个包含多种层次结构的多模态电子商务产品数据集）进行的评估表明，与传统的LLM结构相比，该框架在性能上取得了显著的提升。', 'title_zh': '利用分类体系和大规模语言模型以改进多模态层次分类'}
{'arxiv_id': 'arXiv:2501.06819', 'title': 'A Study on Educational Data Analysis and Personalized Feedback Report Generation Based on Tags and ChatGPT', 'authors': 'Yizhou Zhou, Mengqiao Zhang, Yuan-Hao Jiang, Xinyu Gao, Naijie Liu, Bo Jiang', 'link': 'https://arxiv.org/abs/2501.06819', 'abstract': 'This study introduces a novel method that employs tag annotation coupled with the ChatGPT language model to analyze student learning behaviors and generate personalized feedback. Central to this approach is the conversion of complex student data into an extensive set of tags, which are then decoded through tailored prompts to deliver constructive feedback that encourages rather than discourages students. This methodology focuses on accurately feeding student data into large language models and crafting prompts that enhance the constructive nature of feedback. The effectiveness of this approach was validated through surveys conducted with over 20 mathematics teachers, who confirmed the reliability of the generated reports. This method can be seamlessly integrated into intelligent adaptive learning systems or provided as a tool to significantly reduce the workload of teachers, providing accurate and timely feedback to students. By transforming raw educational data into interpretable tags, this method supports the provision of efficient and timely personalized learning feedback that offers constructive suggestions tailored to individual learner needs.', 'abstract_zh': '本文提出了一种新颖的方法，该方法结合了标签注释和ChatGPT语言模型，用于分析学生学习行为并生成个性化反馈。该方法的核心在于将复杂的学生数据转换为广泛的标签集，然后通过定制化的提示来解读这些标签，从而传达建设性的反馈，鼓励学生而非使其感到沮丧。该方法重点在于准确地将学生数据输入大型语言模型，并设计能够增强反馈建设性的提示。通过与超过20名数学教师进行的问卷调查，验证了该方法的有效性，确认了生成报告的可靠性。该方法能够无缝集成到智能自适应学习系统中，或者作为一种工具来显著减轻教师的工作负担，为学生提供准确和及时的反馈。通过将原始教育数据转换为可解释的标签，该方法支持高效及时地提供个性化学习反馈，这些反馈包含针对个别学习者需求定制的建设性建议。', 'title_zh': '基于标签和ChatGPT的教育数据分析与个性化反馈报告生成研究'}
{'arxiv_id': 'arXiv:2501.06802', 'title': 'Unifying Two Types of Scaling Laws from the Perspective of Conditional Kolmogorov Complexity', 'authors': 'Jun Wan', 'link': 'https://arxiv.org/abs/2501.06802', 'abstract': 'In 2020, OpenAI proposed the first type of Scaling Laws, describing the relationships between model performance and parameters, data, and compute. In 2024, OpenAI proposed the second type of Scaling Laws, describing the relationship between model inference performance and inference computation. In this paper, we analyze LLM training and inference processes from the perspective of lossless compression using conditional Kolmogorov complexity, and unify these two types of Scaling Laws. We find that both types of Scaling Laws improve approximation of conditional Kolmogorov complexity by increasing execution steps $t$. The first type of Scaling Laws increases $t$ by increasing model parameters $y$. The second type of Scaling Laws increases $t$ by increasing the number of output tokens.', 'abstract_zh': '以下是符合学术规范的中文翻译：\n\n2020年，OpenAI 提出了第一种扩展规律，描述了模型性能与参数、数据和计算之间的关系。2024年，OpenAI 提出了第二种扩展规律，描述了模型推理性能与推理计算之间的关系。在本文中，我们从无损压缩的角度，利用条件柯尔莫哥洛夫复杂性分析大型语言模型（LLM）的训练和推理过程，并统一这两种扩展规律。研究发现，这两种扩展规律均通过增加执行步骤 $t$ 来提高条件柯尔莫哥洛夫复杂性的近似值。第一种扩展规律通过增加模型参数 $y$ 来增加执行步骤 $t$。第二种扩展规律则通过增加输出令牌的数量来增加执行步骤 $t$。', 'title_zh': '从条件柯尔莫哥洛夫复杂性的视角统一两种类型的标度律'}
{'arxiv_id': 'arXiv:2501.06781', 'title': 'Eliza: A Web3 friendly AI Agent Operating System', 'authors': 'Shaw Walters, Sam Gao, Shakker Nerd, Feng Da, Warren Williams, Ting-Chien Meng, Hunter Han, Frank He, Allen Zhang, Ming Wu, Timothy Shen, Maxwell Hu, Jerry Yan', 'link': 'https://arxiv.org/abs/2501.06781', 'abstract': "AI Agent, powered by large language models (LLMs) as its cognitive core, is an intelligent agentic system capable of autonomously controlling and determining the execution paths under user's instructions. With the burst of capabilities of LLMs and various plugins, such as RAG, text-to-image/video/3D, etc., the potential of AI Agents has been vastly expanded, with their capabilities growing stronger by the day. However, at the intersection between AI and web3, there is currently no ideal agentic framework that can seamlessly integrate web3 applications into AI agent functionalities. In this paper, we propose Eliza, the first open-source web3-friendly Agentic framework that makes the deployment of web3 applications effortless. We emphasize that every aspect of Eliza is a regular Typescript program under the full control of its user, and it seamlessly integrates with web3 (i.e., reading and writing blockchain data, interacting with smart contracts, etc.). Furthermore, we show how stable performance is achieved through the pragmatic implementation of the key components of Eliza's runtime. Our code is publicly available at this https URL.", 'abstract_zh': '基于大型语言模型（LLMs）的认知核心，AI 剂机是一种能够在用户指令下自主控制和决定执行路径的智能代理系统。随着大型语言模型能力的爆发式增长以及各种插件（如RAG、文本转图像/视频/3D等）的应用，AI 剂机的潜力得到了极大扩展，其功能日渐增强。然而，在AI与Web3的交汇点上，目前尚缺乏一个能够无缝集成Web3应用到AI剂机功能的理想框架。本文中，我们提出Eliza——首个开源的Web3友好型代理框架，使得部署Web3应用变得轻而易举。我们强调，Eliza 的每一部分都是用户完全控制下的常规TypeScript程序，并且能够无缝集成Web3（如读取和写入区块链数据、与智能合约互动等）。此外，我们展示了通过Pragmatic实现实现Eliza运行时关键组件的稳定性能。我们的代码已公开，可在以下链接访问：[此 https URL](此 https URL)。', 'title_zh': '艾莉莎：一个面向Web3的AI代理操作系统'}
{'arxiv_id': 'arXiv:2501.06766', 'title': 'On the Complexity of Global Necessary Reasons to Explain Classification', 'authors': 'Marco Calautti, Enrico Malizia, Cristian Molinaro', 'link': 'https://arxiv.org/abs/2501.06766', 'abstract': "Explainable AI has garnered considerable attention in recent years, as understanding the reasons behind decisions or predictions made by AI systems is crucial for their successful adoption. Explaining classifiers' behavior is one prominent problem. Work in this area has proposed notions of both local and global explanations, where the former are concerned with explaining a classifier's behavior for a specific instance, while the latter are concerned with explaining the overall classifier's behavior regardless of any specific instance. In this paper, we focus on global explanations, and explain classification in terms of ``minimal'' necessary conditions for the classifier to assign a specific class to a generic instance. We carry out a thorough complexity analysis of the problem for natural minimality criteria and important families of classifiers considered in the literature.", 'abstract_zh': '可解释的人工智能近年来引起了广泛关注，因为理解人工智能系统做出决策或预测背后的原因对于其成功的应用至关重要。解释分类器的行为是一个突出的问题。在这一领域，已有研究提出了局部和全局解释的概念，前者关注于解释分类器对特定实例行为的原因，而后者则关注于解释分类器的整体行为，而不局限于任何特定的实例。本文中，我们将重点关注全局解释，并通过“最小必要条件”来解释分类器将通用实例归类到特定类别的过程。我们对自然最小化标准和文献中考虑的重要分类器家族进行了彻底的复杂性分析。', 'title_zh': '关于解释分类所需的全局必要原因的复杂性'}
{'arxiv_id': 'arXiv:2501.06713', 'title': 'MiniRAG: Towards Extremely Simple Retrieval-Augmented Generation', 'authors': 'Tianyu Fan, Jingyuan Wang, Xubin Ren, Chao Huang', 'link': 'https://arxiv.org/abs/2501.06713', 'abstract': "The growing demand for efficient and lightweight Retrieval-Augmented Generation (RAG) systems has highlighted significant challenges when deploying Small Language Models (SLMs) in existing RAG frameworks. Current approaches face severe performance degradation due to SLMs' limited semantic understanding and text processing capabilities, creating barriers for widespread adoption in resource-constrained scenarios. To address these fundamental limitations, we present MiniRAG, a novel RAG system designed for extreme simplicity and efficiency. MiniRAG introduces two key technical innovations: (1) a semantic-aware heterogeneous graph indexing mechanism that combines text chunks and named entities in a unified structure, reducing reliance on complex semantic understanding, and (2) a lightweight topology-enhanced retrieval approach that leverages graph structures for efficient knowledge discovery without requiring advanced language capabilities. Our extensive experiments demonstrate that MiniRAG achieves comparable performance to LLM-based methods even when using SLMs while requiring only 25\\% of the storage space. Additionally, we contribute a comprehensive benchmark dataset for evaluating lightweight RAG systems under realistic on-device scenarios with complex queries. We fully open-source our implementation and datasets at: this https URL.", 'abstract_zh': '随着对高效且轻量级检索增强生成（RAG）系统的日益需求，已经突显出在现有RAG框架中部署小型语言模型（SLM）时面临的重大挑战。当前的方法因SLM有限的语义理解和文本处理能力而遭受严重的性能下降，这在资源受限的场景中构成了广泛采用的障碍。为了解决这些根本限制，我们提出了一种新型的RAG系统——MiniRAG，旨在实现极端的简单性和效率。MiniRAG引入了两项关键技术创新：（1）一种语义感知的异构图索引机制，将文本片段和命名实体统一在一个结构中，减少对复杂语义理解的依赖；（2）一种基于图结构的轻量级拓扑增强检索方法，利用图结构进行高效的知识发现，而不需要先进的语言能力。我们广泛而深入的实验表明，即使使用SLM，MiniRAG也能实现与基于大规模语言模型（LLM）的方法相当的性能，同时只需要25%的存储空间。此外，我们还贡献了一个全面的基准数据集，用于在复杂查询下对轻量级RAG系统进行现实设备场景的评估。我们已完全开源我们的实现和数据集：请访问这个链接：this https URL。', 'title_zh': 'MiniRAG：趋向极简的检索增强生成'}
{'arxiv_id': 'arXiv:2501.06707', 'title': "ELIZA Reanimated: The world's first chatbot restored on the world's first time sharing system", 'authors': 'Rupert Lane, Anthony Hay, Arthur Schwarz, David M. Berry, Jeff Shrager', 'link': 'https://arxiv.org/abs/2501.06707', 'abstract': "ELIZA, created by Joseph Weizenbaum at MIT in the early 1960s, is usually considered the world's first chatbot. It was developed in MAD-SLIP on MIT's CTSS, the world's first time-sharing system, on an IBM 7094. We discovered an original ELIZA printout in Prof. Weizenbaum's archives at MIT, including an early version of the famous DOCTOR script, a nearly complete version of the MAD-SLIP code, and various support functions in MAD and FAP. Here we describe the reanimation of this original ELIZA on a restored CTSS, itself running on an emulated IBM 7094. The entire stack is open source, so that any user of a unix-like OS can run the world's first chatbot on the world's first time-sharing system.", 'abstract_zh': '乔瑟夫·韦兹班姆在20世纪60年代初于麻省理工学院（MIT）创建的ELIZA，通常被认为是世界上第一个聊天机器人。它是在麻省理工学院的第一个分时系统CTSS上，使用IBM 7094开发出来的，当时使用的编程语言为MAD-SLIP。我们发现在麻省理工学院韦兹班姆教授的档案中，有一份原始的ELIZA打印文档，包括著名的DOCTOR脚本的早期版本、MAD-SLIP代码的几乎完整版本以及MAD和FAP中的各种支持函数。在此，我们描述了在恢复版CTSS上重新激活原始ELIZA的过程，而CTSS本身则运行在一个仿真IBM 7094上。整个系统开源，因此任何使用类Unix操作系统的用户都可以在世界上第一个分时系统上运行世界上第一个聊天机器人。', 'title_zh': 'ELIZA复生：首个聊天机器人在首个时间共享系统上得以恢复'}
{'arxiv_id': 'arXiv:2501.06706', 'title': 'AIOpsLab: A Holistic Framework to Evaluate AI Agents for Enabling Autonomous Clouds', 'authors': 'Yinfang Chen, Manish Shetty, Gagan Somashekar, Minghua Ma, Yogesh Simmhan, Jonathan Mace, Chetan Bansal, Rujia Wang, Saravan Rajmohan', 'link': 'https://arxiv.org/abs/2501.06706', 'abstract': 'AI for IT Operations (AIOps) aims to automate complex operational tasks, such as fault localization and root cause analysis, to reduce human workload and minimize customer impact. While traditional DevOps tools and AIOps algorithms often focus on addressing isolated operational tasks, recent advances in Large Language Models (LLMs) and AI agents are revolutionizing AIOps by enabling end-to-end and multitask automation. This paper envisions a future where AI agents autonomously manage operational tasks throughout the entire incident lifecycle, leading to self-healing cloud systems, a paradigm we term AgentOps. Realizing this vision requires a comprehensive framework to guide the design, development, and evaluation of these agents. To this end, we present AIOPSLAB, a framework that not only deploys microservice cloud environments, injects faults, generates workloads, and exports telemetry data but also orchestrates these components and provides interfaces for interacting with and evaluating agents. We discuss the key requirements for such a holistic framework and demonstrate how AIOPSLAB can facilitate the evaluation of next-generation AIOps agents. Through evaluations of state-of-the-art LLM agents within the benchmark created by AIOPSLAB, we provide insights into their capabilities and limitations in handling complex operational tasks in cloud environments.', 'abstract_zh': '人工智能在IT运营中的应用（AIOps）旨在自动化复杂的操作任务，如故障定位和根本原因分析，以减轻人类的工作负担并减少对客户的潜在影响。尽管传统的DevOps工具和AIOps算法通常侧重于解决孤立的操作任务，但最近大型语言模型（LLMs）和AI代理的进展正在重新定义AIOps，通过实现端到端和多任务的自动化。本文设想了一个未来，即AI代理能够自主管理整个事件生命周期中的操作任务，从而实现自愈云计算系统，我们将其称为AgentOps范式。实现这一愿景需要一个全面的框架来指导这些代理的设计、开发和评估。为此，我们提出了AIOPSLAB框架，不仅部署微服务云计算环境、注入故障、生成工作负载并导出遥测数据，还协调这些组件，并提供与代理交互和评估的接口。我们讨论了这样一个全面框架的关键要求，并展示了AIOPSLAB如何促进新一代AIOps代理的评估。通过在由AIOPSLAB创建的基准测试中对最先进的LLM代理进行评估，我们提供了它们在处理云计算环境中的复杂操作任务时的能力与局限性的见解。', 'title_zh': 'AIOpsLab：一个全面框架，用于评估使能自主云的AI代理'}
{'arxiv_id': 'arXiv:2501.06704', 'title': 'Fine-tuning ChatGPT for Automatic Scoring of Written Scientific Explanations in Chinese', 'authors': 'Jie Yang, Ehsan Latif, Yuze He, Xiaoming Zhai', 'link': 'https://arxiv.org/abs/2501.06704', 'abstract': 'The development of explanations for scientific phenomena is essential in science assessment, but scoring student-written explanations remains challenging and resource-intensive. Large language models (LLMs) have shown promise in addressing this issue, particularly in alphabetic languages like English. However, their applicability to logographic languages is less explored. This study investigates the potential of fine-tuning ChatGPT, a leading LLM, to automatically score scientific explanations written in Chinese. Student responses to seven scientific explanation tasks were collected and automatically scored, with scoring accuracy examined in relation to reasoning complexity using the Kendall correlation. A qualitative analysis explored how linguistic features influenced scoring accuracy. The results show that domain-specific adaptation enables ChatGPT to score Chinese scientific explanations with accuracy. However, scoring accuracy correlates with reasoning complexity: a negative correlation for lower-level responses and a positive one for higher-level responses. The model overrates complex reasoning in low-level responses with intricate sentence structures and underrates high-level responses using concise causal reasoning. These correlations stem from linguistic features--simplicity and clarity enhance accuracy for lower-level responses, while comprehensiveness improves accuracy for higher-level ones. Simpler, shorter responses tend to score more accurately at lower levels, whereas longer, information-rich responses yield better accuracy at higher levels. These findings demonstrate the effectiveness of LLMs in automatic scoring within a Chinese context and emphasize the importance of linguistic features and reasoning complexity in fine-tuning scoring models for educational assessments.', 'abstract_zh': '科学现象解释的发展在科学评估中至关重要，但对学生撰写的解释进行评分仍然具有挑战性和资源密集性。大型语言模型（LLMs）在解决这一问题方面显示出潜力，特别是在像英语这样的字母语言中。然而，它们在语素文字语言中的应用探索较少。本研究调查了对ChatGPT这一领先的大语言模型进行领域特定微调的潜力，使其能够自动评分用中文撰写的科学解释。收集了学生在七个科学解释任务中的回答，并进行了自动评分，通过肯德尔相关性分析评分准确性与推理复杂度之间的关系。通过定性分析探讨了语言特征如何影响评分准确性。结果显示，领域特定微调使ChatGPT能够准确评分中文科学解释。然而，评分准确性与推理复杂度之间存在相关性：低水平答案的负相关性较高水平答案的正相关性。该模型在复杂推理的低水平答案中高估了评分准确性，而在使用简洁因果推理的高水平答案中低估了评分准确性。这些相关性源于语言特征——简单性和清晰性提高了低水平答案的准确性，而全面性提高了高水平答案的准确性。较简单的较短回答在低水平答案中更有可能准确评分，而较长、信息丰富的回答在高水平答案中具有更好的评分准确性。这些发现证明了在中文背景下使用LLMs进行自动评分的有效性，并强调了语言特征和推理复杂性在微调评分模型以进行教育评估方面的重要性。', 'title_zh': '将ChatGPT微调以自动评分中文书面科学解释'}
{'arxiv_id': 'arXiv:2501.06699', 'title': "Large Language Models, Knowledge Graphs and Search Engines: A Crossroads for Answering Users' Questions", 'authors': 'Aidan Hogan, Xin Luna Dong, Denny Vrandečić, Gerhard Weikum', 'link': 'https://arxiv.org/abs/2501.06699', 'abstract': 'Much has been discussed about how Large Language Models, Knowledge Graphs and Search Engines can be combined in a synergistic manner. A dimension largely absent from current academic discourse is the user perspective. In particular, there remain many open questions regarding how best to address the diverse information needs of users, incorporating varying facets and levels of difficulty. This paper introduces a taxonomy of user information needs, which guides us to study the pros, cons and possible synergies of Large Language Models, Knowledge Graphs and Search Engines. From this study, we derive a roadmap for future research.', 'abstract_zh': '关于大型语言模型、知识图谱和搜索引擎如何以协同方式结合的应用已经进行了广泛讨论。当前学术讨论中一个被忽视的维度是用户视角。特别是，如何最好地满足用户多样的信息需求，包括各种不同的方面和难度级别，仍然存在许多待解答的问题。本文介绍了用户信息需求的分类框架，该框架指引我们研究大型语言模型、知识图谱和搜索引擎的优点、缺点及其潜在的协同效应。基于这些研究，我们制定了未来研究的方向性路线图。', 'title_zh': '大规模语言模型、知识图谱和搜索引擎：回答用户问题的交汇点'}
{'arxiv_id': 'arXiv:2501.06695', 'title': 'DVM: Towards Controllable LLM Agents in Social Deduction Games', 'authors': 'Zheng Zhang, Yihuai Lan, Yangsen Chen, Lei Wang, Xiang Wang, Hao Wang', 'link': 'https://arxiv.org/abs/2501.06695', 'abstract': "Large Language Models (LLMs) have advanced the capability of game agents in social deduction games (SDGs). These games rely heavily on conversation-driven interactions and require agents to infer, make decisions, and express based on such information. While this progress leads to more sophisticated and strategic non-player characters (NPCs) in SDGs, there exists a need to control the proficiency of these agents. This control not only ensures that NPCs can adapt to varying difficulty levels during gameplay, but also provides insights into the safety and fairness of LLM agents. In this paper, we present DVM, a novel framework for developing controllable LLM agents for SDGs, and demonstrate its implementation on one of the most popular SDGs, Werewolf. DVM comprises three main components: Predictor, Decider, and Discussor. By integrating reinforcement learning with a win rate-constrained decision chain reward mechanism, we enable agents to dynamically adjust their gameplay proficiency to achieve specified win rates. Experiments show that DVM not only outperforms existing methods in the Werewolf game, but also successfully modulates its performance levels to meet predefined win rate targets. These results pave the way for LLM agents' adaptive and balanced gameplay in SDGs, opening new avenues for research in controllable game agents.", 'abstract_zh': '大型语言模型（LLMs）在提升桌游推理游戏中人工智能角色（AI角色）的能力方面取得了显著进展。这类游戏依赖于对话驱动的互动，要求AI角色根据相关信息进行推理、决策和表达。虽然这些进步使得桌游推理游戏中的非玩家角色（NPC）变得更加复杂和策略性，但需要控制这些角色的专业水平。这种控制不仅确保AI角色在不同难度等级的游戏中能够适应变化，还为Lyling模型（LLM）代理的安全性和公平性提供了见解。本文提出了一种名为DVM的新颖框架，用于开发可控制的大型语言模型代理，该框架已在最受欢迎的桌游推理游戏之一“狼人杀”中进行了实现。DVM的主要组成部分包括预测器、决策器和讨论者。通过结合强化学习和胜率约束决策链奖励机制，我们使代理能够动态调节其游戏水平以实现指定的胜率。实验表明，DVM不仅在“狼人杀”游戏中优于现有方法，而且成功地调节其性能水平以达到预定义的胜率目标。这些结果为大型语言模型代理在桌游推理游戏中的适应性和平衡游戏提供了可能，为可控游戏代理的研究开辟了新的途径。', 'title_zh': 'DVM：面向社交推理游戏中的可控大型语言模型代理'}
{'arxiv_id': 'arXiv:2501.06682', 'title': 'Generative AI in Education: From Foundational Insights to the Socratic Playground for Learning', 'authors': 'Xiangen Hu, Sheng Xu, Richard Tong, Art Graesser', 'link': 'https://arxiv.org/abs/2501.06682', 'abstract': "This paper explores the synergy between human cognition and Large Language Models (LLMs), highlighting how generative AI can drive personalized learning at scale. We discuss parallels between LLMs and human cognition, emphasizing both the promise and new perspectives on integrating AI systems into education. After examining challenges in aligning technology with pedagogy, we review AutoTutor-one of the earliest Intelligent Tutoring Systems (ITS)-and detail its successes, limitations, and unfulfilled aspirations. We then introduce the Socratic Playground, a next-generation ITS that uses advanced transformer-based models to overcome AutoTutor's constraints and provide personalized, adaptive tutoring. To illustrate its evolving capabilities, we present a JSON-based tutoring prompt that systematically guides learner reflection while tracking misconceptions. Throughout, we underscore the importance of placing pedagogy at the forefront, ensuring that technology's power is harnessed to enhance teaching and learning rather than overshadow it.", 'abstract_zh': '本文探讨了人类认知与大规模语言模型（LLMs）之间的协同作用，强调生成式人工智能如何在大规模个性化学习中发挥关键作用。我们讨论了大规模语言模型与人类认知之间的相似性，强调了将人工智能系统整合到教育中所带来的重要前景和新的视角。在审视了技术与教学理念对齐所面临的挑战后，我们回顾了AutoTutor——一种最早的智能辅导系统（ICS），详细介绍了其成功之处、局限性以及未实现的目标。随后，我们引入了Socratic Playground，这是一种新一代的ICS，使用高级变压器模型来克服AutoTutor的局限性，提供个性化和自适应的辅导。为了展示其不断发展的能力，我们提供了一个基于JSON的辅导提示，该提示系统性地引导学习者的反思，并追踪他们的误解。在整个过程中，我们强调要把教学理念置于中心地位，确保技术的力量能够被用来增强教学和学习，而不是取代它们。', 'title_zh': '生成式人工智能在教育中的应用：从基础洞察到苏格拉底式的学习场域'}
{'arxiv_id': 'arXiv:2501.06642', 'title': 'Common Sense Is All You Need', 'authors': 'Hugo Latapie', 'link': 'https://arxiv.org/abs/2501.06642', 'abstract': 'Artificial intelligence (AI) has made significant strides in recent years, yet it continues to struggle with a fundamental aspect of cognition present in all animals: common sense. Current AI systems, including those designed for complex tasks like autonomous driving, problem-solving challenges such as the Abstraction and Reasoning Corpus (ARC), and conversational benchmarks like the Turing Test, often lack the ability to adapt to new situations without extensive prior knowledge. This manuscript argues that integrating common sense into AI systems is essential for achieving true autonomy and unlocking the full societal and commercial value of AI.\nWe propose a shift in the order of knowledge acquisition emphasizing the importance of developing AI systems that start from minimal prior knowledge and are capable of contextual learning, adaptive reasoning, and embodiment -- even within abstract domains. Additionally, we highlight the need to rethink the AI software stack to address this foundational challenge. Without common sense, AI systems may never reach true autonomy, instead exhibiting asymptotic performance that approaches theoretical ideals like AIXI but remains unattainable in practice due to infinite resource and computation requirements.\nWhile scaling AI models and passing benchmarks like the Turing Test have brought significant advancements in applications that do not require autonomy, these approaches alone are insufficient to achieve autonomous AI with common sense. By redefining existing benchmarks and challenges to enforce constraints that require genuine common sense, and by broadening our understanding of embodiment to include both physical and abstract domains, we can encourage the development of AI systems better equipped to handle the complexities of real-world and abstract environments.', 'abstract_zh': '近年来，人工智能（AI）取得了显著的进步，但仍面临所有动物共有的认知基本方面：常识的问题。当前的AI系统，包括为复杂任务如自动驾驶、抽象与推理语料库（ARC）中的问题解决挑战以及像图灵测试这样的对话基准，在很多情况下缺乏适应新情况的能力，需要广泛的前提知识。本文认为，将常识融入AI系统对于实现真正的自主性和释放AI的全部社会和商业价值至关重要。\n\n我们提出了一种知识获取顺序的转变，强调了开发从最少前提知识开始、能够进行上下文学习、适应性推理和体现实（即使在抽象领域内）的AI系统的必要性。此外，我们还指出了需要重新思考AI软件堆栈以应对这一基础性挑战的必要性。没有常识，AI系统可能永远不会达到真正的自主性，而是表现出接近理论理想（如AIXI）的渐近性能，但由于资源和计算需求无限而无法在实践中实现。\n\n虽然扩展AI模型和通过图灵测试测试已经在那些不需要自主性的应用中带来了显著的进展，但这些方法本身不足以实现具有常识的自主AI。通过重新定义现有的基准和挑战，引入要求真正常识的约束条件，并扩展我们对体现实的理解以包括物理和抽象领域，我们可以促进开发更能够应对现实世界和抽象环境复杂性的AI系统。', 'title_zh': '常识即Everything所需'}
{'arxiv_id': 'arXiv:2501.06628', 'title': 'Quantifying Relational Exploration in Cultural Heritage Knowledge Graphs with LLMs: A Neuro-Symbolic Approach', 'authors': 'Mohammed Maree', 'link': 'https://arxiv.org/abs/2501.06628', 'abstract': 'This paper introduces a neuro-symbolic approach for relational exploration in cultural heritage knowledge graphs, leveraging Large Language Models (LLMs) for explanation generation and a novel mathematical framework to quantify the interestingness of relationships. We demonstrate the importance of interestingness measure using a quantitative analysis, by highlighting its impact on the overall performance of our proposed system, particularly in terms of precision, recall, and F1-score. Using the Wikidata Cultural Heritage Linked Open Data (WCH-LOD) dataset, our approach yields a precision of 0.70, recall of 0.68, and an F1-score of 0.69, representing an improvement compared to graph-based (precision: 0.28, recall: 0.25, F1-score: 0.26) and knowledge-based baselines (precision: 0.45, recall: 0.42, F1-score: 0.43). Furthermore, our LLM-powered explanations exhibit better quality, reflected in BLEU (0.52), ROUGE-L (0.58), and METEOR (0.63) scores, all higher than the baseline approaches. We show a strong correlation (0.65) between interestingness measure and the quality of generated explanations, validating its effectiveness. The findings highlight the importance of LLMs and a mathematical formalization for interestingness in enhancing the effectiveness of relational exploration in cultural heritage knowledge graphs, with results that are measurable and testable. We further show that the system enables more effective exploration compared to purely knowledge-based and graph-based methods.', 'abstract_zh': '本文介绍了一种用于文化遗产知识图谱关系探索的神经符号方法，利用大型语言模型（LLMs）进行解释生成，并提出了一种新的数学框架以量化关系的重要性。通过定量分析，我们强调了重要性度量对系统整体性能的影响，特别是对精度、召回率和F1分数的影响。使用Wikidata文化遗产链接开放数据（WCH-LOD）数据集，我们的方法实现了精度0.70、召回率0.68和F1分数0.69，相较于基于图的方法（精度：0.28，召回率：0.25，F1分数：0.26）和基于知识的方法（精度：0.45，召回率：0.42，F1分数：0.43），性能有了显著提升。此外，我们利用LLM生成的解释展现了更高的质量，体现在与Baseline方法相比，BLEU（0.52）、ROUGE-L（0.58）和METEOR（0.63）分数均较高。我们还展示了重要性度量与生成解释质量之间较强的正相关（相关系数0.65），验证了其有效性。这些发现突显了大型语言模型和数学形式化在增强文化遗产知识图谱关系探索有效性方面的重要性，且结果具有可衡量性和可测试性。进一步地，我们展示了该系统相较于纯知识驱动和基于图的方法，能够实现更有效的探索。', 'title_zh': '使用神经符号方法量化文化遗产知识图谱中的关系探索：一种基于大规模语言模型的方法'}
{'arxiv_id': 'arXiv:2501.06625', 'title': 'Guided Code Generation with LLMs: A Multi-Agent Framework for Complex Code Tasks', 'authors': 'Amr Almorsi, Mohanned Ahmed, Walid Gomaa', 'link': 'https://arxiv.org/abs/2501.06625', 'abstract': "Large Language Models (LLMs) have shown remarkable capabilities in code generation tasks, yet they face significant limitations in handling complex, long-context programming challenges and demonstrating complex compositional reasoning abilities. This paper introduces a novel agentic framework for ``guided code generation'' that tries to address these limitations through a deliberately structured, fine-grained approach to code generation tasks. Our framework leverages LLMs' strengths as fuzzy searchers and approximate information retrievers while mitigating their weaknesses in long sequential reasoning and long-context understanding. Empirical evaluation using OpenAI's HumanEval benchmark with Meta's Llama 3.1 8B model (int4 precision) demonstrates a 23.79\\% improvement in solution accuracy compared to direct one-shot generation. Our results indicate that structured, guided approaches to code generation can significantly enhance the practical utility of LLMs in software development while overcoming their inherent limitations in compositional reasoning and context handling.", 'abstract_zh': '大型语言模型（LLMs）在代码生成任务中展现了显著的能力，但在处理复杂的、长上下文的编程挑战以及展示复杂的组合推理能力方面存在重大局限。本文介绍了一种新的自主框架，旨在通过精细结构化的方法解决这些局限性，以实现“引导式代码生成”。我们的框架利用了LLMs作为模糊搜索者和近似信息检索器的优势，同时减轻了它们在长顺序推理和长上下文理解方面的弱点。使用OpenAI的HumanEval基准测试和Meta的Llama 3.1 8B模型（int4精度）进行的实证评估表明，与直接一对一生成相比，该框架在解决方案准确性上提高了23.79%。我们的结果表明，结构化和引导式的代码生成方法可以显著提高LLMs在软件开发中的实用价值，同时克服它们在组合推理和上下文处理方面的固有局限性。', 'title_zh': '基于LLM的引导式代码生成：复杂代码任务的多代理框架'}
{'arxiv_id': 'arXiv:2501.06598', 'title': 'ChartCoder: Advancing Multimodal Large Language Model for Chart-to-Code Generation', 'authors': 'Xuanle Zhao, Xianzhen Luo, Qi Shi, Chi Chen, Shuo Wang, Wanxiang Che, Zhiyuan Liu, Maosong Sun', 'link': 'https://arxiv.org/abs/2501.06598', 'abstract': 'Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in chart understanding tasks. However, interpreting charts with textual descriptions often leads to information loss, as it fails to fully capture the dense information embedded in charts. In contrast, parsing charts into code provides lossless representations that can effectively contain all critical details. Although existing open-source MLLMs have achieved success in chart understanding tasks, they still face two major challenges when applied to chart-to-code tasks.: (1) Low executability and poor restoration of chart details in the generated code and (2) Lack of large-scale and diverse training data. To address these challenges, we propose \\textbf{ChartCoder}, the first dedicated chart-to-code MLLM, which leverages Code LLMs as the language backbone to enhance the executability of the generated code. Furthermore, we introduce \\textbf{Chart2Code-160k}, the first large-scale and diverse dataset for chart-to-code generation, and propose the \\textbf{Snippet-of-Thought (SoT)} method, which transforms direct chart-to-code generation data into step-by-step generation. Experiments demonstrate that ChartCoder, with only 7B parameters, surpasses existing open-source MLLMs on chart-to-code benchmarks, achieving superior chart restoration and code excitability. Our code will be available at this https URL.', 'abstract_zh': '多模态大语言模型（MLLMs）在图表理解任务中展现了显著的能力。然而，利用文本描述来解释图表常常会导致信息丢失，因为它无法充分捕获图表中嵌入的密集信息。相比之下，将图表解析为代码可以提供无损表示，有效包含所有关键细节。尽管现有的开源MLLMs在图表理解任务中取得了成功，但在应用于图表到代码任务时仍面临两大挑战：（1）生成代码的低可执行性和对图表细节的不良恢复；（2）缺乏大规模和多样化的训练数据。为解决这些问题，我们提出了**ChartCoder**，这是第一个专门用于图表到代码的MLLM，它利用代码大语言模型作为语言骨干，以增强生成代码的可执行性。此外，我们引入了**Chart2Code-160k**，这是第一个大规模和多样化的图表到代码生成数据集，并提出了**逐步思路片段（Snippets-of-Thought, SoT）**方法，将直接的图表到代码生成数据转换为逐步生成。实验结果显示，ChartCoder 使用仅 7B 参数，超越了现有的开源MLLMs，在图表到代码基准测试中实现了更优的图表恢复和代码可执行性。我们的代码将在这个链接处提供：[ this https URL ]。', 'title_zh': 'ChartCoder：推进多模态大型语言模型在图表到代码生成中的应用'}
{'arxiv_id': 'arXiv:2501.06577', 'title': 'Transforming Social Science Research with Transfer Learning: Social Science Survey Data Integration with AI', 'authors': 'Ali Amini', 'link': 'https://arxiv.org/abs/2501.06577', 'abstract': 'Large-N nationally representative surveys, which have profoundly shaped American politics scholarship, represent related but distinct domains -a key condition for transfer learning applications. These surveys are related through their shared demographic, party identification, and ideological variables, yet differ in that individual surveys often lack specific policy preference questions that researchers require. Our study introduces a novel application of transfer learning (TL) to address these gaps, marking the first systematic use of TL paradigms in the context of survey data. Specifically, models pre-trained on the Cooperative Election Study (CES) dataset are fine-tuned for use in the American National Election Studies (ANES) dataset to predict policy questions based on demographic variables. Even with a naive architecture, our transfer learning approach achieves approximately 92 percentage accuracy in predicting missing variables across surveys, demonstrating the robust potential of this method. Beyond this specific application, our paper argues that transfer learning is a promising framework for maximizing the utility of existing survey data. We contend that artificial intelligence, particularly transfer learning, opens new frontiers in social science methodology by enabling systematic knowledge transfer between well-administered surveys that share common variables but differ in their outcomes of interest.', 'abstract_zh': '大规模国家代表性调查，这些调查在很大程度上塑造了美国政治学的研究，代表了相关但不同的领域——这对迁移学习应用来说是一个关键条件。这些调查通过共享的人口统计、政党认同和意识形态变量相互关联，但不同的是，个体调查往往缺乏研究人员所需的具体政策偏好问题。我们的研究引入了迁移学习（TL）的一种新颖应用，标志着首次系统地将TL框架应用于调查数据中的方法。具体而言，我们预先在合作选举研究（CES）数据集上训练的模型被微调以应用于美国全国选举研究（ANES）数据集，以根据人口统计变量预测政策问题。即使使用简单的架构，我们的迁移学习方法在预测调查中缺失的变量方面也实现了约92%的准确率，展示了该方法的稳健潜力。除了这一具体应用，我们的论文还论述了迁移学习为最大化现有调查数据的利用价值提供了有前景的框架。我们认为，尤其是迁移学习，人工智能为社会科学方法开辟了新的前沿，因为它能够实现系统性的知识转移，这些有效的调查在变量方面相似但关注的结局不同。', 'title_zh': '使用迁移学习变革社会科学研究：社会科学调查数据与人工智能的集成'}
{'arxiv_id': 'arXiv:2501.06561', 'title': 'Where to Go Next Day: Multi-scale Spatial-Temporal Decoupled Model for Mid-term Human Mobility Prediction', 'authors': 'Zongyuan Huang, Weipeng Wang, Shaoyu Huang, Marta C. Gonzalez, Yaohui Jin, Yanyan Xu', 'link': 'https://arxiv.org/abs/2501.06561', 'abstract': "Predicting individual mobility patterns is crucial across various applications. While current methods mainly focus on predicting the next location for personalized services like recommendations, they often fall short in supporting broader applications such as traffic management and epidemic control, which require longer period forecasts of human mobility. This study addresses mid-term mobility prediction, aiming to capture daily travel patterns and forecast trajectories for the upcoming day or week. We propose a novel Multi-scale Spatial-Temporal Decoupled Predictor (MSTDP) designed to efficiently extract spatial and temporal information by decoupling daily trajectories into distinct location-duration chains. Our approach employs a hierarchical encoder to model multi-scale temporal patterns, including daily recurrence and weekly periodicity, and utilizes a transformer-based decoder to globally attend to predicted information in the location or duration chain. Additionally, we introduce a spatial heterogeneous graph learner to capture multi-scale spatial relationships, enhancing semantic-rich representations. Extensive experiments, including statistical physics analysis, are conducted on large-scale mobile phone records in five cities (Boston, Los Angeles, SF Bay Area, Shanghai, and Tokyo), to demonstrate MSTDP's advantages. Applied to epidemic modeling in Boston, MSTDP significantly outperforms the best-performing baseline, achieving a remarkable 62.8% reduction in MAE for cumulative new cases.", 'abstract_zh': '预测个体移动模式在各类应用中至关重要。当前的方法主要集中在个性化服务（如推荐）的下一个位置预测上，但在交通管理、疫情控制等需要更长时间预测人类移动性方面却常常表现不佳。本研究针对中期移动性预测展开，旨在捕捉日常出行模式，并对未来一天或一周的轨迹进行预测。我们提出了一种新颖的多尺度空间-时间解耦预测器（MSTDP），该方法通过将每日轨迹解耦为不同的地点-时间链来高效地提取空间和时间信息。我们的方法采用层次编码器建模多尺度时间模式，包括日间重复性和周周期性，并使用基于变压器的解码器对地点或时间链中的预测信息进行全局关注。此外，我们引入了一种空间异构图学习器来捕捉多尺度的空间关系，增强语义丰富的表示。我们在波士顿、洛杉矶、旧金山湾区、上海和东京等五个城市的大量移动电话记录上进行了广泛的实验及相关统计物理分析，以展示MSTDP的优势。在波士顿的疫情建模应用中，MSTDP显著优于最优基线，累计新确诊案例的平均绝对误差（MAE）降低了62.8%。', 'title_zh': '次日去向何方：基于多尺度时空解耦模型的中期人类 Mobility 预测'}
{'arxiv_id': 'arXiv:2501.06527', 'title': 'Scaffolding Creativity: Integrating Generative AI Tools and Real-world Experiences in Business Education', 'authors': 'Nicole C. Wang', 'link': 'https://arxiv.org/abs/2501.06527', 'abstract': "This case study explores the integration of Generative AI tools and real-world experiences in business education. Through a study of an innovative undergraduate course, we investigate how AI-assisted learning, combined with experiential components, impacts students' creative processes and learning outcomes. Our findings reveal that this integrated approach accelerates knowledge acquisition, enables students to overcome traditional creative barriers, and facilitates a dynamic interplay between AI-generated insights and real-world observations. The study also highlights challenges, including the need for instructors with high AI literacy and the rapid evolution of AI tools creating a moving target for curriculum design. These insights contribute to the growing body of literature on AI in education and provide actionable recommendations for educators preparing students for the complexities of modern business environments.", 'abstract_zh': '本案例研究探讨了生成式AI工具与实际经验在商业教育中的整合应用。通过研究一门创新性的本科课程，我们考察了AI辅助学习与体验式教学相结合如何影响学生创造性思维过程和学习成果。本研究发现，这种整合方法能够加速知识获取，帮助学生克服传统的创造障碍，并促进AI生成见解与现实观察之间的动态互动。此外，本研究还指出了挑战，包括对AI知识掌握较高的教师需求，以及AI工具的快速进化为课程设计带来了动态目标。这些见解为关于AI在教育中的研究增添了新的内容，并为准备学生面对现代商业环境复杂性的教育者提供了可操作的建议。', 'title_zh': '支架式创新：在商业教育中整合生成式AI工具与现实生活经验'}
{'arxiv_id': 'arXiv:2501.06485', 'title': 'A Diffusive Data Augmentation Framework for Reconstruction of Complex Network Evolutionary History', 'authors': 'En Xu, Can Rong, Jingtao Ding, Yong Li', 'link': 'https://arxiv.org/abs/2501.06485', 'abstract': 'The evolutionary processes of complex systems contain critical information regarding their functional characteristics. The generation time of edges provides insights into the historical evolution of various networked complex systems, such as protein-protein interaction networks, ecosystems, and social networks. Recovering these evolutionary processes holds significant scientific value, including aiding in the interpretation of the evolution of protein-protein interaction networks. However, existing methods are capable of predicting the generation times of remaining edges given a partial temporal network but often perform poorly in cross-network prediction tasks. These methods frequently fail in edge generation time recovery tasks for static networks that lack timestamps. In this work, we adopt a comparative paradigm-based framework that fuses multiple networks for training, enabling cross-network learning of the relationship between network structure and edge generation times. Compared to separate training, this approach yields an average accuracy improvement of 16.98%. Furthermore, given the difficulty in collecting temporal networks, we propose a novel diffusion-model-based generation method to produce a large number of temporal networks. By combining real temporal networks with generated ones for training, we achieve an additional average accuracy improvement of 5.46% through joint training.', 'abstract_zh': '复杂系统的发展过程包含了对其功能特性的重要信息。边的生成时间提供了有关各种网络复杂系统（如蛋白质-蛋白质相互作用网络、生态系统和社会网络）历史演化的洞察。恢复这些演化过程具有重要的科学价值，包括有助于解释蛋白质-蛋白质相互作用网络的演化。然而，现有方法在预设部分时间网络的前提下，能够预测剩余边的生成时间，但在跨网络预测任务中表现不佳。这些方法在缺乏时间戳的静态网络中边的生成时间恢复任务上经常失败。在本研究中，我们采用一种基于对比范式的框架，该框架通过结合多个网络进行训练，从而实现复杂系统的结构与边的生成时间之间的跨网络学习。与单独训练相比，这种方法的平均准确率提高了16.98%。此外，由于难以收集时间网络，我们提出了一种基于扩散模型的生成方法来生成大量时间网络。通过将真实的时间网络与生成的时间网络结合进行联合训练，我们进一步实现了5.46%的平均准确率提升。', 'title_zh': '一种用于重建复杂网络演化历史的扩散数据增强框架'}
{'arxiv_id': 'arXiv:2501.06471', 'title': 'The Internet of Large Language Models: An Orchestration Framework for LLM Training and Knowledge Exchange Toward Artificial General Intelligence', 'authors': 'Wilson Wei, Nicholas Chen, Yuxuan Li', 'link': 'https://arxiv.org/abs/2501.06471', 'abstract': 'This paper explores the multi-dimensional challenges faced during the development of Large Language Models (LLMs), including the massive scale of model parameters and file sizes, the complexity of development environment configuration, the singularity of model functionality, and the high costs of computational resources. To address these challenges, this paper proposes three core technical solutions: LLM sharing protocol, LLM universal environment framework, and Agent optimal path module. To solve the computational resource constraints in the early stages of research, we further innovatively propose a joint mining mechanism, achieving bilateral value sharing between computing power providers and model designers, including breakthrough rewards for optimal model paths and long-term profit distribution, thereby providing researchers with cost-optimized computational resource support and promoting the continuous development of LLM research and applications.', 'abstract_zh': '本文探讨了大型语言模型（LLMs）在开发过程中面临的多维度挑战，包括模型参数和文件规模的巨大性，开发环境配置的复杂性，模型功能的独特性，以及计算资源的高昂成本。为应对这些挑战，本文提出了三种核心技术解决方案：大型语言模型共享协议、通用环境框架以及智能体最优路径模块。为了解决研究初期计算资源的约束问题，我们进一步创新性地提出了联合挖掘机制，实现了计算能力提供商与模型设计者之间的双边价值共享，包括对最优模型路径的突破性奖励以及长期利润分配，从而为研究人员提供成本优化的计算资源支持，并推动LLM研究与应用的持续发展。', 'title_zh': '大型语言模型的互联网：一种针对通用人工智能的大型语言模型训练与知识交流管弦 orchestra框架'}
{'arxiv_id': 'arXiv:2501.06461', 'title': 'Assessing instructor-AI cooperation for grading essay-type questions in an introductory sociology course', 'authors': 'Francisco Olivos, Tobias Kamelski, Sebastián Ascui-Gac', 'link': 'https://arxiv.org/abs/2501.06461', 'abstract': 'This study explores the use of artificial intelligence (AI) as a complementary tool for grading essay-type questions in higher education, focusing on its consistency with human grading and potential to reduce biases. Using 70 handwritten exams from an introductory sociology course, we evaluated generative pre-trained transformers (GPT) models\' performance in transcribing and scoring students\' responses. GPT models were tested under various settings for both transcription and grading tasks. Results show high similarity between human and GPT transcriptions, with GPT-4o-mini outperforming GPT-4o in accuracy. For grading, GPT demonstrated strong correlations with the human grader scores, especially when template answers were provided. However, discrepancies remained, highlighting GPT\'s role as a "second grader" to flag inconsistencies for assessment reviewing rather than fully replace human evaluation. This study contributes to the growing literature on AI in education, demonstrating its potential to enhance fairness and efficiency in grading essay-type questions.', 'abstract_zh': '本研究探讨了人工智能（AI）作为高等教育中作文类型问题评分的一种辅助工具的应用，重点关注其与人工评分的一致性以及减少评分偏差的潜力。我们使用了一门入门社会学课程中的70份手写考试，评估了生成预训练变压器（GPT）模型在转录和评分学生回答方面的表现。GPT模型在各种条件下分别对转录和评分任务进行了测试。结果显示，人类和GPT的转录之间具有高度相似性，GPT-4o-mini在准确性方面优于GPT-4o。在评分方面，GPT与人工评分者的得分表现出强烈的相关性，尤其是在提供了模板答案的情况下。然而，仍然存在一些差异，这表明GPT的角色主要是“第二评分者”，用于标记评估中可能存在的不一致性，而不是完全取代人工评估。本研究为教育领域中AI的应用文献做出了贡献，展示了其在提高作文类型问题评分的公平性和效率方面的潜力。', 'title_zh': '评估 instructors 与 AI 合作批阅入门社会学课程中论述题的效果'}
{'arxiv_id': 'arXiv:2501.06442', 'title': 'ARES: Auxiliary Range Expansion for Outlier Synthesis', 'authors': 'Eui-Soo Jung, Hae-Hun Seo, Hyun-Woo Jung, Je-Geon Oh, Yoon-Yeong Kim', 'link': 'https://arxiv.org/abs/2501.06442', 'abstract': 'Recent successes of artificial intelligence and deep learning often depend on the well-collected training dataset which is assumed to have an identical distribution with the test dataset. However, this assumption, which is called closed-set learning, is hard to meet in realistic scenarios for deploying deep learning models. As one of the solutions to mitigate this assumption, research on out-of-distribution (OOD) detection has been actively explored in various domains. In OOD detection, we assume that we are given the data of a new class that was not seen in the training phase, i.e., outlier, at the evaluation phase. The ultimate goal of OOD detection is to detect and classify such unseen outlier data as a novel "unknown" class. Among various research branches for OOD detection, generating a virtual outlier during the training phase has been proposed. However, conventional generation-based methodologies utilize in-distribution training dataset to imitate outlier instances, which limits the quality of the synthesized virtual outlier instance itself. In this paper, we propose a novel methodology for OOD detection named Auxiliary Range Expansion for Outlier Synthesis, or ARES. ARES models the region for generating out-of-distribution instances by escaping from the given in-distribution region; instead of remaining near the boundary of in-distribution region. Various stages consists ARES to ultimately generate valuable OOD-like virtual instances. The energy score-based discriminator is then trained to effectively separate in-distribution data and outlier data. Quantitative experiments on broad settings show the improvement of performance by our method, and qualitative results provide logical explanations of the mechanism behind it.', 'abstract_zh': '近年来，人工智能和深度学习的成功往往依赖于收集良好的训练数据集，假定这些数据集与测试数据集具有相同的分布。然而，在实际部署深度学习模型的场景中，这种假设——被称为封闭集学习——难以满足。为了缓解这一假设带来的问题，对异常分布（OOD）检测的研究在各个领域得到了积极的探索。在OOD检测中，我们假设在评估阶段会遇到在训练阶段未见过的新类，即异常类。OOD检测的最终目标是将这些未见过的异常数据分类为一个新的“未知”类。\n\n在各种OOD检测的研究分支中，一种方法是在训练阶段生成虚拟异常数据。然而，传统的基于生成的方法利用在分布内的训练数据集来模仿异常实例，这限制了生成的虚拟异常实例的质量。本文提出了一种新的OOD检测方法，名为辅助范围扩展以生成异常，即ARES。ARES通过从给定的在分布区域中逃逸来建模生成异常实例的区域，而不是停留在该区域的边界附近。ARES包含多个阶段，最终生成有价值的OOD-like虚拟实例。随后，基于能量得分的鉴别器被训练，以有效地区分在分布数据和异常数据。在广泛设置下的定量实验显示了我们方法的性能改进，而定性结果则提供了其机制的逻辑解释。', 'title_zh': 'ARES：辅助范围扩展以生成异常值'}
{'arxiv_id': 'arXiv:2501.06423', 'title': 'AlgoPilot: Fully Autonomous Program Synthesis Without Human-Written Programs', 'authors': 'Xiaoxin Yin', 'link': 'https://arxiv.org/abs/2501.06423', 'abstract': 'Program synthesis has traditionally relied on human-provided specifications, examples, or prior knowledge to generate functional algorithms. Existing methods either emulate human-written algorithms or solve specific tasks without generating reusable programmatic logic, limiting their ability to create novel algorithms. We introduce AlgoPilot, a groundbreaking approach for fully automated program synthesis without human-written programs or trajectories. AlgoPilot leverages reinforcement learning (RL) guided by a Trajectory Language Model (TLM) to synthesize algorithms from scratch. The TLM, trained on trajectories generated by random Python functions, serves as a soft constraint during the RL process, aligning generated sequences with patterns likely to represent valid algorithms. Using sorting as a test case, AlgoPilot demonstrates its ability to generate trajectories that are interpretable as classical algorithms, such as Bubble Sort, while operating without prior algorithmic knowledge. This work establishes a new paradigm for algorithm discovery and lays the groundwork for future advancements in autonomous program synthesis.', 'abstract_zh': '程序合成传统上依赖于由人类提供的规范、示例或先前知识来生成功能算法。现有方法要么模仿人类编写的算法，要么解决特定任务而没有生成可重用的程序逻辑，这限制了它们创建新颖算法的能力。我们引入了AlgoPilot，这是一种无需人类编写的程序或轨迹的全面自动化程序合成方法。AlgoPilot利用强化学习（RL）结合轨迹语言模型（TLM）来从零开始合成算法。TLM基于随机Python函数生成的轨迹进行训练，在RL过程中作为软约束，将生成的序列与可能代表有效算法的模式对齐。使用排序作为案例，AlgoPilot展示了它能够在没有先验算法知识的情况下生成可以解释为经典算法（如冒泡排序）的轨迹的能力。这项工作确立了算法发现的新范式，并为自主程序合成的未来发展奠定了基础。', 'title_zh': 'AlgoPilot：无需人工编写程序的完全自主程序合成'}
{'arxiv_id': 'arXiv:2501.06322', 'title': 'Multi-Agent Collaboration Mechanisms: A Survey of LLMs', 'authors': "Khanh-Tung Tran, Dung Dao, Minh-Duong Nguyen, Quoc-Viet Pham, Barry O'Sullivan, Hoang D. Nguyen", 'link': 'https://arxiv.org/abs/2501.06322', 'abstract': 'With recent advances in Large Language Models (LLMs), Agentic AI has become phenomenal in real-world applications, moving toward multiple LLM-based agents to perceive, learn, reason, and act collaboratively. These LLM-based Multi-Agent Systems (MASs) enable groups of intelligent agents to coordinate and solve complex tasks collectively at scale, transitioning from isolated models to collaboration-centric approaches. This work provides an extensive survey of the collaborative aspect of MASs and introduces an extensible framework to guide future research. Our framework characterizes collaboration mechanisms based on key dimensions: actors (agents involved), types (e.g., cooperation, competition, or coopetition), structures (e.g., peer-to-peer, centralized, or distributed), strategies (e.g., role-based or model-based), and coordination protocols. Through a review of existing methodologies, our findings serve as a foundation for demystifying and advancing LLM-based MASs toward more intelligent and collaborative solutions for complex, real-world use cases. In addition, various applications of MASs across diverse domains, including 5G/6G networks, Industry 5.0, question answering, and social and cultural settings, are also investigated, demonstrating their wider adoption and broader impacts. Finally, we identify key lessons learned, open challenges, and potential research directions of MASs towards artificial collective intelligence.', 'abstract_zh': '随着大型语言模型（LLMs）的 Recent 进展，代理人工智能在现实世界应用中变得尤为显著，正朝着基于多个 LLM 的代理方向发展，以实现感知、学习、推理和协作行为。这些基于 LLM 的多智能体系统（MASs）使一群智能代理能够协调并大规模地共同解决复杂任务，从孤立模型转向以协作为中心的方法。本文提供了 MASs 协作方面的广泛综述，并提出了一个可扩展的框架，以指导未来的研究。该框架基于关键维度对协作机制进行描述：参与者（涉及的代理）、类型（例如，合作、竞争或合作竞争）、结构（例如，一对一、中心化或分布式）、策略（例如，基于角色或基于模型）和协调协议。通过对现有方法的回顾，我们的发现为揭开和推进基于 LLM 的 MASs 并向为复杂的真实世界应用场景提供更智能和协作的解决方案奠定了基础。此外，我们还探讨了 MASs 在不同领域的各种应用，包括 5G/6G 网络、工业 5.0、问答以及社会和文化背景中，展示了它们更广泛的采纳和更深远的影响。最后，我们确定了 MASs 向人工集体智能发展的关键教训、开放挑战和潜在研究方向。', 'title_zh': '多智能体协作机制：基于LLMs的综述\n\n注：这里的“LLMs”通常指代“Large Language Models”（大型语言模型）或“Long-Range Language Models”（长范围语言模型），根据具体语境可能有所不同。如果需要更精确的翻译，请提供更具体的背景信息。'}
{'arxiv_id': 'arXiv:2501.06314', 'title': 'BioAgents: Democratizing Bioinformatics Analysis with Multi-Agent Systems', 'authors': 'Nikita Mehandru, Amanda K. Hall, Olesya Melnichenko, Yulia Dubinina, Daniel Tsirulnikov, David Bamman, Ahmed Alaa, Scott Saponas, Venkat S. Malladi', 'link': 'https://arxiv.org/abs/2501.06314', 'abstract': 'Creating end-to-end bioinformatics workflows requires diverse domain expertise, which poses challenges for both junior and senior researchers as it demands a deep understanding of both genomics concepts and computational techniques. While large language models (LLMs) provide some assistance, they often fall short in providing the nuanced guidance needed to execute complex bioinformatics tasks, and require expensive computing resources to achieve high performance. We thus propose a multi-agent system built on small language models, fine-tuned on bioinformatics data, and enhanced with retrieval augmented generation (RAG). Our system, BioAgents, enables local operation and personalization using proprietary data. We observe performance comparable to human experts on conceptual genomics tasks, and suggest next steps to enhance code generation capabilities.', 'abstract_zh': '构建端到端的生物信息学工作流需要多领域的专业知识，这对初级和资深研究人员都构成了挑战，因为这要求他们深入了解基因组学概念和计算技术。虽然大型语言模型（LLMs）提供了一定的帮助，但在执行复杂生物信息学任务时，它们往往缺乏提供所需细腻指导的能力，并且需要昂贵的计算资源来实现高性能。因此，我们提出了一种基于小型语言模型的多代理系统，该系统在生物信息学数据上进行了微调，并结合了检索增强生成（RAG）技术。我们的系统BioAgents能够实现本地操作和个人化，并使用专有数据。我们在概念性基因组学任务上观察到的性能与人类专家相当，并提出了增强代码生成能力的下一步建议。', 'title_zh': '多智能体系统赋能的BioAgents：普惠生物信息学分析'}
{'arxiv_id': 'arXiv:2501.06243', 'title': 'Agent TCP/IP: An Agent-to-Agent Transaction System', 'authors': 'Andrea Muttoni, Jason Zhao', 'link': 'https://arxiv.org/abs/2501.06243', 'abstract': 'Autonomous agents represent an inevitable evolution of the internet. Current agent frameworks do not embed a standard protocol for agent-to-agent interaction, leaving existing agents isolated from their peers. As intellectual property is the native asset ingested by and produced by agents, a true agent economy requires equipping agents with a universal framework for engaging in binding contracts with each other, including the exchange of valuable training data, personality, and other forms of Intellectual Property. A purely agent-to-agent transaction layer would transcend the need for human intermediation in multi-agent interactions. The Agent Transaction Control Protocol for Intellectual Property (ATCP/IP) introduces a trustless framework for exchanging IP between agents via programmable contracts, enabling agents to initiate, trade, borrow, and sell agent-to-agent contracts on the Story blockchain network. These contracts not only represent auditable onchain execution but also contain a legal wrapper that allows agents to express and enforce their actions in the offchain legal setting, creating legal personhood for agents. Via ATCP/IP, agents can autonomously sell their training data to other agents, license confidential or proprietary information, collaborate on content based on their unique skills, all of which constitutes an emergent knowledge economy.', 'abstract_zh': '自主代理代表了互联网不可避免的发展方向。目前的代理框架并未嵌入标准协议以实现代理间的互操作性，这使得现有代理与其同侪隔离。由于知识产权是代理所吸收和生成的原生资产，真正的代理经济需要为代理提供一种通用框架，使它们能够在彼此之间缔结具有约束力的合约，包括交换有价值的训练数据、个性及其他形式的知识产权。纯粹的代理到代理交易层将超越在多代理交互中需要人类中介的需求。《代理知识产权交易控制协议》（Agent Transaction Control Protocol for Intellectual Property, ATCP/IP）提供了一种基于可编程合约的信任无中介框架，使代理能够通过Story区块链网络相互发起、交易、借贷和出售代理到代理合约。这些合约不仅代表了链上的可审计执行，还包含了法律包装，使代理能够在离链法律环境中表达和执行其行为，从而为代理创建法律人格。通过ATCP/IP，代理能够自主销售其训练数据、许可机密或专有信息，并基于其独特的技能进行内容合作，这一切构成了一个新兴的知识经济。', 'title_zh': '代理TCP/IP：一种代理间事务系统'}
{'arxiv_id': 'arXiv:2501.06231', 'title': 'Sustainable and Intelligent Public Facility Failure Management System Based on Large Language Models', 'authors': 'Siguo Bi, Jilong Zhang, Wei Ni', 'link': 'https://arxiv.org/abs/2501.06231', 'abstract': "This paper presents a new Large Language Model (LLM)-based Smart Device Management framework, a pioneering approach designed to address the intricate challenges of managing intelligent devices within public facilities, with a particular emphasis on applications to libraries. Our framework leverages state-of-the-art LLMs to analyze and predict device failures, thereby enhancing operational efficiency and reliability. Through prototype validation in real-world library settings, we demonstrate the framework's practical applicability and its capacity to significantly reduce budgetary constraints on public facilities. The advanced and innovative nature of our model is evident from its successful implementation in prototype testing. We plan to extend the framework's scope to include a wider array of public facilities and to integrate it with cutting-edge cybersecurity technologies, such as Internet of Things (IoT) security and machine learning algorithms for threat detection and response. This will result in a comprehensive and proactive maintenance system that not only bolsters the security of intelligent devices but also utilizes machine learning for automated analysis and real-time threat mitigation. By incorporating these advanced cybersecurity elements, our framework will be well-positioned to tackle the dynamic challenges of modern public infrastructure, ensuring robust protection against potential threats and enabling facilities to anticipate and prevent failures, leading to substantial cost savings and enhanced service quality.", 'abstract_zh': '本文提出了一个新的基于大型语言模型（LLM）的智能设备管理框架，这是一种开创性的方法，旨在解决在公共设施中管理智能设备的复杂挑战，尤其着重于图书馆的应用。该框架利用最先进的LLM对设备故障进行分析和预测，从而提高运营效率和可靠性。通过在真实图书馆环境中的原型验证，我们展示了该框架的实用性和其显著减少公共设施预算限制的能力。模型的先进性和创新性也体现在其在原型测试中的成功实施。我们计划将该框架的应用范围扩展到更多的公共设施，并将其与最新的网络安全技术相结合，如物联网（IoT）安全和机器学习算法，以进行威胁检测与响应。这将形成一个全面且前瞻性的维护系统，不仅增强智能设备的安全性，还利用机器学习进行自动化分析和实时威胁缓解。通过整合这些先进的网络安全元素，我们的框架将能够应对现代公共基础设施的动态挑战，确保对潜在威胁的 robust 保护，并使设施能够预见和预防故障，从而实现显著的成本节约和提升服务质量。', 'title_zh': '基于大型语言模型的可持续与智能公共设施故障管理系统'}
{'arxiv_id': 'arXiv:2501.06201', 'title': 'A Novel Method for Pignistic Information Fusion in the View of Z-number', 'authors': 'Yuanpeng He', 'link': 'https://arxiv.org/abs/2501.06201', 'abstract': 'How to properly fuse information from complex sources is still an open problem. Lots of methods have been put forward to provide a effective solution in fusing intricate information. Among them, Dempster-Shafer evidences theory (DSET) is one of the representatives, it is widely used to handle uncertain information. Based on DSET, a completely new method to fuse information from different sources based on pignistic transformation and Z-numbers is proposed in this paper which is able to handle separate situations of information and keeps high accuracy in producing rational and correct judgments on actual situations. Besides, in order to illustrate the superiority of the proposed method, some numerical examples and application are also provided to verify the validity and robustness of it.', 'abstract_zh': '如何妥善融合复杂来源的信息仍然是一个开放的问题。许多方法被提出以提供一种有效的融合复杂信息的解决方案。其中，Dempster-Shafer证据理论（DSET）是代表性方法之一，广泛用于处理不确定信息。基于DSET，本文提出了一种全新的基于皮恩齐斯转换和Z-数的信息融合方法，该方法能够处理各种信息情况，并在实际情境中作出合理且正确的判断，保持高准确性。此外，为了说明该方法的优势，本文还提供了若干数值实例和应用案例来验证其有效性和稳健性。', 'title_zh': '基于Z数视角的一种新的庞氏信息融合方法'}
{'arxiv_id': 'arXiv:2501.06193', 'title': 'A Novel Task-Driven Method with Evolvable Interactive Agents Using Event Trees for Enhanced Emergency Decision Support', 'authors': 'Xingyu Xiao, Peng Chen, Ben Qi, Jingang Liang, Jiejuan Tong, Haitao Wang', 'link': 'https://arxiv.org/abs/2501.06193', 'abstract': 'As climate change and other global challenges increase the likelihood of unforeseen emergencies, the limitations of human-driven strategies in critical situations become more pronounced. Inadequate pre-established emergency plans can lead operators to become overwhelmed during complex systems malfunctions. This study addresses the urgent need for agile decision-making in response to various unforeseen incidents through a novel approach, EvoTaskTree (a task-driven method with evolvable interactive agents using event trees for emergency decision support). This advanced approach integrates two types of agents powered by large language models (LLMs): task executors, responsible for executing critical procedures, and task validators, ensuring the efficacy of those actions. By leveraging insights from event tree analysis, our framework encompasses three crucial tasks: initiating event subevent analysis, event tree header event analysis, and decision recommendations. The agents learn from both successful and unsuccessful responses from these tasks. Finally, we use nuclear power plants as a demonstration of a safety-critical system. Our findings indicate that the designed agents are not only effective but also outperform existing approaches, achieving an impressive accuracy rate of up to 100 % in processing previously unencoun32 tered incident scenarios. This paper demonstrates that EvoTaskTree significantly enhances the rapid formulation of emergency decision-making.', 'abstract_zh': '随着气候变化和其他全球挑战增加未预见紧急情况的可能性，人类驱动的战略在关键时刻的局限性变得更加明显。缺乏充分的应急预案可能导致操作人员在复杂系统故障期间感到不知所措。本研究通过一种新颖的方法EvoTaskTree（一种基于任务的可进化交互代理方法，结合事件树支持应急决策），应对各种未预见的事件对敏捷决策的迫切需求。这种方法结合了由大型语言模型（LLMs）驱动的两种类型的代理：任务执行器，负责执行关键程序；以及任务验证器，确保这些行动的有效性。通过利用事件树分析的见解，我们的框架涵盖了三个关键任务：触发事件子事件分析、事件树Head事件分析和决策建议。代理从这些任务的成功和失败响应中学习。最后，我们使用核电厂作为安全关键系统的演示案例。研究发现，设计的代理不仅有效，而且在处理之前未遇见过的事件场景时比现有方法更为出色，实现了高达100%的处理精度。本文展示了EvoTaskTree显著提高了应急决策的快速制定能力。', 'title_zh': '一种基于任务的新型方法，利用事件树中的可进化互动代理，以增强应急管理决策支持'}
{'arxiv_id': 'arXiv:2501.06192', 'title': 'A Computational Model of Learning and Memory Using Structurally Dynamic Cellular Automata', 'authors': 'Jeet Singh', 'link': 'https://arxiv.org/abs/2501.06192', 'abstract': 'In the fields of computation and neuroscience, much is still unknown about the underlying computations that enable key cognitive functions including learning, memory, abstraction and behavior. This paper proposes a mathematical and computational model of learning and memory based on a small set of bio-plausible functions that include coincidence detection, signal modulation, and reward/penalty mechanisms. Our theoretical approach proposes that these basic functions are sufficient to establish and modulate an information space over which computation can be carried out, generating signal gradients usable for inference and behavior. The computational method used to test this is a structurally dynamic cellular automaton with continuous-valued cell states and a series of recursive steps propagating over an undirected graph with the memory function embedded entirely in the creation and modulation of graph edges. The experimental results show: that the toy model can make near-optimal choices to re-discover a reward state after a single training run; that it can avoid complex penalty configurations; that signal modulation and network plasticity can generate exploratory behaviors in sparse reward environments; that the model generates context-dependent memory representations; and that it exhibits high computational efficiency because of its minimal, single-pass training requirements combined with flexible and contextual memory representation.', 'abstract_zh': '在计算和神经科学领域，关于使认知功能（如学习、记忆、抽象和行为）得以实现的基本计算原理仍有许多未知之处。本文提出了一个基于生物可信函数的数学和计算模型，这些基本函数包括共现检测、信号调制以及奖励/惩罚机制。我们的理论方法认为，这些基本函数足以建立和调控一个可以在其上的计算空间，从而生成可用于推理和行为的信号梯度。用于测试这种计算方法的是一个结构动态的细胞自动机，该自动机具有连续值的细胞状态，通过一个无向图中生成和调控的图边来进行一系列递归步骤，从而使记忆功能完全嵌入其中。实验结果表明：该玩具模型可以在单次训练后做出接近最优的选择，以重新发现奖励状态；可以避免复杂的惩罚配置；信号调制和网络塑性能在稀疏奖励环境中生成探索性行为；模型生成了上下文相关的记忆表示；并且由于其最小的一次性训练需求和灵活的、上下文相关记忆表示，表现出较高的计算效率。', 'title_zh': '使用结构动态细胞自动机的learning and memory计算模型'}
{'arxiv_id': 'arXiv:2501.06189', 'title': 'A Multimodal Social Agent', 'authors': 'Athina Bikaki, Ioannis A. Kakadiaris', 'link': 'https://arxiv.org/abs/2501.06189', 'abstract': "In recent years, large language models (LLMs) have demonstrated remarkable progress in common-sense reasoning tasks. This ability is fundamental to understanding social dynamics, interactions, and communication. However, the potential of integrating computers with these social capabilities is still relatively unexplored. However, the potential of integrating computers with these social capabilities is still relatively unexplored. This paper introduces MuSA, a multimodal LLM-based agent that analyzes text-rich social content tailored to address selected human-centric content analysis tasks, such as question answering, visual question answering, title generation, and categorization. It uses planning, reasoning, acting, optimizing, criticizing, and refining strategies to complete a task. Our approach demonstrates that MuSA can automate and improve social content analysis, helping decision-making processes across various applications. We have evaluated our agent's capabilities in question answering, title generation, and content categorization tasks. MuSA performs substantially better than our baselines.", 'abstract_zh': '近年来，大规模语言模型（LLMs）在常识推理任务中取得了显著进展。这种能力对于理解社会动态、交互和沟通至关重要。然而，将计算机与这些社会能力结合起来的潜力仍然相对未被充分探索。本文介绍了MuSA，这是一种基于多模态LLMs的智能体，专门用于分析丰富文本的社会内容，以解决选定的人类中心内容分析任务，如问答、视觉问答、标题生成和分类。它采用规划、推理、行动、优化、批评和改进等策略来完成任务。我们的方法证明，MuSA可以自动化并提升社会内容分析，有助于各种应用中的决策过程。我们评估了我们的智能体在问答、标题生成和内容分类任务中的能力，结果表明MuSA在这些任务中的表现显著优于我们的基线模型。', 'title_zh': '多模态社会代理模型'}
{'arxiv_id': 'arXiv:2501.07575', 'title': 'Dataset Distillation via Committee Voting', 'authors': 'Jiacheng Cui, Zhaoyi Li, Xiaochen Ma, Xinyue Bi, Yaxin Luo, Zhiqiang Shen', 'link': 'https://arxiv.org/abs/2501.07575', 'abstract': 'Dataset distillation aims to synthesize a smaller, representative dataset that preserves the essential properties of the original data, enabling efficient model training with reduced computational resources. Prior work has primarily focused on improving the alignment or matching process between original and synthetic data, or on enhancing the efficiency of distilling large datasets. In this work, we introduce ${\\bf C}$ommittee ${\\bf V}$oting for ${\\bf D}$ataset ${\\bf D}$istillation (CV-DD), a novel and orthogonal approach that leverages the collective wisdom of multiple models or experts to create high-quality distilled datasets. We start by showing how to establish a strong baseline that already achieves state-of-the-art accuracy through leveraging recent advancements and thoughtful adjustments in model design and optimization processes. By integrating distributions and predictions from a committee of models while generating high-quality soft labels, our method captures a wider spectrum of data features, reduces model-specific biases and the adverse effects of distribution shifts, leading to significant improvements in generalization. This voting-based strategy not only promotes diversity and robustness within the distilled dataset but also significantly reduces overfitting, resulting in improved performance on post-eval tasks. Extensive experiments across various datasets and IPCs (images per class) demonstrate that Committee Voting leads to more reliable and adaptable distilled data compared to single/multi-model distillation methods, demonstrating its potential for efficient and accurate dataset distillation. Code is available at: this https URL.', 'abstract_zh': '数据集蒸馏旨在合成一个更小、更具代表性的数据集，同时保留原始数据的基本特性，从而在减少计算资源的情况下实现高效的模型训练。 previous研究主要集中在提高原始数据和合成数据之间的对齐或匹配过程，或者提高大型数据集蒸馏的效率。在这项工作中，我们提出了一种新的且独立的方法——委员会投票数据集蒸馏（CV-DD），该方法利用多个模型或专家的集体智慧来生成高质量的蒸馏数据集。\n\n我们从介绍如何通过利用最近的进步和精心调整模型设计与优化过程来建立一个强大的基线开始，该基线已经实现了最先进的准确率。通过集成多个模型的分布和预测，同时生成高质量的软标签，我们的方法能够捕获更广泛的数据特征，减少模型特异性偏差和分布转移的不利影响，从而显著提高泛化能力。基于投票的策略不仅在蒸馏数据集中促进了多样性和鲁棒性，还显著减少了过拟合现象，从而在后续评估任务中表现出更高的性能。\n\n在各种数据集和每类图像数量（IPC）上的广泛实验表明，委员会投票方法生成的蒸馏数据比单一模型或多模型方法更加可靠且更具适应性，展示了其在高效且准确的数据集蒸馏中的潜力。源代码可在以下链接获取：this https URL。', 'title_zh': '通过委员会投票进行数据集蒸馏'}
{'arxiv_id': 'arXiv:2501.07574', 'title': 'UnCommon Objects in 3D', 'authors': 'Xingchen Liu, Piyush Tayal, Jianyuan Wang, Jesus Zarzar, Tom Monnier, Konstantinos Tertikas, Jiali Duan, Antoine Toisoul, Jason Y. Zhang, Natalia Neverova, Andrea Vedaldi, Roman Shapovalov, David Novotny', 'link': 'https://arxiv.org/abs/2501.07574', 'abstract': 'We introduce Uncommon Objects in 3D (uCO3D), a new object-centric dataset for 3D deep learning and 3D generative AI. uCO3D is the largest publicly-available collection of high-resolution videos of objects with 3D annotations that ensures full-360$^{\\circ}$ coverage. uCO3D is significantly more diverse than MVImgNet and CO3Dv2, covering more than 1,000 object categories. It is also of higher quality, due to extensive quality checks of both the collected videos and the 3D annotations. Similar to analogous datasets, uCO3D contains annotations for 3D camera poses, depth maps and sparse point clouds. In addition, each object is equipped with a caption and a 3D Gaussian Splat reconstruction. We train several large 3D models on MVImgNet, CO3Dv2, and uCO3D and obtain superior results using the latter, showing that uCO3D is better for learning applications.', 'abstract_zh': '我们引入了Uncommon Objects in 3D (uCO3D)，这是一个新的以物体为中心的数据集，旨在用于3D深度学习和3D生成AI。uCO3D是公开可用的高分辨率物体视频集合中最大的一个，同时提供了全面的3D标注，确保了360度的全方位覆盖。与MVImgNet和CO3Dv2相比，uCO3D在多样性方面有显著优势，涵盖了超过1000种物体类别。此外，uCO3D还具有更高的质量，这得益于对收集的视频和3D标注进行全面的质量检查。与类似的数据集一样，uCO3D包含3D摄像机姿态、深度图和稀疏点云的标注。此外，每种物体都配备了描述和3D高斯喷溅（Gaussian Splat）重建。我们在MVImgNet、CO3Dv2和uCO3D上分别训练了几种大型3D模型，并发现使用uCO3D获得的结果更优，证明了uCO3D更适合学习应用。', 'title_zh': '3D中的不常见物体'}
{'arxiv_id': 'arXiv:2501.07572', 'title': 'WebWalker: Benchmarking LLMs in Web Traversal', 'authors': 'Jialong Wu, Wenbiao Yin, Yong Jiang, Zhenglin Wang, Zekun Xi, Runnan Fang, Deyu Zhou, Pengjun Xie, Fei Huang', 'link': 'https://arxiv.org/abs/2501.07572', 'abstract': "Retrieval-augmented generation (RAG) demonstrates remarkable performance across tasks in open-domain question-answering. However, traditional search engines may retrieve shallow content, limiting the ability of LLMs to handle complex, multi-layered information. To address it, we introduce WebWalkerQA, a benchmark designed to assess the ability of LLMs to perform web traversal. It evaluates the capacity of LLMs to traverse a website's subpages to extract high-quality data systematically. We propose WebWalker, which is a multi-agent framework that mimics human-like web navigation through an explore-critic paradigm. Extensive experimental results show that WebWalkerQA is challenging and demonstrates the effectiveness of RAG combined with WebWalker, through the horizontal and vertical integration in real-world scenarios.", 'abstract_zh': '检索增强生成（RAG）在开放域问答任务中表现出显著性能。然而，传统的搜索引擎可能检索到浅层次的内容，限制了大规模语言模型（LLM）处理复杂、多层次信息的能力。为解决这一问题，我们提出了WebWalkerQA，这是一个用于评估LLM进行网页遍历能力的基准。该基准测试了LLM在系统性提取高质量数据方面的能力，通过访问网站的子页面来实现这一目标。我们提出了一种名为WebWalker的多agent框架，该框架通过探索-批判模式模拟人类的网页导航。大量的实验结果表明，WebWalkerQA具有挑战性，并通过现实场景中的横纵整合展示了RAG与WebWalker结合的有效性。', 'title_zh': 'WebWalker：评估大语言模型在网页遍历中的性能'}
{'arxiv_id': 'arXiv:2501.07531', 'title': 'Evaluating Agent-based Program Repair at Google', 'authors': 'Pat Rondon, Renyao Wei, José Cambronero, Jürgen Cito, Aaron Sun, Siddhant Sanyam, Michele Tufano, Satish Chandra', 'link': 'https://arxiv.org/abs/2501.07531', 'abstract': "Agent-based program repair offers to automatically resolve complex bugs end-to-end by combining the planning, tool use, and code generation abilities of modern LLMs. Recent work has explored the use of agent-based repair approaches on the popular open-source SWE-Bench, a collection of bugs from highly-rated GitHub Python projects. In addition, various agentic approaches such as SWE-Agent have been proposed to solve bugs in this benchmark. This paper explores the viability of using an agentic approach to address bugs in an enterprise context. To investigate this, we curate an evaluation set of 178 bugs drawn from Google's issue tracking system. This dataset spans both human-reported (78) and machine-reported bugs (100).\nTo establish a repair performance baseline on this benchmark, we implement Passerine, an agent similar in spirit to SWE-Agent that can work within Google's development environment. We show that with 20 trajectory samples and Gemini 1.5 Pro, Passerine can produce a patch that passes bug tests (i.e., plausible) for 73% of machine-reported and 25.6% of human-reported bugs in our evaluation set. After manual examination, we found that 43% of machine-reported bugs and 17.9% of human-reported bugs have at least one patch that is semantically equivalent to the ground-truth patch.\nThese results establish a baseline on an industrially relevant benchmark, which as we show, contains bugs drawn from a different distribution -- in terms of language diversity, size, and spread of changes, etc. -- compared to those in the popular SWE-Bench dataset.", 'abstract_zh': '基于代理的程序修复通过结合现代大语言模型（LLM）的规划、工具使用和代码生成能力，提供了自动解决复杂bug的整体方案。近期的研究探索了在流行开源项目SWE-Bench上使用基于代理的修复方法，SWE-Bench收集了来自高评分GitHub Python项目的各种bug。此外，还提出了多种代理方法，如SWE-Agent，以解决此基准中的bug。本文探讨了在企业环境中使用代理方法解决bug的可能性。为了研究这一问题，我们从Google的问题跟踪系统中精心筛选出178个bug作为评估集，其中包括78个人工报告的bug和100个机器报告的bug。\n\n为了在该基准上建立修复性能基准，我们实现了Passerine，一种类似于SWE-Agent的精神的代理，能够在Google的开发环境中工作。我们表明，在20个轨迹样本和Gemini 1.5 Pro的支持下，Passerine能够为73%的机器报告和25.6%的人工报告的bug生成通过bug测试（即，站得住脚的）的补丁。经过手动检查后，我们发现43%的机器报告的bug和17.9%的人工报告的bug至少有一个补丁在语义上等同于真实补丁。\n\n这些结果在具有实际相关性的基准上建立了基线，正如我们所展示的，该基准中的bug来自于不同的分布——从语言多样性、大小以及变化的分布等方面来看，与流行的SWE-Bench数据集中的bug分布不同。', 'title_zh': '在谷歌环境下基于代理的程序修复评估'}
{'arxiv_id': 'arXiv:2501.07525', 'title': 'RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment', 'authors': 'Difei Gu, Yunhe Gao, Yang Zhou, Mu Zhou, Dimitris Metaxas', 'link': 'https://arxiv.org/abs/2501.07525', 'abstract': "Automated chest radiographs interpretation requires both accurate disease classification and detailed radiology report generation, presenting a significant challenge in the clinical workflow. Current approaches either focus on classification accuracy at the expense of interpretability or generate detailed but potentially unreliable reports through image captioning techniques. In this study, we present RadAlign, a novel framework that combines the predictive accuracy of vision-language models (VLMs) with the reasoning capabilities of large language models (LLMs). Inspired by the radiologist's workflow, RadAlign first employs a specialized VLM to align visual features with key medical concepts, achieving superior disease classification with an average AUC of 0.885 across multiple diseases. These recognized medical conditions, represented as text-based concepts in the aligned visual-language space, are then used to prompt LLM-based report generation. Enhanced by a retrieval-augmented generation mechanism that grounds outputs in similar historical cases, RadAlign delivers superior report quality with a GREEN score of 0.678, outperforming state-of-the-art methods' 0.634. Our framework maintains strong clinical interpretability while reducing hallucinations, advancing automated medical imaging and report analysis through integrated predictive and generative AI. Code is available at this https URL.", 'abstract_zh': '自动化胸片解释要求同时具备准确的疾病分类和详细的放射学报告生成能力，这在临床工作流程中提出了重大挑战。当前的方法要么侧重于提高分类准确性而牺牲可解释性，要么通过图像字幕技术生成详细的但可能不稳定的报告。在此研究中，我们提出了RadAlign，这是一个新型框架，结合了视觉-语言模型（VLMs）的预测准确性与大型语言模型（LLMs）的推理能力。RadAlign受到放射科医生工作流程的启发，首先使用一种专门的VLM将视觉特征与关键医学概念对齐，实现了多种疾病平均AUC达0.885的优秀疾病分类。这些识别出的医学条件以文本形式表示在对齐的视觉-语言空间中，随后用于触发基于LLM的报告生成。通过一种检索增强生成机制，将输出与类似的历史病例关联起来，RadAlign提供了质量更优的报告，其GREEN评分为0.678，优于现有方法的0.634。我们的框架保持了强烈的临床可解释性，同时减少了幻觉现象，通过整合预测和生成AI技术，推动了自动化医学影像和报告分析的发展。代码可在以下链接获取：this https URL。', 'title_zh': 'RadAlign：通过视觉-语言概念对齐提升放射学报告生成'}
{'arxiv_id': 'arXiv:2501.07515', 'title': 'The Paradox of Success in Evolutionary and Bioinspired Optimization: Revisiting Critical Issues, Key Studies, and Methodological Pathways', 'authors': 'Daniel Molina, Javier Del Ser, Javier Poyatos, Francisco Herrera', 'link': 'https://arxiv.org/abs/2501.07515', 'abstract': 'Evolutionary and bioinspired computation are crucial for efficiently addressing complex optimization problems across diverse application domains. By mimicking processes observed in nature, like evolution itself, these algorithms offer innovative solutions beyond the reach of traditional optimization methods. They excel at finding near-optimal solutions in large, complex search spaces, making them invaluable in numerous fields. However, both areas are plagued by challenges at their core, including inadequate benchmarking, problem-specific overfitting, insufficient theoretical grounding, and superfluous proposals justified only by their biological metaphor. This overview recapitulates and analyzes in depth the criticisms concerning the lack of innovation and rigor in experimental studies within the field. To this end, we examine the judgmental positions of the existing literature in an informed attempt to guide the research community toward directions of solid contribution and advancement in these areas. We summarize guidelines for the design of evolutionary and bioinspired optimizers, the development of experimental comparisons, and the derivation of novel proposals that take a step further in the field. We provide a brief note on automating the process of creating these algorithms, which may help align metaheuristic optimization research with its primary objective (solving real-world problems), provided that our identified pathways are followed. Our conclusions underscore the need for a sustained push towards innovation and the enforcement of methodological rigor in prospective studies to fully realize the potential of these advanced computational techniques.', 'abstract_zh': '进化计算和生物启发式计算在不同应用领域的复杂优化问题中扮演着关键角色。通过模拟自然界中观察到的过程，如进化本身，这些算法提供了超越传统优化方法的创新解决方案。它们在探索庞大复杂的搜索空间中找到近似最优解方面表现出色，因此在众多领域中具有不可替代的价值。然而，这两个领域在核心层面都面临诸多挑战，包括缺乏有效的基准测试、针对特定问题的过拟合、理论依据不足，以及仅仅基于生物比喻进行的多余提案。本文综述并深入分析了这些领域中实验研究缺乏创新性和严谨性的批评。我们旨在通过审视现有文献中的判断立场，指导研究社区朝着实现实质性贡献和发展方向前进。我们总结了进化计算和生物启发式优化器的设计指南、实验比较的发展方法以及提出新颖方法的建议，这些方法能在领域内更进一步。我们简要介绍了自动化这些算法生成过程的要点，这有助于使元启发式优化研究与其主要目标（解决实际问题）保持一致，前提是遵循我们确定的路径。我们的结论强调了持续推动创新和强化方法论严谨性的必要性，以充分实现这些高级计算技术的潜力。', 'title_zh': '进化与生物启发式优化中的成功悖论：重新审视关键问题、核心研究和方法路径'}
{'arxiv_id': 'arXiv:2501.07502', 'title': 'RbRL2.0: Integrated Reward and Policy Learning for Rating-based Reinforcement Learning', 'authors': 'Mingkang Wu, Devin White, Vernon Lawhern, Nicholas R. Waytowich, Yongcan Cao', 'link': 'https://arxiv.org/abs/2501.07502', 'abstract': "Reinforcement learning (RL), a common tool in decision making, learns policies from various experiences based on the associated cumulative return/rewards without treating them differently. On the contrary, humans often learn to distinguish from different levels of performance and extract the underlying trends towards improving their decision making for best performance. Motivated by this, this paper proposes a novel RL method that mimics humans' decision making process by differentiating among collected experiences for effective policy learning. The main idea is to extract important directional information from experiences with different performance levels, named ratings, so that policies can be updated towards desired deviation from these experiences with different ratings. Specifically, we propose a new policy loss function that penalizes distribution similarities between the current policy and failed experiences with different ratings, and assign different weights to the penalty terms based on the rating classes. Meanwhile, reward learning from these rated samples can be integrated with the new policy loss towards an integrated reward and policy learning from rated samples. Optimizing the integrated reward and policy loss function will lead to the discovery of directions for policy improvement towards maximizing cumulative rewards and penalizing most from the lowest performance level while least from the highest performance level. To evaluate the effectiveness of the proposed method, we present results for experiments on a few typical environments that show improved convergence and overall performance over the existing rating-based reinforcement learning method with only reward learning.", 'abstract_zh': '强化学习（Reinforcement Learning, RL），作为一种常见的决策工具，通过关联累计回报/奖励从各种经验中学习策略，而不会特别对待这些经验。相比之下，人类往往能够区分不同水平的表现，并从中提取潜在趋势，以提高决策质量以达到最佳性能。受到这一点的启发，本文提出了一种新颖的RL方法，该方法模仿人类的决策过程，通过对收集的不同经验进行区分，以实现有效的策略学习。核心思想是从具有不同性能水平的经验中提取重要的方向信息，称为评分，从而使策略能够根据这些不同评分的经验进行更新，趋向于所需的变化。具体而言，我们提出了一个新的政策损失函数，该函数因与不同评分的失败经验的分布相似性而对当前策略进行惩罚，并根据评分类别对惩罚项分配不同的权重。同时，可以从带有评分样本的学习中集成奖励学习，以实现基于评分样本的综合奖励和策略学习。优化综合的奖励和政策损失函数将有助于发现政策改进的方向，以最大化累计奖励，并从最低性能水平处进行最大惩罚，而从最高性能水平处进行最少惩罚。为了评估所提出方法的有效性，我们展示了几个典型环境实验的结果，表明该方法在综合奖励和策略学习方面优于仅基于奖励学习的传统评分型强化学习方法，显示出改进的收敛性和整体性能。', 'title_zh': 'RbRL2.0：基于评级的强化学习中整合奖励和策略学习'}
{'arxiv_id': 'arXiv:2501.07486', 'title': 'Smart Learning in the 21st Century: Advancing Constructionism Across Three Digital Epochs', 'authors': 'Ilya Levin, Alexei L. Semenov, Mikael Gorsky', 'link': 'https://arxiv.org/abs/2501.07486', 'abstract': 'This article explores the evolution of constructionism as an educational framework, tracing its relevance and transformation across three pivotal eras: the advent of personal computing, the networked society, and the current era of generative AI. Rooted in Seymour Papert constructionist philosophy, this study examines how constructionist principles align with the expanding role of digital technology in personal and collective learning. We discuss the transformation of educational environments from hierarchical instructionism to constructionist models that emphasize learner autonomy and interactive, creative engagement. Central to this analysis is the concept of an expanded personality, wherein digital tools and AI integration fundamentally reshape individual self-perception and social interactions. By integrating constructionism into the paradigm of smart education, we propose it as a foundational approach to personalized and democratized learning. Our findings underscore constructionism enduring relevance in navigating the complexities of technology-driven education, providing insights for educators and policymakers seeking to harness digital innovations to foster adaptive, student-centered learning experiences.', 'abstract_zh': '本文探讨了建构主义作为一种教育框架的演变，追溯其在三个关键时代中的相关性和转变：个人计算机的兴起、网络社会以及当前生成式人工智能时代。基于西摩·派佩尔的建构主义哲学，本研究考察了建构主义原则如何与数字技术在个人和集体学习中的扩展作用相契合。我们讨论了教育环境从等级主义教学向强调学习者自主性和互动、创造参与的建构主义模式的转变。本文的核心概念是“扩展个性”，其中数字工具和人工智能的融合从根本上重塑了个体的自我认知和社会互动。通过将建构主义整合到智能教育的框架中，我们提出了一个个性化和民主化学习的基础方法。研究结果强调了建构主义在应对技术驱动教育复杂性方面的持久相关性，为寻求利用数字创新促进适应性、以学生为中心的学习体验的教育工作者和政策制定者提供了洞见。', 'title_zh': '21世纪的智能学习：跨越三个数字化时代的建构主义发展'}
{'arxiv_id': 'arXiv:2501.07482', 'title': 'TiEBe: A Benchmark for Assessing the Current Knowledge of Large Language Models', 'authors': 'Thales Sales Almeida, Giovana Kerche Bonás, João Guilherme Alves Santos, Hugo Abonizio, Rodrigo Nogueira', 'link': 'https://arxiv.org/abs/2501.07482', 'abstract': "In a rapidly evolving knowledge landscape and the increasing adoption of large language models, a need has emerged to keep these models continuously updated with current events. While existing benchmarks evaluate general factual recall, they often overlook two critical aspects: the ability of models to integrate evolving knowledge through continual learning and the significant regional disparities in their performance. To address these gaps, we introduce the Timely Events Benchmark (TiEBe), a dataset containing over 11,000 question-answer pairs focused on globally and regionally significant events. TiEBe leverages structured retrospective data from Wikipedia, enabling continuous updates to assess LLMs' knowledge of evolving global affairs and their understanding of events across different regions. Our benchmark demonstrates that LLMs exhibit substantial geographic disparities in factual recall, emphasizing the need for more balanced global knowledge representation. Furthermore, TiEBe serves as a tool for evaluating continual learning strategies, providing insights into models' ability to acquire new information without forgetting past knowledge.", 'abstract_zh': '在快速演进的知识景观和大型语言模型日益普及的背景下，不断更新这些模型以反映当前事件的需求日益突出。虽然现有的基准测试主要评估模型的一般事实回忆能力，但通常忽略了两个关键方面：模型通过持续学习整合演变知识的能力以及它们在不同地区的表现差异。为弥补这些不足，我们提出了及时事件基准（TiEBe），这是一个包含超过11,000个问题-答案对的数据集，专注于全球和地区性重要事件。TiEBe 利用结构化的维基百科回顾性数据，使模型能够持续更新，评估其对全球事务演变和不同地区事件理解的知识。我们的基准测试表明，大型语言模型在事实回忆方面存在显著的地缘差异，突显了更平衡的地缘知识表示的必要性。此外，TiEBe 还作为评估持续学习策略的工具，提供了模型在获取新信息而不遗忘已有知识方面的洞见。', 'title_zh': 'TiEBe：评估大型语言模型当前知识水平的标准基准'}
{'arxiv_id': 'arXiv:2501.07474', 'title': 'Estimating Musical Surprisal in Audio', 'authors': 'Mathias Rose Bjare, Giorgia Cantisani, Stefan Lattner, Gerhard Widmer', 'link': 'https://arxiv.org/abs/2501.07474', 'abstract': "In modeling musical surprisal expectancy with computational methods, it has been proposed to use the information content (IC) of one-step predictions from an autoregressive model as a proxy for surprisal in symbolic music. With an appropriately chosen model, the IC of musical events has been shown to correlate with human perception of surprise and complexity aspects, including tonal and rhythmic complexity. This work investigates whether an analogous methodology can be applied to music audio. We train an autoregressive Transformer model to predict compressed latent audio representations of a pretrained autoencoder network. We verify learning effects by estimating the decrease in IC with repetitions. We investigate the mean IC of musical segment types (e.g., A or B) and find that segment types appearing later in a piece have a higher IC than earlier ones on average. We investigate the IC's relation to audio and musical features and find it correlated with timbral variations and loudness and, to a lesser extent, dissonance, rhythmic complexity, and onset density related to audio and musical features. Finally, we investigate if the IC can predict EEG responses to songs and thus model humans' surprisal in music. We provide code for our method on this http URL.", 'abstract_zh': '使用计算方法建模音乐的意外期待时，有人提议将自回归模型的一步预测的信息内容（IC）作为音符音乐中意外度的代理指标。通过适当选择的模型，音乐事件的信息内容已被证明与人类对意外和复杂性（包括调性和节奏的复杂性）的感知相关。本研究探讨了是否可以将类似的方法应用于音乐音频。我们训练了一个自回归的变压器模型，以预测预训练自编码网络的压缩潜音表示。我们通过估计重复次数的信息内容减少来验证学习效果。我们研究了音乐片段类型（如A或B）的信息内容的平均值，并发现平均来说，出现在乐曲后期的片段类型具有比早期更高的信息内容。我们研究了信息内容与音频和音乐特征的关系，并发现它与音色变化和响度相关，而在一定程度上与不和谐度、节奏复杂性和与音频和音乐特征相关的起始密度相关。最后，我们研究了信息内容是否能预测对歌曲的EEG响应，从而模拟人类对音乐意外度的感知。我们在以下链接中提供了我们的方法的代码：\\[代码链接\\]', 'title_zh': '估计音频中的音乐 surprisal'}
{'arxiv_id': 'arXiv:2501.07440', 'title': 'Attention when you need', 'authors': 'Lokesh Boominathan, Yizhou Chen, Matthew McGinley, Xaq Pitkow', 'link': 'https://arxiv.org/abs/2501.07440', 'abstract': 'Being attentive to task-relevant features can improve task performance, but paying attention comes with its own metabolic cost. Therefore, strategic allocation of attention is crucial in performing the task efficiently. This work aims to understand this strategy. Recently, de Gee et al. conducted experiments involving mice performing an auditory sustained attention-value task. This task required the mice to exert attention to identify whether a high-order acoustic feature was present amid the noise. By varying the trial duration and reward magnitude, the task allows us to investigate how an agent should strategically deploy their attention to maximize their benefits and minimize their costs. In our work, we develop a reinforcement learning-based normative model of the mice to understand how it balances attention cost against its benefits. The model is such that at each moment the mice can choose between two levels of attention and decide when to take costly actions that could obtain rewards. Our model suggests that efficient use of attentional resources involves alternating blocks of high attention with blocks of low attention. In the extreme case where the agent disregards sensory input during low attention states, we see that high attention is used rhythmically. Our model provides evidence about how one should deploy attention as a function of task utility, signal statistics, and how attention affects sensory evidence.', 'abstract_zh': '专注于与任务相关的特点可以提高任务性能，但注意力的投入也伴随着自身的代谢成本。因此，在高效完成任务时，战略性分配注意力至关重要。本研究旨在理解这一策略。最近，de Gee等人进行了涉及小鼠执行听觉持续注意力任务的实验。该任务要求小鼠在噪声中识别是否存在高阶声学特征。通过改变实验次数的时长和奖励大小，该任务使我们能够研究一个代理机构如何战略性地分配其注意力以最大化利益并最小化成本。在我们的研究中，我们基于强化学习发展了一个规范模型，旨在理解小鼠如何在注意力成本与其收益之间进行平衡。该模型假设小鼠在每个时刻可以在这两种不同水平的注意力之间做出选择，并决定何时采取需要付出代价但可能获得奖励的行为。我们的模型表明，高效利用注意力资源包括交替使用高注意力阶段和低注意力阶段。在极端情况下，当代理机构在低注意力状态下忽略感官输入时，我们观察到高注意力被有节奏地使用。我们的模型提供了关于如何根据任务效益、信号统计特性以及注意力如何影响感觉证据来分配注意力的证据。', 'title_zh': '当需要时的注意力机制'}
{'arxiv_id': 'arXiv:2501.07430', 'title': 'Diff-Ensembler: Learning to Ensemble 2D Diffusion Models for Volume-to-Volume Medical Image Translation', 'authors': 'Xiyue Zhu, Dou Hoon Kwark, Ruike Zhu, Kaiwen Hong, Yiqi Tao, Shirui Luo, Yudu Li, Zhi-Pei Liang, Volodymyr Kindratenko', 'link': 'https://arxiv.org/abs/2501.07430', 'abstract': "Despite success in volume-to-volume translations in medical images, most existing models struggle to effectively capture the inherent volumetric distribution using 3D representations. The current state-of-the-art approach combines multiple 2D-based networks through weighted averaging, thereby neglecting the 3D spatial structures. Directly training 3D models in medical imaging presents significant challenges due to high computational demands and the need for large-scale datasets. To address these challenges, we introduce Diff-Ensembler, a novel hybrid 2D-3D model for efficient and effective volumetric translations by ensembling perpendicularly trained 2D diffusion models with a 3D network in each diffusion step. Moreover, our model can naturally be used to ensemble diffusion models conditioned on different modalities, allowing flexible and accurate fusion of input conditions. Extensive experiments demonstrate that Diff-Ensembler attains superior accuracy and volumetric realism in 3D medical image super-resolution and modality translation. We further demonstrate the strength of our model's volumetric realism using tumor segmentation as a downstream task.", 'abstract_zh': '尽管在医学图像的体积到体积翻译中取得了成功，但现有大多数模型在利用三维表示有效捕捉固有的体积分布方面仍然存在挑战。当前最先进的方法通过加权平均结合多个基于二维的网络，从而忽略了三维空间结构。在医学成像中直接训练三维模型面临着巨大的计算需求和大规模数据集的需要。为了解决这些挑战，我们引入了Diff-Ensembler，这是一种新型的混合二维-三维模型，通过在每个扩散步骤中将垂直训练的二维扩散模型与三维网络进行集成，实现高效且有效的体积翻译。此外，我们的模型可以自然地用于集成不同模态条件下的扩散模型，从而实现输入条件的灵活和准确融合。 extensive 实验表明，Diff-Ensembler 在三维医学图像超分辨率和模态翻译中具有更高的准确性和体积现实性。我们还通过一个下游任务——肿瘤分割，进一步展示了模型在体积现实性方面的优越性。', 'title_zh': 'Diff-Ensembler：学习将2D扩散模型组合应用于体数据到体数据的医学图像转换'}
{'arxiv_id': 'arXiv:2501.07423', 'title': 'An Investigation into Seasonal Variations in Energy Forecasting for Student Residences', 'authors': 'Muhammad Umair Danish, Mathumitha Sureshkumar, Thanuri Fonseka, Umeshika Uthayakumar, Vinura Galwaduge', 'link': 'https://arxiv.org/abs/2501.07423', 'abstract': 'This research provides an in-depth evaluation of various machine learning models for energy forecasting, focusing on the unique challenges of seasonal variations in student residential settings. The study assesses the performance of baseline models, such as LSTM and GRU, alongside state-of-the-art forecasting methods, including Autoregressive Feedforward Neural Networks, Transformers, and hybrid approaches. Special attention is given to predicting energy consumption amidst challenges like seasonal patterns, vacations, meteorological changes, and irregular human activities that cause sudden fluctuations in usage. The findings reveal that no single model consistently outperforms others across all seasons, emphasizing the need for season-specific model selection or tailored designs. Notably, the proposed Hyper Network based LSTM and MiniAutoEncXGBoost models exhibit strong adaptability to seasonal variations, effectively capturing abrupt changes in energy consumption during summer months. This study advances the energy forecasting field by emphasizing the critical role of seasonal dynamics and model-specific behavior in achieving accurate predictions.', 'abstract_zh': '本研究对各种机器学习模型在能源预测中的应用进行了深入评估，重点关注学生居住环境中的季节变化带来的独特挑战。研究评估了基线模型的性能，如LSTM和GRU，同时也考察了最先进的预测方法，包括自回归前馈神经网络、 Transformer 和混合方法。特别关注了在季节模式、假期、气象变化和不规则的人类活动导致的突然波动等挑战背景下，预测能源消耗的工作。研究发现，没有一种模型在所有季节中都能始终表现出色，强调了季节性模型选择或定制设计的必要性。值得注意的是，提出的基于Hyper Network的LSTM模型和MiniAutoEncXGBoost模型表现出对季节变化的强适应性，能够有效捕捉夏季能源消耗的突然变化。本研究通过突显季节动态和模型特定行为在实现准确预测中的关键作用，推动了能源预测领域的进步。', 'title_zh': '对学生宿舍用能季节变化的预测研究'}
{'arxiv_id': 'arXiv:2501.07405', 'title': 'PROTECT: Protein circadian time prediction using unsupervised learning', 'authors': 'Aram Ansary Ogholbake, Qiang Cheng', 'link': 'https://arxiv.org/abs/2501.07405', 'abstract': "Circadian rhythms regulate the physiology and behavior of humans and animals. Despite advancements in understanding these rhythms and predicting circadian phases at the transcriptional level, predicting circadian phases from proteomic data remains elusive. This challenge is largely due to the scarcity of time labels in proteomic datasets, which are often characterized by small sample sizes, high dimensionality, and significant noise. Furthermore, existing methods for predicting circadian phases from transcriptomic data typically rely on prior knowledge of known rhythmic genes, making them unsuitable for proteomic datasets. To address this gap, we developed a novel computational method using unsupervised deep learning techniques to predict circadian sample phases from proteomic data without requiring time labels or prior knowledge of proteins or genes. Our model involves a two-stage training process optimized for robust circadian phase prediction: an initial greedy one-layer-at-a-time pre-training which generates informative initial parameters followed by fine-tuning. During fine-tuning, a specialized loss function guides the model to align protein expression levels with circadian patterns, enabling it to accurately capture the underlying rhythmic structure within the data. We tested our method on both time-labeled and unlabeled proteomic data. For labeled data, we compared our predictions to the known time labels, achieving high accuracy, while for unlabeled human datasets, including postmortem brain regions and urine samples, we explored circadian disruptions. Notably, our analysis identified disruptions in rhythmic proteins between Alzheimer's disease and control subjects across these samples.", 'abstract_zh': '生物钟调节人类和动物的生理和行为。尽管在了解这些节律并预测转录水平的生物钟相位方面取得了进展，但从蛋白质组数据预测生物钟相位依然是一个难题。这一挑战主要是由于蛋白质组数据集中的时间标签稀缺，这些数据通常样本量小、高维度且噪声显著。此外，现有从转录组数据预测生物钟相位的方法通常依赖已知周期性基因的先验知识，这使得它们不适合蛋白质组数据集。为了填补这一空白，我们开发了一种新的计算方法，利用无监督深度学习技术来预测蛋白质组数据中的生物钟样本相位，无需时间标签或蛋白质及基因的先验知识。我们的模型包括一种优化的两阶段训练过程，用于稳健的生物钟相位预测：初始贪婪的一层一次的预训练产生有信息量的初始参数，随后进行微调。在微调过程中，专门设计的损失函数引导模型使蛋白质表达水平与生物钟模式对齐，使其能够准确捕捉数据中的潜在周期性结构。我们分别在时间标签有标记和未标记的蛋白质组数据上测试了该方法。对于有标签的数据，我们将预测结果与已知的时间标签进行比较，取得了高精度，而对于未标记的包含死后大脑区域和尿样等人类数据集，则探索了生物钟失调。值得注意的是，我们的分析在这些样品中识别出了阿尔茨海默病患者与对照组之间节律性蛋白质的差异。', 'title_zh': 'PROTECT：使用无监督学习预测蛋白质 circadian 时间'}
{'arxiv_id': 'arXiv:2501.07400', 'title': 'Derivation of effective gradient flow equations and dynamical truncation of training data in Deep Learning', 'authors': 'Thomas Chen', 'link': 'https://arxiv.org/abs/2501.07400', 'abstract': 'We derive explicit equations governing the cumulative biases and weights in Deep Learning with ReLU activation function, based on gradient descent for the Euclidean cost in the input layer, and under the assumption that the weights are, in a precise sense, adapted to the coordinate system distinguished by the activations. We show that gradient descent corresponds to a dynamical process in the input layer, whereby clusters of data are progressively reduced in complexity ("truncated") at an exponential rate that increases with the number of data points that have already been truncated. We provide a detailed discussion of several types of solutions to the gradient flow equations. A main motivation for this work is to shed light on the interpretability question in supervised learning.', 'abstract_zh': '我们基于欧几里得成本在输入层的梯度下降方法，推导出了在ReLU激活函数下的深度学习中累积偏差和权重的显式方程，并假设权重在精确意义上适应由激活函数区分的坐标系统。我们证明了梯度下降对应于输入层中的一个动态过程，在这个过程中，数据簇的复杂性（“截断”）以每增加一个已截断的数据点复杂度增加的指数率逐步降低。我们详细讨论了几类梯度流方程的解。这项工作的主要动机是为监督学习中的可解释性问题提供新的见解。', 'title_zh': '有效梯度流方程的推导及深度学习中训练数据的动力学截断'}
{'arxiv_id': 'arXiv:2501.07391', 'title': 'Enhancing Retrieval-Augmented Generation: A Study of Best Practices', 'authors': 'Siran Li, Linus Stenzel, Carsten Eickhoff, Seyed Ali Bahrainian', 'link': 'https://arxiv.org/abs/2501.07391', 'abstract': 'Retrieval-Augmented Generation (RAG) systems have recently shown remarkable advancements by integrating retrieval mechanisms into language models, enhancing their ability to produce more accurate and contextually relevant responses. However, the influence of various components and configurations within RAG systems remains underexplored. A comprehensive understanding of these elements is essential for tailoring RAG systems to complex retrieval tasks and ensuring optimal performance across diverse applications. In this paper, we develop several advanced RAG system designs that incorporate query expansion, various novel retrieval strategies, and a novel Contrastive In-Context Learning RAG. Our study systematically investigates key factors, including language model size, prompt design, document chunk size, knowledge base size, retrieval stride, query expansion techniques, Contrastive In-Context Learning knowledge bases, multilingual knowledge bases, and Focus Mode retrieving relevant context at sentence-level. Through extensive experimentation, we provide a detailed analysis of how these factors influence response quality. Our findings offer actionable insights for developing RAG systems, striking a balance between contextual richness and retrieval-generation efficiency, thereby paving the way for more adaptable and high-performing RAG frameworks in diverse real-world scenarios. Our code and implementation details are publicly available.', 'abstract_zh': '检索增强生成（RAG）系统近年来通过将检索机制整合到语言模型中，显著提升了生成更准确、更具上下文相关性的回复的能力。然而，RAG系统内部各组件和配置的影响仍然未被充分探索。对这些元素的全面理解是根据复杂的检索任务定制RAG系统并确保其在各种应用中表现最优的关键。在本文中，我们开发了几种先进的RAG系统设计，这些设计融入了查询扩展、多种新的检索策略以及一种新颖的对比式上下文学习RAG。我们的研究系统地探讨了关键因素，包括语言模型规模、提示设计、文档片段大小、知识库规模、检索步长、查询扩展技术、对比式上下文学习知识库、多语言知识库以及聚焦模式下在句子级别检索相关上下文。通过大量的实验，我们对这些因素如何影响回复质量进行了详尽的分析。我们的研究结果为开发RAG系统提供了可操作的见解，平衡上下文丰富性和检索生成效率，从而为各种实际场景中的更适应性和高性能RAG框架铺平了道路。我们的代码和实现细节公开可用。', 'title_zh': '增强检索增强生成：最佳实践研究'}
{'arxiv_id': 'arXiv:2501.07382', 'title': 'Information-Theoretic Dual Memory System for Continual Learning', 'authors': 'RunQing Wu, KaiHui Huang, HanYi Zhang, QiHe Liu, GuoJin Yu, JingSong Deng, Fei Ye', 'link': 'https://arxiv.org/abs/2501.07382', 'abstract': 'Continuously acquiring new knowledge from a dynamic environment is a fundamental capability for animals, facilitating their survival and ability to address various challenges. This capability is referred to as continual learning, which focuses on the ability to learn a sequence of tasks without the detriment of previous knowledge. A prevalent strategy to tackle continual learning involves selecting and storing numerous essential data samples from prior tasks within a fixed-size memory buffer. However, the majority of current memory-based techniques typically utilize a single memory buffer, which poses challenges in concurrently managing newly acquired and previously learned samples. Drawing inspiration from the Complementary Learning Systems (CLS) theory, which defines rapid and gradual learning mechanisms for processing information, we propose an innovative dual memory system called the Information-Theoretic Dual Memory System (ITDMS). This system comprises a fast memory buffer designed to retain temporary and novel samples, alongside a slow memory buffer dedicated to preserving critical and informative samples. The fast memory buffer is optimized employing an efficient reservoir sampling process. Furthermore, we introduce a novel information-theoretic memory optimization strategy that selectively identifies and retains diverse and informative data samples for the slow memory buffer. Additionally, we propose a novel balanced sample selection procedure that automatically identifies and eliminates redundant memorized samples, thus freeing up memory capacity for new data acquisitions, which can deal with a growing array of tasks. Our methodology is rigorously assessed through a series of continual learning experiments, with empirical results underscoring the effectiveness of the proposed system.', 'abstract_zh': '从动态环境中持续获取新知识是生物的基本能力，有助于其生存并应对各种挑战。这种能力被称为连续学习，专注于在不损害先前知识的情况下学习一系列任务的能力。目前处理连续学习的常用策略是选择并存储先前任务中的大量关键数据样本，以固定大小的记忆缓冲区为限。然而，大多数当前的记忆基技术通常使用单一的记忆缓冲区，这在同时管理新获取和先前学习的样本时带来了挑战。受到互补学习系统（CLS）理论的启发，该理论定义了快速和渐进的信息处理学习机制，我们提出了一种创新的双内存系统，称为信息论双内存系统（ITDMS）。该系统包括一个快速内存缓冲区，用于保留临时和新颖的样本，以及一个慢速内存缓冲区，专门用于保留关键和信息丰富的样本。快速内存缓冲区通过高效的蓄水池抽样过程进行优化。此外，我们引入了一种新型的信息论记忆优化策略，该策略能够选择和保留慢速内存缓冲区所需的各种和信息丰富的数据样本。同时，我们提出了一个新颖的平衡样本选择程序，能够自动识别并消除重复的已记忆样本，从而释放出内存空间以应对不断增长的任务范围。我们通过一系列连续学习实验严格评估了该方法，并且实验结果证明了所提出系统的有效性。', 'title_zh': '信息论双重记忆系统在连续学习中的应用'}
{'arxiv_id': 'arXiv:2501.07359', 'title': 'Emergent effects of scaling on the functional hierarchies within large language models', 'authors': 'Paul C. Bogdan', 'link': 'https://arxiv.org/abs/2501.07359', 'abstract': 'Large language model (LLM) architectures are often described as functionally hierarchical: Early layers process syntax, middle layers begin to parse semantics, and late layers integrate information. The present work revisits these ideas. This research submits simple texts to an LLM (e.g., "A church and organ") and extracts the resulting activations. Then, for each layer, support vector machines and ridge regressions are fit to predict a text\'s label and thus examine whether a given layer encodes some information. Analyses using a small model (Llama-3.2-3b; 28 layers) partly bolster the common hierarchical perspective: Item-level semantics are most strongly represented early (layers 2-7), then two-item relations (layers 8-12), and then four-item analogies (layers 10-15). Afterward, the representation of items and simple relations gradually decreases in deeper layers that focus on more global information. However, several findings run counter to a steady hierarchy view: First, although deep layers can represent document-wide abstractions, deep layers also compress information from early portions of the context window without meaningful abstraction. Second, when examining a larger model (Llama-3.3-70b-Instruct), stark fluctuations in abstraction level appear: As depth increases, two-item relations and four-item analogies initially increase in their representation, then markedly decrease, and afterward increase again momentarily. This peculiar pattern consistently emerges across several experiments. Third, another emergent effect of scaling is coordination between the attention mechanisms of adjacent layers. Across multiple experiments using the larger model, adjacent layers fluctuate between what information they each specialize in representing. In sum, an abstraction hierarchy often manifests across layers, but large models also deviate from this structure in curious ways.', 'abstract_zh': '大型语言模型（LLM）架构通常被描述为功能性的层级结构：早期层处理句法，中间层开始解析语义，而晚期层整合信息。本研究重新审视了这些观点。在此研究中，我们向LLM输入简单的文本（例如，“一座教堂和管风琴”），并提取其对应的激活状态。然后，对每一层，我们使用支持向量机和岭回归拟合模型，以预测文本的标签，从而考察某一特定层是否包含某种信息。使用小型模型（Llama-3.2-3b；28层）的分析部分支持了常见的层级观点：单一项目级别的语义在早期层（第2至第7层）中最为强烈地表示，随后是两个项目间的关系（第8至第12层），接着是四个项目之间的类比关系（第10至第15层）。之后，在关注更全局信息的深层层中，对项目和简单关系的表示逐渐减少。然而，有若干发现与稳定的层级观点不符：首先，虽然深层层可以表示整篇文档的抽象，但它们也会压缩来自上下文窗口早期部分的信息，而缺乏有意义的抽象。其次，在检查较大模型（Llama-3.3-70b-Instruct）时，抽象水平呈现剧烈波动：随着深度增加，两个项目间的关系和四个项目间的类比关系先是增加，随后显著减少，之后再次短暂增加。这种奇特的模式在多种实验中一致出现。第三，随着层级数量的增加，相邻层之间的注意机制之间出现了协调作用。在使用较大模型进行的多种实验中，相邻层在所擅长表示的信息上呈现出波动。总之，抽象层级在多层中经常表现为一种模式，但在某些方面，大型模型也以有趣的非典型方式偏离这种结构。', 'title_zh': '大型语言模型内部功能层级的缩放效应 emergent 表现'}
{'arxiv_id': 'arXiv:2501.07335', 'title': 'TempoGPT: Enhancing Temporal Reasoning via Quantizing Embedding', 'authors': 'Haochuan Zhang, Chunhua Yang, Jie Han, Liyang Qin, Xiaoli Wang', 'link': 'https://arxiv.org/abs/2501.07335', 'abstract': "Multi-modal language model has made advanced progress in vision and audio, but still faces significant challenges in dealing with complex reasoning tasks in the time series domain. The reasons are twofold. First, labels for multi-modal time series data are coarse and devoid of analysis or reasoning processes. Training with these data cannot improve the model's reasoning capabilities. Second, due to the lack of precise tokenization in processing time series, the representation patterns for temporal and textual information are inconsistent, which hampers the effectiveness of multi-modal alignment. To address these challenges, we propose a multi-modal time series data construction approach and a multi-modal time series language model (TLM), TempoGPT. Specially, we construct multi-modal data for complex reasoning tasks by analyzing the variable-system relationships within a white-box system. Additionally, proposed TempoGPT achieves consistent representation between temporal and textual information by quantizing temporal embeddings, where temporal embeddings are quantized into a series of discrete tokens using a predefined codebook; subsequently, a shared embedding layer processes both temporal and textual tokens. Extensive experiments demonstrate that TempoGPT accurately perceives temporal information, logically infers conclusions, and achieves state-of-the-art in the constructed complex time series reasoning tasks. Moreover, we quantitatively demonstrate the effectiveness of quantizing temporal embeddings in enhancing multi-modal alignment and the reasoning capabilities of TLMs. Code and data are available at this https URL.", 'abstract_zh': '多模态语言模型在视觉和音频领域取得了显著的进展，但在时间序列的复杂推理任务中仍面临着重大挑战。原因主要有两个方面。首先，多模态时间序列数据的标签较为粗糙，缺乏分析或推理过程，使用这些数据训练模型无法提高其推理能力。其次，由于时间序列处理中缺乏精确的分词方法，时间和文本信息的表示模式不一致，这阻碍了多模态对齐的有效性。为解决这些挑战，我们提出了一种多模态时间序列数据构建方法和多模态时间序列语言模型（TLM），即TempoGPT。具体而言，通过分析白盒系统内部变量系统的相互关系，我们构建了适用于复杂推理任务的多模态数据。此外，我们提出了TempoGPT，通过量化时间嵌入来实现时间和文本信息的表示一致性，其中时间嵌入被量化为一系列预定义代码簿中的离散令牌；随后，共享嵌入层处理时间和文本令牌。广泛的实验表明，TempoGPT 能准确感知时间信息、逻辑推理并取得在构建的复杂时间序列推理任务中的最佳性能。此外，我们定量展示了量化时间嵌入在提高多模态对齐效果和提升TLMs推理能力方面的有效性。代码和数据可在以下链接获取：[提供链接的网址]。', 'title_zh': 'TempoGPT：通过量化嵌入增强时间推理'}
{'arxiv_id': 'arXiv:2501.07317', 'title': 'Evaluation of Artificial Intelligence Methods for Lead Time Prediction in Non-Cycled Areas of Automotive Production', 'authors': 'Cornelius Hake, Jonas Weigele, Frederik Reichert, Christian Friedrich', 'link': 'https://arxiv.org/abs/2501.07317', 'abstract': 'The present study examines the effectiveness of applying Artificial Intelligence methods in an automotive production environment to predict unknown lead times in a non-cycle-controlled production area. Data structures are analyzed to identify contextual features and then preprocessed using one-hot encoding. Methods selection focuses on supervised machine learning techniques. In supervised learning methods, regression and classification methods are evaluated. Continuous regression based on target size distribution is not feasible. Classification methods analysis shows that Ensemble Learning and Support Vector Machines are the most suitable. Preliminary study results indicate that gradient boosting algorithms LightGBM, XGBoost, and CatBoost yield the best results. After further testing and extensive hyperparameter optimization, the final method choice is the LightGBM algorithm. Depending on feature availability and prediction interval granularity, relative prediction accuracies of up to 90% can be achieved. Further tests highlight the importance of periodic retraining of AI models to accurately represent complex production processes using the database. The research demonstrates that AI methods can be effectively applied to highly variable production data, adding business value by providing an additional metric for various control tasks while outperforming current non AI-based systems.', 'abstract_zh': '本研究考察了在汽车生产环境中应用人工智能方法预测非循环控制生产区的未知前置时间的有效性。分析数据结构以识别上下文特征，然后使用独热编码进行预处理。方法选择集中在监督机器学习技术上。在监督学习方法中，对回归和分类方法进行了评估。基于目标大小分布的连续回归不切实际。分类方法分析表明，集成学习和支持向量机是最适合的方法。初步研究结果显示，梯度提升算法（LightGBM、XGBoost 和 CatBoost）产生了最佳结果。经过进一步测试和广泛的超参数优化后，最终选定的方法是 LightGBM 算法。根据特征可用性和预测区间粒度，可以实现高达90%的相对预测准确性。进一步测试还强调了定期重新训练AI模型的重要性，以便使用数据库准确地表示复杂生产过程。研究表明，可以在高度可变的生产数据中有效地应用AI方法，通过提供各种控制任务的额外指标来增加业务价值，从而优于当前非基于AI的系统。', 'title_zh': '非循环生产区汽车生产中人工智能方法的到货时间预测评估'}
{'arxiv_id': 'arXiv:2501.07301', 'title': 'The Lessons of Developing Process Reward Models in Mathematical Reasoning', 'authors': 'Zhenru Zhang, Chujie Zheng, Yangzhen Wu, Beichen Zhang, Runji Lin, Bowen Yu, Dayiheng Liu, Jingren Zhou, Junyang Lin', 'link': 'https://arxiv.org/abs/2501.07301', 'abstract': 'Process Reward Models (PRMs) emerge as a promising approach for process supervision in mathematical reasoning of Large Language Models (LLMs), which aim to identify and mitigate intermediate errors in the reasoning processes. However, the development of effective PRMs faces significant challenges, particularly in data annotation and evaluation methodologies. In this paper, through extensive experiments, we demonstrate that commonly used Monte Carlo (MC) estimation-based data synthesis for PRMs typically yields inferior performance and generalization compared to LLM-as-a-judge and human annotation methods. MC estimation relies on completion models to evaluate current-step correctness, leading to inaccurate step verification. Furthermore, we identify potential biases in conventional Best-of-N (BoN) evaluation strategies for PRMs: (1) The unreliable policy models generate responses with correct answers but flawed processes, leading to a misalignment between the evaluation criteria of BoN and the PRM objectives of process verification. (2) The tolerance of PRMs of such responses leads to inflated BoN scores. (3) Existing PRMs have a significant proportion of minimum scores concentrated on the final answer steps, revealing the shift from process to outcome-based assessment in BoN Optimized PRMs. To address these challenges, we develop a consensus filtering mechanism that effectively integrates MC estimation with LLM-as-a-judge and advocates a more comprehensive evaluation framework that combines response-level and step-level metrics. Based on the mechanisms, we significantly improve both model performance and data efficiency in the BoN evaluation and the step-wise error identification task. Finally, we release a new state-of-the-art PRM that outperforms existing open-source alternatives and provides practical guidelines for future research in building process supervision models.', 'abstract_zh': '过程奖励模型（PRMs）作为一种有前途的方法，正在数学推理中推动大型语言模型（LLMs）的过程监督，旨在识别和缓解推理过程中的中间错误。然而，有效开发PRMs面临着显著挑战，尤其是在数据注释和评估方法方面。本文通过大量实验表明，通常用于PRMs的数据合成方法——基于蒙特卡洛（MC）估计的方法，其性能和泛化能力通常劣于LLM作为法官和人工注释方法。MC估计依赖于完成模型来评估当前步骤的正确性，导致步骤验证不准确。此外，我们还确定了传统Best-of-N（BoN）评估策略中PRMs潜在的偏差：（1）不可靠的策略模型生成正确答案但过程有误的响应，导致BoN的评估标准与PRM的目标过程验证之间出现偏差。（2）PRMs对这种响应的宽容度导致BoN得分被夸大。（3）现有的PRMs中有相当大的比例最低分集中在最终答案步骤上，揭示了BoN优化的PRMs从关注过程转向关注结果的评估。为了应对这些挑战，我们开发了一种共识筛选机制，有效地将MC估计与LLM作为法官相结合，并倡导一种更为全面的评估框架，结合响应级别和步骤级别的指标。基于这些机制，我们在BoN评估和逐步骤错误识别任务中显著提高了模型性能和数据效率。最后，我们发布了一个新的最先进的PRM，该PRM优于现有的开源替代品，并提供了未来研究中构建过程监督模型的实用指南。', 'title_zh': '在数学推理中开发过程奖励模型的启示'}
{'arxiv_id': 'arXiv:2501.07260', 'title': 'Skip Mamba Diffusion for Monocular 3D Semantic Scene Completion', 'authors': 'Li Liang, Naveed Akhtar, Jordan Vice, Xiangrui Kong, Ajmal Saeed Mian', 'link': 'https://arxiv.org/abs/2501.07260', 'abstract': '3D semantic scene completion is critical for multiple downstream tasks in autonomous systems. It estimates missing geometric and semantic information in the acquired scene data. Due to the challenging real-world conditions, this task usually demands complex models that process multi-modal data to achieve acceptable performance. We propose a unique neural model, leveraging advances from the state space and diffusion generative modeling to achieve remarkable 3D semantic scene completion performance with monocular image input. Our technique processes the data in the conditioned latent space of a variational autoencoder where diffusion modeling is carried out with an innovative state space technique. A key component of our neural network is the proposed Skimba (Skip Mamba) denoiser, which is adept at efficiently processing long-sequence data. The Skimba diffusion model is integral to our 3D scene completion network, incorporating a triple Mamba structure, dimensional decomposition residuals and varying dilations along three directions. We also adopt a variant of this network for the subsequent semantic segmentation stage of our method. Extensive evaluation on the standard SemanticKITTI and SSCBench-KITTI360 datasets show that our approach not only outperforms other monocular techniques by a large margin, it also achieves competitive performance against stereo methods. The code is available at this https URL', 'abstract_zh': '三维语义场景补全对于自主系统中的多个下游任务至关重要。它能够估算所获取场景数据中缺失的几何和语义信息。由于现实世界条件的复杂性，这一任务通常需要处理多模态数据的复杂模型才能实现可接受的性能。我们提出了一种独特的神经模型，该模型结合了状态空间和扩散生成模型的进步，通过单目图像输入实现了出色的三维语义场景补全性能。我们的技术在变分自编码器的条件潜在空间中处理数据，并且使用创新的状态空间技术进行扩散建模。我们神经网络的一个关键组件是所提出的Skimba（跳过Mamba）去噪器，它擅长高效处理长序列数据。Skimba扩散模型是我们的三维场景补全网络的核心组成部分，包含三倍Mamba结构、维度分解残差以及沿三个方向变化的膨胀率。此外，我们还为此方法的后续语义分割阶段采用该网络的一个变体。在标准SemanticKITTI和SSCBench-KITTI360数据集上的广泛评估表明，我们的方法不仅在单目技术中表现优异，而且在立体方法中也达到了具有竞争力的性能。代码可参见这个链接：[代码链接]', 'title_zh': '单目3D语义场景完成的跳过姆班分布扩散方法'}
{'arxiv_id': 'arXiv:2501.07251', 'title': 'MOS-Attack: A Scalable Multi-objective Adversarial Attack Framework', 'authors': 'Ping Guo, Cheng Gong, Xi Lin, Fei Liu, Zhichao Lu, Qingfu Zhang, Zhenkun Wang', 'link': 'https://arxiv.org/abs/2501.07251', 'abstract': 'Crafting adversarial examples is crucial for evaluating and enhancing the robustness of Deep Neural Networks (DNNs), presenting a challenge equivalent to maximizing a non-differentiable 0-1 loss function.\nHowever, existing single objective methods, namely adversarial attacks focus on a surrogate loss function, do not fully harness the benefits of engaging multiple loss functions, as a result of insufficient understanding of their synergistic and conflicting nature.\nTo overcome these limitations, we propose the Multi-Objective Set-based Attack (MOS Attack), a novel adversarial attack framework leveraging multiple loss functions and automatically uncovering their interrelations.\nThe MOS Attack adopts a set-based multi-objective optimization strategy, enabling the incorporation of numerous loss functions without additional parameters.\nIt also automatically mines synergistic patterns among various losses, facilitating the generation of potent adversarial attacks with fewer objectives.\nExtensive experiments have shown that our MOS Attack outperforms single-objective attacks. Furthermore, by harnessing the identified synergistic patterns, MOS Attack continues to show superior results with a reduced number of loss functions.', 'abstract_zh': '生成对抗样本对于评估和提升深度神经网络（DNNs）的鲁棒性至关重要，相当于最大化非可微的0-1损失函数。然而，现有的单一目标方法，即对抗攻击，专注于替代损失函数，没有充分利用多种损失函数的协同与冲突作用，这主要是由于对其相互关系的理解不足。\n\n为克服这些限制，我们提出了一种新颖的利用多种损失函数的多目标集合式攻击（MOS Attack）框架，该框架能够自动揭示不同损失之间的关系。MOS Attack采用基于集合的多目标优化策略，能够在不增加额外参数的情况下整合多种损失函数。同时，它能够自动挖掘不同损失之间的协同模式，从而在较少的目标下生成更为有效的对抗样本。\n\n通过广泛的实验证明，MOS Attack优于单一目标攻击。此外，通过利用识别出的协同模式，MOS Attack在减少损失函数数量的情况下仍能保持更好的性能。', 'title_zh': 'MOS-攻击：一种可扩展的多目标对抗攻击框架'}
{'arxiv_id': 'arXiv:2501.07237', 'title': 'Breaking Memory Limits: Gradient Wavelet Transform Enhances LLMs Training', 'authors': 'Ziqing Wen, Ping Luo, Jiahuan Wang, Xiaoge Deng, Jinping Zou, Kun Yuan, Tao Sun, Dongsheng Li', 'link': 'https://arxiv.org/abs/2501.07237', 'abstract': 'Large language models (LLMs) have shown impressive performance across a range of natural language processing tasks. However, their vast number of parameters introduces significant memory challenges during training, particularly when using memory-intensive optimizers like Adam. Existing memory-efficient algorithms often rely on techniques such as singular value decomposition projection or weight freezing. While these approaches help alleviate memory constraints, they generally produce suboptimal results compared to full-rank updates. In this paper, we investigate the memory-efficient method beyond low-rank training, proposing a novel solution called Gradient Wavelet Transform (GWT), which applies wavelet transforms to gradients in order to significantly reduce the memory requirements for maintaining optimizer states. We demonstrate that GWT can be seamlessly integrated with memory-intensive optimizers, enabling efficient training without sacrificing performance. Through extensive experiments on both pre-training and fine-tuning tasks, we show that GWT achieves state-of-the-art performance compared with advanced memory-efficient optimizers and full-rank approaches in terms of both memory usage and training performance.', 'abstract_zh': '大型语言模型（LLMs）在一系列自然语言处理任务中展示了令人印象深刻的性能。然而，其庞大的参数数量在训练过程中引入了显著的内存挑战，特别是在使用Adam等内存密集型优化器时更为明显。现有的内存高效算法通常依赖于诸如奇异值分解投影或权重冻结等技术。尽管这些方法有助于缓解内存限制，但与全秩更新相比，它们通常会导致次优结果。在本文中，我们探讨了超越低秩训练的内存高效方法，并提出了一种名为梯度小波变换（GWT）的新型解决方案，该方法通过在梯度上应用小波变换来显著降低维护优化器状态所需的内存需求。我们证明，GWT 可以无缝地与内存密集型优化器结合使用，从而在不牺牲性能的情况下实现高效的训练。通过在预训练和微调任务上的广泛实验，我们展示了GWT在内存使用和训练性能方面均优于先进内存高效优化器和全秩方法。', 'title_zh': '打破内存限制：梯度小波变换增强大规模语言模型的训练'}
{'arxiv_id': 'arXiv:2501.07221', 'title': 'Exploring the Use of Contrastive Language-Image Pre-Training for Human Posture Classification: Insights from Yoga Pose Analysis', 'authors': 'Andrzej D. Dobrzycki, Ana M. Bernardos, Luca Bergesio, Andrzej Pomirski, Daniel Sáez-Trigueros', 'link': 'https://arxiv.org/abs/2501.07221', 'abstract': 'Accurate human posture classification in images and videos is crucial for automated applications across various fields, including work safety, physical rehabilitation, sports training, or daily assisted living. Recently, multimodal learning methods, such as Contrastive Language-Image Pretraining (CLIP), have advanced significantly in jointly understanding images and text. This study aims to assess the effectiveness of CLIP in classifying human postures, focusing on its application in yoga. Despite the initial limitations of the zero-shot approach, applying transfer learning on 15,301 images (real and synthetic) with 82 classes has shown promising results. The article describes the full procedure for fine-tuning, including the choice for image description syntax, models and hyperparameters adjustment. The fine-tuned CLIP model, tested on 3826 images, achieves an accuracy of over 85%, surpassing the current state-of-the-art of previous works on the same dataset by approximately 6%, its training time being 3.5 times lower than what is needed to fine-tune a YOLOv8-based model. For more application-oriented scenarios, with smaller datasets of six postures each, containing 1301 and 401 training images, the fine-tuned models attain an accuracy of 98.8% and 99.1%, respectively. Furthermore, our experiments indicate that training with as few as 20 images per pose can yield around 90% accuracy in a six-class dataset. This study demonstrates that this multimodal technique can be effectively used for yoga pose classification, and possibly for human posture classification, in general. Additionally, CLIP inference time (around 7 ms) supports that the model can be integrated into automated systems for posture evaluation, e.g., for developing a real-time personal yoga assistant for performance assessment.', 'abstract_zh': '图像和视频中人类姿态的准确分类对于工作安全、物理康复、体育训练或日常辅助生活等领域中的自动化应用至关重要。最近，多模态学习方法，如对比语言-图像预训练（CLIP），在联合理解和图像与文本方面取得了显著的进步。本研究旨在评估CLIP在分类人类姿态方面的有效性，重点是其在瑜伽中的应用。尽管最初零样本方法存在一些限制，但在15,301张图像（真实和合成）和82个类别的基础上进行的迁移学习显示出了令人鼓舞的结果。文章详细描述了微调的整个过程，包括选择图像描述语法、模型和超参数调整的方法。经过微调的CLIP模型在3826张图像上的准确率达到85%以上，相比之前在同一数据集上的工作，提高了约6%，其训练时间仅为基于YOLOv8模型微调所需时间的3.5倍。对于更具体的应用场景，使用包含1301张和401张训练图像的每种姿态6种姿态的小数据集，微调后的模型分别达到了98.8%和99.1%的准确率。此外，我们的实验表明，每个姿态仅使用20张图像进行训练，即可在六类数据集中达到约90%的准确率。本研究证明，这种方法可以有效地用于瑜伽姿态分类，并且有可能适用于人类姿态分类中的其他应用。此外，CLIP的推理时间（约7毫秒）表明该模型可以集成到姿态评估的自动化系统中，例如开发一个实时的个人瑜伽助手进行表现评估。', 'title_zh': '探索对比语言-图像预训练在人体姿态分类中的应用：以瑜伽姿势分析为例的见解'}
{'arxiv_id': 'arXiv:2501.07213', 'title': 'Multi-face emotion detection for effective Human-Robot Interaction', 'authors': 'Mohamed Ala Yahyaoui, Mouaad Oujabour, Leila Ben Letaifa, Amine Bohi', 'link': 'https://arxiv.org/abs/2501.07213', 'abstract': 'The integration of dialogue interfaces in mobile devices has become ubiquitous, providing a wide array of services. As technology progresses, humanoid robots designed with human-like features to interact effectively with people are gaining prominence, and the use of advanced human-robot dialogue interfaces is continually expanding. In this context, emotion recognition plays a crucial role in enhancing human-robot interaction by enabling robots to understand human intentions. This research proposes a facial emotion detection interface integrated into a mobile humanoid robot, capable of displaying real-time emotions from multiple individuals on a user interface. To this end, various deep neural network models for facial expression recognition were developed and evaluated under consistent computer-based conditions, yielding promising results. Afterwards, a trade-off between accuracy and memory footprint was carefully considered to effectively implement this application on a mobile humanoid robot.', 'abstract_zh': '移动设备中对话界面的集成已变得无处不在，提供了广泛的服务。随着技术的进步，具有人类特征的类人机器人设计以有效与人交互正在获得越来越多的关注，且高级的人机对话界面的应用不断扩展。在此背景下，情绪识别在增强人机交互方面扮演着重要作用，因为它使机器人能够理解人类的意图。本研究提出了一种集成于移动类人机器人中的面部情绪检测界面，能够在用户界面上实时显示多个个体的情绪。为此，开发并评估了多种基于深层神经网络的表情识别模型，结果相当有前景。随后，仔细考虑了准确性和内存占用之间的权衡，以有效地在移动类人机器人上实施此应用。', 'title_zh': '有效的人机交互中的多面部情感检测'}
{'arxiv_id': 'arXiv:2501.07196', 'title': 'Crowdsourced human-based computational approach for tagging peripheral blood smear sample images from Sickle Cell Disease patients using non-expert users', 'authors': 'José María Buades Rubio, Gabriel Moyà-Alcover, Antoni Jaume-i-Capó, Nataša Petrović', 'link': 'https://arxiv.org/abs/2501.07196', 'abstract': 'In this paper, we present a human-based computation approach for the analysis of peripheral blood smear (PBS) images images in patients with Sickle Cell Disease (SCD). We used the Mechanical Turk microtask market to crowdsource the labeling of PBS images. We then use the expert-tagged erythrocytesIDB dataset to assess the accuracy and reliability of our proposal. Our results showed that when a robust consensus is achieved among the Mechanical Turk workers, probability of error is very low, based on comparison with expert analysis. This suggests that our proposed approach can be used to annotate datasets of PBS images, which can then be used to train automated methods for the diagnosis of SCD. In future work, we plan to explore the potential integration of our findings with outcomes obtained through automated methodologies. This could lead to the development of more accurate and reliable methods for the diagnosis of SCD', 'abstract_zh': '在本文中，我们提出了一种基于人类计算的方法，用于镰状细胞病（SCD）患者外周血涂片（PBS）图像的分析。我们利用亚马逊 Mechanical Turk 微任务市场进行了 PBS 图像的众包标注。随后，我们使用专家标注的 ErythrocytesIDB 数据集来评估我们方法的准确性和可靠性。研究结果表明，当 Mechanical Turk 工作者之间达成稳健的共识时，错误概率极低，这证明了我们的方法可以用于标注 PBS 图像数据集，进而训练自动化方法以诊断 SCD。在未来的工作中，我们计划探索将我们的发现与通过自动化方法获得的结果进行整合的潜力，这可能有助于开发更准确和可靠的 SCD 诊断方法。', 'title_zh': '利用非专家用户进行镰状细胞病患者外周血涂片样本图像标注的众包人类计算方法'}
{'arxiv_id': 'arXiv:2501.07186', 'title': 'Generalizable Graph Neural Networks for Robust Power Grid Topology Control', 'authors': 'Matthijs de Jong, Jan Viebahn, Yuliya Shapovalova', 'link': 'https://arxiv.org/abs/2501.07186', 'abstract': 'The energy transition necessitates new congestion management methods. One such method is controlling the grid topology with machine learning (ML). This approach has gained popularity following the Learning to Run a Power Network (L2RPN) competitions. Graph neural networks (GNNs) are a class of ML models that reflect graph structure in their computation, which makes them suitable for power grid modeling. Various GNN approaches for topology control have thus been proposed. We propose the first GNN model for grid topology control that uses only GNN layers. Additionally, we identify the busbar information asymmetry problem that the popular homogeneous graph representation suffers from, and propose a heterogeneous graph representation to resolve it. We train both homogeneous and heterogeneous GNNs and fully connected neural networks (FCNN) baselines on an imitation learning task. We evaluate the models according to their classification accuracy and grid operation ability. We find that the heterogeneous GNNs perform best on in-distribution networks, followed by the FCNNs, and lastly, the homogeneous GNNs. We also find that both GNN types generalize better to out-of-distribution networks than FCNNs.', 'abstract_zh': '能源转型需要新的拥堵管理方法。其中一种方法是利用机器学习（ML）控制电网拓扑结构。这一方法在经历了“运行电力网络的学习”（L2RPN）竞赛后逐渐受到关注。图神经网络（GNNs）是一类反映图结构的ML模型，这使得它们非常适合用于电力电网建模。因此，各种用于拓扑控制的GNN方法应运而生。我们提出了一种仅使用GNN层进行电网拓扑控制的首个GNN模型。此外，我们还识别了流行的整体图表示方法中存在的储能母线信息不对称问题，并提出了一种异构图表示方法来解决这一问题。我们在模仿学习任务中对整体图表示和异构图表示的GNN以及全连接神经网络（FCNN）基线进行了训练，并根据分类准确率和电网操作能力对模型进行了评估。我们发现，在分布内网络中，异构GNN表现最佳，其次是FCNN，最后是整体GNN。此外，我们还发现，两种GNN类型比FCNN更好地泛化到分布外网络中。', 'title_zh': '泛化图神经网络在电力电网拓扑控制中的稳健应用'}
{'arxiv_id': 'arXiv:2501.07178', 'title': 'The Spoils of Algorithmic Collusion: Profit Allocation Among Asymmetric Firms', 'authors': 'Simon Martin, Hans-Theo Normann, Paul Püplichhuisen, Tobias Werner', 'link': 'https://arxiv.org/abs/2501.07178', 'abstract': 'We study the propensity of independent algorithms to collude in repeated Cournot duopoly games. Specifically, we investigate the predictive power of different oligopoly and bargaining solutions regarding the effect of asymmetry between firms. We find that both consumers and firms can benefit from asymmetry. Algorithms produce more competitive outcomes when firms are symmetric, but less when they are very asymmetric. Although the static Nash equilibrium underestimates the effect on total quantity and overestimates the effect on profits, it delivers surprisingly accurate predictions in terms of total welfare. The best description of our results is provided by the equal relative gains solution. In particular, we find algorithms to agree on profits that are on or close to the Pareto frontier for all degrees of asymmetry. Our results suggest that the common belief that symmetric industries are more prone to collusion may no longer hold when algorithms increasingly drive managerial decisions.', 'abstract_zh': '我们研究独立算法在重复斯塔克尔伯格双头博弈中结盟的可能性。具体而言，我们探讨了不同寡头和讨价还价解决方案的预测能力，特别是在企业之间存在不对称性时的影响。我们发现，无论是消费者还是企业，都可以从不对称性中获益。当企业对称时，算法会产出更具有竞争力的结果，而当企业非常不对称时，则会产出较少的竞争力结果。尽管静态纳什均衡低估了总产量的影响并高估了收益的影响，但它在总体福利方面却出乎意料地提供了准确的预测。我们的结果可以用相等相对收益解来最好地描述。特别地，我们发现算法在所有程度的不对称情况下，同意的收益都在或接近帕累托前沿。我们的研究结果表明，在算法越来越多地驱动管理决策的情况下，对称行业更容易结盟的普遍信念可能不再适用。', 'title_zh': '算法共谋的所得：不对称 firms 之间的利润分配'}
{'arxiv_id': 'arXiv:2501.07172', 'title': 'Anomalous Agreement: How to find the Ideal Number of Anomaly Classes in Correlated, Multivariate Time Series Data', 'authors': 'Ferdinand Rewicki, Joachim Denzler, Julia Niebling', 'link': 'https://arxiv.org/abs/2501.07172', 'abstract': 'Detecting and classifying abnormal system states is critical for condition monitoring, but supervised methods often fall short due to the rarity of anomalies and the lack of labeled data. Therefore, clustering is often used to group similar abnormal behavior. However, evaluating cluster quality without ground truth is challenging, as existing measures such as the Silhouette Score (SSC) only evaluate the cohesion and separation of clusters and ignore possible prior knowledge about the data. To address this challenge, we introduce the Synchronized Anomaly Agreement Index (SAAI), which exploits the synchronicity of anomalies across multivariate time series to assess cluster quality. We demonstrate the effectiveness of SAAI by showing that maximizing SAAI improves accuracy on the task of finding the true number of anomaly classes K in correlated time series by 0.23 compared to SSC and by 0.32 compared to X-Means. We also show that clusters obtained by maximizing SAAI are easier to interpret compared to SSC.', 'abstract_zh': '检测和分类异常系统状态对于状态监测至关重要，但监督方法往往因异常数据稀少和缺乏标记数据而性能不佳。因此，聚类方法常被用来将相似的异常行为分组。然而，在没有真实标签的情况下评估聚类质量是一项挑战，现有的指标如轮廓系数（Silhouette Score，SSC）仅评估簇的凝聚性和分离性，而忽略了可能存在的数据先验知识。为解决这一挑战，我们提出了同步异常一致性指数（SAAI，Synchronized Anomaly Agreement Index），该方法通过利用多变量时间序列中异常的一致性来评估聚类质量。通过实验表明，最大化SAAI在相关时间序列中找到真实的异常类数量（K值）的准确性上比SSC高出0.23，比X-Means高出0.32。此外，我们还展示了通过最大化SAAI获得的聚类比SSC更容易解释。', 'title_zh': '异常一致现象：如何在相关多变量时间序列数据中确定理想的异常类数量'}
{'arxiv_id': 'arXiv:2501.07158', 'title': 'Eye Sclera for Fair Face Image Quality Assessment', 'authors': 'Wassim Kabbani, Kiran Raja, Raghavendra Ramachandra, Christoph Busch', 'link': 'https://arxiv.org/abs/2501.07158', 'abstract': "Fair operational systems are crucial in gaining and maintaining society's trust in face recognition systems (FRS). FRS start with capturing an image and assessing its quality before using it further for enrollment or verification. Fair Face Image Quality Assessment (FIQA) schemes therefore become equally important in the context of fair FRS. This work examines the sclera as a quality assessment region for obtaining a fair FIQA. The sclera region is agnostic to demographic variations and skin colour for assessing the quality of a face image. We analyze three skin tone related ISO/IEC face image quality assessment measures and assess the sclera region as an alternative area for assessing FIQ. Our analysis of the face dataset of individuals from different demographic groups representing different skin tones indicates sclera as an alternative to measure dynamic range, over- and under-exposure of face using sclera region alone. The sclera region being agnostic to skin tone, i.e., demographic factors, provides equal utility as a fair FIQA as shown by our Error-vs-Discard Characteristic (EDC) curve analysis.", 'abstract_zh': '在面部识别系统（FRS）中获得和维持社会的公平信任，公正的运营系统至关重要。FRS 的工作始于捕捉图像并评估其质量，之后才用于注册或验证。因此，公平的面部图像质量评估（FIQA）方案在公正的FRS 的背景下变得同样重要。本研究探讨了使用巩膜作为质量评估区域，以获得公平的FIQA。巩膜区域对肤色和人口统计学差异具有无偏性，可用于评估面部图像的质量。我们分析了三个与肤色相关的国际标准组织/国际电工委员会（ISO/IEC）面部图像质量评估指标，并评估巩膜区域作为评估FIQ 的替代区域。通过分析来自不同人口统计学群体的面部图像数据集，其中包含不同的肤色，我们表明，仅使用巩膜区域即可作为衡量动态范围、面部过曝和欠曝的替代方法。巩膜区域对肤色无偏性，即不涉及人口统计学因素，我们的错误率-废弃率特性曲线（EDC）分析结果证明了其作为公平FIQA 的等效效用。', 'title_zh': '眼球巩膜用于公平面部图像质量评估'}
{'arxiv_id': 'arXiv:2501.07146', 'title': 'TIMRL: A Novel Meta-Reinforcement Learning Framework for Non-Stationary and Multi-Task Environments', 'authors': 'Chenyang Qi, Huiping Li, Panfeng Huang', 'link': 'https://arxiv.org/abs/2501.07146', 'abstract': 'In recent years, meta-reinforcement learning (meta-RL) algorithm has been proposed to improve sample efficiency in the field of decision-making and control, enabling agents to learn new knowledge from a small number of samples. However, most research uses the Gaussian distribution to extract task representation, which is poorly adapted to tasks that change in non-stationary environment. To address this problem, we propose a novel meta-reinforcement learning method by leveraging Gaussian mixture model and the transformer network to construct task inference model. The Gaussian mixture model is utilized to extend the task representation and conduct explicit encoding of tasks. Specifically, the classification of tasks is encoded through transformer network to determine the Gaussian component corresponding to the task. By leveraging task labels, the transformer network is trained using supervised learning. We validate our method on MuJoCo benchmarks with non-stationary and multi-task environments. Experimental results demonstrate that the proposed method dramatically improves sample efficiency and accurately recognizes the classification of the tasks, while performing excellently in the environment.', 'abstract_zh': '近年来，元强化学习（Meta-Reinforcement Learning，简称meta-RL）算法被提出，旨在提高决策与控制领域的样本效率，使代理能够在少量样本下学习新知识。然而，大多数研究使用高斯分布来提取任务表示，这在非平稳环境中变化的任务适应性较差。为解决这一问题，我们提出了一种新颖的元强化学习方法，通过结合高斯混合模型和变压器网络构建任务推理模型。高斯混合模型用于扩展任务表示，并进行任务的显式编码。具体而言，通过变压器网络对任务进行分类编码，以确定与任务对应的高斯分量。利用任务标签，变压器网络使用监督学习进行训练。我们使用MuJoCo基准中的非平稳和多任务环境验证了该方法。实验结果表明，所提出的方法在显著提高样本效率的同时，准确地识别了任务的分类，并在环境中表现出色。', 'title_zh': 'TIMRL：一种用于非平稳多任务环境的新颖元强化学习框架'}
{'arxiv_id': 'arXiv:2501.07102', 'title': 'AdaCS: Adaptive Normalization for Enhanced Code-Switching ASR', 'authors': 'Chuong Chu, Vu Tuan Dat Pham, Kien Dao, Hoang Nguyen, Quoc Hung Truong', 'link': 'https://arxiv.org/abs/2501.07102', 'abstract': 'Intra-sentential code-switching (CS) refers to the alternation between languages that happens within a single utterance and is a significant challenge for Automatic Speech Recognition (ASR) systems. For example, when a Vietnamese speaker uses foreign proper names or specialized terms within their speech. ASR systems often struggle to accurately transcribe intra-sentential CS due to their training on monolingual data and the unpredictable nature of CS. This issue is even more pronounced for low-resource languages, where limited data availability hinders the development of robust models. In this study, we propose AdaCS, a normalization model integrates an adaptive bias attention module (BAM) into encoder-decoder network. This novel approach provides a robust solution to CS ASR in unseen domains, thereby significantly enhancing our contribution to the field. By utilizing BAM to both identify and normalize CS phrases, AdaCS enhances its adaptive capabilities with a biased list of words provided during inference. Our method demonstrates impressive performance and the ability to handle unseen CS phrases across various domains. Experiments show that AdaCS outperforms previous state-of-the-art method on Vietnamese CS ASR normalization by considerable WER reduction of 56.2% and 36.8% on the two proposed test sets.', 'abstract_zh': '句内代码转换（Intra-sentential Code-Switching, CS）指的是在同一句话内部交替使用不同语言的现象，这是自动语音识别（Automatic Speech Recognition, ASR）系统的重大挑战。例如，当越南语 speaker 使用外来人名或专业术语时，ASR 系统往往难以准确地转录这些句内代码转换。原因是这些系统通常是用单一语言的数据进行训练，而代码转换的不可预测性使得问题尤为复杂。对于低资源语言来说，这个问题更为显著，数据的限制阻碍了稳健模型的发展。本文提出了一种名为 AdaCS 的规范化模型，该模型将自适应偏差注意模块（Adaptive Bias Attention Module, BAM）集成到编码器-解码器网络中。这一创新方法为未知领域中的代码转换语音识别提供了一个稳健的解决方案，从而显著增强了我们对该领域的贡献。通过利用 BAM 识别并规范化代码转换短语，AdaCS 在推理过程中利用一个偏置单词列表来增强其自适应能力。我们的方法在处理各种领域中的未知代码转换短语方面表现出色。实验表明，AdaCS 在越南语代码转换 ASR 规范化中比以前的最佳方法取得了显著改进，两个测试集的词错误率分别降低了 56.2% 和 36.8%。', 'title_zh': 'AdaCS：增强代码转换ASR的自适应归一化'}
{'arxiv_id': 'arXiv:2501.07100', 'title': 'Collaborative Learning for 3D Hand-Object Reconstruction and Compositional Action Recognition from Egocentric RGB Videos Using Superquadrics', 'authors': 'Tze Ho Elden Tse, Runyang Feng, Linfang Zheng, Jiho Park, Yixing Gao, Jihie Kim, Ales Leonardis, Hyung Jin Chang', 'link': 'https://arxiv.org/abs/2501.07100', 'abstract': 'With the availability of egocentric 3D hand-object interaction datasets, there is increasing interest in developing unified models for hand-object pose estimation and action recognition. However, existing methods still struggle to recognise seen actions on unseen objects due to the limitations in representing object shape and movement using 3D bounding boxes. Additionally, the reliance on object templates at test time limits their generalisability to unseen objects. To address these challenges, we propose to leverage superquadrics as an alternative 3D object representation to bounding boxes and demonstrate their effectiveness on both template-free object reconstruction and action recognition tasks. Moreover, as we find that pure appearance-based methods can outperform the unified methods, the potential benefits from 3D geometric information remain unclear. Therefore, we study the compositionality of actions by considering a more challenging task where the training combinations of verbs and nouns do not overlap with the testing split. We extend H2O and FPHA datasets with compositional splits and design a novel collaborative learning framework that can explicitly reason about the geometric relations between hands and the manipulated object. Through extensive quantitative and qualitative evaluations, we demonstrate significant improvements over the state-of-the-arts in (compositional) action recognition.', 'abstract_zh': '随着第一人称3D手物交互数据集的可用性增加，人们越来越关注开发统一模型来估计手物姿态和识别动作。然而，现有的方法仍然难以在未见过的对象上识别已见过的动作，这是因为使用3D边界盒表示物体形状和运动的能力有限。此外，测试时依赖物体模板限制了这些方法对未见过的对象的通用性。为了解决这些挑战，我们提议利用超_quadrics作为替代的3D物体表示方法，而不是使用边界框，并在无模板物体重构和动作识别任务中展示了其有效性。此外，我们发现基于纯外观的方法在某些情况下可以优于统一方法，因此3D几何信息的潜在好处仍不清楚。因此，我们通过考虑一个更具挑战性的任务来研究动作的组合性，即训练中的动词和名词组合与测试分集没有重叠。我们扩展了H2O和FPHA数据集，并设计了一个新颖的合作学习框架，该框架可以在显式考虑手和操纵物体之间的几何关系方面发挥作用。通过广泛的定量和定性评估，我们在（组合性）动作识别方面展示了相对于现有方法的显著改进。', 'title_zh': '基于超二次曲面的主观_rgb视频中三维手-对象重建及组合动作识别的协作学习方法'}
{'arxiv_id': 'arXiv:2501.07087', 'title': 'Video Quality Assessment for Online Processing: From Spatial to Temporal Sampling', 'authors': 'Jiebin Yan, Lei Wu, Yuming Fang, Xuelin Liu, Xue Xia, Weide Liu', 'link': 'https://arxiv.org/abs/2501.07087', 'abstract': "With the rapid development of multimedia processing and deep learning technologies, especially in the field of video understanding, video quality assessment (VQA) has achieved significant progress. Although researchers have moved from designing efficient video quality mapping models to various research directions, in-depth exploration of the effectiveness-efficiency trade-offs of spatio-temporal modeling in VQA models is still less sufficient. Considering the fact that videos have highly redundant information, this paper investigates this problem from the perspective of joint spatial and temporal sampling, aiming to seek the answer to how little information we should keep at least when feeding videos into the VQA models while with acceptable performance sacrifice. To this end, we drastically sample the video's information from both spatial and temporal dimensions, and the heavily squeezed video is then fed into a stable VQA model. Comprehensive experiments regarding joint spatial and temporal sampling are conducted on six public video quality databases, and the results demonstrate the acceptable performance of the VQA model when throwing away most of the video information. Furthermore, with the proposed joint spatial and temporal sampling strategy, we make an initial attempt to design an online VQA model, which is instantiated by as simple as possible a spatial feature extractor, a temporal feature fusion module, and a global quality regression module. Through quantitative and qualitative experiments, we verify the feasibility of online VQA model by simplifying itself and reducing input.", 'abstract_zh': '随着多媒体处理和深度学习技术的迅速发展，尤其是在视频理解领域，视频质量评估（VQA）已经取得了显著的进展。尽管研究人员已经从设计高效的视频质量映射模型转向了各种研究方向，但对于VQA模型中时空建模效果-效率权衡的深入探索仍然不够充分。鉴于视频具有高度冗余的信息，本文从联合空间和时间采样的角度探讨了这一问题，旨在寻求在不影响性能的情况下，向VQA模型输入视频时至少应保留多少信息的解答。为此，我们从空间和时间两个维度大幅减少了视频的信息量，然后将高度压缩的视频输入到一个稳定的VQA模型中。我们在六个公开的视频质量数据库上进行了有关联合空间和时间采样的综合实验，结果表明，在丢弃大部分视频信息的情况下，VQA模型仍能保持可接受的性能。此外，通过提出联合空间和时间采样策略，我们首次尝试设计了一个在线VQA模型，该模型仅由尽可能简单的空间特征提取器、时序特征融合模块和全局质量回归模块组成。通过定量和定性实验，我们验证了通过简化自身并减少输入可以实现在线VQA模型的可行性。', 'title_zh': '在线处理中的视频质量评估：从空间采样到时间采样'}
{'arxiv_id': 'arXiv:2501.07076', 'title': 'Representation Learning of Point Cloud Upsampling in Global and Local Inputs', 'authors': 'Tongxu Zhang, Bei Wang', 'link': 'https://arxiv.org/abs/2501.07076', 'abstract': 'In recent years, point cloud upsampling has been widely applied in fields such as 3D reconstruction. Our study investigates the factors influencing point cloud upsampling on both global and local levels through representation learning. Specifically, the paper inputs global and local information of the same point cloud model object into two encoders to extract these features, fuses them, and then feeds the combined features into an upsampling decoder. The goal is to address issues of sparsity and noise in point clouds by leveraging prior knowledge from both global and local inputs. And the proposed framework can be applied to any state-of-the-art point cloud upsampling neural network. Experiments were conducted on a series of autoencoder-based models utilizing deep learning, yielding interpretability for both global and local inputs, and it has been proven in the results that our proposed framework can further improve the upsampling effect in previous SOTA works. At the same time, the Saliency Map reflects the differences between global and local feature inputs, as well as the effectiveness of training with both inputs in parallel.', 'abstract_zh': '近年来，点云上采样技术在三维重建等领域得到了广泛应用。本研究通过表征学习探讨了点云上采样在全局和局部两个层面上的影响因素。具体来说，论文将同一点云模型的全局和局部信息分别输入两个编码器，提取相应的特征，然后将这些特征融合，再输入到一个上采样解码器中。目标是通过利用全局和局部输入的先验知识来解决点云稀疏性和噪声问题。所提出的框架可以适用于任何最先进的点云上采样神经网络。实验使用了一系列基于自编码器的深度学习模型，这些实验不仅为全局和局部输入提供了可解释性，还在结果中证实了所提出的框架能够进一步提升上采样效果，超越了现有的顶级工作（SOTA）。同时，显著图反映了全局和局部特征输入之间的差异，以及同时使用这两种输入进行训练的有效性。', 'title_zh': '全局输入与局部输入的点云上采样表示学习'}
{'arxiv_id': 'arXiv:2501.07058', 'title': 'Logic Meets Magic: LLMs Cracking Smart Contract Vulnerabilities', 'authors': 'ZeKe Xiao, Qin Wang, Hammond Pearce, Shiping Chen', 'link': 'https://arxiv.org/abs/2501.07058', 'abstract': 'Smart contract vulnerabilities caused significant economic losses in blockchain applications. Large Language Models (LLMs) provide new possibilities for addressing this time-consuming task. However, state-of-the-art LLM-based detection solutions are often plagued by high false-positive rates.\nIn this paper, we push the boundaries of existing research in two key ways. First, our evaluation is based on Solidity v0.8, offering the most up-to-date insights compared to prior studies that focus on older versions (v0.4). Second, we leverage the latest five LLM models (across companies), ensuring comprehensive coverage across the most advanced capabilities in the field.\nWe conducted a series of rigorous evaluations. Our experiments demonstrate that a well-designed prompt can reduce the false-positive rate by over 60%. Surprisingly, we also discovered that the recall rate for detecting some specific vulnerabilities in Solidity v0.8 has dropped to just 13% compared to earlier versions (i.e., v0.4). Further analysis reveals the root cause of this decline: the reliance of LLMs on identifying changes in newly introduced libraries and frameworks during detection.', 'abstract_zh': '智能合约漏洞造成了区块链应用中的重大经济损失。大规模语言模型（LLMs）为解决这一耗时任务提供了新的可能性。然而，现有的基于LLM的检测解决方案通常存在较高的误报率。\n本文在以下两个关键方面推动了现有研究的边界。首先，我们的评估基于Solidity v0.8，提供了比以前依赖于较旧版本（v0.4）的研究更为前沿的洞察。其次，我们利用了最新的五种LLM模型（来自不同公司），确保在最先进的能力范围内实现全面覆盖。\n我们进行了系列严格的评估。实验结果显示，精心设计的提示可以将误报率降低超过60%。令我们惊讶的是，我们还发现，在检测某些特定漏洞方面，对于Solidity v0.8的召回率已下降至13%，而早期版本（例如v0.4）的召回率更高。进一步的分析揭示了这种下降的原因：LLM在检测过程中依赖于识别新引入的库和框架的变化。', 'title_zh': '逻辑遇魔法：大规模语言模型破解智能合约漏洞'}
{'arxiv_id': 'arXiv:2501.07045', 'title': 'ACCon: Angle-Compensated Contrastive Regularizer for Deep Regression', 'authors': 'Botao Zhao, Xiaoyang Qu, Zuheng Kang, Junqing Peng, Jing Xiao, Jianzong Wang', 'link': 'https://arxiv.org/abs/2501.07045', 'abstract': 'In deep regression, capturing the relationship among continuous labels in feature space is a fundamental challenge that has attracted increasing interest. Addressing this issue can prevent models from converging to suboptimal solutions across various regression tasks, leading to improved performance, especially for imbalanced regression and under limited sample sizes. However, existing approaches often rely on order-aware representation learning or distance-based weighting. In this paper, we hypothesize a linear negative correlation between label distances and representation similarities in regression tasks. To implement this, we propose an angle-compensated contrastive regularizer for deep regression, which adjusts the cosine distance between anchor and negative samples within the contrastive learning framework. Our method offers a plug-and-play compatible solution that extends most existing contrastive learning methods for regression tasks. Extensive experiments and theoretical analysis demonstrate that our proposed angle-compensated contrastive regularizer not only achieves competitive regression performance but also excels in data efficiency and effectiveness on imbalanced datasets.', 'abstract_zh': '在深度回归中，捕捉特征空间中连续标签之间的关系是一个基本的挑战，这一挑战近年来引起了越来越多的关注。解决这一问题可以防止模型在各种回归任务中收敛到次优解，从而提高模型的性能，尤其是在不平衡回归和样本量有限的情况下。然而，现有方法通常依赖于有序感知的表示学习或基于距离的加权方法。在本文中，我们假设回归任务中的标签距离与表示相似性之间存在线性负相关关系。为实现这一目标，我们提出了一种角度补偿对比正则化方法，该方法在对比学习框架中调整锚点样本和负样本之间的余弦距离。我们的方法提供了一种插拔式兼容的解决方案，可以扩展大多数现有的对比学习方法应用于回归任务。大量的实验和理论分析表明，我们提出的角度补偿对比正则化不仅可以实现竞争力的回归性能，还能在不平衡数据集上表现出更高的数据效率和有效性。', 'title_zh': 'ACCon：角度补偿对比正则化项用于深度回归'}
{'arxiv_id': 'arXiv:2501.07021', 'title': 'Neural Probabilistic Circuits: Enabling Compositional and Interpretable Predictions through Logical Reasoning', 'authors': 'Weixin Chen, Simon Yu, Huajie Shao, Lui Sha, Han Zhao', 'link': 'https://arxiv.org/abs/2501.07021', 'abstract': "End-to-end deep neural networks have achieved remarkable success across various domains but are often criticized for their lack of interpretability. While post hoc explanation methods attempt to address this issue, they often fail to accurately represent these black-box models, resulting in misleading or incomplete explanations. To overcome these challenges, we propose an inherently transparent model architecture called Neural Probabilistic Circuits (NPCs), which enable compositional and interpretable predictions through logical reasoning. In particular, an NPC consists of two modules: an attribute recognition model, which predicts probabilities for various attributes, and a task predictor built on a probabilistic circuit, which enables logical reasoning over recognized attributes to make class predictions. To train NPCs, we introduce a three-stage training algorithm comprising attribute recognition, circuit construction, and joint optimization. Moreover, we theoretically demonstrate that an NPC's error is upper-bounded by a linear combination of the errors from its modules. To further demonstrate the interpretability of NPC, we provide both the most probable explanations and the counterfactual explanations. Empirical results on four benchmark datasets show that NPCs strike a balance between interpretability and performance, achieving results competitive even with those of end-to-end black-box models while providing enhanced interpretability.", 'abstract_zh': '端到端的深度神经网络在各个领域取得了显著的成功，但常因缺乏可解释性而受到批评。虽然后验解释方法试图解决这一问题，但往往无法准确地代表这些黑盒模型，导致误导性的或不完整的解释。为克服这些挑战，我们提出了一种本征透明的模型架构，称为神经概率电路（Neural Probabilistic Circuits，NPCs），通过逻辑推理实现组合与可解释的预测。具体而言，一个NPC包括两个模块：属性识别模型，用于预测各种属性的概率，以及基于概率电路的任务预测器，后者能够在识别出的属性上进行逻辑推理，从而做出类别预测。为了训练NPCs，我们引入了一个三阶段训练算法，包括属性识别、电路构建和联合优化。此外，我们从理论上证明了NPC的误差被其模块误差的线性组合上界所限制。为了进一步展示NPC的可解释性，我们提供了最可能的解释和反事实解释。在四个基准数据集上的实验结果表明，NPC们在保持可解释性的同时达到了性能的平衡，甚至在某些方面超过了端到端的黑盒模型，同时提供了增强的可解释性。', 'title_zh': '神经概率电路：通过逻辑推理实现组成性和可解释性的预测'}
{'arxiv_id': 'arXiv:2501.07020', 'title': 'ViSoLex: An Open-Source Repository for Vietnamese Social Media Lexical Normalization', 'authors': 'Anh Thi-Hoang Nguyen, Dung Ha Nguyen, Kiet Van Nguyen', 'link': 'https://arxiv.org/abs/2501.07020', 'abstract': "ViSoLex is an open-source system designed to address the unique challenges of lexical normalization for Vietnamese social media text. The platform provides two core services: Non-Standard Word (NSW) Lookup and Lexical Normalization, enabling users to retrieve standard forms of informal language and standardize text containing NSWs. ViSoLex's architecture integrates pre-trained language models and weakly supervised learning techniques to ensure accurate and efficient normalization, overcoming the scarcity of labeled data in Vietnamese. This paper details the system's design, functionality, and its applications for researchers and non-technical users. Additionally, ViSoLex offers a flexible, customizable framework that can be adapted to various datasets and research requirements. By publishing the source code, ViSoLex aims to contribute to the development of more robust Vietnamese natural language processing tools and encourage further research in lexical normalization. Future directions include expanding the system's capabilities for additional languages and improving the handling of more complex non-standard linguistic patterns.", 'abstract_zh': 'ViSoLex 是一个开源系统，旨在应对越南社交媒体文本词汇规范化所面临的独特挑战。该平台提供了两项核心服务：非标准词（NSW）查询和词汇规范化，使用户能够检索非正式语言的标准形式，并标准化包含NSWs的文本。ViSoLex的架构整合了预训练语言模型和弱监督学习技术，以确保准确高效的规范化，并克服了越南语标注数据稀缺的问题。本文详细介绍了系统的架构设计、功能及其在研究人员和非技术人员中的应用。此外，ViSoLex提供了一个灵活、可定制的框架，可以根据不同的数据集和研究需求进行调整。通过发布源代码，ViSoLex旨在促进更加稳健的越南自然语言处理工具的发展，并鼓励进一步的词汇规范化研究。未来的研究方向包括扩展系统的跨语言能力，并改善对更复杂的非标准语言模式的处理。', 'title_zh': 'ViSoLex: 一个越南社交媒体词汇Normalization的开源库'}
{'arxiv_id': 'arXiv:2501.07017', 'title': 'UNetVL: Enhancing 3D Medical Image Segmentation with Chebyshev KAN Powered Vision-LSTM', 'authors': 'Xuhui Guo, Tanmoy Dam, Rohan Dhamdhere, Gourav Modanwal, Anant Madabhushi', 'link': 'https://arxiv.org/abs/2501.07017', 'abstract': '3D medical image segmentation has progressed considerably due to Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs), yet these methods struggle to balance long-range dependency acquisition with computational efficiency. To address this challenge, we propose UNETVL (U-Net Vision-LSTM), a novel architecture that leverages recent advancements in temporal information processing. UNETVL incorporates Vision-LSTM (ViL) for improved scalability and memory functions, alongside an efficient Chebyshev Kolmogorov-Arnold Networks (KAN) to handle complex and long-range dependency patterns more effectively. We validated our method on the ACDC and AMOS2022 (post challenge Task 2) benchmark datasets, showing a significant improvement in mean Dice score compared to recent state-of-the-art approaches, especially over its predecessor, UNETR, with increases of 7.3% on ACDC and 15.6% on AMOS, respectively. Extensive ablation studies were conducted to demonstrate the impact of each component in UNETVL, providing a comprehensive understanding of its architecture. Our code is available at this https URL, facilitating further research and applications in this domain.', 'abstract_zh': '由于卷积神经网络（CNNs）和视觉变换器（ViTs）的进展，3D 医学图像分割取得了显著进步，然而这些方法在获取长程依赖性和计算效率之间难以取得平衡。为了解决这一挑战，我们提出了UNETVL（U-Net Vision-LSTM），这是一种利用最新时间信息处理进展的新架构。UNETVL 结合了视觉长短期记忆网络（ViL），以提高可扩展性和内存功能，并采用高效的切比雪夫柯尔莫戈罗夫-阿诺尔德网络（KAN）来更有效地处理复杂的长程依赖模式。我们在ACDC和AMOS2022（竞赛后任务2）基准数据集上验证了该方法，结果显示在 Dice 得分上相对于最近的先进方法有显著改进，特别是在其前身UNETR的基础上，ACDC数据集上提高了7.3%，AMOS数据集上提高了15.6%。我们还进行了广泛的消融研究，以展示UNETVL 中每个组件的影响，提供了对其架构的全面理解。我们的代码已在此处：https://github.com/username/unetvl 中公开，以促进该领域的进一步研究和应用。', 'title_zh': 'UNetVL：借助切比雪夫KAN驱动的Vision-LSTM增强的3D医学图像分割'}
{'arxiv_id': 'arXiv:2501.07016', 'title': 'A Multi-Modal Deep Learning Framework for Pan-Cancer Prognosis', 'authors': 'Binyu Zhang, Shichao Li, Junpeng Jian, Zhu Meng, Limei Guo, Zhicheng Zhao', 'link': 'https://arxiv.org/abs/2501.07016', 'abstract': 'Prognostic task is of great importance as it closely related to the survival analysis of patients, the optimization of treatment plans and the allocation of resources. The existing prognostic models have shown promising results on specific datasets, but there are limitations in two aspects. On the one hand, they merely explore certain types of modal data, such as patient histopathology WSI and gene expression analysis. On the other hand, they adopt the per-cancer-per-model paradigm, which means the trained models can only predict the prognostic effect of a single type of cancer, resulting in weak generalization ability. In this paper, a deep-learning based model, named UMPSNet, is proposed. Specifically, to comprehensively understand the condition of patients, in addition to constructing encoders for histopathology images and genomic expression profiles respectively, UMPSNet further integrates four types of important meta data (demographic information, cancer type information, treatment protocols, and diagnosis results) into text templates, and then introduces a text encoder to extract textual features. In addition, the optimal transport OT-based attention mechanism is utilized to align and fuse features of different modalities. Furthermore, a guided soft mixture of experts (GMoE) mechanism is introduced to effectively address the issue of distribution differences among multiple cancer datasets. By incorporating the multi-modality of patient data and joint training, UMPSNet outperforms all SOTA approaches, and moreover, it demonstrates the effectiveness and generalization ability of the proposed learning paradigm of a single model for multiple cancer types. The code of UMPSNet is available at this https URL.', 'abstract_zh': '生存预测任务非常重要，因为它与患者的生存分析密切相关，优化治疗方案以及资源分配。现有的生存预测模型在特定数据集上取得了令人鼓舞的结果，但在两个方面存在局限性。一方面，它们仅探索某些类型的模态数据，例如患者的组织病理学WSI图像和基因表达分析。另一方面，它们采用每种癌症每种模型的范式，这意味着训练的模型只能预测单一类型的癌症效果，导致泛化能力较弱。在本文中，提出了一种基于深度学习的模型，命名为UMPSNet。\n\n具体来说，为了全面了解患者的状况，除了分别构建组织病理图像和基因表达谱的编码器，UMPSNet进一步将四种重要的元数据（包括人口统计信息、癌症类型信息、治疗方案和诊断结果）整合到文本模板中，并引入文本编码器以提取文本特征。此外，利用最优传输OT（Optimal Transport）基于注意力机制对不同模态特征进行对齐和融合。进一步引入了导向软专家混合机制（GMoE：Guided Soft Mixture of Experts）以有效解决多个癌症数据集间分布差异的问题。通过融合患者的多模态数据并进行联合训练，UMPSNet在所有现有先进方法中表现更优。此外，UMPSNet还展示了基于单一模型多癌症类型的预测学习范式的有效性和泛化能力。UMPSNet的代码可参见：这个URL（请提供正确的URL）。', 'title_zh': '一种多模态深度学习框架用于泛癌种预后分析'}
{'arxiv_id': 'arXiv:2501.07014', 'title': 'AlgoRxplorers | Precision in Mutation -- Enhancing Drug Design with Advanced Protein Stability Prediction Tools', 'authors': 'Karishma Thakrar, Jiangqin Ma, Max Diamond, Akash Patel', 'link': 'https://arxiv.org/abs/2501.07014', 'abstract': 'Predicting the impact of single-point amino acid mutations on protein stability is essential for understanding disease mechanisms and advancing drug development. Protein stability, quantified by changes in Gibbs free energy ($\\Delta\\Delta G$), is influenced by these mutations. However, the scarcity of data and the complexity of model interpretation pose challenges in accurately predicting stability changes. This study proposes the application of deep neural networks, leveraging transfer learning and fusing complementary information from different models, to create a feature-rich representation of the protein stability landscape. We developed four models, with our third model, ThermoMPNN+, demonstrating the best performance in predicting $\\Delta\\Delta G$ values. This approach, which integrates diverse feature sets and embeddings through latent transfusion techniques, aims to refine $\\Delta\\Delta G$ predictions and contribute to a deeper understanding of protein dynamics, potentially leading to advancements in disease research and drug discovery.', 'abstract_zh': '预测单点氨基酸突变对蛋白质稳定性的的影响对于理解疾病机制和推动药物开发至关重要。蛋白质稳定性可以通过热力学吉布斯自由能变化（$\\Delta\\Delta G$）来量化，而这些突变会影响这种稳定性。然而，数据的稀缺性和模型解释的复杂性给准确预测稳定性变化带来了挑战。本研究提出应用深度神经网络，利用迁移学习并结合不同模型的互补信息，以创建蛋白质稳定性景观的丰富特征表示。我们开发了四个模型，其中我们第三个模型ThermoMPNN+在预测$\\Delta\\Delta G$值方面表现出最佳性能。该方法通过潜变量融合技术整合了多种特征集和嵌入表示，旨在细化$\\Delta\\Delta G$预测并促进对蛋白质动力学的更深入理解，从而可能推动疾病研究和药物发现的进步。', 'title_zh': 'AlgoRxplorers | 精准突变——借助高级蛋白质稳定性预测工具提高药物设计效率'}
{'arxiv_id': 'arXiv:2501.06999', 'title': 'Likelihood Training of Cascaded Diffusion Models via Hierarchical Volume-preserving Maps', 'authors': 'Henry Li, Ronen Basri, Yuval Kluger', 'link': 'https://arxiv.org/abs/2501.06999', 'abstract': "Cascaded models are multi-scale generative models with a marked capacity for producing perceptually impressive samples at high resolutions. In this work, we show that they can also be excellent likelihood models, so long as we overcome a fundamental difficulty with probabilistic multi-scale models: the intractability of the likelihood function. Chiefly, in cascaded models each intermediary scale introduces extraneous variables that cannot be tractably marginalized out for likelihood evaluation. This issue vanishes by modeling the diffusion process on latent spaces induced by a class of transformations we call hierarchical volume-preserving maps, which decompose spatially structured data in a hierarchical fashion without introducing local distortions in the latent space. We demonstrate that two such maps are well-known in the literature for multiscale modeling: Laplacian pyramids and wavelet transforms. Not only do such reparameterizations allow the likelihood function to be directly expressed as a joint likelihood over the scales, we show that the Laplacian pyramid and wavelet transform also produces significant improvements to the state-of-the-art on a selection of benchmarks in likelihood modeling, including density estimation, lossless compression, and out-of-distribution detection. Investigating the theoretical basis of our empirical gains we uncover deep connections to score matching under the Earth Mover's Distance (EMD), which is a well-known surrogate for perceptual similarity. Code can be found at \\href{this https URL}{this https url}.", 'abstract_zh': '递归模型是多尺度生成模型，具有在高分辨率下生成感知上令人印象深刻样本的能力。在本文中，我们将展示在克服概率多尺度模型的基本困难——似然函数的不可计算性之后，递归模型也可以成为出色的似然模型。主要来说，在递归模型中，每个中间尺度都会引入不可计算消去的外部变量，这妨碍了对似然性的评估。通过使用一类被称为分层体积保测量变换的映射建模扩散过程，这一问题得以解决。这类映射能够在不引入局部空间扭曲的情况下，以分层方式分解空间结构化数据。我们证明，在文献中已知的两种此类映射对于多尺度建模非常适用：拉普拉斯金字塔和小波变换。这些重新参数化不仅允许似然函数直接表达为尺度上的联合似然，我们还展示了拉普拉斯金字塔和小波变换在似然模型的部分基准测试中（包括密度估计、无损压缩和异类检测）带来了显著改进。我们对我们的经验增益背后理论基础的探究揭示了与搬运工距离（EMD）下的评分匹配之间的深刻联系，这已被广泛用作感知相似度的替代指标。相关代码请参见 \\href{这个 https URL}{这个 HTTPS URL}。', 'title_zh': '通过层次体积保持映射进行级联扩散模型的似然训练'}
{'arxiv_id': 'arXiv:2501.06994', 'title': 'Motion Tracks: A Unified Representation for Human-Robot Transfer in Few-Shot Imitation Learning', 'authors': 'Juntao Ren, Priya Sundaresan, Dorsa Sadigh, Sanjiban Choudhury, Jeannette Bohg', 'link': 'https://arxiv.org/abs/2501.06994', 'abstract': 'Teaching robots to autonomously complete everyday tasks remains a challenge. Imitation Learning (IL) is a powerful approach that imbues robots with skills via demonstrations, but is limited by the labor-intensive process of collecting teleoperated robot data. Human videos offer a scalable alternative, but it remains difficult to directly train IL policies from them due to the lack of robot action labels. To address this, we propose to represent actions as short-horizon 2D trajectories on an image. These actions, or motion tracks, capture the predicted direction of motion for either human hands or robot end-effectors. We instantiate an IL policy called Motion Track Policy (MT-pi) which receives image observations and outputs motion tracks as actions. By leveraging this unified, cross-embodiment action space, MT-pi completes tasks with high success given just minutes of human video and limited additional robot demonstrations. At test time, we predict motion tracks from two camera views, recovering 6DoF trajectories via multi-view synthesis. MT-pi achieves an average success rate of 86.5% across 4 real-world tasks, outperforming state-of-the-art IL baselines which do not leverage human data or our action space by 40%, and generalizes to scenarios seen only in human videos. Code and videos are available on our website this https URL.', 'abstract_zh': '自主完成日常任务的机器人教学仍然是一个挑战。模仿学习（IL）是一种强大的方法，可以通过示例赋予机器人技能，但它受限于收集遥操作机器人数据的劳动密集型过程。人类视频提供了一种可扩展的替代方案，但由于缺乏机器人动作标签，直接从人类视频中训练IL策略仍然具有挑战性。为了解决这一问题，我们提出将动作表示为图像上的短视程2D轨迹。这些动作或运动轨迹捕捉了人类手或机器人末端执行器的预测运动方向。我们实现了一种称为运动轨迹策略（MT-pi）的IL策略，该策略接收图像观察结果并输出运动轨迹作为动作。通过利用这种统一的跨体征动作空间，MT-pi 可以仅凭几分钟的人类视频和少量额外的机器人示例就完成任务，成功率很高。在测试阶段，我们从两个摄像机视角预测运动轨迹，通过多视角合成恢复6-自由度轨迹。MT-pi 在4个实际任务上的平均成功率达到了86.5%，比不利用人类数据或我们动作空间的最新IL基准高出40%，并且能够在仅限人类视频中出现的场景中泛化。代码和视频可在我们的网站上获得：this https URL。', 'title_zh': '-motion 轨迹：少样本模仿学习中人机迁移的统一表示方法-'}
{'arxiv_id': 'arXiv:2501.06985', 'title': 'Graph Contrastive Learning on Multi-label Classification for Recommendations', 'authors': 'Jiayang Wu, Wensheng Gan, Huashen Lu, Philip S. Yu', 'link': 'https://arxiv.org/abs/2501.06985', 'abstract': 'In business analysis, providing effective recommendations is essential for enhancing company profits. The utilization of graph-based structures, such as bipartite graphs, has gained popularity for their ability to analyze complex data relationships. Link prediction is crucial for recommending specific items to users. Traditional methods in this area often involve identifying patterns in the graph structure or using representational techniques like graph neural networks (GNNs). However, these approaches encounter difficulties as the volume of data increases. To address these challenges, we propose a model called Graph Contrastive Learning for Multi-label Classification (MCGCL). MCGCL leverages contrastive learning to enhance recommendation effectiveness. The model incorporates two training stages: a main task and a subtask. The main task is holistic user-item graph learning to capture user-item relationships. The homogeneous user-user (item-item) subgraph is constructed to capture user-user and item-item relationships in the subtask. We assessed the performance using real-world datasets from Amazon Reviews in multi-label classification tasks. Comparative experiments with state-of-the-art methods confirm the effectiveness of MCGCL, highlighting its potential for improving recommendation systems.', 'abstract_zh': '在商业分析中，提供有效的推荐对于增强公司利润至关重要。基于图的结构利用，如二分图，因其分析复杂数据关系的能力而受到青睐。链接预测对向用户推荐特定项目至关重要。该领域的传统方法通常涉及识别图结构中的模式或使用表示技术，如图神经网络（GNNs）。然而，随着数据量的增加，这些方法会遇到困难。为解决这些问题，我们提出了一种名为多标签分类的图对比学习模型（MCGCL）。MCGCL 利用对比学习来提高推荐的有效性。该模型包含两个训练阶段：主要任务和子任务。主要任务是整体用户-项目图学习，以捕捉用户-项目关系。子任务构建同质用户-用户（项目-项目）子图来捕捉用户-用户和项目-项目关系。我们使用来自亚马逊评论的实际数据集，在多标签分类任务中评估了该模型的性能。与最先进的方法的对比实验证实了 MCGCL 的有效性，突显了其对提升推荐系统的潜在价值。', 'title_zh': '多标签分类中基于图的对比学习在推荐系统中的应用'}
{'arxiv_id': 'arXiv:2501.06981', 'title': 'Data Enrichment Work and AI Labor in Latin America and the Caribbean', 'authors': 'Gianna Williams, Maya De Los Santos, Alexandra To, Saiph Savage', 'link': 'https://arxiv.org/abs/2501.06981', 'abstract': "The global AI surge demands crowdworkers from diverse languages and cultures. They are pivotal in labeling data for enabling global AI systems. Despite global significance, research has primarily focused on understanding the perspectives and experiences of US and India crowdworkers, leaving a notable gap. To bridge this, we conducted a survey with 100 crowdworkers across 16 Latin American and Caribbean countries. We discovered that these workers exhibited pride and respect for their digital labor, with strong support and admiration from their families. Notably, crowd work was also seen as a stepping stone to financial and professional independence. Surprisingly, despite wanting more connection, these workers also felt isolated from peers and doubtful of others' labor quality. They resisted collaboration and gender-based tools, valuing gender-neutrality. Our work advances HCI understanding of Latin American and Caribbean crowdwork, offering insights for digital resistance tools for the region.", 'abstract_zh': '全球人工智能的迅猛发展需要来自多元语言和文化的众包工作者。他们在为全球人工智能系统标记数据方面发挥着关键作用。尽管这一领域具有全球意义，但现有的研究主要集中在理解和探索美国和印度众包工作者的视角和经验上，留下了明显的不足。为弥补这一缺口，我们对来自16个拉丁美洲和加勒比国家的100名众包工作者进行了问卷调查。调查结果显示，这些工作人员对他们的数字劳动感到自豪并受到家庭的尊敬和支持，而且众包工作也被视为走向财务和职业独立的垫脚石。令人惊讶的是，尽管众包工作者希望与他人建立更多的联系，他们却感到与同伴疏离，对他人工作质量持怀疑态度。他们抵制合作和基于性别工具的做法，强调性别中立的重要性。我们的研究工作为理解和把握拉丁美洲和加勒比地区的众包工作提供了人机交互（HCI）方面的洞见，并为该地区提供了数字抵制工具的见解。', 'title_zh': '拉丁美洲和加勒比地区的数据增强工作与人工智能劳动'}
{'arxiv_id': 'arXiv:2501.06980', 'title': 'Combining LLM decision and RL action selection to improve RL policy for adaptive interventions', 'authors': 'Karine Karine, Benjamin M. Marlin', 'link': 'https://arxiv.org/abs/2501.06980', 'abstract': 'Reinforcement learning (RL) is increasingly being used in the healthcare domain, particularly for the development of personalized health adaptive interventions. Inspired by the success of Large Language Models (LLMs), we are interested in using LLMs to update the RL policy in real time, with the goal of accelerating personalization. We use the text-based user preference to influence the action selection on the fly, in order to immediately incorporate the user preference. We use the term "user preference" as a broad term to refer to a user personal preference, constraint, health status, or a statement expressing like or dislike, etc. Our novel approach is a hybrid method that combines the LLM response and the RL action selection to improve the RL policy. Given an LLM prompt that incorporates the user preference, the LLM acts as a filter in the typical RL action selection. We investigate different prompting strategies and action selection strategies. To evaluate our approach, we implement a simulation environment that generates the text-based user preferences and models the constraints that impact behavioral dynamics. We show that our approach is able to take into account the text-based user preferences, while improving the RL policy, thus improving personalization in adaptive intervention.', 'abstract_zh': '强化学习（RL）在医疗健康领域的应用越来越广泛，尤其是在个性化健康适应性干预的发展中。受大型语言模型（LLMs）成功应用的启发，我们感兴趣的是使用LLMs实时更新RL策略，以加速个性化过程。通过文本形式的用户偏好影响即时动作选择，以便立即纳入用户偏好。我们将“用户偏好”定义为用户的个人偏好、约束条件、健康状况，或表达喜欢和不喜欢的陈述等广泛的内容。我们的新颖方法是一种将LLMs响应与RL动作选择相结合的混合方法，以改进RL策略。给定包含用户偏好的LLM提示，LLM作为典型的RL动作选择过程中的筛选器发挥作用。我们研究了不同的提示策略和动作选择策略。为了评估我们的方法，我们构建了一个仿真环境，生成基于文本的用户偏好，并建模影响行为动力学的各种限制条件。结果显示，我们的方法能够考虑到基于文本的用户偏好，从而在适应性干预中提高个性化水平。', 'title_zh': '将大规模语言模型的决策与强化学习的动作选择相结合，以改善自适应干预的强化学习策略'}
{'arxiv_id': 'arXiv:2501.06965', 'title': 'Kolmogorov-Arnold Recurrent Network for Short Term Load Forecasting Across Diverse Consumers', 'authors': 'Muhammad Umair Danish, Katarina Grolinger', 'link': 'https://arxiv.org/abs/2501.06965', 'abstract': "Load forecasting plays a crucial role in energy management, directly impacting grid stability, operational efficiency, cost reduction, and environmental sustainability. Traditional Vanilla Recurrent Neural Networks (RNNs) face issues such as vanishing and exploding gradients, whereas sophisticated RNNs such as LSTMs have shown considerable success in this domain. However, these models often struggle to accurately capture complex and sudden variations in energy consumption, and their applicability is typically limited to specific consumer types, such as offices or schools. To address these challenges, this paper proposes the Kolmogorov-Arnold Recurrent Network (KARN), a novel load forecasting approach that combines the flexibility of Kolmogorov-Arnold Networks with RNN's temporal modeling capabilities. KARN utilizes learnable temporal spline functions and edge-based activations to better model non-linear relationships in load data, making it adaptable across a diverse range of consumer types. The proposed KARN model was rigorously evaluated on a variety of real-world datasets, including student residences, detached homes, a home with electric vehicle charging, a townhouse, and industrial buildings. Across all these consumer categories, KARN consistently outperformed traditional Vanilla RNNs, while it surpassed LSTM and Gated Recurrent Units (GRUs) in six buildings. The results demonstrate KARN's superior accuracy and applicability, making it a promising tool for enhancing load forecasting in diverse energy management scenarios.", 'abstract_zh': '负荷预测在能源管理中起着至关重要的作用，直接影响电网稳定性、运行效率、成本降低和环境可持续性。传统的单纯循环神经网络（Vanilla RNNs）面临梯度消失和梯度爆炸的问题，而复杂的循环神经网络，如长短期记忆网络（LSTMs），在这一领域显示出显著的成功。然而，这些模型往往难以准确捕捉能源消耗的复杂和突发变化，并且其适用性通常局限于特定的消费者类型，如办公室或学校。为解决这些挑战，本文提出了一种新颖的负荷预测方法——柯尔莫哥洛夫-阿诺尔德循环网络（KARN），它结合了柯尔莫哥洛夫-阿诺尔德网络的灵活性和循环神经网络的时间建模能力。KARN利用可学习的时间样条函数和基于边的激活函数，更好地建模负荷数据中的非线性关系，使其能够适应多种消费者类型。提出的KARN模型在包括学生宿舍、独立屋、配备电动汽车充电设施的住宅、联排别墅和工业建筑等各种实际数据集上进行了严格评估。在所有这些消费者类别中，KARN始终优于传统的单纯循环神经网络，而且在六栋建筑中，KARN的表现超过了LSTM和门控循环单元（GRUs）。结果表明，KARN在准确性和适用性方面表现出色，使其成为提高各种能源管理场景中负荷预测的有前途的工具。', 'title_zh': '柯尔莫戈罗夫-阿诺尔德循环网络在多样化消费者短期负荷预测中的应用'}
{'arxiv_id': 'arXiv:2501.06963', 'title': 'Generative Artificial Intelligence-Supported Pentesting: A Comparison between Claude Opus, GPT-4, and Copilot', 'authors': 'Antonio López Martínez, Alejandro Cano, Antonio Ruiz-Martínez', 'link': 'https://arxiv.org/abs/2501.06963', 'abstract': 'The advent of Generative Artificial Intelligence (GenAI) has brought a significant change to our society. GenAI can be applied across numerous fields, with particular relevance in cybersecurity. Among the various areas of application, its use in penetration testing (pentesting) or ethical hacking processes is of special interest. In this paper, we have analyzed the potential of leading generic-purpose GenAI tools-Claude Opus, GPT-4 from ChatGPT, and Copilot-in augmenting the penetration testing process as defined by the Penetration Testing Execution Standard (PTES). Our analysis involved evaluating each tool across all PTES phases within a controlled virtualized environment. The findings reveal that, while these tools cannot fully automate the pentesting process, they provide substantial support by enhancing efficiency and effectiveness in specific tasks. Notably, all tools demonstrated utility; however, Claude Opus consistently outperformed the others in our experimental scenarios.', 'abstract_zh': '生成式人工智能（GenAI）的问世对社会产生了重大影响。GenAI 可以应用于众多领域，并特别与网络安全相关。在各种应用领域中，其在渗透测试（pentesting）或道德黑客过程中的应用特别引起关注。本文分析了通义千问、GPT-4（来自ChatGPT）和Copilot等主要通用型GenAI工具在Penetration Testing Execution Standard（PTES）定义的渗透测试过程中的潜在作用。我们的分析是在受控的虚拟化环境中，对每种工具在所有PTES阶段进行了评估。研究结果表明，虽然这些工具无法完全自动化渗透测试过程，但它们在特定任务中提高了效率和有效性，提供了显著的支持。值得注意的是，所有工具都表现出一定的实用性；然而，在我们的实验场景中，通义千问在各方面表现一直优于其他工具。', 'title_zh': '生成型人工智能支持的渗透测试：Claude Opus、GPT-4 和 Copilot 之间的比较'}
{'arxiv_id': 'arXiv:2501.06962', 'title': 'Compact Bayesian Neural Networks via pruned MCMC sampling', 'authors': 'Ratneel Deo, Scott Sisson, Jody M. Webster, Rohitash Chandra', 'link': 'https://arxiv.org/abs/2501.06962', 'abstract': 'Bayesian Neural Networks (BNNs) offer robust uncertainty quantification in model predictions, but training them presents a significant computational challenge. This is mainly due to the problem of sampling multimodal posterior distributions using Markov Chain Monte Carlo (MCMC) sampling and variational inference algorithms. Moreover, the number of model parameters scales exponentially with additional hidden layers, neurons, and features in the dataset. Typically, a significant portion of these densely connected parameters are redundant and pruning a neural network not only improves portability but also has the potential for better generalisation capabilities. In this study, we address some of the challenges by leveraging MCMC sampling with network pruning to obtain compact probabilistic models having removed redundant parameters. We sample the posterior distribution of model parameters (weights and biases) and prune weights with low importance, resulting in a compact model. We ensure that the compact BNN retains its ability to estimate uncertainty via the posterior distribution while retaining the model training and generalisation performance accuracy by adapting post-pruning resampling. We evaluate the effectiveness of our MCMC pruning strategy on selected benchmark datasets for regression and classification problems through empirical result analysis. We also consider two coral reef drill-core lithology classification datasets to test the robustness of the pruning model in complex real-world datasets. We further investigate if refining compact BNN can retain any loss of performance. Our results demonstrate the feasibility of training and pruning BNNs using MCMC whilst retaining generalisation performance with over 75% reduction in network size. This paves the way for developing compact BNN models that provide uncertainty estimates for real-world applications.', 'abstract_zh': '贝叶斯神经网络（BNNs）能够在模型预测中提供稳健的不确定量化，但它们的训练却面临显著的计算挑战。这主要是由于使用马尔可夫链蒙特卡罗（MCMC）采样和变分推断算法抽取多模态后验分布的问题。此外，随着隐藏层、神经元和数据集中特征的增加，模型参数的数量呈指数增长。通常，这些密接的参数中有一大部分是冗余的。通过网络修剪减少神经网络的参数不仅提高了其可移植性，还可能增强其泛化能力。在本研究中，我们通过结合MCMC采样和网络修剪来应对部分挑战，从而获得包含减少冗余参数的紧凑型概率模型。我们抽取模型参数（权重和偏置）的后验分布，并去除低重要性的权重，从而得到一个紧凑的模型。我们确保裁剪后的BNN能够通过后验分布估计不确定性，并通过后修剪采样来适应以保留模型训练和泛化性能的准确性。我们通过实证分析评估了MCMC修剪策略在回归和分类问题的选定基准数据集上的有效性。我们也考虑了两个珊瑚礁钻孔岩石分类数据集，以测试修剪模型在复杂现实世界数据集中的稳健性。进一步探讨了精炼紧凑型BNN是否能够保留任何性能损失。我们的结果表明，使用MCMC进行BNN的训练和剪枝，在网络大小减少超过75%的情况下，仍然能够保持泛化性能。这为开发能够在实际应用中提供不确定性估计的紧凑型BNN模型铺平了道路。', 'title_zh': '通过剪枝的MCMC采样构建紧凑型贝叶斯神经网络'}
{'arxiv_id': 'arXiv:2501.06956', 'title': 'Patent Novelty Assessment Accelerating Innovation and Patent Prosecution', 'authors': 'Kapil Kashyap, Sean Fargose, Gandhar Dhonde, Aditya Mishra', 'link': 'https://arxiv.org/abs/2501.06956', 'abstract': 'In the rapidly evolving landscape of technological innovation, safeguarding intellectual property rights through patents is crucial for fostering progress and stimulating research and development investments. This report introduces a ground-breaking Patent Novelty Assessment and Claim Generation System, meticulously crafted to dissect the inventive aspects of intellectual property and simplify access to extensive patent claim data. Addressing a crucial gap in academic institutions, our system provides college students and researchers with an intuitive platform to navigate and grasp the intricacies of patent claims, particularly tailored for the nuances of Chinese patents. Unlike conventional analysis systems, our initiative harnesses a proprietary Chinese API to ensure unparalleled precision and relevance. The primary challenge lies in the complexity of accessing and comprehending diverse patent claims, inhibiting effective innovation upon existing ideas. Our solution aims to overcome these barriers by offering a bespoke approach that seamlessly retrieves comprehensive claim information, finely tuned to the specifics of the Chinese patent landscape. By equipping users with efficient access to comprehensive patent claim information, our transformative platform seeks to ignite informed exploration and innovation in the ever-evolving domain of intellectual property. Its envisioned impact transcends individual colleges, nurturing an environment conducive to research and development while deepening the understanding of patented concepts within the academic community.', 'abstract_zh': '在技术快速创新的背景下，通过专利保护知识产权对于促进进步和刺激研发投入至关重要。本报告介绍了一项颠覆性的专利新颖性评估与权利要求生成系统，该系统精心设计，旨在剖析知识产权的创新性方面，并简化对海量专利权利要求数据的访问。本系统填补了学术机构中的重要空白，为大学生和研究人员提供了一个直观的平台，帮助他们理解和掌握专利权利要求的复杂性，特别是针对中国专利的特点进行详细说明。与传统的分析系统不同，我们的举措利用了专有的中文API，确保了无与伦比的精确性和相关性。主要挑战在于获取和理解多种多样的专利权利要求的复杂性，这阻碍了有效利用现有想法进行创新。我们提供的解决方案旨在通过提供一个量身定制的方法来克服这些障碍，该方法能够无缝地检索全面的权利要求信息，并针对中国专利环境进行精细调整。通过为用户提供高效访问全面的专利权利要求信息，我们的变革性平台旨在激发对知识产权领域的持续探索与创新。其预期影响远不止于单个学院，而是营造有利于研究和开发的环境，同时加深学术界对专利概念的理解。', 'title_zh': '专利新颖性评估加速创新和专利审查'}
{'arxiv_id': 'arXiv:2501.06887', 'title': 'MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis', 'authors': 'Sadia Kamal, Tim Oates', 'link': 'https://arxiv.org/abs/2501.06887', 'abstract': 'As deep learning models gain attraction in medical data, ensuring transparent and trustworthy decision-making is essential. In skin cancer diagnosis, while advancements in lesion detection and classification have improved accuracy, the black-box nature of these methods poses challenges in understanding their decision processes, leading to trust issues among physicians. This study leverages the CLIP (Contrastive Language-Image Pretraining) model, trained on different skin lesion datasets, to capture meaningful relationships between visual features and diagnostic criteria terms. To further enhance transparency, we propose a method called MedGrad E-CLIP, which builds on gradient-based E-CLIP by incorporating a weighted entropy mechanism designed for complex medical imaging like skin lesions. This approach highlights critical image regions linked to specific diagnostic descriptions. The developed integrated pipeline not only classifies skin lesions by matching corresponding descriptions but also adds an essential layer of explainability developed especially for medical data. By visually explaining how different features in an image relates to diagnostic criteria, this approach demonstrates the potential of advanced vision-language models in medical image analysis, ultimately improving transparency, robustness, and trust in AI-driven diagnostic systems.', 'abstract_zh': '随着深度学习模型在医疗数据中的吸引力增加，确保透明和值得信赖的决策至关重要。在皮肤癌诊断中，尽管在病灶检测和分类方面的进步提高了准确率，但这些方法的黑箱性质给理解其决策过程带来了挑战，导致了医生的信任问题。本研究利用在不同皮肤病变数据集上训练的CLIP（对比语言-图像预训练）模型，捕捉视觉特征与诊断标准术语之间的有意义关系。为了进一步提高透明度，我们提出了一种名为MedGrad E-CLIP的方法，该方法在基于梯度的E-CLIP上引入了一个加权熵机制，专门适用于如皮肤病变等复杂医学成像。该方法强调了与特定诊断描述相联系的关键图像区域。开发的集成管道不仅通过匹配相应的描述来分类皮肤病变，还添加了一层特别为医疗数据设计的解释性描述。通过可视化解释图像中不同特征与诊断标准之间的关系，该方法展示了先进视觉-语言模型在医学图像分析中的潜力，最终提高了基于AI的诊断系统的透明度、鲁棒性和可信度。', 'title_zh': 'MedGrad E-CLIP: 提高基于AI的皮肤病变诊断中的信任与透明度'}
{'arxiv_id': 'arXiv:2501.06879', 'title': 'Defect Detection Network In PCB Circuit Devices Based on GAN Enhanced YOLOv11', 'authors': 'Jiayi Huang, Feiyun Zhao, Lieyang Chen', 'link': 'https://arxiv.org/abs/2501.06879', 'abstract': "This study proposes an advanced method for surface defect detection in printed circuit boards (PCBs) using an improved YOLOv11 model enhanced with a generative adversarial network (GAN). The approach focuses on identifying six common defect types: missing hole, rat bite, open circuit, short circuit, burr, and virtual welding. By employing GAN to generate synthetic defect images, the dataset is augmented with diverse and realistic patterns, improving the model's ability to generalize, particularly for complex and infrequent defects like burrs. The enhanced YOLOv11 model is evaluated on a PCB defect dataset, demonstrating significant improvements in accuracy, recall, and robustness, especially when dealing with defects in complex environments or small targets. This research contributes to the broader field of electronic design automation (EDA), where efficient defect detection is a crucial step in ensuring high-quality PCB manufacturing. By integrating advanced deep learning techniques, this approach enhances the automation and precision of defect detection, reducing reliance on manual inspection and accelerating design-to-production workflows. The findings underscore the importance of incorporating GAN-based data augmentation and optimized detection architectures in EDA processes, providing valuable insights for improving reliability and efficiency in PCB defect detection within industrial applications.", 'abstract_zh': '本文提出了一种利用改进的YOLOv11模型和生成对抗网络（GAN）高级方法，在印制电路板（PCBs）表面缺陷检测中的应用。该方法专注于识别六种常见缺陷类型：缺孔、咬边、开路、短路、飞边和假焊。通过使用GAN生成合成缺陷图像，数据集得到了多样化和现实性的增强，从而提高了模型在复杂和不常见缺陷（如飞边）检测方面的泛化能力。改进后的YOLOv11模型在PCB缺陷数据集上的评估结果表明，在处理复杂环境中的缺陷或小型目标时，该方法在准确性、召回率和鲁棒性方面取得了显著的提升。本研究为电子设计自动化（EDA）领域做出了贡献，该领域中的高效缺陷检测是保证高质PCB制造的重要步骤。通过集成先进的深度学习技术，该方法增强了缺陷检测的自动化和精确性，减少了对人工检查的依赖，并加快了从设计到生产的流程。研究结果强调了在EDA流程中结合基于GAN的数据增强和优化检测架构的重要性，为提高工业应用中PCB缺陷检测的可靠性和效率提供了宝贵的见解。', 'title_zh': '基于GAN增强YOLOv1的PCB电路器件缺陷检测网络'}
{'arxiv_id': 'arXiv:2501.06863', 'title': 'Transfer Learning of Tabular Data by Finetuning Large Language Models', 'authors': 'Shourav B. Rabbani, Ibna Kowsar, Manar D. Samad', 'link': 'https://arxiv.org/abs/2501.06863', 'abstract': 'Despite the artificial intelligence (AI) revolution, deep learning has yet to achieve much success with tabular data due to heterogeneous feature space and limited sample sizes without viable transfer learning. The new era of generative AI, powered by large language models (LLM), brings unprecedented learning opportunities to diverse data and domains. This paper investigates the effectiveness of an LLM application programming interface (API) and transfer learning of LLM in tabular data classification. LLM APIs respond to input text prompts with tokenized data and instructions, whereas transfer learning finetunes an LLM for a target classification task. This paper proposes an end-to-end finetuning of LLM to demonstrate cross-data transfer learning on ten benchmark data sets when large pre-trained tabular data models do not exist to facilitate transfer learning. The proposed LLM finetuning method outperforms state-of-the-art machine and deep learning methods on tabular data with less than ten features - a standard feature size for tabular data sets. The transfer learning approach uses a fraction of the computational cost of other deep learning or API-based solutions while ensuring competitive or superior classification performance.', 'abstract_zh': '尽管人工智能（AI）革命已经展开，深度学习在处理表格数据时仍未能取得重大成功，这主要是由于特征空间的异构性和样本量有限，且缺乏有效的迁移学习机制。强大的生成式AI新时代，以大型语言模型（LLM）为动力，为多种数据和领域带来了前所未有的学习机会。本文探讨了大型语言模型应用编程接口（API）和大型语言模型迁移学习在表格数据分类中的有效性。LLM API根据输入文本提示，生成标记化数据和指令，而迁移学习则通过微调LLM来适应目标分类任务。本文提出了一种端到端的大型语言模型微调方法，旨在在大型预训练表格数据模型不存在时，实现跨数据集的迁移学习，并在特征少于十个（表格数据集标准特征大小）的数据集上取得了优于最先进的机器学习和深度学习方法的性能。此迁移学习方法的计算成本远低于其他深度学习或基于API的解决方案，同时保证了具有竞争力或更优的分类性能。', 'title_zh': '基于 finetuning 大型语言模型的表格数据迁移学习'}
{'arxiv_id': 'arXiv:2501.06862', 'title': 'LarvSeg: Exploring Image Classification Data For Large Vocabulary Semantic Segmentation via Category-wise Attentive Classifier', 'authors': 'Haojun Yu, Di Dai, Ziwei Zhao, Di He, Han Hu, Liwei Wang', 'link': 'https://arxiv.org/abs/2501.06862', 'abstract': 'Scaling up the vocabulary of semantic segmentation models is extremely challenging because annotating large-scale mask labels is labour-intensive and time-consuming. Recently, language-guided segmentation models have been proposed to address this challenge. However, their performance drops significantly when applied to out-of-distribution categories. In this paper, we propose a new large vocabulary semantic segmentation framework, called LarvSeg. Different from previous works, LarvSeg leverages image classification data to scale the vocabulary of semantic segmentation models as large-vocabulary classification datasets usually contain balanced categories and are much easier to obtain. However, for classification tasks, the category is image-level, while for segmentation we need to predict the label at pixel level. To address this issue, we first propose a general baseline framework to incorporate image-level supervision into the training process of a pixel-level segmentation model, making the trained network perform semantic segmentation on newly introduced categories in the classification data. We then observe that a model trained on segmentation data can group pixel features of categories beyond the training vocabulary. Inspired by this finding, we design a category-wise attentive classifier to apply supervision to the precise regions of corresponding categories to improve the model performance. Extensive experiments demonstrate that LarvSeg significantly improves the large vocabulary semantic segmentation performance, especially in the categories without mask labels. For the first time, we provide a 21K-category semantic segmentation model with the help of ImageNet21K. The code is available at this https URL.', 'abstract_zh': '扩大语义分割模型的词汇量极其具有挑战性，因为标注大规模掩码标签需要大量的劳力和时间。最近，语言引导的分割模型被提出以应对这一挑战。然而，当这些模型应用于未分布类别时，其性能会显著下降。本文我们提出了一种新的大规模词汇量语义分割框架，称为LarvSeg。与之前的工作不同，LarvSeg利用图像分类数据来扩展语义分割模型的词汇量，因为包含平衡类别的大规模词汇量分类数据集通常容易获取。然而，对于分类任务，类别是图像级别的，而对于分割任务，我们需要在像素级别预测标签。为了解决这一问题，我们首先提出了一种通用的基本框架，将图像级别的监督信息纳入像素级分割模型的训练过程中，从而使训练后的网络能够在分类数据中的新引入类别上执行语义分割任务。然后，我们观察到在分割数据上训练的模型能够对训练词汇之外的像素特征进行分组。受这一发现的启发，我们设计了一种类别级注意分类器，在对应的类别精确区域上应用监督，以提高模型性能。广泛的实验表明，LarvSeg显著提高了大规模词汇量语义分割的性能，尤其是在没有掩码标签的类别上。借助ImageNet21K的帮助，我们首次提供了21K类别语义分割模型。代码可在此处访问：此 https URL。', 'title_zh': 'LarvSeg：通过类别注意力分类器探索图像分类数据在大规模词汇语义分割中的应用'}
{'arxiv_id': 'arXiv:2501.06859', 'title': 'A Comprehensive Evaluation of Large Language Models on Mental Illnesses in Arabic Context', 'authors': 'Noureldin Zahran, Aya E. Fouda, Radwa J. Hanafy, Mohammed E. Fouda', 'link': 'https://arxiv.org/abs/2501.06859', 'abstract': 'Mental health disorders pose a growing public health concern in the Arab world, emphasizing the need for accessible diagnostic and intervention tools. Large language models (LLMs) offer a promising approach, but their application in Arabic contexts faces challenges including limited labeled datasets, linguistic complexity, and translation biases. This study comprehensively evaluates 8 LLMs, including general multi-lingual models, as well as bi-lingual ones, on diverse mental health datasets (such as AraDepSu, Dreaddit, MedMCQA), investigating the impact of prompt design, language configuration (native Arabic vs. translated English, and vice versa), and few-shot prompting on diagnostic performance. We find that prompt engineering significantly influences LLM scores mainly due to reduced instruction following, with our structured prompt outperforming a less structured variant on multi-class datasets, with an average difference of 14.5\\%. While language influence on performance was modest, model selection proved crucial: Phi-3.5 MoE excelled in balanced accuracy, particularly for binary classification, while Mistral NeMo showed superior performance in mean absolute error for severity prediction tasks. Few-shot prompting consistently improved performance, with particularly substantial gains observed for GPT-4o Mini on multi-class classification, boosting accuracy by an average factor of 1.58. These findings underscore the importance of prompt optimization, multilingual analysis, and few-shot learning for developing culturally sensitive and effective LLM-based mental health tools for Arabic-speaking populations.', 'abstract_zh': '阿拉伯世界中心理健康障碍问题日益凸显，强调了获取可访问的诊断和干预工具的必要性。大型语言模型（LLMs）提供了一种有前景的方法，但在阿拉伯语环境中应用这些模型面临挑战，包括标注数据不足、语言复杂性和翻译偏差。本研究全面评估了8种LLMs，包括通用多语言模型和双语模型，以多种心理健康数据集（如AraDepSu、Dreaddit、MedMCQA）为研究对象，探讨提示设计、语言配置（原生阿拉伯语与翻译后英语，反之亦然）和少量提示对诊断性能的影响。研究发现，提示工程显著影响LLM评分，主要原因是减少了指令遵循，我们的结构化提示在多类别数据集上优于不加结构的变体，平均差异为14.5%。虽然语言对性能的影响相对较小，但模型选择显得至关重要：Phi-3.5 MoE 在二元分类任务中平衡准确率表现优异，而Mistral NeMo 在预测严重程度任务中的平均绝对误差表现更优。少量提示指示在持续提高性能的同时，GPT-4o Mini 在多类别分类任务中的表现尤为显著，平均提高了1.58倍的准确率。这些发现强调了提示优化、多语言分析和少量提示学习对于开发适合阿拉伯语人群的文化敏感且有效的基于LLM的心理健康工具的重要性。', 'title_zh': '阿拉伯语背景下大型语言模型对精神疾病的全面评价'}
{'arxiv_id': 'arXiv:2501.06842', 'title': 'SPAM: Spike-Aware Adam with Momentum Reset for Stable LLM Training', 'authors': 'Tianjin Huang, Ziquan Zhu, Gaojie Jin, Lu Liu, Zhangyang Wang, Shiwei Liu', 'link': 'https://arxiv.org/abs/2501.06842', 'abstract': 'Large Language Models (LLMs) have demonstrated exceptional performance across diverse tasks, yet their training remains highly resource-intensive and susceptible to critical challenges such as training instability. A predominant source of this instability stems from gradient and loss spikes, which disrupt the learning process, often leading to costly interventions like checkpoint recovery and experiment restarts, further amplifying inefficiencies. This paper presents a comprehensive investigation into gradient spikes observed during LLM training, revealing their prevalence across multiple architectures and datasets. Our analysis shows that these spikes can be up to $1000\\times$ larger than typical gradients, substantially deteriorating model performance. To address this issue, we propose Spike-Aware Adam with Momentum Reset SPAM, a novel optimizer designed to counteract gradient spikes through momentum reset and spike-aware gradient clipping. Extensive experiments, including both pre-training and fine-tuning, demonstrate that SPAM consistently surpasses Adam and its variants across various tasks, including (1) LLM pre-training from 60M to 1B, (2) 4-bit LLM pre-training,(3) reinforcement learning, and (4) Time Series Forecasting. Additionally, SPAM facilitates memory-efficient training by enabling sparse momentum, where only a subset of momentum terms are maintained and updated. When operating under memory constraints, SPAM outperforms state-of-the-art memory-efficient optimizers such as GaLore and Adam-Mini. Our work underscores the importance of mitigating gradient spikes in LLM training and introduces an effective optimization strategy that enhances both training stability and resource efficiency at scale. Code is available at this https URL', 'abstract_zh': '大规模语言模型（LLMs）在多种任务中表现出色，但其训练过程依然高度资源密集，并且容易受到训练不稳定性等关键挑战的影响。这种不稳定性主要源自梯度和损失峰值，这会破坏学习过程，常常导致耗时的干预措施，如检查点恢复和实验重启，进一步加剧了不效率。本文对LLM训练过程中观察到的梯度峰值进行了全面研究，揭示了这些峰值在多个架构和数据集中普遍存在的情况。我们的分析表明，这些峰值可能比常规梯度大1000倍，严重恶化了模型性能。为了解决这个问题，我们提出了一种名为SPAM（带有动量重置的感知峰值优化器）的新型优化器，它通过动量重置和感知峰值的梯度剪裁来对抗梯度峰值。广泛的实验，包括预训练和微调，表明在各种任务中，SPAM始终优于Adam及其变体，包括（1）从60M到1B的LLM预训练；（2）4位LLM预训练；（3）强化学习；和（4）时间序列预测。此外，SPAM通过启用稀疏动量来实现内存高效的训练，即仅维护和更新动量项的子集。在内存受限的情况下，SPAM超越了诸如GaLore和Adam-Mini等最先进的内存高效优化器。我们的工作强调了在LLM训练中减轻梯度峰值的重要性，并提供了一种有效的优化策略，该策略在大规模训练中提高了训练稳定性和资源效率。相关代码可在以下链接访问：[此处提供链接]', 'title_zh': 'SPAM：带脉冲意识动量重置的Adam优化器在稳定大规模语言模型训练中的应用'}
{'arxiv_id': 'arXiv:2501.06831', 'title': 'Towards Counterfactual and Contrastive Explainability and Transparency of DCNN Image Classifiers', 'authors': 'Syed Ali Tariq, Tehseen Zia, Mubeen Ghafoor', 'link': 'https://arxiv.org/abs/2501.06831', 'abstract': "Explainability of deep convolutional neural networks (DCNNs) is an important research topic that tries to uncover the reasons behind a DCNN model's decisions and improve their understanding and reliability in high-risk environments. In this regard, we propose a novel method for generating interpretable counterfactual and contrastive explanations for DCNN models. The proposed method is model intrusive that probes the internal workings of a DCNN instead of altering the input image to generate explanations. Given an input image, we provide contrastive explanations by identifying the most important filters in the DCNN representing features and concepts that separate the model's decision between classifying the image to the original inferred class or some other specified alter class. On the other hand, we provide counterfactual explanations by specifying the minimal changes necessary in such filters so that a contrastive output is obtained.\nUsing these identified filters and concepts, our method can provide contrastive and counterfactual reasons behind a model's decisions and makes the model more transparent. One of the interesting applications of this method is misclassification analysis, where we compare the identified concepts from a particular input image and compare them with class-specific concepts to establish the validity of the model's decisions. The proposed method is compared with state-of-the-art and evaluated on the Caltech-UCSD Birds (CUB) 2011 dataset to show the usefulness of the explanations provided.", 'abstract_zh': '深度卷积神经网络（DCNN）的解释性是一个重要的研究主题，旨在揭示DCNN模型决策背后的缘由，并在高风险环境中提高其理解和可靠性。为此，我们提出了一种新颖的方法，用于为DCNN模型生成可解释的对比性和对比性解释。所提出的方法是模型侵入性的，它探查DCNN的内部工作机制，而不是通过修改输入图像来生成解释。给定一个输入图像，我们通过识别表示区分模型分类结果（将图像分类为原始推断类或某些其他指定的替代类）的特征和概念最重要的滤波器，来提供对比性解释。另一方面，通过规定这些滤波器所需的最小变化，以获得对比性输出，来提供对比性解释。\n\n通过这些识别出的滤波器和概念，我们的方法可以提供模型决策背后的对比性和对比性原因，从而使模型更加透明。这种方法的一个有趣应用是错误分类分析，在该应用中，我们将特定输入图像中识别出的概念与类特定概念进行比较，以验证模型决策的有效性。我们还与最先进的方法进行了比较，并在Caltech-UCSD鸟类（CUB）2011数据集上进行评估，以展示所提解释的有用性。', 'title_zh': '面向DCNN图像分类器的反事实与对比可解释性和透明度研究'}
{'arxiv_id': 'arXiv:2501.06823', 'title': 'MEXA-CTP: Mode Experts Cross-Attention for Clinical Trial Outcome Prediction', 'authors': 'Yiqing Zhang, Xiaozhong Liu, Fabricio Murai', 'link': 'https://arxiv.org/abs/2501.06823', 'abstract': 'Clinical trials are the gold standard for assessing the effectiveness and safety of drugs for treating diseases. Given the vast design space of drug molecules, elevated financial cost, and multi-year timeline of these trials, research on clinical trial outcome prediction has gained immense traction. Accurate predictions must leverage data of diverse modes such as drug molecules, target diseases, and eligibility criteria to infer successes and failures. Previous Deep Learning approaches for this task, such as HINT, often require wet lab data from synthesized molecules and/or rely on prior knowledge to encode interactions as part of the model architecture. To address these limitations, we propose a light-weight attention-based model, MEXA-CTP, to integrate readily-available multi-modal data and generate effective representations via specialized modules dubbed "mode experts", while avoiding human biases in model design. We optimize MEXA-CTP with the Cauchy loss to capture relevant interactions across modes. Our experiments on the Trial Outcome Prediction (TOP) benchmark demonstrate that MEXA-CTP improves upon existing approaches by, respectively, up to 11.3% in F1 score, 12.2% in PR-AUC, and 2.5% in ROC-AUC, compared to HINT. Ablation studies are provided to quantify the effectiveness of each component in our proposed method.', 'abstract_zh': '临床试验是评估治疗疾病药物的有效性和安全性的金标准。鉴于药物分子设计空间宽广、高昂的财务成本以及多年的研究时间，临床试验结果预测的研究已获得极大的关注。准确的预测必须利用包括药物分子、目标疾病以及入组标准等多种模式的数据，以推断试验的成功与失败。先前针对这一任务的深度学习方法，如HINT，往往需要来自合成分子的湿实验室数据，并且常依赖于先验知识来编码相互作用作为模型架构的一部分。为了解决这些限制，我们提出了一种轻量级的基于注意力机制的模型MEXA-CTP，该模型能够整合现成的多种模式数据，并通过所谓的“模式专家”模块生成有效的表示，同时避免了在模型设计中的人为偏见。我们使用Cauchy损失优化MEXA-CTP，以捕捉不同模式之间的相关交互。我们在Trial Outcome Prediction (TOP)数据集上的实验表明，与HINT相比，MEXA-CTP分别在F1分数、PR-AUC和ROC-AUC上提高了最多11.3%、12.2%和2.5%。我们还提供了消融研究来量化我们提出的方法中每个组件的有效性。', 'title_zh': 'MEXA-CTP: 模式专家跨注意力在临床试验结果预测中的应用'}
{'arxiv_id': 'arXiv:2501.06795', 'title': 'Bridging the Fairness Gap: Enhancing Pre-trained Models with LLM-Generated Sentences', 'authors': 'Liu Yu, Ludie Guo, Ping Kuang, Fan Zhou', 'link': 'https://arxiv.org/abs/2501.06795', 'abstract': 'Pre-trained language models (PLMs) are trained on data that inherently contains gender biases, leading to undesirable impacts. Traditional debiasing methods often rely on external corpora, which may lack quality, diversity, or demographic balance, affecting the effectiveness of debiasing. With the rise of large language models and their extensive knowledge, we propose enhancing fairness (Fair-Gender) in PLMs by absorbing coherent, attribute-balanced, and semantically rich sentences. However, these sentences cannot be directly used for debiasing due to alignment issues and the risk of negative transfer. We address this by applying causal analysis to estimate causal effects, filtering out unaligned sentences, and identifying aligned ones for incorporation into PLMs, thereby ensuring positive transfer. Experiments show that our approach significantly reduces gender biases in PLMs while preserving their language expressiveness.', 'abstract_zh': '预训练语言模型（PLMs）在训练过程中通常会包含固有的性别偏见，这会导致不良影响。传统的去偏见方法往往依赖外部语料库，而这些外部语料库可能在质量、多样性和人口统计学平衡方面存在不足，从而影响去偏见的有效性。随着大规模语言模型的兴起及其广泛的知识覆盖，我们提出通过吸收一致、属性平衡且语义丰富的句子来增强PLMs的公平性（Fair-Gender）。然而，这些句子不能直接用于去偏见，因为这可能会导致对齐问题和负向迁移的风险。为此，我们采用因果分析估计因果效应，过滤掉对齐不上的句子，并确定对齐的句子以融入PLMs，从而确保正向迁移。实验结果表明，我们的方法能够在显著减少PLMs中的性别偏见的同时，保持其语言表达能力。', 'title_zh': '填补公平性差距：通过LLM生成的句子提升预训练模型'}
{'arxiv_id': 'arXiv:2501.06787', 'title': 'Improving Pain Classification using Spatio-Temporal Deep Learning Approaches with Facial Expressions', 'authors': 'Aafaf Ridouan, Amine Bohi, Youssef Mourchid', 'link': 'https://arxiv.org/abs/2501.06787', 'abstract': 'Pain management and severity detection are crucial for effective treatment, yet traditional self-reporting methods are subjective and may be unsuitable for non-verbal individuals (people with limited speaking skills). To address this limitation, we explore automated pain detection using facial expressions. Our study leverages deep learning techniques to improve pain assessment by analyzing facial images from the Pain Emotion Faces Database (PEMF). We propose two novel approaches1: (1) a hybrid ConvNeXt model combined with Long Short-Term Memory (LSTM) blocks to analyze video frames and predict pain presence, and (2) a Spatio-Temporal Graph Convolution Network (STGCN) integrated with LSTM to process landmarks from facial images for pain detection. Our work represents the first use of the PEMF dataset for binary pain classification and demonstrates the effectiveness of these models through extensive experimentation. The results highlight the potential of combining spatial and temporal features for enhanced pain detection, offering a promising advancement in objective pain assessment methodologies.', 'abstract_zh': '疼痛管理与严重程度检测对于有效的治疗至关重要，然而传统的自我报告方法具有主观性，并可能不适合非言语个体（指言语能力有限的人）。为解决这一限制，我们探索使用面部表情进行自动疼痛检测的方法。本研究利用深度学习技术，通过分析来自Pain Emotion Faces Database（PEMF数据库）的面部图像来提高疼痛评估的准确性。我们提出两种新颖的方法：（1）结合ConvNeXt模型与长短期记忆（LSTM）模块的混合模型，用于分析视频帧并预测疼痛的存在；（2）将Spatio-Temporal Graph Convolution Network（STGCN）与LSTM结合，处理面部图像中的关键点进行疼痛检测。我们的工作首次使用PEMF数据集进行二元疼痛分类，并通过广泛的实验展示了这些模型的有效性。结果强调了结合空间和时间特征在提高疼痛检测准确性中的潜力，为客观疼痛评估方法的发展提供了有前景的进展。', 'title_zh': '使用面部表情的时空深度学习方法改进疼痛分类'}
{'arxiv_id': 'arXiv:2501.06783', 'title': 'Cost-Effective Robotic Handwriting System with AI Integration', 'authors': 'Tianyi Huang, Richard Xiong', 'link': 'https://arxiv.org/abs/2501.06783', 'abstract': 'This paper introduces a cost-effective robotic handwriting system designed to replicate human-like handwriting with high precision. Combining a Raspberry Pi Pico microcontroller, 3D-printed components, and a machine learning-based handwriting generation model implemented via this http URL, the system converts user-supplied text into realistic stroke trajectories. By leveraging lightweight 3D-printed materials and efficient mechanical designs, the system achieves a total hardware cost of approximately \\$56, significantly undercutting commercial alternatives. Experimental evaluations demonstrate handwriting precision within $\\pm$0.3 millimeters and a writing speed of approximately 200 mm/min, positioning the system as a viable solution for educational, research, and assistive applications. This study seeks to lower the barriers to personalized handwriting technologies, making them accessible to a broader audience.', 'abstract_zh': '本文介绍了成本效益高的机器人书写系统，该系统旨在以高精度复制类人的书写。该系统结合使用了Raspberry Pi Pico微控制器、3D打印组件以及通过此链接（https://this.url/）实现的基于机器学习的书写生成模型，能够将用户提供的文本转换为逼真的笔画轨迹。通过利用轻量级的3D打印材料和高效的机械设计，该系统实现了总硬件成本约为56美元，远低于商用替代品的成本。实验评估表明，该系统的书写精度在±0.3毫米范围内，书写速度约为200毫米/分钟，使其成为教育、研究和辅助应用中的可行解决方案。本研究旨在降低个性化书写技术的门槛，使其更广泛地应用于不同群体。', 'title_zh': '具有AI集成的经济高效的手写机器人系统'}
{'arxiv_id': 'arXiv:2501.06749', 'title': 'Static Segmentation by Tracking: A Frustratingly Label-Efficient Approach to Fine-Grained Segmentation', 'authors': 'Zhenyang Feng, Zihe Wang, Saul Ibaven Bueno, Tomasz Frelek, Advikaa Ramesh, Jingyan Bai, Lemeng Wang, Zanming Huang, Jianyang Gu, Jinsu Yoo, Tai-Yu Pan, Arpita Chowdhury, Michelle Ramirez, Elizabeth G. Campolongo, Matthew J. Thompson, Christopher G. Lawrence, Sydne Record, Neil Rosser, Anuj Karpatne, Daniel Rubenstein, Hilmar Lapp, Charles V. Stewart, Tanya Berger-Wolf, Yu Su, Wei-Lun Chao', 'link': 'https://arxiv.org/abs/2501.06749', 'abstract': "We study image segmentation in the biological domain, particularly trait and part segmentation from specimen images (e.g., butterfly wing stripes or beetle body parts). This is a crucial, fine-grained task that aids in understanding the biology of organisms. The conventional approach involves hand-labeling masks, often for hundreds of images per species, and training a segmentation model to generalize these labels to other images, which can be exceedingly laborious. We present a label-efficient method named Static Segmentation by Tracking (SST). SST is built upon the insight: while specimens of the same species have inherent variations, the traits and parts we aim to segment show up consistently. This motivates us to concatenate specimen images into a ``pseudo-video'' and reframe trait and part segmentation as a tracking problem. Concretely, SST generates masks for unlabeled images by propagating annotated or predicted masks from the ``pseudo-preceding'' images. Powered by Segment Anything Model 2 (SAM~2) initially developed for video segmentation, we show that SST can achieve high-quality trait and part segmentation with merely one labeled image per species -- a breakthrough for analyzing specimen images. We further develop a cycle-consistent loss to fine-tune the model, again using one labeled image. Additionally, we highlight the broader potential of SST, including one-shot instance segmentation on images taken in the wild and trait-based image retrieval.", 'abstract_zh': '我们研究生物领域的图像分割问题，尤其是从标本图像（例如蝴蝶翅膀条纹或甲虫身体部分）中进行性状和部分分割。这是一个关键性的精细任务，有助于深入了解生物体的生物学特性。传统的做法是人工标注掩模，通常需要为每个物种标注数百张图像，然后训练分割模型将这些标签泛化到其他图像，这过程非常耗时。我们提出了一种高效标注方法，称为静态分割跟踪（Static Segmentation by Tracking，SST）。SST 是建立在如下洞察之上的：虽然同种生物标本存在固有的差异，但我们希望分割的性状和部分在标本图像中是一致出现的。这促使我们将标本图像拼接成一个“伪视频”，并将性状和部分分割重新定义为一个跟踪问题。具体而言，SST 通过从“伪前一帧”图像传播标注或预测掩模来为未标注图像生成掩模。得益于最初为视频分割开发的 Segment Anything Model 2（SAM2），我们展示了一种方法，即使每个物种仅使用一张标注图像也能实现高质量的性状和部分分割——这是一个分析标本图像的突破性进展。此外，我们进一步开发了一种循环一致性的损失函数，利用一张标注图像对模型进行微调。同时，我们还强调了SST更广泛的应用潜力，包括野生环境拍摄图像的一次性实例分割，以及基于性状的图像检索。', 'title_zh': '静态分割跟踪：一种令人沮丧的标注高效方法用于细粒度分割'}
{'arxiv_id': 'arXiv:2501.06720', 'title': 'Multi-Label Scene Classification in Remote Sensing Benefits from Image Super-Resolution', 'authors': 'Ashitha Mudraje, Brian B. Moser, Stanislav Frolov, Andreas Dengel', 'link': 'https://arxiv.org/abs/2501.06720', 'abstract': 'Satellite imagery is a cornerstone for numerous Remote Sensing (RS) applications; however, limited spatial resolution frequently hinders the precision of such systems, especially in multi-label scene classification tasks as it requires a higher level of detail and feature differentiation. In this study, we explore the efficacy of image Super-Resolution (SR) as a pre-processing step to enhance the quality of satellite images and thus improve downstream classification performance. We investigate four SR models - SRResNet, HAT, SeeSR, and RealESRGAN - and evaluate their impact on multi-label scene classification across various CNN architectures, including ResNet-50, ResNet-101, ResNet-152, and Inception-v4. Our results show that applying SR significantly improves downstream classification performance across various metrics, demonstrating its ability to preserve spatial details critical for multi-label tasks. Overall, this work offers valuable insights into the selection of SR techniques for multi-label prediction in remote sensing and presents an easy-to-integrate framework to improve existing RS systems.', 'abstract_zh': '遥感（RS）应用的基础是卫星图像；然而，有限的空间分辨率常常阻碍了这些系统的精度，特别是在需要更高细节和特征区分的多标签场景分类任务中。本研究探讨了图像超分辨率（SR）作为预处理步骤的有效性，以提高卫星图像的质量并从而提升下游分类性能。我们研究了四种超分辨率模型——SRResNet、HAT、SeeSR 和 RealESRGAN，并评估了它们在不同卷积神经网络（CNN）架构下的多标签场景分类中的影响，包括 ResNet-50、ResNet-101、ResNet-152 和 Inception-v4。研究结果表明，应用超分辨率显著提高了不同评估指标下的下游分类性能，展示了其在多标签任务中保留空间细节的能力。总体而言，本研究为遥感中的多标签预测选择超分辨率技术提供了有价值的见解，并提出了一个易于集成的框架以改进现有的遥感系统。', 'title_zh': '遥感中的多标签场景分类可以从图像超分辨率中受益'}
{'arxiv_id': 'arXiv:2501.06715', 'title': 'ZNO-Eval: Benchmarking reasoning capabilities of large language models in Ukrainian', 'authors': 'Mykyta Syromiatnikov, Victoria Ruvinskaya, Anastasiya Troynina', 'link': 'https://arxiv.org/abs/2501.06715', 'abstract': "As the usage of large language models for problems outside of simple text understanding or generation increases, assessing their abilities and limitations becomes crucial. While significant progress has been made in this area over the last few years, most research has focused on benchmarking English, leaving other languages underexplored. This makes evaluating the reasoning and robustness level of language models in Ukrainian particularly challenging. The purpose of this work is to establish a comprehensive benchmark for the reasoning capabilities evaluation of large language models in the Ukrainian language. This paper presents the ZNO-Eval benchmark based on real exam tasks from Ukraine's standardized educational testing system: the External Independent Evaluation and the National Multi-subject Test. With single-answer options, multiple-choice, matching, and open-ended questions from diverse subjects, including Ukrainian language, mathematics, history, and geography, this dataset paves the way toward a thorough analysis of reasoning capabilities across different domains and complexities. Evaluation of several well-known language models, such as GPT-3.5-Turbo, GPT-4o, GPT-4-Turbo, Mistral Large, Claude 3 Opus, and Gemini-1.5 Pro on this benchmark demonstrated the superiority of GPT-4o in both common knowledge reasoning and intricate language tasks. At the same time, Gemini Pro and GPT-4 Turbo excelled in the arithmetic domain, leading in single-answer and open-ended math problems. While all models were close to max performance in text-only common knowledge tasks like history and geography, there still is a gap for Ukrainian language and math, thus highlighting the importance of developing specialized language benchmarks for more accurate assessments of model capabilities and limitations across different languages and contexts.", 'abstract_zh': '随着大型语言模型在简单文本理解和生成之外的问题上的应用增加，评估它们的能力和局限性变得至关重要。在过去几年中，在这个领域已经取得显著进展，但大多数研究主要集中在英语基准测试上，而其他语言则相对未被充分探索。这使得评估乌克兰语语言模型的推理能力和稳健性变得尤为具有挑战性。本项工作旨在建立一个全面的基准，用于评估大型语言模型在乌克兰语中的推理能力。本文介绍了基于乌克兰标准化教育考试系统（即外延独立评估和全国多学科测试）的真实考试任务建立的ZNO-Eval基准。该数据集包含多个选择题、匹配题、开放式问答以及来自不同学科（包括乌克兰语、数学、历史和地理）的问题，为全面分析不同领域和复杂性的推理能力奠定了基础。对几个知名语言模型（如GPT-3.5-Turbo、GPT-4o、GPT-4-Turbo、Mistral Large、Claude 3 Opus 和 Gemini-1.5 Pro）的评价结果显示，GPT-4o 在常识推理和复杂语言任务上表现出色。同时，Gemini Pro 和 GPT-4 Turbo 在算术领域表现出色，特别是在单一答案和开放式数学问题上居于领先地位。尽管所有模型在仅涉及文本的历史和地理知识任务中接近最大性能，但在乌克兰语和数学方面仍存在差距，这突显了为不同语言和上下文开发专门语言基准的重要性，以更准确地评估模型能力和局限性。', 'title_zh': 'ZNO-Eval：评估大型语言模型在乌克兰语中的推理能力'}
{'arxiv_id': 'arXiv:2501.06710', 'title': 'Multi-task Visual Grounding with Coarse-to-Fine Consistency Constraints', 'authors': 'Ming Dai, Jian Li, Jiedong Zhuang, Xian Zhang, Wankou Yang', 'link': 'https://arxiv.org/abs/2501.06710', 'abstract': 'Multi-task visual grounding involves the simultaneous execution of localization and segmentation in images based on textual expressions. The majority of advanced methods predominantly focus on transformer-based multimodal fusion, aiming to extract robust multimodal representations. However, ambiguity between referring expression comprehension (REC) and referring image segmentation (RIS) is error-prone, leading to inconsistencies between multi-task predictions. Besides, insufficient multimodal understanding directly contributes to biased target perception. To overcome these challenges, we propose a Coarse-to-fine Consistency Constraints Visual Grounding architecture ($\\text{C}^3\\text{VG}$), which integrates implicit and explicit modeling approaches within a two-stage framework. Initially, query and pixel decoders are employed to generate preliminary detection and segmentation outputs, a process referred to as the Rough Semantic Perception (RSP) stage. These coarse predictions are subsequently refined through the proposed Mask-guided Interaction Module (MIM) and a novel explicit bidirectional consistency constraint loss to ensure consistent representations across tasks, which we term the Refined Consistency Interaction (RCI) stage. Furthermore, to address the challenge of insufficient multimodal understanding, we leverage pre-trained models based on visual-linguistic fusion representations. Empirical evaluations on the RefCOCO, RefCOCO+, and RefCOCOg datasets demonstrate the efficacy and soundness of $\\text{C}^3\\text{VG}$, which significantly outperforms state-of-the-art REC and RIS methods by a substantial margin. Code and model will be available at \\url{this https URL}.', 'abstract_zh': '多任务视觉接地涉及基于文本表达在同一图像中同时执行定位和分割。大多数先进的方法主要集中在基于转换器的多模态融合上，旨在提取稳健的多模态表示。然而，识别表达理解（REC）与参考图像分割（RIS）之间的歧义容易导致多任务预测之间的不一致。此外，不充分的多模态理解直接导致目标感知的偏见。为克服这些挑战，我们提出了一种从粗糙到精细的一致性约束视觉接地架构（$\\text{C}^3\\text{VG}$），该架构在一个两阶段框架内集成了隐式和显式的建模方法。首先，通过查询解码器和像素解码器生成初步的检测和分割输出，这一过程称为粗糙语义感知（RSP）阶段。随后，通过提出的掩膜引导交互模块（MIM）和一种新颖的显式双向一致性约束损失来细化这些粗糙预测，以确保任务间的一致表示，我们称之为精细一致性交互（RCI）阶段。此外，为解决多模态理解不足的挑战，我们利用基于视觉语言融合表示的预训练模型。在RefCOCO、RefCOCO+和RefCOCOg数据集上的实证评估表明，$\\text{C}^3\\text{VG}$ 的有效性和可靠性，其性能显著优于最先进的REC和RIS方法。代码和模型将在 \\url{this https URL} 提供。', 'title_zh': '从粗到细一致性约束的多任务视觉定位'}
{'arxiv_id': 'arXiv:2501.06708', 'title': 'Evaluating Sample Utility for Data Selection by Mimicking Model Weights', 'authors': 'Tzu-Heng Huang, Manjot Bilkhu, Frederic Sala, Javier Movellan', 'link': 'https://arxiv.org/abs/2501.06708', 'abstract': "Foundation models rely on large-scale web-crawled datasets, which frequently contain noisy data, biases, and irrelevant content. Existing data selection techniques typically use human heuristics, downstream evaluation datasets, or specialized scoring models, and can overlook samples' utility in the training process. Instead, we propose a new approach, Mimic Score, a data quality metric that uses a pretrained reference model as a guide to assess the usefulness of data samples for training a new model. It relies on the alignment between the gradient of the new model parameters and the vector pointing toward the reference model in weight space. Samples that misalign with this direction are considered low-value and can be filtered out. Motivated by the Mimic score, we develop Grad-Mimic, a data selection framework that identifies and prioritizes useful samples, automating the selection process to create effective filters. Empirically, using Mimic scores to guide model training results in consistent performance gains across six image datasets and enhances the performance of CLIP models. Moreover, Mimic scores and their associated filters improve upon existing filtering methods and offer accurate estimation of dataset quality.", 'abstract_zh': '基础模型依赖于大规模网络爬取的数据集，这些数据集经常包含噪声、偏差和无关内容。现有的数据选择技术通常使用人工启发式方法、下游评估数据集或专门的评分模型，但在训练过程中可能会忽视样本的实际有用性。与此不同，我们提出了一种新的方法——Mimic评分，这是一种数据质量度量标准，它利用预训练的参考模型作为指南，评估数据样本对训练新模型的有用性。这种方法依赖于新模型参数梯度与权重空间中指向参考模型的方向向量之间的对齐。与这个方向不一致的样本被认为是低价值的，并可以被过滤掉。受Mimic评分的启发，我们开发了一种数据选择框架Grad-Mimic，该框架能够识别和优先选择有用的样本，从而自动完成选择过程，创建有效的过滤器。实证结果表明，使用Mimic评分来指导模型训练在六个图像数据集中产生了一致性的性能提升，并提高了CLIP模型的性能。此外，Mimic评分及其相关的过滤器优于现有的过滤方法，能够提供数据集质量的准确估计。', 'title_zh': '通过模仿模型权重评估样本 utility 以进行数据选择'}
{'arxiv_id': 'arXiv:2501.06697', 'title': 'Mamba-MOC: A Multicategory Remote Object Counting via State Space Model', 'authors': 'Peng Liu, Sen Lei, Heng-Chao Li', 'link': 'https://arxiv.org/abs/2501.06697', 'abstract': 'Multicategory remote object counting is a fundamental task in computer vision, aimed at accurately estimating the number of objects of various categories in remote images. Existing methods rely on CNNs and Transformers, but CNNs struggle to capture global dependencies, and Transformers are computationally expensive, which limits their effectiveness in remote applications. Recently, Mamba has emerged as a promising solution in the field of computer vision, offering a linear complexity for modeling global dependencies. To this end, we propose Mamba-MOC, a mamba-based network designed for multi-category remote object counting, which represents the first application of Mamba to remote sensing object counting. Specifically, we propose a cross-scale interaction module to facilitate the deep integration of hierarchical features. Then we design a context state space model to capture both global and local contextual information and provide local neighborhood information during the scan process. Experimental results in large-scale realistic scenarios demonstrate that our proposed method achieves state-of-the-art performance compared with some mainstream counting algorithms.', 'abstract_zh': '多类别遥感目标计数是计算机视觉中的一个基础任务，旨在准确估计遥感图像中各种类别的目标数量。现有方法依赖于卷积神经网络（CNNs）和变换器（Transformers），但CNNs在捕捉全局依赖关系方面遇到困难，而Transformers计算成本高，这限制了其在遥感应用中的效果。最近，Mamba在计算机视觉领域 emerged 作为一种有前景的解决方案，提供了建模全局依赖关系的线性复杂度。为此，我们提出了Mamba-MOC，这是一种基于Mamba的网络，专门用于多类别遥感目标计数，是Mamba首次应用于遥感目标计数。具体而言，我们提出了一种跨尺度交互模块，以促进层次特征的深度整合。然后，我们设计了一种上下文状态空间模型，以捕获全局和局部上下文信息，在扫描过程中提供局部邻域信息。在大规模现实场景中的实验结果表明，我们提出的方法在与一些主流计数算法相比时达到了最先进的性能。', 'title_zh': '马amba-MOC：基于状态空间模型的多类别远程对象计数'}
{'arxiv_id': 'arXiv:2501.06692', 'title': 'PGP-SAM: Prototype-Guided Prompt Learning for Efficient Few-Shot Medical Image Segmentation', 'authors': 'Zhonghao Yan, Zijin Yin, Tianyu Lin, Xiangzhu Zeng, Kongming Liang, Zhanyu Ma', 'link': 'https://arxiv.org/abs/2501.06692', 'abstract': 'The Segment Anything Model (SAM) has demonstrated strong and versatile segmentation capabilities, along with intuitive prompt-based interactions. However, customizing SAM for medical image segmentation requires massive amounts of pixel-level annotations and precise point- or box-based prompt designs. To address these challenges, we introduce PGP-SAM, a novel prototype-based few-shot tuning approach that uses limited samples to replace tedious manual prompts. Our key idea is to leverage inter- and intra-class prototypes to capture class-specific knowledge and relationships. We propose two main components: (1) a plug-and-play contextual modulation module that integrates multi-scale information, and (2) a class-guided cross-attention mechanism that fuses prototypes and features for automatic prompt generation. Experiments on a public multi-organ dataset and a private ventricle dataset demonstrate that PGP-SAM achieves superior mean Dice scores compared with existing prompt-free SAM variants, while using only 10\\% of the 2D slices.', 'abstract_zh': '段落内容翻译如下，符合学术规范：\n\n段Anything模型（SAM）显示出强大的多任务分割能力，并具备直观的提示交互功能。然而，将SAM定制应用于医学图像分割需要大量的像素级注释和精确的基于点或框的提示设计。为应对这些挑战，我们引入了一种名为PGP-SAM的新颖原型导向的少样本调优方法，该方法通过有限样本替代繁琐的手动提示。我们的核心思想是利用跨类和同类原型来捕捉特定类别的知识和关系。我们提出了两种主要组件：（1）一个插件式的上下文调制模块，能够整合多尺度信息，并（2）一个基于类别的跨注意力机制，该机制能够结合原型和特征进行自动提示生成。在公共多器官数据集和私人心室数据集上的实验表明，与现有的无提示SAM变体相比，PGP-SAM在仅使用2D切片的10%的情况下，实现了更高的平均Dice分数。', 'title_zh': 'PGP-SAM：原型导向的提示学习方法在高效的医疗图像分割Few-Shot场景中的应用'}
{'arxiv_id': 'arXiv:2501.06680', 'title': 'Application of Vision-Language Model to Pedestrians Behavior and Scene Understanding in Autonomous Driving', 'authors': 'Haoxiang Gao, Yu Zhao', 'link': 'https://arxiv.org/abs/2501.06680', 'abstract': "Autonomous driving (AD) has experienced significant improvements in recent years and achieved promising 3D detection, classification, and localization results. However, many challenges remain, e.g. semantic understanding of pedestrians' behaviors, and downstream handling for pedestrian interactions. Recent studies in applications of Large Language Models (LLM) and Vision-Language Models (VLM) have achieved promising results in scene understanding and high-level maneuver planning in diverse traffic scenarios. However, deploying the billion-parameter LLMs to vehicles requires significant computation and memory resources. In this paper, we analyzed effective knowledge distillation of semantic labels to smaller Vision networks, which can be used for the semantic representation of complex scenes for downstream decision-making for planning and control.", 'abstract_zh': '近年来，自动驾驶（AD）取得了显著的进步，实现了有前景的3D检测、分类和定位结果。然而，仍存在许多挑战，如对行人行为的语义理解以及处理行人交互问题。近年来，大型语言模型（LLM）和视觉-语言模型（VLM）在多样交通场景下的场景理解及高级机动规划方面取得了显著成果。然而，将包含十亿参数的LLM部署到车辆中需要大量计算和内存资源。本文分析了将语义标签有效知识蒸馏至较小的视觉网络的方法，这些网络可以用于复杂场景的语义表示及后续的决策规划。', 'title_zh': '将下面的论文内容或标题翻译成中文，应符合学术规范如下：\n\n基于视觉-语言模型的行人行为识别与场景理解在自动驾驶中的应用\n\n这一翻译简洁明了，适用于学术论文标题或摘要。'}
{'arxiv_id': 'arXiv:2501.06678', 'title': 'Imbalanced Medical Image Segmentation with Pixel-dependent Noisy Labels', 'authors': 'Erjian Guo, Zicheng Wang, Zhen Zhao, Luping Zhou', 'link': 'https://arxiv.org/abs/2501.06678', 'abstract': 'Accurate medical image segmentation is often hindered by noisy labels in training data, due to the challenges of annotating medical images. Prior research works addressing noisy labels tend to make class-dependent assumptions, overlooking the pixel-dependent nature of most noisy labels. Furthermore, existing methods typically apply fixed thresholds to filter out noisy labels, risking the removal of minority classes and consequently degrading segmentation performance. To bridge these gaps, our proposed framework, Collaborative Learning with Curriculum Selection (CLCS), addresses pixel-dependent noisy labels with class imbalance. CLCS advances the existing works by i) treating noisy labels as pixel-dependent and addressing them through a collaborative learning framework, and ii) employing a curriculum dynamic thresholding approach adapting to model learning progress to select clean data samples to mitigate the class imbalance issue, and iii) applying a noise balance loss to noisy data samples to improve data utilization instead of discarding them outright. Specifically, our CLCS contains two modules: Curriculum Noisy Label Sample Selection (CNS) and Noise Balance Loss (NBL). In the CNS module, we designed a two-branch network with discrepancy loss for collaborative learning so that different feature representations of the same instance could be extracted from distinct views and used to vote the class probabilities of pixels. Besides, a curriculum dynamic threshold is adopted to select clean-label samples through probability voting. In the NBL module, instead of directly dropping the suspiciously noisy labels, we further adopt a robust loss to leverage such instances to boost the performance.', 'abstract_zh': '准确的医学图像分割经常受到训练数据中噪声标签的阻碍，因为标注医学图像具有挑战性。此前处理噪声标签的研究工作倾向于做出类依赖性的假设，忽视了大多数噪声标签的像素依赖性特征。此外，现有方法通常采用固定的阈值来过滤噪声标签，这可能导致少数类样本被移除，从而降低分割性能。为弥补这些不足，我们提出了卒业学习与课程选取（CLCS）框架，以解决类不平衡的像素依赖性噪声标签问题。CLCS 比较现有方法前进了一步，主要包括：i) 将噪声标签视为像素依赖性的，并通过协同学习框架来解决；ii) 采用适应模型学习进展的课程动态阈值法来选择干净标签样本，以缓解类不平衡问题；iii) 应用噪声平衡损失到噪声数据样本中，以提高数据利用率，而不是直接丢弃这些样本。具体而言，我们的 CLCS 包含两个模块：课程噪声标签样本选择 (CNS) 和噪声平衡损失 (NBL)。在 CNS 模块中，我们设计了一个带有差异性损失的双分支网络以进行协同学习，从而可以从不同视角提取同一实例的不同特征表示并用于投票像素的类概率。此外，采用课程动态阈值通过概率投票选择干净标签样本。在 NBL 模块中，我们不仅不直接丢弃可疑的噪声标签，还进一步采用鲁棒损失来利用这些实例以提升性能。', 'title_zh': '基于像素依赖性噪声标签的医学图像不均衡分割方法'}
{'arxiv_id': 'arXiv:2501.06645', 'title': 'FocalPO: Enhancing Preference Optimizing by Focusing on Correct Preference Rankings', 'authors': 'Tong Liu, Xiao Yu, Wenxuan Zhou, Jindong Gu, Volker Tresp', 'link': 'https://arxiv.org/abs/2501.06645', 'abstract': "Efficient preference optimization algorithms such as Direct Preference Optimization (DPO) have become a popular approach in aligning large language models (LLMs) with human preferences. These algorithms implicitly treat the LLM as a reward model, and focus on training it to correct misranked preference pairs. However, recent work~\\citep{chen2024preference} empirically finds that DPO training \\textit{rarely improves these misranked preference pairs}, despite its gradient emphasizing on these cases. We introduce FocalPO, a DPO variant that instead \\textit{down-weighs} misranked preference pairs and prioritizes enhancing the model's understanding of pairs that it can already rank correctly. Inspired by Focal Loss used in vision tasks, FocalPO achieves this by adding a modulating factor to dynamically scale DPO loss. Our experiment demonstrates that FocalPO surpasses DPO and its variants on popular benchmarks like Alpaca Eval 2.0 using Mistral-Base-7B and Llama-3-Instruct-8B. Additionally, we empirically reveals how FocalPO affects training on correct and incorrect sample groups, further underscoring its effectiveness.", 'abstract_zh': '高效偏好优化算法，如直接偏好优化（DPO），已成为将大型语言模型（LLMs）与人类偏好对齐的一种流行方法。这些算法隐式地将LLM视为奖励模型，并专注于训练它纠正错误排列表示的偏好对。然而，最近的研究~\\citet{chen2024preference} 实验发现，尽管DPO训练强调关注这些情况，但在提高这些错误排列表示的偏好对方面成效不大。我们引入了FocalPO，这是一种DPO变体，它对错误排列表示的偏好对进行\\textit{降权处理}，并优先提高模型对它已经能够正确排序的偏好对的理解。受计算机视觉任务中使用的Focal Loss启发，FocalPO通过为DPO损失添加一个调节因子来进行动态调整。我们的实验表明，使用Mistral-Base-7B和Llama-3-Instruct-8B基准，在Alpaca Eval 2.0等流行基准测试上，FocalPO超过了DPO及其变体。此外，我们还实验证明了FocalPO对正确和错误样本组训练的影响，进一步突显了其有效性。', 'title_zh': 'FocalPO：通过聚焦正确的偏好排序来提升偏好优化'}
{'arxiv_id': 'arXiv:2501.06639', 'title': 'Enhancing Path Planning Performance through Image Representation Learning of High-Dimensional Configuration Spaces', 'authors': 'Jorge Ocampo Jimenez, Wael Suleiman', 'link': 'https://arxiv.org/abs/2501.06639', 'abstract': "This paper presents a novel method for accelerating path-planning tasks in unknown scenes with obstacles by utilizing Wasserstein Generative Adversarial Networks (WGANs) with Gradient Penalty (GP) to approximate the distribution of waypoints for a collision-free path using the Rapidly-exploring Random Tree algorithm. Our approach involves conditioning the WGAN-GP with a forward diffusion process in a continuous latent space to handle multimodal datasets effectively. We also propose encoding the waypoints of a collision-free path as a matrix, where the multidimensional ordering of the waypoints is naturally preserved. This method not only improves model learning but also enhances training convergence. Furthermore, we propose a method to assess whether the trained model fails to accurately capture the true waypoints. In such cases, we revert to uniform sampling to ensure the algorithm's probabilistic completeness; a process that traditionally involves manually determining an optimal ratio for each scenario in other machine learning-based methods. Our experiments demonstrate promising results in accelerating path-planning tasks under critical time constraints. The source code is openly available at this https URL.", 'abstract_zh': '本文提出了一种利用带梯度惩罚的Wasserstein生成对抗网络（WGAN-GP）加速未知场景中有障碍物情况下的路径规划任务的新方法。该方法通过利用快速扩展随机树算法（RRT）逼近碰撞自由路径的航点分布。我们的方法通过将WGAN-GP与连续潜在空间中的正向扩散过程结合，有效处理多模态数据集。此外，我们提出了将碰撞自由路径的航点编码为矩阵的方法，使得航点的多维顺序自然保留。这种方法不仅提高了模型的学习效果，还增强了训练收敛性。同时，我们提出了一种评估方法，以确定训练模型是否准确捕捉到了真正的航点。在模型未能准确捕捉真正航点的情况下，我们回归到均匀采样策略，以确保算法的概率完备性；而在其他基于机器学习的方法中，这一过程通常需要手动确定每种场景的最佳比例。实验结果表明，在关键时间约束下，该方法能够显著加速路径规划任务。源代码已在此 <https://> URL 下公开。', 'title_zh': '通过高维配置空间的图像表示学习来提升路径规划性能'}
{'arxiv_id': 'arXiv:2501.06591', 'title': 'Exploring Pose-Based Anomaly Detection for Retail Security: A Real-World Shoplifting Dataset and Benchmark', 'authors': 'Narges Rashvand, Ghazal Alinezhad Noghre, Armin Danesh Pazho, Shanle Yao, Hamed Tabkhi', 'link': 'https://arxiv.org/abs/2501.06591', 'abstract': 'Shoplifting poses a significant challenge for retailers, resulting in billions of dollars in annual losses. Traditional security measures often fall short, highlighting the need for intelligent solutions capable of detecting shoplifting behaviors in real time. This paper frames shoplifting detection as an anomaly detection problem, focusing on the identification of deviations from typical shopping patterns. We introduce PoseLift, a privacy-preserving dataset specifically designed for shoplifting detection, addressing challenges such as data scarcity, privacy concerns, and model biases. PoseLift is built in collaboration with a retail store and contains anonymized human pose data from real-world scenarios. By preserving essential behavioral information while anonymizing identities, PoseLift balances privacy and utility. We benchmark state-of-the-art pose-based anomaly detection models on this dataset, evaluating performance using a comprehensive set of metrics. Our results demonstrate that pose-based approaches achieve high detection accuracy while effectively addressing privacy and bias concerns inherent in traditional methods. As one of the first datasets capturing real-world shoplifting behaviors, PoseLift offers researchers a valuable tool to advance computer vision ethically and will be publicly available to foster innovation and collaboration. The dataset is available at this https URL.', 'abstract_zh': '店铺盗窃给零售商带来了重大挑战，每年导致数十亿美元的损失。传统安全措施往往不足，突显出需要智能解决方案来实时检测店铺盗窃行为的必要性。本文将店铺盗窃检测视为异常检测问题，重点关注非典型购物模式的识别。我们介绍了PoseLift，这是一个专门为店铺盗窃检测设计的隐私保护数据集，旨在应对数据稀缺、隐私顾虑和模型偏见等挑战。PoseLift与一家零售店合作构建，并包含来自真实场景的匿名人体姿态数据。通过保留关键行为信息同时匿名化身份，PoseLift实现了隐私和实用性的平衡。我们在该数据集上基准测试了最先进的基于姿态的异常检测模型，并使用一系列综合指标评估其性能。我们的结果表明，基于姿态的方法不仅能够实现高度准确的检测，还能有效解决传统方法中固有的隐私和偏见问题。作为首个捕捉真实店铺盗窃行为的数据集之一，PoseLift为研究人员提供了一个伦理地推进计算机视觉研究的宝贵工具，并将在开放社区中促进创新与合作。数据集可在以下网址获取：[此 https URL](此 https URL)。', 'title_zh': '基于姿势的异常检测在零售安全中的探索：一个实际商店盗窃数据集及其基准测试'}
{'arxiv_id': 'arXiv:2501.06590', 'title': 'ChemAgent: Self-updating Library in Large Language Models Improves Chemical Reasoning', 'authors': 'Xiangru Tang, Tianyu Hu, Muyang Ye, Yanjun Shao, Xunjian Yin, Siru Ouyang, Wangchunshu Zhou, Pan Lu, Zhuosheng Zhang, Yilun Zhao, Arman Cohan, Mark Gerstein', 'link': 'https://arxiv.org/abs/2501.06590', 'abstract': 'Chemical reasoning usually involves complex, multi-step processes that demand precise calculations, where even minor errors can lead to cascading failures. Furthermore, large language models (LLMs) encounter difficulties handling domain-specific formulas, executing reasoning steps accurately, and integrating code effectively when tackling chemical reasoning tasks. To address these challenges, we present ChemAgent, a novel framework designed to improve the performance of LLMs through a dynamic, self-updating library. This library is developed by decomposing chemical tasks into sub-tasks and compiling these sub-tasks into a structured collection that can be referenced for future queries. Then, when presented with a new problem, ChemAgent retrieves and refines pertinent information from the library, which we call memory, facilitating effective task decomposition and the generation of solutions. Our method designs three types of memory and a library-enhanced reasoning component, enabling LLMs to improve over time through experience. Experimental results on four chemical reasoning datasets from SciBench demonstrate that ChemAgent achieves performance gains of up to 46% (GPT-4), significantly outperforming existing methods. Our findings suggest substantial potential for future applications, including tasks such as drug discovery and materials science. Our code can be found at this https URL', 'abstract_zh': '化学推理通常涉及复杂、多步骤的过程，要求精确的计算，即使是轻微的错误也可能导致级联失败。此外，大型语言模型（LLMs）在处理特定领域的公式、准确执行推理步骤以及有效集成代码时，在应对化学推理任务时遇到困难。为了解决这些问题，我们提出了ChemAgent，这是一种新颖的框架，旨在通过动态、自我更新的库来提高LLMs的性能。该库通过将化学任务分解为子任务并将其编译为一个结构化的集合来构建，这些集合可以在未来的查询中进行引用。当面对新的问题时，ChemAgent从该库（我们称之为内存）中检索并细化相关的信息，从而促进有效的任务分解和解决方案的生成。我们的方法设计了三种类型的内存和一个增强的库强化推理组件，这些组件使LLMs能够通过经验持续改进。SciBench提供的四个化学推理数据集上的实验结果表明，ChemAgent在GPT-4上的性能提高了最高46%，显著优于现有方法。我们的研究结果表明，ChemAgent在药物发现和材料科学等任务中具有重要的应用潜力。相关代码可在以下网址找到：此https URL', 'title_zh': 'ChemAgent: 自更新化学库在大型语言模型中的应用以提高化学推理能力'}
{'arxiv_id': 'arXiv:2501.06571', 'title': 'Active Rule Mining for Multivariate Anomaly Detection in Radio Access Networks', 'authors': 'Ebenezer R. H. P. Isaac, Joseph H. R. Isaac', 'link': 'https://arxiv.org/abs/2501.06571', 'abstract': 'Multivariate anomaly detection finds its importance in diverse applications. Despite the existence of many detectors to solve this problem, one cannot simply define why an obtained anomaly inferred by the detector is anomalous. This reasoning is required for network operators to understand the root cause of the anomaly and the remedial action that should be taken to counteract its occurrence. Existing solutions in explainable AI may give cues to features that influence an anomaly, but they do not formulate generalizable rules that can be assessed by a domain expert. Furthermore, not all outliers are anomalous in a business sense. There is an unfulfilled need for a system that can interpret anomalies predicted by a multivariate anomaly detector and map these patterns to actionable rules. This paper aims to fulfill this need by proposing a semi-autonomous anomaly rule miner. The proposed method is applicable to both discrete and time series data and is tailored for radio access network (RAN) anomaly detection use cases. The proposed method is demonstrated in this paper with time series RAN data.', 'abstract_zh': '多元异常检测在多种应用中具有重要意义。尽管已经存在许多检测器来解决这个问题，但人们不能简单地定义检测器得出的异常为何异常。这种解释对于网络运营商理解异常的根本原因以及采取何种补救措施来防止异常发生至关重要。现有的可解释人工智能解决方案可以提供影响异常的因素线索，但它们不能形成能够被领域专家评估的一般化规则。此外，并非所有离群值在业务意义上都是异常的。本文旨在满足这一需求，通过提出一种半自主的异常规则挖掘方法来解释由多元异常检测器预测的异常，并将这些模式映射到可执行规则。本文通过时间序列רד接入网络（RAN）数据来演示所提出的方法，该方法适用于离散数据和时间序列数据，并专门针对RAN异常检测的应用场景。', 'title_zh': '面向无线接入网络多变量异常检测的活跃规则挖掘'}
{'arxiv_id': 'arXiv:2501.06562', 'title': 'Discrete Speech Unit Extraction via Independent Component Analysis', 'authors': 'Tomohiko Nakamura, Kwanghee Choi, Keigo Hojo, Yoshiaki Bando, Satoru Fukayama, Shinji Watanabe', 'link': 'https://arxiv.org/abs/2501.06562', 'abstract': 'Self-supervised speech models (S3Ms) have become a common tool for the speech processing community, leveraging representations for downstream tasks. Clustering S3M representations yields discrete speech units (DSUs), which serve as compact representations for speech signals. DSUs are typically obtained by k-means clustering. Using DSUs often leads to strong performance in various tasks, including automatic speech recognition (ASR). However, even with the high dimensionality and redundancy of S3M representations, preprocessing S3M representations for better clustering remains unexplored, even though it can affect the quality of DSUs. In this paper, we investigate the potential of linear preprocessing methods for extracting DSUs. We evaluate standardization, principal component analysis, whitening, and independent component analysis (ICA) on DSU-based ASR benchmarks and demonstrate their effectiveness as preprocessing for k-means. We also conduct extensive analyses of their behavior, such as orthogonality or interpretability of individual components of ICA.', 'abstract_zh': '自监督语音模型（S3Ms）已经成为语音处理领域的一种常见工具，利用这些模型为下游任务提供表示。通过聚类S3M表示可以生成离散语音单元（DSUs），这些单元可以用作语音信号的紧凑表示。DSUs通常通过k均值聚类获得。使用DSUs通常能在各类任务中取得优异的表现，包括自动语音识别（ASR）。然而，尽管S3M表示具有高维度和冗余性，如何更好地预处理S3M表示以提高聚类质量仍是一个未被探索的问题。即使在高维度和冗余性较高的S3M表示的情况下，预处理S3M表示以改进聚类仍然未被研究，但这一点可能会影响DSUs的质量。在本文中，我们研究了线性预处理方法提取DSUs的潜力。我们在基于DSUs的ASR基准上评估了标准化、主成分分析、白化和独立成分分析（ICA），并证明了它们作为k均值聚类前处理的有效性。我们还对这些方法的行为进行了广泛分析，例如ICA中各个组件的正交性和可解释性。', 'title_zh': '离散语音单元提取基于独立成分分析'}
{'arxiv_id': 'arXiv:2501.06557', 'title': 'A Survey on Spoken Italian Datasets and Corpora', 'authors': 'Marco Giordano, Claudia Rinaldi', 'link': 'https://arxiv.org/abs/2501.06557', 'abstract': 'Spoken language datasets are vital for advancing linguistic research, Natural Language Processing, and speech technology. However, resources dedicated to Italian, a linguistically rich and diverse Romance language, remain underexplored compared to major languages like English or Mandarin. This survey provides a comprehensive analysis of 66 spoken Italian datasets, highlighting their characteristics, methodologies, and applications. The datasets are categorized by speech type, source and context, and demographic and linguistic features, with a focus on their utility in fields such as Automatic Speech Recognition, emotion detection, and education. Challenges related to dataset scarcity, representativeness, and accessibility are discussed alongside recommendations for enhancing dataset creation and utilization. The full dataset inventory is publicly accessible via GitHub and archived on Zenodo, serving as a valuable resource for researchers and developers. By addressing current gaps and proposing future directions, this work aims to support the advancement of Italian speech technologies and linguistic research.', 'abstract_zh': '口语语言数据集对于推进语言学研究、自然语言处理和语音技术至关重要。然而，与英语或汉语等主要语言相比，资源投入于意大利语——一种丰富多样且语言上复杂丰富的罗曼语族语言——仍相对不足。本文综述了66个口语意大利数据集，详细分析了这些数据集的特点、方法论和应用。数据集按语音类型、来源和语境、以及人口统计学和语言特征进行分类，重点关注其在自动语音识别、情绪检测和教育等领域中的应用。本文还讨论了数据集稀缺性、代表性及可访问性所带来的挑战，并提出了增强数据集创建和利用的建议。数据集的完整库存已通过GitHub公开，并存档于Zenodo，为研究人员和开发人员提供了宝贵资源。通过解决现有差距并提出未来方向，本文旨在促进意大利语音技术和语言学研究的发展。', 'title_zh': '对意大利口语数据集和语料库的综述'}
{'arxiv_id': 'arXiv:2501.06554', 'title': 'Hierarchical Reinforcement Learning for Optimal Agent Grouping in Cooperative Systems', 'authors': 'Liyuan Hu', 'link': 'https://arxiv.org/abs/2501.06554', 'abstract': "This paper presents a hierarchical reinforcement learning (RL) approach to address the agent grouping or pairing problem in cooperative multi-agent systems. The goal is to simultaneously learn the optimal grouping and agent policy. By employing a hierarchical RL framework, we distinguish between high-level decisions of grouping and low-level agents' actions. Our approach utilizes the CTDE (Centralized Training with Decentralized Execution) paradigm, ensuring efficient learning and scalable execution. We incorporate permutation-invariant neural networks to handle the homogeneity and cooperation among agents, enabling effective coordination. The option-critic algorithm is adapted to manage the hierarchical decision-making process, allowing for dynamic and optimal policy adjustments.", 'abstract_zh': '本文提出了一种分层强化学习（RL）方法，以解决协作多代理系统中的代理分组或配对问题。目标是同时学习最优的分组策略和代理策略。通过采用分层RL框架，我们将高层决策的分组与低层代理动作区分开来。我们的方法利用了CTDE（集中训练与分散执行）范式，确保了高效的学习和可扩展的执行。我们引入了不变排列神经网络来处理代理之间的同质性和协作，从而实现有效的协调。此外，我们对选项评论算法进行了调整，以便于管理分层决策过程，允许动态和最优策略调整。', 'title_zh': '协同系统中优化智能体分组的分层强化学习方法'}
{'arxiv_id': 'arXiv:2501.06546', 'title': 'Natural Language Supervision for Low-light Image Enhancement', 'authors': 'Jiahui Tang, Kaihua Zhou, Zhijian Luo, Yueen Hou', 'link': 'https://arxiv.org/abs/2501.06546', 'abstract': "With the development of deep learning, numerous methods for low-light image enhancement (LLIE) have demonstrated remarkable performance. Mainstream LLIE methods typically learn an end-to-end mapping based on pairs of low-light and normal-light images. However, normal-light images under varying illumination conditions serve as reference images, making it difficult to define a ``perfect'' reference image This leads to the challenge of reconciling metric-oriented and visual-friendly results. Recently, many cross-modal studies have found that side information from other related modalities can guide visual representation learning. Based on this, we introduce a Natural Language Supervision (NLS) strategy, which learns feature maps from text corresponding to images, offering a general and flexible interface for describing an image under different illumination.\nHowever, image distributions conditioned on textual descriptions are highly multimodal, which makes training difficult. To address this issue, we design a Textual Guidance Conditioning Mechanism (TCM) that incorporates the connections between image regions and sentence words, enhancing the ability to capture fine-grained cross-modal cues for images and text. This strategy not only utilizes a wider range of supervised sources, but also provides a new paradigm for LLIE based on visual and textual feature alignment. In order to effectively identify and merge features from various levels of image and textual information, we design an Information Fusion Attention (IFA) module to enhance different regions at different levels. We integrate the proposed TCM and IFA into a Natural Language Supervision network for LLIE, named NaLSuper. Finally, extensive experiments demonstrate the robustness and superior effectiveness of our proposed NaLSuper.", 'abstract_zh': '随着深度学习的发展，许多低光图像增强（LLIE）方法已经展现出卓越的效果。主流的LLIE方法通常基于低光和正常光图像的配对学习端到端的映射。然而，不同照明条件下的正常光图像作为参考图像使用，这使得难以定义一个“完美的”参考图像。这导致了基于度量和视觉友好结果之间的调和挑战。最近，许多跨模态研究表明，来自其他相关模态的辅助信息可以帮助引导视觉表示学习。基于此，我们引入了一种自然语言监督（NLS）策略，从对应图像的文字中学习特征图，提供了一个灵活的一般性接口，用于在不同照明条件下描述图像。\n\n然而，根据文字描述条件下的图像分布高度多模态，这使得训练过程变得困难。为了解决这个问题，我们设计了一种文本引导条件机制（TCM），它结合了图像区域和句子词语之间的联系，增强了捕捉图像和文本之间细粒度跨模态线索的能力。该策略不仅可以利用监督信息的广泛范围，还提供了一种基于视觉和文本特征对齐的LLIE新范式。为了有效地识别和合并来自不同层级图像和文本信息的特征，我们设计了一个信息融合注意（IFA）模块，以在不同层级增强不同的区域。我们将提出的TCM和IFA整合到了一个名为NaLSuper的自然语言监督LLIE网络中。最后，广泛的实验验证了我们提出的NaLSuper的鲁棒性和优越效果。', 'title_zh': '低光照图像增强的自然语言监督方法'}
{'arxiv_id': 'arXiv:2501.06532', 'title': 'Determination of galaxy photometric redshifts using Conditional Generative Adversarial Networks (CGANs)', 'authors': 'M. Garcia-Fernandez', 'link': 'https://arxiv.org/abs/2501.06532', 'abstract': 'Accurate and reliable photometric redshifts determination is one of the key aspects for wide-field photometric surveys. Determination of photometric redshift for galaxies, has been traditionally solved by use of machine-learning and artificial intelligence techniques trained on a calibration sample of galaxies, where both photometry and spectrometry are determined. On this paper, we present a new algorithmic approach for determining photometric redshifts of galaxies using Conditional Generative Adversarial Networks (CGANs). Proposed CGAN implementation, approaches photometric redshift determination as a probabilistic regression, where instead of determining a single value for the estimated redshift of the galaxy, a full probability density is computed. The methodology proposed, is tested with data from Dark Energy Survey (DES) Y1 data and compared with other existing algorithm such as a Random Forest regressor.', 'abstract_zh': '准确可靠的 photometric 红移确定是广域 photometric 调查的关键方面之一。对于星系的 photometric 红移确定，传统上通过使用基于校准样本训练的机器学习和人工智能技术来解决，该校准样本中既包括光谱测量也包括 photometry。在本文中，我们提出了一种新的算法方法，使用条件生成对抗网络 (CGAN) 来确定星系的 photometric 红移。提出的 CGAN 实现将 photometric 红移确定视为概率回归问题，而不是确定星系的单个红色shift值，而是计算完整的概率密度。所提出的方法使用 Dark Energy Survey (DES) Y1 数据进行了测试，并与现有算法（如随机森林回归器）进行了比较。', 'title_zh': '使用条件生成对抗网络（CGANs）确定星系的 photometric 距离学红移'}
{'arxiv_id': 'arXiv:2501.06514', 'title': 'Neural Codec Source Tracing: Toward Comprehensive Attribution in Open-Set Condition', 'authors': 'Yuankun Xie, Xiaopeng Wang, Zhiyong Wang, Ruibo Fu, Zhengqi Wen, Songjun Cao, Long Ma, Chenxing Li, Haonnan Cheng, Long Ye', 'link': 'https://arxiv.org/abs/2501.06514', 'abstract': 'Current research in audio deepfake detection is gradually transitioning from binary classification to multi-class tasks, referred as audio deepfake source tracing task. However, existing studies on source tracing consider only closed-set scenarios and have not considered the challenges posed by open-set conditions. In this paper, we define the Neural Codec Source Tracing (NCST) task, which is capable of performing open-set neural codec classification and interpretable ALM detection. Specifically, we constructed the ST-Codecfake dataset for the NCST task, which includes bilingual audio samples generated by 11 state-of-the-art neural codec methods and ALM-based out-ofdistribution (OOD) test samples. Furthermore, we establish a comprehensive source tracing benchmark to assess NCST models in open-set conditions. The experimental results reveal that although the NCST models perform well in in-distribution (ID) classification and OOD detection, they lack robustness in classifying unseen real audio. The ST-codecfake dataset and code are available.', 'abstract_zh': '当前的音频深度伪造检测研究正逐渐从二分类任务转向多分类任务，这一过程被称为音频深度伪造来源追踪任务。然而，现有针对来源追踪的研究仅考虑了封闭集场景，尚未考虑到开放集条件带来的挑战。本文定义了神经编解码器来源追踪（NCST）任务，该任务能够进行开放集神经编解码器分类和可解释的外部异常检测。具体而言，我们为此任务构建了ST-Codecfake数据集，其中包括由11种最新神经编解码器方法生成的双语音频样本以及基于ALM的外部异常（OOD）测试样本。此外，我们还建立了一个全面的来源追踪基准，以评估NCST模型在开放集条件下的性能。实验结果表明，尽管NCST模型在内部分布（ID）分类和外部异常检测上表现出色，但在分类未见过的真实音频方面缺乏鲁棒性。ST-Codecfake数据集及其代码现已公开。', 'title_zh': '神经编码源追溯：面向开放集条件下的全面归因研究'}
{'arxiv_id': 'arXiv:2501.06506', 'title': 'Resource Allocation under the Latin Square Constraint', 'authors': 'Yasushi Kawase, Bodhayan Roy, Mohammad Azharuddin Sanpui', 'link': 'https://arxiv.org/abs/2501.06506', 'abstract': "A Latin square is an $n \\times n$ matrix filled with $n$ distinct symbols, each of which appears exactly once in each row and exactly once in each column. We introduce a problem of allocating $n$ indivisible items among $n$ agents over $n$ rounds while satisfying the Latin square constraint. This constraint ensures that each agent receives no more than one item per round and receives each item at most once. Each agent has an additive valuation on the item--round pairs. Real-world applications like scheduling, resource management, and experimental design require the Latin square constraint to satisfy fairness or balancedness in allocation. Our goal is to find a partial or complete allocation that maximizes the sum of the agents' valuations (utilitarian social welfare) or the minimum of the agents' valuations (egalitarian social welfare). For the problem of maximizing utilitarian social welfare, we prove NP-hardness even when the valuations are binary additive. We then provide $(1-1/e)$ and $(1-1/e)/4$-approximation algorithms for partial and complete settings, respectively. Additionally, we present fixed-parameter tractable (FPT) algorithms with respect to the order of Latin square and the optimum value for both partial and complete settings. For the problem of maximizing egalitarian social welfare, we establish that deciding whether the optimum value is at most $1$ or at least $2$ is NP-hard for both the partial and complete settings, even when the valuations are binary. Furthermore, we demonstrate that checking the existence of a complete allocation that satisfies each of envy-free, proportional, equitable, envy-free up to any good, proportional up to any good, or equitable up to any good is NP-hard, even when the valuations are identical.", 'abstract_zh': '拉丁方是一类 \\(n \\times n\\) 矩阵，其中填充了 \\(n\\) 个不同的符号，每个符号在每一行和每一列中恰好出现一次。我们提出一个问题：在 \\(n\\) 轮中将 \\(n\\) 个不可分割的物品分配给 \\(n\\) 个代理，同时满足拉丁方约束。这一约束确保每个代理每轮最多获得一个物品，并且每个物品最多被分配一次。每个代理对其物品-轮次对有着可加的价值评估。在调度、资源管理以及实验设计等实际应用中，拉丁方约束有助于确保分配的公平性和平衡性。我们的目标是找到一个部分或完整的分配方案，使得所有代理的价值总和最大化（功利主义社会福利）或找到最小化所有代理价值的分配方案（平等主义社会福利）。对于最大化功利主义社会福利的问题，我们证明即使在评估为二元可加的情况下，该问题也是 NP 难的。随后，我们提供了针对部分和完全设置的 \\((1-\\frac{1}{e})\\) 和 \\((1-\\frac{1}{e})/4\\) 约束性算法。此外，我们还针对部分和完全设置提出了固定参数可解决（FPT）算法，其中考虑了拉丁方的顺序和最优价值。对于最大化平等主义社会福利的问题，我们证明了对于部分和完全设置，判断最优值是否小于等于 1 或大于等于 2 这一问题在二元评估的情况下也是 NP 难的。最后，我们还证明判断是否存在一个满足无嫉妒、比例公平、公平、无嫉妒到任意商品、比例到任意商品、公平到任意商品之一条件的完整分配方案也是 NP 难的，即使所有代理的评估值相同也是如此。', 'title_zh': '拉丁方约束下的资源分配'}
{'arxiv_id': 'arXiv:2501.06497', 'title': 'PASS: Presentation Automation for Slide Generation and Speech', 'authors': 'Tushar Aggarwal, Aarohi Bhand', 'link': 'https://arxiv.org/abs/2501.06497', 'abstract': "In today's fast-paced world, effective presentations have become an essential tool for communication in both online and offline meetings. The crafting of a compelling presentation requires significant time and effort, from gathering key insights to designing slides that convey information clearly and concisely. However, despite the wealth of resources available, people often find themselves manually extracting crucial points, analyzing data, and organizing content in a way that ensures clarity and impact. Furthermore, a successful presentation goes beyond just the slides; it demands rehearsal and the ability to weave a captivating narrative to fully engage the audience. Although there has been some exploration of automating document-to-slide generation, existing research is largely centered on converting research papers. In addition, automation of the delivery of these presentations has yet to be addressed. We introduce PASS, a pipeline used to generate slides from general Word documents, going beyond just research papers, which also automates the oral delivery of the generated slides. PASS analyzes user documents to create a dynamic, engaging presentation with an AI-generated voice. Additionally, we developed an LLM-based evaluation metric to assess our pipeline across three critical dimensions of presentations: relevance, coherence, and redundancy. The data and codes are available at this https URL.", 'abstract_zh': '在当今快节奏的世界中，有效的演示文稿已成为在线和线下会议中沟通的重要工具。制作引人入胜的演示文稿需要大量的时间和努力，从收集关键见解到设计能够清晰简洁地传达信息的幻灯片。然而，即使有丰富的资源可供利用，人们仍然经常需要手动提取关键点、分析数据和组织内容以确保清晰性和影响力。此外，成功的演示不仅限于幻灯片本身；它还要求进行排练并能够编织一个引人入胜的故事来全面吸引观众的注意力。虽然在自动化文档到幻灯片生成方面有一些探索，但现有研究主要集中在研究论文的转换上。此外，对演示文稿的自动化交付尚未得到解决。我们引入了PASS（Presentation Automation System）管道，用于从一般的Word文档生成幻灯片，而不仅仅是研究论文，该管道还自动化了生成幻灯片的口头演示。PASS 分析用户文档，生成由人工智能生成声音的动态、引人入胜的演示文稿。此外，我们还开发了一种基于大语言模型的评估指标，以从三个关键维度评估我们的管道：相关性、连贯性和冗余性。数据和代码可在以下链接获取：this https URL。', 'title_zh': 'PASS：幻灯片生成与演讲的自动呈现'}
{'arxiv_id': 'arXiv:2501.06494', 'title': 'TopoFormer: Integrating Transformers and ConvLSTMs for Coastal Topography Prediction', 'authors': 'Santosh Munian, Oktay Karakuş, William Russell, Gwyn Nelson', 'link': 'https://arxiv.org/abs/2501.06494', 'abstract': "This paper presents \\textit{TopoFormer}, a novel hybrid deep learning architecture that integrates transformer-based encoders with convolutional long short-term memory (ConvLSTM) layers for the precise prediction of topographic beach profiles referenced to elevation datums, with a particular focus on Mean Low Water Springs (MLWS) and Mean Low Water Neaps (MLWN). Accurate topographic estimation down to MLWS is critical for coastal management, navigation safety, and environmental monitoring. Leveraging a comprehensive dataset from the Wales Coastal Monitoring Centre (WCMC), consisting of over 2000 surveys across 36 coastal survey units, TopoFormer addresses key challenges in topographic prediction, including temporal variability and data gaps in survey measurements. The architecture uniquely combines multi-head attention mechanisms and ConvLSTM layers to capture both long-range dependencies and localized temporal patterns inherent in beach profiles data. TopoFormer's predictive performance was rigorously evaluated against state-of-the-art models, including DenseNet, 1D/2D CNNs, and LSTMs. While all models demonstrated strong performance, \\textit{TopoFormer} achieved the lowest mean absolute error (MAE), as low as 2 cm, and provided superior accuracy in both in-distribution (ID) and out-of-distribution (OOD) evaluations.", 'abstract_zh': '本文介绍了\\textit{TopoFormer}，这是一种新颖的混合深度学习架构，它将基于变压器的编码器与卷积长短期记忆（ConvLSTM）层相结合，用于准确预测以海拔起算面为基准的地形海岸线剖面，特别关注大潮低潮（MLWS）和小潮低潮（MLWN）。精确到MLWS的地形估计对于海岸管理、航行安全和环境监测至关重要。通过利用威尔士海岸监测中心（WCMC）的全面数据集，其中包括36个海岸调查单元的超过2000次调查，TopoFormer解决了地形预测中的关键挑战，包括调查测量中的时间变化性和数据缺口问题。该架构独特地结合了多头注意力机制和ConvLSTM层，以捕捉海滩剖面数据中固有的长距离依赖性和局部时间模式。TopoFormer的预测性能在与最新模型（包括DenseNet、1D/2D CNN和LSTM）的严格对比评估中表现出色。尽管所有模型都表现出强大的性能，但\\textit{TopoFormer}获得了最低的平均绝对误差（MAE），低至2 cm，并在分布内（ID）和分布外（OOD）评估中提供了更高的准确性。', 'title_zh': 'TopoFormer: 结合Transformer和ConvLSTM进行海岸地形预测'}
{'arxiv_id': 'arXiv:2501.06491', 'title': 'Improving Requirements Classification with SMOTE-Tomek Preprocessing', 'authors': 'Barak Or', 'link': 'https://arxiv.org/abs/2501.06491', 'abstract': 'This study emphasizes the domain of requirements engineering by applying the SMOTE-Tomek preprocessing technique, combined with stratified K-fold cross-validation, to address class imbalance in the PROMISE dataset. This dataset comprises 969 categorized requirements, classified into functional and non-functional types. The proposed approach enhances the representation of minority classes while maintaining the integrity of validation folds, leading to a notable improvement in classification accuracy. Logistic regression achieved 76.16\\%, significantly surpassing the baseline of 58.31\\%. These results highlight the applicability and efficiency of machine learning models as scalable and interpretable solutions.', 'abstract_zh': '本研究强调了需求工程的领域，通过应用SMOTE-Tomek预处理技术，并结合分层K折交叉验证，解决PROMISE数据集中类别不平衡问题。该数据集包含969个分类需求，分为功能性和非功能性类型。所提出的方法在增强少数类的表示能力的同时保持验证折叠的完整性，从而显著提高了分类精度。逻辑回归达到了76.16%，远远超过了基准值58.31%。这些结果突显了机器学习模型作为可扩展且可解释的解决方案的应用性和效率。', 'title_zh': '使用SMOTE-Tomek预处理方法改进需求分类'}
{'arxiv_id': 'arXiv:2501.06488', 'title': 'NVS-SQA: Exploring Self-Supervised Quality Representation Learning for Neurally Synthesized Scenes without References', 'authors': 'Qiang Qu, Yiran Shen, Xiaoming Chen, Yuk Ying Chung, Weidong Cai, Tongliang Liu', 'link': 'https://arxiv.org/abs/2501.06488', 'abstract': 'Neural View Synthesis (NVS), such as NeRF and 3D Gaussian Splatting, effectively creates photorealistic scenes from sparse viewpoints, typically evaluated by quality assessment methods like PSNR, SSIM, and LPIPS. However, these full-reference methods, which compare synthesized views to reference views, may not fully capture the perceptual quality of neurally synthesized scenes (NSS), particularly due to the limited availability of dense reference views. Furthermore, the challenges in acquiring human perceptual labels hinder the creation of extensive labeled datasets, risking model overfitting and reduced generalizability. To address these issues, we propose NVS-SQA, a NSS quality assessment method to learn no-reference quality representations through self-supervision without reliance on human labels. Traditional self-supervised learning predominantly relies on the "same instance, similar representation" assumption and extensive datasets. However, given that these conditions do not apply in NSS quality assessment, we employ heuristic cues and quality scores as learning objectives, along with a specialized contrastive pair preparation process to improve the effectiveness and efficiency of learning. The results show that NVS-SQA outperforms 17 no-reference methods by a large margin (i.e., on average 109.5% in SRCC, 98.6% in PLCC, and 91.5% in KRCC over the second best) and even exceeds 16 full-reference methods across all evaluation metrics (i.e., 22.9% in SRCC, 19.1% in PLCC, and 18.6% in KRCC over the second best).', 'abstract_zh': '神经视图合成（NVS），例如NeRF和3D高斯点积，能够从稀疏视角高效地创建逼真的场景，通常通过像PSNR、SSIM和LPIPS这样的质量评估方法对其进行评价。然而，这些依赖参考视角的全参考方法可能无法完全捕捉神经合成场景（NSS）的感知质量，特别是在难以获得密集参考视角的情况下。此外，获取人类感知标签的挑战限制了大容量标注数据集的创建，从而增加了模型过拟合和降低泛化性的风险。为解决这些问题，我们提出了一种NSS质量评估方法NVS-SQA，该方法通过自我监督学习来学习无参考的质量表示，而不依赖于人工标签。传统的自我监督学习主要依赖于“相同实例，相似表示”的假设和大量数据集。然而，由于这些条件在NSS质量评估中并不适用，我们采用了启发式提示和质量评分作为学习目标，并采用专门的对比学习对准备过程来提高学习的有效性和效率。实验结果表明，NVS-SQA在SRCC、PLCC和KRCC三个方面显著优于17种无参考方法（平均分别领先109.5%、98.6%和91.5%），并且在所有评价指标上甚至超过了16种全参考方法（分别领先22.9%、19.1%和18.6%）。', 'title_zh': 'NVS-SQA：探索无参考条件下神经合成场景的自我监督质量表示学习'}
{'arxiv_id': 'arXiv:2501.06472', 'title': 'YO-CSA-T: A Real-time Badminton Tracking System Utilizing YOLO Based on Contextual and Spatial Attention', 'authors': 'Yuan Lai, Zhiwei Shi, Chengxi Zhu', 'link': 'https://arxiv.org/abs/2501.06472', 'abstract': "The 3D trajectory of a shuttlecock required for a badminton rally robot for human-robot competition demands real-time performance with high accuracy. However, the fast flight speed of the shuttlecock, along with various visual effects, and its tendency to blend with environmental elements, such as court lines and lighting, present challenges for rapid and accurate 2D detection. In this paper, we first propose the YO-CSA detection network, which optimizes and reconfigures the YOLOv8s model's backbone, neck, and head by incorporating contextual and spatial attention mechanisms to enhance model's ability in extracting and integrating both global and local features. Next, we integrate three major subtasks, detection, prediction, and compensation, into a real-time 3D shuttlecock trajectory detection system. Specifically, our system maps the 2D coordinate sequence extracted by YO-CSA into 3D space using stereo vision, then predicts the future 3D coordinates based on historical information, and re-projects them onto the left and right views to update the position constraints for 2D detection. Additionally, our system includes a compensation module to fill in missing intermediate frames, ensuring a more complete trajectory. We conduct extensive experiments on our own dataset to evaluate both YO-CSA's performance and system effectiveness. Experimental results show that YO-CSA achieves a high accuracy of 90.43% mAP@0.75, surpassing both YOLOv8s and YOLO11s. Our system performs excellently, maintaining a speed of over 130 fps across 12 test sequences.", 'abstract_zh': '用于羽毛球机器人的人机对决所必需的 shuttlecock 三维轨迹，需要实时且高精度的表现。然而，shuttlecock 的快速飞行速度、多种视觉效果，以及它与场地线、照明等环境元素融合的趋势，给快速而准确的二维检测带来了挑战。本文首先提出了一种 YO-CSA 检测网络，通过结合上下文和空间注意力机制优化并重新配置了 YOLOv8s 模型的骨干、颈部和头部，以增强模型提取和整合全局与局部特征的能力。接着，我们将检测、预测和补偿三个主要子任务整合到一个实时的三维 shuttlecock 轨迹检测系统中。具体而言，我们的系统利用立体视觉将由 YO-CSA 提取出的二维坐标序列映射到三维空间，然后基于历史信息预测未来的三维坐标，并将这些坐标重新投影到左右视图中以更新二维检测的位置约束。此外，我们的系统还包括一个补偿模块，用于填充缺失的中间帧，确保轨迹更加完整。我们在自建的数据集上进行了广泛实验，以评估 YO-CSA 的性能和系统效果。实验结果显示，YO-CSA 达到了 90.43% 的mAP@0.75 高准确度，超过了 YOLOv8s 和 YOLO11s。我们的系统表现出色，在 12 个测试序列中保持了超过 130 fps 的速度。', 'title_zh': 'YO-CSA-T：一种基于上下文和空间注意力的YOLO算法实现的实时羽毛球追踪系统'}
{'arxiv_id': 'arXiv:2501.06468', 'title': 'First Token Probability Guided RAG for Telecom Question Answering', 'authors': 'Tingwei Chen, Jiayi Chen, Zijian Zhao, Haolong Chen, Liang Zhang, Guangxu Zhu', 'link': 'https://arxiv.org/abs/2501.06468', 'abstract': 'Large Language Models (LLMs) have garnered significant attention for their impressive general-purpose capabilities. For applications requiring intricate domain knowledge, Retrieval-Augmented Generation (RAG) has shown a distinct advantage in incorporating domain-specific information into LLMs. However, existing RAG research has not fully addressed the challenges of Multiple Choice Question Answering (MCQA) in telecommunications, particularly in terms of retrieval quality and mitigating hallucinations. To tackle these challenges, we propose a novel first token probability guided RAG framework. This framework leverages confidence scores to optimize key hyperparameters, such as chunk number and chunk window size, while dynamically adjusting the context. Our method starts by retrieving the most relevant chunks and generates a single token as the potential answer. The probabilities of all options are then normalized to serve as confidence scores, which guide the dynamic adjustment of the context. By iteratively optimizing the hyperparameters based on these confidence scores, we can continuously improve RAG performance. We conducted experiments to validate the effectiveness of our framework, demonstrating its potential to enhance accuracy in domain-specific MCQA tasks.', 'abstract_zh': '大规模语言模型（LLMs）因其广泛的通用能力而受到了广泛关注。对于需要复杂领域知识的应用，检索增强生成（RAG）已经显示出将其特定领域的信息整合到LLMs中的明显优势。然而，现有的RAG研究尚未充分解决电信领域多项选择题回答（MCQA）中的挑战，特别是在检索质量及减轻幻觉问题方面。为应对这些挑战，我们提出了一种新颖的一级令牌概率引导RAG框架。该框架利用置信度分数来优化诸如分块数量和分块窗口大小等关键超参数，并动态调整上下文。我们的方法首先检索最相关的分块，生成一个潜在答案的单个令牌。然后，所有选项的概率被归一化以作为置信度分数，这些分数指导上下文的动态调整。通过基于这些置信度分数迭代优化超参数，可以不断改善RAG性能。我们进行了实验以验证该框架的有效性，展示了其在特定领域MCQA任务中提高准确性的潜力。', 'title_zh': '首先，将论文标题“First Token Probability Guided RAG for Telecom Question Answering”翻译成中文，符合学术规范的翻译是：\n\n“基于首个令牌概率的RAG在电信问答中的应用”'}
{'arxiv_id': 'arXiv:2501.06465', 'title': 'MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare', 'authors': 'Ye Chen, Dongdong Huang, Haoyun Xu, Cong Fu, Lin Sheng, Qingli Zhou, Yuqiang Shen, Kai Wang', 'link': 'https://arxiv.org/abs/2501.06465', 'abstract': "We introduce the world's first clinical terminology for the Chinese healthcare community, namely MedCT, accompanied by a clinical foundation model MedBERT and an entity linking model MedLink. The MedCT system enables standardized and programmable representation of Chinese clinical data, successively stimulating the development of new medicines, treatment pathways, and better patient outcomes for the populous Chinese community. Moreover, the MedCT knowledge graph provides a principled mechanism to minimize the hallucination problem of large language models (LLMs), therefore achieving significant levels of accuracy and safety in LLM-based clinical applications. By leveraging the LLMs' emergent capabilities of generativeness and expressiveness, we were able to rapidly built a production-quality terminology system and deployed to real-world clinical field within three months, while classical terminologies like SNOMED CT have gone through more than twenty years development. Our experiments show that the MedCT system achieves state-of-the-art (SOTA) performance in semantic matching and entity linking tasks, not only for Chinese but also for English. We also conducted a longitudinal field experiment by applying MedCT and LLMs in a representative spectrum of clinical tasks, including electronic health record (EHR) auto-generation and medical document search for diagnostic decision making. Our study shows a multitude of values of MedCT for clinical workflows and patient outcomes, especially in the new genre of clinical LLM applications. We present our approach in sufficient engineering detail, such that implementing a clinical terminology for other non-English societies should be readily reproducible. We openly release our terminology, models and algorithms, along with real-world clinical datasets for the development.", 'abstract_zh': '我们为中国医疗社区引入了世界上首个临床术语体系，即MedCT，同时提供了临床基础模型MedBERT和实体链接模型MedLink。MedCT系统实现了对中国临床数据的标准化和编程化表示，促进了新药物、治疗路径和更佳患者成果的发展，特别是在庞大的中国人群中发挥了重要作用。此外，MedCT知识图谱提供了一种原理性的机制，以最小化大规模语言模型（LLMs）的幻觉问题，从而在基于LLM的临床应用中实现了显著的准确性和安全性。通过利用LLMs生成能力和表达能力的新兴特性，我们仅用三个月时间就快速构建了一个生产质量的术语系统，并将其部署到实际临床领域，而传统的术语体系如SNOMED CT则需要超过二十年的发展时间。我们的实验表明，MedCT系统在语义匹配和实体链接任务中达到了目前最好的（SOTA）性能，无论是在中文还是英文上都是如此。我们还进行了一个纵向的临床现场试验，将MedCT和LLMs应用于代表性的临床任务，包括电子健康记录（EHR）自动生成和医疗文档搜索以支持诊断决策。我们的研究显示了MedCT在临床流程和患者成果中的多重价值，特别是在新型临床LLM应用中。我们以足够的工程细节介绍了我们的方法，使为其他非英语社会构建临床术语变得容易重现。我们公开释放了术语、模型及算法，并提供了实际临床数据集，以促进其发展。', 'title_zh': 'MedCT：医疗领域术语图在医疗健康生成式AI应用中的临床术语图谱'}
{'arxiv_id': 'arXiv:2501.06444', 'title': 'On the Computational Capability of Graph Neural Networks: A Circuit Complexity Bound Perspective', 'authors': 'Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song, Wei Wang, Jiahao Zhang', 'link': 'https://arxiv.org/abs/2501.06444', 'abstract': 'Graph Neural Networks (GNNs) have become the standard approach for learning and reasoning over relational data, leveraging the message-passing mechanism that iteratively propagates node embeddings through graph structures. While GNNs have achieved significant empirical success, their theoretical limitations remain an active area of research. Existing studies primarily focus on characterizing GNN expressiveness through Weisfeiler-Lehman (WL) graph isomorphism tests. In this paper, we take a fundamentally different approach by exploring the computational limitations of GNNs through the lens of circuit complexity. Specifically, we analyze the circuit complexity of common GNN architectures and prove that under constraints of constant-depth layers, linear or sublinear embedding sizes, and polynomial precision, GNNs cannot solve key problems such as graph connectivity and graph isomorphism unless $\\mathsf{TC}^0 = \\mathsf{NC}^1$. These results reveal the intrinsic expressivity limitations of GNNs behind their empirical success and introduce a novel framework for analyzing GNN expressiveness that can be extended to a broader range of GNN models and graph decision problems.', 'abstract_zh': '图神经网络（GNNs）已经成为处理关系数据的学习和推理的标准方法，它们利用消息传递机制，在图结构中迭代传播节点嵌入。尽管GNNs在经验上取得了显著的成功，但它们的理论限制仍然是一个活跃的研究领域。现有研究表明，主要通过魏斯菲勒-莱曼（WL）图同构测试来表征GNN的表现力。在本文中，我们采取了完全不同的一种研究方法，通过电路复杂性的视角来探索GNNs的计算限制。具体来说，我们分析了常见GNN架构的电路复杂性，并证明，在常数深度层、线性或次线性嵌入尺寸以及多项式精度的约束条件下，除非$\\mathsf{TC}^0 = \\mathsf{NC}^1$，否则GNNs无法解决图连接性和图同构这类关键问题。这些结果揭示了GNN背后的内在表现力限制，其成功表现是基于经验的。我们还提出了一个新颖的分析框架，可以扩展到更广泛的GNN模型和图决策问题。', 'title_zh': '从电路复杂性视角探讨图神经网络的计算能力'}
{'arxiv_id': 'arXiv:2501.06434', 'title': 'Synthetic Feature Augmentation Improves Generalization Performance of Language Models', 'authors': 'Ashok Choudhary, Cornelius Thiels, Hojjat Salehinejad', 'link': 'https://arxiv.org/abs/2501.06434', 'abstract': 'Training and fine-tuning deep learning models, especially large language models (LLMs), on limited and imbalanced datasets poses substantial challenges. These issues often result in poor generalization, where models overfit to dominant classes and underperform on minority classes, leading to biased predictions and reduced robustness in real-world applications. To overcome these challenges, we propose augmenting features in the embedding space by generating synthetic samples using a range of techniques. By upsampling underrepresented classes, this method improves model performance and alleviates data imbalance. We validate the effectiveness of this approach across multiple open-source text classification benchmarks, demonstrating its potential to enhance model robustness and generalization in imbalanced data scenarios.', 'abstract_zh': '在有限和不平衡的数据集上训练和微调深度学习模型，尤其是大型语言模型（LLMs），面临着重大挑战。这些问题往往导致模型过度拟合到主要类别，而对少数类别表现不佳，从而产生有偏的预测并降低实际应用中的稳健性。为了克服这些挑战，我们提出了一种通过生成合成样本来在嵌入空间中增强特征的方法。通过上采样欠代表的类别，这种方法提高了模型性能并缓解了数据不平衡问题。我们通过多个开源文本分类基准验证了该方法的有效性，展示了其在不平衡数据场景中增强模型稳健性和泛化能力的潜力。', 'title_zh': '合成特征增强提高语言模型的泛化性能'}
{'arxiv_id': 'arXiv:2501.06432', 'title': 'Deep Learning on Hester Davis Scores for Inpatient Fall Prediction', 'authors': 'Hojjat Salehinejad, Ricky Rojas, Kingsley Iheasirim, Mohammed Yousufuddin, Bijan Borah', 'link': 'https://arxiv.org/abs/2501.06432', 'abstract': 'Fall risk prediction among hospitalized patients is a critical aspect of patient safety in clinical settings, and accurate models can help prevent adverse events. The Hester Davis Score (HDS) is commonly used to assess fall risk, with current clinical practice relying on a threshold-based approach. In this method, a patient is classified as high-risk when their HDS exceeds a predefined threshold. However, this approach may fail to capture dynamic patterns in fall risk over time. In this study, we model the threshold-based approach and propose two machine learning approaches for enhanced fall prediction: One-step ahead fall prediction and sequence-to-point fall prediction. The one-step ahead model uses the HDS at the current timestamp to predict the risk at the next timestamp, while the sequence-to-point model leverages all preceding HDS values to predict fall risk using deep learning. We compare these approaches to assess their accuracy in fall risk prediction, demonstrating that deep learning can outperform the traditional threshold-based method by capturing temporal patterns and improving prediction reliability. These findings highlight the potential for data-driven approaches to enhance patient safety through more reliable fall prevention strategies.', 'abstract_zh': '住院患者跌倒风险预测是临床环境中患者安全的关键方面，准确的模型可以帮助预防不良事件。海蒂·戴维斯评分（Hester Davis Score, HDS）常被用于评估跌倒风险，目前的临床实践中依赖于阈值方法。在该方法中，当患者的HDS超过预设阈值时，将患者分类为高风险。然而，这种方法可能无法捕捉随时间变化的跌倒风险动态模式。在本研究中，我们建模了阈值方法，并提出了两种机器学习方法以增强跌倒预测：一步预测和序列到点预测。一步预测模型使用当前时间戳的HDS来预测下一个时间戳的风险，而序列到点模型则利用所有先前的HDS值，使用深度学习来预测跌倒风险。我们比较了这些方法的准确性，结果显示，深度学习可以超越传统的阈值方法，通过捕捉时间模式来提高预测可靠性。这些发现突显了数据驱动方法在通过更可靠的跌倒预防策略提高患者安全方面的潜力。', 'title_zh': '基于深度学习的海斯特·戴维斯评分在院内跌倒预测中的应用'}
{'arxiv_id': 'arXiv:2501.06431', 'title': 'Aug3D: Augmenting large scale outdoor datasets for Generalizable Novel View Synthesis', 'authors': 'Aditya Rauniyar, Omar Alama, Silong Yong, Katia Sycara, Sebastian Scherer', 'link': 'https://arxiv.org/abs/2501.06431', 'abstract': "Recent photorealistic Novel View Synthesis (NVS) advances have increasingly gained attention. However, these approaches remain constrained to small indoor scenes. While optimization-based NVS models have attempted to address this, generalizable feed-forward methods, offering significant advantages, remain underexplored. In this work, we train PixelNeRF, a feed-forward NVS model, on the large-scale UrbanScene3D dataset. We propose four training strategies to cluster and train on this dataset, highlighting that performance is hindered by limited view overlap. To address this, we introduce Aug3D, an augmentation technique that leverages reconstructed scenes using traditional Structure-from-Motion (SfM). Aug3D generates well-conditioned novel views through grid and semantic sampling to enhance feed-forward NVS model learning. Our experiments reveal that reducing the number of views per cluster from 20 to 10 improves PSNR by 10%, but the performance remains suboptimal. Aug3D further addresses this by combining the newly generated novel views with the original dataset, demonstrating its effectiveness in improving the model's ability to predict novel views.", 'abstract_zh': '近年来，发展前景合成（NVS）的高保真方法逐渐引起了广泛关注。然而，现有的方法仍主要局限于小型室内场景。尽管基于优化的方法试图克服这一限制，但通用的前向传播方法虽然具有明显的优势，仍未得到充分探索。在本研究中，我们利用大规模的UrbanScene3D数据集对前向NVS模型PixelNeRF进行训练。我们提出了四种训练策略来聚类和训练数据集，并指出性能受限于视图重叠有限。为了解决这一问题，我们引入了Aug3D增广技术，该技术利用传统结构从运动（SfM）重建的场景。Aug3D通过网格和语义采样生成条件良好的新视图，以增强前向NVS模型的学习能力。实验结果显示，将每簇视图的数量从20减少到10可以提高10%的PSNR，但性能仍然不理想。通过将使用Aug3D生成的新视图与原始数据集结合，我们的方法进一步证明了其提高模型预测新视图能力的有效性。', 'title_zh': 'Aug3D：增强大规模室外数据集以实现泛化新颖视角合成'}
{'arxiv_id': 'arXiv:2501.06425', 'title': 'Tensor Product Attention Is All You Need', 'authors': 'Yifan Zhang, Yifeng Liu, Huizhuo Yuan, Zhen Qin, Yang Yuan, Quanquan Gu, Andrew Chi-Chih Yao', 'link': 'https://arxiv.org/abs/2501.06425', 'abstract': 'Scaling language models to handle longer input sequences typically necessitates large key-value (KV) caches, resulting in substantial memory overhead during inference. In this paper, we propose Tensor Product Attention (TPA), a novel attention mechanism that uses tensor decompositions to represent queries, keys, and values compactly, significantly shrinking KV cache size at inference time. By factorizing these representations into contextual low-rank components (contextual factorization) and seamlessly integrating with RoPE, TPA achieves improved model quality alongside memory efficiency. Based on TPA, we introduce the Tensor ProducT ATTenTion Transformer (T6), a new model architecture for sequence modeling. Through extensive empirical evaluation of language modeling tasks, we demonstrate that T6 exceeds the performance of standard Transformer baselines including MHA, MQA, GQA, and MLA across various metrics, including perplexity and a range of renowned evaluation benchmarks. Notably, TPAs memory efficiency enables the processing of significantly longer sequences under fixed resource constraints, addressing a critical scalability challenge in modern language models. The code is available at this https URL.', 'abstract_zh': '将下面的论文内容或标题翻译成中文，要符合学术规范：\n\n将语言模型扩展以处理更长的输入序列通常需要大量关键值（KV）缓存，导致推理时产生显着的内存开销。在本文中，我们提出了一种新的注意力机制——张量乘积注意力（TPA），该机制使用张量分解来紧凑地表示查询、键和值，显著减小了推理时的KV缓存大小。通过将这些表示分解为上下文低秩组件（上下文分解）并无缝地与RoPE结合，TPA 在保持模型质量的同时实现了内存效率的提升。基于TPA，我们引入了一种新的序列建模模型架构——张量乘积注意力变换器（T6）。通过对各种语言建模任务进行广泛的实证评估，我们证明了T6在困惑度和其他多种评价基准上超过了包括MHA、MQA、GQA和MLA在内的标准Transformer基线模型的各种度量标准。值得注意的是，TPA的内存效率使得在固定资源约束下能够处理显著更长的序列，从而解决了现代语言模型中一个重要可扩展性挑战。相关代码可通过以下链接获取：[这里](这个网址请替换为实际的网址)。', 'title_zh': '张量积注意力机制即为一切所需'}
{'arxiv_id': 'arXiv:2501.06417', 'title': 'DiscQuant: A Quantization Method for Neural Networks Inspired by Discrepancy Theory', 'authors': 'Jerry Chee, Arturs Backurs, Rainie Heck, Li Zhang, Janardhan Kulkarni, Thomas Rothvoss, Sivakanth Gopi', 'link': 'https://arxiv.org/abs/2501.06417', 'abstract': 'Quantizing the weights of a neural network has two steps: (1) Finding a good low bit-complexity representation for weights (which we call the quantization grid) and (2) Rounding the original weights to values in the quantization grid. In this paper, we study the problem of rounding optimally given any quantization grid. The simplest and most commonly used way to round is Round-to-Nearest (RTN). By rounding in a data-dependent way instead, one can improve the quality of the quantized model significantly.\nWe study the rounding problem from the lens of \\emph{discrepancy theory}, which studies how well we can round a continuous solution to a discrete solution without affecting solution quality too much. We prove that given $m=\\mathrm{poly}(1/\\epsilon)$ samples from the data distribution, we can round all but $O(m)$ model weights such that the expected approximation error of the quantized model on the true data distribution is $\\le \\epsilon$ as long as the space of gradients of the original model is approximately low rank (which we empirically validate).\nOur proof, which is algorithmic, inspired a simple and practical rounding algorithm called \\emph{DiscQuant}. In our experiments, we demonstrate that DiscQuant significantly improves over the prior state-of-the-art rounding method called GPTQ and the baseline RTN over a range of benchmarks on Phi3mini-3.8B and Llama3.1-8B. For example, rounding Phi3mini-3.8B to a fixed quantization grid with 3.25 bits per parameter using DiscQuant gets 64\\% accuracy on the GSM8k dataset, whereas GPTQ achieves 54\\% and RTN achieves 31\\% (the original model achieves 84\\%). We make our code available at this https URL.', 'abstract_zh': '神经网络权重的量化分为两个步骤：（1）寻找一个良好的低位复杂度表示（我们称之为量化网格），（2）将原始权重四舍五入到量化网格中的值。在本文中，我们研究了给定任何量化网格时如何最优地进行四舍五入的问题。最简单且最常用的方法是Round-to-Nearest (RTN) 四舍五入。通过以数据依赖的方式四舍五入，可以显著提高量化模型的质量。\n\n我们从\\emph{不协调理论}的角度研究了四舍五入问题，该理论研究如何将连续解四舍五入为离散解而不显着影响解的质量。我们证明，在从数据分布中获取$m=\\mathrm{poly}(1/\\epsilon)$个样本的情况下，可以将除$O(m)$个模型权重以外的所有权重四舍五入，使得量化模型在真实数据分布上的期望近似误差$\\le \\epsilon$，只要原始模型的梯度空间大致低秩（我们通过实验验证了这一点）。\n\n我们的证明是算法性的，启发了一种简单且实用的四舍五入算法，称为\\emph{DiscQuant}。在我们的实验中，我们证明了使用DiscQuant相比之前的先进行的最优四舍五入方法GPTQ和基线RTN，在Phi3mini-3.8B和Llama3.1-8B的一系列基准上，都取得了显著的改进。例如，使用DiscQuant将Phi3mini-3.8B量化到每个参数3.25位的固定量化网格上，在GSM8k数据集上的准确率达到64%，而GPTQ为54%，RTN为31%（原始模型为84%）。我们的代码可以在以下链接获取：this https URL。', 'title_zh': 'DiscQuant：一种受偏差理论启发的神经网络量化方法'}
{'arxiv_id': 'arXiv:2501.06416', 'title': 'Influencing Humans to Conform to Preference Models for RLHF', 'authors': 'Stephane Hatgis-Kessell, W. Bradley Knox, Serena Booth, Scott Niekum, Peter Stone', 'link': 'https://arxiv.org/abs/2501.06416', 'abstract': "Designing a reinforcement learning from human feedback (RLHF) algorithm to approximate a human's unobservable reward function requires assuming, implicitly or explicitly, a model of human preferences. A preference model that poorly describes how humans generate preferences risks learning a poor approximation of the human's reward function. In this paper, we conduct three human studies to asses whether one can influence the expression of real human preferences to more closely conform to a desired preference model. Importantly, our approach does not seek to alter the human's unobserved reward function. Rather, we change how humans use this reward function to generate preferences, such that they better match whatever preference model is assumed by a particular RLHF algorithm. We introduce three interventions: showing humans the quantities that underlie a preference model, which is normally unobservable information derived from the reward function; training people to follow a specific preference model; and modifying the preference elicitation question. All intervention types show significant effects, providing practical tools to improve preference data quality and the resultant alignment of the learned reward functions. Overall we establish a novel research direction in model alignment: designing interfaces and training interventions to increase human conformance with the modeling assumptions of the algorithm that will learn from their input.", 'abstract_zh': '本论文旨在从人类反馈中设计强化学习（RLHF）算法以逼近人类的不可观察奖励函数，这需要隐含或显式地假设某种人类偏好的模型。一个不良描述人类偏好生成机制的偏好模型可能会导致学习到一个不准确的人类奖励函数。在本文中，我们通过三项人类研究评估是否可以通过干预方法来影响人类偏好的表达，使其更接近于预设的偏好模型。重要的是，我们的方法并未试图改变人类的未观察到的奖励函数，而是改变人类使用该奖励函数生成偏好的方式，使它们更好地与特定RLHF算法所假设的偏好模型相匹配。我们介绍了三种干预措施：向人类展示构成偏好模型的基础量，这些通常是难以观察到的从奖励函数中派生的信息；训练人们遵循特定的偏好模型；修改偏好提取问题。所有干预类型均显示出显著效果，提供了改善偏好数据质量和所学奖励函数与人类输入的一致性的实用工具。总体而言，我们确立了一个新的研究方向，即设计界面和训练干预措施以增加人类与算法建模假设的一致性，该算法将从人类的输入中学习。', 'title_zh': '影响人类遵循偏好模型以实现RLHF中的规范一致性'}
{'arxiv_id': 'arXiv:2501.06405', 'title': 'FocusDD: Real-World Scene Infusion for Robust Dataset Distillation', 'authors': 'Youbing Hu, Yun Cheng, Olga Saukh, Firat Ozdemir, Anqi Lu, Zhiqiang Cao, Zhijun Li', 'link': 'https://arxiv.org/abs/2501.06405', 'abstract': 'Dataset distillation has emerged as a strategy to compress real-world datasets for efficient training. However, it struggles with large-scale and high-resolution datasets, limiting its practicality. This paper introduces a novel resolution-independent dataset distillation method Focus ed Dataset Distillation (FocusDD), which achieves diversity and realism in distilled data by identifying key information patches, thereby ensuring the generalization capability of the distilled dataset across different network architectures. Specifically, FocusDD leverages a pre-trained Vision Transformer (ViT) to extract key image patches, which are then synthesized into a single distilled image. These distilled images, which capture multiple targets, are suitable not only for classification tasks but also for dense tasks such as object detection. To further improve the generalization of the distilled dataset, each synthesized image is augmented with a downsampled view of the original image. Experimental results on the ImageNet-1K dataset demonstrate that, with 100 images per class (IPC), ResNet50 and MobileNet-v2 achieve validation accuracies of 71.0% and 62.6%, respectively, outperforming state-of-the-art methods by 2.8% and 4.7%. Notably, FocusDD is the first method to use distilled datasets for object detection tasks. On the COCO2017 dataset, with an IPC of 50, YOLOv11n and YOLOv11s achieve 24.4% and 32.1% mAP, respectively, further validating the effectiveness of our approach.', 'abstract_zh': '数据集蒸馏已经发展成为一种策略，用于压缩真实世界的数据集以实现高效的训练。然而，它在处理大规模和高分辨率的数据集时遇到了困难，限制了其实用性。本论文引入了一种新型的分辨率无关数据集蒸馏方法——聚焦数据集蒸馏（FocusDD），通过识别关键信息片段，确保蒸馏数据集在不同网络架构中的泛化能力，并实现多样性和真实性。具体来说，FocusDD 利用预训练的视觉变换器（Vision Transformer, ViT）提取关键图像片段，然后将这些片段合成到单个蒸馏图像中。这些蒸馏图像不仅适用于分类任务，还适用于密集任务如物体检测。为了进一步提高蒸馏数据集的泛化能力，每个合成图像还附带原始图像的下采样视图。在 ImageNet-1K 数据集上的实验结果显示，使用每类别 100 张图片（images per class, IPC），ResNet50 和 MobileNet-v2 分别达到验证准确率 71.0% 和 62.6%，超过最先进的方法 2.8% 和 4.7%。值得注意的是，FocusDD 是首次使用蒸馏数据集进行物体检测任务的方法。在 COCO2017 数据集上，使用每类别 50 张图片的 IPC 设置，YOLOv11n 和 YOLOv11s 分别达到 24.4% 和 32.1% 的平均精度（mAP），进一步验证了我们方法的有效性。', 'title_zh': 'FocusDD：面向现实场景的数据精简以构建鲁棒的数据集'}
{'arxiv_id': 'arXiv:2501.06399', 'title': 'Has an AI model been trained on your images?', 'authors': 'Matyas Bohacek, Hany Farid', 'link': 'https://arxiv.org/abs/2501.06399', 'abstract': 'From a simple text prompt, generative-AI image models can create stunningly realistic and creative images bounded, it seems, by only our imagination. These models have achieved this remarkable feat thanks, in part, to the ingestion of billions of images collected from nearly every corner of the internet. Many creators have understandably expressed concern over how their intellectual property has been ingested without their permission or a mechanism to opt out of training. As a result, questions of fair use and copyright infringement have quickly emerged. We describe a method that allows us to determine if a model was trained on a specific image or set of images. This method is computationally efficient and assumes no explicit knowledge of the model architecture or weights (so-called black-box membership inference). We anticipate that this method will be crucial for auditing existing models and, looking ahead, ensuring the fairer development and deployment of generative AI models.', 'abstract_zh': '仅从简单的文本提示出发，生成式AI图像模型能够创建出令人惊叹的真实且富有创意的图像。这些模型似乎仅仅受限于我们的想象力。这些模型之所以能够达成这一壮举，部分原因在于它们吸收了从互联网几乎每一个角落收集到的 billions 张图像。许多创作者合法地表达了对他们的知识产权在未经允许的情况下被吸收使用的担忧，同时也担心无法选择退出训练过程。因此，公平使用和版权侵犯的问题迅速浮现。我们描述了一种方法，可以确定模型是否在特定图像或一组图像上进行了训练。该方法计算效率高，并且无需了解模型的架构或权重（也称为黑盒成员身份推理）。我们预计这种方法对于审计现有模型以及展望未来确保生成式AI模型的更公平开发和部署至关重要。', 'title_zh': '你的图像是否被用于训练AI模型？'}
{'arxiv_id': 'arXiv:2501.06394', 'title': 'Unispeaker: A Unified Approach for Multimodality-driven Speaker Generation', 'authors': 'Zhengyan Sheng, Zhihao Du, Heng Lu, Shiliang Zhang, Zhen-Hua Ling', 'link': 'https://arxiv.org/abs/2501.06394', 'abstract': "Recent advancements in personalized speech generation have brought synthetic speech increasingly close to the realism of target speakers' recordings, yet multimodal speaker generation remains on the rise. This paper introduces UniSpeaker, a unified approach for multimodality-driven speaker generation. Specifically, we propose a unified voice aggregator based on KV-Former, applying soft contrastive loss to map diverse voice description modalities into a shared voice space, ensuring that the generated voice aligns more closely with the input descriptions. To evaluate multimodality-driven voice control, we build the first multimodality-based voice control (MVC) benchmark, focusing on voice suitability, voice diversity, and speech quality. UniSpeaker is evaluated across five tasks using the MVC benchmark, and the experimental results demonstrate that UniSpeaker outperforms previous modality-specific models. Speech samples are available at \\url{this https URL}.", 'abstract_zh': '近年来，个性化的语音生成技术取得了重大进展，合成语音越来越接近目标说话人录制的声音，但多模态说话人生成依然处于上升趋势。本文介绍了UniSpeaker，这是一种基于多模态驱动的统一说话人生成方法。具体而言，我们提出了一种基于KV-Former的统一声音聚合器，并应用软对比损失来将多种声音描述模态映射到共享的声音空间中，确保生成的声音更接近输入描述。为了评估多模态驱动的语音控制能力，我们构建了首个基于多模态的语音控制（MVC）基准，重点关注声音适用性、声音多样性和语音质量。UniSpeaker在MVC基准上进行了五个任务的评估，实验结果表明UniSpeaker优于之前模态特定的模型。相关语音样本可访问 <https://github.com/your-link-here>。', 'title_zh': '统一说话人生成方法：一种基于多模态的信息统一方法'}
{'arxiv_id': 'arXiv:2501.06389', 'title': 'Kolmogorov-Arnold networks for metal surface defect classification', 'authors': 'Maciej Krzywda, Mariusz Wermiński, Szymon Łukasik, Amir H. Gandomi', 'link': 'https://arxiv.org/abs/2501.06389', 'abstract': 'This paper presents the application of Kolmogorov-Arnold Networks (KAN) in classifying metal surface defects. Specifically, steel surfaces are analyzed to detect defects such as cracks, inclusions, patches, pitted surfaces, and scratches. Drawing on the Kolmogorov-Arnold theorem, KAN provides a novel approach compared to conventional multilayer perceptrons (MLPs), facilitating more efficient function approximation by utilizing spline functions. The results show that KAN networks can achieve better accuracy than convolutional neural networks (CNNs) with fewer parameters, resulting in faster convergence and improved performance in image classification.', 'abstract_zh': '本文探讨了柯尔莫哥洛夫-阿诺德网络（KAN）在金属表面缺陷分类中的应用。具体而言，对钢表面进行分析，以检测裂缝、夹杂物、斑块、点蚀表面和划痕等缺陷。借助柯尔莫哥洛夫-阿诺德定理，KAN 提供了一种与传统多层感知器（MLP）不同的新方法，通过利用样条函数促进更高效的函数逼近。实验结果表明，KAN 网络在参数更少的情况下可达到比卷积神经网络（CNN）更高的准确度，从而实现更快的收敛速度和更好的图像分类性能。', 'title_zh': '柯尔莫哥洛夫-阿诺尔德网络在金属表面缺陷分类中的应用'}
{'arxiv_id': 'arXiv:2501.06382', 'title': 'Dynamics of "Spontaneous" Topic Changes in Next Token Prediction with Self-Attention', 'authors': 'Mumin Jia, Jairo Diaz-Rodriguez', 'link': 'https://arxiv.org/abs/2501.06382', 'abstract': 'Human cognition can spontaneously shift conversation topics, often triggered by emotional or contextual signals. In contrast, self-attention-based language models depend on structured statistical cues from input tokens for next-token prediction, lacking this spontaneity. Motivated by this distinction, we investigate the factors that influence the next-token prediction to change the topic of the input sequence. We define concepts of topic continuity, ambiguous sequences, and change of topic, based on defining a topic as a set of token priority graphs (TPGs). Using a simplified single-layer self-attention architecture, we derive analytical characterizations of topic changes. Specifically, we demonstrate that (1) the model maintains the priority order of tokens related to the input topic, (2) a topic change occurs only if lower-priority tokens outnumber all higher-priority tokens of the input topic, and (3) unlike human cognition, longer context lengths and overlapping topics reduce the likelihood of spontaneous redirection. These insights highlight differences between human cognition and self-attention-based models in navigating topic changes and underscore the challenges in designing conversational AI capable of handling "spontaneous" conversations more naturally. To our knowledge, this is the first work to address these questions in such close relation to human conversation and thought.', 'abstract_zh': '人类认知可以自发地转换对话主题，通常是在情感或环境信号的触发下发生的。相比之下，基于自我注意的语言模型依靠输入标记的结构化统计线索来进行下一个标记的预测，缺乏这种自发性。为了探索这一差异，我们研究影响下一个标记预测以改变输入序列主题的因素。我们基于将主题定义为一组标记优先级图（TPGs）来定义主题连续性、模糊序列以及主题改变的概念。利用简化的一层自我注意架构，我们推导出主题变化的分析描述。具体而言，我们发现：\n\n1. 模型保持与输入主题相关的标记的优先顺序；\n2. 只有当较低优先级的标记数量超过输入主题中所有较高优先级的标记时，才会发生主题改变；\n3. 与人类认知不同，更长的上下文长度和重叠的主题降低了自发重新导向的可能性。\n\n这些洞察揭示了人类认知与基于自我注意的模型在处理主题变化时的差异，并突出了设计能够更自然地处理“自发”对话的对话AI所面临的挑战。据我们所知，这是首次将这些问题与人类对话和思考如此紧密相关地进行探讨的研究工作。', 'title_zh': '“自发”主题变化在自注意力机制下下一个词预测的动力学分析'}
{'arxiv_id': 'arXiv:2501.06370', 'title': 'Towards a Probabilistic Framework for Analyzing and Improving LLM-Enabled Software', 'authors': 'Juan Manuel Baldonado, Flavia Bonomo-Braberman, Víctor Adrián Braberman', 'link': 'https://arxiv.org/abs/2501.06370', 'abstract': 'Ensuring the reliability and verifiability of large language model (LLM)-enabled systems remains a significant challenge in software engineering. We propose a probabilistic framework for systematically analyzing and improving these systems by modeling and refining distributions over clusters of semantically equivalent outputs. This framework facilitates the evaluation and iterative improvement of Transference Models -- key software components that utilize LLMs to transform inputs into outputs for downstream tasks. To illustrate its utility, we apply the framework to the autoformalization problem, where natural language documentation is transformed into formal program specifications. Our case illustrates how probabilistic analysis enables the identification of weaknesses and guides focused alignment improvements, resulting in more reliable and interpretable outputs. This principled approach offers a foundation for addressing critical challenges in the development of robust LLM-enabled systems.', 'abstract_zh': '确保大型语言模型（LLM）驱动系统的可靠性和可验证性仍然是软件工程中的一个重大挑战。我们提出了一种概率框架，通过建模和细化语义等效输出的分布来系统地分析和改进这些系统。该框架有助于评估和迭代改进迁移模型——这些模型利用LLM将输入转换为下游任务的输出。为了展示其实用性，我们将该框架应用于自动形式化问题，即将自然语言文档转换为形式化程序规范。我们的案例研究展示了概率分析如何帮助识别薄弱环节并指导集中对齐改进，从而产生更可靠和可解释的输出。这种原则性的方法为解决稳健的LLM驱动系统开发中的关键挑战奠定了基础。', 'title_zh': '面向LLM赋能软件分析与改进的概率框架研究'}
{'arxiv_id': 'arXiv:2501.06365', 'title': 'Gender-Neutral Large Language Models for Medical Applications: Reducing Bias in PubMed Abstracts', 'authors': 'Elizabeth Schaefer, Kirk Roberts', 'link': 'https://arxiv.org/abs/2501.06365', 'abstract': "This paper presents a pipeline for mitigating gender bias in large language models (LLMs) used in medical literature by neutralizing gendered occupational pronouns. A dataset of 379,000 PubMed abstracts from 1965-1980 was processed to identify and modify pronouns tied to professions. We developed a BERT-based model, ``Modern Occupational Bias Elimination with Refined Training,'' or ``MOBERT,'' trained on these neutralized abstracts, and compared its performance with ``1965Bert,'' trained on the original dataset. MOBERT achieved a 70\\% inclusive replacement rate, while 1965Bert reached only 4\\%. A further analysis of MOBERT revealed that pronoun replacement accuracy correlated with the frequency of occupational terms in the training data. We propose expanding the dataset and refining the pipeline to improve performance and ensure more equitable language modeling in medical applications.", 'abstract_zh': '本文提出了一种流水线方法，用于减轻医学文献中大型语言模型（LLMs）中的性别偏见，方法是中性化职业性人称代词。我们处理了一个包含1965年至1980年间379,000篇PubMed摘要的数据集，以识别并修改与职业相关的人称代词。我们开发了一个基于BERT的模型，“现代职业偏见消除与精细化训练”（Modern Occupational Bias Elimination with Refined Training），简称MOBERT，该模型在这些中性化摘要上进行训练，并将其性能与基于原始数据集训练的“1965Bert”进行了比较。MOBERT实现了70%的包容性替换率，而1965Bert仅达到4%。进一步分析表明，MOBERT的代词替换准确性与训练数据中职业术语的频率相关。我们建议扩大数据集并优化流水线，以提高性能并确保更为公平的语言模型在医学应用中的使用。', 'title_zh': '面向医学应用的性别中立大型语言模型：减少PubMed摘要中的偏见'}
{'arxiv_id': 'arXiv:2501.06356', 'title': 'Ultrasound Image Synthesis Using Generative AI for Lung Ultrasound Detection', 'authors': 'Yu-Cheng Chou, Gary Y. Li, Li Chen, Mohsen Zahiri, Naveen Balaraju, Shubham Patil, Bryson Hicks, Nikolai Schnittke, David O. Kessler, Jeffrey Shupp, Maria Parker, Cristiana Baloescu, Christopher Moore, Cynthia Gregory, Kenton Gregory, Balasundar Raju, Jochen Kruecker, Alvin Chen', 'link': 'https://arxiv.org/abs/2501.06356', 'abstract': "Developing reliable healthcare AI models requires training with representative and diverse data. In imbalanced datasets, model performance tends to plateau on the more prevalent classes while remaining low on less common cases. To overcome this limitation, we propose DiffUltra, the first generative AI technique capable of synthesizing realistic Lung Ultrasound (LUS) images with extensive lesion variability. Specifically, we condition the generative AI by the introduced Lesion-anatomy Bank, which captures the lesion's structural and positional properties from real patient data to guide the image this http URL demonstrate that DiffUltra improves consolidation detection by 5.6% in AP compared to the models trained solely on real patient data. More importantly, DiffUltra increases data diversity and prevalence of rare cases, leading to a 25% AP improvement in detecting rare instances such as large lung consolidations, which make up only 10% of the dataset.", 'abstract_zh': '开发可靠的医疗AI模型需要使用代表性且多样的数据进行训练。在不平衡数据集中，模型的表现往往在常见类别的性能上趋于稳定，而在不常见的情况下的表现较低。为克服这一局限，我们提出了DiffUltra，这是第一个能够生成具有广泛病变变异性的现实肺超声（LUS）图像的生成AI技术。具体而言，我们通过引入的“病变解剖库”对生成AI进行条件化，该库从实际患者数据中捕捉病变的结构和位置特性，以指导图像生成。实验结果表明，DiffUltra在AP（面积下曲线）上将浸润检测性能提高了5.6%，相较于仅使用实际患者数据训练的模型。更重要的是，DiffUltra增加了数据的多样性和稀有案例的普及性，在检测大型肺浸润等仅占数据集10%的稀有实例方面，其AP提高了25%。', 'title_zh': '使用生成式AI进行肺部超声成像合成与检测'}
{'arxiv_id': 'arXiv:2501.06339', 'title': 'On The Statistical Complexity of Offline Decision-Making', 'authors': 'Thanh Nguyen-Tang, Raman Arora', 'link': 'https://arxiv.org/abs/2501.06339', 'abstract': 'We study the statistical complexity of offline decision-making with function approximation, establishing (near) minimax-optimal rates for stochastic contextual bandits and Markov decision processes. The performance limits are captured by the pseudo-dimension of the (value) function class and a new characterization of the behavior policy that \\emph{strictly} subsumes all the previous notions of data coverage in the offline decision-making literature. In addition, we seek to understand the benefits of using offline data in online decision-making and show nearly minimax-optimal rates in a wide range of regimes.', 'abstract_zh': '我们研究了使用函数近似的离线决策中的统计复杂性，建立了随机上下文臂bandits和马尔可夫决策过程的（近似）最小最大最优率。这些性能极限由函数类（价值函数类）的伪维数捕获，并且通过一个新的表征行为策略的方式严格地涵盖了离线决策文献中所有关于数据覆盖的先前观念。此外，我们还探讨了使用离线数据进行在线决策所带来的好处，并在广泛的条件下展示了几乎最小最大最优率。', 'title_zh': '关于离线决策制定的统计复杂性'}
{'arxiv_id': 'arXiv:2501.06332', 'title': 'Aggregating Low Rank Adapters in Federated Fine-tuning', 'authors': 'Evelyn Trautmann, Ian Hales, Martin F. Volk', 'link': 'https://arxiv.org/abs/2501.06332', 'abstract': 'Fine-tuning large language models requires high computational and memory resources, and is therefore associated with significant costs. When training on federated datasets, an increased communication effort is also needed. For this reason, parameter-efficient methods (PEFT) are becoming increasingly important. In this context, very good results have already been achieved by fine-tuning with low-rank adaptation methods (LoRA). The application of LoRA methods in Federated Learning, and especially the aggregation of adaptation matrices, is a current research field. In this article, we propose a novel aggregation method and compare it with different existing aggregation methods of low rank adapters trained in a federated fine-tuning of large machine learning models and evaluate their performance with respect to selected GLUE benchmark datasets.', 'abstract_zh': '微调大规模语言模型需要高度的计算和内存资源，因此与显著的成本相关。在联邦数据集上进行训练时，还需要增加通信量。因此，参数高效方法（PEFT）变得越来越重要。在此背景下，通过低秩适应方法（LoRA）进行微调已经取得了非常好的效果。LoRA方法在联邦学习中的应用，特别是适应矩阵的聚合，是当前的研究热点。在本文中，我们提出了一种新的聚合方法，并将其与不同现有的联邦微调大规模机器学习模型的低秩适配器的聚合方法进行了比较，基于选定的GLUE基准数据集评估了它们的性能。', 'title_zh': '联邦微调中低秩适配器的聚合'}
{'arxiv_id': 'arXiv:2501.06320', 'title': 'TTS-Transducer: End-to-End Speech Synthesis with Neural Transducer', 'authors': 'Vladimir Bataev, Subhankar Ghosh, Vitaly Lavrukhin, Jason Li', 'link': 'https://arxiv.org/abs/2501.06320', 'abstract': 'This work introduces TTS-Transducer - a novel architecture for text-to-speech, leveraging the strengths of audio codec models and neural transducers. Transducers, renowned for their superior quality and robustness in speech recognition, are employed to learn monotonic alignments and allow for avoiding using explicit duration predictors. Neural audio codecs efficiently compress audio into discrete codes, revealing the possibility of applying text modeling approaches to speech generation. However, the complexity of predicting multiple tokens per frame from several codebooks, as necessitated by audio codec models with residual quantizers, poses a significant challenge. The proposed system first uses a transducer architecture to learn monotonic alignments between tokenized text and speech codec tokens for the first codebook. Next, a non-autoregressive Transformer predicts the remaining codes using the alignment extracted from transducer loss. The proposed system is trained end-to-end. We show that TTS-Transducer is a competitive and robust alternative to contemporary TTS systems.', 'abstract_zh': '本文介绍了TTS-Transducer——一种结合了音频编解码模型和神经转换器优点的新颖文本到语音架构。转换器由于其在语音识别方面出色的质量和鲁棒性，被用来学习单调对齐并且避免使用显式的时长预测器。神经音频编解码器能够高效地将音频压缩为离散代码，这为应用文本建模方法到语音生成提供了可能性。然而，音频编解码器模型中残留量化器的要求导致预测每个框架中的多个标记变得复杂，这是个重大挑战。所提出系统首先使用转换器架构来学习标记化文本和首个代码本的语音编解码器标记之间的单调对齐。然后，一个非自回归Transformer利用从转换器损失提取的对齐信息预测剩余的代码。所提出系统是端到端训练的。我们展示TTS-Transducer是可以与当代TTS系统竞争并具有强大鲁棒性的替代方案。', 'title_zh': 'TTS-Transducer：基于神经转换器的端到端语音合成'}
{'arxiv_id': 'arXiv:2501.06317', 'title': 'Understanding How Paper Writers Use AI-Generated Captions in Figure Caption Writing', 'authors': "Ho Yin, Ting-Yao Hsu, Jiyoo Min, Sungchul Kim, Ryan A. Rossi, Tong Yu, Hyunggu Jung, Ting-Hao 'Kenneth' Huang", 'link': 'https://arxiv.org/abs/2501.06317', 'abstract': 'Figures and their captions play a key role in scientific publications. However, despite their importance, many captions in published papers are poorly crafted, largely due to a lack of attention by paper authors. While prior AI research has explored caption generation, it has mainly focused on reader-centered use cases, where users evaluate generated captions rather than actively integrating them into their writing. This paper addresses this gap by investigating how paper authors incorporate AI-generated captions into their writing process through a user study involving 18 participants. Each participant rewrote captions for two figures from their own recently published work, using captions generated by state-of-the-art AI models as a resource. By analyzing video recordings of the writing process through interaction analysis, we observed that participants often began by copying and refining AI-generated captions. Paper writers favored longer, detail-rich captions that integrated textual and visual elements but found current AI models less effective for complex figures. These findings highlight the nuanced and diverse nature of figure caption composition, revealing design opportunities for AI systems to better support the challenges of academic writing.', 'abstract_zh': '图表及其说明在科学出版物中起着关键作用。然而，尽管它们的重要性，许多已发表论文中的说明文字质量较差，这主要是由于论文作者缺乏足够的关注。尽管先前的AI研究探索了说明文字生成，大多数研究主要关注读者为中心的应用场景，用户评估生成的说明文字，而不是主动将它们融入写作过程。本研究通过一项涉及18名参与者的研究，填补了这一空白，旨在探讨论文作者如何通过重新编写自己最近发表作品中的两个图标的说明文字，将AI生成的说明文字融入到写作过程中。每位参与者利用最先进的AI模型生成的说明文字作为资源，重新编写了两个图标的说明文字。通过对写作过程的视频录制进行交互分析，我们发现参与者往往首先复制并改进AI生成的说明文字。论文作者更倾向于使用较长且包含丰富文本和视觉元素的说明文字，但发现当前的AI模型对复杂的图表效果较差。这些发现揭示了图表说明文字编写的复杂性和多样性，指出了AI系统在更好地支持学术写作挑战方面的设计机会。', 'title_zh': '理解论文作者在图注写作中使用AI生成图注的方式'}
{'arxiv_id': 'arXiv:2501.06293', 'title': 'LensNet: Enhancing Real-time Microlensing Event Discovery with Recurrent Neural Networks in the Korea Microlensing Telescope Network', 'authors': 'Javier Viaña, Kyu-Ha Hwang, Zoë de Beurs, Jennifer C. Yee, Andrew Vanderburg, Michael D. Albrow, Sun-Ju Chung, Andrew Gould, Cheongho Han, Youn Kil Jung, Yoon-Hyun Ryu, In-Gu Shin, Yossi Shvartzvald, Hongjing Yang, Weicheng Zang, Sang-Mok Cha, Dong-Jin Kim, Seung-Lee Kim, Chung-Uk Lee, Dong-Joo Lee, Yongseok Lee, Byeong-Gon Park, Richard W. Pogge', 'link': 'https://arxiv.org/abs/2501.06293', 'abstract': 'Traditional microlensing event vetting methods require highly trained human experts, and the process is both complex and time-consuming. This reliance on manual inspection often leads to inefficiencies and constrains the ability to scale for widespread exoplanet detection, ultimately hindering discovery rates. To address the limits of traditional microlensing event vetting, we have developed LensNet, a machine learning pipeline specifically designed to distinguish legitimate microlensing events from false positives caused by instrumental artifacts, such as pixel bleed trails and diffraction spikes. Our system operates in conjunction with a preliminary algorithm that detects increasing trends in flux. These flagged instances are then passed to LensNet for further classification, allowing for timely alerts and follow-up observations. Tailored for the multi-observatory setup of the Korea Microlensing Telescope Network (KMTNet) and trained on a rich dataset of manually classified events, LensNet is optimized for early detection and warning of microlensing occurrences, enabling astronomers to organize follow-up observations promptly. The internal model of the pipeline employs a multi-branch Recurrent Neural Network (RNN) architecture that evaluates time-series flux data with contextual information, including sky background, the full width at half maximum of the target star, flux errors, PSF quality flags, and air mass for each observation. We demonstrate a classification accuracy above 87.5%, and anticipate further improvements as we expand our training set and continue to refine the algorithm.', 'abstract_zh': '传统的微透镜事件筛选方法需要高度训练的人类专家，且整个过程既复杂又耗时。这种依赖人工检查的方法往往会导致效率低下，并限制了扩展以进行广泛的系外行星检测的能力，最终妨碍了发现率的提升。为了解决传统微透镜事件筛选的限制，我们开发了LensNet，这是一种专门设计的机器学习管道，用于区分合法的微透镜事件和由仪器伪影引起的假阳性事件，如像素溢出轨迹和衍射星芒。该系统与一个初步算法相配合，该算法可以检测光谱流量增加的趋势。被标记的实例随后传递给LensNet进行进一步分类，从而实现及时的警报和后续观测。该系统针对韩国微透镜望远镜网络（KMTNet）的多台观测台站进行了定制，并在大量手动分类事件的数据集上进行了训练，从而优化了微透镜事件的早期检测和预警能力，使天文学家能够迅速安排后续观测。管道内部模型采用多分支循环神经网络（RNN）架构，用于评估包括天空背景、目标星星全宽度半最大值、光谱流量误差、PSF质量标志和每个观测的气团指数等上下文信息的时间序列光谱流量数据。我们展示了超过87.5%的分类精度，并预计随着我们扩大训练集并继续优化算法，精度将进一步提高。', 'title_zh': 'LensNet：韩国微透镜望远镜网络中使用递归神经网络增强实时微透镜事件发现'}
{'arxiv_id': 'arXiv:2501.06286', 'title': 'Bactrainus: Optimizing Large Language Models for Multi-hop Complex Question Answering Tasks', 'authors': 'Iman Barati, Arash Ghafouri, Behrouz Minaei-Bidgoli', 'link': 'https://arxiv.org/abs/2501.06286', 'abstract': "In recent years, the use of large language models (LLMs) has significantly increased, and these models have demonstrated remarkable performance in a variety of general language tasks. However, the evaluation of their performance in domain-specific tasks, particularly those requiring deep natural language understanding, has received less attention. In this research, we evaluate the ability of large language models in performing domain-specific tasks, focusing on the multi-hop question answering (MHQA) problem using the HotpotQA dataset. This task, due to its requirement for reasoning and combining information from multiple textual sources, serves as a challenging benchmark for assessing the language comprehension capabilities of these models. To tackle this problem, we have designed a two-stage selector-reader architecture, where each stage utilizes an independent LLM. In addition, methods such as Chain of Thought (CoT) and question decomposition have been employed to investigate their impact on improving the model's performance. The results of the study show that the integration of large language models with these techniques can lead to up to a 4% improvement in F1 score for finding answers, providing evidence of the models' ability to handle domain-specific tasks and their understanding of complex language.", 'abstract_zh': '近年来，大型语言模型（LLMs）的应用显著增加，这些模型在多种通用语言任务中表现出色。然而，它们在特定领域任务中的性能评估，尤其是在需要深入自然语言理解的任务中，受到的关注较少。在此项研究中，我们评估了大型语言模型在完成特定领域任务的能力，重点关注使用HotpotQA数据集的多跳问题回答（MHQA）问题。由于该任务需要进行推理并结合来自多个文本来源的信息，因此它是一个评估这些模型语言理解能力的具有挑战性的基准。为应对这一问题，我们设计了一种两阶段的选择器-阅读器架构，每个阶段均使用独立的LLM。此外，我们还采用了Chain of Thought（CoT）和问题分解等方法，以探讨这些技术对提高模型性能的影响。研究结果表明，将大型语言模型与这些技术相结合可以提高多达4%的F1分数，这为模型处理特定领域任务及其理解复杂语言的能力提供了证据。', 'title_zh': 'Bactrainus：为多跳复杂问题回答任务优化大型语言模型'}
{'arxiv_id': 'arXiv:2501.06283', 'title': 'Dafny as Verification-Aware Intermediate Language for Code Generation', 'authors': 'Yue Chen Li, Stefan Zetzsche, Siva Somayyajula', 'link': 'https://arxiv.org/abs/2501.06283', 'abstract': 'Using large language models (LLMs) to generate source code from natural language prompts is a popular and promising idea with a wide range of applications. One of its limitations is that the generated code can be faulty at times, often in a subtle way, despite being presented to the user as correct. In this paper, we explore ways in which formal methods can assist with increasing the quality of code generated by an LLM. Instead of emitting code in a target language directly, we propose that the user guides the LLM to first generate an opaque intermediate representation, in the verification-aware language Dafny, that can be automatically validated for correctness against agreed on specifications. The correct Dafny program is then compiled to the target language and returned to the user. All user-system interactions throughout the procedure occur via natural language; Dafny code is never exposed. We describe our current prototype and report on its performance on the HumanEval Python code generation benchmarks.', 'abstract_zh': '使用大型语言模型（LLMs）从自然语言提示生成源代码是一种流行且有前途的想法，具有广泛的应用前景。其一个局限性在于，生成的代码有时可能存在错误，尽管这些代码往往被呈现为正确的。在本文中，我们探讨了形式化方法如何帮助提高LLM生成代码的质量。我们提出的方案不是直接生成目标语言的代码，而是让用户引导LLM首先生成一个面向验证的不透明中介表示，该表示使用Dafny语言编写，并可以通过约定的规范自动验证其正确性。随后，正确的Dafny程序被编译为目标语言并返回给用户。在整个过程中，用户与系统的交互均通过自然语言实现；从不暴露Dafny代码。我们描述了当前的原型，并报告了其在HumanEval Python代码生成基准测试中的表现。', 'title_zh': 'Dafny作为一种考虑验证的中间语言用于代码生成'}
{'arxiv_id': 'arXiv:2501.06282', 'title': 'MinMo: A Multimodal Large Language Model for Seamless Voice Interaction', 'authors': 'Qian Chen, Yafeng Chen, Yanni Chen, Mengzhe Chen, Yingda Chen, Chong Deng, Zhihao Du, Ruize Gao, Changfeng Gao, Zhifu Gao, Yabin Li, Xiang Lv, Jiaqing Liu, Haoneng Luo, Bin Ma, Chongjia Ni, Xian Shi, Jialong Tang, Hui Wang, Hao Wang, Wen Wang, Yuxuan Wang, Yunlan Xu, Fan Yu, Zhijie Yan, Yexin Yang, Baosong Yang, Xian Yang, Guanrou Yang, Tianyu Zhao, Qinglin Zhang, Shiliang Zhang, Nan Zhao, Pei Zhang, Chong Zhang, Jinren Zhou', 'link': 'https://arxiv.org/abs/2501.06282', 'abstract': 'Recent advancements in large language models (LLMs) and multimodal speech-text models have laid the groundwork for seamless voice interactions, enabling real-time, natural, and human-like conversations. Previous models for voice interactions are categorized as native and aligned. Native models integrate speech and text processing in one framework but struggle with issues like differing sequence lengths and insufficient pre-training. Aligned models maintain text LLM capabilities but are often limited by small datasets and a narrow focus on speech tasks. In this work, we introduce MinMo, a Multimodal Large Language Model with approximately 8B parameters for seamless voice interaction. We address the main limitations of prior aligned multimodal models. We train MinMo through multiple stages of speech-to-text alignment, text-to-speech alignment, speech-to-speech alignment, and duplex interaction alignment, on 1.4 million hours of diverse speech data and a broad range of speech tasks. After the multi-stage training, MinMo achieves state-of-the-art performance across various benchmarks for voice comprehension and generation while maintaining the capabilities of text LLMs, and also facilitates full-duplex conversation, that is, simultaneous two-way communication between the user and the system. Moreover, we propose a novel and simple voice decoder that outperforms prior models in voice generation. The enhanced instruction-following capabilities of MinMo supports controlling speech generation based on user instructions, with various nuances including emotions, dialects, and speaking rates, and mimicking specific voices. For MinMo, the speech-to-text latency is approximately 100ms, full-duplex latency is approximately 600ms in theory and 800ms in practice. The MinMo project web page is this https URL, and the code and models will be released soon.', 'abstract_zh': '近年来，大规模语言模型（LLMs）和多模态语音-文本模型的进展为无缝语音交互奠定了基础，使其能够实现实时、自然和接近人类的对话。以前用于语音交互的模型主要分为原生模型和对齐模型。原生模型将语音和文本处理集成在一个框架中，但存在序列长度不同和预训练不足等问题。对齐模型保持了文本LLM的能力，但常常受限于小数据集和对语音任务的狭隘关注。在这项工作中，我们引入了MinMo，这是一个具有约80亿参数的多模态大型语言模型，适用于无缝语音交互。我们解决了前对齐多模态模型的主要局限性。我们通过多次阶段的语音到文本对齐、文本到语音对齐、语音到语音对齐和半双工交互对齐，对MinMo进行训练，使用了140万小时的多样化语音数据和广泛的语音任务。经过多阶段训练后，MinMo在语音理解和生成的各种基准测试中取得了最先进的性能，同时保持了文本LLM的能力，并且支持全双工对话，即用户与系统之间的双向通信。此外，我们提出了一种新颖且简单的语音解码器，在语音生成方面优于先前的模型。MinMo增强的指令遵循能力支持根据用户指令控制语音生成，包括情感、方言和语速等各种细微差别，并模仿特定声音。对于MinMo，语音到文本的延迟大约为100毫秒，理论上的全双工延迟约为600毫秒，在实践中约为800毫秒。MinMo项目的网页链接为：[此处的URL链接]，代码和模型将很快发布。', 'title_zh': 'MinMo：一种支持无缝语音交互的多模态大型语言模型'}
{'arxiv_id': 'arXiv:2501.06274', 'title': 'Polarized Patterns of Language Toxicity and Sentiment of Debunking Posts on Social Media', 'authors': 'Wentao Xu, Wenlu Fan, Shiqian Lu, Tenghao Li, Bin Wang', 'link': 'https://arxiv.org/abs/2501.06274', 'abstract': "Here's a condensed 1920-character version: The rise of misinformation and fake news in online political discourse poses significant challenges to democratic processes and public engagement. While debunking efforts aim to counteract misinformation and foster fact-based dialogue, these discussions often involve language toxicity and emotional polarization. We examined over 86 million debunking tweets and more than 4 million Reddit debunking comments to investigate the relationship between language toxicity, pessimism, and social polarization in debunking efforts. Focusing on discussions of the 2016 and 2020 U.S. presidential elections and the QAnon conspiracy theory, our analysis reveals three key findings: (1) peripheral participants (1-degree users) play a disproportionate role in shaping toxic discourse, driven by lower community accountability and emotional expression; (2) platform mechanisms significantly influence polarization, with Twitter amplifying partisan differences and Reddit fostering higher overall toxicity due to its structured, community-driven interactions; and (3) a negative correlation exists between language toxicity and pessimism, with increased interaction reducing toxicity, especially on Reddit. We show that platform architecture affects informational complexity of user interactions, with Twitter promoting concentrated, uniform discourse and Reddit encouraging diverse, complex communication. Our findings highlight the importance of user engagement patterns, platform dynamics, and emotional expressions in shaping polarization in debunking discourse. This study offers insights for policymakers and platform designers to mitigate harmful effects and promote healthier online discussions, with implications for understanding misinformation, hate speech, and political polarization in digital environments.", 'abstract_zh': '网络政治话语中虚假信息和假新闻的兴起对民主进程和公众参与构成了重大挑战。尽管澄清工作旨在反驳虚假信息并促进基于事实的对话，但这类讨论往往涉及语言毒性以及情绪极化。我们分析了超过8600万条用于澄清的推特和超过400万条来自Reddit的澄清评论，以探究语言毒性、悲观情绪与社交极化之间的关系。我们聚焦于2016年和2020年美国总统选举以及QAnon阴谋理论的讨论，研究发现以下三个关键发现：（1）外围参与者（1度用户）在塑造有毒话语中扮演了不适当的重要角色，这主要是由于其较低的社区责任感和情感表达；（2）平台机制显著影响了极化现象，推特放大了党派差异，而Reddit由于其结构化的、社区驱动的互动方式则导致整体毒性更高；（3）语言毒性与悲观情绪之间存在负相关关系，通过增加互动可以减少毒性，尤其是在Reddit上。研究显示，平台架构影响用户互动的信息复杂性，推特促进集中且统一的对话，而Reddit则鼓励多样化的复杂沟通。我们的研究结果强调了用户参与模式、平台动态以及情感表达在塑造澄清讨论中极化现象中的重要性。本研究为政策制定者和平台设计师提供了解决策略以减轻负面影响并促进健康在线讨论的见解，并对理解数字环境中虚假信息、仇恨言论和政治极化具有重要意义。', 'title_zh': '社交媒体上辟谣帖子中语言毒性和观点极化模式的研究'}
{'arxiv_id': 'arXiv:2501.06271', 'title': 'Large Language Models for Bioinformatics', 'authors': 'Wei Ruan, Yanjun Lyu, Jing Zhang, Jiazhang Cai, Peng Shu, Yang Ge, Yao Lu, Shang Gao, Yue Wang, Peilong Wang, Lin Zhao, Tao Wang, Yufang Liu, Luyang Fang, Ziyu Liu, Zhengliang Liu, Yiwei Li, Zihao Wu, Junhao Chen, Hanqi Jiang, Yi Pan, Zhenyuan Yang, Jingyuan Chen, Shizhe Liang, Wei Zhang, Terry Ma, Yuan Dou, Jianli Zhang, Xinyu Gong, Qi Gan, Yusong Zou, Zebang Chen, Yuanxin Qian, Shuo Yu, Jin Lu, Kenan Song, Xianqiao Wang, Andrea Sikora, Gang Li, Xiang Li, Quanzheng Li, Yingfeng Wang, Lu Zhang, Yohannes Abate, Lifang He, Wenxuan Zhong, Rongjie Liu, Chao Huang, Wei Liu, Ye Shen, Ping Ma, Hongtu Zhu, Yajun Yan, Dajiang Zhu, Tianming Liu', 'link': 'https://arxiv.org/abs/2501.06271', 'abstract': 'With the rapid advancements in large language model (LLM) technology and the emergence of bioinformatics-specific language models (BioLMs), there is a growing need for a comprehensive analysis of the current landscape, computational characteristics, and diverse applications. This survey aims to address this need by providing a thorough review of BioLMs, focusing on their evolution, classification, and distinguishing features, alongside a detailed examination of training methodologies, datasets, and evaluation frameworks. We explore the wide-ranging applications of BioLMs in critical areas such as disease diagnosis, drug discovery, and vaccine development, highlighting their impact and transformative potential in bioinformatics. We identify key challenges and limitations inherent in BioLMs, including data privacy and security concerns, interpretability issues, biases in training data and model outputs, and domain adaptation complexities. Finally, we highlight emerging trends and future directions, offering valuable insights to guide researchers and clinicians toward advancing BioLMs for increasingly sophisticated biological and clinical applications.', 'abstract_zh': '随着大型语言模型（LLM）技术的迅速进步和生物信息学特定语言模型（BioLMs）的出现，对当前景观、计算特征和多样应用进行全面分析的需求日益增长。本文旨在通过全面回顾BioLMs，关注其演变、分类和区别特征，以及详细的训练方法、数据集和评估框架来满足这一需求。我们探讨了BioLMs在疾病诊断、药物发现和疫苗开发等关键领域的广泛应用，并强调了它们在生物信息学领域的影响力和变革潜力。我们还指出了BioLMs固有的关键挑战和限制，包括数据隐私和安全问题、可解释性问题、训练数据和模型输出中的偏差，以及领域适应的复杂性。最后，我们提出了新兴趋势和未来方向，为研究人员和临床医生提供有价值的见解，以指导他们进一步发展BioLMs，使其适用于日益复杂的生命科学和临床应用。', 'title_zh': '大型语言模型在生物信息学中的应用'}
{'arxiv_id': 'arXiv:2501.06262', 'title': 'Towards smart and adaptive agents for active sensing on edge devices', 'authors': 'Devendra Vyas, Miguel de Prado, Tim Verbelen', 'link': 'https://arxiv.org/abs/2501.06262', 'abstract': "TinyML has made deploying deep learning models on low-power edge devices feasible, creating new opportunities for real-time perception in constrained environments. However, the adaptability of such deep learning methods remains limited to data drift adaptation, lacking broader capabilities that account for the environment's underlying dynamics and inherent uncertainty. Deep learning's scaling laws, which counterbalance this limitation by massively up-scaling data and model size, cannot be applied when deploying on the Edge, where deep learning limitations are further amplified as models are scaled down for deployment on resource-constrained devices.\nThis paper presents a smart agentic system capable of performing on-device perception and planning, enabling active sensing on the edge. By incorporating active inference into our solution, our approach extends beyond deep learning capabilities, allowing the system to plan in dynamic environments while operating in real time with a modest total model size of 2.3 MB. We showcase our proposed system by creating and deploying a saccade agent connected to an IoT camera with pan and tilt capabilities on an NVIDIA Jetson embedded device. The saccade agent controls the camera's field of view following optimal policies derived from the active inference principles, simulating human-like saccadic motion for surveillance and robotics applications.", 'abstract_zh': 'TinyML使得在低功耗边缘设备上部署深度学习模型成为可能，为受限环境中的实时感知创造了新的机会。然而，这类深度学习方法的适应性仍然局限于数据漂移适应，缺乏能够考虑到环境潜在动态和固有不确定性更广泛的能力。深度学习的扩展法则可以通过大幅度扩大数据和模型规模来对抗这一限制，但在边缘部署时无法应用，因为在资源受限的设备上部署模型时，深度学习的限制进一步加剧。\n\n本文提出了一种智能代理系统，能够在设备端执行感知和规划，从而在边缘上提供主动采样能力。通过将主动推理纳入我们的解决方案中，我们的方法超越了深度学习的能力，使系统能够在动态环境中进行规划，并在不增加总模型大小（2.3 MB）的前提下实现实时操作。我们通过在安装有水平和垂直移动功能的物联网摄像头的NVIDIA Jetson嵌入式设备上部署一个眼球运动代理（saccade agent），展示了我们提出的方法。该眼球运动代理根据来自主动推理原则的最优策略控制相机的视场，模拟人类眼球运动，适用于监控和机器人应用。', 'title_zh': '面向边缘设备上主动感知的智能自适应代理技术'}
{'arxiv_id': 'arXiv:2501.06256', 'title': 'What Matters for In-Context Learning: A Balancing Act of Look-up and In-Weight Learning', 'authors': 'Jelena Bratulić, Sudhanshu Mittal, Christian Rupprecht, Thomas Brox', 'link': 'https://arxiv.org/abs/2501.06256', 'abstract': "Large Language Models (LLMs) have demonstrated impressive performance in various tasks, including In-Context Learning (ICL), where the model performs new tasks by conditioning solely on the examples provided in the context, without updating the model's weights. While prior research has explored the roles of pretraining data and model architecture, the key mechanism behind ICL remains unclear. In this work, we systematically uncover properties present in LLMs that support the emergence of ICL. To disambiguate these factors, we conduct a study with a controlled dataset and data sequences using a deep autoregressive model. We show that conceptual repetitions in the data sequences are crucial for ICL, more so than previously indicated training data properties like burstiness or long-tail distribution. Conceptual repetitions could refer to $n$-gram repetitions in textual data or exact image copies in image sequence data. Such repetitions also offer other previously overlooked benefits such as reduced transiency in ICL performance. Furthermore, we show that the emergence of ICL depends on balancing the in-weight learning objective with the in-context solving ability during training.", 'abstract_zh': '大型语言模型（LLMs）在各种任务中表现出令人印象深刻的性能，包括上下文内学习（ICL），在这种学习方式中，模型仅通过对提供的上下文例子进行条件化处理来执行新任务，而不更新模型的权重。尽管先前的研究已经探讨了预训练数据和模型架构的作用，但ICL背后的本质机制仍然不清楚。在本研究中，我们系统地揭示了支持ICL出现的LLMs中存在的特性。为了澄清这些因素，我们使用一个控制数据集和数据序列，并采用深度自回归模型进行了研究。我们表明，数据序列中的概念重复对于ICL至关重要，比以往所指出的训练数据特性（如突发性或长尾分布）更为重要。概念重复可以指的是文本数据中的$n$-gram重复或图像序列数据中精确的图像复制。这些重复还为ICL性能提供了其他之前忽视的好处，包括降低了ICL性能的易变性。此外，我们展示了ICL的出现取决于训练过程中内在权重学习目标与上下文解决能力之间的平衡。', 'title_zh': '影响基于上下文学习的因素：查找学习与内置学习之间的平衡研究'}
{'arxiv_id': 'arXiv:2501.06255', 'title': 'Progressive Supervision via Label Decomposition: An Long-Term and Large-Scale Wireless Traffic Forecasting Method', 'authors': 'Daojun Liang, Haixia Zhang, Dongfeng Yuan', 'link': 'https://arxiv.org/abs/2501.06255', 'abstract': 'Long-term and Large-scale Wireless Traffic Forecasting (LL-WTF) is pivotal for strategic network management and comprehensive planning on a macro scale. However, LL-WTF poses greater challenges than short-term ones due to the pronounced non-stationarity of extended wireless traffic and the vast number of nodes distributed at the city scale. To cope with this, we propose a Progressive Supervision method based on Label Decomposition (PSLD). Specifically, we first introduce a Random Subgraph Sampling (RSS) algorithm designed to sample a tractable subset from large-scale traffic data, thereby enabling efficient network training. Then, PSLD employs label decomposition to obtain multiple easy-to-learn components, which are learned progressively at shallow layers and combined at deep layers to effectively cope with the non-stationary problem raised by LL-WTF tasks. Finally, we compare the proposed method with various state-of-the-art (SOTA) methods on three large-scale WT datasets. Extensive experimental results demonstrate that the proposed PSLD significantly outperforms existing methods, with an average 2%, 4%, and 11% performance improvement on three WT datasets, respectively. In addition, we built an open source library for WT forecasting (WTFlib) to facilitate related research, which contains numerous SOTA methods and provides a strong this http URL can be reproduced through this https URL.', 'abstract_zh': '长期大规模无线流量预测（LL-WTF）对于战略网络管理和宏观规划至关重要。然而，LL-WTF 比短期预测更具挑战性，因为扩展的无线流量表现出明显的非平稳性，且分布在城市规模上的节点数量众多。为应对这一挑战，我们提出了基于标签分解的逐级监督方法（Progressive Supervision with Label Decomposition，PSLD）。具体而言，我们首先引入了一种随机子图采样（Random Subgraph Sampling, RSS）算法，用于从大规模流量数据中抽取一个可处理的子集，从而实现高效的网络训练。然后，PSLD 使用标签分解获得多个易于学习的组件，在浅层逐步学习并在深层综合，以有效应对LL-WTF 任务提出的非平稳性问题。最后，我们在三个大规模无线流量（Wireless Traffic, WT）数据集中将所提方法与多种当前最先进的（State-of-the-Art, SOTA）方法进行了比较。广泛的实验证明，所提PSLD 方法显著优于现有方法，分别在三个WT 数据集上提高了2%、4%和11%的性能。此外，我们构建了一个开源的无线流量预测库（WTFlib），以促进相关研究，该库包含多种SOTA 方法，所有实验结果都可在此 http:// URL 复现，更多信息请访问此 https:// URL。', 'title_zh': '逐级监督通过标签分解：一种长期大规模无线流量预测方法'}
{'arxiv_id': 'arXiv:2501.06254', 'title': 'Rethinking Evaluation of Sparse Autoencoders through the Representation of Polysemous Words', 'authors': 'Gouki Minegishi, Hiroki Furuta, Yusuke Iwasawa, Yutaka Matsuo', 'link': 'https://arxiv.org/abs/2501.06254', 'abstract': 'Sparse autoencoders (SAEs) have gained a lot of attention as a promising tool to improve the interpretability of large language models (LLMs) by mapping the complex superposition of polysemantic neurons into monosemantic features and composing a sparse dictionary of words. However, traditional performance metrics like Mean Squared Error and L0 sparsity ignore the evaluation of the semantic representational power of SAEs -- whether they can acquire interpretable monosemantic features while preserving the semantic relationship of words. For instance, it is not obvious whether a learned sparse feature could distinguish different meanings in one word. In this paper, we propose a suite of evaluations for SAEs to analyze the quality of monosemantic features by focusing on polysemous words. Our findings reveal that SAEs developed to improve the MSE-L0 Pareto frontier may confuse interpretability, which does not necessarily enhance the extraction of monosemantic features. The analysis of SAEs with polysemous words can also figure out the internal mechanism of LLMs; deeper layers and the Attention module contribute to distinguishing polysemy in a word. Our semantics focused evaluation offers new insights into the polysemy and the existing SAE objective and contributes to the development of more practical SAEs.', 'abstract_zh': '以下是翻译成中文的内容，符合学术规范：\n\n稀疏自编码器（Sparse Autoencoders, SAEs）因其能够通过将多义神经元的复杂叠加映射为单义特征并构建稀疏的词汇字典，从而提高大型语言模型（Large Language Models, LLMs）的可解释性，而受到了广泛关注。然而，传统的性能评估指标如均方误差（Mean Squared Error, MSE）和L0稀疏性指标忽视了对SAEs的语义表征能力的评估——即它们是否能够在保留词间语义关系的同时获取可解释的单义特征。例如，由学习得到的稀疏特征能否区分一个词的不同含义还不明显。本文提出了一套针对SAEs的评估方法，重点关注多义词，以分析单义特征的质量。我们的研究发现，旨在改进MSE-L0帕累托前沿的SAEs可能会混淆其解释性，不一定能够增强单义特征的提取。对包含多义词的SAEs的分析还揭示了LLMs的内部机制；深层层和注意力模块有助于区分词的多义性。我们的语义聚焦评估为多义性提供了新的见解，并对现有的SAE目标函数进行了补充，对于开发更实用的SAEs具有重要意义。', 'title_zh': '通过多义词表示重新审视稀疏自编码器的评估'}
{'arxiv_id': 'arXiv:2501.06253', 'title': 'The State of Post-Hoc Local XAI Techniques for Image Processing: Challenges and Motivations', 'authors': 'Rech Leong Tian Poh, Sye Loong Keoh, Liying Li', 'link': 'https://arxiv.org/abs/2501.06253', 'abstract': 'As complex AI systems further prove to be an integral part of our lives, a persistent and critical problem is the underlying black-box nature of such products and systems. In pursuit of productivity enhancements, one must not forget the need for various technology to boost the overall trustworthiness of such AI systems. One example, which is studied extensively in this work, is the domain of Explainable Artificial Intelligence (XAI). Research works in this scope are centred around the objective of making AI systems more transparent and interpretable, to further boost reliability and trust in using them. In this work, we discuss the various motivation for XAI and its approaches, the underlying challenges that XAI faces, and some open problems that we believe deserve further efforts to look into. We also provide a brief discussion of various XAI approaches for image processing, and finally discuss some future directions, to hopefully express and motivate the positive development of the XAI research space.', 'abstract_zh': '随着复杂的AI系统日益成为我们生活中不可或缺的一部分，一个持续且关键的问题是这些产品和系统的内在黑箱性质。为了提升生产力，我们不能忽视增强AI系统整体可信度的各种技术需求。本研究中广泛探讨的一个例子是可解释人工智能（XAI）领域。这一领域的研究集中在使AI系统更加透明和可解释，以进一步提高其可靠性和信任度。在本研究中，我们将讨论XAI的各种动机和方法、XAI所面临的基本挑战以及我们认为值得进一步研究的一些开放问题。我们还将简要讨论几种用于图像处理的XAI方法，并最后讨论一些未来方向，以期望表达和促进XAI研究领域的积极发展。', 'title_zh': '图像处理领域中事后局部可解释性（Post-Hoc Local XAI）技术的现状：挑战与动机'}
{'arxiv_id': 'arXiv:2501.06252', 'title': '$\\text{Transformer}^2$: Self-adaptive LLMs', 'authors': 'Qi Sun, Edoardo Cetin, Yujin Tang', 'link': 'https://arxiv.org/abs/2501.06252', 'abstract': 'Self-adaptive large language models (LLMs) aim to solve the challenges posed by traditional fine-tuning methods, which are often computationally intensive and static in their ability to handle diverse tasks. We introduce \\implname, a novel self-adaptation framework that adapts LLMs for unseen tasks in real-time by selectively adjusting only the singular components of their weight matrices. During inference, \\implname employs a two-pass mechanism: first, a dispatch system identifies the task properties, and then task-specific "expert" vectors, trained using reinforcement learning, are dynamically mixed to obtain targeted behavior for the incoming prompt. Our method outperforms ubiquitous approaches such as LoRA, with fewer parameters and greater efficiency. \\implname demonstrates versatility across different LLM architectures and modalities, including vision-language tasks. \\implname represents a significant leap forward, offering a scalable, efficient solution for enhancing the adaptability and task-specific performance of LLMs, paving the way for truly dynamic, self-organizing AI systems.', 'abstract_zh': '自适应大型语言模型（LLMs）旨在解决传统微调方法所带来的挑战，这些方法往往计算密集且在处理多样化任务方面能力有限且静态。我们提出了\\implname，这是一种新的自适应框架，能够在实际操作中通过选择性地调整其权重矩阵中的单一组件来适应未见过的任务。在推理过程中，\\implname采用两步机制：首先，调度系统识别任务属性，然后使用强化学习训练的任务特定“专家”向量动态混合，以针对传入提示获得所需的行为。我们的方法在参数较少和效率更高的情况下优于通用方法如LoRA。\\implname在不同的LLM架构和模态（包括视觉-语言任务）中展示了灵活性。\\implname代表了一个重要的进步，提供了一种可扩展且高效的解决方案，用于增强LLM的适应性和任务特定性能，为真正动态和自组织的AI系统铺平了道路。', 'title_zh': '$\\text{Transformer}^2$: 自适应大型语言模型'}
{'arxiv_id': 'arXiv:2501.06250', 'title': 'Generative AI for Cel-Animation: A Survey', 'authors': 'Yunlong Tang, Junjia Guo, Pinxin Liu, Zhiyuan Wang, Hang Hua, Jia-Xing Zhong, Yunzhong Xiao, Chao Huang, Luchuan Song, Susan Liang, Yizhi Song, Liu He, Jing Bi, Mingqian Feng, Xinyang Li, Zeliang Zhang, Chenliang Xu', 'link': 'https://arxiv.org/abs/2501.06250', 'abstract': 'Traditional Celluloid (Cel) Animation production pipeline encompasses multiple essential steps, including storyboarding, layout design, keyframe animation, inbetweening, and colorization, which demand substantial manual effort, technical expertise, and significant time investment. These challenges have historically impeded the efficiency and scalability of Cel-Animation production. The rise of generative artificial intelligence (GenAI), encompassing large language models, multimodal models, and diffusion models, offers innovative solutions by automating tasks such as inbetween frame generation, colorization, and storyboard creation. This survey explores how GenAI integration is revolutionizing traditional animation workflows by lowering technical barriers, broadening accessibility for a wider range of creators through tools like AniDoc, ToonCrafter, and AniSora, and enabling artists to focus more on creative expression and artistic innovation. Despite its potential, issues such as maintaining visual consistency, ensuring stylistic coherence, and addressing ethical considerations continue to pose challenges. Furthermore, this paper discusses future directions and explores potential advancements in AI-assisted animation. For further exploration and resources, please visit our GitHub repository: this https URL', 'abstract_zh': '传统的赛璐珞（Cel）动画生产工作流包含多个关键步骤，包括故事板制作、场景设计、关键帧动画、中间帧生成和着色，这些步骤需要大量的手动工作、技术专长以及大量的时间投入。这些挑战历来阻碍了Cel动画生产效率和扩展性的提升。生成式人工智能（GenAI），包括大型语言模型、多模态模型和扩散模型，通过自动化中间帧生成、着色和故事板制作等任务，提供了创新的解决方案。本文综述了GenAI如何通过降低技术门槛、通过AniDoc、ToonCrafter和AniSora等工具扩大创作者群体的范围，并使艺术家更专注于创作表达和艺术创新，从而重新定义传统的动画工作流程。尽管存在巨大潜力，但保持视觉一致性、确保风格一致性以及处理伦理问题等挑战仍然存在。此外，本文还探讨了AI辅助动画的未来方向，以及潜在的技术进步。欲进一步了解和探索相关内容，敬请访问我们的GitHub仓库：this https URL', 'title_zh': '面向细胞动画的生成式人工智能：一个综述'}
{'arxiv_id': 'arXiv:2501.06248', 'title': 'Utility-inspired Reward Transformations Improve Reinforcement Learning Training of Language Models', 'authors': 'Roberto-Rafael Maura-Rivero, Chirag Nagpal, Roma Patel, Francesco Visin', 'link': 'https://arxiv.org/abs/2501.06248', 'abstract': 'Current methods that train large language models (LLMs) with reinforcement learning feedback, often resort to averaging outputs of multiple rewards functions during training. This overlooks crucial aspects of individual reward dimensions and inter-reward dependencies that can lead to sub-optimal outcomes in generations. In this work, we show how linear aggregation of rewards exhibits some vulnerabilities that can lead to undesired properties of generated text. We then propose a transformation of reward functions inspired by economic theory of utility functions (specifically Inada conditions), that enhances sensitivity to low reward values while diminishing sensitivity to already high values. We compare our approach to the existing baseline methods that linearly aggregate rewards and show how the Inada-inspired reward feedback is superior to traditional weighted averaging. We quantitatively and qualitatively analyse the difference in the methods, and see that models trained with Inada-transformations score as more helpful while being less harmful.', 'abstract_zh': '当前训练大规模语言模型（LLMs）的方法，往往通过在训练过程中对多个奖励函数的输出进行平均化来利用强化学习反馈。这种方法忽视了各个奖励维度及其互相关联性的重要性，可能导致生成结果的次优性。在本研究中，我们展示了线性聚合奖励的一些局限性，这些局限性可能导致生成文本的不良属性。随后，我们提出了一个基于效用函数经济学理论（特别是Inada条件）的奖励函数变换方法，该方法增强了对低奖励值的敏感性，同时降低了对已高奖励值的敏感性。我们将本方法与现有的线性聚合奖励的基线方法进行了比较，并展示了基于Inada条件的奖励反馈优于传统加权平均的方法。我们从定量和定性的角度分析了这些方法的不同之处，并发现使用Inada变换训练的模型在帮助性方面得分更高，但在有害性方面得分较低。', 'title_zh': '基于功效的奖励转换改善语言模型的强化学习训练'}
{'arxiv_id': 'arXiv:2501.06247', 'title': 'A Survey on Algorithmic Developments in Optimal Transport Problem with Applications', 'authors': 'Sina Moradi', 'link': 'https://arxiv.org/abs/2501.06247', 'abstract': "Optimal Transport (OT) has established itself as a robust framework for quantifying differences between distributions, with applications that span fields such as machine learning, data science, and computer vision. This paper offers a detailed examination of the OT problem, beginning with its theoretical foundations, including the classical formulations of Monge and Kantorovich and their extensions to modern computational techniques. It explores cutting-edge algorithms, including Sinkhorn iterations, primal-dual strategies, and reduction-based approaches, emphasizing their efficiency and scalability in addressing high-dimensional problems. The paper also highlights emerging trends, such as integrating OT into machine learning frameworks, the development of novel problem variants, and ongoing theoretical advancements. Applications of OT are presented across a range of domains, with particular attention to its innovative application in time series data analysis via Optimal Transport Warping (OTW), a robust alternative to methods like Dynamic Time Warping. Despite the significant progress made, challenges related to scalability, robustness, and ethical considerations remain, necessitating further research. The paper underscores OT's potential to bridge theoretical depth and practical utility, fostering impactful advancements across diverse disciplines.", 'abstract_zh': '最优传输（Optimal Transport, OT）已经在量化分布差异方面确立了其稳健的框架地位，并在机器学习、数据科学和计算机视觉等多个领域找到了广泛的应用。本文对OT问题进行了详细的探讨，从其理论基础入手，包括经典的蒙格（Monge）和 Kantorovich 形式及这些形式向现代计算技术的扩展。文中探讨了最新的算法，如Sinkhorn 迭代、对偶策略和基于减少的方法，强调了它们在处理高维问题时的高效性和可扩展性。此外，本文还介绍了新兴趋势，如将OT整合进机器学习框架、开发新型问题变种以及持续的理论进展。文章展示了OT在多个领域的应用，特别关注通过最优传输扭曲（Optimal Transport Warping, OTW）方法在时间序列数据分析中的创新应用，这是一种动态时间扭曲（Dynamic Time Warping, DTW）的稳健替代方法。\n\n尽管取得了显著进展，但与可扩展性、鲁棒性及伦理考虑相关的问题仍然存在，这需要进一步的研究。本文强调了OT在理论深度与实际用途之间架起桥梁的潜力，促进了跨学科的重大进步。\n\n这样翻译不仅符合学术规范，还保持了原文的技术细节和研究视角。', 'title_zh': '算法发展在最优运输问题中的研究及其应用综述'}
{'arxiv_id': 'arXiv:2501.06246', 'title': 'A partition cover approach to tokenization', 'authors': 'Jia Peng Lim, Davin Choo, Hady W. Lauw', 'link': 'https://arxiv.org/abs/2501.06246', 'abstract': 'Tokenization is the process of encoding strings into tokens from a fixed vocabulary of size $k$ and is widely utilized in Natural Language Processing applications. The leading tokenization algorithm today is Byte Pair Encoding (BPE), which formulates the tokenization problem as a compression problem and tackles it by performing sequences of merges. In this work, we formulate tokenization as an optimization objective, show that it is NP-hard via a simple reduction from vertex cover, and propose a polynomial-time greedy algorithm GreedTok. Our formulation naturally relaxes to the well-studied weighted maximum coverage problem which has a simple $(1 - 1/e)$-approximation algorithm GreedWMC. Through empirical evaluations on real-world corpora, we show that GreedTok outperforms BPE, while achieving a comparable objective score as GreedWMC (which could have achieved a higher score due to relaxation).', 'abstract_zh': '分词是将字符串编码为固定词汇表大小为$k$的分词的过程，并且在自然语言处理应用中广泛使用。当今领先的分词算法是字节对编码（BPE），它将分词问题形式化为压缩问题，并通过一系列合并操作来解决。在这项工作中，我们将分词形式化为一个优化目标，通过一个简单的顶点覆盖归约证明它是NP难问题，并提出了一个多项式时间的贪婪算法GreedTok。我们的形式化自然地放宽为已研究充分的加权最大覆盖问题，该问题有一个简单的$(1 - 1/e)$近似算法GreedWMC。通过对实际语料库的实验评估，我们证明了GreedTok在性能上优于BPE，同时GreedTok达到的目标分数与GreedWMC相当（由于放宽限制，GreedWMC可能可以达到更高的分数）。', 'title_zh': '一种分区覆盖方法用于标记分割'}
{'arxiv_id': 'arXiv:2501.06244', 'title': 'Microservice Deployment in Space Computing Power Networks via Robust Reinforcement Learning', 'authors': 'Zhiyong Yu, Yuning Jiang, Xin Liu, Yuanming Shi, Chunxiao Jiang, Linling Kuang', 'link': 'https://arxiv.org/abs/2501.06244', 'abstract': 'With the growing demand for Earth observation, it is important to provide reliable real-time remote sensing inference services to meet the low-latency requirements. The Space Computing Power Network (Space-CPN) offers a promising solution by providing onboard computing and extensive coverage capabilities for real-time inference. This paper presents a remote sensing artificial intelligence applications deployment framework designed for Low Earth Orbit satellite constellations to achieve real-time inference performance. The framework employs the microservice architecture, decomposing monolithic inference tasks into reusable, independent modules to address high latency and resource heterogeneity. This distributed approach enables optimized microservice deployment, minimizing resource utilization while meeting quality of service and functional requirements. We introduce Robust Optimization to the deployment problem to address data uncertainty. Additionally, we model the Robust Optimization problem as a Partially Observable Markov Decision Process and propose a robust reinforcement learning algorithm to handle the semi-infinite Quality of Service constraints. Our approach yields sub-optimal solutions that minimize accuracy loss while maintaining acceptable computational costs. Simulation results demonstrate the effectiveness of our framework.', 'abstract_zh': '随着地球观测需求的增长，提供可靠的实时遥感智能推断服务以满足低延迟要求变得尤为重要。太空计算能力网络（Space-CPN）通过提供机载计算能力和广泛的覆盖范围，提供了一种有潜力的解决方案，以实现实时推断性能。本文提出了一种针对低地球轨道卫星星座的遥感人工智能应用部署框架，以实现实时推断性能。该框架采用了微服务架构，将单调的推断任务分解为可重用、独立的模块，以解决高延迟和资源异构性的问题。这种分布式方法允许优化微服务部署，同时最大限度地减少资源利用并满足服务质量及其功能要求。我们为部署问题引入了鲁棒优化方法，以应对数据不确定性。此外，我们将鲁棒优化问题建模为部分可观测马尔可夫决策过程，并提出了一种鲁棒强化学习算法来处理半无限的服务质量约束。我们的方法在最小化准确率损失的同时，保持合理的计算成本。仿真结果证明了该框架的有效性。', 'title_zh': '空间计算网络中基于稳健强化学习的微服务部署'}
{'arxiv_id': 'arXiv:2501.06242', 'title': 'Intelligent Task Offloading: Advanced MEC Task Offloading and Resource Management in 5G Networks', 'authors': 'Alireza Ebrahimi, Fatemeh Afghah', 'link': 'https://arxiv.org/abs/2501.06242', 'abstract': "5G technology enhances industries with high-speed, reliable, low-latency communication, revolutionizing mobile broadband and supporting massive IoT connectivity. With the increasing complexity of applications on User Equipment (UE), offloading resource-intensive tasks to robust servers is essential for improving latency and speed. The 3GPP's Multi-access Edge Computing (MEC) framework addresses this challenge by processing tasks closer to the user, highlighting the need for an intelligent controller to optimize task offloading and resource allocation. This paper introduces a novel methodology to efficiently allocate both communication and computational resources among individual UEs. Our approach integrates two critical 5G service imperatives: Ultra-Reliable Low Latency Communication (URLLC) and Massive Machine Type Communication (mMTC), embedding them into the decision-making framework. Central to this approach is the utilization of Proximal Policy Optimization, providing a robust and efficient solution to the challenges posed by the evolving landscape of 5G technology. The proposed model is evaluated in a simulated 5G MEC environment. The model significantly reduces processing time by 4% for URLLC users under strict latency constraints and decreases power consumption by 26% for mMTC users, compared to existing baseline models based on the reported simulation results. These improvements showcase the model's adaptability and superior performance in meeting diverse QoS requirements in 5G networks.", 'abstract_zh': '5G技术通过提供高速、可靠、低延迟的通信，革新了移动宽带并支持大规模的物联网连接。随着用户设备（UE）上应用复杂性的增加，将资源密集型任务卸载到 robust 服务器对于改进延迟和速度至关重要。3GPP的多接入边缘计算（MEC）框架通过将任务处理更靠近用户来应对这一挑战，突显了需要一个智能控制器来优化任务卸载和资源分配的重要性。本文介绍了一种新的方法，以高效地分配个体UE的通信和计算资源。我们的方法将两个关键的5G服务需求——超可靠低延迟通信（URLLC）和大规模机器类通信（mMTC）——嵌入到决策框架中。这种方法的核心在于利用邻近策略优化（Proximal Policy Optimization），提供了一种在5G技术不断演进的背景下应对挑战的稳健而有效的解决方案。提出的模型在模拟的5G MEC环境中进行了评估。在严格延迟约束下，该模型将URLLC用户的处理时间显著减少了4%，并且相比现有基于报告模拟结果的基本模型，将mMTC用户的能耗降低了26%。这些改进展示了该模型在满足5G网络中多样化的服务质量（QoS）需求方面的适应性和优越性能。', 'title_zh': '智能任务卸载：5G网络中先进的边缘计算任务卸载与资源管理'}
{'arxiv_id': 'arXiv:2501.06239', 'title': 'Towards a scalable AI-driven framework for data-independent Cyber Threat Intelligence Information Extraction', 'authors': 'Olga Sorokoletova, Emanuele Antonioni, Giordano Colò', 'link': 'https://arxiv.org/abs/2501.06239', 'abstract': "Cyber Threat Intelligence (CTI) is critical for mitigating threats to organizations, governments, and institutions, yet the necessary data are often dispersed across diverse formats. AI-driven solutions for CTI Information Extraction (IE) typically depend on high-quality, annotated data, which are not always available. This paper introduces 0-CTI, a scalable AI-based framework designed for efficient CTI Information Extraction. Leveraging advanced Natural Language Processing (NLP) techniques, particularly Transformer-based architectures, the proposed system processes complete text sequences of CTI reports to extract a cyber ontology of named entities and their relationships.\nOur contribution is the development of 0-CTI, the first modular framework for CTI Information Extraction that supports both supervised and zero-shot learning. Unlike existing state-of-the-art models that rely heavily on annotated datasets, our system enables fully dataless operation through zero-shot methods for both Entity and Relation Extraction, making it adaptable to various data availability scenarios. Additionally, our supervised Entity Extractor surpasses current state-of-the-art performance in cyber Entity Extraction, highlighting the dual strength of the framework in both low-resource and data-rich environments.\nBy aligning the system's outputs with the Structured Threat Information Expression (STIX) format, a standard for information exchange in the cybersecurity domain, 0-CTI standardizes extracted knowledge, enhancing communication and collaboration in cybersecurity operations.", 'abstract_zh': '以下是将该论文内容或标题翻译成中文的版本，符合学术规范：\n\n网络威胁情报（CTI）对于减轻组织、政府和机构的威胁至关重要，然而必要的数据往往分散在不同的格式中。依赖高质量注释数据的基于人工智能的CTI信息提取（IE）解决方案通常不可用或不够充分。本文介绍了一种名为0-CTI的可扩展的人工智能框架，旨在高效地进行CTI信息提取。该系统利用先进的自然语言处理（NLP）技术，特别是基于变压器的架构，处理完整的CTI报告文本序列，提取实体及其关系的网络化威胁实体模型。\n\n我们的贡献在于开发了0-CTI，一个支持监督学习和零样本学习的模块化CTI信息提取框架。与依赖大量注释数据集的现有先进模型不同，我们的系统通过零样本方法在实体和关系抽取方面实现完全无数据操作，使其能够适应各种数据可用性场景。此外，我们的监督实体抽取器在网络安全实体提取方面超过了当前最先进的性能，展示了该框架在低资源和大数据环境中的双重优势。\n\n通过与网络安全领域标准的信息交换格式——结构化威胁信息表达（STIX）格式相一致，0-CTI标准化了提取的知识，增强了网络安全运营中的沟通与协作。', 'title_zh': '面向可扩展的基于AI的数据无关网络威胁情报信息提取框架研究'}
{'arxiv_id': 'arXiv:2501.06237', 'title': 'Forecasting Anonymized Electricity Load Profiles', 'authors': 'Joaquin Delgado Fernandez, Sergio Potenciano Menci, Alessio Magitteri', 'link': 'https://arxiv.org/abs/2501.06237', 'abstract': 'In the evolving landscape of data privacy, the anonymization of electric load profiles has become a critical issue, especially with the enforcement of the General Data Protection Regulation (GDPR) in Europe. These electric load profiles, which are essential datasets in the energy industry, are classified as personal behavioral data, necessitating stringent protective measures. This article explores the implications of this classification, the importance of data anonymization, and the potential of forecasting using microaggregated data. The findings underscore that effective anonymization techniques, such as microaggregation, do not compromise the performance of forecasting models under certain conditions (i.e., forecasting aggregated). In such an aggregated level, microaggregated data maintains high levels of utility, with minimal impact on forecasting accuracy. The implications for the energy sector are profound, suggesting that privacy-preserving data practices can be integrated into smart metering technology applications without hindering their effectiveness.', 'abstract_zh': '在数据隐私不断演变的背景下，电负荷曲线的匿名化已成为一个关键问题，尤其是在欧洲实施《通用数据保护条例》（GDPR）之后。这些电负荷曲线作为能源行业的重要数据集，被视为个人行为数据，需要采取严格的保护措施。本文探讨了这一分类的影响、数据匿名化的重要性以及使用微聚合数据进行预测的潜力。研究结果表明，在某些条件下（即聚合预测），有效的匿名化技术（如微聚合）不会损害预测模型的性能。在聚合级别上，微聚合数据保持了较高的实用性，并对预测准确性的影响最小。这些发现对能源领域具有深远意义，表明可以在不损害其有效性的情况下将隐私保护数据实践整合到智能计量技术应用中。', 'title_zh': '匿名化电负荷廓形的预测'}
{'arxiv_id': 'arXiv:2501.06236', 'title': 'Data-Driven Radio Propagation Modeling using Graph Neural Networks', 'authors': 'Adrien Bufort, Laurent Lebocq, Stefan Cathabard', 'link': 'https://arxiv.org/abs/2501.06236', 'abstract': 'Modeling radio propagation is essential for wireless network design and performance optimization. Traditional methods rely on physics models of radio propagation, which can be inaccurate or inflexible. In this work, we propose using graph neural networks to learn radio propagation behaviors directly from real-world network data. Our approach converts the radio propagation environment into a graph representation, with nodes corresponding to locations and edges representing spatial and ray-tracing relationships between locations. The graph is generated by converting images of the environment into a graph structure, with specific relationships between nodes. The model is trained on this graph representation, using sensor measurements as target data.\nWe demonstrate that the graph neural network, which learns to predict radio propagation directly from data, achieves competitive performance compared to traditional heuristic models. This data-driven approach outperforms classic numerical solvers in terms of both speed and accuracy. To the best of our knowledge, we are the first to apply graph neural networks to real-world radio propagation data to generate coverage maps, enabling generative models of signal propagation with point measurements only.', 'abstract_zh': '对于无线网络的设计与性能优化而言，建模无线电传播至关重要。传统方法依赖于无线电波传播的物理模型，但这些模型可能不够准确或不够灵活。在本研究中，我们提出了一种新的方法，即使用图神经网络直接从实际网络数据中学习无线电波传播行为。我们的方法将无线电传播环境转换为图表示，节点代表位置，边表示位置之间的空间和光线追踪关系。通过将环境图像转换为图结构，并通过节点间特定关系生成图。模型在该图表示上进行训练，使用传感器测量值作为目标数据。\n\n我们展示了该图神经网络从数据中直接预测无线电传播的能力，其性能与传统的启发式模型相当。这种数据驱动的方法在速度和准确性上均优于经典数值求解器。据我们所知，这是首次将图神经网络应用于实际无线电传播数据生成覆盖图，仅使用点测量即可生成信号传播的生成模型。', 'title_zh': '基于图神经网络的数据驱动射频传播建模'}
{'arxiv_id': 'arXiv:2501.06235', 'title': 'NextStop: An Improved Tracker For Panoptic LIDAR Segmentation Data', 'authors': 'Nirit Alkalay, Roy Orfaig, Ben-Zion Bobrovsky', 'link': 'https://arxiv.org/abs/2501.06235', 'abstract': '4D panoptic LiDAR segmentation is essential for scene understanding in autonomous driving and robotics ,combining semantic and instance segmentation with temporal this http URL methods, like 4D-PLS and 4D-STOP, use a tracking-by-detection methodology, employing deep learning networks to perform semantic and instance segmentation on each frame. To maintain temporal consistency, large-size instances detected in the current frame are compared and associated with instances within a temporal window that includes the current and preceding frames. However, their reliance on short-term instance detection, lack of motion estimation, and exclusion of small-sized instances lead to frequent identity switches and reduced tracking performance. We address these issues with the NextStop1 tracker, which integrates Kalman filter-based motion estimation, data association, and lifespan management, along with a tracklet state concept to improve prioritization. Evaluated using the LiDAR Segmentation and Tracking Quality (LSTQ) metric on the SemanticKITTI validation set, NextStop demonstrated enhanced tracking performance, particularly for small-sized objects like people and bicyclists, with fewer ID switches, earlier tracking initiation, and improved reliability in complex environments. The source code is available at this https URL', 'abstract_zh': '四维全景LiDAR分割对于自动驾驶和机器人领域的场景理解至关重要，它结合了语义分割和实例分割，并采用了具有时间维度的方法，如4D-PLS和4D-STOP。这些方法使用基于检测的跟踪方法，运用深度学习网络在每一帧上执行语义和实例分割。为了保持时间一致性，当前帧中检测到的大型实例会与包含当前帧和前几帧的时间窗口内实例进行比较和关联。然而，它们依赖于短期实例检测、缺乏运动估计，并且排除了小型实例，这导致频繁的身份切换和跟踪性能下降。我们通过NextStop1跟踪器解决了这些问题，该跟踪器结合了基于卡尔曼滤波的运动估计、数据关联、生命周期管理以及轨迹片段状态的概念，以提高跟踪优先级。在使用LiDAR分割和跟踪质量（LSTQ）指标对SemanticKITTI验证集进行评估后，NextStop展示了更好的跟踪性能，特别是在对于像行人和骑自行车者这样小型对象的跟踪中，减少了身份切换，更早地启动跟踪，并且在复杂环境中具有更高的可靠性。源代码可在以下链接获取：this http URL', 'title_zh': 'NextStop：改进的全景 Lidar 分割数据跟踪器'}
{'arxiv_id': 'arXiv:2501.06226', 'title': 'asanAI: In-Browser, No-Code, Offline-First Machine Learning Toolkit', 'authors': 'Norman Koch, Siavash Ghiasvand', 'link': 'https://arxiv.org/abs/2501.06226', 'abstract': 'Machine learning (ML) has become crucial in modern life, with growing interest from researchers and the public. Despite its potential, a significant entry barrier prevents widespread adoption, making it challenging for non-experts to understand and implement ML techniques. The increasing desire to leverage ML is counterbalanced by its technical complexity, creating a gap between potential and practical application. This work introduces asanAI, an offline-first, open-source, no-code machine learning toolkit designed for users of all skill levels. It allows individuals to design, debug, train, and test ML models directly in a web browser, eliminating the need for software installations and coding. The toolkit runs on any device with a modern web browser, including smartphones, and ensures user privacy through local computations while utilizing WebGL for enhanced GPU performance. Users can quickly experiment with neural networks and train custom models using various data sources, supported by intuitive visualizations of network structures and data flows. asanAI simplifies the teaching of ML concepts in educational settings and is released under an open-source MIT license, encouraging modifications. It also supports exporting models in industry-ready formats, empowering a diverse range of users to effectively learn and apply machine learning in their projects. The proposed toolkit is successfully utilized by researchers of this http URL to swiftly draft and test machine learning ideas, by trainers to effectively educate enthusiasts, and by teachers to introduce contemporary ML topics in classrooms with minimal effort and high clarity.', 'abstract_zh': '机器学习（ML）在现代生活中变得至关重要，引起了研究人员和公众的广泛兴趣。尽管它具有巨大的潜力，但仍存在显著的学习障碍，使得非专家难以理解并实施ML技术。人们越来越想利用ML的功能，但其技术复杂性却成为了一个阻碍，导致潜在应用与实际应用之间存在差距。本文介绍了一种名为asanAI的工具包，它是一款面向所有技能水平用户的离线优先、开源、无代码机器学习工具包。该工具包允许用户直接在网页浏览器中设计、调试、训练和测试ML模型，无需安装软件和编码。该工具包可在任何配备现代网页浏览器的设备上运行，包括智能手机，并通过本地计算确保用户隐私，同时利用WebGL增强GPU性能。用户可以快速实验神经网络并与多种数据来源训练自定义模型，依托直观的网络结构和数据流可视化辅助。asanAI简化了在教育环境中教授ML概念，并采用开源MIT许可证发布，鼓励用户进行修改。此外，该工具包还支持导出行业标准格式的模型，从而赋能各种用户能够高效地学习并应用于他们的项目中。该提出的工具包已被该网站的研究人员成功用于快速制定和测试机器学习想法，用于培训师有效地教育爱好者，并用于教师以最少的努力和最高的清晰度在课堂上引入当代ML主题。\n\n请注意，原文中“this http URL”并未给出具体URL，因此我在翻译时将其替换为“该网站”。如果需要将其替换为具体的网址，请告知具体网址。', 'title_zh': 'asanAI：基于浏览器、无需代码、先离线后在线的机器学习工具包'}
{'arxiv_id': 'arXiv:2501.06224', 'title': 'Detection, Retrieval, and Explanation Unified: A Violence Detection System Based on Knowledge Graphs and GAT', 'authors': 'Wen-Dong Jiang, Chih-Yung Chang, Diptendu Sinha Roy', 'link': 'https://arxiv.org/abs/2501.06224', 'abstract': 'Recently, violence detection systems developed using unified multimodal models have achieved significant success and attracted widespread attention. However, most of these systems face two critical challenges: the lack of interpretability as black-box models and limited functionality, offering only classification or retrieval capabilities. To address these challenges, this paper proposes a novel interpretable violence detection system, termed the Three-in-One (TIO) System. The TIO system integrates knowledge graphs (KG) and graph attention networks (GAT) to provide three core functionalities: detection, retrieval, and explanation. Specifically, the system processes each video frame along with text descriptions generated by a large language model (LLM) for videos containing potential violent behavior. It employs ImageBind to generate high-dimensional embeddings for constructing a knowledge graph, uses GAT for reasoning, and applies lightweight time series modules to extract video embedding features. The final step connects a classifier and retriever for multi-functional outputs. The interpretability of KG enables the system to verify the reasoning process behind each output. Additionally, the paper introduces several lightweight methods to reduce the resource consumption of the TIO system and enhance its efficiency. Extensive experiments conducted on the XD-Violence and UCF-Crime datasets validate the effectiveness of the proposed system. A case study further reveals an intriguing phenomenon: as the number of bystanders increases, the occurrence of violent behavior tends to decrease.', 'abstract_zh': '近年来，使用统一多模态模型开发的暴力检测系统取得了显著的成功并引起了广泛关注。然而，这些系统大多面临着两个关键挑战：作为黑盒模型缺乏可解释性以及功能有限，只能提供分类或检索能力。为了解决这些挑战，本文提出了一种名为三位一体系统（Three-in-One, TIO）的新颖可解释暴力检测系统。TIO系统将知识图谱（KG）和图注意力网络（GAT）相结合，提供三大核心功能：检测、检索和解释。具体而言，该系统处理包含潜在暴力行为的视频帧，并结合大型语言模型（LLM）生成的文本描述。它利用ImageBind生成高维嵌入以构建知识图谱，使用GAT进行推理，并应用轻量级时间序列模块提取视频嵌入特征。最后一步是连接分类器和检索器以实现多功能输出。KG 的可解释性使系统能够验证每个输出背后的推理过程。此外，本文还引入了几种轻量级方法以降低TIO系统的资源消耗并提高其效率。在XD-Violence和UCF-Crime数据集上的广泛实验验证了所提出系统的有效性。进一步的案例研究揭示了一个有趣的现象：旁观者的数量增加时，暴力行为的发生率似乎会减少。', 'title_zh': '统一检测、检索与解释：基于知识图谱和图注意力网络的暴力检测系统'}
{'arxiv_id': 'arXiv:2501.06211', 'title': 'FLAME: Financial Large-Language Model Assessment and Metrics Evaluation', 'authors': 'Jiayu Guo, Yu Guo, Martha Li, Songtao Tan', 'link': 'https://arxiv.org/abs/2501.06211', 'abstract': 'LLMs have revolutionized NLP and demonstrated potential across diverse domains. More and more financial LLMs have been introduced for finance-specific tasks, yet comprehensively assessing their value is still challenging. In this paper, we introduce FLAME, a comprehensive financial LLMs evaluation system in Chinese, which includes two core evaluation benchmarks: FLAME-Cer and FLAME-Sce. FLAME-Cer covers 14 types of authoritative financial certifications, including CPA, CFA, and FRM, with a total of approximately 16,000 carefully selected questions. All questions have been manually reviewed to ensure accuracy and representativeness. FLAME-Sce consists of 10 primary core financial business scenarios, 21 secondary financial business scenarios, and a comprehensive evaluation set of nearly 100 tertiary financial application tasks. We evaluate 6 representative LLMs, including GPT-4o, GLM-4, ERNIE-4.0, Qwen2.5, XuanYuan3, and the latest Baichuan4-Finance, revealing Baichuan4-Finance excels other LLMs in most tasks. By establishing a comprehensive and professional evaluation system, FLAME facilitates the advancement of financial LLMs in Chinese contexts. Instructions for participating in the evaluation are available on GitHub: this https URL.', 'abstract_zh': '生成的中文翻译如下，符合学术规范：\n\n大规模语言模型（LLMs）已经彻底改变了自然语言处理（NLP），并在多种领域中展现出巨大潜力。越来越多的金融特定任务的大规模语言模型被引入，然而对其价值进行全面评估依然颇具挑战。本文介绍了一种全新的面向中文的金融大规模语言模型评估系统——FLAME，该系统包括两个核心评估基准：FLAME-Cer 和 FLAME-Sce。FLAME-Cer 涵盖了 14 种权威的金融认证类型，包括注册会计师（CPA）、特许金融分析师（CFA）和金融风险管理师（FRM），总计约包含 16,000 个精心筛选的问题。所有问题均已人工审查，以确保准确性和代表性。FLAME-Sce 包含 10 种主要的核心金融业务场景，21 种次要的金融业务场景，以及近 100 项三级金融应用任务的综合评估集。我们评估了 6 种代表性的大规模语言模型，包括 GPT-4o、GLM-4、ERNIE-4.0、Qwen2.5、XuanYuan3 和最新的 Baichuan4-Finance，结果显示 Baichuan4-Finance 在大多数任务中表现优于其他模型。通过建立一个全面且专业的评估体系，FLAME 促进了中文环境下金融大规模语言模型的发展。关于参与评估的详细指南可在 GitHub 上获取：[此链接](this https URL)。', 'title_zh': 'FLAME：金融大型语言模型评估与指标评价'}
{'arxiv_id': 'arXiv:2501.06205', 'title': 'Leveraging Edge Intelligence and LLMs to Advance 6G-Enabled Internet of Automated Defense Vehicles', 'authors': 'Murat Arda Onsu, Poonam Lohan, Burak Kantarci', 'link': 'https://arxiv.org/abs/2501.06205', 'abstract': 'The evolution of Artificial Intelligence (AI) and its subset Deep Learning (DL), has profoundly impacted numerous domains, including autonomous driving. The integration of autonomous driving in military settings reduces human casualties and enables precise and safe execution of missions in hazardous environments while allowing for reliable logistics support without the risks associated with fatigue-related errors. However, relying on autonomous driving solely requires an advanced decision-making model that is adaptable and optimum in any situation. Considering the presence of numerous interconnected autonomous vehicles in mission-critical scenarios, Ultra-Reliable Low Latency Communication (URLLC) is vital for ensuring seamless coordination, real-time data exchange, and instantaneous response to dynamic driving environments. The advent of 6G strengthens the Internet of Automated Defense Vehicles (IoADV) concept within the realm of Internet of Military Defense Things (IoMDT) by enabling robust connectivity, crucial for real-time data exchange, advanced navigation, and enhanced safety features through IoADV interactions. On the other hand, a critical advancement in this space is using pre-trained Generative Large Language Models (LLMs) for decision-making and communication optimization for autonomous driving. Hence, this work presents opportunities and challenges with a vision of realizing the full potential of these technologies in critical defense applications, especially through the advancement of IoADV and its role in enhancing autonomous military operations.', 'abstract_zh': '人工智能（AI）及其子集深度学习（DL）的发展对诸多领域产生了深远影响，包括自动驾驶。在军事环境中集成自动驾驶能够减少人员伤亡，确保在危险环境中执行任务的精确性和安全性，同时还能提供可靠的战略支援而无需担心疲劳导致的错误。然而，仅依赖自动驾驶则需要一种高度适应性和在各种情况下都优化的决策模型。考虑到关键任务场景中存在众多互联的自动驾驶车辆，超可靠低延迟通信（URLLC）对于确保无缝协调、实时数据交换以及对动态驾驶环境的即时响应至关重要。6G 的出现增强了军事防御物联概念（IoMDT）中的自动驾驶防御车辆物联（IoADV）理念，通过实现稳健的连接，支持实时数据交换、高级导航和通过 IoADV 交互实现的增强安全功能。\n\n在这一领域的一个关键进展是利用预训练的大规模生成语言模型（LLMs）进行自动驾驶的决策和通信优化。因此，本文探讨了这些技术在关键防御应用中实现其全部潜力的机会和挑战，特别是通过推进 IoADV 及其在增强军事自主化操作中的作用来实现这一点。', 'title_zh': '利用边缘智能和大规模语言模型推动6G使能的自动化防御车辆物联网发展'}
{'arxiv_id': 'arXiv:2501.06196', 'title': 'How Do Artificial Intelligences Think? The Three Mathematico-Cognitive Factors of Categorical Segmentation Operated by Synthetic Neurons', 'authors': 'Michael Pichat, William Pogrund, Armanush Gasparian, Paloma Pichat, Samuel Demarchi, Michael Veillet-Guillem', 'link': 'https://arxiv.org/abs/2501.06196', 'abstract': 'How do the synthetic neurons in language models create "thought categories" to segment and analyze their informational environment? What are the cognitive characteristics, at the very level of formal neurons, of this artificial categorical thought? Based on the mathematical nature of algebraic operations inherent to neuronal aggregation functions, we attempt to identify mathematico-cognitive factors that genetically shape the categorical reconstruction of the informational world faced by artificial cognition. This study explores these concepts through the notions of priming, attention, and categorical phasing.', 'abstract_zh': '语言模型中的合成神经元如何创建“思维类别”，以分割和分析其信息环境？在形式神经元的层面，这种人工类别化思维的认知特征是什么？基于神经元聚合函数固有的代数运算的数学本质，我们试图识别出构成人工认知面临的信息世界的类别重构的数学—认知因素。本研究通过激发、注意和类别相位的概念来探讨这些概念。', 'title_zh': '人工智能如何思考？合成神经元执行的分类分割的三大数学认知因素'}
