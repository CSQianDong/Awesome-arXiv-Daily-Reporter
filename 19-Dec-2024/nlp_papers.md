# TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks 

**Title (ZH)**: 《AgentCompany：评估大型语言模型代理在具有后果的现实世界任务上的表现》

这个翻译在保持原意的基础上，符合学术写作的规范，确保了术语的准确性和表述的专业性。 

**Authors**: Frank F. Xu, Yufan Song, Boxuan Li, Yuxuan Tang, Kritanjali Jain, Mengxue Bao, Zora Z. Wang, Xuhui Zhou, Zhitong Guo, Murong Cao, Mingyang Yang, Hao Yang Lu, Amaad Martin, Zhe Su, Leander Maben, Raj Mehta, Wayne Chi, Lawrence Jang, Yiqing Xie, Shuyan Zhou, Graham Neubig  

**Link**: [PDF](https://arxiv.org/pdf/2412.14161)  

**Abstract**: We interact with computers on an everyday basis, be it in everyday life or work, and many aspects of work can be done entirely with access to a computer and the Internet. At the same time, thanks to improvements in large language models (LLMs), there has also been a rapid development in AI agents that interact with and affect change in their surrounding environments. But how performant are AI agents at helping to accelerate or even autonomously perform work-related tasks? The answer to this question has important implications for both industry looking to adopt AI into their workflows, and for economic policy to understand the effects that adoption of AI may have on the labor market. To measure the progress of these LLM agents' performance on performing real-world professional tasks, in this paper, we introduce TheAgentCompany, an extensible benchmark for evaluating AI agents that interact with the world in similar ways to those of a digital worker: by browsing the Web, writing code, running programs, and communicating with other coworkers. We build a self-contained environment with internal web sites and data that mimics a small software company environment, and create a variety of tasks that may be performed by workers in such a company. We test baseline agents powered by both closed API-based and open-weights language models (LMs), and find that with the most competitive agent, 24% of the tasks can be completed autonomously. This paints a nuanced picture on task automation with LM agents -- in a setting simulating a real workplace, a good portion of simpler tasks could be solved autonomously, but more difficult long-horizon tasks are still beyond the reach of current systems. 

**Abstract (ZH)**: 我们日常生活中与计算机的交互无处不在，无论是日常生活还是工作中，许多工作都可以通过计算机和互联网来完成。同时，由于大型语言模型（LLMs）的改进，与环境互动并对其产生影响的人工智能代理也得到了迅速发展。但这些AI代理在帮助加速甚至自主完成与工作相关任务方面表现如何？这个问题的答案对于希望将AI融入其工作流程的行业以及了解AI采用可能对劳动力市场产生的影响的经济政策都有重要意义。为了衡量这些LLM代理在执行真实世界专业任务方面的性能进步，我们在本文中介绍了TheAgentCompany，这是一个可扩展的基准测试方法，用于评估以类似于数字员工的方式与世界交互的AI代理：通过浏览网络、编写代码、运行程序和与其他同事沟通。我们构建了一个自包含的环境，其中包含模拟小型软件公司环境的内部网站和数据，并创建了由此类公司员工可能执行的各种任务。我们测试了基于闭源API和开源权重语言模型（LMs）的基线代理，并发现使用最竞争性的代理时，有24%的任务可以自主完成。这在模拟真实工作场所的环境中描绘了一幅复杂的工作任务自动化图景——许多简单任务可以自主解决，但更复杂、长期的任务仍超出了当前系统的处理能力。 

---
# TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks 

**Title (ZH)**: 《代理公司：基于后果性现实世界任务评估大型语言模型代理》

这个标题翻译旨在保持原意的同时，确保符合学术规范和中文表达习惯。其中，“Large Language Model Agents”被翻译为“大型语言模型代理”，以便更准确地反映当前学术界对这类模型的理解和使用。 

**Authors**: Frank F. Xu, Yufan Song, Boxuan Li, Yuxuan Tang, Kritanjali Jain, Mengxue Bao, Zora Z. Wang, Xuhui Zhou, Zhitong Guo, Murong Cao, Mingyang Yang, Hao Yang Lu, Amaad Martin, Zhe Su, Leander Maben, Raj Mehta, Wayne Chi, Lawrence Jang, Yiqing Xie, Shuyan Zhou, Graham Neubig  

**Link**: [PDF](https://arxiv.org/pdf/2412.14161)  

**Abstract**: We interact with computers on an everyday basis, be it in everyday life or work, and many aspects of work can be done entirely with access to a computer and the Internet. At the same time, thanks to improvements in large language models (LLMs), there has also been a rapid development in AI agents that interact with and affect change in their surrounding environments. But how performant are AI agents at helping to accelerate or even autonomously perform work-related tasks? The answer to this question has important implications for both industry looking to adopt AI into their workflows, and for economic policy to understand the effects that adoption of AI may have on the labor market. To measure the progress of these LLM agents' performance on performing real-world professional tasks, in this paper, we introduce TheAgentCompany, an extensible benchmark for evaluating AI agents that interact with the world in similar ways to those of a digital worker: by browsing the Web, writing code, running programs, and communicating with other coworkers. We build a self-contained environment with internal web sites and data that mimics a small software company environment, and create a variety of tasks that may be performed by workers in such a company. We test baseline agents powered by both closed API-based and open-weights language models (LMs), and find that with the most competitive agent, 24% of the tasks can be completed autonomously. This paints a nuanced picture on task automation with LM agents -- in a setting simulating a real workplace, a good portion of simpler tasks could be solved autonomously, but more difficult long-horizon tasks are still beyond the reach of current systems. 

**Abstract (ZH)**: 我们在日常生活中和工作中每天都与计算机进行交互，许多工作任务仅通过计算机和互联网就可以完成。与此同时，由于大型语言模型（LLMs）的改进，也迅速发展出了能够与环境交互并影响环境变化的AI代理。那么，这些AI代理在辅助加速或自主完成工作相关任务方面表现如何呢？这一问题的答案对于希望将AI整合到工作流程中的行业以及希望理解AI采用可能对劳动力市场产生的影响的经济政策制定者都具有重要意义。

为了衡量这些LLM代理在执行现实世界专业任务方面的性能进展，本文引入了TheAgentCompany，这是一个可扩展的基准测试，用于评估以类似数字工作者的方式与世界交互的AI代理。通过构建一个包含内部网站和数据的自包含环境，模仿小型软件公司的工作环境，我们创建了多种由此类公司员工可能执行的任务。我们测试了基于封闭API和开放权重语言模型（LMs）的基线代理，并发现最先进的代理可以自主完成24%的任务。这一结果描绘了LM代理任务自动化的一个复杂图景——在模拟现实工作场所的环境中，相当一部分简单任务可以自主解决，但更复杂、长期的任务仍然是当前系统的挑战。 

---
# GLIDER: Grading LLM Interactions and Decisions using Explainable Ranking 

**Title (ZH)**: GLIDER：使用可解释排名来评估大规模语言模型交互与决策 

**Authors**: Darshan Deshpande, Selvan Sunitha Ravi, Sky CH-Wang, Bartosz Mielczarek, Anand Kannappan, Rebecca Qian  

**Link**: [PDF](https://arxiv.org/pdf/2412.14140)  

**Abstract**: The LLM-as-judge paradigm is increasingly being adopted for automated evaluation of model outputs. While LLM judges have shown promise on constrained evaluation tasks, closed source LLMs display critical shortcomings when deployed in real world applications due to challenges of fine grained metrics and explainability, while task specific evaluation models lack cross-domain generalization. We introduce GLIDER, a powerful 3B evaluator LLM that can score any text input and associated context on arbitrary user defined criteria. GLIDER shows higher Pearson's correlation than GPT-4o on FLASK and greatly outperforms prior evaluation models, achieving comparable performance to LLMs 17x its size. GLIDER supports fine-grained scoring, multilingual reasoning, span highlighting and was trained on 685 domains and 183 criteria. Extensive qualitative analysis shows that GLIDER scores are highly correlated with human judgments, with 91.3% human agreement. We have open-sourced GLIDER to facilitate future research. 

**Abstract (ZH)**: 基于大语言模型（LLM）作为裁判的范式越来越多地被采用，用于自动评估模型输出。尽管在受限评估任务中，LLM裁判已经展示了潜力，但闭源LLM在实际应用中由于精细度度量和可解释性的挑战，出现了关键性的不足，而针对特定任务的评估模型缺乏跨领域的泛化能力。我们引入了GLIDER——一个强大的30亿参数的评估LLM，它可以对任意用户定义的评价标准对任何文本输入及其上下文进行评分。GLIDER在FLASK上的皮尔逊相关系数高于GPT-4o，并且在评估模型中的表现远超之前的模型，其性能与比自己大17倍的LLM相当。GLIDER支持精细评分、多语言推理、片段高亮，并且是在685个领域和183个评价标准下进行训练的。广泛的定性分析表明，GLIDER的评分与人类判断高度相关，有91.3%的人类一致性。我们已开源GLIDER，以促进未来的研究。 

---
# Performance Gap in Entity Knowledge Extraction Across Modalities in Vision Language Models 

**Title (ZH)**: 视觉语言模型中跨模态实体知识提取的性能差距 

**Authors**: Ido Cohen, Daniela Gottesman, Mor Geva, Raja Giryes  

**Link**: [PDF](https://arxiv.org/pdf/2412.14133)  

**Abstract**: Vision-language models (VLMs) excel at extracting and reasoning about information from images. Yet, their capacity to leverage internal knowledge about specific entities remains underexplored. This work investigates the disparity in model performance when answering factual questions about an entity described in text versus depicted in an image. Our results reveal a significant accuracy drop --averaging 19%-- when the entity is presented visually instead of textually. We hypothesize that this decline arises from limitations in how information flows from image tokens to query tokens. We use mechanistic interpretability tools to reveal that, although image tokens are preprocessed by the vision encoder, meaningful information flow from these tokens occurs only in the much deeper layers. Furthermore, critical image processing happens in the language model's middle layers, allowing few layers for consecutive reasoning, highlighting a potential inefficiency in how the model utilizes its layers for reasoning. These insights shed light on the internal mechanics of VLMs and offer pathways for enhancing their reasoning capabilities. 

**Abstract (ZH)**: 视觉语言模型（VLMs）在从图像中提取和推理信息方面表现出色。然而，它们在利用特定实体的内部知识方面的能力尚未得到充分探索。本研究探讨了当模型回答有关文本中描述的实体的常识性问题与图像中描绘的实体的问题时，模型性能之间的差异。我们的结果表明，当实体以视觉形式而非文本形式呈现时，模型的准确性平均下降了19%。我们假设这种下降源于信息从图像标记到查询标记流动的限制。我们使用机制可解释性工具表明，虽然图像标记由视觉编码器预处理，但这些标记中的意义性信息流动主要发生在较深的层中。此外，关键的图像处理在语言模型的中间层中发生，使得较少的层能够进行连续推理，突显了模型在利用其层进行推理方面可能存在的一种潜在低效性。这些发现揭示了VLMs的内部机理，并提供了一种增强其推理能力的途径。 

---
# SEKE: Specialised Experts for Keyword Extraction 

**Title (ZH)**: SEKE：专门领域的关键词提取专家 

**Authors**: Matej Martinc, Hanh Thi Hong Tran, Senja Pollak, Boshko Koloski  

**Link**: [PDF](https://arxiv.org/pdf/2412.14087)  

**Abstract**: Keyword extraction involves identifying the most descriptive words in a document, allowing automatic categorisation and summarisation of large quantities of diverse textual data. Relying on the insight that real-world keyword detection often requires handling of diverse content, we propose a novel supervised keyword extraction approach based on the mixture of experts (MoE) technique. MoE uses a learnable routing sub-network to direct information to specialised experts, allowing them to specialize in distinct regions of the input space. SEKE, a mixture of Specialised Experts for supervised Keyword Extraction, uses DeBERTa as the backbone model and builds on the MoE framework, where experts attend to each token, by integrating it with a recurrent neural network (RNN), to allow successful extraction even on smaller corpora, where specialisation is harder due to lack of training data. The MoE framework also provides an insight into inner workings of individual experts, enhancing the explainability of the approach. We benchmark SEKE on multiple English datasets, achieving state-of-the-art performance compared to strong supervised and unsupervised baselines. Our analysis reveals that depending on data size and type, experts specialize in distinct syntactic and semantic components, such as punctuation, stopwords, parts-of-speech, or named entities. Code is available at: this https URL 

**Abstract (ZH)**: 关键词提取涉及识别文档中最具描述性的词语，从而允许对大量多样化的文本数据进行自动分类和总结。鉴于现实世界中的关键词检测往往需要处理多种内容的特点，我们提出了一种基于专家混合体（MoE）技术的新颖监督关键词提取方法。MoE 使用一个可学习的路由子网络，将信息导向专门化的专家，使其能够在输入空间的不同区域进行专业化。SEKE（基于专门化专家的监督关键词提取）采用 DeBERTa 作为基础模型，并基于 MoE 框架构建，通过将循环神经网络（RNN）与专家相结合，使在小型语料库中也能够成功进行提取，即使在这种情况下，由于缺乏训练数据，专业化更难实现。MoE 框架还为个体专家的内部工作提供了见解，增强了该方法的解释性。我们在多种英文数据集上对 SEKE 进行基准测试，其性能优于强大的监督和非监督基线方法。我们的分析表明，根据数据大小和类型的不同，专家会专注于不同的句法和语义成分，如标点符号、停用词、词性或命名实体。代码可在以下链接获取：this https URL 

---
# Digestion Algorithm in Hierarchical Symbolic Forests: A Fast Text Normalization Algorithm and Semantic Parsing Framework for Specific Scenarios and Lightweight Deployment 

**Title (ZH)**: 层级符号森林中的消化算法：一种适用于特定场景的快速文本规范化算法及其轻量级部署语义解析框架 

**Authors**: Kevin You  

**Link**: [PDF](https://arxiv.org/pdf/2412.14054)  

**Abstract**: Text Normalization and Semantic Parsing have numerous applications in natural language processing, such as natural language programming, paraphrasing, data augmentation, constructing expert systems, text matching, and more. Despite the prominent achievements of deep learning in Large Language Models (LLMs), the interpretability of neural network architectures is still poor, which affects their credibility and hence limits the deployments of risk-sensitive scenarios. In certain scenario-specific domains with scarce data, rapidly obtaining a large number of supervised learning labels is challenging, and the workload of manually labeling data would be enormous. Catastrophic forgetting in neural networks further leads to low data utilization rates. In situations where swift responses are vital, the density of the model makes local deployment difficult and the response time long, which is not conducive to local applications of these fields. Inspired by the multiplication rule, a principle of combinatorial mathematics, and human thinking patterns, a multilayer framework along with its algorithm, the Digestion Algorithm in Hierarchical Symbolic Forests (DAHSF), is proposed to address these above issues, combining text normalization and semantic parsing workflows. The Chinese Scripting Language "Fire Bunny Intelligent Development Platform V2.0" is an important test and application of the technology discussed in this paper. DAHSF can run locally in scenario-specific domains on little datasets, with model size and memory usage optimized by at least two orders of magnitude, thus improving the execution speed, and possessing a promising optimization outlook. 

**Abstract (ZH)**: 文本规范化和语义解析在自然语言处理中有着广泛的应用，例如自然语言编程、同义句转换、数据扩增、构建专家系统、文本匹配等。尽管大型语言模型（LLMs）中的深度学习取得了显著成就，但神经网络架构的可解释性仍然较差，这影响了它们的可信度，从而限制了在风险敏感场景中的应用。在某些数据稀缺的领域特定场景中，快速获得大量监督学习标签是极具挑战性的，手动标注数据的工作量将会非常庞大。神经网络中的灾难性遗忘进一步导致数据利用效率低下。在需要快速响应的情况下，模型的密集性使得局部部署困难且响应时间较长，这不利于这些领域的本地应用。受乘法法则、组合数学原理以及人类思维模式的启发，提出了一种多层次框架及其算法——分层符号森林的消化算法（DAHSF），以解决上述问题，并结合文本规范化和语义解析的工作流程。中文编程语言“Fire Bunny智能开发平台V2.0”是本文讨论的技术的重要测试和应用平台。DAHSF可以在少量数据的领域特定场景中进行局部运行，并且通过至少两个数量级优化模型大小和内存使用，提高了执行速度，具有良好的优化前景。 

---
# Cross-Lingual Transfer of Debiasing and Detoxification in Multilingual LLMs: An Extensive Investigation 

**Title (ZH)**: 多语言大规模语言模型中去偏见和解毒的跨语言迁移：一项全面探究 

**Authors**: Vera Neplenbroek, Arianna Bisazza, Raquel Fernández  

**Link**: [PDF](https://arxiv.org/pdf/2412.14050)  

**Abstract**: Recent generative large language models (LLMs) show remarkable performance in non-English languages, but when prompted in those languages they tend to express higher harmful social biases and toxicity levels. Prior work has shown that finetuning on specialized datasets can mitigate this behavior, and doing so in English can transfer to other languages. In this work, we investigate the impact of different finetuning methods on the model's bias and toxicity, but also on its ability to produce fluent and diverse text. Our results show that finetuning on curated non-harmful text is more effective for mitigating bias, and finetuning on direct preference optimization (DPO) datasets is more effective for mitigating toxicity. The mitigation caused by applying these methods in English also transfers to non-English languages. We find evidence that the extent to which transfer takes place can be predicted by the amount of data in a given language present in the model's pretraining data. However, this transfer of bias and toxicity mitigation often comes at the expense of decreased language generation ability in non-English languages, highlighting the importance of developing language-specific bias and toxicity mitigation methods. 

**Abstract (ZH)**: 近年来，生成型大型语言模型（LLMs）在非英语语言中表现出显著的能力，但当用这些语言进行提示时，往往会表现出较高的有害社会偏见和毒性水平。先前的研究表明，通过专门数据集进行微调能够缓解这种行为，并且在英语上的微调可以转移到其他语言。在本研究中，我们探讨了不同微调方法对模型偏见和毒性的影响，同时也考察了其生成流畅且多样化文本的能力。我们的结果表明，使用策划的无害文本进行微调更有效地缓解了偏见，而直接偏好优化（DPO）数据集的微调更有效地缓解了毒性。通过这些方法在英语上的微调对其他语言也有缓解作用。我们发现，数据转移的效果可以由模型预训练数据中特定语言的数据量来预测。然而，这种偏见和毒性的缓解往往以非英语语言生成能力下降为代价，这突显了开发特定语言的偏见和毒性缓解方法的重要性。 

---
# Hansel: Output Length Controlling Framework for Large Language Models 

**Title (ZH)**: Hansel: 大型语言模型输出长度控制框架 

**Authors**: Seoha Song, Junhyun Lee, Hyeonmok Ko  

**Link**: [PDF](https://arxiv.org/pdf/2412.14033)  

**Abstract**: Despite the great success of large language models (LLMs), efficiently controlling the length of the output sequence still remains a challenge. In this paper, we propose Hansel, an efficient framework for length control in LLMs without affecting its generation ability. Hansel utilizes periodically outputted hidden special tokens to keep track of the remaining target length of the output sequence. Together with techniques to avoid abrupt termination of the output, this seemingly simple method proved to be efficient and versatile, while not harming the coherency and fluency of the generated text. The framework can be applied to any pre-trained LLMs during the finetuning stage of the model, regardless of its original positional encoding method. We demonstrate this by finetuning four different LLMs with Hansel and show that the mean absolute error of the output sequence decreases significantly in every model and dataset compared to the prompt-based length control finetuning. Moreover, the framework showed a substantially improved ability to extrapolate to target lengths unseen during finetuning, such as long dialog responses or extremely short summaries. This indicates that the model learns the general means of length control, rather than learning to match output lengths to those seen during training. 

**Abstract (ZH)**: 尽管大型语言模型（LLMs）取得了巨大成功，有效地控制输出序列的长度仍然是一项挑战。本文提出了一种名为Hansel的高效框架，能够在不影响LLMs生成能力的前提下控制输出序列的长度。Hansel利用周期性输出的隐藏特殊标记来跟踪剩余的目标长度。结合避免输出突然终止的技术，这一看似简单的办法证明了其高效性和灵活性，同时不损害生成文本的连贯性和流畅性。该框架可以在模型的微调阶段应用于任何预训练的LLMs，不论其原始的位置编码方法为何。通过使用Hansel微调四种不同的LLMs，我们证明了使用Hansel微调后，各模型和数据集中的输出序列的均绝对误差显著下降，优于基于提示的长度控制微调。此外，该框架在延伸到微调过程中未见过的目标长度（如长对话响应或极其简短的摘要）时表现出显著增强的能力。这表明模型学习了长度控制的一般方法，而不仅仅是学习匹配训练期间见过的输出长度。 

---
# Towards an optimised evaluation of teachers' discourse: The case of engaging messages 

**Title (ZH)**: 优化教师言说评价的研究：以参与性信息为例 

**Authors**: Samuel Falcon, Jaime Leon  

**Link**: [PDF](https://arxiv.org/pdf/2412.14011)  

**Abstract**: Evaluating teachers' skills is crucial for enhancing education quality and student outcomes. Teacher discourse, significantly influencing student performance, is a key component. However, coding this discourse can be laborious. This study addresses this issue by introducing a new methodology for optimising the assessment of teacher discourse. The research consisted of two studies, both within the framework of engaging messages used by secondary education teachers. The first study involved training two large language models on real-world examples from audio-recorded lessons over two academic years to identify and classify the engaging messages from the lessons' transcripts. This resulted in sensitivities of 84.31% and 91.11%, and specificities of 97.69% and 86.36% in identification and classification, respectively. The second study applied these models to transcripts of audio-recorded lessons from a third academic year to examine the frequency and distribution of message types by educational level and moment of the academic year. Results showed teachers predominantly use messages emphasising engagement benefits, linked to improved outcomes, while one-third highlighted non-engagement disadvantages, associated with increased anxiety. The use of engaging messages declined in Grade 12 and towards the academic year's end. These findings suggest potential interventions to optimise engaging message use, enhancing teaching quality and student outcomes. 

**Abstract (ZH)**: 评估教师技能对于提高教育质量和学生成果至关重要。教师话语在显著影响学生表现方面起着关键作用。然而，对这一话语进行编码可能耗费大量劳动力。为此，本研究引入了一种新的方法，以优化教师话语的评估。研究包含两个部分，均基于中学生的互动信息。第一部分研究通过对两年学术年度录制课程的音频示例对两个大型语言模型进行训练，以识别和分类课程转录中的互动信息。这一过程实现了84.31%和91.11%的敏感性，以及97.69%和86.36%的特异度。第二部分研究将这些模型应用于第三学术年度录制课程的转录，以探讨不同教育水平和学年阶段互动信息类型的频率和分布情况。研究结果表明，教师主要使用强调参与益处的信息，这些信息与改进的成果相关，而三分之一的信息则强调未能参与的弊端，这些信息与较高的焦虑水平相关。在高二年级和学年末，使用互动信息的情况有所下降。这些发现为优化互动信息使用提供了潜在的干预措施，有助于提高教学质量和学生成果。 

---
# FarExStance: Explainable Stance Detection for Farsi 

**Title (ZH)**: FarExStance：可解释的波斯语态度检测 

**Authors**: Majid Zarharan, Maryam Hashemi, Malika Behroozrazegh, Sauleh Eetemadi, Mohammad Taher Pilehvar, Jennifer Foster  

**Link**: [PDF](https://arxiv.org/pdf/2412.14008)  

**Abstract**: We introduce FarExStance, a new dataset for explainable stance detection in Farsi. Each instance in this dataset contains a claim, the stance of an article or social media post towards that claim, and an extractive explanation which provides evidence for the stance label. We compare the performance of a fine-tuned multilingual RoBERTa model to several large language models in zero-shot, few-shot, and parameter-efficient fine-tuned settings on our new dataset. On stance detection, the most accurate models are the fine-tuned RoBERTa model, the LLM Aya-23-8B which has been fine-tuned using parameter-efficient fine-tuning, and few-shot Claude-3.5-Sonnet. Regarding the quality of the explanations, our automatic evaluation metrics indicate that few-shot GPT-4o generates the most coherent explanations, while our human evaluation reveals that the best Overall Explanation Score (OES) belongs to few-shot Claude-3.5-Sonnet. The fine-tuned Aya-32-8B model produced explanations most closely aligned with the reference explanations. 

**Abstract (ZH)**: 我们将介绍一种新的数据集FarExStance，用于波斯语可解释立场检测。该数据集中的每个实例包含一个陈述、一篇文章或社交媒体帖子对该陈述的立场，以及一个提取性解释，提供了支持立场标签的证据。我们在这一新数据集上将微调的多语言RoBERTa模型的性能与几种大型语言模型在零样本、少样本和参数高效微调设置下进行了比较。在立场检测方面，最准确的模型是微调过的RoBERTa模型、使用参数高效微调的LLM Aya-23-8B以及少样本的Claude-3.5-Sonnet。关于解释的质量，我们的自动评估指标显示，少样本的GPT-4o生成的解释最连贯；而我们的手动评估表明，少样本的Claude-3.5-Sonnet在总体解释分数（OES）方面的表现最佳。微调过的Aya-32-8B模型生成的解释与参考解释最为接近。 

---
# What makes a good metric? Evaluating automatic metrics for text-to-image consistency 

**Title (ZH)**: 什么样的度量标准才算良好？评估-automatic-生成的文本-图像一致性度量标准 

**Authors**: Candace Ross, Melissa Hall, Adriana Romero Soriano, Adina Williams  

**Link**: [PDF](https://arxiv.org/pdf/2412.13989)  

**Abstract**: Language models are increasingly being incorporated as components in larger AI systems for various purposes, from prompt optimization to automatic evaluation. In this work, we analyze the construct validity of four recent, commonly used methods for measuring text-to-image consistency - CLIPScore, TIFA, VPEval, and DSG - which rely on language models and/or VQA models as components. We define construct validity for text-image consistency metrics as a set of desiderata that text-image consistency metrics should have, and find that no tested metric satisfies all of them. We find that metrics lack sufficient sensitivity to language and visual properties. Next, we find that TIFA, VPEval and DSG contribute novel information above and beyond CLIPScore, but also that they correlate highly with each other. We also ablate different aspects of the text-image consistency metrics and find that not all model components are strictly necessary, also a symptom of insufficient sensitivity to visual information. Finally, we show that all three VQA-based metrics likely rely on familiar text shortcuts (such as yes-bias in QA) that call their aptitude as quantitative evaluations of model performance into question. 

**Abstract (ZH)**: 语言模型越来越多地被纳入到各种目的的大型AI系统中，从提示优化到自动评估。在这项工作中，我们分析了四种近期广泛使用的测量文本-图像一致性的方法的构念效度——CLIPScore、TIFA、VPEval和DSG，这些方法依赖于语言模型和/或视觉问答（VQA）模型作为组件。我们将文本-图像一致性度量的构念效度定义为一组度量应具备的标准，并发现没有经过测试的度量能够满足所有这些标准。我们发现这些度量在语言和视觉特性方面缺乏足够的敏感性。接下来，我们发现TIFA、VPEval和DSG提供了CLIPScore之上的一些新信息，但也存在高度相关的问题。我们还消减了文本-图像一致性度量的不同方面，发现并非所有模型组件都是必不可少的，这也是视觉信息敏感性不足的症结之一。最后，我们表明，基于VQA的方法很可能依赖于熟悉的文本捷径（如QA中的是向偏见），这对其作为模型性能定量评估的合适性提出了质疑。 

---
