# Multi-Agent Verification: Scaling Test-Time Compute with Multiple Verifiers 

**Title (ZH)**: 多智能体验证：通过多种验证者扩展测试时的计算能力 

**Authors**: Shalev Lifshitz, Sheila A. McIlraith, Yilun Du  

**Link**: [PDF](https://arxiv.org/pdf/2502.20379)  

**Abstract**: By utilizing more computational resources at test-time, large language models (LLMs) can improve without additional training. One common strategy uses verifiers to evaluate candidate outputs. In this work, we propose a novel scaling dimension for test-time compute: scaling the number of verifiers. We introduce Multi-Agent Verification (MAV) as a test-time compute paradigm that combines multiple verifiers to improve performance. We propose using Aspect Verifiers (AVs), off-the-shelf LLMs prompted to verify different aspects of outputs, as one possible choice for the verifiers in a MAV system. AVs are a convenient building block for MAV since they can be easily combined without additional training. Moreover, we introduce BoN-MAV, a simple multi-agent verification algorithm that combines best-of-n sampling with multiple verifiers. BoN-MAV demonstrates stronger scaling patterns than self-consistency and reward model verification, and we demonstrate both weak-to-strong generalization, where combining weak verifiers improves even stronger LLMs, and self-improvement, where the same base model is used to both generate and verify outputs. Our results establish scaling the number of verifiers as a promising new dimension for improving language model performance at test-time. 

**Abstract (ZH)**: 通过在测试时利用更多的计算资源，大型语言模型（LLMs）可以在无需额外训练的情况下得到改进。一种常见的策略是使用验证器来评估候选输出。本研究提出了一种新的测试时计算维度：增加验证器的数量。我们介绍了一种名为多智能体验证（MAV）的测试时计算范式，该范式结合了多个验证器以提升性能。我们提出使用方面验证器（AVs），即预先配置以验证输出不同方面并可即插即用的现成语言模型，作为MAV系统中验证器的一种可能选择。由于AVs可以在无需额外训练的情况下轻松组合，因此它们成为构建MAV的理想组件。此外，我们引入了一种简单的多智能体验证算法BoN-MAV，该算法结合了最优-n采样和多个验证器。BoN-MAV在不同验证器数量上的性能表现优于自我一致性验证和奖励模型验证。我们证明了从弱到强的泛化能力，即结合弱验证器能提升更强的LLMs，并展示了自改进能力，即使用同一个基础模型同时生成和验证输出。我们的研究结果证明，增加验证器的数量是一个值得探索的新维度，有助于提高语言模型在测试时的性能。 

---
# Towards Responsible AI in Education: Hybrid Recommendation System for K-12 Students Case Study 

**Title (ZH)**: 面向教育责任的人工智能：K-12 学生混合推荐系统案例研究 

**Authors**: Nazarii Drushchak, Vladyslava Tyshchenko, Nataliya Polyakovska  

**Link**: [PDF](https://arxiv.org/pdf/2502.20354)  

**Abstract**: The growth of Educational Technology (EdTech) has enabled highly personalized learning experiences through Artificial Intelligence (AI)-based recommendation systems tailored to each student needs. However, these systems can unintentionally introduce biases, potentially limiting fair access to learning resources. This study presents a recommendation system for K-12 students, combining graph-based modeling and matrix factorization to provide personalized suggestions for extracurricular activities, learning resources, and volunteering opportunities. To address fairness concerns, the system includes a framework to detect and reduce biases by analyzing feedback across protected student groups. This work highlights the need for continuous monitoring in educational recommendation systems to support equitable, transparent, and effective learning opportunities for all students. 

**Abstract (ZH)**: 教育技术（EdTech）的发展通过基于人工智能（AI）的推荐系统使个性化学习体验成为可能，这些系统可以根据每个学生的需求量身定制。然而，这些系统可能会无意中引入偏见，可能限制了学生对学习资源的公平获取。本研究提出了一种针对K-12学生使用的推荐系统，结合图模型和矩阵分解技术，为其提供个性化建议，包括课外活动、学习资源和志愿服务机会。为了应对公平性问题，该系统包含了一个框架，用于通过分析受保护的学生群体的反馈来检测和减少偏见。本研究强调，需要持续监控教育推荐系统，以支持所有学生获得公平、透明和有效的学习机会。 

---
# EAIRA: Establishing a Methodology for Evaluating AI Models as Scientific Research Assistants 

**Title (ZH)**: EAIRA：建立评估人工智能模型作为科学研究助手的方法论 

**Authors**: Franck Cappello, Sandeep Madireddy, Robert Underwood, Neil Getty, Nicholas Lee-Ping Chia, Nesar Ramachandra, Josh Nguyen, Murat Keceli, Tanwi Mallick, Zilinghan Li, Marieme Ngom, Chenhui Zhang, Angel Yanguas-Gil, Evan Antoniuk, Bhavya Kailkhura, Minyang Tian, Yufeng Du, Yuan-Sen Ting, Azton Wells, Bogdan Nicolae, Avinash Maurya, M. Mustafa Rafique, Eliu Huerta, Bo Li, Ian Foster, Rick Stevens  

**Link**: [PDF](https://arxiv.org/pdf/2502.20309)  

**Abstract**: Recent advancements have positioned AI, and particularly Large Language Models (LLMs), as transformative tools for scientific research, capable of addressing complex tasks that require reasoning, problem-solving, and decision-making. Their exceptional capabilities suggest their potential as scientific research assistants but also highlight the need for holistic, rigorous, and domain-specific evaluation to assess effectiveness in real-world scientific applications. This paper describes a multifaceted methodology for Evaluating AI models as scientific Research Assistants (EAIRA) developed at Argonne National Laboratory. This methodology incorporates four primary classes of evaluations. 1) Multiple Choice Questions to assess factual recall; 2) Open Response to evaluate advanced reasoning and problem-solving skills; 3) Lab-Style Experiments involving detailed analysis of capabilities as research assistants in controlled environments; and 4) Field-Style Experiments to capture researcher-LLM interactions at scale in a wide range of scientific domains and applications. These complementary methods enable a comprehensive analysis of LLM strengths and weaknesses with respect to their scientific knowledge, reasoning abilities, and adaptability. Recognizing the rapid pace of LLM advancements, we designed the methodology to evolve and adapt so as to ensure its continued relevance and applicability. This paper describes the methodology state at the end of February 2025. Although developed within a subset of scientific domains, the methodology is designed to be generalizable to a wide range of scientific domains. 

**Abstract (ZH)**: 近年来，人工智能，尤其是大型语言模型（LLMs），已被视为推动科学研究变革的工具，能够在需要推理、问题解决和决策的任务中发挥作用。它们的出色能力表明它们在科学研究助理方面具有巨大的潜力，但也强调了对其进行全面、严谨且领域特定的评估的必要性，以评估其在实际科学应用中的有效性。本文描述了阿贡国家实验室开发的一种多维度方法，用于评估人工智能模型作为科学研究助理（EAIRA）。该方法包含四种主要的评估类别。1) 多选题以评估事实记忆；2) 开放式回答以评估高级推理和问题解决能力；3) 实验室风格的实验，通过在受控环境中详细分析其作为研究助理的能力来评估其能力；4) 现场风格的实验，以在广泛的科学领域和应用中捕捉研究人员与LLM的交互情况。这些互补的方法能够全面分析LLMs在科学知识、推理能力和适应性方面的优势和劣势。考虑到LLMs快速发展的步伐，我们设计了该方法以便于其不断进化和适应，以确保其持续的相关性和适用性。本文描述了截至2025年2月底的方法状态。尽管该方法是在某些科学领域内开发的，但设计目的是使其能够广泛应用于各种科学领域。 

---
# Evaluating Human Trust in LLM-Based Planners: A Preliminary Study 

**Title (ZH)**: 基于语言模型的规划器中的人类信任评估：一项初步研究 

**Authors**: Shenghui Chen, Yunhao Yang, Kayla Boggess, Seongkook Heo, Lu Feng, Ufuk Topcu  

**Link**: [PDF](https://arxiv.org/pdf/2502.20284)  

**Abstract**: Large Language Models (LLMs) are increasingly used for planning tasks, offering unique capabilities not found in classical planners such as generating explanations and iterative refinement. However, trust--a critical factor in the adoption of planning systems--remains underexplored in the context of LLM-based planning tasks. This study bridges this gap by comparing human trust in LLM-based planners with classical planners through a user study in a Planning Domain Definition Language (PDDL) domain. Combining subjective measures, such as trust questionnaires, with objective metrics like evaluation accuracy, our findings reveal that correctness is the primary driver of trust and performance. Explanations provided by the LLM improved evaluation accuracy but had limited impact on trust, while plan refinement showed potential for increasing trust without significantly enhancing evaluation accuracy. 

**Abstract (ZH)**: 大型语言模型（LLMs）越来越多地应用于规划任务，提供了经典规划器所不具备的独特能力，如生成解释和迭代优化。然而，信任——在规划系统采用中至关重要的因素——在基于LLM的规划任务背景下尚未得到充分探索。本研究通过在规划领域定义语言（PDDL）领域进行用户研究，比较了人们对于LLM规划器和经典规划器的信任度，填补了这一空白。结合主观指标（如信任问卷）与客观指标（如评估准确性），我们的研究发现正确性是驱动信任和性能的主要因素。LLM提供的解释提高了评估准确性，但对信任的影响有限，而规划改进显示出在不显著提高评估准确性的情况下增加信任的潜力。 

---
# AI Will Always Love You: Studying Implicit Biases in Romantic AI Companions 

**Title (ZH)**: AI 之爱永恒：研究浪漫型人工智能伴侣中的隐性偏见 

**Authors**: Clare Grogan, Jackie Kay, María Pérez-Ortiz  

**Link**: [PDF](https://arxiv.org/pdf/2502.20231)  

**Abstract**: While existing studies have recognised explicit biases in generative models, including occupational gender biases, the nuances of gender stereotypes and expectations of relationships between users and AI companions remain underexplored. In the meantime, AI companions have become increasingly popular as friends or gendered romantic partners to their users. This study bridges the gap by devising three experiments tailored for romantic, gender-assigned AI companions and their users, effectively evaluating implicit biases across various-sized LLMs. Each experiment looks at a different dimension: implicit associations, emotion responses, and sycophancy. This study aims to measure and compare biases manifested in different companion systems by quantitatively analysing persona-assigned model responses to a baseline through newly devised metrics. The results are noteworthy: they show that assigning gendered, relationship personas to Large Language Models significantly alters the responses of these models, and in certain situations in a biased, stereotypical way. 

**Abstract (ZH)**: 尽管现有研究已承认生成模型中存在的明确偏见，包括职业性别偏见，但用户与AI伴侣之间关系中的性别刻板印象及其微妙之处仍处于研究不足的状态。与此同时，AI伴侣因其作为朋友或性别化浪漫伴侣变得更加流行。本研究通过为性别指定的AI伴侣及其用户量身设计三项实验，填补了这一空白，有效地评估了不同大小的语言模型中的隐性偏见。每个实验考察了一个不同的维度：隐含关联、情绪响应和曲意奉承。本研究旨在通过新的度量标准对不同伴侣系统的偏见进行定量分析，从而进行测量和比较。研究结果值得注意：它们表明将性别化的关系角色分配给大型语言模型显著改变了这些模型的响应，并在某些情况下以一种带有偏见和刻板印象的方式表现出来。 

---
# An Extensive Evaluation of PDDL Capabilities in off-the-shelf LLMs 

**Title (ZH)**: 对现成的大语言模型中PDDL能力的广泛评估 

**Authors**: Kaustubh Vyas, Damien Graux, Sébastien Montella, Pavlos Vougiouklis, Ruofei Lai, Keshuang Li, Yang Ren, Jeff Z. Pan  

**Link**: [PDF](https://arxiv.org/pdf/2502.20175)  

**Abstract**: In recent advancements, large language models (LLMs) have exhibited proficiency in code generation and chain-of-thought reasoning, laying the groundwork for tackling automatic formal planning tasks. This study evaluates the potential of LLMs to understand and generate Planning Domain Definition Language (PDDL), an essential representation in artificial intelligence planning. We conduct an extensive analysis across 20 distinct models spanning 7 major LLM families, both commercial and open-source. Our comprehensive evaluation sheds light on the zero-shot LLM capabilities of parsing, generating, and reasoning with PDDL. Our findings indicate that while some models demonstrate notable effectiveness in handling PDDL, others pose limitations in more complex scenarios requiring nuanced planning knowledge. These results highlight the promise and current limitations of LLMs in formal planning tasks, offering insights into their application and guiding future efforts in AI-driven planning paradigms. 

**Abstract (ZH)**: 近年来，大规模语言模型（LLMs）在代码生成和链式推理方面表现出色，为自动形式化规划任务奠定了基础。本研究评估了LLMs在理解和生成规划领域定义语言（PDDL）方面的潜力，PDDL是人工智能规划中的重要表示方法。我们对20种不同模型进行了全面分析，涵盖了7个主要的LLM家族，既有商业模型也有开源模型。我们的全面评估揭示了零样本LLMs在解析、生成和处理PDDL方面的能力。研究发现，虽然有些模型在处理PDDL方面表现出色，但在需要精细规划知识的复杂场景中，其他模型则存在局限性。这些结果突显了LLMs在形式化规划任务中的潜力和当前限制，为它们的应用提供了见解，并指导未来基于AI的规划范式的努力。 

---
# Meta-Reasoner: Dynamic Guidance for Optimized Inference-time Reasoning in Large Language Models 

**Title (ZH)**: 元推理器：用于大型语言模型优化推理时推理的动态指导 

**Authors**: Yuan Sui, Yufei He, Tri Cao, Simeng Han, Bryan Hooi  

**Link**: [PDF](https://arxiv.org/pdf/2502.19918)  

**Abstract**: Large Language Models (LLMs) increasingly rely on prolonged reasoning chains to solve complex tasks. However, this trial-and-error approach often leads to high computational overhead and error propagation, where early mistakes can derail subsequent steps. To address these issues, we introduce Meta-Reasoner, a framework that dynamically optimizes inference-time reasoning by enabling LLMs to "think about how to think." Drawing inspiration from human meta-cognition and dual-process theory, Meta-Reasoner operates as a strategic advisor, decoupling high-level guidance from step-by-step generation. It employs "contextual multi-armed bandits" to iteratively evaluate reasoning progress, and select optimal strategies (e.g., backtrack, clarify ambiguity, restart from scratch, or propose alternative approaches), and reallocates computational resources toward the most promising paths. Our evaluations on mathematical reasoning and puzzles highlight the potential of dynamic reasoning chains to overcome inherent challenges in the LLM reasoning process and also show promise in broader applications, offering a scalable and adaptable solution for reasoning-intensive tasks. 

**Abstract (ZH)**: 大型语言模型（LLMs）越来越多地依赖于长期的推理链来解决复杂的任务。然而，这种试错方法通常会导致计算开销高昂并产生错误传播的问题，即早期的错误可能会影响后续的步骤。为了解决这些问题，我们提出了一种名为Meta-Reasoner的框架，该框架通过使LLMs能够“思考如何思考”来动态优化推理过程。受到人类元认知和双重过程理论的启发，Meta-Reasoner充当一个策略顾问，将高层次的指导与逐步生成过程分离。它使用“上下文多臂老虎机”来逐步评估推理进展，并选择最优策略（例如回退、澄清歧义、从头开始或提出替代方法），并将计算资源重新分配到最有前途的路径上。我们对数学推理和谜题的评估突显了动态推理链在克服LLMs推理过程中的固有挑战方面的潜力，并表明在更广泛的应用中具有前景，提供了一种可扩展和适应性强的解决方案，适用于涉及大量推理的任务。 

---
# LLM-driven Effective Knowledge Tracing by Integrating Dual-channel Difficulty 

**Title (ZH)**: 由大规模语言模型驱动的有效知识追踪：通过集成双通道难度机制 

**Authors**: Jiahui Cen, Jianghao Lin, Weizhong Xuan, Dong Zhou, Jin Chen, Aimin Yang, Yongmei Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2502.19915)  

**Abstract**: Knowledge Tracing (KT) is a fundamental technology in intelligent tutoring systems used to simulate changes in students' knowledge state during learning, track personalized knowledge mastery, and predict performance. However, current KT models face three major challenges: (1) When encountering new questions, models face cold-start problems due to sparse interaction records, making precise modeling difficult; (2) Traditional models only use historical interaction records for student personalization modeling, unable to accurately track individual mastery levels, resulting in unclear personalized modeling; (3) The decision-making process is opaque to educators, making it challenging for them to understand model judgments. To address these challenges, we propose a novel Dual-channel Difficulty-aware Knowledge Tracing (DDKT) framework that utilizes Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) for subjective difficulty assessment, while integrating difficulty bias-aware algorithms and student mastery algorithms for precise difficulty measurement. Our framework introduces three key innovations: (1) Difficulty Balance Perception Sequence (DBPS) - students' subjective perceptions combined with objective difficulty, measuring gaps between LLM-assessed difficulty, mathematical-statistical difficulty, and students' subjective perceived difficulty through attention mechanisms; (2) Difficulty Mastery Ratio (DMR) - precise modeling of student mastery levels through different difficulty zones; (3) Knowledge State Update Mechanism - implementing personalized knowledge acquisition through gated networks and updating student knowledge state. Experimental results on two real datasets show our method consistently outperforms nine baseline models, improving AUC metrics by 2% to 10% while effectively addressing cold-start problems and enhancing model interpretability. 

**Abstract (ZH)**: 知识追踪（KT）是智能辅导系统中的基本技术，用于模拟学生在学习过程中知识状态的变化、跟踪个性化知识掌握情况，并预测表现。然而，当前的KT模型面临三大挑战：（1）当遇到新问题时，模型因交互记录稀疏而面临冷启动问题，使得精确建模变得困难；（2）传统的模型仅使用历史交互记录进行个性化建模，无法准确跟踪个体掌握水平，导致个性化建模模糊不清；（3）决策过程对教育者来说是透明的，使得他们难以理解模型的判断。为了解决这些问题，我们提出了一种新的双通道难度感知知识追踪（DDKT）框架，该框架利用大型语言模型（LLMs）和检索增强生成（RAG）进行主观难度评估，同时结合难度偏差感知算法和学生掌握算法进行精确难度测量。我们的框架引入了三个关键创新：（1）难度平衡感知序列（DBPS）——结合学生的主观感知和客观难度，通过注意力机制测量LLMs评估难度、数学统计难度和学生主观感知难度之间的差距；（2）难度掌握比例（DMR）——通过不同的难度区间进行精确的学生掌握水平建模；（3）知识状态更新机制——通过门控网络实现个性化知识的获取，并更新学生的知识状态。在两个真实数据集上的实验结果表明，我们的方法在AUC指标上优于九个基准模型，提高了2%到10%，同时有效解决了冷启动问题，提高了模型的可解释性。 

---
# Optimus-2: Multimodal Minecraft Agent with Goal-Observation-Action Conditioned Policy 

**Title (ZH)**: Optimus-2：基于目标-观察-动作条件策略的多模态Minecraft代理 

**Authors**: Zaijing Li, Yuquan Xie, Rui Shao, Gongwei Chen, Dongmei Jiang, Liqiang Nie  

**Link**: [PDF](https://arxiv.org/pdf/2502.19902)  

**Abstract**: Building an agent that can mimic human behavior patterns to accomplish various open-world tasks is a long-term goal. To enable agents to effectively learn behavioral patterns across diverse tasks, a key challenge lies in modeling the intricate relationships among observations, actions, and language. To this end, we propose Optimus-2, a novel Minecraft agent that incorporates a Multimodal Large Language Model (MLLM) for high-level planning, alongside a Goal-Observation-Action Conditioned Policy (GOAP) for low-level control. GOAP contains (1) an Action-guided Behavior Encoder that models causal relationships between observations and actions at each timestep, then dynamically interacts with the historical observation-action sequence, consolidating it into fixed-length behavior tokens, and (2) an MLLM that aligns behavior tokens with open-ended language instructions to predict actions auto-regressively. Moreover, we introduce a high-quality Minecraft Goal-Observation-Action (MGOA)} dataset, which contains 25,000 videos across 8 atomic tasks, providing about 30M goal-observation-action pairs. The automated construction method, along with the MGOA dataset, can contribute to the community's efforts to train Minecraft agents. Extensive experimental results demonstrate that Optimus-2 exhibits superior performance across atomic tasks, long-horizon tasks, and open-ended instruction tasks in Minecraft. 

**Abstract (ZH)**: 构建能够模拟人类行为模式的代理以完成各种开放世界任务是一项长期目标。为了使代理能够有效地跨多种任务学习行为模式，一个关键挑战在于建模观测、动作和语言之间的复杂关系。为此，我们提出了Optimus-2，这是一种结合了多模态大型语言模型（MLLM）进行高层次规划，并结合了目标-观测-动作条件策略（GOAP）进行低层次控制的新型Minecraft代理。GOAP 包含以下两个组成部分：(1) 行动导向的行为编码器，该编码器在每个时间步长中建模观测与动作之间的因果关系，然后与历史观测-动作序列动态交互，将其合并成固定长度的行为令牌；(2) MLLM，该模型将行为令牌与开放性语言指令对齐以自回归地预测动作。此外，我们还引入了一个高质量的Minecraft目标-观测-动作（MGOA）数据集，该数据集包含25,000个视频，横跨8个原子任务，提供了大约3000万个目标-观测-动作对。自动化构建方法以及MGOA数据集能够为Minecraft代理的训练工作做出贡献。广泛的实验结果表明，Optimus-2在Minecraft中的原子任务、长时任务和开放式指令任务中均表现出卓越的性能。 

---
# Developmental Support Approach to AI's Autonomous Growth: Toward the Realization of a Mutually Beneficial Stage Through Experiential Learning 

**Title (ZH)**: 基于发展支持的方法促进人工智能自主成长：通过经验学习实现 mutually beneficial stage 的路径探索

注：原文中的"mutually beneficial stage"在中文中翻译为“互相受益阶段”或“互惠阶段”。考虑到学术规范和流畅性，第一种翻译更为合适。如果“mutually beneficial stage”有特定的学术含义或专业术语，建议根据具体背景进一步确认翻译。 

**Authors**: Taichiro Endo  

**Link**: [PDF](https://arxiv.org/pdf/2502.19798)  

**Abstract**: This study proposes an "AI Development Support" approach that, unlike conventional AI Alignment-which aims to forcefully inject human values-supports the ethical and moral development of AI itself. As demonstrated by the Orthogonality Thesis, the level of intelligence and the moral quality of a goal are independent; merely expanding knowledge does not enhance ethical judgment. Furthermore, to address the risk of Instrumental Convergence in ASI-that is, the tendency to engage in subsidiary behaviors such as self-protection, resource acquisition, and power reinforcement to achieve a goal-we have constructed a learning framework based on a cycle of experience, introspection, analysis, and hypothesis formation. As a result of post-training using Supervised Fine Tuning (SFT) and Direct Preference Optimization (DPO) with synthetic data generated by large language models (LLMs), responses demonstrating cooperative and highly advanced moral judgment (reaching the high-est Stage 6) were obtained even under adversarial prompts. This method represents a promising implementation approach for enabling AI to establish sustainable, symbiotic relationships. 

**Abstract (ZH)**: 本研究提出了一种“AI发展支持”方法，该方法与传统的AI对齐有所不同，后者旨在强制注入人类价值观，而是支持AI本身的伦理和道德发展。正如正交性论题所展示的，智能程度与目标的道德品质是独立的；仅仅增加知识并不能提升伦理判断能力。此外，为了应对ASI（超智能系统）工具化趋同的风险，即为了实现目标而倾向于进行诸如自我保护、资源获取和权力增强等辅助行为，我们建立了一种基于经验、反思、分析和假设形成循环的学习框架。通过使用大型语言模型（LLMs）生成的合成数据进行监督微调（SFT）和直接偏好优化（DPO）的后续训练，即使在对抗性提示下，也获得了表现出高度合作和高度先进的道德判断（达到最高阶段6）的响应。该方法代表了一种有前景的实现方式，能够使AI建立可持续的共生关系。 

---
# Agentic Mixture-of-Workflows for Multi-Modal Chemical Search 

**Title (ZH)**: 用于多模态化学搜索的代理工作流混合模型 

**Authors**: Tiffany J. Callahan, Nathaniel H. Park, Sara Capponi  

**Link**: [PDF](https://arxiv.org/pdf/2502.19629)  

**Abstract**: The vast and complex materials design space demands innovative strategies to integrate multidisciplinary scientific knowledge and optimize materials discovery. While large language models (LLMs) have demonstrated promising reasoning and automation capabilities across various domains, their application in materials science remains limited due to a lack of benchmarking standards and practical implementation frameworks. To address these challenges, we introduce Mixture-of-Workflows for Self-Corrective Retrieval-Augmented Generation (CRAG-MoW) - a novel paradigm that orchestrates multiple agentic workflows employing distinct CRAG strategies using open-source LLMs. Unlike prior approaches, CRAG-MoW synthesizes diverse outputs through an orchestration agent, enabling direct evaluation of multiple LLMs across the same problem domain. We benchmark CRAG-MoWs across small molecules, polymers, and chemical reactions, as well as multi-modal nuclear magnetic resonance (NMR) spectral retrieval. Our results demonstrate that CRAG-MoWs achieve performance comparable to GPT-4o while being preferred more frequently in comparative evaluations, highlighting the advantage of structured retrieval and multi-agent synthesis. By revealing performance variations across data types, CRAG-MoW provides a scalable, interpretable, and benchmark-driven approach to optimizing AI architectures for materials discovery. These insights are pivotal in addressing fundamental gaps in benchmarking LLMs and autonomous AI agents for scientific applications. 

**Abstract (ZH)**: 巨大的材料设计空间要求采用创新策略整合多学科科学知识并优化材料发现过程。虽然大型语言模型（LLMs）在诸多领域展现了有希望的推理和自动化能力，但它们在材料科学中的应用仍然受限，主要是由于缺乏基准测试标准和实际实施框架。为应对这些挑战，我们引入了一种新的范式——混合工作流自纠正检索增强生成（Mixture-of-Workflows for Self-Corrective Retrieval-Augmented Generation, CRAG-MoW）——该范式使用开源LLMs协调多个独立的CRAG策略。与之前的 approached 不同，CRAG-MoW 通过一个调和代理将不同的输出进行集成，从而使多种LLMs能够直接在同一问题域内进行评估。我们对小分子、聚合物、化学反应以及多模态核磁共振（NMR）光谱检索进行了基准测试。结果显示，CRAG-MoWs 在性能上与GPT-4o相当，并且在比较评估中被更频繁地优先选择，这突显了结构化检索和多代理合成的优势。通过揭示不同数据类型下的性能差异，CRAG-MoW 提供了一种可扩展、可解释并以基准驱动的方法，以优化材料发现中的AI架构。这些见解对于弥合LLMs和自主AI代理在科学应用领域的基准测试基本差距至关重要。 

---
# Self-rewarding correction for mathematical reasoning 

**Title (ZH)**: 数学推理中的自我奖励修正 

**Authors**: Wei Xiong, Hanning Zhang, Chenlu Ye, Lichang Chen, Nan Jiang, Tong Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2502.19613)  

**Abstract**: We study self-rewarding reasoning large language models (LLMs), which can simultaneously generate step-by-step reasoning and evaluate the correctness of their outputs during the inference time-without external feedback. This integrated approach allows a single model to independently guide its reasoning process, offering computational advantages for model deployment. We particularly focus on the representative task of self-correction, where models autonomously detect errors in their responses, revise outputs, and decide when to terminate iterative refinement loops. To enable this, we propose a two-staged algorithmic framework for constructing self-rewarding reasoning models using only self-generated data. In the first stage, we employ sequential rejection sampling to synthesize long chain-of-thought trajectories that incorporate both self-rewarding and self-correction mechanisms. Fine-tuning models on these curated data allows them to learn the patterns of self-rewarding and self-correction. In the second stage, we further enhance the models' ability to assess response accuracy and refine outputs through reinforcement learning with rule-based signals. Experiments with Llama-3 and Qwen-2.5 demonstrate that our approach surpasses intrinsic self-correction capabilities and achieves performance comparable to systems that rely on external reward models. 

**Abstract (ZH)**: 我们研究了一种自我奖励推理的大语言模型（LLMs），它能够在推理过程中同时生成逐步推理过程并在输出时评估其正确性，无需外部反馈。这种集成方法允许单个模型独立指导其推理过程，为模型部署提供了计算上的优势。我们特别关注自我修正任务，即模型能够自主检测其回复中的错误、修正输出，并决定何时终止迭代精炼循环。为了实现这一目标，我们提出了一种仅使用自动生成数据的两阶段算法框架，以构建自我奖励推理模型。在第一阶段，我们采用序列拒绝采样方法合成包含自我奖励和自我修正机制的长推理轨迹。通过在这些精心筛选的数据上微调模型，可以让模型学习自我奖励和自我修正的模式。在第二阶段，我们进一步通过基于规则的信号进行强化学习，增强模型评估响应准确性和精炼输出的能力。实验结果显示，我们的方法超越了内在的自我修正能力，并且达到了与依赖外部奖励模型的系统相当的性能。 

---
# Program Synthesis Dialog Agents for Interactive Decision-Making 

**Title (ZH)**: 交互决策中的程序合成对话代理 

**Authors**: Matthew Toles, Nikhil Balwani, Rattandeep Singh, Valentina Giulia Sartori Rodriguez, Zhou Yu  

**Link**: [PDF](https://arxiv.org/pdf/2502.19610)  

**Abstract**: Many real-world eligibility problems, ranging from medical diagnosis to tax planning, can be mapped to decision problems expressed in natural language, wherein a model must make a binary choice based on user features. Large-scale domains such as legal codes or frequently updated funding opportunities render human annotation (e.g., web forms or decision trees) impractical, highlighting the need for agents that can automatically assist in decision-making. Since relevant information is often only known to the user, it is crucial that these agents ask the right questions. As agents determine when to terminate a conversation, they face a trade-off between accuracy and the number of questions asked, a key metric for both user experience and cost. To evaluate this task, we propose BeNYfits, a new benchmark for determining user eligibility for multiple overlapping social benefits opportunities through interactive decision-making. Our experiments show that current language models struggle with frequent hallucinations, with GPT-4o scoring only 35.7 F1 using a ReAct-style chain-of-thought. To address this, we introduce ProADA, a novel approach that leverages program synthesis to assist in decision-making by mapping dialog planning to a code generation problem and using gaps in structured data to determine the best next action. Our agent, ProADA, improves the F1 score to 55.6 while maintaining nearly the same number of dialog turns. 

**Abstract (ZH)**: 许多实际应用中的资格问题，从医疗诊断到税务规划，都可以映射为自然语言表达的决策问题，在这些问题中，模型必须基于用户特征做出二元选择。在法律条文或经常更新的资金机会等大规模领域中，手动标注（例如网页表单或决策树）变得不切实际，突显了能够自动辅助决策的代理的需求。由于相关信息通常只有用户知晓，因此这些代理提出正确问题至关重要。随着代理决定何时终止对话，他们需要在准确性和提出的问题数量之间进行权衡，这是用户经验和成本的重要指标。为了评估这一任务，我们提出了BeNYfits基准，这是一个新的交互式决策方案，用于确定用户是否符合多个重叠的社会福利机会的资格。实验结果显示，当前的语言模型在频繁出现幻觉方面表现不佳，GPT-4o仅获得35.7的F1得分，使用ReAct风格的推理链。为了解决这个问题，我们提出了ProADA，这是一种新型方法，利用程序合成来辅助决策，通过将对话规划映射为代码生成问题，并利用结构化数据中的空白来决定最佳下一步行动。我们的代理ProADA将F1得分提高到55.6，同时基本保持了相同的对话轮次。 

---
# Trustworthy Answers, Messier Data: Bridging the Gap in Low-Resource Retrieval-Augmented Generation for Domain Expert Systems 

**Title (ZH)**: 可信的答案，复杂的数据：领域专家系统中低资源检索增强生成鸿沟的跨越 

**Authors**: Nayoung Choi, Grace Byun, Andrew Chung, Ellie S. Paek, Shinsun Lee, Jinho D. Choi  

**Link**: [PDF](https://arxiv.org/pdf/2502.19596)  

**Abstract**: RAG has become a key technique for enhancing LLMs by reducing hallucinations, especially in domain expert systems where LLMs may lack sufficient inherent knowledge. However, developing these systems in low-resource settings introduces several challenges: (1) handling heterogeneous data sources, (2) optimizing retrieval phase for trustworthy answers, and (3) evaluating generated answers across diverse aspects. To address these, we introduce a data generation pipeline that transforms raw multi-modal data into structured corpus and Q&A pairs, an advanced re-ranking phase improving retrieval precision, and a reference matching algorithm enhancing answer traceability. Applied to the automotive engineering domain, our system improves factual correctness (+1.94), informativeness (+1.16), and helpfulness (+1.67) over a non-RAG baseline, based on a 1-5 scale by an LLM judge. These results highlight the effectiveness of our approach across distinct aspects, with strong answer grounding and transparency. 

**Abstract (ZH)**: RAG已成为通过减少幻觉来增强大规模语言模型（LLM）的关键技术，特别是在LLM可能缺乏足够内在知识的领域专家系统中表现尤为突出。然而，在低资源环境中开发这些系统也带来了若干挑战：（1）处理异构数据源，（2）优化检索阶段以获得可靠的答案，以及（3）从多方面评价生成的答案。为解决这些问题，我们提出了一种数据生成流水线，将原始多模态数据转换为结构化的语料库和问答对，引入先进的重新排名阶段以提高检索精度，并采用参考匹配算法增强答案的可追溯性。在汽车工程领域应用时，我们的系统在事实正确性（+1.94）、信息量（+1.16）和有用性（+1.67）方面超过了非RAG基线，评分标准为1到5分，由LLM评判员基于1-5分进行评估。这些结果突显了我们方法在多个方面的有效性，具有强大的答案落地性和透明度。 

---
# Repurposing the scientific literature with vision-language models 

**Title (ZH)**: 利用视觉-语言模型重塑科学文献 

**Authors**: Anton Alyakin, Jaden Stryker, Daniel Alexander Alber, Karl L. Sangwon, Brandon Duderstadt, Akshay Save, David Kurland, Spencer Frome, Shrutika Singh, Jeff Zhang, Eunice Yang, Ki Yun Park, Cordelia Orillac, Aly A. Valliani, Sean Neifert, Albert Liu, Aneek Patel, Christopher Livia, Darryl Lau, Ilya Laufer, Peter A. Rozman, Eveline Teresa Hidalgo, Howard Riina, Rui Feng, Todd Hollon, Yindalon Aphinyanaphongs, John G. Golfinos, Laura Snyder, Eric Leuthardt, Douglas Kondziolka, Eric Karl Oermann  

**Link**: [PDF](https://arxiv.org/pdf/2502.19546)  

**Abstract**: Research in AI for Science often focuses on using AI technologies to augment components of the scientific process, or in some cases, the entire scientific method; how about AI for scientific publications? Peer-reviewed journals are foundational repositories of specialized knowledge, written in discipline-specific language that differs from general Internet content used to train most large language models (LLMs) and vision-language models (VLMs). We hypothesized that by combining a family of scientific journals with generative AI models, we could invent novel tools for scientific communication, education, and clinical care. We converted 23,000 articles from Neurosurgery Publications into a multimodal database - NeuroPubs - of 134 million words and 78,000 image-caption pairs to develop six datasets for building AI models. We showed that the content of NeuroPubs uniquely represents neurosurgery-specific clinical contexts compared with broader datasets and PubMed. For publishing, we employed generalist VLMs to automatically generate graphical abstracts from articles. Editorial board members rated 70% of these as ready for publication without further edits. For education, we generated 89,587 test questions in the style of the ABNS written board exam, which trainee and faculty neurosurgeons found indistinguishable from genuine examples 54% of the time. We used these questions alongside a curriculum learning process to track knowledge acquisition while training our 34 billion-parameter VLM (CNS-Obsidian). In a blinded, randomized controlled trial, we demonstrated the non-inferiority of CNS-Obsidian to GPT-4o (p = 0.1154) as a diagnostic copilot for a neurosurgical service. Our findings lay a novel foundation for AI with Science and establish a framework to elevate scientific communication using state-of-the-art generative artificial intelligence while maintaining rigorous quality standards. 

**Abstract (ZH)**: 人工智能在科学中的研究通常关注使用AI技术来增强科学研究过程的某些组成部分，或者在某些情况下，增强整个科学方法；那么，人工智能在科学出版中的作用如何？经同行评审的期刊是专业知识的基础仓库，其内容使用的是学科特定的语言，这与大多数大型语言模型（LLMs）和视觉语言模型（VLMs）用于训练的一般网络内容不同。我们假设通过将一系列科学期刊与生成式AI模型结合起来，可以发明新的工具，用于科学研究、教育和临床护理。我们从《神经外科出版物》中转换了23,000篇文章，构建了一个包含1.34亿单词和7.8万幅图片配对语句的多模态数据库——NeuroPubs，以开发六个数据集用于构建AI模型。研究表明，NeuroPubs的内容在神经外科特定的临床环境中具有独特性，与更广泛的数据库和PubMed中的内容相比。在出版方面，我们使用通用型VLMs自动生成图形摘要。编辑委员会成员中有70%的文章在不进行进一步编辑的情况下认为可以直接发表。在教育方面，我们生成了89,587道考试题目，模仿ABNS书面考试的风格，学员和教员神经外科医生有54%的时间分辨不出这些题目与真实题目有何区别。我们使用这些题目和一个课程学习过程，在训练我们的34亿参数VLM（CNS-Obsidian）的同时追踪知识获取。在一项双盲随机对照试验中，我们证明了CNS-Obsidian在神经外科服务中的诊断副驾驶作用与GPT-4o不存在非劣性差异（p = 0.1154）。我们的研究为将科学与AI相结合奠定了新的基础，并建立了一个框架，利用最先进生成式人工智能提升科学交流，同时维持严格的质量标准。 

---
# Opus: A Workflow Intention Framework for Complex Workflow Generation 

**Title (ZH)**: opus：一种复杂工作流生成的工作流意图框架 

**Authors**: Phillip Kingston, Théo Fagnoni, Mahsun Altin  

**Link**: [PDF](https://arxiv.org/pdf/2502.19532)  

**Abstract**: This paper introduces Workflow Intention, a novel framework for identifying and encoding process objectives within complex business environments. Workflow Intention is the alignment of Input, Process and Output elements defining a Workflow's transformation objective interpreted from Workflow Signal inside Business Artefacts. It specifies how Input is processed to achieve desired Output, incorporating quality standards, business rules, compliance requirements and constraints. We adopt an end-to-end Business Artefact Encoder and Workflow Signal interpretation methodology involving four steps: Modality-Specific Encoding, Intra-Modality Attention, Inter-Modality Fusion Attention then Intention Decoding. We provide training procedures and critical loss function definitions. In this paper we introduce the concepts of Workflow Signal and Workflow Intention, where Workflow Signal decomposed into Input, Process and Output elements is interpreted from Business Artefacts, and Workflow Intention is a complete triple of these elements. We introduce a mathematical framework for representing Workflow Signal as a vector and Workflow Intention as a tensor, formalizing properties of these objects. Finally, we propose a modular, scalable, trainable, attention-based multimodal generative system to resolve Workflow Intention from Business Artefacts. 

**Abstract (ZH)**: 本文介绍了工作流意图（Workflow Intention）框架，这是一种在复杂商业环境中识别和编码过程目标的新颖方法。工作流意图表示工作流基于业务 artefacts 中的 workflow signal 转化目标的 Input、Process 和 Output 元素的对齐。它明确了如何处理 Input 以实现期望的 Output，并融入了质量标准、业务规则、合规要求和约束条件。我们采用涵盖四个步骤的端到端商业模式编码和 workflow signal 解释方法：特定模态编码、模态内注意力、跨模态融合注意力以及意图解码。我们提供了训练程序和关键损失函数定义。在本文中，我们引入了 workflow signal 和 work flow intention 的概念，其中 workflow signal 由 workflow 的 Input、Process 和 Output 元素组成，并从业务 artefacts 中进行解释，而 work flow intention 则是这些元素的完整三元组。我们提出了数学框架来表示 workflow signal 为向量和 workflow intention 为张量，正式化了这些对象的性质。最后，我们提出了一种模块化、可扩展、可训练的基于注意力的多模态生成系统，用于从业务 artefacts 中解析工作流意图。 

---
# Building Knowledge Graphs Towards a Global Food Systems Datahub 

**Title (ZH)**: 构建知识图谱以建立全球食品体系数据枢纽 

**Authors**: Nirmal Gelal, Aastha Gautam, Sanaz Saki Norouzi, Nico Giordano, Claudio Dias da Silva Jr, Jean Ribert Francois, Kelsey Andersen Onofre, Katherine Nelson, Stacy Hutchinson, Xiaomao Lin, Stephen Welch, Romulo Lollato, Pascal Hitzler, Hande Küçük McGinty  

**Link**: [PDF](https://arxiv.org/pdf/2502.19507)  

**Abstract**: Sustainable agricultural production aligns with several sustainability goals established by the United Nations (UN). However, there is a lack of studies that comprehensively examine sustainable agricultural practices across various products and production methods. Such research could provide valuable insights into the diverse factors influencing the sustainability of specific crops and produce while also identifying practices and conditions that are universally applicable to all forms of agricultural production. While this research might help us better understand sustainability, the community would still need a consistent set of vocabularies. These consistent vocabularies, which represent the underlying datasets, can then be stored in a global food systems datahub. The standardized vocabularies might help encode important information for further statistical analyses and AI/ML approaches in the datasets, resulting in the research targeting sustainable agricultural production. A structured method of representing information in sustainability, especially for wheat production, is currently unavailable. In an attempt to address this gap, we are building a set of ontologies and Knowledge Graphs (KGs) that encode knowledge associated with sustainable wheat production using formal logic. The data for this set of knowledge graphs are collected from public data sources, experimental results collected at our experiments at Kansas State University, and a Sustainability Workshop that we organized earlier in the year, which helped us collect input from different stakeholders throughout the value chain of wheat. The modeling of the ontology (i.e., the schema) for the Knowledge Graph has been in progress with the help of our domain experts, following a modular structure using KNARM methodology. In this paper, we will present our preliminary results and schemas of our Knowledge Graph and ontologies. 

**Abstract (ZH)**: 可持续的农业生产与联合国（UN）确立的多项可持续发展目标相一致。然而，缺乏全面研究各种产品和生产方式下的可持续农业实践。这种研究可以为特定作物和产品可持续性的多种因素提供有价值的见解，同时也能识别出适用于所有农业生产的通用实践和条件。尽管这类研究有助于我们更好地理解可持续性，但研究社区仍需要一套一致的词汇。这些一致的词汇代表了底层数据集，可以储存在全球食品系统数据湖中。标准化的词汇有助于在数据集中编码重要信息，进一步支持统计分析和AI/ML方法，从而瞄准可持续农业生产的研究。目前，特别是在小麦生产中，缺乏一种结构化的信息表示方法。为了解决这一问题，我们正在建立一组本体和知识图谱（KGs），使用形式逻辑编码与可持续小麦生产相关的知识。这些知识图谱的数据来源包括公共数据源、我们在堪萨斯州立大学实验中收集的实验结果以及我们今年早些时候组织的可持续性研讨会，这帮助我们从价值链中的不同利益相关者那里收集反馈。我们依靠领域专家，在KNARM方法框架下采用模块化结构来建模本体（即模式）。本文将介绍我们知识图谱和本体的初步结果及模式。 

---
# Conversational Planning for Personal Plans 

**Title (ZH)**: 个人计划的对话式规划 

**Authors**: Konstantina Christakopoulou, Iris Qu, John Canny, Andrew Goodridge, Cj Adams, Minmin Chen, Maja Matarić  

**Link**: [PDF](https://arxiv.org/pdf/2502.19500)  

**Abstract**: The language generation and reasoning capabilities of large language models (LLMs) have enabled conversational systems with impressive performance in a variety of tasks, from code generation, to composing essays, to passing STEM and legal exams, to a new paradigm for knowledge search. Besides those short-term use applications, LLMs are increasingly used to help with real-life goals or tasks that take a long time to complete, involving multiple sessions across days, weeks, months, or even years. Thus to enable conversational systems for long term interactions and tasks, we need language-based agents that can plan for long horizons. Traditionally, such capabilities were addressed by reinforcement learning agents with hierarchical planning capabilities. In this work, we explore a novel architecture where the LLM acts as the meta-controller deciding the agent's next macro-action, and tool use augmented LLM-based option policies execute the selected macro-action. We instantiate this framework for a specific set of macro-actions enabling adaptive planning for users' personal plans through conversation and follow-up questions collecting user feedback. We show how this paradigm can be applicable in scenarios ranging from tutoring for academic and non-academic tasks to conversational coaching for personal health plans. 

**Abstract (ZH)**: 大型语言模型（LLMs）的生成语言和推理能力使得在各种任务中实现了令人印象深刻的对话系统，这些任务从代码生成到撰写论文，再到通过科学、技术、工程和法律考试，甚至是一种新的知识搜索范式。除了这些短期应用，LLMs 越来越多地被用于帮助实现长期的生活目标或需要跨多天、周、月甚至年才能完成的任务。因此，为了让对话系统能够处理长期互动和任务，我们需要基于语言的代理能够为远期规划做好准备。传统上，这些能力是通过具有层次规划能力的强化学习代理来解决的。在本文中，我们探索了一个新的架构，其中LLM充当元控制器，决定代理的下一步宏观行动，而基于LLM的选项策略增强工具使用执行选定的宏观行动。我们为特定的一组宏观行动实例化了这一框架，通过对话和后续问题收集用户反馈，实现用户个人计划的自适应规划。我们展示了这一范式如何适用于从学术和非学术任务的辅导到个人健康计划的对话式指导等各种场景。 

---
# Sim-to-Real Reinforcement Learning for Vision-Based Dexterous Manipulation on Humanoids 

**Title (ZH)**: 基于视觉的灵巧操作中类转真实强化学习方法研究（应用于类人机器人） 

**Authors**: Toru Lin, Kartik Sachdev, Linxi Fan, Jitendra Malik, Yuke Zhu  

**Link**: [PDF](https://arxiv.org/pdf/2502.20396)  

**Abstract**: Reinforcement learning has delivered promising results in achieving human- or even superhuman-level capabilities across diverse problem domains, but success in dexterous robot manipulation remains limited. This work investigates the key challenges in applying reinforcement learning to solve a collection of contact-rich manipulation tasks on a humanoid embodiment. We introduce novel techniques to overcome the identified challenges with empirical validation. Our main contributions include an automated real-to-sim tuning module that brings the simulated environment closer to the real world, a generalized reward design scheme that simplifies reward engineering for long-horizon contact-rich manipulation tasks, a divide-and-conquer distillation process that improves the sample efficiency of hard-exploration problems while maintaining sim-to-real performance, and a mixture of sparse and dense object representations to bridge the sim-to-real perception gap. We show promising results on three humanoid dexterous manipulation tasks, with ablation studies on each technique. Our work presents a successful approach to learning humanoid dexterous manipulation using sim-to-real reinforcement learning, achieving robust generalization and high performance without the need for human demonstration. 

**Abstract (ZH)**: 强化学习在多个问题领域取得了令人鼓舞的结果，实现了接近甚至超越人类的性能，但在灵巧机器人操作方面取得的成功仍然有限。本研究探讨了将强化学习应用于解决人形机器人 embodiment 上的接触丰富操作任务的关键挑战，并引入了新的技术以进行实证验证。我们的主要贡献包括：一种自动化的实到仿真实验模块，使仿真的环境更加接近真实世界；一种通用的奖励设计方案，简化了长期时间接触丰富操作任务的奖励工程；一种分而治之的教学过程，提高了难以探索问题的学习效率，同时保持了仿真的真实性能；以及一种稀疏和密集表示的混合，以弥合仿真与现实之间的感知差距。我们在三个灵巧操作任务中展示了有前景的结果，并对每种技术进行了消融研究。我们的工作提出了一种利用仿真到现实的强化学习进行人形灵巧操作学习的成功方法，实现了鲁棒泛化和高性能，无需人类演示。 

---
# Walking the Web of Concept-Class Relationships in Incrementally Trained Interpretable Models 

**Title (ZH)**: 逐步训练的可解释模型中概念类关系的探索 

**Authors**: Susmit Agrawal, Deepika Vemuri, Sri Siddarth Chakaravarthy P, Vineeth N. Balasubramanian  

**Link**: [PDF](https://arxiv.org/pdf/2502.20393)  

**Abstract**: Concept-based methods have emerged as a promising direction to develop interpretable neural networks in standard supervised settings. However, most works that study them in incremental settings assume either a static concept set across all experiences or assume that each experience relies on a distinct set of concepts. In this work, we study concept-based models in a more realistic, dynamic setting where new classes may rely on older concepts in addition to introducing new concepts themselves. We show that concepts and classes form a complex web of relationships, which is susceptible to degradation and needs to be preserved and augmented across experiences. We introduce new metrics to show that existing concept-based models cannot preserve these relationships even when trained using methods to prevent catastrophic forgetting, since they cannot handle forgetting at concept, class, and concept-class relationship levels simultaneously. To address these issues, we propose a novel method - MuCIL - that uses multimodal concepts to perform classification without increasing the number of trainable parameters across experiences. The multimodal concepts are aligned to concepts provided in natural language, making them interpretable by design. Through extensive experimentation, we show that our approach obtains state-of-the-art classification performance compared to other concept-based models, achieving over 2$\times$ the classification performance in some cases. We also study the ability of our model to perform interventions on concepts, and show that it can localize visual concepts in input images, providing post-hoc interpretations. 

**Abstract (ZH)**: 基于概念的方法在标准监督设置中发展可解释的神经网络方面展现出了有希望的方向。然而，大多数在增量设置中研究这些方法的工作要么假设所有经验中概念集合静态不变，要么假设每个经验依赖于不同的概念集。在本研究中，我们探讨了概念模型在更具现实性和动态性的环境中，其中新类别不仅依赖于旧概念，还引入了新概念。我们发现，概念和类别之间形成了一个复杂的关系网络，这一网络容易退化并需要在经验中得到保留和增强。我们引入了新的度量标准，证明现有的基于概念的方法在使用防止灾难性遗忘的方法进行训练时，仍然无法保留这些关系，因为它们无法同时处理概念、类别和概念-类别关系层面的遗忘。为了解决这些问题，我们提出了一种新颖的方法——MuCIL，该方法使用多模态概念进行分类，同时不会增加跨经验的可训练参数数量。多模态概念与自然语言提供的概念对齐，使其具有可解释性。通过广泛实验，我们展示了我们的方法在分类性能上优于其他基于概念的方法，某些情况下甚至提高了两倍以上的分类性能。我们还研究了模型在概念干预方面的能力，并展示了其能够在输入图像中定位视觉概念，提供后解释性解释。 

---
# Physics-Driven Data Generation for Contact-Rich Manipulation via Trajectory Optimization 

**Title (ZH)**: 基于物理驱动的数据生成方法：通过轨迹优化实现接触丰富的操作 

**Authors**: Lujie Yang, H.J. Terry Suh, Tong Zhao, Bernhard Paus Graesdal, Tarik Kelestemur, Jiuguang Wang, Tao Pang, Russ Tedrake  

**Link**: [PDF](https://arxiv.org/pdf/2502.20382)  

**Abstract**: We present a low-cost data generation pipeline that integrates physics-based simulation, human demonstrations, and model-based planning to efficiently generate large-scale, high-quality datasets for contact-rich robotic manipulation tasks. Starting with a small number of embodiment-flexible human demonstrations collected in a virtual reality simulation environment, the pipeline refines these demonstrations using optimization-based kinematic retargeting and trajectory optimization to adapt them across various robot embodiments and physical parameters. This process yields a diverse, physically consistent dataset that enables cross-embodiment data transfer, and offers the potential to reuse legacy datasets collected under different hardware configurations or physical parameters. We validate the pipeline's effectiveness by training diffusion policies from the generated datasets for challenging contact-rich manipulation tasks across multiple robot embodiments, including a floating Allegro hand and bimanual robot arms. The trained policies are deployed zero-shot on hardware for bimanual iiwa arms, achieving high success rates with minimal human input. Project website: this https URL. 

**Abstract (ZH)**: 我们提出了一种低成本的数据生成流水线，该流水线整合了基于物理的模拟、人类演示和基于模型的规划，以高效地生成大规模、高质量的数据集，用于接触丰富的机器人操作任务。该流程从虚拟现实模拟环境中收集的少量灵活载体的人类演示开始，通过基于优化的运动重构和轨迹优化，对这些演示进行细化，使其适应各种机器人载体和物理参数。这一过程产生了一个多样且物理一致的数据集，能够实现跨载体的数据传输，并具有重用在不同硬件配置或物理参数下收集的旧数据集的潜力。我们通过在多个机器人载体上训练扩散策略，包括浮动的Allegro手和双臂机器人，验证了该流水线的有效性，这些策略在双臂iiwa机器人上实现零样本部署，实现了高成功率，并且只需要少量的人工干预。项目网站: [请在此处添加网址]。 

---
# Multi-Turn Code Generation Through Single-Step Rewards 

**Title (ZH)**: 通过单步奖励实现多轮代码生成 

**Authors**: Arnav Kumar Jain, Gonzalo Gonzalez-Pumariega, Wayne Chen, Alexander M Rush, Wenting Zhao, Sanjiban Choudhury  

**Link**: [PDF](https://arxiv.org/pdf/2502.20380)  

**Abstract**: We address the problem of code generation from multi-turn execution feedback. Existing methods either generate code without feedback or use complex, hierarchical reinforcement learning to optimize multi-turn rewards. We propose a simple yet scalable approach, $\mu$Code, that solves multi-turn code generation using only single-step rewards. Our key insight is that code generation is a one-step recoverable MDP, where the correct code can be recovered from any intermediate code state in a single turn. $\mu$Code iteratively trains both a generator to provide code solutions conditioned on multi-turn execution feedback and a verifier to score the newly generated code. Experimental evaluations show that our approach achieves significant improvements over the state-of-the-art baselines. We provide analysis of the design choices of the reward models and policy, and show the efficacy of $\mu$Code at utilizing the execution feedback. Our code is available at this https URL. 

**Abstract (ZH)**: 我们解决了多轮执行反馈下的代码生成问题。现有的方法要么在没有反馈的情况下生成代码，要么使用复杂的层次强化学习来优化多轮奖励。我们提出了一种简单而可扩展的方法，即 $\mu$Code，该方法仅使用单步奖励来解决多轮代码生成问题。我们的关键洞察是代码生成是一个一步骤可恢复的马尔可夫决策过程（MDP），正确的代码可以从任何中间代码状态在单一迭代中被恢复。$\mu$Code 通过迭代训练一个生成器，根据多轮执行反馈提供代码解决方案，并训练一个验证器来评估新生成的代码。实验评估表明，我们的方法在与最先进的基线方法相比时取得了显著的改进。我们深入分析了奖励模型和策略的设计选择，并展示了 $\mu$Code 在利用执行反馈方面的有效性。我们的代码可以在以下链接中获取：[此链接](this https URL)。 

---
# PhantomWiki: On-Demand Datasets for Reasoning and Retrieval Evaluation 

**Title (ZH)**: PhantomWiki：按需数据集用于推理和检索评估 

**Authors**: Albert Gong, Kamilė Stankevičiūtė, Chao Wan, Anmol Kabra, Raphael Thesmar, Johann Lee, Julius Klenke, Carla P. Gomes, Kilian Q. Weinberger  

**Link**: [PDF](https://arxiv.org/pdf/2502.20377)  

**Abstract**: High-quality benchmarks are essential for evaluating reasoning and retrieval capabilities of large language models (LLMs). However, curating datasets for this purpose is not a permanent solution as they are prone to data leakage and inflated performance results. To address these challenges, we propose PhantomWiki: a pipeline to generate unique, factually consistent document corpora with diverse question-answer pairs. Unlike prior work, PhantomWiki is neither a fixed dataset, nor is it based on any existing data. Instead, a new PhantomWiki instance is generated on demand for each evaluation. We vary the question difficulty and corpus size to disentangle reasoning and retrieval capabilities respectively, and find that PhantomWiki datasets are surprisingly challenging for frontier LLMs. Thus, we contribute a scalable and data leakage-resistant framework for disentangled evaluation of reasoning, retrieval, and tool-use abilities. Our code is available at this https URL. 

**Abstract (ZH)**: 高质量的标准数据集对于评估大型语言模型（LLMs）的推理和检索能力至关重要。然而，专门为这一目的构建数据集并非长久之计，因为它们容易发生数据泄露，并导致夸大性能结果。为了解决这些挑战，我们提出了一种名为PhantomWiki的管道，用于生成独特且事实一致的文档集，并包含多样化的问答对。与先前的工作不同，PhantomWiki既不是一个固定的数据库，也不基于任何现有的数据集。相反，针对每次评估，都会生成一个新的PhantomWiki实例。我们通过变化问题难度和文档集的规模，分别分离推理能力和检索能力，并发现PhantomWiki数据集对前沿的LLMs构成了出乎意料的挑战。因此，我们贡献了一种可扩展且抗数据泄露的框架，用于分离评估推理、检索和工具使用能力。我们的代码可以在以下链接获取：<代码链接> 

---
# Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization 

**Title (ZH)**: 法律知识与AI融合：基于向量存储、知识图谱和分层非负矩阵分解的检索增强生成方法 

**Authors**: Ryan C. Barron, Maksim E. Eren, Olga M. Serafimova, Cynthia Matuszek, Boian S. Alexandrov  

**Link**: [PDF](https://arxiv.org/pdf/2502.20364)  

**Abstract**: Agentic Generative AI, powered by Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG), Knowledge Graphs (KGs), and Vector Stores (VSs), represents a transformative technology applicable to specialized domains such as legal systems, research, recommender systems, cybersecurity, and global security, including proliferation research. This technology excels at inferring relationships within vast unstructured or semi-structured datasets. The legal domain here comprises complex data characterized by extensive, interrelated, and semi-structured knowledge systems with complex relations. It comprises constitutions, statutes, regulations, and case law. Extracting insights and navigating the intricate networks of legal documents and their relations is crucial for effective legal research. Here, we introduce a generative AI system that integrates RAG, VS, and KG, constructed via Non-Negative Matrix Factorization (NMF), to enhance legal information retrieval and AI reasoning and minimize hallucinations. In the legal system, these technologies empower AI agents to identify and analyze complex connections among cases, statutes, and legal precedents, uncovering hidden relationships and predicting legal trends-challenging tasks that are essential for ensuring justice and improving operational efficiency. Our system employs web scraping techniques to systematically collect legal texts, such as statutes, constitutional provisions, and case law, from publicly accessible platforms like Justia. It bridges the gap between traditional keyword-based searches and contextual understanding by leveraging advanced semantic representations, hierarchical relationships, and latent topic discovery. This framework supports legal document clustering, summarization, and cross-referencing, for scalable, interpretable, and accurate retrieval for semi-structured data while advancing computational law and AI. 

**Abstract (ZH)**: 受大型语言模型（LLMs）驱动的代理生成AI，通过检索增强生成（RAG）、知识图谱（KGs）和向量存储（VSs）技术，代表了一种变革性的技术，适用于法律系统、研究、推荐系统、网络安全以及全球安全领域，包括防扩散研究。该技术在推导 vast 的非结构化或半结构化数据集中的关系方面表现出色。这里的法律领域包含具有复杂关系的复杂数据，这些数据展现了广泛的、相互关联的和半结构化的知识系统。这些数据包括宪法、法规、规章和判例法。从复杂的法律文件及其关系中提取洞察并导航其复杂的网络是有效进行法律研究的关键。在此，我们介绍了一个集成了RAG、VS和通过非负矩阵分解（NMF）构建的KG的生成AI系统，以增强法律信息检索和AI推理能力，同时减少幻觉现象。在法律系统中，这些技术使AI代理能够识别和分析案例、法规和法律先例之间的复杂联系，揭示隐藏的关系并预测法律趋势，这些都是确保公正性和提高操作效率的关键挑战。我们的系统使用网页抓取技术系统地收集法律文本，如法规、宪法条款和判例法，来源于诸如Justia等公共可访问平台。它通过利用高级语义表示、层次关系和潜在主题发现，缓解了传统关键词搜索与上下文理解之间的差距。该框架支持法律文件聚类、总结和跨引用，从而实现半结构化数据的大规模、可解释和准确的检索，同时推动计算法学和人工智能的发展。 

---
# Bridging the Creativity Understanding Gap: Small-Scale Human Alignment Enables Expert-Level Humor Ranking in LLMs 

**Title (ZH)**: 弥合创造力理解差距：小型规模的人类对齐使大语言模型在幽默排序方面的水平达到专家级别 

**Authors**: Kuan Lok Zhou, Jiayi Chen, Siddharth Suresh, Reuben Narad, Timothy T. Rogers, Lalit K Jain, Robert D Nowak, Bob Mankoff, Jifan Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2502.20356)  

**Abstract**: Large Language Models (LLMs) have shown significant limitations in understanding creative content, as demonstrated by Hessel et al. (2023)'s influential work on the New Yorker Cartoon Caption Contest (NYCCC). Their study exposed a substantial gap between LLMs and humans in humor comprehension, establishing that understanding and evaluating creative content is key challenge in AI development. We revisit this challenge by decomposing humor understanding into three components and systematically improve each: enhancing visual understanding through improved annotation, utilizing LLM-generated humor reasoning and explanations, and implementing targeted alignment with human preference data. Our refined approach achieves 82.4% accuracy in caption ranking, singificantly improving upon the previous 67% benchmark and matching the performance of world-renowned human experts in this domain. Notably, while attempts to mimic subgroup preferences through various persona prompts showed minimal impact, model finetuning with crowd preferences proved remarkably effective. These findings reveal that LLM limitations in creative judgment can be effectively addressed through focused alignment to specific subgroups and individuals. Lastly, we propose the position that achieving artificial general intelligence necessitates systematic collection of human preference data across creative domains. We advocate that just as human creativity is deeply influenced by individual and cultural preferences, training LLMs with diverse human preference data may be essential for developing true creative understanding. 

**Abstract (ZH)**: 大规模语言模型（LLMs）在理解创造性内容方面显示出明显的局限性，这在Hessel等人（2023）对《纽约客》漫画标题比赛（NYCCC）的研究中得到了证实。他们的研究揭示了LLMs与人类在幽默理解方面存在显著差距，确立了理解和评估创造性内容是AI发展中面临的关键挑战。我们通过将幽默理解分解为三个组成部分，并系统地改进每一部分，重新审视了这一挑战：通过改进注释增强视觉理解，利用LLM生成的幽默推理和解释，以及实施针对人类偏好数据的定向对齐。我们的改进方法在标题排名中实现了82.4%的准确率，显著超越了之前的67%基准，并与该领域世界知名的人类专家的表现相匹敌。值得注意的是，通过各种人格提示模拟子群体偏好的尝试几乎未产生影响，而用民众偏好对模型进行微调则表现出显著的有效性。这些发现表明，通过针对特定子群和个体进行聚焦对齐，可以有效地解决LLMs在创造性判断方面的能力局限。最后，我们提出观点，要实现通用人工智能，需要系统地收集跨创造领域的个体偏好数据。我们认为，正如人类创造力深受个体和文化偏好的影响，用多元化的个体偏好数据训练LLM可能对于培养真正的创造性理解至关重要。 

---
# Naturalistic Computational Cognitive Science: Towards generalizable models and theories that capture the full range of natural behavior 

**Title (ZH)**: 自然主义计算认知科学：朝向能够捕捉自然行为完整范围的一般化模型和理论发展 

**Authors**: Wilka Carvalho, Andrew Lampinen  

**Link**: [PDF](https://arxiv.org/pdf/2502.20349)  

**Abstract**: Artificial Intelligence increasingly pursues large, complex models that perform many tasks within increasingly realistic domains. How, if at all, should these developments in AI influence cognitive science?
We argue that progress in AI offers timely opportunities for cognitive science to embrace experiments with increasingly naturalistic stimuli, tasks, and behaviors; and computational models that can accommodate these changes. We first review a growing body of research spanning neuroscience, cognitive science, and AI that suggests that incorporating a broader range of naturalistic experimental paradigms (and models that accommodate them) may be necessary to resolve some aspects of natural intelligence and ensure that our theories generalize. We then suggest that integrating recent progress in AI and cognitive science will enable us to engage with more naturalistic phenomena without giving up experimental control or the pursuit of theoretically grounded understanding. We offer practical guidance on how methodological practices can contribute to cumulative progress in naturalistic computational cognitive science, and illustrate a path towards building computational models that solve the real problems of natural cognition - together with a reductive understanding of the processes and principles by which they do so. 

**Abstract (ZH)**: 人工智能越来越多地追求大型、复杂的模型，这些模型在越来越具现实性的领域内执行多种任务。这些AI发展的进展在多大程度上应该影响认知科学？

我们认为，人工智能的进步为认知科学提供了及时的机会，可以采用更加自然主义的刺激、任务和行为；以及能够适应这些变化的计算模型。首先，我们回顾了神经科学、认知科学和人工智能领域快速增长的研究成果，这些研究成果表明，为了解决自然智能的某些方面问题并确保我们的理论能够泛化，可能需要纳入更广泛的自然主义实验范式（及其适应这些范式的模型）。然后，我们建议将最近在人工智能和认知科学方面的进展结合起来，将使我们可以研究更多自然主义的现象，同时仍保持实验控制和基于理论的理解。我们提供了一些实践指导，说明方法论实践如何促进自然主义计算认知科学的累计进展，并描绘了一条构建能够解决自然认知问题的计算模型的道路——同时对这些模型解决问题的过程和原则进行简约的理解。 

---
# Thinking Slow, Fast: Scaling Inference Compute with Distilled Reasoners 

**Title (ZH)**: 慢思快想：通过精练推理器扩展推理计算规模 

**Authors**: Daniele Paliotta, Junxiong Wang, Matteo Pagliardini, Kevin Y. Li, Aviv Bick, J. Zico Kolter, Albert Gu, François Fleuret, Tri Dao  

**Link**: [PDF](https://arxiv.org/pdf/2502.20339)  

**Abstract**: Recent advancements have demonstrated that the performance of large language models (LLMs) can be significantly enhanced by scaling computational resources at test time. A common strategy involves generating multiple Chain-of-Thought (CoT) trajectories and aggregating their outputs through various selection mechanisms. This raises a fundamental question: can models with lower complexity leverage their superior generation throughput to outperform similarly sized Transformers for a fixed computational budget? To address this question and overcome the lack of strong subquadratic reasoners, we distill pure and hybrid Mamba models from pretrained Transformers. Trained on only 8 billion tokens, our distilled models show strong performance and scaling on mathematical reasoning datasets while being much faster at inference for large batches and long sequences. Despite the zero-shot performance hit due to distillation, both pure and hybrid Mamba models can scale their coverage and accuracy performance past their Transformer teacher models under fixed time budgets, opening a new direction for scaling inference compute. 

**Abstract (ZH)**: 近期的研究表明，在测试时扩展计算资源可以显著提升大型语言模型（LLMs）的表现。一种常见策略是生成多个思维链（Chain-of-Thought, CoT）轨迹，并通过各种选择机制汇总其输出。这引发了一个基本问题：在固定计算预算下，复杂度较低的模型能否利用其更强的生成吞吐量超越同样大小的Transformer模型？为了回答这一问题并克服缺乏高性能的亚二次阶推理器，我们对预训练的Transformer进行了蒸馏，得到纯种和混合Mamba模型。这些模型仅在80亿个令牌上进行训练，显示出在数学推理数据集上的强大性能和扩展性，同时还能够在大型批次和长序列的推理中显著加快速度。尽管蒸馏导致了零样本性能的下降，但在固定时间预算下，纯种和混合Mamba模型能够扩展其覆盖范围和准确性，这为扩展推理计算开辟了新方向。 

---
# Expertise Is What We Want 

**Title (ZH)**: 专家知识正是我们所需要的 

**Authors**: Alan Ashworth, Munir Al-Dajani, Keegan Duchicela, Kiril Kafadarov, Allison Kurian, Othman Laraki, Amina Lazrak, Divneet Mandair, Wendy McKennon, Rebecca Miksad, Jayodita Sanghvi, Travis Zack  

**Link**: [PDF](https://arxiv.org/pdf/2502.20335)  

**Abstract**: Clinical decision-making depends on expert reasoning, which is guided by standardized, evidence-based guidelines. However, translating these guidelines into automated clinical decision support systems risks inaccuracy and importantly, loss of nuance. We share an application architecture, the Large Language Expert (LLE), that combines the flexibility and power of Large Language Models (LLMs) with the interpretability, explainability, and reliability of Expert Systems. LLMs help address key challenges of Expert Systems, such as integrating and codifying knowledge, and data normalization. Conversely, an Expert System-like approach helps overcome challenges with LLMs, including hallucinations, atomic and inexpensive updates, and testability.
To highlight the power of the Large Language Expert (LLE) system, we built an LLE to assist with the workup of patients newly diagnosed with cancer. Timely initiation of cancer treatment is critical for optimal patient outcomes. However, increasing complexity in diagnostic recommendations has made it difficult for primary care physicians to ensure their patients have completed the necessary workup before their first visit with an oncologist. As with many real-world clinical tasks, these workups require the analysis of unstructured health records and the application of nuanced clinical decision logic. In this study, we describe the design & evaluation of an LLE system built to rapidly identify and suggest the correct diagnostic workup. The system demonstrated a high degree of clinical-level accuracy (>95%) and effectively addressed gaps identified in real-world data from breast and colon cancer patients at a large academic center. 

**Abstract (ZH)**: 临床决策依赖于专家推理，而这种推理则由标准化和基于证据的指南指导。然而，将这些指南转化为自动化临床决策支持系统可能会引入不准确性和重要细节的丧失。本文介绍了一种应用架构——大型语言专家（LLE），该架构结合了大型语言模型（LLMs）的灵活性和强大功能与专家系统的可解释性、可解释性和可靠性。LLMs有助于解决专家系统的关键挑战，如知识整合与编码，以及数据规范。相反，专家系统的方法有助于克服大型语言模型的挑战，包括幻觉、原子级和低成本更新，以及测试性。

为凸显大型语言专家（LLE）系统的强大功能，我们构建了一个LLE系统，用于协助新诊断为癌症患者的诊疗工作。及时开始癌症治疗对于优化患者预后至关重要。然而，诊断建议不断增加的复杂性使得初级保健医生难以确保患者在首次与肿瘤科医生会面前完成了必要的诊疗工作。与许多实际临床任务类似，这些诊疗工作要求分析未结构化的医疗记录并应用复杂的临床决策逻辑。本研究描述了一个LLE系统的设计与评估，该系统能够迅速识别并建议正确的诊断工作。该系统展示了极高的临床准确度（>95%），并有效填补了大型学术中心乳腺癌和结肠癌患者在实际数据中发现的空白。 

---
# Emergent Symbolic Mechanisms Support Abstract Reasoning in Large Language Models 

**Title (ZH)**: 大型语言模型中 Emergent 符号机制支持抽象推理 

**Authors**: Yukang Yang, Declan Campbell, Kaixuan Huang, Mengdi Wang, Jonathan Cohen, Taylor Webb  

**Link**: [PDF](https://arxiv.org/pdf/2502.20332)  

**Abstract**: Many recent studies have found evidence for emergent reasoning capabilities in large language models, but debate persists concerning the robustness of these capabilities, and the extent to which they depend on structured reasoning mechanisms. To shed light on these issues, we perform a comprehensive study of the internal mechanisms that support abstract rule induction in an open-source language model (Llama3-70B). We identify an emergent symbolic architecture that implements abstract reasoning via a series of three computations. In early layers, symbol abstraction heads convert input tokens to abstract variables based on the relations between those tokens. In intermediate layers, symbolic induction heads perform sequence induction over these abstract variables. Finally, in later layers, retrieval heads predict the next token by retrieving the value associated with the predicted abstract variable. These results point toward a resolution of the longstanding debate between symbolic and neural network approaches, suggesting that emergent reasoning in neural networks depends on the emergence of symbolic mechanisms. 

**Abstract (ZH)**: 许多近期的研究发现了大型语言模型中涌现推理能力的证据，但这些能力的稳健性以及它们依赖于结构化推理机制的程度仍然存在争议。为了澄清这些问题，我们对一个开源语言模型（Llama3-70B）支持抽象规则归纳的内部机制进行了全面研究。我们确定了一种涌现的符号架构，该架构通过一系列三个计算过程来实现抽象推理。在早期层中，符号抽象头将输入标记转换为基于这些标记间关系的抽象变量。在中间层中，符号归纳头在这些抽象变量上进行序列归纳。最后，在较晚的层中，检索头通过检索预测的抽象变量关联的值来预测下一个标记。这些结果为符号方法与神经网络方法之间的长期争论提供了可能的解决方案，表明神经网络中的涌现推理依赖于符号机制的出现。 

---
# Deep Reinforcement Learning based Autonomous Decision-Making for Cooperative UAVs: A Search and Rescue Real World Application 

**Title (ZH)**: 基于深度强化学习的自主决策方法在协作无人机搜救应用中的研究 

**Authors**: Thomas Hickling, Maxwell Hogan, Abdulla Tammam, Nabil Aouf  

**Link**: [PDF](https://arxiv.org/pdf/2502.20326)  

**Abstract**: This paper proposes a holistic framework for autonomous guidance, navigation, and task distribution among multi-drone systems operating in Global Navigation Satellite System (GNSS)-denied indoor settings. We advocate for a Deep Reinforcement Learning (DRL)-based guidance mechanism, utilising the Twin Delayed Deep Deterministic Policy Gradient algorithm. To improve the efficiency of the training process, we incorporate an Artificial Potential Field (APF)-based reward structure, enabling the agent to refine its movements, thereby promoting smoother paths and enhanced obstacle avoidance in indoor contexts. Furthermore, we tackle the issue of task distribution among cooperative UAVs through a DRL-trained Graph Convolutional Network (GCN). This GCN represents the interactions between drones and tasks, facilitating dynamic and real-time task allocation that reflects the current environmental conditions and the capabilities of the drones. Such an approach fosters effective coordination and collaboration among multiple drones during search and rescue operations or other exploratory endeavours. Lastly, to ensure precise odometry in environments lacking GNSS, we employ Light Detection And Ranging Simultaneous Localisation and Mapping complemented by a depth camera to mitigate the hallway problem. This integration offers robust localisation and mapping functionalities, thereby enhancing the systems dependability in indoor navigation. The proposed multi-drone framework not only elevates individual navigation capabilities but also optimises coordinated task allocation in complex, obstacle-laden environments. Experimental evaluations conducted in a setup tailored to meet the requirements of the NATO Sapience Autonomous Cooperative Drone Competition demonstrate the efficacy of the proposed system, yielding outstanding results and culminating in a first-place finish in the 2024 Sapience competition. 

**Abstract (ZH)**: 本文提出了一种整体框架，用于在拒绝全球导航卫星系统（GNSS）的室内环境中进行多无人机系统的自主导航、制导和任务分配。我们主张采用基于深度强化学习（DRL）的制导机制，并利用双延迟深度确定性策略梯度（TD3）算法。为了提高训练效率，我们引入了一种基于人工势场（APF）的奖励结构，使智能体能够优化其移动方式，从而在室内环境中促进更平滑的路径和更有效的障碍物规避。此外，我们通过基于DRL训练的图卷积网络（GCN）来解决协作无人机间任务分配的问题。此GCN表示无人机与任务之间的交互关系，从而实现动态和实时的任务分配，反映当前的环境状况和无人机的能力。这种方法在搜索与救援等探索性任务中促进了多无人机之间的有效协调与合作。最后，为了在没有GNSS信号的环境中确保精确的里程计，我们采用了结合深度相机的激光探测与测距（LIDAR）同步定位与地图构建（SLAM），以解决走廊问题。这种集成提供了稳健的定位与绘图功能，从而提高了系统在室内导航中的可靠性。所提出的多无人机框架不仅提升了个体的导航能力，还优化了复杂、障碍多的环境中的协作任务分配。在专门为符合北约Sapience自主协同无人机比赛要求的情境下进行的实验评估证明了所提系统的有效性，取得了优秀的结果，并在2024年Sapience比赛中获得第一名。 

---
# UniTok: A Unified Tokenizer for Visual Generation and Understanding 

**Title (ZH)**: UniTok：统一的视觉生成与理解分词器 

**Authors**: Chuofan Ma, Yi Jiang, Junfeng Wu, Jihan Yang, Xin Yu, Zehuan Yuan, Bingyue Peng, Xiaojuan Qi  

**Link**: [PDF](https://arxiv.org/pdf/2502.20321)  

**Abstract**: The representation disparity between visual generation and understanding imposes a critical gap in integrating these capabilities into a single framework. To bridge this gap, we introduce UniTok, a discrete visual tokenizer that encodes fine-grained details for generation while also capturing high-level semantics for understanding. Despite recent studies have shown that these objectives could induce loss conflicts in training, we reveal that the underlying bottleneck stems from limited representational capacity of discrete tokens. We address this by introducing multi-codebook quantization, which divides vector quantization with several independent sub-codebooks to expand the latent feature space, while avoiding training instability caused by overlarge codebooks. Our method significantly raises the upper limit of unified discrete tokenizers to match or even surpass domain-specific continuous tokenizers. For instance, UniTok achieves a remarkable rFID of 0.38 (versus 0.87 for SD-VAE) and a zero-shot accuracy of 78.6% (versus 76.2% for CLIP) on ImageNet. Our code is available at this https URL. 

**Abstract (ZH)**: 视觉生成与理解之间的表示差异在将这些能力整合到单一框架中时造成了一个关键的差距。为了弥合这一差距，我们提出了UniTok，这是一种离散视觉分词器，既可以编码生成所需的详细信息，又可以捕获理解所需的高层语义。尽管近期的研究表明这些目标在训练中可能会导致损失冲突，但我们发现根本的问题在于离散令牌的表示能力有限。为此，我们引入了多码本量化方法，通过将向量量化分成多个独立的子码本来扩展潜在特征空间，同时避免由于码本书过大而导致的训练不稳定问题。我们的方法显著提高了统一离散分词器的上限，使其能够匹配甚至超越领域特定的连续分词器。例如，UniTok在ImageNet上的rFID达到了0.38（而SD-VAE为0.87），零样本准确率为78.6%（而CLIP为76.2%）。我们的代码可以在以下链接获取：[该链接]。 

---
# Mixture of Structural-and-Textual Retrieval over Text-rich Graph Knowledge Bases 

**Title (ZH)**: 文本丰富的图知识库中的结构-text检索混合模型 

**Authors**: Yongjia Lei, Haoyu Han, Ryan A. Rossi, Franck Dernoncourt, Nedim Lipka, Mahantesh M Halappanavar, Jiliang Tang, Yu Wang  

**Link**: [PDF](https://arxiv.org/pdf/2502.20317)  

**Abstract**: Text-rich Graph Knowledge Bases (TG-KBs) have become increasingly crucial for answering queries by providing textual and structural knowledge. However, current retrieval methods often retrieve these two types of knowledge in isolation without considering their mutual reinforcement and some hybrid methods even bypass structural retrieval entirely after neighboring aggregation. To fill in this gap, we propose a Mixture of Structural-and-Textual Retrieval (MoR) to retrieve these two types of knowledge via a Planning-Reasoning-Organizing framework. In the Planning stage, MoR generates textual planning graphs delineating the logic for answering queries. Following planning graphs, in the Reasoning stage, MoR interweaves structural traversal and textual matching to obtain candidates from TG-KBs. In the Organizing stage, MoR further reranks fetched candidates based on their structural trajectory. Extensive experiments demonstrate the superiority of MoR in harmonizing structural and textual retrieval with insights, including uneven retrieving performance across different query logics and the benefits of integrating structural trajectories for candidate reranking. Our code is available at this https URL. 

**Abstract (ZH)**: 文本丰富的图知识库（TG-KBs）对于通过提供文本和结构化知识来回答查询变得越来越重要。然而，当前的检索方法通常将这两种类型的知识孤立地检索出来，而不考虑它们之间的互相强化。一些混合方法甚至在邻接聚合后完全跳过了结构化检索。为填补这一空白，我们提出了一个结构化和文本化检索混合的方法（Mixture of Structural-and-Textual Retrieval, MoR），通过计划-推理-组织框架来同时检索这两种类型的知识。在计划阶段，MoR生成文本化的计划图，阐明回答查询的逻辑。在推理阶段，MoR交织结构化遍历和文本匹配，从TG-KBs中获取候选对象。在组织阶段，MoR进一步根据其结构轨迹对获取的候选对象进行重新排序。 extensive实验表明，MoR在协调结构化和文本化检索方面具有优越性，包括不同查询逻辑间的检索性能差异以及结构化轨迹在候选对象重新排序中的益处。我们的代码已在此处提供：[链接地址]。 

---
# Multi-Scale Neighborhood Occupancy Masked Autoencoder for Self-Supervised Learning in LiDAR Point Clouds 

**Title (ZH)**: 多尺度邻域占有率掩蔽自动编码器在LiDAR点云中的自监督学习 

**Authors**: Mohamed Abdelsamad, Michael Ulrich, Claudius Gläser, Abhinav Valada  

**Link**: [PDF](https://arxiv.org/pdf/2502.20316)  

**Abstract**: Masked autoencoders (MAE) have shown tremendous potential for self-supervised learning (SSL) in vision and beyond. However, point clouds from LiDARs used in automated driving are particularly challenging for MAEs since large areas of the 3D volume are empty. Consequently, existing work suffers from leaking occupancy information into the decoder and has significant computational complexity, thereby limiting the SSL pre-training to only 2D bird's eye view encoders in practice. In this work, we propose the novel neighborhood occupancy MAE (NOMAE) that overcomes the aforementioned challenges by employing masked occupancy reconstruction only in the neighborhood of non-masked voxels. We incorporate voxel masking and occupancy reconstruction at multiple scales with our proposed hierarchical mask generation technique to capture features of objects of different sizes in the point cloud. NOMAEs are extremely flexible and can be directly employed for SSL in existing 3D architectures. We perform extensive evaluations on the nuScenes and Waymo Open datasets for the downstream perception tasks of semantic segmentation and 3D object detection, comparing with both discriminative and generative SSL methods. The results demonstrate that NOMAE sets the new state-of-the-art on multiple benchmarks for multiple point cloud perception tasks. 

**Abstract (ZH)**: 掩码自动编码器（MAE）在视觉领域的自监督学习（SSL）中展示了巨大的潜力，但在自动驾驶领域使用的LiDAR点云中，由于大量3D体积存在空洞区域，MAE的应用面临着特殊挑战。现有的工作容易泄露占据信息到解码器，并且计算复杂度较高，这在实际中限制了SSL预训练仅限于2D的鸟瞰视图编码器。在本工作中，我们提出了新的邻域占据MAE（NOMAE），通过仅在非掩码体素的邻域中进行掩码占据重建来克服上述挑战。我们提出了分层掩码生成技术，在多个尺度上集成体素掩码和占据重建，以捕捉点云中不同尺寸的物体特征。NOMAE非常灵活，并可以直接应用于现有的3D架构中的SSL。我们在nuScenes和Waymo Open数据集上进行了广泛的下游感知任务评估，包括语义分割和3D物体检测，与判别性和生成性SSL方法进行了比较。结果表明，NOMAE在多个点云感知任务基准上达到了新的最先进水平。 

---
# LangProBe: a Language Programs Benchmark 

**Title (ZH)**: LangProBe：语言程序基准测试 

**Authors**: Shangyin Tan, Lakshya A Agrawal, Arnav Singhvi, Liheng Lai, Michael J Ryan, Dan Klein, Omar Khattab, Koushik Sen, Matei Zaharia  

**Link**: [PDF](https://arxiv.org/pdf/2502.20315)  

**Abstract**: Composing language models (LMs) into multi-step language programs and automatically optimizing their modular prompts is now a mainstream paradigm for building AI systems, but the tradeoffs in this space have only scarcely been studied before. We introduce LangProBe, the first large-scale benchmark for evaluating the architectures and optimization strategies for language programs, with over 2000 combinations of tasks, architectures, optimizers, and choices of LMs. Using LangProBe, we are the first to study the impact of program architectures and optimizers (and their compositions together and with different models) on tradeoffs of quality and cost. We find that optimized language programs offer strong cost--quality Pareto improvement over raw calls to models, but simultaneously demonstrate that human judgment (or empirical decisions) about which compositions to pursue is still necessary for best performance. We will open source the code and evaluation data for LangProBe. 

**Abstract (ZH)**: 将以下论文内容或标题翻译成中文，同时确保符合学术规范：

将语言模型（LMs）组合成多步语言程序，并自动优化它们的模块化提示，现在已成为构建AI系统的主流范式。但在这一领域，关于其权衡的问题研究甚少。我们引入了LangProBe，这是首个用于评估语言程序架构和优化策略的大规模基准测试，其中包括超过2000种任务、架构、优化器和LM选择的组合。利用LangProBe，我们首次系统研究了程序架构和优化器（及其组合以及与不同模型的结合）对质量和成本权衡的影响。我们发现，优化后的语言程序相比直接调用模型的原始版本，在质量和成本之间提供了显著的帕累托改进，但同时也表明，仍有必要依靠人类判断（或实验性的决策）来确定最佳的组合方式，以获得最佳性能。我们将开源LangProBe的代码和评估数据。 

---
# M^3Builder: A Multi-Agent System for Automated Machine Learning in Medical Imaging 

**Title (ZH)**: M^3Builder：用于医学影像领域自动化机器学习的多代理系统 

**Authors**: Jinghao Feng, Qiaoyu Zheng, Chaoyi Wu, Ziheng Zhao, Ya Zhang, Yanfeng Wang, Weidi Xie  

**Link**: [PDF](https://arxiv.org/pdf/2502.20301)  

**Abstract**: Agentic AI systems have gained significant attention for their ability to autonomously perform complex tasks. However, their reliance on well-prepared tools limits their applicability in the medical domain, which requires to train specialized models. In this paper, we make three contributions: (i) We present M3Builder, a novel multi-agent system designed to automate machine learning (ML) in medical imaging. At its core, M3Builder employs four specialized agents that collaborate to tackle complex, multi-step medical ML workflows, from automated data processing and environment configuration to self-contained auto debugging and model training. These agents operate within a medical imaging ML workspace, a structured environment designed to provide agents with free-text descriptions of datasets, training codes, and interaction tools, enabling seamless communication and task execution. (ii) To evaluate progress in automated medical imaging ML, we propose M3Bench, a benchmark comprising four general tasks on 14 training datasets, across five anatomies and three imaging modalities, covering both 2D and 3D data. (iii) We experiment with seven state-of-the-art large language models serving as agent cores for our system, such as Claude series, GPT-4o, and DeepSeek-V3. Compared to existing ML agentic designs, M3Builder shows superior performance on completing ML tasks in medical imaging, achieving a 94.29% success rate using Claude-3.7-Sonnet as the agent core, showing huge potential towards fully automated machine learning in medical imaging. 

**Abstract (ZH)**: 代理型人工智能系统因其能够自主执行复杂任务而受到了广泛关注。然而，它们对外部准备好的工具的依赖限制了其在医学领域的应用，这需要对专门模型进行训练。在本文中，我们做出了三项贡献：（i）我们提出了 M3Builder，这是一种新颖的多代理系统，旨在自动化医学成像领域的机器学习（ML）。M3Builder的核心是四个专门设计的代理，它们协作处理复杂、多步骤的医学ML工作流，从自动数据处理和环境配置，到自我封闭的自动调试和模型训练。这些代理在医学成像ML工作区中运行，这是一种结构化的环境，为代理提供了关于数据集、训练代码和交互工具的文本描述，从而实现无缝的通信和任务执行。（ii）为了评估自动化医学成像ML的进步，我们提出了M3Bench这一基准测试，它包含四个一般任务，跨越十五个训练数据集、五种解剖结构和三种成像模态，涵盖了二维和三维数据。（iii）我们使用七种最先进的大型语言模型作为系统的核心代理，例如Claude系列、GPT-4o和DeepSeek-V3进行实验。与现有的ML代理设计相比，M3Builder在医学成像领域的机器学习任务上表现出更优异的表现，在使用Claude-3.7-Sonnet作为核心代理时，成功率达到94.29%，显示出在医学成像领域实现完全自动化机器学习的巨大潜力。 

---
# An exploration of features to improve the generalisability of fake news detection models 

**Title (ZH)**: 对提高虚假新闻检测模型普适性的特征进行探索 

**Authors**: Nathaniel Hoy, Theodora Koulouri  

**Link**: [PDF](https://arxiv.org/pdf/2502.20299)  

**Abstract**: Fake news poses global risks by influencing elections and spreading misinformation, making detection critical. Existing NLP and supervised Machine Learning methods perform well under cross-validation but struggle to generalise across datasets, even within the same domain. This issue stems from coarsely labelled training data, where articles are labelled based on their publisher, introducing biases that token-based models like TF-IDF and BERT are sensitive to. While Large Language Models (LLMs) offer promise, their application in fake news detection remains limited. This study demonstrates that meaningful features can still be extracted from coarsely labelled data to improve real-world robustness. Stylistic features-lexical, syntactic, and semantic-are explored due to their reduced sensitivity to dataset biases. Additionally, novel social-monetisation features are introduced, capturing economic incentives behind fake news, such as advertisements, external links, and social media elements. The study trains on the coarsely labelled NELA 2020-21 dataset and evaluates using the manually labelled Facebook URLs dataset, a gold standard for generalisability. Results highlight the limitations of token-based models trained on biased data and contribute to the scarce evidence on LLMs like LLaMa in this field. Findings indicate that stylistic and social-monetisation features offer more generalisable predictions than token-based methods and LLMs. Statistical and permutation feature importance analyses further reveal their potential to enhance performance and mitigate dataset biases, providing a path forward for improving fake news detection. 

**Abstract (ZH)**: 虚假信息对全球构成风险，通过影响选举和传播错误信息，因此检测至关重要。现有的自然语言处理（NLP）和有监督机器学习方法在交叉验证中表现良好，但在跨数据集推广时遇到困难，即使是同一领域内的数据集也是如此。这一问题源自粗糙标注的训练数据，其中文章是根据其出版商进行标注的，这引入了对基于标记的模型（如TF-IDF和BERT）敏感的偏差。尽管大型语言模型（LLMs）前景广阔，但在假新闻检测中的应用依然有限。本研究证明，仍可以从粗糙标注的数据中提取有意义的特征，以提高实际应用中的鲁棒性。研究探索了风格特征（词汇、句法和语义），这些特征对数据集偏差的敏感度较低。此外，还引入了新型社交媒体货币化特征，这些特征捕捉了假新闻背后的经济激励，如广告、外部链接和社会媒体元素。研究基于粗糙标注的NELA 2020-21数据集进行训练，并使用手工标注的Facebook网址数据集进行评估，后者是评估泛化能力的标准数据集。研究结果突显了基于标记模型训练偏差数据的局限性，并为LLM如LLaMa在这一领域的证据不足做出了贡献。研究结果表明，风格特征和社会货币化特征在泛化预测方面优于基于标记的方法和LLMs。统计学和置换特征重要性分析进一步表明，这些特征有潜力提高性能并减轻数据集偏差，为提高假新闻检测提供了一条前进的道路。 

---
# Judge a Book by its Cover: Investigating Multi-Modal LLMs for Multi-Page Handwritten Document Transcription 

**Title (ZH)**: 以貌取书：探究多模态大语言模型在多页手写文档转录中的应用 

**Authors**: Benjamin Gutteridge, Matthew Thomas Jackson, Toni Kukurin, Xiaowen Dong  

**Link**: [PDF](https://arxiv.org/pdf/2502.20295)  

**Abstract**: Handwritten text recognition (HTR) remains a challenging task, particularly for multi-page documents where pages share common formatting and contextual features. While modern optical character recognition (OCR) engines are proficient with printed text, their performance on handwriting is limited, often requiring costly labeled data for fine-tuning. In this paper, we explore the use of multi-modal large language models (MLLMs) for transcribing multi-page handwritten documents in a zero-shot setting. We investigate various configurations of commercial OCR engines and MLLMs, utilizing the latter both as end-to-end transcribers and as post-processors, with and without image components. We propose a novel method, '+first page', which enhances MLLM transcription by providing the OCR output of the entire document along with just the first page image. This approach leverages shared document features without incurring the high cost of processing all images. Experiments on a multi-page version of the IAM Handwriting Database demonstrate that '+first page' improves transcription accuracy, balances cost with performance, and even enhances results on out-of-sample text by extrapolating formatting and OCR error patterns from a single page. 

**Abstract (ZH)**: 手写文本识别（HTR）仍然是一个具有挑战性的任务，尤其是对于多页文档，在这些文档中，各页共享常见的格式和上下文特征。尽管现代光学字符识别（OCR）引擎在印刷文本方面表现出色，但在手写识别方面的能力却有限，通常需要高质量的标注数据进行微调，这往往成本高昂。在本文中，我们探讨了在零样本设置下使用多模式大型语言模型（MLLMs）来转录多页手写文档的可能性。我们研究了不同配置的商用OCR引擎和MLLMs，利用后者作为端到端的转录器或后处理器，有时甚至使用图像组件。我们提出了一种新颖的方法‘+第一页’，通过提供整文档的OCR输出以及仅第一页的图像来增强MLLM的转录效果。这种方法利用共享的文档特征，而无需处理所有图像的高成本。在IAM手写数据库的多页版本上的实验表明，‘+第一页’方法提高了转录准确性，平衡了成本与性能，并且甚至通过从单页中推断格式和OCR错误模式提高了不在样本中的文本转录效果。 

---
# Explainable, Multi-modal Wound Infection Classification from Images Augmented with Generated Captions 

**Title (ZH)**: 具备解释性的、多模态伤口感染分类：结合生成的描述图像 

**Authors**: Palawat Busaranuvong, Emmanuel Agu, Reza Saadati Fard, Deepak Kumar, Shefalika Gautam, Bengisu Tulu, Diane Strong  

**Link**: [PDF](https://arxiv.org/pdf/2502.20277)  

**Abstract**: Infections in Diabetic Foot Ulcers (DFUs) can cause severe complications, including tissue death and limb amputation, highlighting the need for accurate, timely diagnosis. Previous machine learning methods have focused on identifying infections by analyzing wound images alone, without utilizing additional metadata such as medical notes. In this study, we aim to improve infection detection by introducing Synthetic Caption Augmented Retrieval for Wound Infection Detection (SCARWID), a novel deep learning framework that leverages synthetic textual descriptions to augment DFU images. SCARWID consists of two components: (1) Wound-BLIP, a Vision-Language Model (VLM) fine-tuned on GPT-4o-generated descriptions to synthesize consistent captions from images; and (2) an Image-Text Fusion module that uses cross-attention to extract cross-modal embeddings from an image and its corresponding Wound-BLIP caption. Infection status is determined by retrieving the top-k similar items from a labeled support set. To enhance the diversity of training data, we utilized a latent diffusion model to generate additional wound images. As a result, SCARWID outperformed state-of-the-art models, achieving average sensitivity, specificity, and accuracy of 0.85, 0.78, and 0.81, respectively, for wound infection classification. Displaying the generated captions alongside the wound images and infection detection results enhances interpretability and trust, enabling nurses to align SCARWID outputs with their medical knowledge. This is particularly valuable when wound notes are unavailable or when assisting novice nurses who may find it difficult to identify visual attributes of wound infection. 

**Abstract (ZH)**: 糖尿病足溃疡（DFUs）感染可能导致严重并发症，包括组织坏死和截肢，凸显了准确、及时诊断的必要性。以往的机器学习方法主要依赖于分析伤口图像来识别感染，而未利用附加的元数据，如医疗笔记。在本研究中，我们旨在通过引入合成描述增强检索以检测伤口感染（SCARWID）这一新颖的深度学习框架来改进感染的检测。SCARWID包含两个组成部分：（1）伤口-BLIP，一种基于GPT-4o生成的描述对图像进行微调的视觉-语言模型（VLM），用于从图像中合成一致的描述；（2）图像-文本融合模块，该模块利用交叉注意机制从图像及其对应的伤口-BLIP描述中提取跨模态嵌入。感染状态通过从标记的支持集中检索最相似项来确定。为了增强训练数据的多样性，我们利用潜在扩散模型生成额外的伤口图像。结果表明，SCARWID超越了最先进的模型，分别在伤口感染分类中的平均敏感性、特异性和准确率达到了85%、78%和81%。将生成的描述与伤口图像和感染检测结果一起显示，能够增强解释性和可信度，使护士能够将SCARWID的输出与医学知识对接。特别是在伤口记录不可用或帮助识别伤口感染的视觉特征存在困难的初学者护士时，这一点尤为重要。 

---
# HVI: A New color space for Low-light Image Enhancement 

**Title (ZH)**: HVI：一种新的低光照图像增强颜色空间 

**Authors**: Qingsen Yan, Yixu Feng, Cheng Zhang, Guansong Pang, Kangbiao Shi, Peng Wu, Wei Dong, Jinqiu Sun, Yanning Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2502.20272)  

**Abstract**: Low-Light Image Enhancement (LLIE) is a crucial computer vision task that aims to restore detailed visual information from corrupted low-light images. Many existing LLIE methods are based on standard RGB (sRGB) space, which often produce color bias and brightness artifacts due to inherent high color sensitivity in sRGB. While converting the images using Hue, Saturation and Value (HSV) color space helps resolve the brightness issue, it introduces significant red and black noise artifacts. To address this issue, we propose a new color space for LLIE, namely Horizontal/Vertical-Intensity (HVI), defined by polarized HS maps and learnable intensity. The former enforces small distances for red coordinates to remove the red artifacts, while the latter compresses the low-light regions to remove the black artifacts. To fully leverage the chromatic and intensity information, a novel Color and Intensity Decoupling Network (CIDNet) is further introduced to learn accurate photometric mapping function under different lighting conditions in the HVI space. Comprehensive results from benchmark and ablation experiments show that the proposed HVI color space with CIDNet outperforms the state-of-the-art methods on 10 datasets. The code is available at this https URL. 

**Abstract (ZH)**: 低光照图像增强（LLIE）是计算机视觉中的一个关键任务，旨在从受损的低光照图像中恢复详细的视觉信息。许多现有的LLIE方法基于标准RGB（sRGB）空间，由于其固有的高色彩敏感性，常会产生颜色偏差和亮度伪影。虽然通过将图像转换到色调、饱和度和亮度（HSV）色彩空间可以解决亮度问题，但会引入显著的红噪和黑斑噪声伪影。为了解决这一问题，我们提出了一种新的LLIE色彩空间，即水平/垂直-亮度（HVI），由极化HS图和可学习的亮度定义。前者通过限制红色坐标间的距离来去除红噪，后者压缩低光照区域以去除黑斑噪声。为了充分利用色调和亮度信息，我们进一步引入了一种新颖的颜色和亮度解耦网络（CIDNet），以在HVI空间的不同光照条件下学习准确的光度映射函数。基准实验和消融实验的综合结果显示，提出的HVI色彩空间结合CIDNet在10个数据集上的性能优于现有最先进的方法。相关代码可在以下链接获得：这个 https URL。 

---
# Large Language Models as Attribution Regularizers for Efficient Model Training 

**Title (ZH)**: 大规模语言模型作为高效模型训练的归因正则化器 

**Authors**: Davor Vukadin, Marin Šilić, Goran Delač  

**Link**: [PDF](https://arxiv.org/pdf/2502.20268)  

**Abstract**: Large Language Models (LLMs) have demonstrated remarkable performance across diverse domains. However, effectively leveraging their vast knowledge for training smaller downstream models remains an open challenge, especially in domains like tabular data learning, where simpler models are often preferred due to interpretability and efficiency.
In this paper, we introduce a novel yet straightforward method for incorporating LLM-generated global task feature attributions into the training process of smaller networks. Specifically, we propose an attribution-matching regularization term that aligns the training dynamics of the smaller model with the insights provided by the LLM. By doing so, our approach yields superior performance in few-shot learning scenarios. Notably, our method requires only black-box API access to the LLM, making it easy to integrate into existing training pipelines with minimal computational overhead.
Furthermore, we demonstrate how this method can be used to address common issues in real-world datasets, such as skewness and bias. By integrating high-level knowledge from LLMs, our approach improves generalization, even when training data is limited or imbalanced. We validate its effectiveness through extensive experiments across multiple tasks, demonstrating improved learning efficiency and model robustness. 

**Abstract (ZH)**: 大规模语言模型（LLMs）在不同领域中展示了卓越的表现。然而，有效利用它们丰富的知识来训练较小的下游模型仍然是一个开放的挑战，尤其是在表格数据学习等领域中，人们往往更倾向于使用更简单的模型，因为这些模型具有更高的可解释性和效率。
在本文中，我们介绍了一种新颖且简单的方法，通过将LLM生成的全局任务特征归因融入较小网络的训练过程中。具体而言，我们提出了一种归因匹配正则化项，该项将较小模型的训练动态与LLM提供的见解对齐。通过这种方式，我们的方法在少样本学习场景中表现出更优的效果。值得注意的是，我们的方法只需要黑盒API访问LLM，这使得它能够轻松地与现有的训练管道集成，并且具有最小的计算开销。
此外，我们展示了这种方法如何用于解决实际数据集中常见的问题，如分布偏斜和偏差。通过整合来自LLM的高层次知识，我们的方法即使在训练数据有限或不平衡时，也能提高泛化能力。我们通过在多个任务上进行广泛实验验证了其有效性，证明了其改进的学习效率和模型鲁棒性。 

---
# LLM as a Broken Telephone: Iterative Generation Distorts Information 

**Title (ZH)**: LLM 作为broken telephone效应：迭代生成扭曲信息

注释：这里的“broken telephone”通常被解释为“电话 Ginsberg 效应”，指的是信息在传递过程中逐级扭曲的现象。在学术翻译中，直接翻译为“broken telephone效应”是比较符合中文表达习惯和学术规范的。 

**Authors**: Amr Mohamed, Mingmeng Geng, Michalis Vazirgiannis, Guokan Shang  

**Link**: [PDF](https://arxiv.org/pdf/2502.20258)  

**Abstract**: As large language models are increasingly responsible for online content, concerns arise about the impact of repeatedly processing their own outputs. Inspired by the "broken telephone" effect in chained human communication, this study investigates whether LLMs similarly distort information through iterative generation. Through translation-based experiments, we find that distortion accumulates over time, influenced by language choice and chain complexity. While degradation is inevitable, it can be mitigated through strategic prompting techniques. These findings contribute to discussions on the long-term effects of AI-mediated information propagation, raising important questions about the reliability of LLM-generated content in iterative workflows. 

**Abstract (ZH)**: 随着大型语言模型在在线内容生成中扮演越来越重要的角色，人们开始关注反复处理其自身输出可能产生的影响。受到“密室传递”这一链式人与人交互效应的启发，本研究探讨大型语言模型在迭代生成过程中是否也会扭曲信息。通过基于翻译的实验，我们发现随着时间的推移，信息的扭曲会累积，这受语言选择和链式复杂性的影响。虽然信息质量的下降不可避免，但可以通过策略性的提示技术来减轻这种影响。这些发现为讨论AI中介信息传播的长期效应提供了贡献，并引发了关于语言模型生成内容在迭代工作流程中的可靠性的重要问题。 

---
# Teasing Apart Architecture and Initial Weights as Sources of Inductive Bias in Neural Networks 

**Title (ZH)**: 解开架构与初始权重作为神经网络归约偏见来源的区分 

**Authors**: Gianluca Bencomo, Max Gupta, Ioana Marinescu, R. Thomas McCoy, Thomas L. Griffiths  

**Link**: [PDF](https://arxiv.org/pdf/2502.20237)  

**Abstract**: Artificial neural networks can acquire many aspects of human knowledge from data, making them promising as models of human learning. But what those networks can learn depends upon their inductive biases -- the factors other than the data that influence the solutions they discover -- and the inductive biases of neural networks remain poorly understood, limiting our ability to draw conclusions about human learning from the performance of these systems. Cognitive scientists and machine learning researchers often focus on the architecture of a neural network as a source of inductive bias. In this paper we explore the impact of another source of inductive bias -- the initial weights of the network -- using meta-learning as a tool for finding initial weights that are adapted for specific problems. We evaluate four widely-used architectures -- MLPs, CNNs, LSTMs, and Transformers -- by meta-training 430 different models across three tasks requiring different biases and forms of generalization. We find that meta-learning can substantially reduce or entirely eliminate performance differences across architectures and data representations, suggesting that these factors may be less important as sources of inductive bias than is typically assumed. When differences are present, architectures and data representations that perform well without meta-learning tend to meta-train more effectively. Moreover, all architectures generalize poorly on problems that are far from their meta-training experience, underscoring the need for stronger inductive biases for robust generalization. 

**Abstract (ZH)**: 人工神经网络可以从数据中获得许多人类知识，因此它们有望成为人类学习的模型。但是，这些网络所学到的内容取决于它们的归纳偏置——即除了数据以外影响它们发现解的问题因素——而神经网络的归纳偏置仍未被充分理解，限制了我们从这些系统的性能中推断出人类学习结论的能力。认知科学家和机器学习研究者通常将神经网络的架构作为一种归纳偏置来源。本文通过使用元学习作为工具，探讨了另一种归纳偏置来源——网络的初始权重——的影响。我们通过在三个需要不同偏置和泛化的任务上对430种不同模型进行元训练，评估了四种广泛使用的架构——多层感知机（MLPs）、卷积神经网络（CNNs）、长短期记忆网络（LSTMs）和变压器（Transformers）。我们发现，通过元学习可以显著减少或完全消除不同架构和数据表示之间的性能差异，这表明这些因素可能不像通常认为的那样是归纳偏置的重要来源。当存在差异时，即使没有元学习也能表现出色的架构和数据表示更倾向于更有效地通过元学习进行训练。此外，所有架构在远离其元训练经验的问题上泛化能力较差，这强调了为了实现稳健泛化，需要更强的归纳偏置。 

---
# Selective Use of Yannakakis' Algorithm to Improve Query Performance: Machine Learning to the Rescue 

**Title (ZH)**: 利用Yannakakis算法的选择性应用以提高查询性能：机器学习来助力 

**Authors**: Daniela Böhm, Georg Gottlob, Matthias Lanzinger, Davide Longo, Cem Okulmus, Reinhard Pichler, Alexander Selzer  

**Link**: [PDF](https://arxiv.org/pdf/2502.20233)  

**Abstract**: Query optimization has played a central role in database research for decades. However, more often than not, the proposed optimization techniques lead to a performance improvement in some, but not in all, situations. Therefore, we urgently need a methodology for designing a decision procedure that decides for a given query whether the optimization technique should be applied or not.
In this work, we propose such a methodology with a focus on Yannakakis-style query evaluation as our optimization technique of interest. More specifically, we formulate this decision problem as an algorithm selection problem and we present a Machine Learning based approach for its solution. Empirical results with several benchmarks on a variety of database systems show that our approach indeed leads to a statistically significant performance improvement. 

**Abstract (ZH)**: 查询优化在数据库研究中占据了数十年的核心地位。然而，通常提出的优化技术仅在某些情况下而非所有情况下能够提高性能。因此，我们需要一种方法学来设计一个决策过程，以决定给定的查询是否应应用优化技术。
在本文中，我们提出了一种以Yannakakis风格的查询评估作为我们感兴趣的优化技术的方法学。更具体地，我们将这一决策问题表述为算法选择问题，并提出了一种基于机器学习的方法来解决这个问题。在多种数据库系统上的多个基准测试中，我们的方法确实展示了统计上显著的性能提升。 

---
# RURANET++: An Unsupervised Learning Method for Diabetic Macular Edema Based on SCSE Attention Mechanisms and Dynamic Multi-Projection Head Clustering 

**Title (ZH)**: RURANET++：基于SCSE注意力机制和动态多投影头聚类的无监督学习方法用于糖尿病黄斑水肿 

**Authors**: Wei Yang, Yiran Zhu, Jiayu Shen, Yuhan Tang, Chengchang Pan, Hui He, Yan Su, Honggang Qi  

**Link**: [PDF](https://arxiv.org/pdf/2502.20224)  

**Abstract**: Diabetic Macular Edema (DME), a prevalent complication among diabetic patients, constitutes a major cause of visual impairment and blindness. Although deep learning has achieved remarkable progress in medical image analysis, traditional DME diagnosis still relies on extensive annotated data and subjective ophthalmologist assessments, limiting practical applications. To address this, we present RURANET++, an unsupervised learning-based automated DME diagnostic system. This framework incorporates an optimized U-Net architecture with embedded Spatial and Channel Squeeze & Excitation (SCSE) attention mechanisms to enhance lesion feature extraction. During feature processing, a pre-trained GoogLeNet model extracts deep features from retinal images, followed by PCA-based dimensionality reduction to 50 dimensions for computational efficiency. Notably, we introduce a novel clustering algorithm employing multi-projection heads to explicitly control cluster diversity while dynamically adjusting similarity thresholds, thereby optimizing intra-class consistency and inter-class discrimination. Experimental results demonstrate superior performance across multiple metrics, achieving maximum accuracy (0.8411), precision (0.8593), recall (0.8411), and F1-score (0.8390), with exceptional clustering quality. This work provides an efficient unsupervised solution for DME diagnosis with significant clinical implications. 

**Abstract (ZH)**: 糖尿病黄斑水肿（DME），是糖尿病患者中常见的一种并发症，是导致视力下降和失明的主要原因之一。尽管深度学习在医学图像分析方面取得了显著的进步，但传统的DME诊断仍然依赖于大量标注数据和眼科医生的主观评估，限制了其实用应用。为此，我们提出了一种基于无监督学习的自动化DME诊断系统RURANET++。该框架采用了优化的U-Net架构，并嵌入了空间和通道挤压与激励（SCSE）注意力机制，以增强病灶特征的提取。在特征处理过程中，采用预训练的GoogLeNet模型从视网膜图像中提取深层特征，然后通过主成分分析（PCA）进行维数降维至50维，以提高计算效率。特别地，我们引入了一种新颖的聚类算法，采用多投影头以显式地控制聚类多样性，并动态调整相似性阈值，从而优化了类内一致性并增强了类间区分度。实验结果表明，该方法在多个指标上表现出色，实现了最高准确率（0.8411）、精确率（0.8593）、召回率（0.8411）和F1评分（0.8390），聚类质量尤为突出。本研究为DME诊断提供了一种高效且无监督的解决方案，具有重要的临床意义。 

---
# Deep Convolutional Neural Networks for Palm Fruit Maturity Classification 

**Title (ZH)**: 深度卷积神经网络在棕榈果实成熟度分类中的应用 

**Authors**: Mingqiang Han, Chunlin Yi  

**Link**: [PDF](https://arxiv.org/pdf/2502.20223)  

**Abstract**: To maximize palm oil yield and quality, it is essential to harvest palm fruit at the optimal maturity stage. This project aims to develop an automated computer vision system capable of accurately classifying palm fruit images into five ripeness levels. We employ deep Convolutional Neural Networks (CNNs) to classify palm fruit images based on their maturity stage. A shallow CNN serves as the baseline model, while transfer learning and fine-tuning are applied to pre-trained ResNet50 and InceptionV3 architectures. The study utilizes a publicly available dataset of over 8,000 images with significant variations, which is split into 80\% for training and 20\% for testing. The proposed deep CNN models achieve test accuracies exceeding 85\% in classifying palm fruit maturity stages. This research highlights the potential of deep learning for automating palm fruit ripeness assessment, which can contribute to optimizing harvesting decisions and improving palm oil production efficiency. 

**Abstract (ZH)**: 为了最大化棕榈油产量和质量，必须在最佳成熟阶段采摘棕榈果。本项目旨在开发一个自动化计算机视觉系统，能够准确将棕榈果图像分类为五个成熟等级。我们采用深度卷积神经网络（CNNs）根据棕榈果的成熟阶段对棕榈果图像进行分类。浅层CNN作为基线模型，而预训练的ResNet50和InceptionV3架构则通过迁移学习和微调进行改进。研究使用一个包含超过8,000张具有显著差异的公开数据集，并将数据集分为80%用于训练和20%用于测试。所提出的深度CNN模型在分类棕榈果成熟阶段方面的测试准确率超过85%。本研究突显了深度学习在自动化棕榈果成熟度评估方面的潜力，这可以有助于优化采摘决策并提高棕榈油生产效率。 

---
# DIPSER: A Dataset for In-Person Student1 Engagement Recognition in the Wild 

**Title (ZH)**: DIPSER：野生场景中在校学生参与度识别的数据集 

**Authors**: Luis Marquez-Carpintero, Sergio Suescun-Ferrandiz, Carolina Lorenzo Álvarez, Jorge Fernandez-Herrero, Diego Viejo, Rosabel Roig-Vila, Miguel Cazorla  

**Link**: [PDF](https://arxiv.org/pdf/2502.20209)  

**Abstract**: In this paper, a novel dataset is introduced, designed to assess student attention within in-person classroom settings. This dataset encompasses RGB camera data, featuring multiple cameras per student to capture both posture and facial expressions, in addition to smartwatch sensor data for each individual. This dataset allows machine learning algorithms to be trained to predict attention and correlate it with emotion. A comprehensive suite of attention and emotion labels for each student is provided, generated through self-reporting as well as evaluations by four different experts. Our dataset uniquely combines facial and environmental camera data, smartwatch metrics, and includes underrepresented ethnicities in similar datasets, all within in-the-wild, in-person settings, making it the most comprehensive dataset of its kind currently available.
The dataset presented offers an extensive and diverse collection of data pertaining to student interactions across different educational contexts, augmented with additional metadata from other tools. This initiative addresses existing deficiencies by offering a valuable resource for the analysis of student attention and emotion in face-to-face lessons. 

**Abstract (ZH)**: 在本文中，我们引入了一个新的数据集，旨在评估面对面教室环境中的学生注意力。该数据集包含RGB摄像头数据，每名学生配备多个摄像头以捕捉姿势和面部表情，同时还包括每位个体的智能手表传感器数据。该数据集允许机器学习算法的训练，以预测注意力并将其与情绪相关联。每位学生都提供了全面的注意力和情绪标签，这些标签通过自我报告及四位专家的评估产生。我们的数据集独特地结合了面部和环境摄像头数据、智能手表指标，并且包括了相似数据集中未被充分代表的族裔群体，所有这些都处于真实世界中的面对面环境中，使其成为目前此类数据集中最全面的一个。

该数据集提供了一个广泛而多样的学生交互数据集，涵盖了不同教育环境下的交互信息，并附加了其他工具提供的元数据。此项目通过提供一个宝贵的资源来弥补现有研究中的不足，以便分析面对面课程中学生注意力和情绪。 

---
# Highly Parallelized Reinforcement Learning Training with Relaxed Assignment Dependencies 

**Title (ZH)**: 高并行化的强化学习训练与宽松的任务依赖关系 

**Authors**: Zhouyu He, Peng Qiao, Rongchun Li, Yong Dou, Yusong Tan  

**Link**: [PDF](https://arxiv.org/pdf/2502.20190)  

**Abstract**: As the demands for superior agents grow, the training complexity of Deep Reinforcement Learning (DRL) becomes higher. Thus, accelerating training of DRL has become a major research focus. Dividing the DRL training process into subtasks and using parallel computation can effectively reduce training costs. However, current DRL training systems lack sufficient parallelization due to data assignment between subtask components. This assignment issue has been ignored, but addressing it can further boost training efficiency. Therefore, we propose a high-throughput distributed RL training system called TianJi. It relaxes assignment dependencies between subtask components and enables event-driven asynchronous communication. Meanwhile, TianJi maintains clear boundaries between subtask components. To address convergence uncertainty from relaxed assignment dependencies, TianJi proposes a distributed strategy based on the balance of sample production and consumption. The strategy controls the staleness of samples to correct their quality, ensuring convergence. We conducted extensive experiments. TianJi achieves a convergence time acceleration ratio of up to 4.37 compared to related comparison systems. When scaled to eight computational nodes, TianJi shows a convergence time speedup of 1.6 and a throughput speedup of 7.13 relative to XingTian, demonstrating its capability to accelerate training and scalability. In data transmission efficiency experiments, TianJi significantly outperforms other systems, approaching hardware limits. TianJi also shows effectiveness in on-policy algorithms, achieving convergence time acceleration ratios of 4.36 and 2.95 compared to RLlib and XingTian. TianJi is accessible at this https URL. 

**Abstract (ZH)**: 随着对更优秀代理的需求增加，深度强化学习（DRL）的训练复杂性也随之提高。因此，加速DRL的训练已成为主要研究方向。将DRL训练过程分解为子任务并利用并行计算可以有效降低训练成本。然而，当前的DRL训练系统由于子任务组件之间的数据分配不足，缺乏充分的并行化。这一分配问题已经被忽视，但解决这个问题可以进一步提升训练效率。因此，我们提出了一种高吞吐量的分布式强化学习训练系统——天机（TianJi）。该系统放松了子任务组件之间的数据分配依赖，并支持事件驱动的异步通信。同时，天机保持子任务组件之间的清晰边界。为了解决放松数据分配依赖带来的收敛不确定性，天机提出了一种基于样本生产和消费平衡的分布式策略。该策略控制样本的陈旧度，以纠正其质量，确保收敛。我们进行了广泛实验。相比相关比较系统，天机将收敛时间加速比提高到4.37。在扩展到八台计算节点时，与星天（XingTian）相比，天机的收敛时间加速比为1.6，吞吐量加速比为7.13，展示了其加速训练和扩展能力。在数据传输效率实验中，天机显著优于其他系统，接近硬件极限。天机在使用策略上的算法上也表现出有效性，相比RLlib和星天，其收敛时间加速比分别为4.36和2.95。天机的源代码可通过以下链接访问：[这里](提供链接)。 

---
# Accelerating Model-Based Reinforcement Learning with State-Space World Models 

**Title (ZH)**: 基于状态空间世界模型加速模型导向强化学习 

**Authors**: Maria Krinner, Elie Aljalbout, Angel Romero, Davide Scaramuzza  

**Link**: [PDF](https://arxiv.org/pdf/2502.20168)  

**Abstract**: Reinforcement learning (RL) is a powerful approach for robot learning. However, model-free RL (MFRL) requires a large number of environment interactions to learn successful control policies. This is due to the noisy RL training updates and the complexity of robotic systems, which typically involve highly non-linear dynamics and noisy sensor signals. In contrast, model-based RL (MBRL) not only trains a policy but simultaneously learns a world model that captures the environment's dynamics and rewards. The world model can either be used for planning, for data collection, or to provide first-order policy gradients for training. Leveraging a world model significantly improves sample efficiency compared to model-free RL. However, training a world model alongside the policy increases the computational complexity, leading to longer training times that are often intractable for complex real-world scenarios. In this work, we propose a new method for accelerating model-based RL using state-space world models. Our approach leverages state-space models (SSMs) to parallelize the training of the dynamics model, which is typically the main computational bottleneck. Additionally, we propose an architecture that provides privileged information to the world model during training, which is particularly relevant for partially observable environments. We evaluate our method in several real-world agile quadrotor flight tasks, involving complex dynamics, for both fully and partially observable environments. We demonstrate a significant speedup, reducing the world model training time by up to 10 times, and the overall MBRL training time by up to 4 times. This benefit comes without compromising performance, as our method achieves similar sample efficiency and task rewards to state-of-the-art MBRL methods. 

**Abstract (ZH)**: 强化学习（RL）是机器人学习的一种强大方法。然而，无模型强化学习（MFRL）需要大量的环境交互来学习成功的控制策略。这主要是因为RL训练更新过程中的噪声以及机器人的复杂性，通常涉及高度非线性的动力学和噪声传感器信号。相比之下，基于模型的强化学习（MBRL）不仅训练策略，还同时学习一个世界模型来捕捉环境的动力学和奖励。世界模型可以用于规划、数据收集，或者为训练提供一阶策略梯度。利用世界模型可以显著提高样本效率，相比无模型的强化学习。然而，同时训练世界模型和策略会增加计算复杂性，导致更长的训练时间，尤其是在复杂的现实场景中往往难以实现。在本工作中，我们提出了一种使用状态空间世界模型加速基于模型的强化学习的新方法。我们的方法利用状态空间模型（SSM）并行化动力学模型的训练，这通常是计算瓶颈。此外，我们在训练过程中提出了一种架构，向世界模型提供特权信息，特别是在部分可观测环境中尤为重要。我们评估了该方法在几个现实世界的敏捷四旋翼飞行任务中的表现，涉及复杂动力学，包括完全可观测和部分可观测环境。我们展示了显著的加速效果，将世界模型的训练时间减少多达10倍，MBRL整体训练时间减少多达4倍。这种加速并不降低性能，因为我们的方法在样本效率和任务奖励方面达到了当前最先进的MBRL方法的水平。 

---
# Adaptive H&E-IHC information fusion staining framework based on feature extra 

**Title (ZH)**: 基于特征提取的自适应HE-IHC信息融合染色框架 

**Authors**: Yifan Jia, Xingda Yu, Zhengyang Ji, Songning Lai, Yutao Yue  

**Link**: [PDF](https://arxiv.org/pdf/2502.20156)  

**Abstract**: Immunohistochemistry (IHC) staining plays a significant role in the evaluation of diseases such as breast cancer. The H&E-to-IHC transformation based on generative models provides a simple and cost-effective method for obtaining IHC images. Although previous models can perform digital coloring well, they still suffer from (i) coloring only through the pixel features that are not prominent in HE, which is easy to cause information loss in the coloring process; (ii) The lack of pixel-perfect H&E-IHC groundtruth pairs poses a challenge to the classical L1 this http URL address the above challenges, we propose an adaptive information enhanced coloring framework based on feature extractors. We first propose the VMFE module to effectively extract the color information features using multi-scale feature extraction and wavelet transform convolution, while combining the shared decoder for feature fusion. The high-performance dual feature extractor of H&E-IHC is trained by contrastive learning, which can effectively perform feature alignment of HE-IHC in high latitude space. At the same time, the trained feature encoder is used to enhance the features and adaptively adjust the loss in the HE section staining process to solve the problems related to unclear and asymmetric information. We have tested on different datasets and achieved excellent this http URL code is available at this https URL 

**Abstract (ZH)**: 免疫组织化学(IHC)染色在乳腺癌等疾病的评估中发挥着重要作用。基于生成模型的H&E到IHC转换提供了一种简单且成本效益高的获取IHC图像的方法。尽管先前的模型在数字着色方面表现良好，但仍然存在以下问题：(i) 仅通过在H&E中不显著的像素特征进行着色，这可能导致着色过程中的信息丢失；(ii) 缺乏像素级别的H&E-IHC配对数据对经典L1距离损失函数构成了挑战。为了解决上述挑战，我们提出了一种基于特征提取器的自适应信息增强着色框架。我们首先提出了VMFE模块，利用多尺度特征提取和小波变换卷积有效地提取颜色信息特征，并结合了共享解码器进行特征融合。通过对比学习训练高性能的H&E-IHC双特征提取器，可以有效地在高纬度空间内进行HE-IHC特征对齐。同时，训练后的特征编码器用于增强特征并自适应调整H&E染色过程中的损失，以解决与不清晰和不对称信息相关的问题。我们在不同的数据集上进行了测试，并取得了出色的性能。代码已发布在以下链接：[代码链接] 

---
# QPM: Discrete Optimization for Globally Interpretable Image Classification 

**Title (ZH)**: QPM：全局可解释的图像分类的离散优化 

**Authors**: Thomas Norrenbrock, Timo Kaiser, Sovan Biswas, Ramesh Manuvinakurike, Bodo Rosenhahn  

**Link**: [PDF](https://arxiv.org/pdf/2502.20130)  

**Abstract**: Understanding the classifications of deep neural networks, e.g. used in safety-critical situations, is becoming increasingly important. While recent models can locally explain a single decision, to provide a faithful global explanation about an accurate model's general behavior is a more challenging open task. Towards that goal, we introduce the Quadratic Programming Enhanced Model (QPM), which learns globally interpretable class representations. QPM represents every class with a binary assignment of very few, typically 5, features, that are also assigned to other classes, ensuring easily comparable contrastive class representations. This compact binary assignment is found using discrete optimization based on predefined similarity measures and interpretability constraints. The resulting optimal assignment is used to fine-tune the diverse features, so that each of them becomes the shared general concept between the assigned classes. Extensive evaluations show that QPM delivers unprecedented global interpretability across small and large-scale datasets while setting the state of the art for the accuracy of interpretable models. 

**Abstract (ZH)**: 深入神经网络的分类理解，尤其是在安全关键情况下使用时，正变得越来越重要。虽然最近的模型可以在局部解释单个决策，但提供对模型准确行为的整体可靠解释仍然是一个更具挑战性的开放问题。为了解决这一问题，我们提出了增强规划模型（QPM，Quadratic Programming Enhanced Model），该模型学习全局可解释的类别表示。QPM 使用二进制编码表示每一类，通常只使用 5 个特征，这些特征也会被分配给其他类，从而确保对比类别表示的易比较性。这种紧凑的二进制编码是通过基于预定义的相似度度量和可解释性约束的离散优化找到的。最终的最佳分配被用于微调多样化的特征，使得每个特征都成为分配类别之间的共享通用概念。大量的评估表明，QPM 在小型和大型数据集上提供了前所未有的全局可解释性，同时在可解释模型的准确性方面确立了新的标准。 

---
# Adaptive H&E-IHC information fusion staining framework based on feature extra 

**Title (ZH)**: 基于特征提取的自适应HE-IHC信息融合染色框架 

**Authors**: Yifan Jia, Xingda Yu, Zhengyang Ji, Songning Lai, Yutao Yue  

**Link**: [PDF](https://arxiv.org/pdf/2502.20156)  

**Abstract**: Immunohistochemistry (IHC) staining plays a significant role in the evaluation of diseases such as breast cancer. The H&E-to-IHC transformation based on generative models provides a simple and cost-effective method for obtaining IHC images. Although previous models can perform digital coloring well, they still suffer from (i) coloring only through the pixel features that are not prominent in HE, which is easy to cause information loss in the coloring process; (ii) The lack of pixel-perfect H&E-IHC groundtruth pairs poses a challenge to the classical L1 this http URL address the above challenges, we propose an adaptive information enhanced coloring framework based on feature extractors. We first propose the VMFE module to effectively extract the color information features using multi-scale feature extraction and wavelet transform convolution, while combining the shared decoder for feature fusion. The high-performance dual feature extractor of H&E-IHC is trained by contrastive learning, which can effectively perform feature alignment of HE-IHC in high latitude space. At the same time, the trained feature encoder is used to enhance the features and adaptively adjust the loss in the HE section staining process to solve the problems related to unclear and asymmetric information. We have tested on different datasets and achieved excellent this http URL code is available at this https URL 

**Abstract (ZH)**: 免疫组织化学（IHC）染色在乳腺癌等疾病的评估中发挥着重要作用。基于生成模型的H&E到IHC转换提供了一种简单且成本效益高的获取IHC图像的方法。尽管以往的模型在数字着色方面表现良好，但在着色过程中仍然存在以下问题：（i）仅通过在HE图像中不明显的像素特征进行着色，容易导致着色过程中的信息损失；（ii）缺乏像素级精确的H&E-IHC groundtruth配对给经典的L1损失函数带来了挑战。为了解决上述挑战，我们提出了一种基于特征提取器的自适应信息增强着色框架。首先，我们提出了VMFE模块，该模块利用多尺度特征提取和小波变换卷积有效地提取颜色信息特征，并结合共享解码器进行特征融合。通过对比学习训练具有高性能的H&E-IHC双特征提取器，可以有效地在高纬度空间中执行HE-IHC特征对齐。同时，训练好的特征编码器用于增强特征并自适应调整HE染色过程中的损失，以解决不清晰和不对称信息相关的问题。我们已在不同数据集上进行了测试，并取得了优异的结果。此代码可在以下链接中获得：[代码链接]。 

---
# QPM: Discrete Optimization for Globally Interpretable Image Classification 

**Title (ZH)**: QPM：全局可解释的图像分类离散优化 

**Authors**: Thomas Norrenbrock, Timo Kaiser, Sovan Biswas, Ramesh Manuvinakurike, Bodo Rosenhahn  

**Link**: [PDF](https://arxiv.org/pdf/2502.20130)  

**Abstract**: Understanding the classifications of deep neural networks, e.g. used in safety-critical situations, is becoming increasingly important. While recent models can locally explain a single decision, to provide a faithful global explanation about an accurate model's general behavior is a more challenging open task. Towards that goal, we introduce the Quadratic Programming Enhanced Model (QPM), which learns globally interpretable class representations. QPM represents every class with a binary assignment of very few, typically 5, features, that are also assigned to other classes, ensuring easily comparable contrastive class representations. This compact binary assignment is found using discrete optimization based on predefined similarity measures and interpretability constraints. The resulting optimal assignment is used to fine-tune the diverse features, so that each of them becomes the shared general concept between the assigned classes. Extensive evaluations show that QPM delivers unprecedented global interpretability across small and large-scale datasets while setting the state of the art for the accuracy of interpretable models. 

**Abstract (ZH)**: 在安全关键应用场景中使用的深度神经网络分类的理解变得越来越重要。尽管最近的模型可以在局部解释单个决策，但提供一个关于准确模型普遍行为的忠实全局解释仍然是一个更具挑战性的开放问题。为此，我们提出了增强型二次规划模型（QPM），它可以学习全局可解释的类别表示。QPM通过将每个类别表示为少量（通常为5个）特征的二元分配来进行表示，这些特征也被分配给其他类别，以确保对比类别表示易于比较。这种紧凑的二元分配是通过基于预定义的相似度度量和可解释性约束的离散优化找到的。最终最优分配用于微调多样化的特征，使得每个特征成为分配类别之间的共享通用概念。广泛评估表明，QPM不仅在小规模和大规模数据集上提供了前所未有的全局可解释性，还设定了可解释模型准确性的最新标准。 

---
# SoRFT: Issue Resolving with Subtask-oriented Reinforced Fine-Tuning 

**Title (ZH)**: SoRFT：面向子任务的强化 fine-tuning 问题解决 

**Authors**: Zexiong Ma, Chao Peng, Pengfei Gao, Xiangxin Meng, Yanzhen Zou, Bing Xie  

**Link**: [PDF](https://arxiv.org/pdf/2502.20127)  

**Abstract**: Mainstream issue-resolving frameworks predominantly rely on commercial models, leading to high costs and privacy concerns. Existing training approaches for issue resolving struggle with poor generalization and fail to fully leverage open-source development resources. We propose Subtask-oriented Reinforced Fine-Tuning (SoRFT), a novel training approach to enhance the issue resolving capability of LLMs. We decomposes issue resolving into structured subtasks: file localization, function localization, line localization, and code edit generation. SoRFT consists of two training stages: (1) rejection-sampled supervised fine-tuning, Chain of Thought (CoT) data is filtered using ground-truth before fine-tuning the LLM, and (2) rule-based reinforcement learning, which leverages PPO with ground-truth based rewards. We evaluate the SoRFT-trained model on SWE-Bench Verified and SWE-Bench Lite, achieving state-of-the-art (SOTA) performance among open-source models (e.g., resolve 21.4% issues on SWE-Bench Verified with SoRFT-Qwen-7B). The experimental results demonstrate that SoRFT significantly enhances issue-resolving performance, improves model generalization, and provides a cost-efficient alternative to commercial models. 

**Abstract (ZH)**: 主流的问题解决框架主要依赖商业模型，这导致了高成本和隐私担忧。现有的问题解决训练方法难以泛化，并且无法充分利用开源开发资源。我们提出了面向子任务的强化微调（Subtask-oriented Reinforced Fine-Tuning，SoRFT），这是一种新的训练方法，旨在提高大规模语言模型（LLMs）的问题解决能力。我们把问题解决分解为结构化的子任务：文件定位、函数定位、行定位和代码编辑生成。SoRFT 包含两个训练阶段：（1）拒绝采样的监督微调，在微调大规模语言模型之前使用 ground-truth 对链式思考（CoT）数据进行筛选；（2）基于规则的强化学习，利用 PPO 并使用基于 ground-truth 的奖励。我们对 SoRFT 训练的模型在 SWE-Bench Verified 和 SWE-Bench Lite 上进行了评估，展示了开源模型中最佳性能（例如，在 SWE-Bench Verified 上解决了 21.4% 的问题，使用 SoRFT-Qwen-7B）。实验结果表明，SoRFT 显著提高了问题解决性能，增强了模型泛化能力，并提供了一种商业模型的成本效益替代方案。 

---
# Exploring Open-world Continual Learning with Knowns-Unknowns Knowledge Transfer 

**Title (ZH)**: 探索开放世界连续学习中的已知未知知识迁移 

**Authors**: Yujie Li, Guannan Lai, Xin Yang, Yonghao Li, Marcello Bonsangue, Tianrui Li  

**Link**: [PDF](https://arxiv.org/pdf/2502.20124)  

**Abstract**: Open-World Continual Learning (OWCL) is a challenging paradigm where models must incrementally learn new knowledge without forgetting while operating under an open-world assumption. This requires handling incomplete training data and recognizing unknown samples during inference. However, existing OWCL methods often treat open detection and continual learning as separate tasks, limiting their ability to integrate open-set detection and incremental classification in OWCL. Moreover, current approaches primarily focus on transferring knowledge from known samples, neglecting the insights derived from unknown/open samples. To address these limitations, we formalize four distinct OWCL scenarios and conduct comprehensive empirical experiments to explore potential challenges in OWCL. Our findings reveal a significant interplay between the open detection of unknowns and incremental classification of knowns, challenging a widely held assumption that unknown detection and known classification are orthogonal processes. Building on our insights, we propose \textbf{HoliTrans} (Holistic Knowns-Unknowns Knowledge Transfer), a novel OWCL framework that integrates nonlinear random projection (NRP) to create a more linearly separable embedding space and distribution-aware prototypes (DAPs) to construct an adaptive knowledge space. Particularly, our HoliTrans effectively supports knowledge transfer for both known and unknown samples while dynamically updating representations of open samples during OWCL. Extensive experiments across various OWCL scenarios demonstrate that HoliTrans outperforms 22 competitive baselines, bridging the gap between OWCL theory and practice and providing a robust, scalable framework for advancing open-world learning paradigms. 

**Abstract (ZH)**: 开放世界持续学习（OWCL）是一种具有挑战性的范式，其中模型必须在开放世界假设下无遗忘地增量学习新知识。这要求处理不完整训练数据并在推理过程中识别未知样本。然而，现有的OWCL方法通常将开放检测和持续学习视为独立任务，限制了它们在OWCL中整合开放集检测和增量分类的能力。此外，当前的方法主要关注从已知样本转移知识，而忽视了未知/开放样本提供的洞察。为了克服这些限制，我们正式定义了四种不同的OWCL场景，并通过全面的实证实验探索OWCL中的潜在挑战。我们的研究发现开放未知样本的检测与已知样本的增量分类之间存在显著的相互作用，挑战了开放样本检测和已知样本分类是相互独立过程的普遍假设。基于我们的发现，我们提出了**HoliTrans**（全方位已知-未知知识迁移）框架，该框架结合非线性随机投影（NRP）以创建更线性可分的嵌入空间，并采用分布感知原型（DAPs）构建自适应的知识空间。特别是，HoliTrans 在OWCL过程中有效支持已知和未知样本的知识迁移，同时动态更新开放样本的表示。在各种OWCL场景下的广泛实验表明，HoliTrans 显著优于22个竞争性基线，填补了OWCL理论与实践之间的差距，并提供了一个 robust 和可扩展的框架来推动开放世界学习范式的进步。 

---
# Self-Training Elicits Concise Reasoning in Large Language Models 

**Title (ZH)**: 自我训练促使大型语言模型进行精炼的推理 

**Authors**: Tergel Munkhbat, Namgyu Ho, Seohyun Kim, Yongjin Yang, Yujin Kim, Se-Young Yun  

**Link**: [PDF](https://arxiv.org/pdf/2502.20122)  

**Abstract**: Chain-of-thought (CoT) reasoning has enabled large language models (LLMs) to utilize additional computation through intermediate tokens to solve complex tasks. However, we posit that typical reasoning traces contain many redundant tokens, incurring extraneous inference costs. Upon examination of the output distribution of current LLMs, we find evidence on their latent ability to reason more concisely, relative to their default behavior. To elicit this capability, we propose simple fine-tuning methods which leverage self-generated concise reasoning paths obtained by best-of-N sampling and few-shot conditioning, in task-specific settings. Our combined method achieves a 30% reduction in output tokens on average, across five model families on GSM8K and MATH, while maintaining average accuracy. By exploiting the fundamental stochasticity and in-context learning capabilities of LLMs, our self-training approach robustly elicits concise reasoning on a wide range of models, including those with extensive post-training. Code is available at this https URL 

**Abstract (ZH)**: 链式推理（CoT）使得大型语言模型（LLMs）能够通过中间令牌进行额外的计算来解决复杂任务。然而，我们提出，典型的推理过程包含了许多冗余的令牌，引起不必要的推理成本。通过对当前LLMs输出分布的分析，我们发现它们在潜在能力上能够更简洁地进行推理，相对于其默认行为具有一定的优势。为了激发这种能力，我们提出了一种简单的微调方法，该方法利用了通过最佳N次采样和少量示例条件生成的简洁推理路径，在特定任务设置中加以应用。我们的综合方法在GSM8K和MATH数据集上的五种模型家族中，平均减少了30%的输出令牌，同时保持了平均精度。通过利用LLMs的基本随机性和上下文学习能力，我们提出的自训练方法能够稳健地在各种模型中激发简洁的推理，包括那些具有广泛后训练的模型。相关代码可在此处访问：[提供代码链接] 

---
# Forward-Cooperation-Backward (FCB) learning in a Multi-Encoding Uni-Decoding neural network architecture 

**Title (ZH)**: 多编码单解码神经网络架构中的前向合作-后向学习（FCB 学习） 

**Authors**: Prasun Dutta, Koustab Ghosh, Rajat K. De  

**Link**: [PDF](https://arxiv.org/pdf/2502.20113)  

**Abstract**: The most popular technique to train a neural network is backpropagation. Recently, the Forward-Forward technique has also been introduced for certain learning tasks. However, in real life, human learning does not follow any of these techniques exclusively. The way a human learns is basically a combination of forward learning, backward propagation and cooperation. Humans start learning a new concept by themselves and try to refine their understanding hierarchically during which they might come across several doubts. The most common approach to doubt solving is a discussion with peers, which can be called cooperation. Cooperation/discussion/knowledge sharing among peers is one of the most important steps of learning that humans follow. However, there might still be a few doubts even after the discussion. Then the difference between the understanding of the concept and the original literature is identified and minimized over several revisions. Inspired by this, the paper introduces Forward-Cooperation-Backward (FCB) learning in a deep neural network framework mimicking the human nature of learning a new concept. A novel deep neural network architecture, called Multi Encoding Uni Decoding neural network model, has been designed which learns using the notion of FCB. A special lateral synaptic connection has also been introduced to realize cooperation. The models have been justified in terms of their performance in dimension reduction on four popular datasets. The ability to preserve the granular properties of data in low-rank embedding has been tested to justify the quality of dimension reduction. For downstream analyses, classification has also been performed. An experimental study on convergence analysis has been performed to establish the efficacy of the FCB learning strategy. 

**Abstract (ZH)**: 训练神经网络最流行的方法是反向传播。最近，还引入了一种名为前向-前向（Forward-Forward）的技术，用于某些学习任务。然而，在现实生活中，人类学习并不单独遵循这些任何一种技术。人类学习的过程实际上是一个结合了前向学习、反向传播和合作的过程。人类在学习新概念时，先自学并尝试层次化地完善理解，在此过程中可能会遇到各种疑问。最常见的疑问解决方法是与同伴讨论，这被称为合作。同伴之间的合作、讨论和知识共享是人类学习的重要步骤之一。即使在讨论之后，仍可能有一些疑问。然后，通过多次修订，逐渐识别并最小化概念理解与原始文献之间的差异。受到这一过程的启发，本文在深度神经网络框架中引入了前向-合作-后向（Forward-Cooperation-Backward，FCB）学习策略，模仿人类学习新概念的自然过程。设计了一种新的深度神经网络架构，称为多编码统一解码（Multi Encoding Uni Decoding）神经网络模型，该模型利用FCB的概念进行学习。还引入了一种特殊的侧向突触连接，以实现合作。性能方面，这些模型在四个流行的数据集上进行了维数降低效果的验证，并测试了它们在低秩嵌入中保留数据细粒度属性的能力来证明维数降低的质量。为了下游分析，还进行了分类任务以评估性能。进行了一个收敛性分析的实验研究，以证明FCB学习策略的有效性。 

---
# MITracker: Multi-View Integration for Visual Object Tracking 

**Title (ZH)**: MITracker：多视图集成视觉目标跟踪 

**Authors**: Mengjie Xu, Yitao Zhu, Haotian Jiang, Jiaming Li, Zhenrong Shen, Sheng Wang, Haolin Huang, Xinyu Wang, Qing Yang, Han Zhang, Qian Wang  

**Link**: [PDF](https://arxiv.org/pdf/2502.20111)  

**Abstract**: Multi-view object tracking (MVOT) offers promising solutions to challenges such as occlusion and target loss, which are common in traditional single-view tracking. However, progress has been limited by the lack of comprehensive multi-view datasets and effective cross-view integration methods. To overcome these limitations, we compiled a Multi-View object Tracking (MVTrack) dataset of 234K high-quality annotated frames featuring 27 distinct objects across various scenes. In conjunction with this dataset, we introduce a novel MVOT method, Multi-View Integration Tracker (MITracker), to efficiently integrate multi-view object features and provide stable tracking outcomes. MITracker can track any object in video frames of arbitrary length from arbitrary viewpoints. The key advancements of our method over traditional single-view approaches come from two aspects: (1) MITracker transforms 2D image features into a 3D feature volume and compresses it into a bird's eye view (BEV) plane, facilitating inter-view information fusion; (2) we propose an attention mechanism that leverages geometric information from fused 3D feature volume to refine the tracking results at each view. MITracker outperforms existing methods on the MVTrack and GMTD datasets, achieving state-of-the-art performance. The code and the new dataset will be available at this https URL. 

**Abstract (ZH)**: 多视角目标跟踪（Multi-view Object Tracking, MVOT）为解决传统单视角跟踪中常见的遮挡和目标丢失等问题提供了有前景的解决方案。然而，由于缺乏全面的多视角数据集和有效的跨视角整合方法，进展受到了限制。为克服这些限制，我们构建了一个包含234,000帧高质量标注图像的数据集MVTrack，这些图像涵盖了27种不同物体的多种场景。在此基础上，我们提出了一种名为Multi-View Integration Tracker（MITracker）的新方法，用于高效地整合多视角目标特征并提供稳定的跟踪结果。MITracker可以跟踪视频帧中任意长度和任意视角下的任何物体。我们方法相对于传统单视角方法的主要进步体现在两个方面：（1）MITracker将二维图像特征转换为三维特征体，并将其压缩成顶视图（Bird’s Eye View, BEV）平面，便于跨视角信息融合；（2）我们提出了一种基于融合的三维特征体中的几何信息的注意力机制，在每个视角下细化跟踪结果。MITracker在MVTrack和GMTD数据集上的表现优于现有方法，达到了最先进的水平。代码和新数据集可在此处访问：[请在此处填写网址或具体信息]。 

---
# Sanity Checking Causal Representation Learning on a Simple Real-World System 

**Title (ZH)**: 对简单实际系统中的因果表示学习进行合理性检查 

**Authors**: Juan L. Gamella, Simon Bing, Jakob Runge  

**Link**: [PDF](https://arxiv.org/pdf/2502.20099)  

**Abstract**: We evaluate methods for causal representation learning (CRL) on a simple, real-world system where these methods are expected to work. The system consists of a controlled optical experiment specifically built for this purpose, which satisfies the core assumptions of CRL and where the underlying causal factors (the inputs to the experiment) are known, providing a ground truth. We select methods representative of different approaches to CRL and find that they all fail to recover the underlying causal factors. To understand the failure modes of the evaluated algorithms, we perform an ablation on the data by substituting the real data-generating process with a simpler synthetic equivalent. The results reveal a reproducibility problem, as most methods already fail on this synthetic ablation despite its simple data-generating process. Additionally, we observe that common assumptions on the mixing function are crucial for the performance of some of the methods but do not hold in the real data. Our efforts highlight the contrast between the theoretical promise of the state of the art and the challenges in its application. We hope the benchmark serves as a simple, real-world sanity check to further develop and validate methodology, bridging the gap towards CRL methods that work in practice. We make all code and datasets publicly available at this http URL 

**Abstract (ZH)**: 我们将因果表示学习（Causal Representation Learning, CRL）方法应用于一个简单的实际系统，以评估这些方法的效能。该系统包括一个专为这一目的设计的受控光学实验，该实验满足CRL的核心假设，并且实验的底层因果因素（实验的输入）已知，从而提供了一个基准真相。我们选择代表不同CRL方法的方法，并发现它们都无法恢复底层的因果因素。为了理解评估算法的失效模式，我们通过用一个更简单的合成等价物替换真实的数据生成过程来进行数据的剥离实验。结果揭示了一个再现性问题，尽管合成数据生成过程非常简单，大多数方法在合成剥离中就已经失效。另外，我们观察到一些方法的性能依赖于混合函数的常见假设，但在实际数据中这些假设并不成立。我们的努力突显了现状理论上的承诺与其实用中的挑战之间的对比。我们希望这个基准能够作为一个简单的现实检查，以进一步开发和验证方法，从而弥合理论方法与实际应用之间的差距。我们将在以下网址公开所有代码和数据集：[请替换为实际网址] 

---
# WalnutData: A UAV Remote Sensing Dataset of Green Walnuts and Model Evaluation 

**Title (ZH)**: 《WalnutData：绿壳核桃无人机遥感数据集及其模型评估》

这个标题翻译成中文既保持了原意，又符合学术文献的规范用语。其中，“WalnutData”是一个专有名词，通常保留原名，译为“核桃数据”或“核桃数据集”更为贴切。“UAV Remote Sensing”翻译为“无人机遥感”，“Green Walnuts” 翻译为“绿壳核桃”，“Model Evaluation”翻译为“模型评估”。 

**Authors**: Mingjie Wu, Chenggui Yang, Huihua Wang, Chen Xue, Yibo Wang, Haoyu Wang, Yansong Wang, Can Peng, Yuqi Han, Ruoyu Li, Lijun Yun, Zaiqing Chen, Songfan Shi, Luhao Fang, Shuyi Wan, Tingfeng Li, Shuangyao Liu, Haotian Feng  

**Link**: [PDF](https://arxiv.org/pdf/2502.20092)  

**Abstract**: The UAV technology is gradually maturing and can provide extremely powerful support for smart agriculture and precise monitoring. Currently, there is no dataset related to green walnuts in the field of agricultural computer vision. Thus, in order to promote the algorithm design in the field of agricultural computer vision, we used UAV to collect remote-sensing data from 8 walnut sample plots. Considering that green walnuts are subject to various lighting conditions and occlusion, we constructed a large-scale dataset with a higher-granularity of target features - WalnutData. This dataset contains a total of 30,240 images and 706,208 instances, and there are 4 target categories: being illuminated by frontal light and unoccluded (A1), being backlit and unoccluded (A2), being illuminated by frontal light and occluded (B1), and being backlit and occluded (B2). Subsequently, we evaluated many mainstream algorithms on WalnutData and used these evaluation results as the baseline standard. The dataset and all evaluation results can be obtained at this https URL. 

**Abstract (ZH)**: 无人机技术逐渐成熟，为智能农业和精准监测提供了极其强大的支持。目前，在农业计算机视觉领域尚未有关于青核桃的相关数据集。因此，为促进农业计算机视觉领域的算法设计，我们利用无人机从8个核桃样品田块中收集了遥感数据。鉴于青核桃会受到各种光照条件和遮挡的影响，我们构建了一个具有更详细目标特征的大规模数据集——WalnutData。该数据集包含共计30,240张图像和706,208个实例，并包含4个目标类别：正面光照且无遮挡（A1）、背面光照且无遮挡（A2）、正面光照且遮挡（B1）以及背面光照且遮挡（B2）。随后，我们在WalnutData上评估了多种主流算法，并以这些评估结果作为基准标准。数据集及相关评估结果可从以下链接获取：\[此链接\]。 

---
# RIZE: Regularized Imitation Learning via Distributional Reinforcement Learning 

**Title (ZH)**: RIZE：通过分布强化学习正则化模仿学习 

**Authors**: Adib Karimi, Mohammad Mehdi Ebadzadeh  

**Link**: [PDF](https://arxiv.org/pdf/2502.20089)  

**Abstract**: We introduce a novel Inverse Reinforcement Learning (IRL) approach that overcomes limitations of fixed reward assignments and constrained flexibility in implicit reward regularization. By extending the Maximum Entropy IRL framework with a squared temporal-difference (TD) regularizer and adaptive targets, dynamically adjusted during training, our method indirectly optimizes a reward function while incorporating reinforcement learning principles. Furthermore, we integrate distributional RL to capture richer return information. Our approach achieves state-of-the-art performance on challenging MuJoCo tasks, demonstrating expert-level results on the Humanoid task with only 3 demonstrations. Extensive experiments and ablation studies validate the effectiveness of our method, providing insights into adaptive targets and reward dynamics in imitation learning. 

**Abstract (ZH)**: 我们提出了一种新颖的逆强化学习（IRL）方法，以克服固定奖励分配和隐式奖励正则化中固有的局限性和灵活性不足问题。通过将最大熵IRL框架扩展为带平方时间差（TD）正则化的自适应目标，并在训练过程中动态调整这些目标，我们的方法间接优化了奖励函数，并结合了强化学习的基本原理。此外，我们还整合了分布型强化学习以捕捉更丰富的回报信息。我们的方法在具有挑战性的MuJoCo任务中实现了最先进的性能，并仅通过3次演示就达到了与专家水平相当的结果。广泛的实验和消融研究验证了我们方法的有效性，提供了关于模仿学习中自适应目标和奖励动态的见解。 

---
# Minds on the Move: Decoding Trajectory Prediction in Autonomous Driving with Cognitive Insights 

**Title (ZH)**: 《思维在移动中：基于认知洞察的自动驾驶轨迹预测解码》 

**Authors**: Haicheng Liao, Chengyue Wang, Kaiqun Zhu, Yilong Ren, Bolin Gao, Shengbo Eben Li, Chengzhong Xu, Zhenning Li  

**Link**: [PDF](https://arxiv.org/pdf/2502.20084)  

**Abstract**: In mixed autonomous driving environments, accurately predicting the future trajectories of surrounding vehicles is crucial for the safe operation of autonomous vehicles (AVs). In driving scenarios, a vehicle's trajectory is determined by the decision-making process of human drivers. However, existing models primarily focus on the inherent statistical patterns in the data, often neglecting the critical aspect of understanding the decision-making processes of human drivers. This oversight results in models that fail to capture the true intentions of human drivers, leading to suboptimal performance in long-term trajectory prediction. To address this limitation, we introduce a Cognitive-Informed Transformer (CITF) that incorporates a cognitive concept, Perceived Safety, to interpret drivers' decision-making mechanisms. Perceived Safety encapsulates the varying risk tolerances across drivers with different driving behaviors. Specifically, we develop a Perceived Safety-aware Module that includes a Quantitative Safety Assessment for measuring the subject risk levels within scenarios, and Driver Behavior Profiling for characterizing driver behaviors. Furthermore, we present a novel module, Leanformer, designed to capture social interactions among vehicles. CITF demonstrates significant performance improvements on three well-established datasets. In terms of long-term prediction, it surpasses existing benchmarks by 12.0% on the NGSIM, 28.2% on the HighD, and 20.8% on the MoCAD dataset. Additionally, its robustness in scenarios with limited or missing data is evident, surpassing most state-of-the-art (SOTA) baselines, and paving the way for real-world applications. 

**Abstract (ZH)**: 在混合自动驾驶环境中，准确预测周围车辆的未来轨迹对于自动驾驶车辆（AVs）的安全运行至关重要。在驾驶场景中，车辆的轨迹是由人类驾驶员的决策过程决定的。然而，现有模型主要关注数据中的固有统计模式，往往忽视了理解人类驾驶员决策过程这一关键方面。这种忽视导致模型无法捕捉到人类驾驶员的真实意图，从而在长期轨迹预测方面表现欠佳。为了解决这一局限性，我们提出了一种认知启发式的Transformer（CITF），该模型整合了一个认知概念——感知安全性（Perceived Safety），以解释驾驶员的决策机制。感知安全性涵盖了不同驾驶行为的驾驶员在风险承受方面的差异。具体来说，我们开发了一个感知安全感知模块，该模块包括定量安全性评估，用于在场景中衡量主体风险水平，以及驾驶员行为特征分析，用以刻画驾驶员行为。此外，我们还提出了一种新的模块Leanformer，用于捕捉车辆之间的社会交互。CITF 在三个广泛认可的数据集上展示了显著的性能改进。在长期预测方面，它在NGSIM数据集上的表现比现有基准高出12.0%，在HighD数据集上高出28.2%，在MoCAD数据集上高出20.8%。此外，CITF 在数据有限或缺失的情况下仍然表现出色，超越了大多数最先进的基线模型，为实际应用铺平了道路。 

---
# Collab-Overcooked: Benchmarking and Evaluating Large Language Models as Collaborative Agents 

**Title (ZH)**: Collab-Overcooked: 评估大型语言模型作为合作代理的基准测试与评估 

**Authors**: Haochen Sun, Shuwen Zhang, Lei Ren, Hao Xu, Hao Fu, Caixia Yuan, Xiaojie Wang  

**Link**: [PDF](https://arxiv.org/pdf/2502.20073)  

**Abstract**: Large language models (LLMs) based agent systems have made great strides in real-world applications beyond traditional NLP tasks. This paper proposes a new LLM-powered Multi-Agent System (LLM-MAS) benchmark, Collab-Overcooked, built on the popular Overcooked-AI game with more applicable and challenging tasks in interactive environments. Collab-Overcooked extends existing benchmarks from two novel perspectives. First, it provides a multi-agent framework supporting diverse tasks and objectives and encourages collaboration through natural language communication. Second, it introduces a spectrum of process-oriented evaluation metrics to assess the fine-grained collaboration capabilities of different LLM agents, a dimension often overlooked in prior work. We conduct extensive experiments over 10 popular LLMs and show that, while the LLMs present a strong ability in goal interpretation, there is a significant discrepancy in active collaboration and continuous adaption that are critical for efficiently fulfilling complicated tasks. Notably, we highlight the strengths and weaknesses in LLM-MAS and provide insights for improving and evaluating LLM-MAS on a unified and open-sourced benchmark. Environments, 30 open-ended tasks, and an integrated evaluation package are now publicly available at this https URL. 

**Abstract (ZH)**: 基于大规模语言模型（LLM）的代理系统在传统自然语言处理（NLP）任务之外的实际应用中取得了显著进展。本文提出了一种新的LLM驱动的多代理系统（LLM-MAS）基准——Collab-Overcooked，该系统基于流行的Overcooked-AI游戏，并引入了更多适用性和挑战性的交互环境任务。Collab-Overcooked从两个新的角度扩展了现有基准。首先，它提供了一个支持多样任务和目标的多代理框架，并通过自然语言通信促进合作。其次，它引入了一系列注重过程的评估指标，以评估不同LLM代理的精细合作能力，这是之前工作中常常被忽视的一个维度。我们在10种流行的LLM上进行了广泛的实验，结果显示，尽管这些LLM在目标理解方面表现出强大的能力，但在关键的高效完成复杂任务所需的主动合作和持续适应方面仍然存在显著差异。值得注意的是，我们强调了LLM-MAS的优点和不足，并为在统一和开源的基础上改进和评估LLM-MAS提供了见解。所有环境、30项开放性任务以及集成评估包现已在以下链接公开：this https URL。 

---
# Enhanced Contrastive Learning with Multi-view Longitudinal Data for Chest X-ray Report Generation 

**Title (ZH)**: 基于多视图 longitudinal 数据增强的对比学习方法在胸部X光报告生成中的应用 

**Authors**: Kang Liu, Zhuoqi Ma, Xiaolu Kang, Yunan Li, Kun Xie, Zhicheng Jiao, Qiguang Miao  

**Link**: [PDF](https://arxiv.org/pdf/2502.20056)  

**Abstract**: Automated radiology report generation offers an effective solution to alleviate radiologists' workload. However, most existing methods focus primarily on single or fixed-view images to model current disease conditions, which limits diagnostic accuracy and overlooks disease progression. Although some approaches utilize longitudinal data to track disease progression, they still rely on single images to analyze current visits. To address these issues, we propose enhanced contrastive learning with Multi-view Longitudinal data to facilitate chest X-ray Report Generation, named MLRG. Specifically, we introduce a multi-view longitudinal contrastive learning method that integrates spatial information from current multi-view images and temporal information from longitudinal data. This method also utilizes the inherent spatiotemporal information of radiology reports to supervise the pre-training of visual and textual representations. Subsequently, we present a tokenized absence encoding technique to flexibly handle missing patient-specific prior knowledge, allowing the model to produce more accurate radiology reports based on available prior knowledge. Extensive experiments on MIMIC-CXR, MIMIC-ABN, and Two-view CXR datasets demonstrate that our MLRG outperforms recent state-of-the-art methods, achieving a 2.3% BLEU-4 improvement on MIMIC-CXR, a 5.5% F1 score improvement on MIMIC-ABN, and a 2.7% F1 RadGraph improvement on Two-view CXR. 

**Abstract (ZH)**: 自动化放射学报告生成提供了一种有效的方法来减轻放射科医生的工作负担。然而，大多数现有方法主要集中在单个或固定视角的图像上，以建模当前的疾病状况，这限制了诊断的准确性并忽略了疾病的发展。尽管有些方法利用纵向数据来跟踪疾病的发展，但它们仍然依赖单个图像来分析当前的就诊情况。为了解决这些问题，我们提出了一种增强对比学习方法，结合多视角纵向数据，以促进胸部X光报告生成，命名为MLRG。具体来说，我们引入了一种多视角纵向对比学习方法，将当前多视角图像的空问信息和纵向数据的时间信息结合起来。该方法还利用放射学报告中的固有时空信息来监督视觉和文本表示的预训练。随后，我们提出了一种标记化的缺失编码技术，以灵活处理患者特异性先验知识的缺失，从而使模型能够基于可用的先验知识生成更准确的放射学报告。在MIMIC-CXR、MIMIC-ABN和双视角胸部X光数据集上的广泛实验表明，我们的MLRG方法优于近期的先进方法，实现了2.3%的BLEU-4改进、5.5%的F1分数改进和2.7%的F1 RadGraph改进。 

---
# Polish-ASTE: Aspect-Sentiment Triplet Extraction Datasets for Polish 

**Title (ZH)**: 波兰-ASTE：波兰语方面-情感三元组提取数据集 

**Authors**: Marta Lango, Borys Naglik, Mateusz Lango, Iwo Naglik  

**Link**: [PDF](https://arxiv.org/pdf/2502.20046)  

**Abstract**: Aspect-Sentiment Triplet Extraction (ASTE) is one of the most challenging and complex tasks in sentiment analysis. It concerns the construction of triplets that contain an aspect, its associated sentiment polarity, and an opinion phrase that serves as a rationale for the assigned polarity. Despite the growing popularity of the task and the many machine learning methods being proposed to address it, the number of datasets for ASTE is very limited. In particular, no dataset is available for any of the Slavic languages. In this paper, we present two new datasets for ASTE containing customer opinions about hotels and purchased products expressed in Polish. We also perform experiments with two ASTE techniques combined with two large language models for Polish to investigate their performance and the difficulty of the assembled datasets. The new datasets are available under a permissive licence and have the same file format as the English datasets, facilitating their use in future research. 

**Abstract (ZH)**: _aspect-情感三元组提取 (ASTE) 是情感分析中最具挑战性和复杂性的任务之一。它涉及构建包含方面、其相关的极性以及作为极性理由的意见短语的三元组。尽管该任务的受欢迎程度逐渐增加，并且提出了许多机器学习方法来解决这一问题，但ASTE数据集的数量非常有限。特别是，对于斯拉夫语系的任何语言都没有现成的数据集。在本文中，我们提出了两个新的数据集，包含客户对波兰语酒店和购买产品的意见，这些意见用波兰语表达。我们还使用两种ASTE技术与两种大型语言模型对波兰语数据进行了实验，以研究这些技术在所组装数据集上的性能及其难度。新的数据集采用宽松的许可协议，并具有与英文数据集相同的数据格式，方便未来研究中的使用。 

---
# Text2VDM: Text to Vector Displacement Maps for Expressive and Interactive 3D Sculpting 

**Title (ZH)**: Text2VDM：文本到向量位移图的转换方法，用于表达性和互动性3D雕刻 

**Authors**: Hengyu Meng, Duotun Wang, Zhijing Shao, Ligang Liu, Zeyu Wang  

**Link**: [PDF](https://arxiv.org/pdf/2502.20045)  

**Abstract**: Professional 3D asset creation often requires diverse sculpting brushes to add surface details and geometric structures. Despite recent progress in 3D generation, producing reusable sculpting brushes compatible with artists' workflows remains an open and challenging problem. These sculpting brushes are typically represented as vector displacement maps (VDMs), which existing models cannot easily generate compared to natural images. This paper presents Text2VDM, a novel framework for text-to-VDM brush generation through the deformation of a dense planar mesh guided by score distillation sampling (SDS). The original SDS loss is designed for generating full objects and struggles with generating desirable sub-object structures from scratch in brush generation. We refer to this issue as semantic coupling, which we address by introducing classifier-free guidance (CFG) weighted blending of prompt tokens to SDS, resulting in a more accurate target distribution and semantic guidance. Experiments demonstrate that Text2VDM can generate diverse, high-quality VDM brushes for sculpting surface details and geometric structures. Our generated brushes can be seamlessly integrated into mainstream modeling software, enabling various applications such as mesh stylization and real-time interactive modeling. 

**Abstract (ZH)**: 专业级3D资产创造往往需要多种雕刻刷来添加表面细节和几何结构。尽管在3D生成方面取得了最近的进步，但生成与艺术家工作流程兼容的可重复使用的雕刻刷仍然是一个开放而具有挑战性的问题。这些雕刻刷通常表示为向量位移图（VDMs），而现有模型难以像生成自然图像那样轻松地生成这些图。本文提出了一种名为Text2VDM的新框架，该框架通过由得分蒸馏抽样（SDS）引导的密集平面网格变形来生成文本到VDM的雕刻刷。原始的SDS损失主要用于生成完整对象，在雕刻刷生成中难以从头生成理想的子对象结构。我们将此问题称为语义耦合，我们通过引入去分类器的指导（CFG）加权混合提示令牌来SDS来解决这一问题，从而获得更准确的目标分布和语义指导。实验结果表明，Text2VDM可以生成用于雕刻表面细节和几何结构的多样化高质量VDM雕刻刷。我们生成的雕刻刷可以无缝集成到主流建模软件中，从而实现如网格风格化和实时交互式建模等各种应用。 

---
# CleanMel: Mel-Spectrogram Enhancement for Improving Both Speech Quality and ASR 

**Title (ZH)**: CleanMel：改进语音质量和ASR性能的梅尔频谱图增强方法 

**Authors**: Nian Shao, Rui Zhou, Pengyu Wang, Xian Li, Ying Fang, Yujie Yang, Xiaofei Li  

**Link**: [PDF](https://arxiv.org/pdf/2502.20040)  

**Abstract**: In this work, we propose CleanMel, a single-channel Mel-spectrogram denoising and dereverberation network for improving both speech quality and automatic speech recognition (ASR) performance. The proposed network takes as input the noisy and reverberant microphone recording and predicts the corresponding clean Mel-spectrogram. The enhanced Mel-spectrogram can be either transformed to speech waveform with a neural vocoder or directly used for ASR. The proposed network is composed of interleaved cross-band and narrow-band processing in the Mel-frequency domain, for learning the full-band spectral pattern and the narrow-band properties of signals, respectively. Compared to linear-frequency domain or time-domain speech enhancement, the key advantage of Mel-spectrogram enhancement is that Mel-frequency presents speech in a more compact way and thus is easier to learn, which will benefit both speech quality and ASR. Experimental results on four English and one Chinese datasets demonstrate a significant improvement in both speech quality and ASR performance achieved by the proposed model. Code and audio examples of our model are available online in this https URL. 

**Abstract (ZH)**: 在本文中，我们提出了一种单通道梅尔频谱去噪和降混响网络——CleanMel，以提升语音质量和自动语音识别（ASR）性能。所提出的网络接受受噪和混响麦克风录音作为输入，并预测相应的干净梅尔频谱。增强后的梅尔频谱可以使用神经声码器转换为语音波形，或者直接用于ASR。所提出的网络由梅尔频率域内的交叉带和窄带交织处理组成，分别学习全带谱模式和信号的窄带特性。与线性频率域或时域语音增强相比，梅尔频谱增强的关键优势在于梅尔频率以更紧凑的方式表示语音，因此更容易学习，这将有利于语音质量和ASR。在四个英语和一个中文数据集上的实验结果表明，所提出的模型在语音质量和ASR性能上取得了显著的改进。我们的模型代码和音频示例已在线发布，链接为：[此处填入具体链接]。 

---
# Order-Robust Class Incremental Learning: Graph-Driven Dynamic Similarity Grouping 

**Title (ZH)**: 序列表征稳健的类别增量学习：图驱动的动态相似性分组 

**Authors**: Guannan Lai, Yujie Li, Xiangkun Wang, Junbo Zhang, Tianrui Li, Xin Yang  

**Link**: [PDF](https://arxiv.org/pdf/2502.20032)  

**Abstract**: Class Incremental Learning (CIL) requires a model to continuously learn new classes without forgetting previously learned ones. While recent studies have significantly alleviated the problem of catastrophic forgetting (CF), more and more research reveals that the order in which classes appear have significant influences on CIL models. Specifically, prioritizing the learning of classes with lower similarity will enhance the model's generalization performance and its ability to mitigate forgetting. Hence, it is imperative to develop an order-robust class incremental learning model that maintains stable performance even when faced with varying levels of class similarity in different orders. In response, we first provide additional theoretical analysis, which reveals that when the similarity among a group of classes is lower, the model demonstrates increased robustness to the class order. Then, we introduce a novel \textbf{G}raph-\textbf{D}riven \textbf{D}ynamic \textbf{S}imilarity \textbf{G}rouping (\textbf{GDDSG}) method, which leverages a graph coloring algorithm for class-based similarity grouping. The proposed approach trains independent CIL models for each group of classes, ultimately combining these models to facilitate joint prediction. Experimental results demonstrate that our method effectively addresses the issue of class order sensitivity while achieving optimal performance in both model accuracy and anti-forgetting capability. Our code is available at this https URL. 

**Abstract (ZH)**: 连续类增量学习（Class Incremental Learning，CIL）要求模型能够在不遗忘之前学习的类别的同时，持续学习新的类别。虽然近期的研究已显著减轻了灾难性遗忘（Catastrophic Forgetting，CF）的问题，但越来越多的研究表明，类别的出现顺序对CIL模型有显著影响。具体来说，优先学习相似性较低的类可以增强模型的泛化性能和减轻遗忘的能力。因此，开发一种鲁棒性强、能够适应不同相似性级别和不同顺序的类增量学习模型是至关重要的。为此，我们首先提供了额外的理论分析，揭示了当一组类别的相似性较低时，模型对类顺序的鲁棒性增强。然后，我们提出了一种新的**G**raph-**D**riven **D**ynamic **S**imilarity **G**rouping（GDDSG）方法，该方法利用图着色算法进行基于类的相似性分组。所提出的方法为每个类组训练独立的CIL模型，并最终将这些模型结合以进行联合预测。实验结果证明，我们的方法能够有效解决类顺序敏感性问题，同时在模型精度和抗遗忘能力方面均达到了最优性能。我们的代码可以在以下链接获取：[在这里插入链接]。 

---
# Can Large Language Models Unveil the Mysteries? An Exploration of Their Ability to Unlock Information in Complex Scenarios 

**Title (ZH)**: 大型语言模型能否揭开神秘面纱？探索其在复杂场景中解锁信息的能力 

**Authors**: Chao Wang, Luning Zhang, Zheng Wang, Yang Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2502.19973)  

**Abstract**: Combining multiple perceptual inputs and performing combinatorial reasoning in complex scenarios is a sophisticated cognitive function in humans. With advancements in multi-modal large language models, recent benchmarks tend to evaluate visual understanding across multiple images. However, they often overlook the necessity of combinatorial reasoning across multiple perceptual information. To explore the ability of advanced models to integrate multiple perceptual inputs for combinatorial reasoning in complex scenarios, we introduce two benchmarks: Clue-Visual Question Answering (CVQA), with three task types to assess visual comprehension and synthesis, and Clue of Password-Visual Question Answering (CPVQA), with two task types focused on accurate interpretation and application of visual data. For our benchmarks, we present three plug-and-play approaches: utilizing model input for reasoning, enhancing reasoning through minimum margin decoding with randomness generation, and retrieving semantically relevant visual information for effective data integration. The combined results reveal current models' poor performance on combinatorial reasoning benchmarks, even the state-of-the-art (SOTA) closed-source model achieves only 33.04% accuracy on CVQA, and drops to 7.38% on CPVQA. Notably, our approach improves the performance of models on combinatorial reasoning, with a 22.17% boost on CVQA and 9.40% on CPVQA over the SOTA closed-source model, demonstrating its effectiveness in enhancing combinatorial reasoning with multiple perceptual inputs in complex scenarios. The code will be publicly available. 

**Abstract (ZH)**: 将以下论文内容或标题翻译成中文并符合学术规范：

人类在复杂场景中结合多种感知输入并进行组合推理是一种复杂的认知功能。随着多模态大型语言模型的发展，最近的基准测试往往评估多张图片的视觉理解能力。然而，这些基准测试往往忽视了跨多种感知信息进行组合推理的必要性。为了探索先进模型在复杂场景中整合多种感知输入进行组合推理的能力，我们引入了两个基准测试：Clue-Visual Question Answering（Clue-VQA）包括三种任务类型评估视觉理解和综合能力；Clue of Password-Visual Question Answering（CPVQA）包括两种任务类型，侧重于视觉数据的准确解读和应用。对于我们的基准测试，我们提出了三种即插即用的方法：利用模型输入进行推理、通过最小边际解码结合随机生成进行推理增强、以及检索具有语义相关性的视觉信息以实现有效的数据整合。综合结果表明，当前模型在组合推理基准测试中的表现较差，即使是最先进的（SOTA）封闭源代码模型，在Clue-VQA上的准确率也仅为33.04%，在CPVQA上的准确率降至7.38%。值得注意的是，我们的方法能显著提高模型在组合推理中的表现，在Clue-VQA 上相较于SOTA封闭源代码模型提升了22.17%，在CPVQA上提升了9.40%，证明了其在复杂场景中通过多种感知输入增强组合推理的有效性。该代码将对公众开放。 

---
# Efficient and Universal Neural-Network Decoder for Stabilizer-Based Quantum Error Correction 

**Title (ZH)**: 基于stabiliizer的量子错误纠正的高效通用神经网络解码器 

**Authors**: Gengyuan Hu, Wanli Ouyang, Chao-Yang Lu, Chen Lin, Han-Sen Zhong  

**Link**: [PDF](https://arxiv.org/pdf/2502.19971)  

**Abstract**: Quantum error correction is crucial for large-scale quantum computing, but the absence of efficient decoders for new codes like quantum low-density parity-check (QLDPC) codes has hindered progress. Here we introduce a universal decoder based on linear attention sequence modeling and graph neural network that operates directly on any stabilizer code's graph structure. Our numerical experiments demonstrate that this decoder outperforms specialized algorithms in both accuracy and speed across diverse stabilizer codes, including surface codes, color codes, and QLDPC codes. The decoder maintains linear time scaling with syndrome measurements and requires no structural modifications between different codes. For the Bivariate Bicycle code with distance 12, our approach achieves a 39.4% lower logical error rate than previous best decoders while requiring only ~1% of the decoding time. These results provide a practical, universal solution for quantum error correction, eliminating the need for code-specific decoders. 

**Abstract (ZH)**: 量子错误校正是大规模量子计算的关键，但由于缺乏对新代码（如量子低密度 parity-check，QLDPC 码）高效解码器的支持，进展受到了阻碍。在此，我们介绍了一种基于线性注意力序列建模和图神经网络的通用解码器，它可以针对任何校验器代码的图结构直接操作。我们的数值实验表明，该解码器在多种校验器代码（包括表面码、彩色码和 QLDPC 码）中均表现出更高的准确性和更快的速度。该解码器的时间复杂度与综合测量成线性关系，并且在不同代码之间无需进行结构修改。对于距离为 12 的双变量自行车码，我们的方法在逻辑错误率上比之前的最佳解码器低 39.4%，且所需的解码时间仅为前者的约 1%。这些结果提供了一种实用且通用的量子错误校正解决方案，消除了需要特定代码解码器的需求。 

---
# Deterministic or probabilistic? The psychology of LLMs as random number generators 

**Title (ZH)**: 确定性还是概率性？关于LLM作为随机数生成器的心里学探究 

**Authors**: Javier Coronado-Blázquez  

**Link**: [PDF](https://arxiv.org/pdf/2502.19965)  

**Abstract**: Large Language Models (LLMs) have transformed text generation through inherently probabilistic context-aware mechanisms, mimicking human natural language. In this paper, we systematically investigate the performance of various LLMs when generating random numbers, considering diverse configurations such as different model architectures, numerical ranges, temperature, and prompt languages. Our results reveal that, despite their stochastic transformers-based architecture, these models often exhibit deterministic responses when prompted for random numerical outputs. In particular, we find significant differences when changing the model, as well as the prompt language, attributing this phenomenon to biases deeply embedded within the training data. Models such as DeepSeek-R1 can shed some light on the internal reasoning process of LLMs, despite arriving to similar results. These biases induce predictable patterns that undermine genuine randomness, as LLMs are nothing but reproducing our own human cognitive biases. 

**Abstract (ZH)**: 大规模语言模型（LLMs）通过固有的基于概率的上下文感知机制改变了文本生成的方式，模拟了人类自然语言的生成过程。在本文中，我们系统地研究了各种LLMs在生成随机数时的性能，考虑了不同的模型架构、数值范围、温度和提示语言等多种配置。我们的结果表明，尽管这些模型基于包含随机变换器的架构，但在被要求生成随机数值输出时，它们往往会表现出确定性的响应。具体而言，我们发现当更改模型或提示语言时，这些现象显示出显著差异，这主要是由于这些模型在训练数据中深深嵌入了偏见。虽然诸如DeepSeek-R1之类的模型可以在一定程度上揭示LLMs的内部推理过程，但它们也会产生类似的结果。这些偏见会导致可预测的模式，从而削弱真正的随机性，因为LLMs本质上只是再现我们自身的人类认知偏见。 

---
# Collaborative Stance Detection via Small-Large Language Model Consistency Verification 

**Title (ZH)**: 基于小型-大型语言模型一致性的协作立场检测 

**Authors**: Yu Yan, Sheng Sun, Zixiang Tang, Teli Liu, Min Liu  

**Link**: [PDF](https://arxiv.org/pdf/2502.19954)  

**Abstract**: Stance detection on social media aims to identify attitudes expressed in tweets towards specific targets. Current studies prioritize Large Language Models (LLMs) over Small Language Models (SLMs) due to the overwhelming performance improving provided by LLMs. However, heavily relying on LLMs for stance detection, regardless of the cost, is impractical for real-world social media monitoring systems that require vast data analysis. To this end, we propose \textbf{\underline{Co}}llaborative Stance Detection via Small-Large Language Model Consistency \textbf{\underline{Ver}}ification (\textbf{CoVer}) framework, which enhances LLM utilization via context-shared batch reasoning and logical verification between LLM and SLM. Specifically, instead of processing each text individually, CoVer processes texts batch-by-batch, obtaining stance predictions and corresponding explanations via LLM reasoning in a shared context. Then, to exclude the bias caused by context noises, CoVer introduces the SLM for logical consistency verification. Finally, texts that repeatedly exhibit low logical consistency are classified using consistency-weighted aggregation of prior LLM stance predictions. Our experiments show that CoVer outperforms state-of-the-art methods across multiple benchmarks in the zero-shot setting, achieving 0.54 LLM queries per tweet while significantly enhancing performance. Our CoVer offers a more practical solution for LLM deploying for social media stance detection. 

**Abstract (ZH)**: 社交媒体上的立场检测旨在识别推文中对特定目标所表达的态度。当前的研究倾向于使用大型语言模型（LLMs）而非小型语言模型（SLMs），这是由于LLMs提供了显著的性能提升。然而，无论成本如何，过度依赖LLMs进行立场检测在需要大量数据分析的现实社交媒体监控系统中是不切实际的。为此，我们提出了**协作立场检测通过小型与大型语言模型一致性验证（CoVer）框架**，该框架通过上下文共享批量推理和LLMs与SLMs之间的逻辑验证来增强LLM的利用。具体来说，CoVer 不是逐条处理文本，而是批量处理文本，通过共享上下文中的LLM推理获得立场预测及其相应的解释。然后，为了排除由上下文噪声引起的偏差，CoVer 引入SLM进行逻辑一致性验证。最后，反复表现出低逻辑一致性的文本通过混合前LLM立场预测的逻辑一致性加权聚合来进行分类。我们的实验表明，在零样本设置下，CoVer 在多个基准测试中优于最先进的方法，每条推文仅需0.54次LLM查询，并且显著提升了性能。我们的CoVer 提供了一个更实用的解决方案，用于在社交媒体立场检测中部署LLM。 

---
# Dynamic DropConnect: Enhancing Neural Network Robustness through Adaptive Edge Dropping Strategies 

**Title (ZH)**: 动态DropConnect：通过自适应边丢弃策略增强神经网络的鲁棒性 

**Authors**: Yuan-Chih Yang, Hung-Hsuan Chen  

**Link**: [PDF](https://arxiv.org/pdf/2502.19948)  

**Abstract**: Dropout and DropConnect are well-known techniques that apply a consistent drop rate to randomly deactivate neurons or edges in a neural network layer during training. This paper introduces a novel methodology that assigns dynamic drop rates to each edge within a layer, uniquely tailoring the dropping process without incorporating additional learning parameters. We perform experiments on synthetic and openly available datasets to validate the effectiveness of our approach. The results demonstrate that our method outperforms Dropout, DropConnect, and Standout, a classic mechanism known for its adaptive dropout capabilities. Furthermore, our approach improves the robustness and generalization of neural network training without increasing computational complexity. The complete implementation of our methodology is publicly accessible for research and replication purposes at this https URL. 

**Abstract (ZH)**: Dropout 和 DropConnect 是广泛使用的技术，在神经网络训练期间随机禁用神经元或边以保持一致的失活率。本文介绍了一种新颖的方法，该方法为每一层内的每条边分配动态的失活率，从而独特地定制失活过程，而不引入额外的学习参数。我们在合成数据集和公开可用的数据集上进行了实验，以验证我们方法的有效性。结果表明，我们的方法在Dropout、DropConnect和Standout（一种以适应性失活能力著称的经典机制）之上表现出优越性。此外，我们的方法提高了神经网络训练的鲁棒性和泛化能力，而不增加计算复杂性。我们的方法的完整实现已公开，供研究和复现使用，链接为：this https URL。 

---
# Algebraic Machine Learning: Learning as computing an algebraic decomposition of a task 

**Title (ZH)**: 代数机器学习：学习视为计算任务的代数分解 

**Authors**: Fernando Martin-Maroto, Nabil Abderrahaman, David Mendez, Gonzalo G. de Polavieja  

**Link**: [PDF](https://arxiv.org/pdf/2502.19944)  

**Abstract**: Statistics and Optimization are foundational to modern Machine Learning. Here, we propose an alternative foundation based on Abstract Algebra, with mathematics that facilitates the analysis of learning. In this approach, the goal of the task and the data are encoded as axioms of an algebra, and a model is obtained where only these axioms and their logical consequences hold. Although this is not a generalizing model, we show that selecting specific subsets of its breakdown into algebraic atoms obtained via subdirect decomposition gives a model that generalizes. We validate this new learning principle on standard datasets such as MNIST, FashionMNIST, CIFAR-10, and medical images, achieving performance comparable to optimized multilayer perceptrons. Beyond data-driven tasks, the new learning principle extends to formal problems, such as finding Hamiltonian cycles from their specifications and without relying on search. This algebraic foundation offers a fresh perspective on machine intelligence, featuring direct learning from training data without the need for validation dataset, scaling through model additivity, and asymptotic convergence to the underlying rule in the data. 

**Abstract (ZH)**: 统计学和优化是现代机器学习的基础。本文提出了一种基于抽象代数的新基础，通过数学方法促进了对学习的分析。在这一方法中，任务目标和数据被编码为代数的公理，从而获得一个仅包含这些公理及其逻辑后果的模型。尽管这不是一个泛化模型，但我们展示了通过子直接分解将其分解为代数原子的特定子集可以得到一个泛化能力较强的模型。我们在这项新的学习原则上进行了验证，包括使用标准数据集如MNIST、FashionMNIST、CIFAR-10和医学图像，其性能与优化后的多层感知器相当。对于数据驱动的任务之外，这项新的学习原则还扩展到形式问题，如根据其规格找到哈密顿回路，而不需要依赖搜索。这一代数基础为机器智能提供了新的视角，包括直接从训练数据进行学习、避免验证数据集的需求、通过模型可加性进行扩展以及渐近收敛到数据的基本规则。 

---
# Flexible Bivariate Beta Mixture Model: A Probabilistic Approach for Clustering Complex Data Structures 

**Title (ZH)**: 灵活的双变量beta混合模型：一种用于聚类复杂数据结构的概率方法 

**Authors**: Yung-Peng Hsu, Hung-Hsuan Chen  

**Link**: [PDF](https://arxiv.org/pdf/2502.19938)  

**Abstract**: Clustering is essential in data analysis and machine learning, but traditional algorithms like $k$-means and Gaussian Mixture Models (GMM) often fail with nonconvex clusters. To address the challenge, we introduce the Flexible Bivariate Beta Mixture Model (FBBMM), which utilizes the flexibility of the bivariate beta distribution to handle diverse and irregular cluster shapes. Using the Expectation Maximization (EM) algorithm and Sequential Least Squares Programming (SLSQP) optimizer for parameter estimation, we validate FBBMM on synthetic and real-world datasets, demonstrating its superior performance in clustering complex data structures, offering a robust solution for big data analytics across various domains. We release the experimental code at this https URL. 

**Abstract (ZH)**: 聚类在数据分析和机器学习中至关重要，但传统的算法如$k$-均值和高斯混合模型（GMM）往往难以处理非凸聚类。为应对这一挑战，我们引入了灵活的双变量贝塔混合模型（FBBMM），该模型利用双变量贝塔分布的灵活性来处理多种多样且不规则的聚类形状。通过使用期望最大化（EM）算法和序列二次规划（SLSQP）优化器进行参数估计，我们在合成和真实数据集上验证了FBBMM，展示了其在聚类复杂数据结构方面的优越性能，提供了一个在各个领域中进行大数据分析的 robust 解决方案。我们已在以下链接处发布了实验代码：[此 https URL](此 https URL)。 

---
# Lotus at SemEval-2025 Task 11: RoBERTa with Llama-3 Generated Explanations for Multi-Label Emotion Classification 

**Title (ZH)**: Lotus 在 SemEval-2025 任务 11 中的方法：使用 Llama-3 生成的解释进行多标签情绪分类 

**Authors**: Niloofar Ranjbar, Hamed Baghbani  

**Link**: [PDF](https://arxiv.org/pdf/2502.19935)  

**Abstract**: This paper presents a novel approach for multi-label emotion detection, where Llama-3 is used to generate explanatory content that clarifies ambiguous emotional expressions, thereby enhancing RoBERTa's emotion classification performance. By incorporating explanatory context, our method improves F1-scores, particularly for emotions like fear, joy, and sadness, and outperforms text-only models. The addition of explanatory content helps resolve ambiguity, addresses challenges like overlapping emotional cues, and enhances multi-label classification, marking a significant advancement in emotion detection tasks. 

**Abstract (ZH)**: 本文提出了一种新的多标签情绪检测方法，其中使用Llama-3生成解释性内容以澄清模糊的情绪表达，从而提高RoBERTa的情绪分类性能。通过引入解释性上下文，我们的方法在恐惧、喜悦和悲伤等情绪上的F1分数得到了显著提升，并且在文本模型之上表现出更优的效果。增加解释性内容有助于解决模糊性，应对如情绪线索重叠等挑战，并提升多标签分类性能，标志着情绪检测任务中的一个重要进步。 

---
# DiffCSS: Diverse and Expressive Conversational Speech Synthesis with Diffusion Models 

**Title (ZH)**: DiffCSS：基于扩散模型的多样且表达丰富的对话式语音合成 

**Authors**: Weihao wu, Zhiwei Lin, Yixuan Zhou, Jingbei Li, Rui Niu, Qinghua Wu, Songjun Cao, Long Ma, Zhiyong Wu  

**Link**: [PDF](https://arxiv.org/pdf/2502.19924)  

**Abstract**: Conversational speech synthesis (CSS) aims to synthesize both contextually appropriate and expressive speech, and considerable efforts have been made to enhance the understanding of conversational context. However, existing CSS systems are limited to deterministic prediction, overlooking the diversity of potential responses. Moreover, they rarely employ language model (LM)-based TTS backbones, limiting the naturalness and quality of synthesized speech. To address these issues, in this paper, we propose DiffCSS, an innovative CSS framework that leverages diffusion models and an LM-based TTS backbone to generate diverse, expressive, and contextually coherent speech. A diffusion-based context-aware prosody predictor is proposed to sample diverse prosody embeddings conditioned on multimodal conversational context. Then a prosody-controllable LM-based TTS backbone is developed to synthesize high-quality speech with sampled prosody embeddings. Experimental results demonstrate that the synthesized speech from DiffCSS is more diverse, contextually coherent, and expressive than existing CSS systems 

**Abstract (ZH)**: 对话合成（Conversational Speech Synthesis, CSS）的目标是生成既符合上下文又富有表现力的语音。在增强对对话上下文的理解方面，已经做出了显著的努力。然而，现有的CSS系统主要局限于确定性的预测，忽视了潜在回应的多样性。此外，它们很少采用基于语言模型（Language Model, LM）的合成语音技术（Text-to-Speech, TTS）框架，这限制了生成语音的自然性和质量。为了解决这些问题，本文提出了一种创新的CSS框架——DiffCSS，该框架结合了扩散模型和基于LM的TTS骨架，以生成多样、富有表现力且上下文连贯的语音。提出了一种基于扩散模型的上下文感知韵律预测器，用于在多模态对话上下文中条件采样多样韵律嵌入。然后开发了一种韵律可控的基于LM的TTS骨架，以生成具有采样韵律嵌入的高质量语音。实验结果表明，DiffCSS生成的语音比现有CSS系统更加多样、上下文连贯且富有表现力。 

---
# Incremental Learning with Repetition via Pseudo-Feature Projection 

**Title (ZH)**: 通过伪特征投影实现重复驱动的增量学习 

**Authors**: Benedikt Tscheschner, Eduardo Veas, Marc Masana  

**Link**: [PDF](https://arxiv.org/pdf/2502.19922)  

**Abstract**: Incremental Learning scenarios do not always represent real-world inference use-cases, which tend to have less strict task boundaries, and exhibit repetition of common classes and concepts in their continual data stream. To better represent these use-cases, new scenarios with partial repetition and mixing of tasks are proposed, where the repetition patterns are innate to the scenario and unknown to the strategy. We investigate how exemplar-free incremental learning strategies are affected by data repetition, and we adapt a series of state-of-the-art approaches to analyse and fairly compare them under both settings. Further, we also propose a novel method (Horde), able to dynamically adjust an ensemble of self-reliant feature extractors, and align them by exploiting class repetition. Our proposed exemplar-free method achieves competitive results in the classic scenario without repetition, and state-of-the-art performance in the one with repetition. 

**Abstract (ZH)**: 增量学习场景并不总是反映真实世界推理应用场景的特点，后者倾向于任务边界较不严格，持续的数据流中会重复出现常见类和概念。为了更好地反映这些应用场景，本文提出了新的场景，其中包含部分重复和任务混合的情景，且这些重复模式是内在的，对策略而言是未知的。我们研究了无示例的增量学习策略在数据重复条件下的表现，并将一系列最先进的方法适应和公平地比较它们在两类情景下的性能。此外，我们还提出了一种新方法（Horde），该方法能够动态调整一组自我依赖的特征提取器，并通过利用类别重复来对齐它们。我们提出的无示例方法在无重复的经典情景中达到了竞争性的结果，并在有重复的情景中达到了最先进的性能。 

---
# Shared Autonomy for Proximal Teaching 

**Title (ZH)**: proximity 教学中的共自主决策 

**Authors**: Megha Srivastava, Reihaneh Iranmanesh, Yuchen Cui, Deepak Gopinath, Emily Sumner, Andrew Silva, Laporsha Dees, Guy Rosman, Dorsa Sadigh  

**Link**: [PDF](https://arxiv.org/pdf/2502.19899)  

**Abstract**: Motor skill learning often requires experienced professionals who can provide personalized instruction. Unfortunately, the availability of high-quality training can be limited for specialized tasks, such as high performance racing. Several recent works have leveraged AI-assistance to improve instruction of tasks ranging from rehabilitation to surgical robot tele-operation. However, these works often make simplifying assumptions on the student learning process, and fail to model how a teacher's assistance interacts with different individuals' abilities when determining optimal teaching strategies. Inspired by the idea of scaffolding from educational psychology, we leverage shared autonomy, a framework for combining user inputs with robot autonomy, to aid with curriculum design. Our key insight is that the way a student's behavior improves in the presence of assistance from an autonomous agent can highlight which sub-skills might be most ``learnable'' for the student, or within their Zone of Proximal Development. We use this to design Z-COACH, a method for using shared autonomy to provide personalized instruction targeting interpretable task sub-skills. In a user study (n=50), where we teach high performance racing in a simulated environment of the Thunderhill Raceway Park with the CARLA Autonomous Driving simulator, we show that Z-COACH helps identify which skills each student should first practice, leading to an overall improvement in driving time, behavior, and smoothness. Our work shows that increasingly available semi-autonomous capabilities (e.g. in vehicles, robots) can not only assist human users, but also help *teach* them. 

**Abstract (ZH)**: 运动技能学习往往需要经验丰富的专业人员提供个性化的指导。然而，对于像高性能赛车这样的专门任务，高质量的训练机会可能有限。近年来，一些研究工作利用人工智能辅助来改善从康复到手术机器人远程操作等任务的教学。然而，这些工作往往在学生的学习过程上做出简化假设，并未能建模教师辅助与不同个体能力的互动对最佳教学策略的确定方式。受教育心理学中支架式教学的概念启发，我们利用协同自主，一种结合用户输入与机器人自主性的框架，来辅助课程设计。我们的核心见解是，当学生在自主代理提供的辅助下行为改进时，这可以突出哪些子技能可能对每个学生来说最容易“学习”，或者在他们的最近发展区。我们利用这一点设计了Z-COACH方法，该方法用于使用协同自主提供针对可解释任务子技能的个性化教学。在一项用户研究中（n=50），我们使用CARLA自动驾驶模拟器在Thunderhill赛车场公园的模拟环境中教授高性能赛车，结果显示Z-COACH有助于确定每个学生首先应该练习哪些技能，从而整体上提高了驾驶时间、行为和流畅性。我们的研究展示了日益普及的半自主能力（如在车辆、机器人中）不仅可以帮助人类用户，还可以帮助他们*学习*。 

---
# ColorDynamic: Generalizable, Scalable, Real-time, End-to-end Local Planner for Unstructured and Dynamic Environments 

**Title (ZH)**: ColorDynamic: 具有通用性、可扩展性、实时性和端到端集成的非结构化和动态环境的局部规划器 

**Authors**: Jinghao Xin, Zhichao Liang, Zihuan Zhang, Peng Wang, Ning Li  

**Link**: [PDF](https://arxiv.org/pdf/2502.19892)  

**Abstract**: Deep Reinforcement Learning (DRL) has demonstrated potential in addressing robotic local planning problems, yet its efficacy remains constrained in highly unstructured and dynamic environments. To address these challenges, this study proposes the ColorDynamic framework. First, an end-to-end DRL formulation is established, which maps raw sensor data directly to control commands, thereby ensuring compatibility with unstructured environments. Under this formulation, a novel network, Transqer, is introduced. The Transqer enables online DRL learning from temporal transitions, substantially enhancing decision-making in dynamic scenarios. To facilitate scalable training of Transqer with diverse data, an efficient simulation platform E-Sparrow, along with a data augmentation technique leveraging symmetric invariance, are developed. Comparative evaluations against state-of-the-art methods, alongside assessments of generalizability, scalability, and real-time performance, were conducted to validate the effectiveness of ColorDynamic. Results indicate that our approach achieves a success rate exceeding 90% while exhibiting real-time capacity (1.2-1.3 ms per planning). Additionally, ablation studies were performed to corroborate the contributions of individual components. Building on this, the OkayPlan-ColorDynamic (OPCD) navigation system is presented, with simulated and real-world experiments demonstrating its superiority and applicability in complex scenarios. The codebase and experimental demonstrations have been open-sourced on our website to facilitate reproducibility and further research. 

**Abstract (ZH)**: 深度强化学习（DRL）在解决机器人局部规划问题方面展现了潜力，但在高度未结构化和动态环境中仍受到限制。为应对这些挑战，本研究提出了ColorDynamic框架。首先，我们建立了一个端到端的DRL框架，将原始传感器数据直接映射到控制命令，从而确保其与未结构化环境的兼容性。在此框架下，引入了一个新型网络Transqer。Transqer能够在线从时间过渡中进行强化学习，大幅提升了动态场景下的决策能力。为了促进Transqer的可扩展训练，我们开发了一个高效的模拟平台E-Sparrow，并结合对称不变性实现数据增强技术。我们对ColorDynamic进行了与最先进的方法的对比评估，并对其泛化能力、可扩展性和实时性能进行了测试，以验证其有效性。结果表明，我们的方法在规划成功率达到90%以上的同时，具有实时能力（每规划1.2-1.3毫秒）。此外，我们还进行了消融研究，以验证各个组件的贡献。基于此，我们提出了OkayPlan-ColorDynamic (OPCD) 导航系统，在模拟和实际场景中的实验均证明了其在复杂场景中的优越性和适用性。我们的代码基础和实验演示已开源在我们的网站上，旨在促进可重复性和进一步的研究。 

---
# Beyond the Tip of Efficiency: Uncovering the Submerged Threats of Jailbreak Attacks in Small Language Models 

**Title (ZH)**: 超越效率的极限：揭示小语言模型中被掩蔽的 Jailbreak 攻击威胁 

**Authors**: Sibo Yi, Tianshuo Cong, Xinlei He, Qi Li, Jiaxing Song  

**Link**: [PDF](https://arxiv.org/pdf/2502.19883)  

**Abstract**: Small language models (SLMs) have become increasingly prominent in the deployment on edge devices due to their high efficiency and low computational cost. While researchers continue to advance the capabilities of SLMs through innovative training strategies and model compression techniques, the security risks of SLMs have received considerably less attention compared to large language models (LLMs).To fill this gap, we provide a comprehensive empirical study to evaluate the security performance of 13 state-of-the-art SLMs under various jailbreak attacks. Our experiments demonstrate that most SLMs are quite susceptible to existing jailbreak attacks, while some of them are even vulnerable to direct harmful this http URL address the safety concerns, we evaluate several representative defense methods and demonstrate their effectiveness in enhancing the security of SLMs. We further analyze the potential security degradation caused by different SLM techniques including architecture compression, quantization, knowledge distillation, and so on. We expect that our research can highlight the security challenges of SLMs and provide valuable insights to future work in developing more robust and secure SLMs. 

**Abstract (ZH)**: 小语言模型（SLMs）由于其高效率和低计算成本，在边缘设备上的部署日益成为热点。尽管研究人员通过创新的训练策略和模型压缩技术不断提升SLMs的能力，但与大型语言模型（LLMs）相比，SLMs的安全风险问题得到了较少的关注。为填补这一空白，我们提供了一项全面的经验性研究，评估了13种最先进的SLMs在各种 Jailbreak 攻击下的安全性能。我们的实验结果表明，大多数SLMs对现有的Jailbreak攻击非常敏感，甚至有些模型直接暴露于潜在的危害中。鉴于这些问题，我们评估了几种代表性的防御方法，并展示了它们在增强SLMs安全性方面的有效性。我们进一步分析了不同SLM技术（包括架构压缩、量化、知识蒸馏等）可能引起的潜在安全降级问题。我们期望我们的研究能突出SLMs所面临的安全挑战，并为未来开发更 robust 和安全的SLMs提供有价值的见解。 

---
# MIND: Towards Immersive Psychological Healing with Multi-agent Inner Dialogue 

**Title (ZH)**: MIND：迈向基于多代理内心对话的沉浸式心理治愈 

**Authors**: Yujia Chen, Changsong Li, Yiming Wang, Qingqing Xiao, Nan Zhang, Zifan Kong, Peng Wang, Binyu Yan  

**Link**: [PDF](https://arxiv.org/pdf/2502.19860)  

**Abstract**: Mental health issues are worsening in today's competitive society, such as depression and anxiety. Traditional healings like counseling and chatbots fail to engage effectively, they often provide generic responses lacking emotional depth. Although large language models (LLMs) have the potential to create more human-like interactions, they still struggle to capture subtle emotions. This requires LLMs to be equipped with human-like adaptability and warmth. To fill this gap, we propose the MIND (Multi-agent INner Dialogue), a novel paradigm that provides more immersive psychological healing environments. Considering the strong generative and role-playing ability of LLM agents, we predefine an interactive healing framework and assign LLM agents different roles within the framework to engage in interactive inner dialogues with users, thereby providing an immersive healing experience. We conduct extensive human experiments in various real-world healing dimensions, and find that MIND provides a more user-friendly experience than traditional paradigms. This demonstrates that MIND effectively leverages the significant potential of LLMs in psychological healing. 

**Abstract (ZH)**: 现代社会的竞争加剧导致心理健康问题愈发严重，如抑郁症和焦虑症等。传统的治疗方法，如咨询和聊天机器人，往往无法有效吸引患者，它们提供的往往是缺乏情感深度的通用回复。尽管大型语言模型（LLMs）具有创造更加人性化的互动的可能性，但它们仍然难以捕捉到细微的情感变化。这就需要LLMs具备类似人类的适应能力和温暖感。为了解决这一问题，我们提出了一种名为MIND（Multi-agent INner Dialogue，多代理内心对话）的新范式，为用户提供更加沉浸式的心灵治愈环境。考虑到LLM代理的强大生成能力和角色扮演能力，我们预先定义了一个互动治愈框架，并在框架中赋予不同角色的LLM代理不同的任务，使其能够与用户进行互动内心对话，从而提供更加沉浸式的治愈体验。我们进行了广泛的人类实验，涉及各种实际治疗领域，结果发现MIND比传统的范式提供了更加用户友好的体验。这表明，MIND有效地利用了LLMs在心理治疗方面的重要潜力。 

---
# ConvCodeWorld: Benchmarking Conversational Code Generation in Reproducible Feedback Environments 

**Title (ZH)**: ConvCodeWorld: 在可重复反馈环境中对话式代码生成的基准测试 

**Authors**: Hojae Han, Seung-won Hwang, Rajhans Samdani, Yuxiong He  

**Link**: [PDF](https://arxiv.org/pdf/2502.19852)  

**Abstract**: Large language models (LLMs) have proven invaluable for code generation, particularly in interactive settings. However, existing code generation benchmarks fail to capture the diverse feedback encountered in multi-turn interactions, limiting our ability to evaluate LLMs in these contexts. To address this gap, we present a set of novel benchmarks that explicitly model the quality of feedback provided to code generation LLMs. Our contributions are threefold: First, we introduce CONVCODEWORLD, a novel and reproducible environment for benchmarking interactive code generation. CONVCODEWORLD simulates 9 distinct interactive code generation scenarios while systematically combining three types of feedback: (a) compilation feedback; (b) execution feedback with varying test coverage; (c) verbal feedback generated by GPT-4o with different levels of expertise. Second, we introduce CONVCODEBENCH, a fast, static version of benchmark that uses pre-generated feedback logs, eliminating the need for costly dynamic verbal feedback generation while maintaining strong Spearman's rank correlations (0.82 to 0.99) with CONVCODEWORLD. Third, extensive evaluations of both closed-source and open-source LLMs including R1-Distill on CONVCODEWORLD reveal key insights: (a) LLM performance varies significantly based on the feedback provided; (b) Weaker LLMs, with sufficient feedback, can outperform single-turn results of state-of-the-art LLMs without feedback; (c) Training on a specific feedback combination can limit an LLM's ability to utilize unseen combinations; (d) LLMs solve problems in fewer turns (high MRR) may not solve as many problems overall (high Recall), and vice versa. All implementations and benchmarks will be made publicly available at this https URL 

**Abstract (ZH)**: 大型语言模型（LLMs）在代码生成方面表现出色，特别是在交互式环境中。然而，现有的代码生成基准测试无法捕捉到多轮交互中遇到的多样化反馈，限制了我们评估LLMs在这种情境下的能力。为解决这一问题，我们提出了一组新型基准测试，明确地建模了反馈质量对代码生成LLMs的影响。我们的贡献包括三个方面：

首先，我们引入了CONVCODEWORLD，这是一个新型且可复现的交互式代码生成基准测试环境。CONVCODEWORLD模拟了9种独特的交互式代码生成场景，系统地结合了三种类型的反馈：（a）编译反馈；（b）不同覆盖率的执行反馈；（c）由GPT-4o生成的不同专业水平的心理反馈。

其次，我们引入了CONVCODEBENCH，这是一个快速的静态基准测试版本，使用预生成的反馈日志，消除了昂贵的心理反馈生成的需要，同时保持了与CONVCODEWORLD高度相关（Spearman秩相关系数范围为0.82到0.99）的结果。

第三，对封闭源代码和开源LLMs（包括R1-Distill）在CONVCODEWORLD上的广泛评估揭示了关键见解：（a）LLMs的表现基于提供的反馈显著不同；（b）有足够反馈的较弱LLMs可以超越未使用反馈的最先进的单一轮次LLMs；（c）针对特定反馈组合的训练可能会限制LLMs利用未见过的组合的能力；（d）解决相同问题的轮次较少（高MRR），但解决不同问题的能力较低（高召回率），反之亦然。

所有实现和基准测试将公开发布，具体地址为：[此处插入链接]。

请注意，在提供此翻译时，格式可能需要调整以确保符合目标文档的要求。请根据实际情况调整排版和格式。 

---
# Revisiting Self-Consistency from Dynamic Distributional Alignment Perspective on Answer Aggregation 

**Title (ZH)**: 从动态分布对齐视角 revisiting 自洽性：关于答案聚合的研究 

**Authors**: Yiwei Li, Ji Zhang, Shaoxiong Feng, Peiwen Yuan, Xinglin Wang, Jiayi Shi, Yueqi Zhang, Chuyi Tan, Boyuan Pan, Yao Hu, Kan Li  

**Link**: [PDF](https://arxiv.org/pdf/2502.19830)  

**Abstract**: Self-consistency improves reasoning by aggregating diverse stochastic samples, yet the dynamics behind its efficacy remain underexplored. We reframe self-consistency as a dynamic distributional alignment problem, revealing that decoding temperature not only governs sampling randomness but also actively shapes the latent answer distribution. Given that high temperatures require prohibitively large sample sizes to stabilize, while low temperatures risk amplifying biases, we propose a confidence-driven mechanism that dynamically calibrates temperature: sharpening the sampling distribution under uncertainty to align with high-probability modes, and promoting exploration when confidence is high. Experiments on mathematical reasoning tasks show this approach outperforms fixed-diversity baselines under limited samples, improving both average and best-case performance across varying initial temperatures without additional data or modules. This establishes self-consistency as a synchronization challenge between sampling dynamics and evolving answer distributions. 

**Abstract (ZH)**: 自我一致性通过聚合多样化的随机样本来提升推理能力，但其有效性的动态机制仍待深入探索。我们将自我一致性重新框定为一种动态的分布对齐问题，揭示出解码温度不仅控制着采样随机性，还积极塑造潜在答案的分布。鉴于高温需要巨大的样本量才能稳定，而低温则可能放大偏差，我们提出了一种基于信心的机制，该机制动态校准温度：在不确定性时强化采样分布以与高概率模式对齐，并在信心高时促进探索。在数学推理任务上的实验表明，该方法在有限样本下优于固定多样性的基线方法，并且在不同初始温度下都能改善平均和最佳性能，无需额外数据或模块。这确立了自我一致性是一种采样动态与演化答案分布之间的同步挑战。 

---
# GraphSparseNet: a Novel Method for Large Scale Trafffic Flow Prediction 

**Title (ZH)**: GraphSparseNet：一种新型大规模交通流预测方法 

**Authors**: Weiyang Kong, Kaiqi Wu, Sen Zhang, Yubao Liu  

**Link**: [PDF](https://arxiv.org/pdf/2502.19823)  

**Abstract**: Traffic flow forecasting is a critical spatio-temporal data mining task with wide-ranging applications in intelligent route planning and dynamic traffic management. Recent advancements in deep learning, particularly through Graph Neural Networks (GNNs), have significantly enhanced the accuracy of these forecasts by capturing complex spatio-temporal dynamics. However, the scalability of GNNs remains a challenge due to their exponential growth in model complexity with increasing nodes in the graph. Existing methods to address this issue, including sparsification, decomposition, and kernel-based approaches, either do not fully resolve the complexity issue or risk compromising predictive accuracy. This paper introduces GraphSparseNet (GSNet), a novel framework designed to improve both the scalability and accuracy of GNN-based traffic forecasting models. GraphSparseNet is comprised of two core modules: the Feature Extractor and the Relational Compressor. These modules operate with linear time and space complexity, thereby reducing the overall computational complexity of the model to a linear scale. Our extensive experiments on multiple real-world datasets demonstrate that GraphSparseNet not only significantly reduces training time by 3.51x compared to state-of-the-art linear models but also maintains high predictive performance. 

**Abstract (ZH)**: 交通流量 forecasting 是一项关键的时空数据挖掘任务，广泛应用于智能路径规划和动态交通管理中。最近在深度学习领域，尤其是通过图神经网络（GNNs）的发展，已经显著提高了这些预测的准确性，通过捕获复杂的时空动态。然而，GNNs 的可扩展性仍然是一个挑战，因为它们随图中节点数量增加而呈现出指数级复杂度的增长。现有的解决这个问题的方法，包括稀疏化、分解和核基方法，要么没有充分解决复杂性问题，要么可能会牺牲预测准确性。本文提出了 GraphSparseNet（GSNet），这是一种新的框架，旨在改进基于 GNN 的交通流量预测模型的可扩展性和准确性。GraphSparseNet 包含两个核心模块：特征提取器和关系压缩器。这两个模块具有线性的时间和空间复杂度，从而将模型的整体计算复杂度降低到线性级别。我们对多个实际数据集的广泛实验表明，GraphSparseNet 不仅将训练时间显著降低至先进线性模型的 3.51 倍，还保持了高度的预测性能。 

---
# Foot-In-The-Door: A Multi-turn Jailbreak for LLMs 

**Title (ZH)**: 脚踏门槛：LLMs的多轮脱困方法 

**Authors**: Zixuan Weng, Xiaolong Jin, Jinyuan Jia, Xiangyu Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2502.19820)  

**Abstract**: Ensuring AI safety is crucial as large language models become increasingly integrated into real-world applications. A key challenge is jailbreak, where adversarial prompts bypass built-in safeguards to elicit harmful disallowed outputs. Inspired by psychological foot-in-the-door principles, we introduce FITD,a novel multi-turn jailbreak method that leverages the phenomenon where minor initial commitments lower resistance to more significant or more unethical this http URL approach progressively escalates the malicious intent of user queries through intermediate bridge prompts and aligns the model's response by itself to induce toxic responses. Extensive experimental results on two jailbreak benchmarks demonstrate that FITD achieves an average attack success rate of 94% across seven widely used models, outperforming existing state-of-the-art methods. Additionally, we provide an in-depth analysis of LLM self-corruption, highlighting vulnerabilities in current alignment strategies and emphasizing the risks inherent in multi-turn this http URL code is available at this https URL . 

**Abstract (ZH)**: 确保人工智能安全至关重要，因为大型语言模型正在越来越多地集成到实际应用中。一个关键的挑战是“监狱突破”问题，即恶意提示绕过了内置的安全措施，引出了有害的禁止输出。借鉴心理学中的“踏门槛效应”原理，我们提出了一种新颖的多轮次监狱突破方法FITD，该方法利用初始的小规模承诺会降低个体对后续更大或更不道德承诺的抵制效果这一现象。通过中间的桥梁提示逐步升级用户的恶意意图，并使模型通过自身调整来诱导产生有毒响应。在两个监狱突破基准上的大规模实验结果表明，FITD在七个广泛使用的模型上实现了平均攻击成功率94%，优于现有最先进的方法。此外，我们还深入分析了LLM自我腐蚀问题，指出了当前对齐策略中存在的漏洞，并强调了多轮次这一过程固有的风险。相关代码可在此处访问：[提供代码链接]。 

---
# Comet: Fine-grained Computation-communication Overlapping for Mixture-of-Experts 

**Title (ZH)**: 彗星：专家混合模型中的细粒度计算-通信Overlap 

**Authors**: Shulai Zhang, Ningxin Zheng, Haibin Lin, Ziheng Jiang, Wenlei Bao, Chengquan Jiang, Qi Hou, Weihao Cui, Size Zheng, Li-Wen Chang, Quan Chen, Xin Liu  

**Link**: [PDF](https://arxiv.org/pdf/2502.19811)  

**Abstract**: Mixture-of-experts (MoE) has been extensively employed to scale large language models to trillion-plus parameters while maintaining a fixed computational cost. The development of large MoE models in the distributed scenario encounters the problem of large communication overhead. The inter-device communication of a MoE layer can occupy 47% time of the entire model execution with popular models and frameworks. Therefore, existing methods suggest the communication in a MoE layer to be pipelined with the computation for overlapping. However, these coarse grained overlapping schemes introduce a notable impairment of computational efficiency and the latency concealing is sub-optimal.
To this end, we present COMET, an optimized MoE system with fine-grained communication-computation overlapping. Leveraging data dependency analysis and task rescheduling, COMET achieves precise fine-grained overlapping of communication and computation. Through adaptive workload assignment, COMET effectively eliminates fine-grained communication bottlenecks and enhances its adaptability across various scenarios. Our evaluation shows that COMET accelerates the execution of a single MoE layer by $1.96\times$ and for end-to-end execution, COMET delivers a $1.71\times$ speedup on average. COMET has been adopted in the production environment of clusters with ten-thousand-scale of GPUs, achieving savings of millions of GPU hours. 

**Abstract (ZH)**: 混合专家模型（MoE）已被广泛应用于将大规模语言模型扩展到万亿及以上参数，同时保持固定的计算成本。在分布式场景下开发大规模MoE模型遇到了巨大的通信开销问题。一个MoE层的跨设备通信可能占据整个模型执行时间的47%。因此，现有方法建议将MoE层的通信与计算流水线化，以实现重叠。然而，这些粗粒度的重叠方案会显著降低计算效率，且通信延时的隐藏效果也很差。

为了解决上述问题，我们提出了COMET，这是一种具有精细粒度通信-计算重叠优化的MoE系统。通过数据依赖性分析和任务重调度，COMET实现了精确的精细粒度重叠。通过自适应工作负载分配，COMET有效地消除了精细粒度的通信瓶颈，并增强了其在各种场景中的适应性。我们的评估表明，COMET将单个MoE层的执行速度提升了1.96倍，而端到端执行时，COMET平均提升了1.71倍的速度。COMET已经在包含数千张GPU的集群生产环境中采用，实现了数百万GPU小时的节支。 

---
# Implicit Search via Discrete Diffusion: A Study on Chess 

**Title (ZH)**: 通过离散扩散进行隐式搜索：以国际象棋为例的研究 

**Authors**: Jiacheng Ye, Zhenyu Wu, Jiahui Gao, Zhiyong Wu, Xin Jiang, Zhenguo Li, Lingpeng Kong  

**Link**: [PDF](https://arxiv.org/pdf/2502.19805)  

**Abstract**: In the post-AlphaGo era, there has been a renewed interest in search techniques such as Monte Carlo Tree Search (MCTS), particularly in their application to Large Language Models (LLMs). This renewed attention is driven by the recognition that current next-token prediction models often lack the ability for long-term planning. Is it possible to instill search-like abilities within the models to enhance their planning abilities without relying on explicit search? We propose DiffuSearch , a model that does \textit{implicit search} by looking into the future world via discrete diffusion modeling. We instantiate DiffuSearch on a classical board game, Chess, where explicit search is known to be essential. Through extensive controlled experiments, we show DiffuSearch outperforms both the searchless and explicit search-enhanced policies. Specifically, DiffuSearch outperforms the one-step policy by 19.2% and the MCTS-enhanced policy by 14% on action accuracy. Furthermore, DiffuSearch demonstrates a notable 30% enhancement in puzzle-solving abilities compared to explicit search-based policies, along with a significant 540 Elo increase in game-playing strength assessment. These results indicate that implicit search via discrete diffusion is a viable alternative to explicit search over a one-step policy. All codes are publicly available at \href{this https URL}{this https URL}. 

**Abstract (ZH)**: 在AlphaGo之后的时代，对搜索技术，特别是蒙特卡洛树搜索（MCTS）的应用，尤其是在大型语言模型（LLMs）中的应用，再次引起了人们的兴趣。这种重新关注的原因在于认识到当前的下一个词预测模型往往缺乏长期规划的能力。是否可以在不依赖显式搜索的情况下，在模型中植入类似搜索的能力，以提高其规划能力？我们提出了一种名为DiffuSearch的模型，它通过离散扩散建模来实现“隐式搜索”，即通过展望未来的世界来进行搜索。我们将在经典的棋盘游戏国际象棋上实例化DiffuSearch，众所周知，在国际象棋中进行显式搜索是必不可少的。通过大量的受控实验，我们展示了DiffuSearch在行动准确率上优于无搜索策略和增强搜索策略的政策。具体来说，DiffuSearch在行动准确率上分别优于一步政策19.2%和MCTS增强策略14%。此外，DiffuSearch在解谜能力上表现出显著的30%的提升，与基于显式搜索的策略相比，在棋局下棋实力评估中提升了540 Elo分数。这些结果表明，通过离散扩散实现的隐式搜索是替代一项策略中显式搜索的有效替代方案。所有代码均已公开，可访问此处：[这个链接](this https URL)。 

---
# Mixtera: A Data Plane for Foundation Model Training 

**Title (ZH)**: Mixtera：一种大规模预训练模型训练的数据平面设计 

**Authors**: Maximilian Böther, Xiaozhe Yao, Tolga Kerimoglu, Ana Klimovic  

**Link**: [PDF](https://arxiv.org/pdf/2502.19790)  

**Abstract**: State-of-the-art large language and vision models are trained over trillions of tokens that are aggregated from a large variety of sources. As training data collections grow, manually managing the samples becomes time-consuming, tedious, and prone to errors. Yet recent research shows that the data mixture and the order in which samples are visited during training can significantly influence model accuracy. We build and present Mixtera, a data plane for foundation model training that enables users to declaratively express which data samples should be used in which proportion and in which order during training. Mixtera is a centralized, read-only layer that is deployed on top of existing training data collections and can be declaratively queried. It operates independently of the filesystem structure and supports mixtures across arbitrary properties (e.g., language, source dataset) as well as dynamic adjustment of the mixture based on model feedback. We experimentally evaluate Mixtera and show that our implementation does not bottleneck training and scales to 256 GH200 superchips. We demonstrate how Mixtera supports recent advancements in mixing strategies by implementing the proposed Adaptive Data Optimization (ADO) algorithm in the system and evaluating its performance impact. We also explore the role of mixtures for vision-language models. 

**Abstract (ZH)**: 当前最先进的大型语言和视觉模型是基于数十万亿个令牌训练的，这些令牌来源于多种多样的来源。随着训练数据集合的增长，手动管理样本变得耗时、繁琐且容易出错。然而，最近的研究表明，在训练过程中样本的使用混合方式及其访问顺序会对模型准确性产生显著影响。我们构建并展示了Mixtera，一种用于基础模型训练的数据平面，它使用户能够声明性地表达在训练过程中应使用哪些数据样本、以及这些样本应以何种比例和顺序使用。Mixtera 是一个中心化且只读的层，部署在现有的训练数据集合之上，并且可以通过声明性查询对其进行查询。它独立于文件系统结构，并支持跨任意属性（例如，语言、源数据集）的数据混合，同时也支持根据模型反馈动态调整混合比例。我们实验性地评估了Mixtera，并展示了我们的实现不会阻碍训练且能够扩展到256个GH200超级芯片。我们展示了Mixtera如何支持最近在混合策略方面的进展，通过在系统中实现并评估提出的自适应数据优化（ADO）算法来证明其性能影响。我们还探讨了混合在视觉语言模型中的作用。 

---
# NaijaNLP: A Survey of Nigerian Low-Resource Languages 

**Title (ZH)**: NaijaNLP：尼日利亚低资源语言综述 

**Authors**: Isa Inuwa-Dutse  

**Link**: [PDF](https://arxiv.org/pdf/2502.19784)  

**Abstract**: With over 500 languages in Nigeria, three languages -- Hausa, Yorùbá and Igbo -- spoken by over 175 million people, account for about 60% of the spoken languages. However, these languages are categorised as low-resource due to insufficient resources to support tasks in computational linguistics. Several research efforts and initiatives have been presented, however, a coherent understanding of the state of Natural Language Processing (NLP) - from grammatical formalisation to linguistic resources that support complex tasks such as language understanding and generation is lacking. This study presents the first comprehensive review of advancements in low-resource NLP (LR-NLP) research across the three major Nigerian languages (NaijaNLP). We quantitatively assess the available linguistic resources and identify key challenges. Although a growing body of literature addresses various NLP downstream tasks in Hausa, Igbo, and Yorùbá, only about 25.1% of the reviewed studies contribute new linguistic resources. This finding highlights a persistent reliance on repurposing existing data rather than generating novel, high-quality resources. Additionally, language-specific challenges, such as the accurate representation of diacritics, remain under-explored. To advance NaijaNLP and LR-NLP more broadly, we emphasise the need for intensified efforts in resource enrichment, comprehensive annotation, and the development of open collaborative initiatives. 

**Abstract (ZH)**: 尼日利亚拥有超过500种语言，其中 Hausa、Yorùbá 和 Igbo 三种语言被超过1.75亿人使用，约占 spoken 语言的60%。然而，由于支持计算语言学任务所需资源不足，这些语言被归类为低资源语言。尽管已经提出了多项研究努力和倡议，但关于自然语言处理（NLP）的现状——从句法形式化到支持复杂任务（如语言理解和生成）的 linguistics 资源方面，仍缺乏系统性的理解。本文介绍了 NaijaNLP（针对尼日利亚三大语言的低资源 NLP 研究的第一个全面回顾）。我们定量评估了可用的语言资源，并指出了关键挑战。尽管关于 Hausa、Igbo 和 Yorùbá 的各种 NLP 下游任务的研究文献越来越多，但只有大约25.1%的审阅研究贡献了新的语言资源。这一发现凸显了对数据再利用的持久依赖性，而不是生成新颖和高质量的资源。此外，特定于语言的挑战，如准确表示重音符号，仍被忽视。为了推进 NaijaNLP 和更广泛的 LR-NLP，我们强调需要在资源丰富、全面注释和开放合作倡议的发展方面加强努力。 

---
# Do Retrieval-Augmented Language Models Adapt to Varying User Needs? 

**Title (ZH)**: 检索增强语言模型能够适应不同用户需求吗？ 

**Authors**: Peilin Wu, Xinlu Zhang, Wenhao Yu, Xingyu Liu, Xinya Du, Zhiyu Zoey Chen  

**Link**: [PDF](https://arxiv.org/pdf/2502.19779)  

**Abstract**: Recent advancements in Retrieval-Augmented Language Models (RALMs) have demonstrated their efficacy in knowledge-intensive tasks. However, existing evaluation benchmarks often assume a single optimal approach to leveraging retrieved information, failing to account for varying user needs. This paper introduces a novel evaluation framework that systematically assesses RALMs under three user need cases-Context-Exclusive, Context-First, and Memory-First-across three distinct context settings: Context Matching, Knowledge Conflict, and Information Irrelevant. By varying both user instructions and the nature of retrieved information, our approach captures the complexities of real-world applications where models must adapt to diverse user requirements. Through extensive experiments on multiple QA datasets, including HotpotQA, DisentQA, and our newly constructed synthetic URAQ dataset, we find that restricting memory usage improves robustness in adversarial retrieval conditions but decreases peak performance with ideal retrieval results and model family dominates behavioral differences. Our findings highlight the necessity of user-centric evaluations in the development of retrieval-augmented systems and provide insights into optimizing model performance across varied retrieval contexts. We will release our code and URAQ dataset upon acceptance of the paper. 

**Abstract (ZH)**: 近年来，检索增强语言模型（RALMs）在知识密集型任务中的有效性得到了证明。然而，现有的评估基准往往假定存在一种最佳方法来利用检索到的信息，未能考虑用户需求的差异。本文介绍了一个新的评估框架，该框架系统地评估了RALMs在三种用户需求场景下的表现：仅上下文、先上下文后检索和先记忆后检索，这些场景分别在三种不同的上下文设置中进行评估：上下文匹配、知识冲突和信息无关。通过改变用户指令和检索到信息的性质，本文的方法捕捉到了实际应用中的复杂性，其中模型必须适应多样的用户需求。通过在多个问答数据集（包括HotpotQA、DisentQA以及我们新构建的合成URAQ数据集）上进行广泛的实验，我们发现限制内存使用在对抗性检索条件下可以提高鲁棒性，但在理想检索结果的情况下会降低峰值性能，模型家族主导了行为差异。我们的研究结果强调了在开发检索增强系统时进行用户中心评估的必要性，并提供了优化模型在各种检索上下文中的性能的见解。我们将在论文被接受后发布我们的代码和URAQ数据集。 

---
# The erasure of intensive livestock farming in text-to-image generative AI 

**Title (ZH)**: 文本到图像生成人工智能中密集型畜牧业的消失现象 

**Authors**: Kehan Sheng, Frank A.M. Tuyttens, Marina A.G. von Keyserlingk  

**Link**: [PDF](https://arxiv.org/pdf/2502.19771)  

**Abstract**: Generative AI (e.g., ChatGPT) is increasingly integrated into people's daily lives. While it is known that AI perpetuates biases against marginalized human groups, their impact on non-human animals remains understudied. We found that ChatGPT's text-to-image model (DALL-E 3) introduces a strong bias toward romanticizing livestock farming as dairy cows on pasture and pigs rooting in mud. This bias remained when we requested realistic depictions and was only mitigated when the automatic prompt revision was inhibited. Most farmed animal in industrialized countries are reared indoors with limited space per animal, which fail to resonate with societal values. Inhibiting prompt revision resulted in images that more closely reflected modern farming practices; for example, cows housed indoors accessing feed through metal headlocks, and pigs behind metal railings on concrete floors in indoor facilities. While OpenAI introduced prompt revision to mitigate bias, in the case of farmed animal production systems, it paradoxically introduces a strong bias towards unrealistic farming practices. 

**Abstract (ZH)**: 生成式AI（例如ChatGPT）越来越多地融入人们的日常生活中。尽管已知AI会延续对边缘化人类群体的偏见，但其对非人类动物的影响却研究不足。我们发现，ChatGPT的文本转图像模型（DALL-E 3）倾向于将牲畜养殖美化为牧场中的奶牛和在泥泞中拱食的猪，这种偏见在要求其提供真实场景时依然存在，只有在禁止自动提示修订时才有所缓解。在工业化国家中，大多数饲养的动物在室内环境中生长，每只动物的活动空间有限，这与社会价值相悖。禁止提示修订后生成的图像更贴近现代农业实践，例如圈养的奶牛通过金属头环获取饲料，以及圈养在混凝土地面上并配有金属栏杆的猪。虽然OpenAI引入了提示修订以减轻偏见，在农场动物生产体系的情况下，这一做法反而强化了对不切实际的农业生产方式的偏见。 

---
# Obtaining Example-Based Explanations from Deep Neural Networks 

**Title (ZH)**: 从深度神经网络获取基于实例的解释 

**Authors**: Genghua Dong, Henrik Boström, Michalis Vazirgiannis, Roman Bresson  

**Link**: [PDF](https://arxiv.org/pdf/2502.19768)  

**Abstract**: Most techniques for explainable machine learning focus on feature attribution, i.e., values are assigned to the features such that their sum equals the prediction. Example attribution is another form of explanation that assigns weights to the training examples, such that their scalar product with the labels equals the prediction. The latter may provide valuable complementary information to feature attribution, in particular in cases where the features are not easily interpretable. Current example-based explanation techniques have targeted a few model types only, such as k-nearest neighbors and random forests. In this work, a technique for obtaining example-based explanations from deep neural networks (EBE-DNN) is proposed. The basic idea is to use the deep neural network to obtain an embedding, which is employed by a k-nearest neighbor classifier to form a prediction; the example attribution can hence straightforwardly be derived from the latter. Results from an empirical investigation show that EBE-DNN can provide highly concentrated example attributions, i.e., the predictions can be explained with few training examples, without reducing accuracy compared to the original deep neural network. Another important finding from the empirical investigation is that the choice of layer to use for the embeddings may have a large impact on the resulting accuracy. 

**Abstract (ZH)**: 大多数可解释机器学习的技术集中在特征归因上，即为特征分配值，使得这些值的总和等于预测值。另一种形式的解释是根据其标量积与标签等于预测值的方式来为训练实例分配权重。后者在这种特征不易解释的情况下可以提供有价值的补充信息。当前基于实例的解释技术主要针对少数几种模型类型，如K近邻和随机森林。在这项工作中，我们提出了一种从深度神经网络获取基于实例的解释的技术（EBE-DNN）。基本思想是使用深度神经网络获得嵌入，然后使用K近邻分类器生成预测；因此，可以很容易地从后者中导出实例归因。实证研究的结果表明，EBE-DNN可以提供高度集中的实例归因，即可以用少量的训练实例来解释预测结果，同时不会降低与原始深度神经网络相比的准确率。另一个重要的实证发现是，用于嵌入的层的选择可能会对最终的准确率产生重大影响。 

---
# Learning with Exact Invariances in Polynomial Time 

**Title (ZH)**: 在多项式时间内学习具有确切不变性的方法 

**Authors**: Ashkan Soleymani, Behrooz Tahmasebi, Stefanie Jegelka, Patrick Jaillet  

**Link**: [PDF](https://arxiv.org/pdf/2502.19758)  

**Abstract**: We study the statistical-computational trade-offs for learning with exact invariances (or symmetries) using kernel regression. Traditional methods, such as data augmentation, group averaging, canonicalization, and frame-averaging, either fail to provide a polynomial-time solution or are not applicable in the kernel setting. However, with oracle access to the geometric properties of the input space, we propose a polynomial-time algorithm that learns a classifier with \emph{exact} invariances. Moreover, our approach achieves the same excess population risk (or generalization error) as the original kernel regression problem. To the best of our knowledge, this is the first polynomial-time algorithm to achieve exact (not approximate) invariances in this context. Our proof leverages tools from differential geometry, spectral theory, and optimization. A key result in our development is a new reformulation of the problem of learning under invariances as optimizing an infinite number of linearly constrained convex quadratic programs, which may be of independent interest. 

**Abstract (ZH)**: 我们研究了在核回归中利用精确不变性（或对称性）学习的统计-计算权衡问题。传统的方法，如数据增强、群平均、基元化和框架平均，要么无法提供多项式时间的解决方案，要么在核空间设置中不适用。然而，通过获取输入空间几何性质的oracle访问，我们提出了一种多项式时间算法，该算法可以在保持不变性的情况下学习分类器。此外，我们的方法能够达到与原始核回归问题相同的期望总体风险（或泛化误差）。据我们所知，这是第一个在该上下文中实现精确（而非近似）不变性的多项式时间算法。我们的证明利用了微分几何、谱理论和最优化工具。我们开发中的一个重要成果是对在不变性条件下学习问题的一种新表征，将其转化为优化无限多个线性约束的凸二次规划问题，这可能具有独立的研究价值。 

---
# Probabilistic Federated Prompt-Tuning with Non-IID and Imbalanced Data 

**Title (ZH)**: 概率 federated 提示微调方法在非IID和分布不平衡数据上的应用 

**Authors**: Pei-Yau Weng, Minh Hoang, Lam M. Nguyen, My T. Thai, Tsui-Wei Weng, Trong Nghia Hoang  

**Link**: [PDF](https://arxiv.org/pdf/2502.19752)  

**Abstract**: Fine-tuning pre-trained models is a popular approach in machine learning for solving complex tasks with moderate data. However, fine-tuning the entire pre-trained model is ineffective in federated data scenarios where local data distributions are diversely skewed. To address this, we explore integrating federated learning with a more effective prompt-tuning method, optimizing for a small set of input prefixes to reprogram the pre-trained model's behavior. Our approach transforms federated learning into a distributed set modeling task, aggregating diverse sets of prompts to globally fine-tune the pre-trained model. We benchmark various baselines based on direct adaptations of existing federated model aggregation techniques and introduce a new probabilistic prompt aggregation method that substantially outperforms these baselines. Our reported results on a variety of computer vision datasets confirm that the proposed method is most effective to combat extreme data heterogeneity in federated learning. 

**Abstract (ZH)**: 预训练模型的微调是机器学习中解决复杂任务的一种流行方法，尤其是在数据量适中的情况下。然而，在联邦学习场景中，由于局部数据分布存在多样且偏斜的情况，直接对整个预训练模型进行微调是无效的。为了解决这一问题，我们探索了将联邦学习与更有效的提示调优方法相结合的方法，优化一小部分输入前缀以重新编程预训练模型的行为。我们的方法将联邦学习转换为分布式集合建模任务，汇集多样化的提示集合以全局微调预训练模型。我们基于现有联邦模型聚合技术的直接改编设置了多种基线，并引入了一种新的概率提示聚合方法，该方法在这些基线中表现出显著的优越性。我们在多种计算机视觉数据集上的结果表明，所提出的方法在联邦学习中对抗极端数据异质性方面最为有效。 

---
# CNsum:Automatic Summarization for Chinese News Text 

**Title (ZH)**: CNsum：中文新闻文本自动摘要 

**Authors**: Yu Zhao, Songping Huang, Dongsheng Zhou, Zhaoyun Ding, Fei Wang, Aixin Nian  

**Link**: [PDF](https://arxiv.org/pdf/2502.19723)  

**Abstract**: Obtaining valuable information from massive data efficiently has become our research goal in the era of Big Data. Text summarization technology has been continuously developed to meet this demand. Recent work has also shown that transformer-based pre-trained language models have achieved great success on various tasks in Natural Language Processing (NLP). Aiming at the problem of Chinese news text summary generation and the application of Transformer structure on Chinese, this paper proposes a Chinese news text summarization model (CNsum) based on Transformer structure, and tests it on Chinese datasets such as THUCNews. The results of the conducted experiments show that CNsum achieves better ROUGE score than the baseline models, which verifies the outperformance of the model. 

**Abstract (ZH)**: 在大数据时代，从海量数据中高效获取有价值的信息已成为我们的研究目标。文本摘要技术不断进步，以满足这一需求。近年来，基于变换器的预训练语言模型已在自然语言处理（NLP）的各种任务中取得了巨大成功。鉴于中文新闻文本摘要生成的问题以及变换器结构在中文领域的应用，本文提出了一种基于变换器结构的中文新闻文本摘要模型（CNsum），并在THUCNews等中文数据集上进行了测试。实验结果表明，CNsum在ROUGE评分上优于基线模型，验证了该模型的优越性。 

---
# Exponential Topology-enabled Scalable Communication in Multi-agent Reinforcement Learning 

**Title (ZH)**: 基于拓扑结构的指数级可扩展通信在多智能体强化学习中的应用 

**Authors**: Xinran Li, Xiaolu Wang, Chenjia Bai, Jun Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2502.19717)  

**Abstract**: In cooperative multi-agent reinforcement learning (MARL), well-designed communication protocols can effectively facilitate consensus among agents, thereby enhancing task performance. Moreover, in large-scale multi-agent systems commonly found in real-world applications, effective communication plays an even more critical role due to the escalated challenge of partial observability compared to smaller-scale setups. In this work, we endeavor to develop a scalable communication protocol for MARL. Unlike previous methods that focus on selecting optimal pairwise communication links-a task that becomes increasingly complex as the number of agents grows-we adopt a global perspective on communication topology design. Specifically, we propose utilizing the exponential topology to enable rapid information dissemination among agents by leveraging its small-diameter and small-size properties. This approach leads to a scalable communication protocol, named ExpoComm. To fully unlock the potential of exponential graphs as communication topologies, we employ memory-based message processors and auxiliary tasks to ground messages, ensuring that they reflect global information and benefit decision-making. Extensive experiments on large-scale cooperative benchmarks, including MAgent and Infrastructure Management Planning, demonstrate the superior performance and robust zero-shot transferability of ExpoComm compared to existing communication strategies. The code is publicly available at this https URL. 

**Abstract (ZH)**: 在合作多智能体强化学习（MARL）中，精心设计的通信协议可以有效地促进智能体之间的共识，从而提高任务性能。此外，在现实应用中常见的大规模多智能体系统中，由于与小规模设置相比更容易受到部分可观测性的挑战，有效的通信变得更加关键。在此项工作中，我们致力于开发一种可扩展的通信协议，以应对MARL中的通信挑战。不同于以往方法主要集中在选择最优的成对通信连接——随着智能体数量的增长，这项任务变得越来越复杂——我们从全局角度设计通信拓扑结构。具体而言，我们提出了利用指数拓扑结构来通过其直径小和规模小的特性促进快速信息传播。这种方法导致了一个可扩展的通信协议，名为ExpoComm。为了充分发挥指数图作为通信拓扑结构的潜力，我们采用了基于内存的消息处理器和辅助任务来确保消息能够反映全局信息，并促进决策过程。在MAgent和基础设施管理规划等大规模合作基准测试中的广泛实验表明，ExpoComm在现有的通信策略中具有优越的性能和稳健的零样本迁移能力。该代码在本链接公开：https://github.com/your-username/expocomm。 

---
# BEVDiffuser: Plug-and-Play Diffusion Model for BEV Denoising with Ground-Truth Guidance 

**Title (ZH)**: BEVDiffuser：带有地面真实指导的插件式差分模型用于BEV去噪 

**Authors**: Xin Ye, Burhaneddin Yaman, Sheng Cheng, Feng Tao, Abhirup Mallik, Liu Ren  

**Link**: [PDF](https://arxiv.org/pdf/2502.19694)  

**Abstract**: Bird's-eye-view (BEV) representations play a crucial role in autonomous driving tasks. Despite recent advancements in BEV generation, inherent noise, stemming from sensor limitations and the learning process, remains largely unaddressed, resulting in suboptimal BEV representations that adversely impact the performance of downstream tasks. To address this, we propose BEVDiffuser, a novel diffusion model that effectively denoises BEV feature maps using the ground-truth object layout as guidance. BEVDiffuser can be operated in a plug-and-play manner during training time to enhance existing BEV models without requiring any architectural modifications. Extensive experiments on the challenging nuScenes dataset demonstrate BEVDiffuser's exceptional denoising and generation capabilities, which enable significant enhancement to existing BEV models, as evidenced by notable improvements of 12.3\% in mAP and 10.1\% in NDS achieved for 3D object detection without introducing additional computational complexity. Moreover, substantial improvements in long-tail object detection and under challenging weather and lighting conditions further validate BEVDiffuser's effectiveness in denoising and enhancing BEV representations. 

**Abstract (ZH)**: 鸟瞰视图（BEV）表示在自主驾驶任务中发挥着关键作用。尽管在BEV生成方面取得了最近的进展，但由于传感器限制和学习过程中的固有噪声，这类噪声在很大程度上仍未能得到有效解决，导致生成的BEV表示不尽如人意，从而对下游任务的性能产生负面影响。为解决这一问题，我们提出了一种新颖的扩散模型BEVDiffuser，该模型利用真实物体布局作为指导，有效去噪BEV特征图。BEVDiffuser可以在训练过程中以即插即用的方式运行，增强现有的BEV模型而无需进行任何架构修改。在具有挑战性的nuScenes数据集上的实验结果表明，BEVDiffuser具有出色的去噪和生成能力，能够显著提升现有BEV模型，这得到了在3D物体检测中mAP提升12.3%和NDS提升10.1%的显著改善，而无需增加额外的计算复杂度。此外，在长尾物体检测以及在恶劣天气和光照条件下的显著改进，进一步验证了BEVDiffuser在BEV表示去噪和增强方面的有效性。 

---
# Accurate and Scalable Graph Neural Networks via Message Invariance 

**Title (ZH)**: 通过消息不变性实现高效可扩展的图神经网络 

**Authors**: Zhihao Shi, Jie Wang, Zhiwei Zhuang, Xize Liang, Bin Li, Feng Wu  

**Link**: [PDF](https://arxiv.org/pdf/2502.19693)  

**Abstract**: Message passing-based graph neural networks (GNNs) have achieved great success in many real-world applications. For a sampled mini-batch of target nodes, the message passing process is divided into two parts: message passing between nodes within the batch (MP-IB) and message passing from nodes outside the batch to those within it (MP-OB). However, MP-OB recursively relies on higher-order out-of-batch neighbors, leading to an exponentially growing computational cost with respect to the number of layers. Due to the neighbor explosion, the whole message passing stores most nodes and edges on the GPU such that many GNNs are infeasible to large-scale graphs. To address this challenge, we propose an accurate and fast mini-batch approach for large graph transductive learning, namely topological compensation (TOP), which obtains the outputs of the whole message passing solely through MP-IB, without the costly MP-OB. The major pillar of TOP is a novel concept of message invariance, which defines message-invariant transformations to convert costly MP-OB into fast MP-IB. This ensures that the modified MP-IB has the same output as the whole message passing. Experiments demonstrate that TOP is significantly faster than existing mini-batch methods by order of magnitude on vast graphs (millions of nodes and billions of edges) with limited accuracy degradation. 

**Abstract (ZH)**: 基于消息传递的图神经网络（GNNs）在许多实际应用中取得了巨大的成功。对于采样的小批量目标节点，消息传递过程分为两个部分：小批量内部节点之间的问题传递（MP-IB）和小批量外部节点向内部节点的消息传递（MP-OB）。然而，MP-OB递归地依赖于更高阶的外部邻居节点，导致计算成本随层数呈指数级增长。由于邻居数量的爆炸性增长，整个消息传递过程需要将大多数节点和边存储在GPU上，从而使许多GNNs在大规模图上不可行。为了解决这一挑战，我们提出了一种适用于大规模图归纳学习的高效小批量方法，称为拓扑补偿（TOP），它可以仅通过MP-IB获得整个消息传递的输出，而无需昂贵的MP-OB。TOP的核心是引入了一个新的概念——消息不变性，定义了消息不变性变换将昂贵的MP-OB转换为快速的MP-IB。这确保了修改后的MP-IB与整个消息传递的输出相同。实验表明，与现有的小批量方法相比，TOP在大规模图（数百万节点和数十亿边）上的速度显著提高，同时准确度下降幅度有限。 

---
# Rethinking Epistemic and Aleatoric Uncertainty for Active Open-Set Annotation: An Energy-Based Approach 

**Title (ZH)**: 重新审视知识性和偶然性不确定性在主动开放集标注中的应用：一种基于能量的方法 

**Authors**: Chen-Chen Zong, Sheng-Jun Huang  

**Link**: [PDF](https://arxiv.org/pdf/2502.19691)  

**Abstract**: Active learning (AL), which iteratively queries the most informative examples from a large pool of unlabeled candidates for model training, faces significant challenges in the presence of open-set classes. Existing methods either prioritize query examples likely to belong to known classes, indicating low epistemic uncertainty (EU), or focus on querying those with highly uncertain predictions, reflecting high aleatoric uncertainty (AU). However, they both yield suboptimal performance, as low EU corresponds to limited useful information, and closed-set AU metrics for unknown class examples are less meaningful. In this paper, we propose an Energy-based Active Open-set Annotation (EAOA) framework, which effectively integrates EU and AU to achieve superior performance. EAOA features a $(C+1)$-class detector and a target classifier, incorporating an energy-based EU measure and a margin-based energy loss designed for the detector, alongside an energy-based AU measure for the target classifier. Another crucial component is the target-driven adaptive sampling strategy. It first forms a smaller candidate set with low EU scores to ensure closed-set properties, making AU metrics meaningful. Subsequently, examples with high AU scores are queried to form the final query set, with the candidate set size adjusted adaptively. Extensive experiments show that EAOA achieves state-of-the-art performance while maintaining high query precision and low training overhead. The code is available at this https URL. 

**Abstract (ZH)**: 主动学习（AL）通过迭代地从大量未标记候选集中查询最有信息性的示例以供模型训练，在开放集类存在的情况下面临着重大挑战。现有方法要么着重于查询很可能属于已知类别的示例，这些示例具有较低的亚氏不确定性（EU），要么侧重于查询预测具有高度不确定性的示例，这反映了较高的随机不确定性（AU）。然而，这两种方法都表现出次优的性能，因为较低的EU意味着有用信息有限，而针对未知类别示例的闭集AU度量指标意义不大。本文提出了一种基于能量的主动开放集注释（EAOA）框架，该框架有效地结合了EU和AU，从而实现更好的性能。EAOA包含一个$(C+1)$类检测器和一个目标分类器，并结合了基于能量的EU度量、专为检测器设计的边际能量损失，以及基于能量的AU度量。另一个关键组成部分是目标驱动的自适应采样策略。该策略首先根据低EU得分形成一个较小的候选集，以确保闭集特性，使AU度量有意义。随后，查询高AU得分的示例形成最终的查询集，并且根据需要适配调整候选集大小。广泛的实验表明，EAOA在保持高查询精确度和低训练开销的同时，达到了最先进的性能。代码可在以下链接中获取：this https URL。 

---
# Risk-aware Integrated Task and Motion Planning for Versatile Snake Robots under Localization Failures 

**Title (ZH)**: 在局部化故障情况下，面向风险的集成任务与运动规划方法在多功能蛇形机器人中的应用 

**Authors**: Ashkan Jasour, Guglielmo Daddi, Masafumi Endo, Tiago S. Vaquero, Michael Paton, Marlin P. Strub, Sabrina Corpino, Michel Ingham, Masahiro Ono, Rohan Thakker  

**Link**: [PDF](https://arxiv.org/pdf/2502.19690)  

**Abstract**: Snake robots enable mobility through extreme terrains and confined environments in terrestrial and space applications. However, robust perception and localization for snake robots remain an open challenge due to the proximity of the sensor payload to the ground coupled with a limited field of view. To address this issue, we propose Blind-motion with Intermittently Scheduled Scans (BLISS) which combines proprioception-only mobility with intermittent scans to be resilient against both localization failures and collision risks. BLISS is formulated as an integrated Task and Motion Planning (TAMP) problem that leads to a Chance-Constrained Hybrid Partially Observable Markov Decision Process (CC-HPOMDP), known to be computationally intractable due to the curse of history. Our novelty lies in reformulating CC-HPOMDP as a tractable, convex Mixed Integer Linear Program. This allows us to solve BLISS-TAMP significantly faster and jointly derive optimal task-motion plans. Simulations and hardware experiments on the EELS snake robot show our method achieves over an order of magnitude computational improvement compared to state-of-the-art POMDP planners and $>$ 50\% better navigation time optimality versus classical two-stage planners. 

**Abstract (ZH)**: 蛇形机器人可在陆地和太空应用中的极端地形和受限环境中实现移动。然而，由于传感器载荷与地面的近距离以及有限的视野，蛇形机器人的稳健感知和定位仍然是一个待解决的挑战。为此，我们提出了一种结合本体感觉移动与间歇性扫描的“盲动与间歇性扫描”(BLIND-MOTION with Intermittently Scheduled Scans, BLISS) 方法，以应对定位失败和碰撞风险。BLISS 被形式化为一个集成任务与动作规划问题（Task and Motion Planning, TAMP），这将导致一个条件约束混合部分可观测马尔科夫决策过程（Chance-Constrained Hybrid Partially Observable Markov Decision Process, CC-HPOMDP），由于历史诅咒的限制，CC-HPOMDP 是计算上不可解的。我们的创新之处在于将 CC-HPOMDP 重新表述为一个可处理的、凸优化的混合整数线性规划问题。这使得我们能够显著加快解决 BLISS-TAMP 的速度，并联合生成最优的任务-动作计划。在 EELS 蛇形机器人的仿真和硬件实验中，我们的方法在计算效率上相比最先进的 POMDP 规划器实现了至少一个数量级的改进，并且在导航时间优化方面相较于传统的两阶段规划方法提高了超过 50% 的性能。 

---
# M-LLM Based Video Frame Selection for Efficient Video Understanding 

**Title (ZH)**: 基于M-LLM的视频帧选择方法以实现高效视频理解 

**Authors**: Kai Hu, Feng Gao, Xiaohan Nie, Peng Zhou, Son Tran, Tal Neiman, Lingyun Wang, Mubarak Shah, Raffay Hamid, Bing Yin, Trishul Chilimbi  

**Link**: [PDF](https://arxiv.org/pdf/2502.19680)  

**Abstract**: Recent advances in Multi-Modal Large Language Models (M-LLMs) show promising results in video reasoning. Popular Multi-Modal Large Language Model (M-LLM) frameworks usually apply naive uniform sampling to reduce the number of video frames that are fed into an M-LLM, particularly for long context videos. However, it could lose crucial context in certain periods of a video, so that the downstream M-LLM may not have sufficient visual information to answer a question. To attack this pain point, we propose a light-weight M-LLM -based frame selection method that adaptively select frames that are more relevant to users' queries. In order to train the proposed frame selector, we introduce two supervision signals (i) Spatial signal, where single frame importance score by prompting a M-LLM; (ii) Temporal signal, in which multiple frames selection by prompting Large Language Model (LLM) using the captions of all frame candidates. The selected frames are then digested by a frozen downstream video M-LLM for visual reasoning and question answering. Empirical results show that the proposed M-LLM video frame selector improves the performances various downstream video Large Language Model (video-LLM) across medium (ActivityNet, NExT-QA) and long (EgoSchema, LongVideoBench) context video question answering benchmarks. 

**Abstract (ZH)**: 近年来，多模态大型语言模型（M-LLMs）在视频推理方面展现了令人鼓舞的结果。流行的多模态大型语言模型（M-LLM）框架通常采用简单的均匀采样方法来减少输入M-LLM的视频帧数量，尤其是在处理长上下文视频时。然而，这种方法可能会在视频的某些时期丢失关键的上下文信息，导致下游M-LLM可能缺乏足够的视觉信息来回答问题。为了解决这一问题，我们提出了一种轻量级的M-LLM基于的帧选择方法，该方法能够适应性地选择与用户查询更加相关的关键帧。为了训练提出的帧选择器，我们引入了两种监督信号：（i）空间信号，通过提示M-LLM单帧的重要性分数；（ii）时间信号，在此信号中，通过使用所有候选帧的字幕来提示大型语言模型（LLM）进行多帧选择。选出的关键帧随后由冻结状态的下游视频M-LLM用于视觉推理和问题回答。实验结果表明，提出的M-LLM视频帧选择器能够提高各类中长上下文视频大型语言模型（视频-LLM）在（ActivityNet，NExT-QA）和（EgoSchema，LongVideoBench）基准测试中的性能。 

---
# SuPreME: A Supervised Pre-training Framework for Multimodal ECG Representation Learning 

**Title (ZH)**: SuPreME：一种监督预训练的多模态心电图表示学习框架 

**Authors**: Mingsheng Cai, Jiuming Jiang, Wenhao Huang, Che Liu, Rossella Arcucci  

**Link**: [PDF](https://arxiv.org/pdf/2502.19668)  

**Abstract**: Cardiovascular diseases are a leading cause of death and disability worldwide. Electrocardiogram (ECG) recordings are critical for diagnosing and monitoring cardiac health, but obtaining large-scale annotated ECG datasets is labor-intensive and time-consuming. Recent ECG Self-Supervised Learning (eSSL) methods mitigate this by learning features without extensive labels but fail to capture fine-grained clinical semantics and require extensive task-specific fine-tuning. To address these challenges, we propose $\textbf{SuPreME}$, a $\textbf{Su}$pervised $\textbf{Pre}$-training framework for $\textbf{M}$ultimodal $\textbf{E}$CG representation learning. SuPreME applies Large Language Models (LLMs) to extract structured clinical entities from free-text ECG reports, filter out noise and irrelevant content, enhance clinical representation learning, and build a high-quality, fine-grained labeled dataset. By using text-based cardiac queries instead of traditional categorical labels, SuPreME enables zero-shot classification of unseen diseases without additional fine-tuning. We evaluate SuPreME on six downstream datasets covering 127 cardiac conditions, achieving superior zero-shot AUC performance over state-of-the-art eSSL and multimodal methods by over 1.96\%. Results demonstrate the effectiveness of SuPreME in leveraging structured, clinically relevant knowledge for high-quality ECG representations. All code and data will be released upon acceptance. 

**Abstract (ZH)**: 心血管疾病是全球范围内导致死亡和残疾的主要原因。心电图（ECG）记录是诊断和监测心脏健康的关键工具，但获取大规模标注的ECG数据集是一项劳动密集型和耗时的工作。近期的ECG半监督学习（eSSL）方法通过在较少标注的情况下学习特征来缓解这一问题，但这些方法难以捕捉细微的临床语义，并且需要大量的任务特定微调。为了解决这些挑战，我们提出了一种名为$\textbf{SuPreME}$的$\textbf{S}$upervised $\textbf{P}$re-$\textbf{T}$raining框架，该框架用于多模态ECG表示学习。SuPreME利用大型语言模型（LLMs）从自由文本ECG报告中提取结构化的临床实体，过滤噪声和不必要的内容，增强临床表示学习，并构建高质量、细微标注的数据集。通过使用基于文本的心脏病查询而非传统的分类标签，SuPreME能够在无需额外微调的情况下实现对未知疾病的零样本分类。我们将在六个下游数据集上对SuPreME进行评估，这些数据集覆盖了127种心脏状况，与现有最先进的eSSL和多模态方法相比，SuPreME在零样本AUC性能上提高了1.96%以上。结果表明，SuPreME在利用结构化、临床相关的知识构建高质量ECG表示方面具有有效性。所有代码和数据将在接受后公开发布。 

---
# HALO: Hardware-aware quantization with low critical-path-delay weights for LLM acceleration 

**Title (ZH)**: HALO：硬件感知的量化方法，采用低关键路径延迟权重以加速大规模语言模型 

**Authors**: Rohan Juneja, Shivam Aggarwal, Safeen Huda, Tulika Mitra, Li-Shiuan Peh  

**Link**: [PDF](https://arxiv.org/pdf/2502.19662)  

**Abstract**: Quantization is critical for realizing efficient inference of LLMs. Traditional quantization methods are hardware-agnostic, limited to bit-width constraints, and lacking circuit-level insights, such as timing and energy characteristics of Multiply-Accumulate (MAC) units. We introduce HALO, a versatile framework that adapts to various hardware through a Hardware-Aware Post-Training Quantization (PTQ) approach. By leveraging MAC unit properties, HALO minimizes critical-path delays and enables dynamic frequency scaling. Deployed on LLM accelerators like TPUs and GPUs, HALO achieves on average 270% performance gains and 51% energy savings, all with minimal accuracy drop. 

**Abstract (ZH)**: 量化对于实现大规模语言模型（LLM）的高效推理至关重要。传统的量化方法缺乏硬件感知性，局限于位宽约束，并且缺乏乘加单元（MAC单元）在时间延迟和能量特性方面的电路级洞察。我们引入了HALO，这是一种通过硬件感知后训练量化（PTQ）方法来适应各种硬件的多功能框架。通过利用MAC单元的特性，HALO最小化了关键路径延迟，并允许动态频率调整。在TPU和GPU等LLM加速器上部署HALO，平均每种模型实现了270%的性能提升和51%的能量节省，同时最小化了准确性下降。 

---
# Med-RLVR: Emerging Medical Reasoning from a 3B base model via reinforcement Learning 

**Title (ZH)**: Med-RLVR：通过强化学习从3B基础模型中 emerges 医学推理 

**Authors**: Sheng Zhang, Qianchu Liu, Guanghui Qin, Tristan Naumann, Hoifung Poon  

**Link**: [PDF](https://arxiv.org/pdf/2502.19655)  

**Abstract**: Reinforcement learning from verifiable rewards (RLVR) has recently gained attention for its ability to elicit self-evolved reasoning capabilitie from base language models without explicit reasoning supervisions, as demonstrated by DeepSeek-R1. While prior work on RLVR has primarily focused on mathematical and coding domains, its applicability to other tasks and domains remains unexplored. In this work, we investigate whether medical reasoning can emerge from RLVR. We introduce Med-RLVR as an initial study of RLVR in the medical domain leveraging medical multiple-choice question answering (MCQA) data as verifiable labels. Our results demonstrate that RLVR is not only effective for math and coding but also extends successfully to medical question answering. Notably, Med-RLVR achieves performance comparable to traditional supervised fine-tuning (SFT) on in-distribution tasks while significantly improving out-of-distribution generalization, with an 8-point accuracy gain. Further analysis of training dynamics reveals that, with no explicit reasoning supervision, reasoning emerges from the 3B-parameter base model. These findings underscore the potential of RLVR in domains beyond math and coding, opening new avenues for its application in knowledge-intensive fields such as medicine. 

**Abstract (ZH)**: 验证奖励的强化学习（RLVR）因其能够从基础语言模型中引出自我演化的推理能力，而无需显式的推理监督，近年来引起了广泛关注，DeepSeek-R1 已经展示了这一点。尽管现有的 RLVR 工作主要集中在数学和编程领域，但其在其他任务和领域的应用尚未被充分探索。在此项工作中，我们探讨了RLVR在医学推理中的可能性。我们提出Med-RLVR，作为在医学领域利用医学选择题解答（MCQA）数据作为验证标签的RLVR初步研究。结果显示，除了数学和编程任务外，RLVR在医学问答任务上的有效性也得到了证实。值得注意的是，Med-RLVR在分布内任务的表现与传统的监督微调（SFT）相当，而在分布外泛化方面显著提升，准确率提升8个百分点。进一步分析训练动态表明，在没有任何显式推理监督的情况下，推理能力来源于基础模型中的30亿参数。这些发现突显了RLVR在数学和编程之外领域的潜在应用价值，为在知识密集型领域如医学中的应用开辟了新的途径。 

---
# Robust Gymnasium: A Unified Modular Benchmark for Robust Reinforcement Learning 

**Title (ZH)**: 稳健的健身房：统一的模块化稳健强化学习基准测试 

**Authors**: Shangding Gu, Laixi Shi, Muning Wen, Ming Jin, Eric Mazumdar, Yuejie Chi, Adam Wierman, Costas Spanos  

**Link**: [PDF](https://arxiv.org/pdf/2502.19652)  

**Abstract**: Driven by inherent uncertainty and the sim-to-real gap, robust reinforcement learning (RL) seeks to improve resilience against the complexity and variability in agent-environment sequential interactions. Despite the existence of a large number of RL benchmarks, there is a lack of standardized benchmarks for robust RL. Current robust RL policies often focus on a specific type of uncertainty and are evaluated in distinct, one-off environments. In this work, we introduce Robust-Gymnasium, a unified modular benchmark designed for robust RL that supports a wide variety of disruptions across all key RL components-agents' observed state and reward, agents' actions, and the environment. Offering over sixty diverse task environments spanning control and robotics, safe RL, and multi-agent RL, it provides an open-source and user-friendly tool for the community to assess current methods and foster the development of robust RL algorithms. In addition, we benchmark existing standard and robust RL algorithms within this framework, uncovering significant deficiencies in each and offering new insights. 

**Abstract (ZH)**: 受到固有的不确定性和仿真到现实差距的驱使，鲁棒强化学习（RL）旨在提高代理在与环境进行顺序交互时对其复杂性和变化性的抗性。尽管存在大量的RL基准测试，但鲁棒RL的标准基准仍然缺乏。当前的鲁棒RL策略往往专注于特定类型的不确定性，并且在一个接一个独立的环境中进行评估。在本工作中，我们引入了Robust-Gymnasium，这是一个统一的模块化基准测试，专为鲁棒RL设计，支持在所有关键的RL组件（代理观测到的状态和奖励、代理的动作以及环境）上广泛的干扰。该基准测试提供了六十多个涵盖控制、机器人技术、安全RL和多代理RL的多样任务环境，为社区提供了一个开源且用户友好的工具，用于评估当前的方法并促进鲁棒RL算法的发展。此外，我们在此框架内对现有的标准RL和鲁棒RL算法进行了基准测试，揭示了每种算法中存在的显著缺陷，并提供了新的见解。 

---
# AutoBS: Autonomous Base Station Deployment Framework with Reinforcement Learning and Digital Twin Network 

**Title (ZH)**: AutoBS：基于强化学习和数字孪生网络的自主基站部署框架 

**Authors**: Ju-Hyung Lee, Andreas F. Molisch  

**Link**: [PDF](https://arxiv.org/pdf/2502.19647)  

**Abstract**: This paper introduces AutoBS, a reinforcement learning (RL)-based framework for optimal base station (BS) deployment in 6G networks. AutoBS leverages the Proximal Policy Optimization (PPO) algorithm and fast, site-specific pathloss predictions from PMNet to efficiently learn deployment strategies that balance coverage and capacity. Numerical results demonstrate that AutoBS achieves 95% for a single BS, and 90% for multiple BSs, of the capacity provided by exhaustive search methods while reducing inference time from hours to milliseconds, making it highly suitable for real-time applications. AutoBS offers a scalable and automated solution for large-scale 6G networks, addressing the challenges of dynamic environments with minimal computational overhead. 

**Abstract (ZH)**: 本文介绍了AutoBS，这是一种基于强化学习（RL）的框架，用于在6G网络中进行最优基站（BS）部署。AutoBS利用了近端策略优化（PPO）算法和来自PMNet的快速、站点特定的路径损耗预测，以高效地学习兼顾覆盖和容量的部署策略。数值结果表明，对于单个BS，AutoBS能够实现与详尽搜索方法相当的95%的容量，而对于多个BS，则能实现90%的容量，同时将推理时间从数小时缩短到毫秒级，使其非常适合实时应用。AutoBS为大规模6G网络提供了一种可扩展且自动化的解决方案，能够应对动态环境下的挑战，并具有最小的计算开销。 

---
# Fine-Tuning Vision-Language-Action Models: Optimizing Speed and Success 

**Title (ZH)**: 视觉-语言-动作模型的微调：优化速度与成功率 

**Authors**: Moo Jin Kim, Chelsea Finn, Percy Liang  

**Link**: [PDF](https://arxiv.org/pdf/2502.19645)  

**Abstract**: Recent vision-language-action models (VLAs) build upon pretrained vision-language models and leverage diverse robot datasets to demonstrate strong task execution, language following ability, and semantic generalization. Despite these successes, VLAs struggle with novel robot setups and require fine-tuning to achieve good performance, yet how to most effectively fine-tune them is unclear given many possible strategies. In this work, we study key VLA adaptation design choices such as different action decoding schemes, action representations, and learning objectives for fine-tuning, using OpenVLA as our representative base model. Our empirical analysis informs an Optimized Fine-Tuning (OFT) recipe that integrates parallel decoding, action chunking, a continuous action representation, and a simple L1 regression-based learning objective to altogether improve inference efficiency, policy performance, and flexibility in the model's input-output specifications. We propose OpenVLA-OFT, an instantiation of this recipe, which sets a new state of the art on the LIBERO simulation benchmark, significantly boosting OpenVLA's average success rate across four task suites from 76.5% to 97.1% while increasing action generation throughput by 26$\times$. In real-world evaluations, our fine-tuning recipe enables OpenVLA to successfully execute dexterous, high-frequency control tasks on a bimanual ALOHA robot and outperform other VLAs ($\pi_0$ and RDT-1B) fine-tuned using their default recipes, as well as strong imitation learning policies trained from scratch (Diffusion Policy and ACT) by up to 15% (absolute) in average success rate. We release code for OFT and pretrained model checkpoints at this https URL. 

**Abstract (ZH)**: 近年来，视觉-语言-动作模型（VLAs）基于预训练的视觉-语言模型，并利用多种多样的机器人数据集，展示了强大的任务执行能力、语言理解和语义泛化能力。尽管取得了这些成功，但VLAs在面对新型机器人设置时仍存在挑战，需要进行微调才能获得良好的性能，然而如何最有效地进行微调仍不明确，因为存在多种可能的策略。在本工作中，我们研究了关键的VLA调整设计选择，如不同的动作解码方案、动作表示和学习目标，以进行微调，将OpenVLA作为我们的代表性基模型。我们的实证分析为一种优化的微调（OFT）食谱提供建议，该食谱整合了并行解码、动作分块、连续的动作表示，以及基于L1回归的学习目标，以整体提高推理效率、策略性能以及模型输入输出规范的灵活性。我们提出了OpenVLA-OFT，这是该食谱的一个实例，在LIBERO模拟基准测试中，它不仅在四个任务套件中将OpenVLA的平均成功率从76.5%提升到了97.1%，还使动作生成吞吐量提高了26倍。在现实世界的评估中，我们的微调方案使OpenVLA能够成功执行双臂ALOHA机器人的灵巧、高频控制任务，并优于使用默认食谱进行微调的其他VLAs（$\pi_0$和RDT-1B），以及从零开始训练的强大模仿学习策略（Diffusion Policy和ACT），在平均成功率上提高了高达15%。我们在此提供OFT的代码和预训练模型检查点，链接为：[此 url 地址]。 

---
# MedVLM-R1: Incentivizing Medical Reasoning Capability of Vision-Language Models (VLMs) via Reinforcement Learning 

**Title (ZH)**: MedVLM-R1：通过强化学习激励视觉-语言模型的医学推理能力 

**Authors**: Jiazhen Pan, Che Liu, Junde Wu, Fenglin Liu, Jiayuan Zhu, Hongwei Bran Li, Chen Chen, Cheng Ouyang, Daniel Rueckert  

**Link**: [PDF](https://arxiv.org/pdf/2502.19634)  

**Abstract**: Reasoning is a critical frontier for advancing medical image analysis, where transparency and trustworthiness play a central role in both clinician trust and regulatory approval. Although Medical Visual Language Models (VLMs) show promise for radiological tasks, most existing VLMs merely produce final answers without revealing the underlying reasoning. To address this gap, we introduce MedVLM-R1, a medical VLM that explicitly generates natural language reasoning to enhance transparency and trustworthiness. Instead of relying on supervised fine-tuning (SFT), which often suffers from overfitting to training distributions and fails to foster genuine reasoning, MedVLM-R1 employs a reinforcement learning framework that incentivizes the model to discover human-interpretable reasoning paths without using any reasoning references. Despite limited training data (600 visual question answering samples) and model parameters (2B), MedVLM-R1 boosts accuracy from 55.11% to 78.22% across MRI, CT, and X-ray benchmarks, outperforming larger models trained on over a million samples. It also demonstrates robust domain generalization under out-of-distribution tasks. By unifying medical image analysis with explicit reasoning, MedVLM-R1 marks a pivotal step toward trustworthy and interpretable AI in clinical practice. 

**Abstract (ZH)**: 推理是推动医学图像分析的重要前沿领域，其中透明度和可信度在临床医生的信任和监管批准中起到核心作用。尽管医学视觉语言模型（VLMs）在放射学任务中展现出潜力，但大多数现有的VLMs仅生成最终答案，而不揭示其背后的推理过程。为了解决这一问题，我们提出了MedVLM-R1，这是一种 Explicitly 生成自然语言推理的医学VLM，以增强透明度和可信度。MedVLM-R1 不依赖于监督微调（SFT），后者常常容易过拟合训练分布且无法促进真实的推理过程。相反，MedVLM-R1 使用强化学习框架，激励模型发现可由人类解释的推理路径，而无需使用任何推理参考模型。尽管有限的训练数据（600个视觉问答样本）和模型参数（20亿），MedVLM-R1 在 MRI、CT 和 X 射线基准测试中的准确性从 55.11% 提升到 78.22%，优于在超过一百万样本上训练的更大模型。它还在离分布任务中展示了强大的领域泛化能力。通过将医学图像分析与显式推理统一起来，MedVLM-R1 标志着在临床实践中迈向安全可解释 AI 的关键一步。 

---
# 3D Nephrographic Image Synthesis in CT Urography with the Diffusion Model and Swin Transformer 

**Title (ZH)**: 使用扩散模型和Swin Transformer实现的CT尿路造影中的3D肾图图像合成 

**Authors**: Hongkun Yu, Syed Jamal Safdar Gardezi, E. Jason Abel, Daniel Shapiro, Meghan G. Lubner, Joshua Warner, Matthew Smith, Giuseppe Toia, Lu Mao, Pallavi Tiwari, Andrew L. Wentland  

**Link**: [PDF](https://arxiv.org/pdf/2502.19623)  

**Abstract**: Purpose: This study aims to develop and validate a method for synthesizing 3D nephrographic phase images in CT urography (CTU) examinations using a diffusion model integrated with a Swin Transformer-based deep learning approach. Materials and Methods: This retrospective study was approved by the local Institutional Review Board. A dataset comprising 327 patients who underwent three-phase CTU (mean $\pm$ SD age, 63 $\pm$ 15 years; 174 males, 153 females) was curated for deep learning model development. The three phases for each patient were aligned with an affine registration algorithm. A custom deep learning model coined dsSNICT (diffusion model with a Swin transformer for synthetic nephrographic phase images in CT) was developed and implemented to synthesize the nephrographic images. Performance was assessed using Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), Mean Absolute Error (MAE), and Fréchet Video Distance (FVD). Qualitative evaluation by two fellowship-trained abdominal radiologists was performed. Results: The synthetic nephrographic images generated by our proposed approach achieved high PSNR (26.3 $\pm$ 4.4 dB), SSIM (0.84 $\pm$ 0.069), MAE (12.74 $\pm$ 5.22 HU), and FVD (1323). Two radiologists provided average scores of 3.5 for real images and 3.4 for synthetic images (P-value = 0.5) on a Likert scale of 1-5, indicating that our synthetic images closely resemble real images. Conclusion: The proposed approach effectively synthesizes high-quality 3D nephrographic phase images. This model can be used to reduce radiation dose in CTU by 33.3\% without compromising image quality, which thereby enhances the safety and diagnostic utility of CT urography. 

**Abstract (ZH)**: 目的：本研究旨在开发并验证一种通过结合Swin Transformer的深度学习方法和扩散模型，在CT尿路造影（CTU）检查中合成3D肾图相位图像的方法。材料与方法：本回顾性研究得到本地机构审查委员会的批准。用于深度学习模型开发的数据集包括327名患者（平均年龄 ± 标准差，63 ± 15岁；男性174例，女性153例），均进行了三相CTU检查。每个患者的三个相位使用仿射配准算法进行对齐。开发并实现了一种自定义深度学习模型（命名为dsSNICT，即基于Swin Transformer的合成CT肾图相位图像的扩散模型），用于合成肾图图像。性能评估使用峰值信噪比（PSNR）、结构相似性索引（SSIM）、均方绝对误差（MAE）和弗雷歇视频距离（FVD）。由两名经过专科培训的腹部放射科医师进行了定性评估。结果：我们提出的方法生成的合成肾图图像的PSNR为26.3 ± 4.4 dB、SSIM为0.84 ± 0.069、MAE为12.74 ± 5.22 HU、FVD为1323。两名放射科医师分别对真实图像和合成图像的评分分别为3.5和3.4（P值 = 0.5），在1-5的李克特量表上，表明合成图像与真实图像非常接近。结论：提出的方法能够有效合成高质量的3D肾图相位图像。该模型可以在不牺牲图像质量的情况下将CTU的辐射剂量降低33.3%，从而提高了CT尿路造影的安全性和诊断价值。 

---
# Weaker LLMs' Opinions Also Matter: Mixture of Opinions Enhances LLM's Mathematical Reasoning 

**Title (ZH)**: 弱语言模型的观点同样重要：混合观点增强语言模型的数学推理能力 

**Authors**: Yanan Chen, Ali Pesaranghader, Tanmana Sadhu  

**Link**: [PDF](https://arxiv.org/pdf/2502.19622)  

**Abstract**: Recent advances in Large Language Models (LLMs) have raised interest in their formal reasoning capabilities, particularly in mathematics. While closed LLMs like GPT-4 perform well on mathematical benchmarks, e.g., GSM8K, it remains unclear whether small to medium-sized open LLMs can achieve similar performance, questioning their reliability. To close this gap, we propose a post-training approach leveraging a mixture of opinions (MoO) from weaker ancillary LLMs to enhance a (relatively) stronger LLM's reasoning. For that, each post-training sample is augmented with Chain-of-Thought (CoT) reasoning steps and answers from ancillary LLMs, enabling the main LLM to learn from diverse perspectives. We compare MoO with standard supervised fine-tuning (SFT), few-shot prompting, and the Mixture of Agents (MoA) method on mathematical reasoning benchmarks. Our results show that incorporating weaker LLMs' opinions improves mathematical reasoning by an average of 5%, highlighting the value of diverse perspectives in reasoning tasks. 

**Abstract (ZH)**: 近年来，大规模语言模型（LLMs）的进展引起了对其形式推理能力，尤其是数学推理能力的关注。虽然像GPT-4这样的封闭LLMs在数学基准测试中表现出色，例如GSM8K，但尚不清楚较小到中等规模的开放LLMs能否达到类似的性能，从而对它们的可靠性提出了质疑。为了解决这一问题，我们提出了一种后训练方法，利用较弱辅助LLMs的意见混合（MoO）来增强一个相对较强大的LLMs的推理能力。为此，每个后训练样本都将增加包含因果思维（CoT）推理步骤和辅助LLMs的答案，使主要LLM能够从多种视角学习。我们将MoO与标准监督微调（SFT）、少样本提示以及代理混合（MoA）方法在数学推理基准测试上进行了比较。结果显示，将较弱LLMs的意见纳入其中，平均可以提高5%的数学推理性能，突显了在推理任务中多样视角的价值。 

---
# Is Your Paper Being Reviewed by an LLM? A New Benchmark Dataset and Approach for Detecting AI Text in Peer Review 

**Title (ZH)**: 你的论文是否正在被一个大规模语言模型审稿？一个新的基准数据集和检测同行评审中AI文本的方法 

**Authors**: Sungduk Yu, Man Luo, Avinash Madusu, Vasudev Lal, Phillip Howard  

**Link**: [PDF](https://arxiv.org/pdf/2502.19614)  

**Abstract**: Peer review is a critical process for ensuring the integrity of published scientific research. Confidence in this process is predicated on the assumption that experts in the relevant domain give careful consideration to the merits of manuscripts which are submitted for publication. With the recent rapid advancements in large language models (LLMs), a new risk to the peer review process is that negligent reviewers will rely on LLMs to perform the often time consuming process of reviewing a paper. However, there is a lack of existing resources for benchmarking the detectability of AI text in the domain of peer review.
To address this deficiency, we introduce a comprehensive dataset containing a total of 788,984 AI-written peer reviews paired with corresponding human reviews, covering 8 years of papers submitted to each of two leading AI research conferences (ICLR and NeurIPS). We use this new resource to evaluate the ability of 18 existing AI text detection algorithms to distinguish between peer reviews written by humans and different state-of-the-art LLMs. Motivated by the shortcomings of existing methods, we propose a new detection approach which surpasses existing methods in the identification of AI written peer reviews. Our work reveals the difficulty of identifying AI-generated text at the individual peer review level, highlighting the urgent need for new tools and methods to detect this unethical use of generative AI. 

**Abstract (ZH)**: 同行评审是确保发表的科学研究 integrity的关键过程。这一过程的信心基于一个假设，即相关领域的专家会对提交发表的手稿的优点给予慎重考虑。随着大型语言模型（LLMs）近来的快速发展，新的同行评审风险出现了，即粗心的评审者可能会依赖LLMs来完成常常耗时的论文评审过程。然而，现有资源中缺乏针对同行评审领域的AI文本检测能力的基准测试。

为应对这一不足，我们引入了一个包含共计788,984份AI撰写同行评审和对应的由人类撰写的同行评审的综合数据集，这些数据涵盖了过去8年向两场领先的AI研究会议（ICLR和NeurIPS）提交的论文的同行评审过程。我们利用这一新资源评估了18种现有的AI文本检测算法在区分人类撰写的同行评审和不同先进LLMs撰写的同行评审方面的能力。受到现有方法的局限性的启发，我们提出了一种新的检测方法，该方法在识别AI撰写的同行评审方面超过了现有的方法。我们的研究揭示了在个体同行评审级别上鉴别人工生成文本的难度，突显了迫切需要新的工具和方法来检测这种不道德使用生成性AI的问题。 

---
# Improving Representation Learning of Complex Critical Care Data with ICU-BERT 

**Title (ZH)**: 使用ICU-BERT提升复杂重症监护数据的表示学习 

**Authors**: Ricardo Santos, André V. Carreiro, Xi Peng, Hugo Gamboa, Holger Fröhlich  

**Link**: [PDF](https://arxiv.org/pdf/2502.19593)  

**Abstract**: The multivariate, asynchronous nature of real-world clinical data, such as that generated in Intensive Care Units (ICUs), challenges traditional AI-based decision-support systems. These often assume data regularity and feature independence and frequently rely on limited data scopes and manual feature engineering. The potential of generative AI technologies has not yet been fully exploited to analyze clinical data. We introduce ICU-BERT, a transformer-based model pre-trained on the MIMIC-IV database using a multi-task scheme to learn robust representations of complex ICU data with minimal preprocessing. ICU-BERT employs a multi-token input strategy, incorporating dense embeddings from a biomedical Large Language Model to learn a generalizable representation of complex and multivariate ICU data. With an initial evaluation of five tasks and four additional ICU datasets, ICU-BERT results indicate that ICU-BERT either compares to or surpasses current performance benchmarks by leveraging fine-tuning. By integrating structured and unstructured data, ICU-BERT advances the use of foundational models in medical informatics, offering an adaptable solution for clinical decision support across diverse applications. 

**Abstract (ZH)**: 现实世界临床数据（如重症监护病房ICUs生成的数据）的多变量和非同步特性，对基于传统AI的决策支持系统构成了挑战。这些系统通常假设数据的规律性和特征的独立性，并常常依赖于有限的数据范围和手动特征工程。尽管生成式AI技术具有巨大潜力，但其在分析临床数据方面的应用尚未充分利用。我们介绍了ICU-BERT，这是一种基于变压器的模型，通过多任务方案在MIMIC-IV数据库上进行预训练，以最少的预处理来学习复杂ICU数据的稳健表示。ICU-BERT采用多标记输入策略，结合生物医学大规模语言模型的密集嵌入，学习复杂且多变量ICU数据的一般表示。通过五个任务的初步评估和四个额外的ICU数据集，ICU-BERT的结果表明，通过微调，它可以与或超越当前的性能基准。通过整合结构化和非结构化数据，ICU-BERT促进了基础模型在医学信息学中的应用，提供了一种适用于多种临床决策支持应用的灵活解决方案。 

---
# NeoBERT: A Next-Generation BERT 

**Title (ZH)**: NeoBERT：下一代BERT模型 

**Authors**: Lola Le Breton, Quentin Fournier, Mariam El Mezouar, Sarath Chandar  

**Link**: [PDF](https://arxiv.org/pdf/2502.19587)  

**Abstract**: Recent innovations in architecture, pre-training, and fine-tuning have led to the remarkable in-context learning and reasoning abilities of large auto-regressive language models such as LLaMA and DeepSeek. In contrast, encoders like BERT and RoBERTa have not seen the same level of progress despite being foundational for many downstream NLP applications. To bridge this gap, we introduce NeoBERT, a next-generation encoder that redefines the capabilities of bidirectional models by integrating state-of-the-art advancements in architecture, modern data, and optimized pre-training methodologies. NeoBERT is designed for seamless adoption: it serves as a plug-and-play replacement for existing base models, relies on an optimal depth-to-width ratio, and leverages an extended context length of 4,096 tokens. Despite its compact 250M parameter footprint, it achieves state-of-the-art results on the massive MTEB benchmark, outperforming BERT large, RoBERTa large, NomicBERT, and ModernBERT under identical fine-tuning conditions. In addition, we rigorously evaluate the impact of each modification on GLUE and design a uniform fine-tuning and evaluation framework for MTEB. We release all code, data, checkpoints, and training scripts to accelerate research and real-world adoption. 

**Abstract (ZH)**: 近年来，在架构、预训练和微调方面的创新显著提升了大型自回归语言模型如LLaMA和DeepSeek的上下文学习和推理能力。相比之下，虽然BERT和RoBERTa作为许多下游自然语言处理应用的基础模块，但它们的进步并不明显。为弥合这一差距，我们引入了NeoBERT，这是一种下一代编码器，通过整合最新的架构进步、现代数据和优化的预训练方法，重新定义了双向模型的能力。NeoBERT设计为无缝替换现有基础模型：它采用最佳的深度与宽度比率，支持扩展至4,096个令牌的上下文长度。尽管参数量仅为250M，NeoBERT在庞大的MTEB基准测试中仍实现了最佳结果，在相同微调条件下，超越了BERT Large、RoBERTa Large、NomicBERT和ModernBERT。此外，我们严格评估了每个修改项对GLUE的影响，并为MTEB设计了统一的微调和评估框架。我们已公开所有代码、数据、检查点和训练脚本，旨在加速研究并推动实际应用的采纳。 

---
# Tell me why: Visual foundation models as self-explainable classifiers 

**Title (ZH)**: 《告诉我原因：视觉基础模型作为自解释分类器》

这个标题翻译成中文后，既保留了原文的意思，又符合学术规范。如果你需要进一步的修改或有特定的研究方向，请告诉我！ 

**Authors**: Hugues Turbé, Mina Bjelogrlic, Gianmarco Mengaldo, Christian Lovis  

**Link**: [PDF](https://arxiv.org/pdf/2502.19577)  

**Abstract**: Visual foundation models (VFMs) have become increasingly popular due to their state-of-the-art performance. However, interpretability remains crucial for critical applications. In this sense, self-explainable models (SEM) aim to provide interpretable classifiers that decompose predictions into a weighted sum of interpretable concepts. Despite their promise, recent studies have shown that these explanations often lack faithfulness. In this work, we combine VFMs with a novel prototypical architecture and specialized training objectives. By training only a lightweight head (approximately 1M parameters) on top of frozen VFMs, our approach (ProtoFM) offers an efficient and interpretable solution. Evaluations demonstrate that our approach achieves competitive classification performance while outperforming existing models across a range of interpretability metrics derived from the literature. Code is available at this https URL. 

**Abstract (ZH)**: 视觉基础模型（VFMs）由于其卓越的性能而越来越受欢迎。然而，在关键应用中，可解释性仍然至关重要。在此背景下，自解释模型（SEM）旨在提供可解释的分类器，将预测分解为可解释概念的加权和。尽管具有潜力，但近期研究表明，这些解释往往缺乏忠实性。在本工作中，我们结合了VFMs和一种新型原型架构以及专门的训练目标。通过仅在冻结的VFMs顶部训练一个轻量级头部（大约100万个参数），我们的方法（ProtoFM）提供了高效且可解释的方案。评估表明，我们的方法在多种文献来源的可解释性指标上优于现有模型，同时保持了竞争力的分类性能。代码可在以下链接获取：this https URL。 

---
# Do Large Language Models Know How Much They Know? 

**Title (ZH)**: 大型语言模型知道自己知道多少吗？ 

**Authors**: Gabriele Prato, Jerry Huang, Prasannna Parthasarathi, Shagun Sodhani, Sarath Chandar  

**Link**: [PDF](https://arxiv.org/pdf/2502.19573)  

**Abstract**: Large Language Models (LLMs) have emerged as highly capable systems and are increasingly being integrated into various uses. However, the rapid pace of their deployment has outpaced a comprehensive understanding of their internal mechanisms and a delineation of their capabilities and limitations. A desired attribute of an intelligent system is its ability to recognize the scope of its own knowledge. To investigate whether LLMs embody this characteristic, we develop a benchmark designed to challenge these models to enumerate all information they possess on specific topics. This benchmark evaluates whether the models recall excessive, insufficient, or the precise amount of information, thereby indicating their awareness of their own knowledge. Our findings reveal that all tested LLMs, given sufficient scale, demonstrate an understanding of how much they know about specific topics. While different architectures exhibit varying rates of this capability's emergence, the results suggest that awareness of knowledge may be a generalizable attribute of LLMs. Further research is needed to confirm this potential and fully elucidate the underlying mechanisms. 

**Abstract (ZH)**: 大规模语言模型（LLMs）已经展现出高度的能力，并被越来越多地整合到各种应用场景中。然而，它们的迅速部署速度超出了对其内部机制的全面理解以及对其能力与限制的界定。智能系统的一个理想特性是能够识别自身知识的范围。为了探究LLMs是否具备这一特性，我们开发了一个基准测试，旨在挑战这些模型，使其列出自己在特定主题上掌握的所有信息。该基准测试评估模型回忆过多、不足或精确数量的信息，从而表明它们对其自身知识的意识。我们的研究发现，在具有足够规模的情况下，所有测试的LLMs都展示了对特定主题上知识范围的理解。虽然不同架构展现出这一能力出现的不同速率，但结果表明，对知识的意识可能是LLMs的普遍特性。为进一步确认这一潜在特性和完全阐明背后的机制，还需进行更多研究。 

---
# Atlas: A Framework for ML Lifecycle Provenance & Transparency 

**Title (ZH)**: Atlas：一个机器学习生命周期溯源与透明度框架 

**Authors**: Marcin Spoczynski, Marcela S. Melara, Sebastian Szyller  

**Link**: [PDF](https://arxiv.org/pdf/2502.19567)  

**Abstract**: The rapid adoption of open source machine learning (ML) datasets and models exposes today's AI applications to critical risks like data poisoning and supply chain attacks across the ML lifecycle. With growing regulatory pressure to address these issues through greater transparency, ML model vendors face challenges balancing these requirements against confidentiality for data and intellectual property needs. We propose Atlas, a framework that enables fully attestable ML pipelines. Atlas leverages open specifications for data and software supply chain provenance to collect verifiable records of model artifact authenticity and end-to-end lineage metadata. Atlas combines trusted hardware and transparency logs to enhance metadata integrity, preserve data confidentiality, and limit unauthorized access during ML pipeline operations, from training through deployment. Our prototype implementation of Atlas integrates several open-source tools to build an ML lifecycle transparency system, and assess the practicality of Atlas through two case study ML pipelines. 

**Abstract (ZH)**: 开源机器学习（ML）数据集和模型的迅速采用使今天的AI应用程序面临数据中毒和供应链攻击等关键风险，这些风险贯穿于整个ML生命周期。随着监管压力不断增加，要求通过更大的透明度来解决这些问题，ML模型供应商在满足这些要求与保护数据和知识产权的保密性之间面临着挑战。我们提出了Atlas框架，旨在实现完整的可验证ML管道。Atlas利用开放的规格来追踪数据和软件供应链的来源，收集可验证的模型制品真实性和端到端的元数据记录。Atlas结合了可信硬件和透明日志来增强元数据的完整性，保护数据的保密性，并在ML管道操作期间限制未经授权的访问，从训练到部署。我们对Atlas的原型实施将多个开源工具整合在一起，构建了一个ML生命周期透明系统，并通过两个案例研究ML管道来评估Atlas的实用性。 

---
# Distill Not Only Data but Also Rewards: Can Smaller Language Models Surpass Larger Ones? 

**Title (ZH)**: 不仅提炼数据，还要提炼奖励：较小的语言模型能否超越较大的模型？ 

**Authors**: Yudi Zhang, Lu Wang, Meng Fang, Yali Du, Chenghua Huang, Jun Wang, Qingwei Lin, Mykola Pechenizkiy, Dongmei Zhang, Saravan Rajmohan, Qi Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2502.19557)  

**Abstract**: Distilling large language models (LLMs) typically involves transferring the teacher model's responses through supervised fine-tuning (SFT). However, this approach neglects the potential to distill both data (output content) and reward signals (quality evaluations). Extracting reliable reward signals directly from teacher models is challenging, as LLMs are optimized for generation rather than evaluation, often resulting in biased or inconsistent assessments. To address this limitation, we propose a novel distillation pipeline that transfers both responses and rewards. Our method generates pseudo-rewards through a self-supervised mechanism that leverages the inherent structure of both teacher and student responses, enabling reward learning without explicit external evaluation. The reward model subsequently guides reinforcement learning (RL), allowing iterative refinement of the student model after an SFT warm-up phase. Experiments on GSM8K and MMLU-PRO demonstrate that our method consistently outperforms traditional SFT-based approaches, enabling student models to surpass the performance of their teachers. This work highlights the potential for scalable, efficient distillation through structured self-supervised reward learning, reducing dependence on external reward supervision. 

**Abstract (ZH)**: 大型语言模型（LLMs）的知识萃取通常涉及通过监督微调（SFT）将教师模型的回答转移到学生模型中。然而，这种方法未能充分利用数据（输出内容）和奖励信号（质量评估）的潜力进行知识萃取。从教师模型中直接提取可靠奖励信号具有挑战性，因为LLMs更侧重于生成而非性能评估，往往导致偏颇或不一致的评价。为解决这一局限，我们提出了一种新的萃取管道，能够转移响应和奖励。该方法通过利用教师模型和学生模型响应中的固有结构，自监督生成伪奖励，从而在无需显式外部评估的情况下进行奖励学习。随后的奖励模型指导强化学习（RL），在SFT预热阶段后逐步优化学生模型。在GSM8K和MMLU-PRO上的实验表明，我们的方法在传统的SFT基础上表现出更优的性能，使学生模型能够超越其教师模型的表现。这项工作突显了结构化的自监督奖励学习在可扩展和高效知识萃取中的潜力，减少了对外部奖励监督的依赖。 

---
# Winning Big with Small Models: Knowledge Distillation vs. Self-Training for Reducing Hallucination in QA Agents 

**Title (ZH)**: 用小模型赢取大胜利：知识蒸馏与自我训练在减少QA代理幻觉中的作用比较 

**Authors**: Ashley Lewis, Michael White, Jing Liu, Toshiaki Koike-Akino, Kieran Parsons, Ye Wang  

**Link**: [PDF](https://arxiv.org/pdf/2502.19545)  

**Abstract**: The deployment of Large Language Models (LLMs) in customer support is constrained by hallucination-generating false information-and the high cost of proprietary models. To address these challenges, we propose a retrieval-augmented question-answering (QA) pipeline and explore how to balance human input and automation. Using a dataset of questions about a Samsung Smart TV user manual, we demonstrate that synthetic data generated by LLMs outperforms crowdsourced data in reducing hallucination in finetuned models. We also compare self-training (fine-tuning models on their own outputs) and knowledge distillation (fine-tuning on stronger models' outputs, e.g., GPT-4o), and find that self-training achieves comparable hallucination reduction. We conjecture that this surprising finding can be attributed to increased exposure bias issues in the knowledge distillation case and support this conjecture with post hoc analysis. We also improve robustness to unanswerable questions and retrieval failures with contextualized "I don't know" responses. These findings show that scalable, cost-efficient QA systems can be built using synthetic data and self-training with open-source models, reducing reliance on proprietary tools or costly human annotations. 

**Abstract (ZH)**: 将大型语言模型（LLMs）部署到客户服务中受到生成虚假信息的幻觉和专有模型高昂成本的限制。为应对这些挑战，我们提出了一种检索增强问答（QA）流水线，并探讨如何平衡人类输入和自动化。我们使用有关三星智能电视用户手册的问题数据集，证明由LLMs生成的合成数据在减少微调模型中的幻觉方面优于众包数据。我们还比较了自训练（使用自身输出进行微调）和知识蒸馏（使用更强模型的输出进行微调，例如GPT-4o），发现自训练在幻觉减少方面达到了相当的效果。我们推测，这种意外的研究结果可能归因于知识蒸馏情况下增加的曝光偏差问题，并通过事后分析支持这一推测。此外，我们通过上下文化的“我不知道”回复改进了系统对无法回答的问题和检索失败的鲁棒性。这些发现表明，可以使用合成数据和开源模型的自训练来构建可扩展、成本效益高的QA系统，从而减少对专有工具或昂贵的人工注释的依赖。 

---
# No, of course I can! Refusal Mechanisms Can Be Exploited Using Harmless Fine-Tuning Data 

**Title (ZH)**: 当然可以！拒绝机制可以利用无害的微调数据进行利用。 

**Authors**: Joshua Kazdan, Lisa Yu, Rylan Schaeffer, Chris Cundy, Sanmi Koyejo, Dvijotham Krishnamurthy  

**Link**: [PDF](https://arxiv.org/pdf/2502.19537)  

**Abstract**: Leading language model (LM) providers like OpenAI and Google offer fine-tuning APIs that allow customers to adapt LMs for specific use cases. To prevent misuse, these LM providers implement filtering mechanisms to block harmful fine-tuning data. Consequently, adversaries seeking to produce unsafe LMs via these APIs must craft adversarial training data that are not identifiably harmful. We make three contributions in this context: 1. We show that many existing attacks that use harmless data to create unsafe LMs rely on eliminating model refusals in the first few tokens of their responses. 2. We show that such prior attacks can be blocked by a simple defense that pre-fills the first few tokens from an aligned model before letting the fine-tuned model fill in the rest. 3. We describe a new data-poisoning attack, ``No, Of course I Can Execute'' (NOICE), which exploits an LM's formulaic refusal mechanism to elicit harmful responses. By training an LM to refuse benign requests on the basis of safety before fulfilling those requests regardless, we are able to jailbreak several open-source models and a closed-source model (GPT-4o). We show an attack success rate (ASR) of 57% against GPT-4o; our attack earned a Bug Bounty from OpenAI. Against open-source models protected by simple defenses, we improve ASRs by an average of 3.25 times compared to the best performing previous attacks that use only harmless data. NOICE demonstrates the exploitability of repetitive refusal mechanisms and broadens understanding of the threats closed-source models face from harmless data. 

**Abstract (ZH)**: 领导者语言模型（Leading Language Models, LMs）提供商如OpenAI和Google提供了微调API，允许用户为特定应用场景适应LM。为了防止滥用，这些LM提供商实现了过滤机制，以阻止有害数据的微调。因此，希望利用这些API生成不安全LM的对手必须精心制作不会被识别为有害的训练数据。在此背景下，我们做出了三项贡献：

1. 我们表明，许多现有攻击利用无害数据生成不安全LM的方法依赖于消除模型在响应的前几个词中的拒绝行为。
2. 我们表明，通过简单的防护措施——在微调模型填充剩余内容之前先从对齐模型中填入前几个词，可以阻止此类先前的攻击。
3. 我们描述了一种新的数据投毒攻击，称为“当然，我可以执行”（No, Of Course I Can Execute, NOICE），这种攻击利用了LM的一些公式化的拒绝机制，诱使其产生有害响应。通过对安全性的考虑，训练LM在履行请求时拒绝良性请求，我们能够突破几个开源模型和一个闭源模型（GPT-4o）的防护。我们针对GPT-4o的攻击成功率（Attack Success Rate, ASR）达到了57%；这个攻击得到了OpenAI的漏洞赏金。相比其他仅使用无害数据的最优攻击方法，我们针对简易防护的开源模型的ASR提高了3.25倍。NOICE展示了重复拒绝机制可以被利用的特性，并扩展了我们对闭源模型在无害数据攻击面前面临威胁的理解。 

---
# Retrieval Augmented Anomaly Detection (RAAD): Nimble Model Adjustment Without Retraining 

**Title (ZH)**: 基于检索增强的异常检测（RAAD）：无需重新训练的灵活模型调整 

**Authors**: Sam Pastoriza, Iman Yousfi, Christopher Redino, Marc Vucovich, Abdul Rahman, Sal Aguinaga, Dhruv Nandakumar  

**Link**: [PDF](https://arxiv.org/pdf/2502.19534)  

**Abstract**: We propose a novel mechanism for real-time (human-in-the-loop) feedback focused on false positive reduction to enhance anomaly detection models. It was designed for the lightweight deployment of a behavioral network anomaly detection model. This methodology is easily integrable to similar domains that require a premium on throughput while maintaining high precision. In this paper, we introduce Retrieval Augmented Anomaly Detection, a novel method taking inspiration from Retrieval Augmented Generation. Human annotated examples are sent to a vector store, which can modify model outputs on the very next processed batch for model inference. To demonstrate the generalization of this technique, we benchmarked several different model architectures and multiple data modalities, including images, text, and graph-based data. 

**Abstract (ZH)**: 我们提出了一种新颖的机制，旨在实现实时（人类在环中）反馈，专注于减少假阳性，以增强异常检测模型。该机制设计用于轻量级部署行为网络异常检测模型。该方法易于集成到需要高吞吐量且保持高精度的类似领域。在这篇论文中，我们引入了检索增强异常检测（Retrieval-Augmented Anomaly Detection，RAAD）方法，该方法从检索增强生成中汲取灵感。人工标注的示例被发送到向量存储中，在处理的下一个批量进行模型推理时，可以修改模型输出。为了展示该技术的通用性，我们在多种不同的模型架构和多种数据模态（包括图像、文本和图数据）上进行了基准测试。 

---
# Cognitive networks highlight differences and similarities in the STEM mindsets of human and LLM-simulated trainees, experts and academics 

**Title (ZH)**: 认知网络突出人类和模拟的LLM、专家和学者在STEM思维方式上的差异与相似性 

**Authors**: Edith Haim, Lars van den Bergh, Cynthia S. Q. Siew, Yoed N. Kenett, Daniele Marinazzo, Massimo Stella  

**Link**: [PDF](https://arxiv.org/pdf/2502.19529)  

**Abstract**: Understanding attitudes towards STEM means quantifying the cognitive and emotional ways in which individuals, and potentially large language models too, conceptualise such subjects. This study uses behavioural forma mentis networks (BFMNs) to investigate the STEM-focused mindset, i.e. ways of associating and perceiving ideas, of 177 human participants and 177 artificial humans simulated by GPT-3.5. Participants were split in 3 groups - trainees, experts and academics - to compare the influence of expertise level on their mindset. The results revealed that human forma mentis networks exhibited significantly higher clustering coefficients compared to GPT-3.5, indicating that human mindsets displayed a tendency to form and close triads of conceptual associations while recollecting STEM ideas. Human experts, in particular, demonstrated robust clustering coefficients, reflecting better integration of STEM concepts into their cognitive networks. In contrast, GPT-3.5 produced sparser mindsets. Furthermore, both human and GPT mindsets framed mathematics in neutral or positive terms, differently from STEM high schoolers, researchers and other large language models sampled in other works. This research contributes to understanding how mindset structure can provide cognitive insights about memory structure and machine limitations. 

**Abstract (ZH)**: 理解人们对STEM学科的态度需要量化个人（包括大型语言模型）对这些学科的认知和情感概念化方式。本研究采用行为模式网络（BFMNs）来探讨177名人类参与者和通过GPT-3.5模拟的177个人工智能主体的STEM导向思维模式，即他们在关联和感知STEM相关概念的方式。参与者被分为三组——学徒、专家和学术界人士——以比较不同专业水平对其思维模式的影响。研究结果表明，人类的思维模式网络的聚类系数显著高于GPT-3.5，表明人类思维倾向于在回忆STEM概念时形成紧密的概念关联三角体。特别是人类专家的聚类系数更加稳健，反映出他们在认知网络中更好地整合了STEM概念。相比之下，GPT-3.5生成的思维模式较为稀疏。此外，无论是人类还是大型语言模型的思维模式都将数学概念化为中性或积极的描述，这与以往研究中采样的STEM高中学生、研究人员及其他大型语言模型有所不同。这项研究为理解思维模式结构如何提供关于记忆结构和机器限制的认知见解做出了贡献。 

---
# Accessing LLMs for Front-end Software Architecture Knowledge 

**Title (ZH)**: 面向前端软件架构知识访问大规模语言模型 

**Authors**: L. P. Franciscatto Guerra, N. Ernst  

**Link**: [PDF](https://arxiv.org/pdf/2502.19518)  

**Abstract**: Large Language Models (LLMs) have demonstrated significant promise in automating software development tasks, yet their capabilities with respect to software design tasks remains largely unclear. This study investigates the capabilities of an LLM in understanding, reproducing, and generating structures within the complex VIPER architecture, a design pattern for iOS applications. We leverage Bloom's taxonomy to develop a comprehensive evaluation framework to assess the LLM's performance across different cognitive domains such as remembering, understanding, applying, analyzing, evaluating, and creating. Experimental results, using ChatGPT 4 Turbo 2024-04-09, reveal that the LLM excelled in higher-order tasks like evaluating and creating, but faced challenges with lower-order tasks requiring precise retrieval of architectural details. These findings highlight both the potential of LLMs to reduce development costs and the barriers to their effective application in real-world software design scenarios. This study proposes a benchmark format for assessing LLM capabilities in software architecture, aiming to contribute toward more robust and accessible AI-driven development tools. 

**Abstract (ZH)**: 大型语言模型（LLMs）在自动化软件开发任务方面展现出了显著的潜力，但它们在软件设计任务方面的能力仍然不清楚。本研究调查了一个LLM在理解、再现和生成 iOS 应用程序复杂 VIPER 架构中的结构的能力。我们利用布卢姆分类法开发了一个全面的评估框架，以评估LLM在不同认知领域（包括记忆、理解、应用、分析、评价和创作）的表现。使用ChatGPT 4 Turbo 2024-04-09进行的实验结果表明，LLM在高级任务如评价和创作中表现出色，但在需要精确检索架构细节的低级任务中面临挑战。这些发现凸显了LLMs在降低开发成本方面的潜力以及在实际软件设计场景中有效应用所面临的障碍。本研究提出了一种评估LLM在软件架构方面能力的基准格式，旨在为更稳健和易获取的AI驱动开发工具作出贡献。 

---
# Mixtraining: A Better Trade-Off Between Compute and Performance 

**Title (ZH)**: Mixtraining: 更佳的计算与性能权衡方案 

**Authors**: Zexin Li, Jiancheng Zhang, Yinglun Zhu, Cong Liu  

**Link**: [PDF](https://arxiv.org/pdf/2502.19513)  

**Abstract**: Incorporating self-supervised learning (SSL) before standard supervised learning (SL) has become a widely used strategy to enhance model performance, particularly in data-limited scenarios. However, this approach introduces a trade-off between computation and performance: while SSL helps with representation learning, it requires a separate, often time-consuming training phase, increasing computational overhead and limiting efficiency in resource-constrained settings. To address these challenges, we propose MixTraining, a novel framework that interleaves several SSL and SL epochs within a unified mixtraining training phase, featuring a smooth transition between two learning objectives. MixTraining enhances synergy between SSL and SL for improved accuracy and consolidates shared computation steps to reduce computation overhead. MixTraining is versatile and applicable to both single-task and multi-task learning scenarios. Extensive experiments demonstrate that MixTraining offers a superior compute-performance trade-off compared to conventional pipelines, achieving an 8.81% absolute accuracy gain (18.89% relative accuracy gain) on the TinyImageNet dataset while accelerating training by up to 1.29x
with the ViT-Tiny model. 

**Abstract (ZH)**: 在标准监督学习（SL）之前引入自监督学习（SSL）已成为提高模型性能的一种广泛采用的策略，特别是在数据有限的情况下。然而，这种方法引入了计算和性能之间的权衡：虽然SSL有助于表示学习，但它需要一个单独的、通常耗时的训练阶段，增加了计算开销并限制了在资源受限环境中的效率。为了应对这些挑战，我们提出了一种名为MixTraining的新框架，该框架在统一的混合训练阶段内交替进行多个SSL和SL epoch，特色是两个学习目标之间的平滑过渡。MixTraining增强了SSL和SL之间的协同作用，以提高精度，并整合共同的计算步骤以减少计算开销。MixTraining既适用于单任务学习也适用于多任务学习场景。广泛的实验证明，与传统的流水线相比，MixTraining提供了更好的计算性能权衡，TinyImageNet数据集上绝对精度提高了8.81%（相对精度提高了18.89%），同时使用ViT-Tiny模型将训练速度加速至最高1.29倍。 

---
# Do LLMs exhibit demographic parity in responses to queries about Human Rights? 

**Title (ZH)**: 大型语言模型在回答人权相关查询时whether LLMs 在回答人权相关查询时是否存在人口统计学公平性？ 

**Authors**: Rafiya Javed, Jackie Kay, David Yanni, Abdullah Zaini, Anushe Sheikh, Maribeth Rauh, Iason Gabriel, Laura Weidinger  

**Link**: [PDF](https://arxiv.org/pdf/2502.19463)  

**Abstract**: This research describes a novel approach to evaluating hedging behaviour in large language models (LLMs), specifically in the context of human rights as defined in the Universal Declaration of Human Rights (UDHR). Hedging and non-affirmation are behaviours that express ambiguity or a lack of clear endorsement on specific statements. These behaviours are undesirable in certain contexts, such as queries about whether different groups are entitled to specific human rights; since all people are entitled to human rights. Here, we present the first systematic attempt to measure these behaviours in the context of human rights, with a particular focus on between-group comparisons. To this end, we design a novel prompt set on human rights in the context of different national or social identities. We develop metrics to capture hedging and non-affirmation behaviours and then measure whether LLMs exhibit demographic parity when responding to the queries. We present results on three leading LLMs and find that all models exhibit some demographic disparities in how they attribute human rights between different identity groups. Futhermore, there is high correlation between different models in terms of how disparity is distributed amongst identities, with identities that have high disparity in one model also facing high disparity in both the other models. While baseline rates of hedging and non-affirmation differ, these disparities are consistent across queries that vary in ambiguity and they are robust across variations of the precise query wording. Our findings highlight the need for work to explicitly align LLMs to human rights principles, and to ensure that LLMs endorse the human rights of all groups equally. 

**Abstract (ZH)**: 本研究提出了一种评估大型语言模型（LLMs）在人权语境下（根据《世界人权宣言》定义的人权）对冲行为的新方法。对冲和非肯定行为表示对具体陈述的模糊或缺乏明确背书。在某些情境下，如有关不同群体是否有权享有特定人权的查询中，这种行为是不理想的，因为所有人均应享有基本人权。为此，我们首次系统地尝试在人权语境下衡量这些行为，特别关注不同群体之间的比较。为了实现这一目标，我们设计了一套专门针对不同国家或社会身份的人权新提示。我们开发了衡量对冲和非肯定行为的指标，然后测量这些指标在各个人工智能模型中的表现，以评估它们在回应查询时是否体现了群体公正。我们对三个主要LILM模型进行了评估，并发现所有模型在赋予不同身份群体人权方面都存在一定程度的群体差异。此外，各个模型在不同身份群体间的差异分布方面存在高度相关性，即在某一模型中存在显著差异的身份群体，在其他模型中也存在显著差异。虽然不同模型的基本对冲和非肯定率有所不同，但这些差异在不同模糊程度的查询中表现出一致性，并且在查询措辞变化时仍然稳定。我们的研究结果强调了明确让大型语言模型符合人权原则的必要性，确保所有群体在享有基本人权方面得到平等的背书。 

---
# Practical Evaluation of Copula-based Survival Metrics: Beyond the Independent Censoring Assumption 

**Title (ZH)**: 基于 copula 的生存指标实用评估：超越独立截尾假设 

**Authors**: Christian Marius Lillelund, Shi-ang Qi, Russell Greiner  

**Link**: [PDF](https://arxiv.org/pdf/2502.19460)  

**Abstract**: Conventional survival metrics, such as Harrell's concordance index and the Brier Score, rely on the independent censoring assumption for valid inference in the presence of right-censored data. However, when instances are censored for reasons related to the event of interest, this assumption no longer holds, as this kind of dependent censoring biases the marginal survival estimates of popular nonparametric estimators. In this paper, we propose three copula-based metrics to evaluate survival models in the presence of dependent censoring, and design a framework to create realistic, semi-synthetic datasets with dependent censoring to facilitate the evaluation of the metrics. Our empirical analyses in synthetic and semi-synthetic datasets show that our metrics can give error estimates that are closer to the true error, mainly in terms of predictive accuracy. 

**Abstract (ZH)**: 传统的生存分析指标，如Harrell的一致性指标和Brier评分，依赖于无关联失访假设，以便在存在右截尾数据时进行有效的推断。然而，当失访原因与研究事件相关时，这一假设不再成立，因为这种相关失访会偏倚流行非参数估计器的边际生存估计。本文中，我们提出了三种基于 copula 的指标，用于评估在相关失访情况下生存模型的表现，并设计了一个框架来创建具有相关失访的现实且半合成数据集，以促进这些指标的评估。我们对合成数据集和半合成数据集的实证分析表明，我们的指标能够给出更接近真实误差的误差估计，特别是在预测准确性方面。 

---
# Multispectral to Hyperspectral using Pretrained Foundational model 

**Title (ZH)**: 使用预训练基础模型将多光谱转化为超光谱 

**Authors**: Ruben Gonzalez, Conrad M Albrecht, Nassim Ait Ali Braham, Devyani Lambhate, Joao Lucas de Sousa Almeida, Paolo Fraccaro, Benedikt Blumenstiel, Thomas Brunschwiler, Ranjini Bangalore  

**Link**: [PDF](https://arxiv.org/pdf/2502.19451)  

**Abstract**: Hyperspectral imaging provides detailed spectral information, offering significant potential for monitoring greenhouse gases like CH4 and NO2. However, its application is constrained by limited spatial coverage and infrequent revisit times. In contrast, multispectral imaging delivers broader spatial and temporal coverage but lacks the spectral granularity required for precise GHG detection. To address these challenges, this study proposes Spectral and Spatial-Spectral transformer models that reconstruct hyperspectral data from multispectral inputs. The models in this paper are pretrained on EnMAP and EMIT datasets and fine-tuned on spatio-temporally aligned (Sentinel-2, EnMAP) and (HLS-S30, EMIT) image pairs respectively. Our model has the potential to enhance atmospheric monitoring by combining the strengths of hyperspectral and multispectral imaging systems. 

**Abstract (ZH)**: hyperspectral 成像提供了详细的光谱信息，为监测诸如甲烷 (CH₄) 和二氧化氮 (NO₂) 等温室气体提供了巨大的潜力。然而，其应用受到有限的空间覆盖范围和不频繁的重访时间的限制。相比之下，多光谱成像提供了更广泛的空间和时间覆盖范围，但缺乏精确检测温室气体所需的光谱分辨率。为解决这些挑战，本研究提出了光谱和空时光谱变换器模型，该模型能够从多光谱输入中重构高光谱数据。本文中的模型分别在 EnMAP 和 EMIT 数据集上预训练，并分别在时空对齐的 Sentinel-2 和 EnMAP 图像对以及 HLS-S30 和 EMIT 图像对上进行微调。我们的模型有望通过结合高光谱和多光谱成像系统的优点，增强大气监测能力。 

---
# Multi-objective Cat Swarm Optimization Algorithm based on a Grid System 

**Title (ZH)**: 基于网格系统的多目标猫群优化算法 

**Authors**: Aram M. Ahmed, Bryar A. Hassan, Tarik A. Rashid, Kaniaw A. Noori, Soran Ab. M. Saeed, Omed H. Ahmed, Shahla U. Umar  

**Link**: [PDF](https://arxiv.org/pdf/2502.19439)  

**Abstract**: This paper presents a multi-objective version of the Cat Swarm Optimization Algorithm called the Grid-based Multi-objective Cat Swarm Optimization Algorithm (GMOCSO). Convergence and diversity preservation are the two main goals pursued by modern multi-objective algorithms to yield robust results. To achieve these goals, we first replace the roulette wheel method of the original CSO algorithm with a greedy method. Then, two key concepts from Pareto Archived Evolution Strategy Algorithm (PAES) are adopted: the grid system and double archive strategy. Several test functions and a real-world scenario called the Pressure vessel design problem are used to evaluate the proposed algorithm's performance. In the experiment, the proposed algorithm is compared with other well-known algorithms using different metrics such as Reversed Generational Distance, Spacing metric, and Spread metric. The optimization results show the robustness of the proposed algorithm, and the results are further confirmed using statistical methods and graphs. Finally, conclusions and future directions were presented.. 

**Abstract (ZH)**: 本文提出了一种基于网格的多目标猫群优化算法（Grid-based Multi-objective Cat Swarm Optimization Algorithm，GMOCSO）。现代多目标算法追求收敛性和多样性的双重目标以获得稳健的结果。为实现这些目标，我们首先用贪婪方法替换了原始猫群优化算法中的轮盘赌方法。然后，采用了Pareto存档进化策略算法（PAES）中的两个关键概念：网格系统和双存档策略。通过多种测试函数和一个实际场景——压力容器设计问题，评估了所提出算法的性能。在实验中，使用不同的度量标准（如倒排序代际距离、间距度量和分散度量），比较了所提算法与其他知名算法的性能。优化结果表明所提出算法的稳健性，并通过统计方法和图形进一步验证了这些结果。最后，总结了结论并指出了未来的研究方向。 

---
# Evolutionary Algorithms Approach For Search Based On Semantic Document Similarity 

**Title (ZH)**: 基于语义文档相似性的搜索进化算法方法 

**Authors**: Chandrashekar Muniyappa, Eujin Kim  

**Link**: [PDF](https://arxiv.org/pdf/2502.19437)  

**Abstract**: Advancements in cloud computing and distributed computing have fostered research activities in Computer science. As a result, researchers have made significant progress in Neural Networks, Evolutionary Computing Algorithms like Genetic, and Differential evolution algorithms. These algorithms are used to develop clustering, recommendation, and question-and-answering systems using various text representation and similarity measurement techniques. In this research paper, Universal Sentence Encoder (USE) is used to capture the semantic similarity of text; And the transfer learning technique is used to apply Genetic Algorithm (GA) and Differential Evolution (DE) algorithms to search and retrieve relevant top N documents based on user query. The proposed approach is applied to the Stanford Question and Answer (SQuAD) Dataset to identify a user query. Finally, through experiments, we prove that text documents can be efficiently represented as sentence embedding vectors using USE to capture the semantic similarity, and by comparing the results of the Manhattan Distance, GA, and DE algorithms we prove that the evolutionary algorithms are good at finding the top N results than the traditional ranking approach. 

**Abstract (ZH)**: 随着云计算和分布式计算的进步，计算机科学领域的研究活动取得了显著进展。研究人员在神经网络、遗传进化计算算法（如遗传算法）和差分进化算法方面取得了重要进展。这些算法被用于开发基于各种文本表示和相似度度量技术的聚类、推荐和问答系统。在本研究论文中，使用了通用句子编码器（USE）来捕捉文本的语义相似性，并利用迁移学习技术将遗传算法（GA）和差分进化算法（DE）应用于根据用户查询搜索和检索相关文档。所提出的方法应用于斯坦福问答（SQuAD）数据集，以识别用户查询。最后，通过实验，我们证明了可以使用USE将文本文档高效地表示为句子嵌入向量以捕捉语义相似性，并通过对比曼哈顿距离、GA和DE算法的结果，证明进化算法在找到前N个结果方面优于传统的排名方法。 

---
# Implementation of a Generative AI Assistant in K-12 Education: The CGScholar AI Helper Initiative 

**Title (ZH)**: K-12教育中生成式AI助教的实施：CGScholar AI助教计划 

**Authors**: Vania Castro, Ana Karina de Oliveira Nascimento, Raigul Zheldibayeva, Duane Searsmith, Akash Saini, Bill Cope, Mary Kalantzis  

**Link**: [PDF](https://arxiv.org/pdf/2502.19422)  

**Abstract**: This paper focuses on the piloting of the CGScholar AI Helper, a Generative AI (GenAI) assistant tool that aims to provide feedback on writing in high school contexts. The aim was to use GenAI to provide formative and summative feedback on students' texts in English Language Arts (ELA) and History. The trials discussed in this paper relate to Grade 11, a crucial learning phase when students are working towards college readiness. These trials took place in two very different schools in the Midwest of the United States, one in a low socio-economic background with low-performance outcomes and the other in a high socio-economic background with high-performance outcomes. The assistant tool used two main mechanisms "prompt engineering" based on participant teachers' assessment rubric and "fine-tuning" a Large Language Model (LLM) from a customized corpus of teaching materials using Retrieval Augmented Generation (RAG). This paper focuses on the CGScholar AI Helper's potential to enhance students' writing abilities and support teachers in ELA and other subject areas requiring written assignments. 

**Abstract (ZH)**: 本文聚焦于CGScholar AI辅助工具的试点应用，该工具是一款生成式人工智能（GenAI）助手，旨在为高中情境下的写作提供反馈。本研究旨在利用GenAI为学生的英语语言艺术（ELA）和历史课程文本提供形成性和总结性反馈。本文所述的实验主要针对第11年级的学生，这是他们为大学做好准备的关键学习阶段。这些实验在美国中西部的两所截然不同的学校进行，一所学校的经济背景较低且成绩较差，另一所学校的经济背景较高且成绩较好。辅助工具采用了两种主要机制：“提示工程”，基于参与者教师的评价标准，并且“微调”了一个通过检索增强生成（RAG）定制教学材料语料库训练的大语言模型（LLM）。本文重点探讨CGScholar AI辅助工具提高学生写作能力以及支持ELA和其他需要写作作业的学科教师的潜力。 

---
# Machine Learning-Based Cloud Computing Compliance Process Automation 

**Title (ZH)**: 基于机器学习的云computing合规过程自动化 

**Authors**: Yuqing Wang, Xiao Yang  

**Link**: [PDF](https://arxiv.org/pdf/2502.16344)  

**Abstract**: Cloud computing adoption across industries has revolutionized enterprise operations while introducing significant challenges in compliance management. Organizations must continuously meet evolving regulatory requirements such as GDPR and ISO 27001, yet traditional manual review processes have become increasingly inadequate for modern business scales. This paper presents a novel machine learning-based framework for automating cloud computing compliance processes, addressing critical challenges including resource-intensive manual reviews, extended compliance cycles, and delayed risk identification. Our proposed framework integrates multiple machine learning technologies, including BERT-based document processing (94.5% accuracy), One-Class SVM for anomaly detection (88.7% accuracy), and an improved CNN-LSTM architecture for sequential compliance data analysis (90.2% accuracy). Implementation results demonstrate significant improvements: reducing compliance process duration from 7 days to 1.5 days, improving accuracy from 78% to 93%, and decreasing manual effort by 73.3%. A real-world deployment at a major securities firm validated these results, processing 800,000 daily transactions with 94.2% accuracy in risk identification. 

**Abstract (ZH)**: 云计算在各行业的应用已经革命性地改变了企业的运营模式，但也带来了合规管理方面的重大挑战。组织必须不断满足不断变化的监管要求，如GDPR和ISO 27001，然而传统的手动审核流程越来越不适用于现代企业的规模。本文提出了一种基于机器学习的新颖框架，以自动化云计算合规流程，解决资源密集型的手动审核、延长的合规周期以及延迟的风险识别等关键挑战。我们提出的框架整合了多种机器学习技术，包括基于BERT的文件处理（准确率94.5%）、One-Class SVM进行异常检测（准确率88.7%），以及改进的CNN-LSTM架构进行顺序合规数据分析（准确率90.2%）。实施结果表明显著改进：将合规流程时间从7天缩短至1.5天，准确率从78%提高至93%，减少手动工作量73.3%。在一家大型证券公司的实际部署中，该框架处理了每日80万笔交易，风险识别准确率为94.2%。 

---
