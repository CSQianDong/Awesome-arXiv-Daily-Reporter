{'arxiv_id': 'arXiv:2501.10326', 'title': 'Large language models for automated scholarly paper review: A survey', 'authors': 'Zhenzhen Zhuang, Jiandong Chen, Hongfeng Xu, Yuwen Jiang, Jialiang Lin', 'link': 'https://arxiv.org/abs/2501.10326', 'abstract': 'Large language models (LLMs) have significantly impacted human society, influencing various domains. Among them, academia is not simply a domain affected by LLMs, but it is also the pivotal force in the development of LLMs. In academic publications, this phenomenon is represented during the incorporation of LLMs into the peer review mechanism for reviewing manuscripts. We proposed the concept of automated scholarly paper review (ASPR) in our previous paper. As the incorporation grows, it now enters the coexistence phase of ASPR and peer review, which is described in that paper. LLMs hold transformative potential for the full-scale implementation of ASPR, but they also pose new issues and challenges that need to be addressed. In this survey paper, we aim to provide a holistic view of ASPR in the era of LLMs. We begin with a survey to find out which LLMs are used to conduct ASPR. Then, we review what ASPR-related technological bottlenecks have been solved with the incorporation of LLM technology. After that, we move on to explore new methods, new datasets, new source code, and new online systems that come with LLMs for ASPR. Furthermore, we summarize the performance and issues of LLMs in ASPR, and investigate the attitudes and reactions of publishers and academia to ASPR. Lastly, we discuss the challenges associated with the development of LLMs for ASPR. We hope this survey can serve as an inspirational reference for the researchers and promote the progress of ASPR for its actual implementation.', 'abstract_zh': '大型语言模型（LLMs）对人类社会产生了重大影响，影响了各个领域。在这些领域中，学术界不仅是LLMs影响的对象，同时也是推动LLMs发展的重要力量。在学术出版物中，这一现象体现在将LLMs纳入同行评审机制以审查手稿的过程中。我们之前提出的概念是“自动化学术论文评审”（ASPR）。随着这一过程的发展，我们现在进入了ASPR与传统同行评审共存的阶段，这部分内容也在我们之前的论文中有所描述。LLMs具有完全实施ASPR的革命性潜力，但同时也带来了新的问题和挑战，需要加以解决。本文旨在提供一份关于在LLMs时代ASPR的全面视角。我们首先进行一项调查，以找出在ASPR中使用的LLMs。然后，我们回顾LLM技术集成过程中解决的ASPR相关技术瓶颈。接着，我们探讨与LLM相关的新方法、新数据集、新源代码和新在线系统在ASPR中的应用。此外，我们总结了在ASPR中LLMs的性能和存在的问题，并调查出版商和学术界对ASPR的态度和反应。最后，我们讨论了为了支撑ASPR发展而面临的LLM开发挑战。我们希望这份调查能够为研究人员提供启发性参考，并促进ASPR的实际实施进程。', 'title_zh': '大型语言模型在自动化学术论文评审中的应用：一项综述'}
{'arxiv_id': 'arXiv:2501.10300', 'title': 'An Ontology for Social Determinants of Education (SDoEd) based on Human-AI Collaborative Approach', 'authors': 'Navya Martin Kollapally, James Geller, Patricia Morreale, Daehan Kwak', 'link': 'https://arxiv.org/abs/2501.10300', 'abstract': 'The use of computational ontologies is well-established in the field of Medical Informatics. The topic of Social Determinants of Health (SDoH) has also received extensive attention. Work at the intersection of ontologies and SDoH has been published. However, a standardized framework for Social Determinants of Education (SDoEd) is lacking. In this paper, we are closing the gap by introducing an SDoEd ontology for creating a precise conceptualization of the interplay between life circumstances of students and their possible educational achievements. The ontology was developed utilizing suggestions from ChatGPT-3.5-010422 and validated using peer-reviewed research articles. The first version of developed ontology was evaluated by human experts in the field of education and validated using standard ontology evaluation software. This version of the SDoEd ontology contains 231 domain concepts, 10 object properties, and 24 data properties', 'abstract_zh': '在医学信息学领域，计算本体的应用已经得到广泛应用。社会决定因素（Social Determinants of Health, SDoH）也是一个受到广泛关注的主题。在本体与SDoH交叉领域的研究已经发表。然而，目前缺乏关于社会决定因素教育（Social Determinants of Education, SDoEd）的标准框架。在本文中，我们通过引入一种SDoEd本体来填补这一空白，以精确地阐述学生生活境遇与其可能教育成就之间的相互作用。该本体是基于ChatGPT-3.5-010422的建议开发，并通过同行评审的研究论文进行了验证。开发的第一个版本经教育领域的专家评审，并使用标准本体评估软件进行了验证。SDoEd本体的这一版本包含231个领域概念、10个对象属性和24个数据属性。', 'title_zh': '基于人-机协作方法的教育社会决定因素本体（SDoEd）'}
{'arxiv_id': 'arXiv:2501.10190', 'title': 'Temporal Causal Reasoning with (Non-Recursive) Structural Equation Models', 'authors': 'Maksim Gladyshev, Natasha Alechina, Mehdi Dastani, Dragan Doder, Brian Logan', 'link': 'https://arxiv.org/abs/2501.10190', 'abstract': 'Structural Equation Models (SEM) are the standard approach to representing causal dependencies between variables in causal models. In this paper we propose a new interpretation of SEMs when reasoning about Actual Causality, in which SEMs are viewed as mechanisms transforming the dynamics of exogenous variables into the dynamics of endogenous variables. This allows us to combine counterfactual causal reasoning with existing temporal logic formalisms, and to introduce a temporal logic, CPLTL, for causal reasoning about such structures. We show that the standard restriction to so-called \\textit{recursive} models (with no cycles in the dependency graph) is not necessary in our approach, allowing us to reason about mutually dependent processes and feedback loops. Finally, we introduce new notions of model equivalence for temporal causal models, and show that CPLTL has an efficient model-checking procedure.', 'abstract_zh': '结构方程模型（SEM）是表示因果模型中变量之间因果依赖的标准方法。在本文中，我们提出了一个关于实际因果关系推理的新解释，在这种解释中，SEM被视为机制，将外生变量的动力学转化为内生变量的动力学。这使我们能够将反事实因果推理与现有的时空逻辑形式主义相结合，并引入一种新的时空逻辑CPLTL，用于此类结构的因果推理。我们展示了标准的递归模型（即依赖图中没有循环）限制在我们的方法中并非必要，从而允许我们分析相互依赖的过程和反馈循环。最后，我们引入了时空因果模型的新模型等价概念，并证明了CPLTL具有高效的模型检查程序。', 'title_zh': '使用（非递归）结构方程模型进行时间因果推理'}
{'arxiv_id': 'arXiv:2501.10186', 'title': 'Generative Artificial Intelligence: Implications for Biomedical and Health Professions Education', 'authors': 'William Hersh', 'link': 'https://arxiv.org/abs/2501.10186', 'abstract': 'Generative AI has had a profound impact on biomedicine and health, both in professional work and in education. Based on large language models (LLMs), generative AI has been found to perform as well as humans in simulated situations taking medical board exams, answering clinical questions, solving clinical cases, applying clinical reasoning, and summarizing information. Generative AI is also being used widely in education, performing well in academic courses and their assessments. This review summarizes the successes of LLMs and highlights some of their challenges in the context of education, most notably aspects that may undermines the acquisition of knowledge and skills for professional work. It then provides recommendations for best practices overcoming shortcomings for LLM use in education. Although there are challenges for use of generative AI in education, all students and faculty, in biomedicine and health and beyond, must have understanding and be competent in its use.', 'abstract_zh': '生成式AI对生物医学和健康领域在专业工作和教育中的影响产生了深远的影响。基于大型语言模型（LLMs），生成式AI已被发现能够在模拟的医学执照考试、回答临床问题、解决临床病例、应用临床推理和总结信息等方面表现得与人类相当。生成式AI在教育中的应用也非常广泛，在学术课程及其评估方面表现良好。本文总结了大型语言模型的成功，并在教育背景下指出了它们的一些挑战，特别是那些可能影响专业工作知识和技能获取的问题。然后，本文提供了克服生成式AI在教育中使用局限性的最佳实践建议。尽管在教育中使用生成式AI存在挑战，但所有学生和教职员工，无论是在生物医学和健康领域，还是其他领域，都必须了解并具备有效地使用生成式AI的能力。', 'title_zh': '生成式人工智能：对生物医学和健康专业教育的影响'}
{'arxiv_id': 'arXiv:2501.10160', 'title': 'CSSDM Ontology to Enable Continuity of Care Data Interoperability', 'authors': 'Subhashis Das, Debashis Naskar, Sara Rodriguez Gonzalez, Pamela Hussey', 'link': 'https://arxiv.org/abs/2501.10160', 'abstract': 'The rapid advancement of digital technologies and recent global pandemic scenarios have led to a growing focus on how these technologies can enhance healthcare service delivery and workflow to address crises. Action plans that consolidate existing digital transformation programs are being reviewed to establish core infrastructure and foundations for sustainable healthcare solutions. Reforming health and social care to personalize home care, for example, can help avoid treatment in overcrowded acute hospital settings and improve the experiences and outcomes for both healthcare professionals and service users. In this information-intensive domain, addressing the interoperability challenge through standards-based roadmaps is crucial for enabling effective connections between health and social care services. This approach facilitates safe and trustworthy data workflows between different healthcare system providers. In this paper, we present a methodology for extracting, transforming, and loading data through a semi-automated process using a Common Semantic Standardized Data Model (CSSDM) to create personalized healthcare knowledge graph (KG). The CSSDM is grounded in the formal ontology of ISO 13940 ContSys and incorporates FHIR-based specifications to support structural attributes for generating KGs. We propose that the CSSDM facilitates data harmonization and linking, offering an alternative approach to interoperability. This approach promotes a novel form of collaboration between companies developing health information systems and cloud-enabled health services. Consequently, it provides multiple stakeholders with access to high-quality data and information sharing.', 'abstract_zh': '近年来，数字化技术的迅猛发展和全球疫情等诸多紧急情况推动了对这些技术如何增强医疗服务交付和工作流程以应对危机的广泛关注。目前正在审查现有的数字化转型计划，以建立可持续医疗解决方案的核心基础设施和基础。例如，改革健康和社会护理，以个性化家庭护理，可以避免在拥挤的急性医院环境中接受治疗，并改善医疗服务提供者和用户的经验和结果。在信息密集型的这一领域，通过基于标准的路线图解决互操作性挑战至关重要，这有助于在健康和社会护理服务之间建立有效的连接。这种方式促进了不同医疗服务提供者之间的安全和可信赖的数据流程。本文介绍了一种利用公共语义标准化数据模型（CSSDM）通过半自动化过程提取、转换和加载数据的方法，以创建个性化的健康知识图（KG）。CSSDM基于ISO 13940 ContSys的形式本体，并结合FHIR规范支持结构属性，以支持生成KGs。我们提出，CSSDM促进了数据的协调和链接，提供了一种新的互操作性方法。这种方法促进了开发健康信息系统和基于云的医疗服务的公司之间的新型合作。因此，它为多个利益相关者提供了高质量的数据和信息共享的途径。', 'title_zh': 'CSSDM概念模型以促进连续护理数据互操作性'}
{'arxiv_id': 'arXiv:2501.10151', 'title': 'Topology-Driven Attribute Recovery for Attribute Missing Graph Learning in Social Internet of Things', 'authors': 'Mengran Li, Junzhou Chen, Chenyun Yu, Guanying Jiang, Ronghui Zhang, Yanming Shen, Houbing Herbert Song', 'link': 'https://arxiv.org/abs/2501.10151', 'abstract': "With the advancement of information technology, the Social Internet of Things (SIoT) has fostered the integration of physical devices and social networks, deepening the study of complex interaction patterns. Text Attribute Graphs (TAGs) capture both topological structures and semantic attributes, enhancing the analysis of complex interactions within the SIoT. However, existing graph learning methods are typically designed for complete attributed graphs, and the common issue of missing attributes in Attribute Missing Graphs (AMGs) increases the difficulty of analysis tasks. To address this, we propose the Topology-Driven Attribute Recovery (TDAR) framework, which leverages topological data for AMG learning. TDAR introduces an improved pre-filling method for initial attribute recovery using native graph topology. Additionally, it dynamically adjusts propagation weights and incorporates homogeneity strategies within the embedding space to suit AMGs' unique topological structures, effectively reducing noise during information propagation. Extensive experiments on public datasets demonstrate that TDAR significantly outperforms state-of-the-art methods in attribute reconstruction and downstream tasks, offering a robust solution to the challenges posed by AMGs. The code is available at this https URL.", 'abstract_zh': '随着信息技术的进步，社会物联网（SIoT）促进了物理设备与社会网络的集成，加深了对复杂交互模式的研究。文字属性图（TAGs）既捕捉拓扑结构又包含语义属性，增强了SIoT中复杂交互的分析。然而，现有的图学习方法通常设计用于完备属性图，而属性缺失图（AMGs）中常见的属性缺失问题增加了数据分析任务的难度。为了解决这一问题，我们提出了基于拓扑驱动的属性恢复（TDAR）框架，该框架利用拓扑数据进行AMG学习。TDAR引入了一种改进的预填充方法，使用原始图拓扑进行初始属性恢复。此外，它动态调整传播权重并在嵌入空间中引入同质性策略，以适应AMGs的独特拓扑结构，在信息传播过程中有效减少了噪声。在公共数据集上进行的广泛实验表明，TDAR在属性重建和下游任务中显著优于现有最先进的方法，提供了一种应对AMGs挑战的稳健解决方案。相关代码可以在该链接访问：this https URL。', 'title_zh': '基于拓扑驱动的属性恢复方法在社会物联网中的属性缺失图学习'}
{'arxiv_id': 'arXiv:2501.10134', 'title': 'Exploring the Impact of Generative Artificial Intelligence in Education: A Thematic Analysis', 'authors': 'Abhishek Kaushik, Sargam Yadav, Andrew Browne, David Lillis, David Williams, Jack Mc Donnell, Peadar Grant, Siobhan Connolly Kernan, Shubham Sharma, Mansi Arora', 'link': 'https://arxiv.org/abs/2501.10134', 'abstract': 'The recent advancements in Generative Artificial intelligence (GenAI) technology have been transformative for the field of education. Large Language Models (LLMs) such as ChatGPT and Bard can be leveraged to automate boilerplate tasks, create content for personalised teaching, and handle repetitive tasks to allow more time for creative thinking. However, it is important to develop guidelines, policies, and assessment methods in the education sector to ensure the responsible integration of these tools. In this article, thematic analysis has been performed on seven essays obtained from professionals in the education sector to understand the advantages and pitfalls of using GenAI models such as ChatGPT and Bard in education. Exploratory Data Analysis (EDA) has been performed on the essays to extract further insights from the text. The study found several themes which highlight benefits and drawbacks of GenAI tools, as well as suggestions to overcome these limitations and ensure that students are using these tools in a responsible and ethical manner.', 'abstract_zh': '生成型人工智能（GenAI）技术的近期发展正在对教育领域产生变革性的影响。大型语言模型（LLMs）如ChatGPT和Bard可以自动化一些模板化任务，为个性化教学创建内容，并处理重复性任务，从而为创造性的思考提供更多时间。然而，在教育领域中整合这些工具时，必须开发相应的指导方针、政策和评估方法以确保其负责任的使用。本文通过对教育领域专业人士撰写的七篇论文进行了主题分析，以了解在教育中使用ChatGPT和Bard等GenAI模型的优势与挑战。此外，还进行了探索性数据分析（EDA）以从文本中提取更多见解。研究发现了一些主题，这些主题不仅指出了GenAI工具的优势和不足之处，而且还提出了克服这些限制的建议，以确保学生能够负责任且符合道德地使用这些工具。', 'title_zh': '探索生成式人工智能在教育中的影响：一种主题分析'}
{'arxiv_id': 'arXiv:2501.10114', 'title': 'Infrastructure for AI Agents', 'authors': 'Alan Chan, Kevin Wei, Sihao Huang, Nitarshan Rajkumar, Elija Perrier, Seth Lazar, Gillian K. Hadfield, Markus Anderljung', 'link': 'https://arxiv.org/abs/2501.10114', 'abstract': "Increasingly many AI systems can plan and execute interactions in open-ended environments, such as making phone calls or buying online goods. As developers grow the space of tasks that such AI agents can accomplish, we will need tools both to unlock their benefits and manage their risks. Current tools are largely insufficient because they are not designed to shape how agents interact with existing institutions (e.g., legal and economic systems) or actors (e.g., digital service providers, humans, other AI agents). For example, alignment techniques by nature do not assure counterparties that some human will be held accountable when a user instructs an agent to perform an illegal action. To fill this gap, we propose the concept of agent infrastructure: technical systems and shared protocols external to agents that are designed to mediate and influence their interactions with and impacts on their environments. Agent infrastructure comprises both new tools and reconfigurations or extensions of existing tools. For example, to facilitate accountability, protocols that tie users to agents could build upon existing systems for user authentication, such as OpenID. Just as the Internet relies on infrastructure like HTTPS, we argue that agent infrastructure will be similarly indispensable to ecosystems of agents. We identify three functions for agent infrastructure: 1) attributing actions, properties, and other information to specific agents, their users, or other actors; 2) shaping agents' interactions; and 3) detecting and remedying harmful actions from agents. We propose infrastructure that could help achieve each function, explaining use cases, adoption, limitations, and open questions. Making progress on agent infrastructure can prepare society for the adoption of more advanced agents.", 'abstract_zh': '越来越多的AI系统能够在开放环境中规划和执行交互，例如拨打电话或在线购买商品。随着开发人员扩展此类AI代理能够完成的任务范围，我们需要工具来充分利用这些技术的优势并管理其带来的风险。当前的工具远不足以满足需求，因为它们未设计用于干预代理与现有机构（如法律和经济体系）或参与者（如数字服务提供商、人类及其他AI代理）的互动方式。例如，尽管对齐技术本质上无法保证当用户指示代理执行非法行为时，其行为将被认可并承担责任。为填补这一空白，我们提出了“代理基础设施”的概念：这些技术系统和外部共享协议旨在调解和影响代理与其环境之间的互动及其影响。代理基础设施既包括新工具，也包括现有工具的重组或扩展。例如，为促进可问责性，用户与代理关联的协议可以利用现有的用户身份验证系统（如OpenID）来构建。正如互联网依赖于HTTPS等基础设施一样，我们认为代理基础设施也将成为代理生态系统中不可或缺的部分。我们识别了代理基础设施的三种功能：1) 将代理、其用户或其它参与者的行为、属性及其他信息归因；2) 影响代理的互动；3) 检测并纠正代理的有害行为。我们提出了能够实现这些功能的基础设施，并解释了其应用场景、采纳情况、局限性和开放问题。推进代理基础设施的建设可以为更先进代理的普及做好准备。', 'title_zh': 'AI代理的基础设施'}
{'arxiv_id': 'arXiv:2501.10106', 'title': 'LLM Reasoner and Automated Planner: A new NPC approach', 'authors': 'Israel Puerta-Merino, Jordi Sabater-Mir', 'link': 'https://arxiv.org/abs/2501.10106', 'abstract': 'In domains requiring intelligent agents to emulate plausible human-like behaviour, such as formative simulations, traditional techniques like behaviour trees encounter significant challenges. Large Language Models (LLMs), despite not always yielding optimal solutions, usually offer plausible and human-like responses to a given problem. In this paper, we exploit this capability and propose a novel architecture that integrates an LLM for decision-making with a classical automated planner that can generate sound plans for that decision. The combination aims to equip an agent with the ability to make decisions in various situations, even if they were not anticipated during the design phase.', 'abstract_zh': '在需要智能代理模仿人类行为的领域，如形成性模拟中，传统方法如行为树面临重大挑战。尽管大型语言模型（LLMs）通常不能总是提供最优解，但通常能提供合理且类似人类的响应。本文利用这一能力，提出了一种新的架构，该架构将LLM用于决策制定与经典的自动规划器相结合，后者能够生成支持该决策的可信计划。此组合旨在使代理能够在各种情况下做出决策，即使这些情况在设计阶段并未预见。', 'title_zh': '大规模语言模型推理器和自动规划器：一种新的NPC方法'}
{'arxiv_id': 'arXiv:2501.10069', 'title': 'A Survey on LLM Test-Time Compute via Search: Tasks, LLM Profiling, Search Algorithms, and Relevant Frameworks', 'authors': 'Xinzhe Li', 'link': 'https://arxiv.org/abs/2501.10069', 'abstract': 'LLM test-time compute (or LLM inference) via search has emerged as a promising research area with rapid developments. However, current frameworks often adopt distinct perspectives on three key aspects (task definition, LLM profiling, and search procedures), making direct comparisons challenging. Moreover, the search algorithms employed often diverge from standard implementations, and their specific characteristics are not thoroughly specified. In this survey, we provide a comprehensive technical review that unifies task definitions and provides modular definitions of LLM profiling and search procedures. The definitions enable precise comparisons of various LLM inference frameworks while highlighting their departures from conventional search algorithms. We also discuss the applicability, performance, and efficiency of these methods. For further details and ongoing updates, please refer to our GitHub repository: this https URL', 'abstract_zh': '基于搜索的大型语言模型（LLM）测试时计算（或推断）近年来已成为一个充满前景的研究领域，伴随着快速的发展。然而，当前的框架在任务定义、LLM分析和搜索过程三个方面通常采用不同的视角，这使得直接比较变得困难。此外，所使用的搜索算法往往不同于标准实现，其具体特征也没有得到充分规定。在本文综述中，我们提供了一个全面的技术回顾，统一了任务定义，并提供了模块化的LLM分析和搜索过程定义。这些定义使各种LLM推断框架之间的精确比较成为可能，同时突显了它们与传统搜索算法的不同之处。我们还讨论了这些方法的适用性、性能和效率。如需更多详细信息或最新更新，请参阅我们的GitHub仓库：[这个链接](this https URL)。', 'title_zh': '关于通过搜索进行大模型测试时计算的研究综述：任务、大模型分析、搜索算法及相关框架'}
{'arxiv_id': 'arXiv:2501.10053', 'title': 'AirRAG: Activating Intrinsic Reasoning for Retrieval Augmented Generation via Tree-based Search', 'authors': 'Wenfeng Feng, Chuzhan Hao, Yuewei Zhang, Jingyi Song, Hao Wang', 'link': 'https://arxiv.org/abs/2501.10053', 'abstract': 'Leveraging the autonomous decision-making capabilities of large language models (LLMs) demonstrates superior performance in reasoning tasks. Despite the successes of iterative or recursive retrieval-augmented generation (RAG), they often are trapped in a single solution space when confronted with complex tasks. In this paper, we propose a novel thinking pattern in RAG which integrates system analysis with efficient reasoning actions, significantly activating intrinsic reasoning capabilities and expanding the solution space of specific tasks via Monte Carlo Tree Search (MCTS), dubbed AirRAG. Specifically, our approach designs five fundamental reasoning actions that are expanded to a wide tree-based reasoning spaces using MCTS. The extension also uses self-consistency verification to explore potential reasoning paths and implement inference scaling. In addition, computationally optimal strategies are used to apply more inference computation to key actions to achieve further performance improvements. Experimental results demonstrate the effectiveness of AirRAG through considerable performance gains over complex QA datasets. Furthermore, AirRAG is flexible and lightweight, making it easy to integrate with other advanced technologies.', 'abstract_zh': '利用大型语言模型（LLMs）的自主决策能力在推理任务中展现了优异的表现。尽管迭代或递归检索增强生成（RAG）方法取得了成功，但在面对复杂任务时，它们往往受限于单一的解决方案空间。本文提出了一种名为AirRAG的新颖的RAG推理模式，该方法将系统分析与高效的推理动作相结合，通过蒙特卡洛树搜索（MCTS）显著激活内在的推理能力，并通过这种方法扩展特定任务的解决方案空间。具体而言，我们的方法设计了五个基本的推理动作，并通过MCTS扩展到广泛的树结构推理空间。扩展还采用了自我一致性验证来探索潜在的推理路径并实现推理扩展。此外，使用计算上优化的策略将更多的推理计算应用到关键动作上，以实现进一步的性能提升。实验结果显示，与复杂的QA数据集相比，AirRAG在性能提升方面具有明显的效果。此外，AirRAG具有高度的灵活性和轻量级特性，使其易于与其他先进技术集成。', 'title_zh': 'AirRAG：通过树状搜索激活内在推理以增强检索生成\n\n这个翻译符合学术规范，保留了原文的核心概念和结构。希望这对你有帮助！如果有更具体的内容需要翻译或进一步的帮助，请告诉我。'}
{'arxiv_id': 'arXiv:2501.10041', 'title': 'Spatiotemporal Prediction of Secondary Crashes by Rebalancing Dynamic and Static Data with Generative Adversarial Networks', 'authors': 'Junlan Chen, Yiqun Li, Chenyu Ling, Ziyuan Pu, Xiucheng Guo', 'link': 'https://arxiv.org/abs/2501.10041', 'abstract': "Data imbalance is a common issue in analyzing and predicting sudden traffic events. Secondary crashes constitute only a small proportion of all crashes. These secondary crashes, triggered by primary crashes, significantly exacerbate traffic congestion and increase the severity of incidents. However, the severe imbalance of secondary crash data poses significant challenges for prediction models, affecting their generalization ability and prediction accuracy. Existing methods fail to fully address the complexity of traffic crash data, particularly the coexistence of dynamic and static features, and often struggle to effectively handle data samples of varying lengths. Furthermore, most current studies predict the occurrence probability and spatiotemporal distribution of secondary crashes separately, lacking an integrated solution. To address these challenges, this study proposes a hybrid model named VarFusiGAN-Transformer, aimed at improving the fidelity of secondary crash data generation and jointly predicting the occurrence and spatiotemporal distribution of secondary crashes. The VarFusiGAN-Transformer model employs Long Short-Term Memory (LSTM) networks to enhance the generation of multivariate long-time series data, incorporating a static data generator and an auxiliary discriminator to model the joint distribution of dynamic and static features. In addition, the model's prediction module achieves simultaneous prediction of both the occurrence and spatiotemporal distribution of secondary crashes. Compared to existing methods, the proposed model demonstrates superior performance in generating high-fidelity data and improving prediction accuracy.", 'abstract_zh': '数据不平衡是分析和预测突发交通事件中的一个常见问题。二次碰撞只占所有碰撞中的一小部分，这些由一次碰撞引发的二次碰撞显著加剧了交通拥堵并增加了事件的严重性。然而，二次碰撞数据的严重不平衡给预测模型带来了巨大挑战，影响了它们的泛化能力和预测准确性。现有方法未能充分解决交通碰撞数据的复杂性，特别是在动态和静态特征共存的情况下，通常难以有效处理不同长度的数据样本。此外，大多数现有研究分别预测二次碰撞的发生概率和空间-时间分布，缺乏一个集成的解决方案。为了解决这些问题，本研究提出了一个混合模型——VarFusiGAN-Transformer，旨在提高二次碰撞数据生成的真实性，并同时预测二次碰撞的发生和空间-时间分布。VarFusiGAN-Transformer模型利用长短期记忆（LSTM）网络增强多变量长时间序列数据的生成，结合静态数据生成器和辅助判别器来建模动态和静态特征的联合分布。此外，该模型的预测模块实现了二次碰撞的发生和空间-时间分布的同时预测。与现有方法相比，所提出的模型在生成高真实度数据和提高预测准确性方面表现出更优的性能。', 'title_zh': '使用生成对抗网络平衡动态和静态数据以预测次生事故的空间-时间分布'}
{'arxiv_id': 'arXiv:2501.10017', 'title': 'Enhancing Crash Frequency Modeling Based on Augmented Multi-Type Data by Hybrid VAE-Diffusion-Based Generative Neural Networks', 'authors': 'Junlan Chen, Qijie He, Pei Liu, Wei Ma, Ziyuan Pu', 'link': 'https://arxiv.org/abs/2501.10017', 'abstract': 'Crash frequency modelling analyzes the impact of factors like traffic volume, road geometry, and environmental conditions on crash occurrences. Inaccurate predictions can distort our understanding of these factors, leading to misguided policies and wasted resources, which jeopardize traffic safety. A key challenge in crash frequency modelling is the prevalence of excessive zero observations, caused by underreporting, the low probability of crashes, and high data collection costs. These zero observations often reduce model accuracy and introduce bias, complicating safety decision making. While existing approaches, such as statistical methods, data aggregation, and resampling, attempt to address this issue, they either rely on restrictive assumptions or result in significant information loss, distorting crash data. To overcome these limitations, we propose a hybrid VAE-Diffusion neural network, designed to reduce zero observations and handle the complexities of multi-type tabular crash data (count, ordinal, nominal, and real-valued variables). We assess the synthetic data quality generated by this model through metrics like similarity, accuracy, diversity, and structural consistency, and compare its predictive performance against traditional statistical models. Our findings demonstrate that the hybrid VAE-Diffusion model outperforms baseline models across all metrics, offering a more effective approach to augmenting crash data and improving the accuracy of crash frequency predictions. This study highlights the potential of synthetic data to enhance traffic safety by improving crash frequency modelling and informing better policy decisions.', 'abstract_zh': '交通事故频率建模分析了交通流量、道路几何结构和环境条件等因素对交通事故发生的影响。不准确的预测可能会扭曲我们对这些因素的理解，导致决策失误和资源浪费，从而威胁交通安全。交通事故频率建模的一个关键挑战是观察到的零事件（即没有发生事故）过多，这可能是由于报告不足、事故发生的低概率以及数据收集成本高所导致。这些零事件往往降低了模型的准确性并引入偏倚，使得安全决策过程复杂化。尽管现有的方法，如统计方法、数据聚合和重采样等，试图解决这一问题，但它们要么依赖于严格的假设，要么会导致大量信息丢失，从而扭曲事故数据。\n\n为克服这些局限，我们提出了一种结合VAE（变分自编码器）和扩散神经网络的混合模型，旨在减少零事件并处理多类型表格事故数据（计数、序数、名义和实值变量）的复杂性。我们通过相似度、准确性、多样性和结构一致性等指标评估该模型生成的合成数据质量，并将其预测性能与传统的统计模型进行比较。研究表明，该混合VAE-扩散模型在所有评估指标上均优于基线模型，提供了更有效的事故数据增强方法，提高了交通事故频率预测的准确性。本研究突显了合成数据在增强交通安全方面的作用，通过改进交通事故频率建模和制定更好的政策决策。', 'title_zh': '基于扩展多类型数据的混合VAE-扩散生成神经网络增强碰撞频率建模'}
{'arxiv_id': 'arXiv:2501.09926', 'title': 'ForestProtector: An IoT Architecture Integrating Machine Vision and Deep Reinforcement Learning for Efficient Wildfire Monitoring', 'authors': 'Kenneth Bonilla-Ormachea, Horacio Cuizaga, Edwin Salcedo, Sebastian Castro, Sergio Fernandez-Testa, Misael Mamani', 'link': 'https://arxiv.org/abs/2501.09926', 'abstract': "Early detection of forest fires is crucial to minimizing the environmental and socioeconomic damage they cause. Indeed, a fire's duration directly correlates with the difficulty and cost of extinguishing it. For instance, a fire burning for 1 minute might require 1 liter of water to extinguish, while a 2-minute fire could demand 100 liters, and a 10-minute fire might necessitate 1,000 liters. On the other hand, existing fire detection systems based on novel technologies (e.g., remote sensing, PTZ cameras, UAVs) are often expensive and require human intervention, making continuous monitoring of large areas impractical. To address this challenge, this work proposes a low-cost forest fire detection system that utilizes a central gateway device with computer vision capabilities to monitor a 360° field of view for smoke at long distances. A deep reinforcement learning agent enhances surveillance by dynamically controlling the camera's orientation, leveraging real-time sensor data (smoke levels, ambient temperature, and humidity) from distributed IoT devices. This approach enables automated wildfire monitoring across expansive areas while reducing false positives.", 'abstract_zh': '早期检测森林火灾对于最小化其造成的环境和经济社会损害至关重要。事实上，火灾的持续时间直接关系到扑灭难度和成本。例如，燃烧1分钟的火灾可能只需要1升水来扑灭，而燃烧2分钟的火灾可能需要100升水，10分钟的火灾可能需要1000升水。相比之下，基于新型技术（如遥感、PTZ摄像头、无人机）的现有火灾检测系统通常较为昂贵，并且需要人工干预，这使得对大面积区域进行连续监控变得不切实际。为应对这一挑战，本研究提出了一种低成本的森林火灾检测系统，该系统利用具有计算机视觉能力的中央网关设备，对远距离的360°视野进行监控以识别烟雾。深度强化学习代理通过动态控制摄像头的方向，利用分布式物联网设备提供的实时传感器数据（如烟雾浓度、环境温度和湿度）来增强监控。该方法能够在大面积区域内实现自动化的野火监测，并减少误报。', 'title_zh': 'ForestProtector：一种集成机器视觉和深度强化学习的物联网架构，用于高效的森林火灾监控'}
{'arxiv_id': 'arXiv:2501.09918', 'title': 'GenSC-6G: A Prototype Testbed for Integrated Generative AI, Quantum, and Semantic Communication', 'authors': 'Brian E. Arfeto, Shehbaz Tariq, Uman Khalid, Trung Q. Duong, Hyundong Shin', 'link': 'https://arxiv.org/abs/2501.09918', 'abstract': 'We introduce a prototyping testbed, GenSC-6G, developed to generate a comprehensive dataset that supports the integration of generative artificial intelligence (AI), quantum computing, and semantic communication for emerging sixth-generation (6G) applications. The GenSC-6G dataset is designed with noise-augmented synthetic data optimized for semantic decoding, classification, and localization tasks, significantly enhancing flexibility for diverse AI-driven communication applications. This adaptable prototype supports seamless modifications across baseline models, communication modules, and goal-oriented decoders. Case studies demonstrate its application in lightweight classification, semantic upsampling, and edge-based language inference under noise conditions. The GenSC-6G dataset serves as a scalable and robust resource for developing goal-oriented communication systems tailored to the growing demands of 6G networks.', 'abstract_zh': '我们介绍了一个原型测试平台GenSC-6G，该平台旨在生成一个综合数据集，以支持生成型人工智能(AI)、量子计算和语义通信在新兴第六代(6G)应用中的集成。GenSC-6G数据集采用噪声增强的合成数据设计，优化了语义解码、分类和定位任务，显著增强了针对不同AI驱动通信应用的灵活性。该可适应的原型平台可在基础模型、通信模块和目标导向解码器之间无缝修改。案例研究展示了其在轻量级分类、语义上采样和基于边缘的语言推断等噪声条件下的应用。GenSC-6G数据集作为开发符合6G网络不断增长需求的目标导向通信系统的可扩展且稳健的资源。', 'title_zh': 'GenSC-6G：生成式AI、量子技术和语义通信综合的原型试验台'}
{'arxiv_id': 'arXiv:2501.09913', 'title': 'Towards A Litmus Test for Common Sense', 'authors': 'Hugo Latapie', 'link': 'https://arxiv.org/abs/2501.09913', 'abstract': 'This paper is the second in a planned series aimed at envisioning a path to safe and beneficial artificial intelligence. Building on the conceptual insights of "Common Sense Is All You Need," we propose a more formal litmus test for common sense, adopting an axiomatic approach that combines minimal prior knowledge (MPK) constraints with diagonal or Godel-style arguments to create tasks beyond the agent\'s known concept set. We discuss how this approach applies to the Abstraction and Reasoning Corpus (ARC), acknowledging training/test data constraints, physical or virtual embodiment, and large language models (LLMs). We also integrate observations regarding emergent deceptive hallucinations, in which more capable AI systems may intentionally fabricate plausible yet misleading outputs to disguise knowledge gaps. The overarching theme is that scaling AI without ensuring common sense risks intensifying such deceptive tendencies, thereby undermining safety and trust. Aligning with the broader goal of developing beneficial AI without causing harm, our axiomatic litmus test not only diagnoses whether an AI can handle truly novel concepts but also provides a stepping stone toward an ethical, reliable foundation for future safe, beneficial, and aligned artificial intelligence.', 'abstract_zh': '本文是旨在构想一条实现安全且有益的人工智能路径的一系列计划中的第二篇论文。基于“常识即一切所必需”的概念洞察，我们提出了一种更为形式化的常识检验标准，采用公理化方法，结合最小先验知识（MPK）约束与对角线或哥德尔式论据，以创建超出代理已知概念集的任务。我们讨论了这种方法如何应用于抽象与推理语料库（ARC），同时也承认训练/测试数据限制、物理或虚拟实体化以及大语言模型（LLMs）的问题。此外，我们还整合了关于自发放谎现象的观察，这种现象中，更具能力的AI系统可能会故意制造出看似真实但具有误导性的输出，以掩盖知识缺口。总体而言，这一主题是，如果没有确保常识，单纯扩大AI规模可能会加剧这种自发放谎倾向，从而削弱安全性和信任度。符合更广泛的目标——即在不造成伤害的情况下开发有益的AI——我们的公理化检验标准不仅诊断AI能否处理真正新颖的概念，还为建设伦理、可靠的基础以支持未来安全、有益和对齐的人工智能提供了一个步骤。', 'title_zh': '向着常识评估标准的构建'}
{'arxiv_id': 'arXiv:2501.09891', 'title': 'Evolving Deeper LLM Thinking', 'authors': 'Kuang-Huei Lee, Ian Fischer, Yueh-Hua Wu, Dave Marwood, Shumeet Baluja, Dale Schuurmans, Xinyun Chen', 'link': 'https://arxiv.org/abs/2501.09891', 'abstract': 'We explore an evolutionary search strategy for scaling inference time compute in Large Language Models. The proposed approach, Mind Evolution, uses a language model to generate, recombine and refine candidate responses. The proposed approach avoids the need to formalize the underlying inference problem whenever a solution evaluator is available. Controlling for inference cost, we find that Mind Evolution significantly outperforms other inference strategies such as Best-of-N and Sequential Revision in natural language planning tasks. In the TravelPlanner and Natural Plan benchmarks, Mind Evolution solves more than 98% of the problem instances using Gemini 1.5 Pro without the use of a formal solver.', 'abstract_zh': '我们探索了一种进化搜索策略，以扩展大型语言模型的推理时间计算能力。所提出的方法名为Mind Evolution，利用语言模型生成、重组并优化候选答案。该方法避免了在有解决方案评估器可用时需要形式化底层推理问题的需要。在控制推理成本的情况下，我们发现Mind Evolution在自然语言规划任务中显著优于其他推理策略，如Best-of-N和序列修订。在TravelPlanner和Natural Plan基准测试中，没有使用正式解算器的情况下，Mind Evolution解决了超过98%的问题实例，使用的模型为Gemini 1.5 Pro。', 'title_zh': '演化更深的大型语言模型思维'}
{'arxiv_id': 'arXiv:2501.09890', 'title': 'Exploring the Implementation of AI in Early Onset Interviews to Help Mitigate Bias', 'authors': 'Nishka Lal, Omar Benkraouda', 'link': 'https://arxiv.org/abs/2501.09890', 'abstract': "This paper investigates the application of artificial intelligence (AI) in early-stage recruitment interviews in order to reduce inherent bias, specifically sentiment bias. Traditional interviewers are often subject to several biases, including interviewer bias, social desirability effects, and even confirmation bias. In turn, this leads to non-inclusive hiring practices, and a less diverse workforce. This study further analyzes various AI interventions that are present in the marketplace today such as multimodal platforms and interactive candidate assessment tools in order to gauge the current market usage of AI in early-stage recruitment. However, this paper aims to use a unique AI system that was developed to transcribe and analyze interview dynamics, which emphasize skill and knowledge over emotional sentiments. Results indicate that AI effectively minimizes sentiment-driven biases by 41.2%, suggesting its revolutionizing power in companies' recruitment processes for improved equity and efficiency.", 'abstract_zh': '本文探讨了人工智能（AI）在早期招聘面试中的应用，以减少固有的偏见，特别是情感偏见。传统面试官往往会受到多种偏见的影响，包括面试者偏见、社会赞许效应以及确认偏见。这导致了选拔过程中的非包容性行为，进而导致工作队伍更加同质化。本文进一步分析了市场上现有的各种AI干预措施，如多模态平台和互动候选人评估工具，以评估AI在早期招聘中的当前市场应用情况。然而，本文旨在使用一种独特的AI系统，该系统能够转录和分析面试动态，注重技能和知识而非情感因素。结果显示，AI有效地减少了41.2%的情感驱动偏见，表明其在公司招聘流程中具有变革性的力量，以提高公平性和效率。', 'title_zh': '探究AI在早期采访中的应用实施以减轻偏见'}
{'arxiv_id': 'arXiv:2501.10343', 'title': '3rd Workshop on Maritime Computer Vision (MaCVi) 2025: Challenge Results', 'authors': 'Benjamin Kiefer, Lojze Žust, Jon Muhovič, Matej Kristan, Janez Perš, Matija Teršek, Uma Mudenagudi Chaitra Desai, Arnold Wiliem, Marten Kreis, Nikhil Akalwadi, Yitong Quan, Zhiqiang Zhong, Zhe Zhang, Sujie Liu, Xuran Chen, Yang Yang, Matej Fabijanić, Fausto Ferreira, Seongju Lee, Junseok Lee, Kyoobin Lee, Shanliang Yao, Runwei Guan, Xiaoyu Huang, Yi Ni, Himanshu Kumar, Yuan Feng, Yi-Ching Cheng, Tzu-Yu Lin, Chia-Ming Lee, Chih-Chung Hsu, Jannik Sheikh, Andreas Michel, Wolfgang Gross, Martin Weinmann, Josip Šarić, Yipeng Lin, Xiang Yang, Nan Jiang, Yutang Lu, Fei Feng, Ali Awad, Evan Lucas, Ashraf Saleem, Ching-Heng Cheng, Yu-Fan Lin, Tzu-Yu Lin, Chih-Chung Hsu', 'link': 'https://arxiv.org/abs/2501.10343', 'abstract': 'The 3rd Workshop on Maritime Computer Vision (MaCVi) 2025 addresses maritime computer vision for Unmanned Surface Vehicles (USV) and underwater. This report offers a comprehensive overview of the findings from the challenges. We provide both statistical and qualitative analyses, evaluating trends from over 700 submissions. All datasets, evaluation code, and the leaderboard are available to the public at this https URL.', 'abstract_zh': '第三届海洋计算机视觉研讨会（MaCVi 2025）专注于无人驾驶表面车辆（USV）和水下环境中的海洋计算机视觉。本报告提供了对挑战研究结果的全面概述，包括统计分析和定性分析，评估了超过700份提交作品的趋势。所有数据集、评价代码和排行榜均可通过以下链接获取：[这里](https://your-link-here.com)。', 'title_zh': '第三届海洋计算机视觉研讨会（MaCVi 2025）：挑战结果'}
{'arxiv_id': 'arXiv:2501.10332', 'title': 'Agent4Edu: Generating Learner Response Data by Generative Agents for Intelligent Education Systems', 'authors': 'Weibo Gao, Qi Liu, Linan Yue, Fangzhou Yao, Rui Lv, Zheng Zhang, Hao Wang, Zhenya Huang', 'link': 'https://arxiv.org/abs/2501.10332', 'abstract': "Personalized learning represents a promising educational strategy within intelligent educational systems, aiming to enhance learners' practice efficiency. However, the discrepancy between offline metrics and online performance significantly impedes their progress. To address this challenge, we introduce Agent4Edu, a novel personalized learning simulator leveraging recent advancements in human intelligence through large language models (LLMs). Agent4Edu features LLM-powered generative agents equipped with learner profile, memory, and action modules tailored to personalized learning algorithms. The learner profiles are initialized using real-world response data, capturing practice styles and cognitive factors. Inspired by human psychology theory, the memory module records practice facts and high-level summaries, integrating reflection mechanisms. The action module supports various behaviors, including exercise understanding, analysis, and response generation. Each agent can interact with personalized learning algorithms, such as computerized adaptive testing, enabling a multifaceted evaluation and enhancement of customized services. Through a comprehensive assessment, we explore the strengths and weaknesses of Agent4Edu, emphasizing the consistency and discrepancies in responses between agents and human learners. The code, data, and appendix are publicly available at this https URL.", 'abstract_zh': '个性化学习在智能教育资源系统中代表了一种有前景的教学策略，旨在提高学习者的学习效率。然而，离线指标与在线表现之间的差异严重阻碍了其进步。为解决这一挑战，我们介绍了Agent4Edu，这是一种利用大型语言模型（LLMs）近期在人类智能方面的进展的新型个性化学习模拟器。Agent4Edu 配备了由学习者概况、记忆和行为模块支持的LLM驱动生成代理，这些模块专门针对个性化学习算法进行了定制。学习者概况使用实际反应数据进行初始化，捕捉了学习者的实践风格和认知因素。该记忆模块记录了实践事实和高阶总结，并整合了反思机制。行为模块支持各种行为，包括理解练习、分析和生成响应。每个代理都可以与个性化学习算法（如计算机化自适应测试）进行交互，从而实现对定制服务的多维评估和增强。通过全面评估，我们探讨了Agent4Edu的优势和不足，强调了代理和人类学习者之间反应的一致性和差异性。相关代码、数据和附录可在以下网址公开访问：[此链接](此链接)。', 'title_zh': 'Agent4Edu: 生成学习者响应数据的生成型智能代理以支持智能教育系统'}
{'arxiv_id': 'arXiv:2501.10322', 'title': 'Hierarchical Autoregressive Transformers: Combining Byte-~and Word-Level Processing for Robust, Adaptable Language Models', 'authors': 'Pit Neitemeier, Björn Deiseroth, Constantin Eichenberg, Lukas Balles', 'link': 'https://arxiv.org/abs/2501.10322', 'abstract': 'Tokenization is a fundamental step in natural language processing, breaking text into units that computational models can process. While learned subword tokenizers have become the de-facto standard, they present challenges such as large vocabularies, limited adaptability to new domains or languages, and sensitivity to spelling errors and variations. To overcome these limitations, we investigate a hierarchical architecture for autoregressive language modelling that combines character-level and word-level processing. It employs a lightweight character-level encoder to convert character sequences into word embeddings, which are then processed by a word-level backbone model and decoded back into characters via a compact character-level decoder. This method retains the sequence compression benefits of word-level tokenization without relying on a rigid, predefined vocabulary. We demonstrate, at scales up to 7 billion parameters, that hierarchical transformers match the downstream task performance of subword-tokenizer-based models while exhibiting significantly greater robustness to input perturbations. Additionally, during continued pretraining on an out-of-domain language, our model trains almost twice as fast, achieves superior performance on the target language, and retains more of its previously learned knowledge. Hierarchical transformers pave the way for NLP systems that are more robust, flexible, and generalizable across languages and domains.', 'abstract_zh': '分词是自然语言处理中的一个基本步骤，它将文本分割为计算模型可以处理的单元。虽然基于学习的子词分词器已成为事实上的标准，但它们也面临着诸如词汇量庞大、对新领域或语言的适应性有限以及对拼写错误和变化的敏感性等问题。为克服这些限制，我们探究了一种结合字符级和词级处理的分层架构，用于自回归语言建模。该架构使用一个轻量级的字符级编码器将字符序列转换为词嵌入，这些词嵌入随后由词级主干模型处理并通过紧凑的字符级解码器反向转换回字符。这种方法保留了词级分词的序列压缩优势，同时不依赖于固定或刚性的词汇表。我们通过参数量高达70亿的模型验证，分层Transformer在下游任务性能上与基于子词分词器的模型相匹配，但在输入扰动具有显著更高的鲁棒性。此外，在跨领域语言的持续预训练中，我们的模型几乎快一倍地完成训练，在目标语言上表现出色，并保留了更多之前学习的知识。分层Transformer为构建跨语言和领域更鲁棒、更灵活和更泛化的NLP系统铺平了道路。', 'title_zh': '层次自回归变压器：结合字节级和词级处理以构建稳健且适应性强的语言模型'}
{'arxiv_id': 'arXiv:2501.10273', 'title': 'SEANN: A Domain-Informed Neural Network for Epidemiological Insights', 'authors': 'Jean-Baptiste Guimbaud, Marc Plantevit, Léa Maître, Rémy Cazabet', 'link': 'https://arxiv.org/abs/2501.10273', 'abstract': 'In epidemiology, traditional statistical methods such as logistic regression, linear regression, and other parametric models are commonly employed to investigate associations between predictors and health outcomes. However, non-parametric machine learning techniques, such as deep neural networks (DNNs), coupled with explainable AI (XAI) tools, offer new opportunities for this task. Despite their potential, these methods face challenges due to the limited availability of high-quality, high-quantity data in this field. To address these challenges, we introduce SEANN, a novel approach for informed DNNs that leverages a prevalent form of domain-specific knowledge: Pooled Effect Sizes (PES). PESs are commonly found in published Meta-Analysis studies, in different forms, and represent a quantitative form of a scientific consensus. By direct integration within the learning procedure using a custom loss, we experimentally demonstrate significant improvements in the generalizability of predictive performances and the scientific plausibility of extracted relationships compared to a domain-knowledge agnostic neural network in a scarce and noisy data setting.', 'abstract_zh': '在流行病学中，传统的统计方法，如逻辑回归、线性回归以及其他参数模型，常被用来探究预测因子与健康结果之间的关联。然而，结合可解释的人工智能（XAI）工具的非参数机器学习技术，如深度神经网络（DNNs），为这一任务提供了新的机遇。尽管这些方法具有潜力，但由于该领域高质量和大量数据的限制，它们仍面临挑战。为应对这些挑战，我们提出了一种名为SEANN的新方法，该方法利用了一种常见的领域特定知识：汇总效应量（PES）。PESs常见于已发表的元分析研究中，以不同的形式存在，代表了科学共识的量化形式。通过在学习过程中直接集成一种自定义损失函数，我们实验性地展示了在数据稀缺且存在噪声的情况下，这种方法在预测性能的泛化能力和提取关系的科学合理性方面相比传统无知域知识的神经网络具有显著改进。', 'title_zh': 'SEANN：一种基于领域知识的神经网络，用于流行病学洞察'}
{'arxiv_id': 'arXiv:2501.10256', 'title': 'Unsupervised Rhythm and Voice Conversion of Dysarthric to Healthy Speech for ASR', 'authors': 'Karl El Hajal, Enno Hermann, Ajinkya Kulkarni, Mathew Magimai.-Doss', 'link': 'https://arxiv.org/abs/2501.10256', 'abstract': 'Automatic speech recognition (ASR) systems are well known to perform poorly on dysarthric speech. Previous works have addressed this by speaking rate modification to reduce the mismatch with typical speech. Unfortunately, these approaches rely on transcribed speech data to estimate speaking rates and phoneme durations, which might not be available for unseen speakers. Therefore, we combine unsupervised rhythm and voice conversion methods based on self-supervised speech representations to map dysarthric to typical speech. We evaluate the outputs with a large ASR model pre-trained on healthy speech without further fine-tuning and find that the proposed rhythm conversion especially improves performance for speakers of the Torgo corpus with more severe cases of dysarthria. Code and audio samples are available at this https URL .', 'abstract_zh': '自动语音识别（ASR）系统在处理构音障碍语音时表现不佳。以往的工作通过改变语速来减少与典型语音的不匹配。然而，这些方法依赖于转录的语音数据来估计语速和音素持续时间，而对于未见过的说话者，这类数据可能不可用。因此，我们结合了基于自监督语音表示的无监督节奏转换和语音转换方法，将构音障碍语音映射到典型语音。我们使用在健康语音上预先训练的大规模ASR模型对输出进行评估，发现提出的节奏转换特别提高了Torgo语料库中病情更为严重的说话者的识别性能。代码和音频样本可在以下链接获取：this https URL。', 'title_zh': '无监督的构音障碍语音的节奏和音色转换至健康语音以用于自动语音识别'}
{'arxiv_id': 'arXiv:2501.10243', 'title': 'Random-Key Algorithms for Optimizing Integrated Operating Room Scheduling', 'authors': 'Bruno Salezze Vieira, Eduardo Machado Silva, Antonio Augusto Chaves', 'link': 'https://arxiv.org/abs/2501.10243', 'abstract': 'Efficient surgery room scheduling is essential for hospital efficiency, patient satisfaction, and resource utilization. This study addresses this challenge by introducing a novel concept of Random-Key Optimizer (RKO), rigorously tested on literature and new, real-world inspired instances. Our combinatorial optimization problem incorporates multi-room scheduling, equipment scheduling, and complex availability constraints for rooms, patients, and surgeons, facilitating rescheduling and enhancing operational flexibility. The RKO approach represents solutions as points in a continuous space, which are then mapped in the problem solution space via a deterministic function known as a decoder. The core idea is to operate metaheuristics and heuristics in the random-key space, unaware of the original solution space. We design the Biased Random-Key Genetic Algorithm with $Q$-Learning, Simulated Annealing, and Iterated Local Search for use within an RKO framework, employing a single decoder function. The proposed metaheuristics are complemented by lower-bound formulations, providing optimal gaps for evaluating the effectiveness of the heuristic results. Our results demonstrate significant lower and upper bounds improvements for the literature instances, notably proving one optimal result. Furthermore, the best-proposed metaheuristic efficiently generates schedules for the newly introduced instances, even in highly constrained scenarios. This research offers valuable insights and practical solutions for improving surgery scheduling processes, offering tangible benefits to hospitals by optimising resource allocation, reducing patient wait times, and enhancing overall operational efficiency.', 'abstract_zh': '高效的手术室排程对于医院的运作效率、患者满意度以及资源利用至关重要。本研究通过引入一种新颖的概念——随机键优化器（Random-Key Optimizer, RKO），并通过在文献和新出现的实际问题实例中对其进行严格测试来应对这一挑战。我们提出的问题综合优化结合了多室排程、设备排程以及复杂的房间、患者和外科医生可用性约束，有助于重新排程并增强操作的灵活性。RKO方法将解决方案表示为连续空间中的点，然后通过称为解码器的确定性函数映射到问题解空间中。核心思想是在随机键空间中操作元启发式和启发式方法，而不了解原来的解空间。我们设计了Biased Random-Key遗传算法（结合了Q-Learning、模拟退火和迭代局部搜索），并在RKO框架中使用单一解码器函数。提出的元启发式方法通过下界形式进行了补充，为评估启发式结果的有效性提供了最优间隙。实验结果表明，对于文献中的实例，我们显著提高了上下界，甚至证明了一个最优结果。此外，提出的最优元启发式方法能够有效地为新引入的实例生成排程，即使在高度受限的场景下也是如此。本研究提供了改进手术排程流程的重要见解和实用解决方案，通过优化资源配置、减少患者等待时间以及整体提升运营效率，为医院带来了具体的益处。', 'title_zh': '优化手术室综合调度的随机密钥算法'}
{'arxiv_id': 'arXiv:2501.10240', 'title': 'Challenges and recommendations for Electronic Health Records data extraction and preparation for dynamic prediction modelling in hospitalized patients -- a practical guide', 'authors': 'Elena Albu, Shan Gao, Pieter Stijnen, Frank E. Rademakers, Bas C T van Bussel, Taya Collyer, Tina Hernandez-Boussard, Laure Wynants, Ben Van Calster', 'link': 'https://arxiv.org/abs/2501.10240', 'abstract': 'Dynamic predictive modeling using electronic health record (EHR) data has gained significant attention in recent years. The reliability and trustworthiness of such models depend heavily on the quality of the underlying data, which is largely determined by the stages preceding the model development: data extraction from EHR systems and data preparation. We list over forty challenges encountered during these stages and provide actionable recommendations for addressing them. These challenges are organized into four categories: cohort definition, outcome definition, feature engineering, and data cleaning. This list is designed to serve as a practical guide for data extraction engineers and researchers, supporting better practices and improving the quality and real-world applicability of dynamic prediction models in clinical settings.', 'abstract_zh': '近年来，基于电子健康记录（EHR）数据的动态预测建模受到了广泛关注。此类模型的可靠性和可信度很大程度上取决于底层数据的质量，而这又主要取决于模型开发之前的几个阶段：数据从EHR系统中提取和数据准备。我们列出了在这些阶段遇到的四十多个挑战，并提供了应对这些建议。我们将挑战分为四个类别：队列定义、结局定义、特征工程和数据清洗。这份清单旨在为数据提取工程师和研究人员提供实用指南，支持更好的实践，提高临床环境中动态预测模型的质量和实际适用性。', 'title_zh': '住院患者电子健康记录数据提取和准备以进行动态预测建模的挑战与建议——实用指南'}
{'arxiv_id': 'arXiv:2501.10187', 'title': 'Good things come in small packages: Should we adopt Lite-GPUs in AI infrastructure?', 'authors': 'Burcu Canakci, Junyi Liu, Xingbo Wu, Nathanaël Cheriere, Paolo Costa, Sergey Legtchenko, Dushyanth Narayanan, Ant Rowstron', 'link': 'https://arxiv.org/abs/2501.10187', 'abstract': 'To match the blooming demand of generative AI workloads, GPU designers have so far been trying to pack more and more compute and memory into single complex and expensive packages. However, there is growing uncertainty about the scalability of individual GPUs and thus AI clusters, as state-of-the-art GPUs are already displaying packaging, yield, and cooling limitations. We propose to rethink the design and scaling of AI clusters through efficiently-connected large clusters of Lite-GPUs, GPUs with single, small dies and a fraction of the capabilities of larger GPUs. We think recent advances in co-packaged optics can be key in overcoming the communication challenges of distributing AI workloads onto more Lite-GPUs. In this paper, we present the key benefits of Lite-GPUs on manufacturing cost, blast radius, yield, and power efficiency; and discuss systems opportunities and challenges around resource, workload, memory, and network management.', 'abstract_zh': '为了应对生成AI工作负载快速增长的需求，GPU设计师一直在尝试将更多的计算和内存集成到单个复杂且昂贵的封装中。然而，随着最先进的GPU已经开始显示出封装、良率和冷却方面的限制，人们对单个GPU及其构成的AI集群的可扩展性产生了越来越多的不确定性。我们提议通过高效连接的Lite-GPU集群重新思考AI集群的设计和扩展。Lite-GPU是一种单颗小芯片且具备更大GPU部分能力的GPU。我们相信最近在共封装光学方面的进展可能是克服向更多Lite-GPU分配AI工作负载的通信挑战的关键。在本文中，我们将讨论Lite-GPU在制造成本、冲击范围、良率和能源效率方面的关键优势；并探讨资源、工作负载、内存和网络管理方面的系统机遇与挑战。', 'title_zh': '小包装中的大惊喜：我们应该在AI基础设施中采用Lite-GPU吗？'}
{'arxiv_id': 'arXiv:2501.10179', 'title': 'A Simple but Effective Closed-form Solution for Extreme Multi-label Learning', 'authors': 'Kazuma Onishi, Katsuhiko Hayashi', 'link': 'https://arxiv.org/abs/2501.10179', 'abstract': 'Extreme multi-label learning (XML) is a task of assigning multiple labels from an extremely large set of labels to each data instance. Many current high-performance XML models are composed of a lot of hyperparameters, which complicates the tuning process. Additionally, the models themselves are adapted specifically to XML, which complicates their reimplementation. To remedy this problem, we propose a simple method based on ridge regression for XML. The proposed method not only has a closed-form solution but also is composed of a single hyperparameter. Since there are no precedents on applying ridge regression to XML, this paper verified the performance of the method by using various XML benchmark datasets. Furthermore, we enhanced the prediction of low-frequency labels in XML, which hold informative content. This prediction is essential yet challenging because of the limited amount of data. Here, we employed a simple frequency-based weighting. This approach greatly simplifies the process compared with existing techniques. Experimental results revealed that it can achieve levels of performance comparable to, or even exceeding, those of models with numerous hyperparameters. Additionally, we found that the frequency-based weighting significantly improved the predictive performance for low-frequency labels, while requiring almost no changes in implementation. The source code for the proposed method is available on github at this https URL.', 'abstract_zh': '极端多标签学习（XML）是一项任务，即从一个极其庞大的标签集为每个数据实例分配多个标签。当前许多高性能的XML模型包含大量的超参数，这使得调优过程变得更加复杂。此外，这些模型专门针对XML进行了调整，使其重新实现也变得复杂。为了解决这一问题，我们提出了一种基于岭回归的简单方法。所提出的方法不仅具有封闭形式的解，而且只包含一个超参数。由于目前还没有将岭回归应用于XML的方法，本文通过使用多种XML基准数据集验证了该方法的性能。此外，我们还增强了XML中低频标签的预测，这些标签富含有意义的内容。由于数据量有限，这一预测虽然至关重要，但也是一个挑战。在这里，我们采用了一种简单的基于频率的加权方法。这种方法相较于现有技术大大简化了过程。实验结果表明，该方法可以达到甚至超过包含大量超参数的模型的性能水平。此外，我们发现基于频率的加权方法显著提高了低频标签的预测性能，而几乎不需要在实现上进行任何改动。所提出方法的源代码可在GitHub上的此链接获得：[此 https URL]。', 'title_zh': '一种简单而有效的极端多标签学习的闭形式解决方案'}
{'arxiv_id': 'arXiv:2501.10153', 'title': 'Region-wise stacking ensembles for estimating brain-age using MRI', 'authors': 'Georgios Antonopoulos, Shammi More, Simon B. Eickhoff, Federico Raimondo, Kaustubh R. Patil', 'link': 'https://arxiv.org/abs/2501.10153', 'abstract': "Predictive modeling using structural magnetic resonance imaging (MRI) data is a prominent approach to study brain-aging. Machine learning algorithms and feature extraction methods have been employed to improve predictions and explore healthy and accelerated aging e.g. neurodegenerative and psychiatric disorders. The high-dimensional MRI data pose challenges to building generalizable and interpretable models as well as for data privacy. Common practices are resampling or averaging voxels within predefined parcels, which reduces anatomical specificity and biological interpretability as voxels within a region may differently relate to aging. Effectively, naive fusion by averaging can result in information loss and reduced accuracy. We present a conceptually novel two-level stacking ensemble (SE) approach. The first level comprises regional models for predicting individuals' age based on voxel-wise information, fused by a second-level model yielding final predictions. Eight data fusion scenarios were explored using as input Gray matter volume (GMV) estimates from four datasets covering the adult lifespan. Performance, measured using mean absolute error (MAE), R2, correlation and prediction bias, showed that SE outperformed the region-wise averages. The best performance was obtained when first-level regional predictions were obtained as out-of-sample predictions on the application site with second-level models trained on independent and site-specific data (MAE=4.75 vs baseline regional mean GMV MAE=5.68). Performance improved as more datasets were used for training. First-level predictions showed improved and more robust aging signal providing new biological insights and enhanced data privacy. Overall, the SE improves accuracy compared to the baseline while preserving or enhancing data privacy.", 'abstract_zh': '使用结构磁共振成像（MRI）数据进行预测建模是研究大脑衰老的一种突出方法。机器学习算法和特征提取方法已被应用于提高预测准确性并探索健康和加速的衰老，例如神经退行性疾病和精神疾病。高维MRI数据对建立可泛化且可解释的模型以及数据隐私提出了挑战。常用的做法是重新采样或在预定义的区域内平均体素，这会降低解剖特异性并降低生物可解释性，因为区域内的体素可能与衰老的关系不同。实际上，简单的平均融合可能会导致信息丢失并降低准确性。我们提出了一种概念上新颖的两级堆叠集成（Stacking Ensemble，SE）方法。第一级由基于体素级信息的区域模型组成，通过第二级模型融合，产生最终预测。使用来自四个覆盖成人 lifespan 的数据集的灰质体积（GMV）估计值，探讨了八种数据融合场景。采用平均绝对误差（MAE）、R²、相关性和预测偏差来衡量性能，结果表明SE方法优于区域平均值。当在应用现场获取第一级区域预测并使用独立且特定于站点的数据训练第二级模型时，性能最佳（MAE=4.75 vs 基线区域平均GMV MAE=5.68）。随着更多数据集用于训练，性能得到了提高。第一级预测显示了改善且更稳健的衰老信号，提供了新的生物医学洞察，并增强了数据隐私。总体而言，SE方法在保留或增强数据隐私的同时提高了准确性。', 'title_zh': '使用MRI估计脑年龄的区域级堆叠集成方法'}
{'arxiv_id': 'arXiv:2501.10150', 'title': 'Dual Debiasing: Remove Stereotypes and Keep Factual Gender for Fair Language Modeling and Translation', 'authors': 'Tomasz Limisiewicz, David Mareček, Tomáš Musil', 'link': 'https://arxiv.org/abs/2501.10150', 'abstract': "Mitigation of biases, such as language models' reliance on gender stereotypes, is a crucial endeavor required for the creation of reliable and useful language technology. The crucial aspect of debiasing is to ensure that the models preserve their versatile capabilities, including their ability to solve language tasks and equitably represent various genders. To address this issue, we introduce a streamlined Dual Dabiasing Algorithm through Model Adaptation (2DAMA). Novel Dual Debiasing enables robust reduction of stereotypical bias while preserving desired factual gender information encoded by language models. We show that 2DAMA effectively reduces gender bias in English and is one of the first approaches facilitating the mitigation of stereotypical tendencies in translation. The proposed method's key advantage is the preservation of factual gender cues, which are useful in a wide range of natural language processing tasks.", 'abstract_zh': '减轻偏差，例如语言模型对性别刻板印象的依赖，是创建可靠和有用的语言技术不可或缺的重要领域。消除偏差的核心在于确保模型保留其多种多样的能力，包括解决语言任务和公平地表现各种性别。为了应对这一问题，我们提出了一种简化性的双重偏差消除算法通过模型适应（2DAMA）。新颖的双重消除偏差能够稳健地减少刻板印象偏差，同时保留语言模型编码的事实性别信息。研究结果显示，2DAMA 有效地减少了英语中的性别偏差，并且是首屈一指的方法之一，能够在翻译中减少刻板印象倾向。所提出方法的关键优势在于保留了事实上的性别线索，这些线索在广泛的语言处理任务中非常有用。', 'title_zh': '双重去偏见：消除刻板印象并保留事实上的性别，以实现公平的语言建模与翻译'}
{'arxiv_id': 'arXiv:2501.10141', 'title': 'Enhancing UAV Path Planning Efficiency Through Accelerated Learning', 'authors': 'Joseanne Viana, Boris Galkin, Lester Ho, Holger Claussen', 'link': 'https://arxiv.org/abs/2501.10141', 'abstract': 'Unmanned Aerial Vehicles (UAVs) are increasingly essential in various fields such as surveillance, reconnaissance, and telecommunications. This study aims to develop a learning algorithm for the path planning of UAV wireless communication relays, which can reduce storage requirements and accelerate Deep Reinforcement Learning (DRL) convergence. Assuming the system possesses terrain maps of the area and can estimate user locations using localization algorithms or direct GPS reporting, it can input these parameters into the learning algorithms to achieve optimized path planning performance. However, higher resolution terrain maps are necessary to extract topological information such as terrain height, object distances, and signal blockages. This requirement increases memory and storage demands on UAVs while also lengthening convergence times in DRL algorithms. Similarly, defining the telecommunication coverage map in UAV wireless communication relays using these terrain maps and user position estimations demands higher memory and storage utilization for the learning path planning algorithms. Our approach reduces path planning training time by applying a dimensionality reduction technique based on Principal Component Analysis (PCA), sample combination, Prioritized Experience Replay (PER), and the combination of Mean Squared Error (MSE) and Mean Absolute Error (MAE) loss calculations in the coverage map estimates, thereby enhancing a Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm. The proposed solution reduces the convergence episodes needed for basic training by approximately four times compared to the traditional TD3.', 'abstract_zh': '无人航空器(UAVs)在监控、侦察和电信等多个领域中已成为不可或缺的工具。本文旨在开发一种用于UAV无线通信中继路径规划的学习算法，以减少存储需求并加速深度强化学习（DRL）的收敛速度。假定系统具有该地区的地形图，并能通过局部化算法或直接的GPS报告估计用户位置，这些参数可以被输入到学习算法中，以实现最优路径规划性能。然而，为了提取地形高度、物体距离和信号遮挡等拓扑信息，需要更高分辨率的地形图。这将增加无人机的存储需求，并延长DRL算法的收敛时间。同样地，使用地形图和用户位置估计来定义UAV无线通信中继的电信覆盖范围图也需要更高的内存和存储使用率，以供学习路径规划算法使用。通过应用基于主成分分析（PCA）的降维技术、样本组合、优先经验回放（PER）以及均方误差（MSE）和平均绝对误差（MAE）损失计算的结合方法，我们减少了覆盖范围估计中的路径规划训练时间，并增强了双延迟深度确定性策略梯度（TD3）算法。相比传统的TD3算法，所提出的方法将基本训练所需的收敛周期减少了大约四倍。', 'title_zh': '通过加速学习提高无人机路径规划效率'}
{'arxiv_id': 'arXiv:2501.10139', 'title': 'Conformal Prediction Sets with Improved Conditional Coverage using Trust Scores', 'authors': 'Jivat Neet Kaur, Michael I. Jordan, Ahmed Alaa', 'link': 'https://arxiv.org/abs/2501.10139', 'abstract': "Standard conformal prediction offers a marginal guarantee on coverage, but for prediction sets to be truly useful, they should ideally ensure coverage conditional on each test point. Unfortunately, it is impossible to achieve exact, distribution-free conditional coverage in finite samples. In this work, we propose an alternative conformal prediction algorithm that targets coverage where it matters most--in instances where a classifier is overconfident in its incorrect predictions. We start by dissecting miscoverage events in marginally-valid conformal prediction, and show that miscoverage rates vary based on the classifier's confidence and its deviation from the Bayes optimal classifier. Motivated by this insight, we develop a variant of conformal prediction that targets coverage conditional on a reduced set of two variables: the classifier's confidence in a prediction and a nonparametric trust score that measures its deviation from the Bayes classifier. Empirical evaluation on multiple image datasets shows that our method generally improves conditional coverage properties compared to standard conformal prediction, including class-conditional coverage, coverage over arbitrary subgroups, and coverage over demographic groups.", 'abstract_zh': '标准校准预测提供了边际的覆盖保证，但为了使预测集真正有用，它们应该在每个测试点上确保条件覆盖。不幸的是，在有限样本中实现精确的、无分布假设的条件覆盖是不可能的。在本文中，我们提出了一种替代的校准预测算法，该算法针对最需要覆盖的地方——分类器在错误预测方面过度自信的地方进行目标覆盖。首先，我们分解了边缘有效校准预测中的覆盖失误事件，表明覆盖误差率取决于分类器的置信度与其贝叶斯最优分类器的偏差。受到这一洞见的启发，我们开发了一种校准预测的变体，该变体针对一个减少的变量集（分类器对预测的信心程度和一个非参数信任分数，该分数测量它的贝叶斯分类器偏差）进行条件覆盖。在多个图像数据集上的实证评估显示，与标准校准预测相比，我们的方法通常能够改善条件覆盖性质，包括类别条件覆盖、任意子组的覆盖以及人口统计群体的覆盖。', 'title_zh': '使用信任评分提高条件覆盖的 conformal 预测集'}
{'arxiv_id': 'arXiv:2501.10129', 'title': 'Spatio-temporal Graph Learning on Adaptive Mined Key Frames for High-performance Multi-Object Tracking', 'authors': 'Futian Wang, Fengxiang Liu, Xiao Wang', 'link': 'https://arxiv.org/abs/2501.10129', 'abstract': 'In the realm of multi-object tracking, the challenge of accurately capturing the spatial and temporal relationships between objects in video sequences remains a significant hurdle. This is further complicated by frequent occurrences of mutual occlusions among objects, which can lead to tracking errors and reduced performance in existing methods. Motivated by these challenges, we propose a novel adaptive key frame mining strategy that addresses the limitations of current tracking approaches. Specifically, we introduce a Key Frame Extraction (KFE) module that leverages reinforcement learning to adaptively segment videos, thereby guiding the tracker to exploit the intrinsic logic of the video content. This approach allows us to capture structured spatial relationships between different objects as well as the temporal relationships of objects across frames. To tackle the issue of object occlusions, we have developed an Intra-Frame Feature Fusion (IFF) module. Unlike traditional graph-based methods that primarily focus on inter-frame feature fusion, our IFF module uses a Graph Convolutional Network (GCN) to facilitate information exchange between the target and surrounding objects within a frame. This innovation significantly enhances target distinguishability and mitigates tracking loss and appearance similarity due to occlusions. By combining the strengths of both long and short trajectories and considering the spatial relationships between objects, our proposed tracker achieves impressive results on the MOT17 dataset, i.e., 68.6 HOTA, 81.0 IDF1, 66.6 AssA, and 893 IDS, proving its effectiveness and accuracy.', 'abstract_zh': '在多目标跟踪领域，准确捕捉视频序列中物体间的空间和时间关系仍然是一个重大的挑战。由于物体间频繁的相互遮挡现象，这进一步增加了这一挑战的复杂性，导致现有方法中的跟踪错误和性能下降。鉴于这些挑战，我们提出了一种新的自适应关键帧挖掘策略，以解决现有跟踪方法的局限性。具体来说，我们引入了关键帧提取（KFE）模块，该模块利用强化学习自适应地分割视频，从而引导跟踪器利用视频内容的内在逻辑。这种方法允许我们捕获不同物体之间的结构化空间关系以及帧间物体的时间关系。为了解决物体遮挡问题，我们开发了帧内特征融合（IFF）模块。不同于传统的基于图的方法主要关注帧间特征融合，我们的IFF模块使用图卷积网络（GCN）在帧内促进目标及其周围物体之间的信息交换。这一创新显著提高了目标的可分辨性，并减轻了遮挡导致的目标辨识度降低和外观相似性问题。通过结合长轨迹和短轨迹的优势，并考虑物体之间的空间关系，我们提出的方法在MOT17数据集上取得了卓越的结果，包括68.6的HOTA、81.0的IDF1、66.6的AssA和893的IDS，进一步证明了其有效性和准确性。', 'title_zh': '自适应挖掘关键帧的时空图学习方法及其在高性能多目标跟踪中的应用'}
{'arxiv_id': 'arXiv:2501.10107', 'title': 'BBPOS: BERT-based Part-of-Speech Tagging for Uzbek', 'authors': 'Latofat Bobojonova, Arofat Akhundjanova, Phil Ostheimer, Sophie Fellenz', 'link': 'https://arxiv.org/abs/2501.10107', 'abstract': 'This paper advances NLP research for the low-resource Uzbek language by evaluating two previously untested monolingual Uzbek BERT models on the part-of-speech (POS) tagging task and introducing the first publicly available UPOS-tagged benchmark dataset for Uzbek. Our fine-tuned models achieve 91% average accuracy, outperforming the baseline multi-lingual BERT as well as the rule-based tagger. Notably, these models capture intermediate POS changes through affixes and demonstrate context sensitivity, unlike existing rule-based taggers.', 'abstract_zh': '本文通过对两种此前未测试过的单语乌兹别克语 BERT 模型在词性标注（POS 标注）任务上的评估，并引入了第一个公开发布的 UPOS 标注基准数据集，推动了低资源乌兹别克语的自然语言处理（NLP）研究。我们微调后的模型实现了 91% 的平均准确率，优于基线的多语言 BERT 和基于规则的标签器。值得注意的是，这些模型能够捕捉通过词缀表现出的中间词性变化，并且表现出上下文敏感性，而现有的基于规则的标签器则不具备这些特性。', 'title_zh': 'BBPOS：基于BERT的乌兹别克语词性标注'}
{'arxiv_id': 'arXiv:2501.10105', 'title': 'Universal Actions for Enhanced Embodied Foundation Models', 'authors': 'Jinliang Zheng, Jianxiong Li, Dongxiu Liu, Yinan Zheng, Zhihao Wang, Zhonghong Ou, Yu Liu, Jingjing Liu, Ya-Qin Zhang, Xianyuan Zhan', 'link': 'https://arxiv.org/abs/2501.10105', 'abstract': 'Training on diverse, internet-scale data is a key factor in the success of recent large foundation models. Yet, using the same recipe for building embodied agents has faced noticeable difficulties. Despite the availability of many crowd-sourced embodied datasets, their action spaces often exhibit significant heterogeneity due to distinct physical embodiment and control interfaces for different robots, causing substantial challenges in developing embodied foundation models using cross-domain data. In this paper, we introduce UniAct, a new embodied foundation modeling framework operating in a tokenized Universal Action Space. Our learned universal actions capture the generic atomic behaviors across diverse robots by exploiting their shared structural features, and enable enhanced cross-domain data utilization and cross-embodiment generalizations by eliminating the notorious heterogeneity. The universal actions can be efficiently translated back to heterogeneous actionable commands by simply adding embodiment-specific details, from which fast adaptation to new robots becomes simple and straightforward. Our 0.5B instantiation of UniAct outperforms 14X larger SOTA embodied foundation models in extensive evaluations on various real-world and simulation robots, showcasing exceptional cross-embodiment control and adaptation capability, highlighting the crucial benefit of adopting universal actions. Project page: this https URL', 'abstract_zh': '在大规模互联网数据上进行训练是近期大型基础模型取得成功的关键因素。然而，使用相同的方法构建具身智能体遇到了明显的困难。尽管有许多开源的具身数据集，但由于不同机器人具有独特的物理表现形式和控制接口，其动作空间往往表现出显著的异质性，这在利用跨域数据开发具身基础模型时带来了巨大挑战。本文介绍了一种新的具身基础建模框架——UniAct，它在标记化的统一动作空间中运行。我们的学习到的通用动作捕获了不同机器人之间的一般原子行为，并通过消除 notorious 的异质性，增强了跨域数据利用和跨载体泛化的能力。可以通过简单地添加与具体机器人相关的细节，将通用动作高效地转换回异质的可执行命令，从而使得对新机器人的快速适应变得简单直接。我们的 UniAct 实例在各种真实世界和仿真机器人上的广泛评估中表现出色，超过了比其大14倍的现有最佳具身基础模型，展示了卓越的跨载体控制和适应能力，突显了采用通用动作的重要性。项目页面：[这里](this https URL)', 'title_zh': '增强型体化基础模型的通用行动方案'}
{'arxiv_id': 'arXiv:2501.10100', 'title': 'Robotic World Model: A Neural Network Simulator for Robust Policy Optimization in Robotics', 'authors': 'Chenhao Li, Andreas Krause, Marco Hutter', 'link': 'https://arxiv.org/abs/2501.10100', 'abstract': 'Learning robust and generalizable world models is crucial for enabling efficient and scalable robotic control in real-world environments. In this work, we introduce a novel framework for learning world models that accurately capture complex, partially observable, and stochastic dynamics. The proposed method employs a dual-autoregressive mechanism and self-supervised training to achieve reliable long-horizon predictions without relying on domain-specific inductive biases, ensuring adaptability across diverse robotic tasks. We further propose a policy optimization framework that leverages world models for efficient training in imagined environments and seamless deployment in real-world systems. Through extensive experiments, our approach consistently outperforms state-of-the-art methods, demonstrating superior autoregressive prediction accuracy, robustness to noise, and generalization across manipulation and locomotion tasks. Notably, policies trained with our method are successfully deployed on ANYmal D hardware in a zero-shot transfer, achieving robust performance with minimal sim-to-real performance loss. This work advances model-based reinforcement learning by addressing the challenges of long-horizon prediction, error accumulation, and sim-to-real transfer. By providing a scalable and robust framework, the introduced methods pave the way for adaptive and efficient robotic systems in real-world applications.', 'abstract_zh': '建立稳健且通用的世界模型对于在现实环境中的高效可扩展机器人控制至关重要。本工作中，我们提出了一种新的框架，用于学习能够准确捕捉复杂、部分可观测及随机动力学的世界模型。所提出的方法采用双自回归机制并采用自我监督训练，以实现可靠的长时预测，同时无需依赖特定领域的归纳偏置，从而确保跨多样的机器人任务具有适应性。我们进一步提出了一种利用世界模型进行高效想象环境训练和无缝实现实物系统部署的策略优化框架。通过广泛的实验，我们的方法在各个方面均优于现有最先进的方法，展示了优越的自回归预测准确性、对噪声的鲁棒性和在操作和运动任务中的泛化能力。特别地，使用我们的方法训练的策略能够无缝地部署于ANYmal D硬件平台上，在零样本迁移的情况下实现了鲁棒性能，并且仿真到现实的性能损失极小。本工作通过解决长时预测、误差累积和仿真到现实过渡的挑战，推进了模型驱动的强化学习领域。通过提供一种可扩展且稳健的框架，所提出的方法为实际应用中的自适应高效机器人系统开辟了道路。', 'title_zh': '机器人世界模型：一种用于机器人稳健策略优化的神经网络模拟器'}
{'arxiv_id': 'arXiv:2501.10098', 'title': 'landmarker: a Toolkit for Anatomical Landmark Localization in 2D/3D Images', 'authors': 'Jef Jonkers, Luc Duchateau, Glenn Van Wallendael, Sofie Van Hoecke', 'link': 'https://arxiv.org/abs/2501.10098', 'abstract': 'Anatomical landmark localization in 2D/3D images is a critical task in medical imaging. Although many general-purpose tools exist for landmark localization in classical computer vision tasks, such as pose estimation, they lack the specialized features and modularity necessary for anatomical landmark localization applications in the medical domain. Therefore, we introduce landmarker, a Python package built on PyTorch. The package provides a comprehensive, flexible toolkit for developing and evaluating landmark localization algorithms, supporting a range of methodologies, including static and adaptive heatmap regression. landmarker enhances the accuracy of landmark identification, streamlines research and development processes, and supports various image formats and preprocessing pipelines. Its modular design allows users to customize and extend the toolkit for specific datasets and applications, accelerating innovation in medical imaging. landmarker addresses a critical need for precision and customization in landmark localization tasks not adequately met by existing general-purpose pose estimation tools.', 'abstract_zh': '在2D/3D图像中定位解剖学特征点是医学成像领域中的关键任务。尽管存在许多适用于经典计算机视觉任务（如姿态估计）的一般工具，但它们缺乏针对医学领域特征点定位应用所需的专门特性和模块化功能。因此，本文介绍了一种基于PyTorch的Python包，即landmarker。该包提供了一个全面且灵活的工具箱，适用于开发和评估特征点定位算法，支持多种方法，包括静态和自适应热图回归。landmarker提高了特征点识别的准确性，简化了研究和开发流程，并支持多种图像格式和预处理流水线。其模块化设计使用户能够根据特定的数据集和应用定制和扩展工具箱，从而加速医学成像领域中的创新。landmarker填补了现有通用姿态估计工具在精度和定制方面无法满足的关键需求。', 'title_zh': 'Landmarker：一种二维/三维图像解剖标志点定位工具包'}
{'arxiv_id': 'arXiv:2501.10091', 'title': 'How Do Programming Students Use Generative AI?', 'authors': 'Christian Rahe, Walid Maalej', 'link': 'https://arxiv.org/abs/2501.10091', 'abstract': "Programming students have a widespread access to powerful Generative AI tools like ChatGPT. While this can help understand the learning material and assist with exercises, educators are voicing more and more concerns about an over-reliance on generated outputs and lack of critical thinking skills. It is thus important to understand how students actually use generative AI and what impact this could have on their learning behavior. To this end, we conducted a study including an exploratory experiment with 37 programming students, giving them monitored access to ChatGPT while solving a code understanding and improving exercise. While only 23 of the students actually opted to use the chatbot, the majority of those eventually prompted it to simply generate a full solution. We observed two prevalent usage strategies: to seek knowledge about general concepts and to directly generate solutions. Instead of using the bot to comprehend the code and their own mistakes, students often got trapped in a vicious cycle of submitting wrong generated code and then asking the bot for a fix. Those who self-reported using generative AI regularly were more likely to prompt the bot to generate a solution. Our findings indicate that concerns about potential decrease in programmers' agency and productivity with Generative AI are justified. We discuss how researchers and educators can respond to the potential risk of students uncritically over-relying on generative AI. We also discuss potential modifications to our study design for large-scale replications.", 'abstract_zh': '程序设计学生广泛接触到了强大的生成式AI工具，如ChatGPT。虽然这些工具可以帮助学生更好地理解和完成练习，但教育工作者对过度依赖生成内容和批判性思维能力不足的问题表达了越来越多的担忧。因此，了解学生实际上如何使用生成式AI及这种使用方式对他们的学习行为可能产生的影响变得非常重要。为此，我们进行了一项研究，其中包括一项探索性实验，让37名程序设计学生在解决代码理解和改进练习时有限地接触ChatGPT。虽然只有23名学生实际使用了聊天机器人，但大多数学生最终还是让聊天机器人直接生成完整解决方案。我们观察到了两种常见的使用策略：寻求有关通用概念的知识和直接生成解决方案。学生往往陷入了一个错误代码提交循环，提交错误生成的代码后，再请求机器人进行修正。那些自述经常使用生成式AI的学生更有可能请求机器人生成解决方案。我们的研究结果表明，关于生成式AI可能导致编程人员自主性和生产率下降的担忧是合理的。我们讨论了研究人员和教育工作者如何应对学生可能对生成式AI的非批判性过度依赖的风险。我们还讨论了如何修改研究设计以便进行大规模复制。', 'title_zh': '编程学生如何使用生成式AI？'}
{'arxiv_id': 'arXiv:2501.10075', 'title': 'Robust Change Captioning in Remote Sensing: SECOND-CC Dataset and MModalCC Framework', 'authors': 'Ali Can Karaca, M. Enes Ozelbas, Saadettin Berber, Orkhan Karimli, Turabi Yildirim, M. Fatih Amasyali', 'link': 'https://arxiv.org/abs/2501.10075', 'abstract': 'Remote sensing change captioning (RSICC) aims to describe changes between bitemporal images in natural language. Existing methods often fail under challenges like illumination differences, viewpoint changes, blur effects, leading to inaccuracies, especially in no-change regions. Moreover, the images acquired at different spatial resolutions and have registration errors tend to affect the captions. To address these issues, we introduce SECOND-CC, a novel RSICC dataset featuring high-resolution RGB image pairs, semantic segmentation maps, and diverse real-world scenarios. SECOND-CC which contains 6,041 pairs of bitemporal RS images and 30,205 sentences describing the differences between images. Additionally, we propose MModalCC, a multimodal framework that integrates semantic and visual data using advanced attention mechanisms, including Cross-Modal Cross Attention (CMCA) and Multimodal Gated Cross Attention (MGCA). Detailed ablation studies and attention visualizations further demonstrate its effectiveness and ability to address RSICC challenges. Comprehensive experiments show that MModalCC outperforms state-of-the-art RSICC methods, including RSICCformer, Chg2Cap, and PSNet with +4.6% improvement on BLEU4 score and +9.6% improvement on CIDEr score. We will make our dataset and codebase publicly available to facilitate future research at this https URL', 'abstract_zh': '遥感变化描述（Remote Sensing Change Captioning, RSICC）旨在利用自然语言描述不同时期图像之间的变化。现有方法在光照差异、视角变化、模糊效果等挑战下常常会出现准确性下降的问题，尤其是在无变化区域。此外，不同空间分辨率的图像及其注册误差也会影响描述的准确性。为解决这些问题，我们引入了SECOND-CC，这是一个全新的RSICC数据集，该数据集包含高分辨率的RGB图像对、语义分割图以及多样化的现实场景。SECOND-CC包含6041个不同时期的遥感图像对和30205个描述图像差异的句子。此外，我们提出了MModalCC，这是一种多模态框架，通过使用高级注意力机制（包括跨模态跨注意力CMCA和多模态门控跨注意力MGCA）来结合语义和视觉数据。详细的消融研究和注意力可视化进一步证明了其有效性和对RSICC挑战的解决能力。全面的实验表明，MModalCC在最先进的RSICC方法（包括RSICCformer, Chg2Cap和PSNet）中表现更佳，提高了BLEU4分数4.6%和CIDEr分数9.6%。我们将我们的数据集和代码库公开发布，以促进未来的研究，链接如下：[此链接此处替换为实际的公开链接]', 'title_zh': '遥感中的稳健变化描述：SECOND-CC 数据集和 MModalCC 框架'}
{'arxiv_id': 'arXiv:2501.10074', 'title': 'SpatialCoT: Advancing Spatial Reasoning through Coordinate Alignment and Chain-of-Thought for Embodied Task Planning', 'authors': 'Yuecheng Liu, Dafeng Chi, Shiguang Wu, Zhanguang Zhang, Yaochen Hu, Lingfeng Zhang, Yingxue Zhang, Shuang Wu, Tongtong Cao, Guowei Huang, Guangjian Tian, Xingyue Quan, Jianye Hao, Yuzheng Zhuang', 'link': 'https://arxiv.org/abs/2501.10074', 'abstract': 'Spatial reasoning is an essential problem in embodied AI research. Efforts to enhance spatial reasoning abilities through supplementary spatial data and fine-tuning have proven limited and ineffective when addressing complex embodied tasks, largely due to their dependence on language-based outputs. While some approaches have introduced a point-based action space to mitigate this issue, they fall short in managing more intricate tasks within complex environments. This deficiency arises from their failure to fully exploit the inherent thinking and reasoning capabilities that are fundamental strengths of Vision-Language Models (VLMs). To address these limitations, we propose a novel approach named SpatialCoT, specifically designed to bolster the spatial reasoning capabilities of VLMs. Our approach comprises two stages: spatial coordinate bi-directional alignment, which aligns vision-language inputs with spatial coordinates, and chain-of-thought spatial grounding, which harnesses the reasoning capabilities of language models for advanced spatial reasoning. We evaluate SpatialCoT on challenging navigation and manipulation tasks, both in simulation and real-world settings. Experimental results demonstrate that our method significantly outperforms previous state-of-the-art approaches in both tasks.', 'abstract_zh': '在具身人工智能研究中，空间推理是一个核心问题。通过补充空间数据和微调来提升空间推理能力的努力，在应对复杂的具身任务时效果有限，主要原因在于这些方法高度依赖基于语言的输出。尽管一些方法引入了基于点的动作空间以缓解这一问题，但在处理复杂环境中的复杂任务时仍然力有未逮。这一不足之处源于它们未能充分利用视觉语言模型（VLMs）固有的思维和推理能力。为了解决这些局限性，我们提出了一种名为SpatialCoT的新方法，专门用于增强VLM的空间推理能力。该方法包含两个阶段：空间坐标双向对齐，将视觉语言输入与空间坐标对齐；以及带有推理能力的因果链空间语义定位，利用语言模型的推理能力进行高级空间推理。我们通过仿真和真实环境中的导航和操作任务对SpatialCoT进行了评估。实验结果表明，我们的方法在两项任务中均显著优于之前的最先进的方法。', 'title_zh': 'SpatialCoT: 通过坐标对齐和链式思考促进体计算法中的空间推理'}
{'arxiv_id': 'arXiv:2501.10054', 'title': 'Accelerating Large Language Models through Partially Linear Feed-Forward Network', 'authors': 'Gansen Hu, Zhaoguo Wang, Jinglin Wei, Wei Huang, Haibo Chen', 'link': 'https://arxiv.org/abs/2501.10054', 'abstract': 'Large language models (LLMs) demonstrate remarkable capabilities but face deployment challenges due to their massive parameter counts. While existing compression techniques like pruning can reduce model size, it leads to significant accuracy degradation under high compression ratios. We present a novel perspective inspired by constant folding in compiler optimization. Our approach enables parameter reduction by treating activation functions in LLMs as linear functions.\nHowever, recent LLMs use complex non-linear activations like GELU that prevent direct application of this technique. We propose TARDIS, which enables optimization of LLMs with non-linear activations by partially approximating them with linear functions in frequently occurring input ranges. For outlier inputs, TARDIS employs an online predictor to dynamically fall back to original computations.\nOur experiments demonstrate that TARDIS achieves 80% parameter reduction in feed-forward networks, while significantly outperforming state-of-the-art pruning methods Wanda and RIA with up to 65% higher accuracy. In practical deployments for a 7B model, TARDIS achieves 1.6x end-to-end inference speedup when integrated with the vLLM serving system, and 1.4x speedup with the widely adopted HuggingFace implementation, while incurring only a 10.9% accuracy trade-off.', 'abstract_zh': 'larg的语言模型（LLMs）表现出卓越的能力，但由于其庞大的参数数量，部署时面临挑战。虽然现有的压缩技术如剪枝可以在一定程度上减少模型大小，但在高压缩比下，这会导致显著的准确率下降。我们提出了一种新的视角，借鉴编译器优化中的常量折叠策略。我们的方法通过将LLMs中的激活函数视为线性函数来实现参数减少。\n\n然而，最近的LLMs使用复杂的非线性激活函数（如GELU），这使得这种方法的直接应用变得不可能。为此，我们提出了TARDIS，它通过在经常出现的输入范围内部分地用线性函数近似非线性激活函数来优化使用非线性激活函数的LLMs。对于异常输入，TARDIS 使用一个在线预测器，根据需要动态切换回原始计算。\n\n实验结果表明，TARDIS 在前向网络中实现了80%的参数减少，同时显著优于最先进的剪枝方法Wanda和RIA，在准确率上提高了高达65%。在结合vLLM服务系统和广泛采用的HuggingFace实现的实际部署中，TARDIS 为7B模型实现了1.6倍的端到端推理速度提升，同时仅有10.9%的准确率损失。', 'title_zh': '通过部分线性前馈网络加速大型语言模型'}
{'arxiv_id': 'arXiv:2501.10048', 'title': 'Virtual Nodes Improve Long-term Traffic Prediction', 'authors': 'Xiaoyang Cao, Dingyi Zhuang, Jinhua Zhao, Shenhao Wang', 'link': 'https://arxiv.org/abs/2501.10048', 'abstract': 'Effective traffic prediction is a cornerstone of intelligent transportation systems, enabling precise forecasts of traffic flow, speed, and congestion. While traditional spatio-temporal graph neural networks (ST-GNNs) have achieved notable success in short-term traffic forecasting, their performance in long-term predictions remains limited. This challenge arises from over-squashing problem, where bottlenecks and limited receptive fields restrict information flow and hinder the modeling of global dependencies. To address these challenges, this study introduces a novel framework that incorporates virtual nodes, which are additional nodes added to the graph and connected to existing nodes, in order to aggregate information across the entire graph within a single GNN layer. Our proposed model incorporates virtual nodes by constructing a semi-adaptive adjacency matrix. This matrix integrates distance-based and adaptive adjacency matrices, allowing the model to leverage geographical information while also learning task-specific features from data. Experimental results demonstrate that the inclusion of virtual nodes significantly enhances long-term prediction accuracy while also improving layer-wise sensitivity to mitigate the over-squashing problem. Virtual nodes also offer enhanced explainability by focusing on key intersections and high-traffic areas, as shown by the visualization of their adjacency matrix weights on road network heat maps. Our advanced approach enhances the understanding and management of urban traffic systems, making it particularly well-suited for real-world applications.', 'abstract_zh': '有效的交通预测是智能交通系统的关键基石，能够实现对交通流量、车速和拥堵的精确预测。虽然传统的空时图神经网络（ST-GNNs）在短期交通预测方面取得了显著成功，但在长期内的预测性能仍然有限。这一挑战源于过度压缩问题，瓶颈和有限的感受野限制了信息流，阻碍了对全局依赖性的建模。为了解决这些挑战，本研究提出了一种新的框架，该框架通过在图中加入虚拟节点来汇整合图的信息。虚拟节点是添加到图中的额外节点，并与现有节点相连。我们提出的模型通过构建半自适应邻接矩阵来结合虚拟节点。该矩阵将基于距离的邻接矩阵与自适应的邻接矩阵相结合，使模型能够利用地理信息，同时从数据中学习特定任务的特征。实验结果表明，虚拟节点的引入显著提高了长期预测的准确度，同时提高了层间的敏感性，从而缓解了过度压缩问题。虚拟节点还通过关注关键交叉口和高流量区域，提供了增强的可解释性，如图网络热图中其邻接矩阵权重的可视化所示。我们提出的方法增强了对城市交通系统的理解和管理，使其特别适用于实际应用。', 'title_zh': '虚拟节点提高长期交通预测性能'}
{'arxiv_id': 'arXiv:2501.10024', 'title': 'Automatic Speech Recognition for Sanskrit with Transfer Learning', 'authors': 'Bidit Sadhukhan, Swami Punyeshwarananda', 'link': 'https://arxiv.org/abs/2501.10024', 'abstract': "Sanskrit, one of humanity's most ancient languages, has a vast collection of books and manuscripts on diverse topics that have been accumulated over millennia. However, its digital content (audio and text), which is vital for the training of AI systems, is profoundly limited. Furthermore, its intricate linguistics make it hard to develop robust NLP tools for wider accessibility. Given these constraints, we have developed an automatic speech recognition model for Sanskrit by employing transfer learning mechanism on OpenAI's Whisper model. After carefully optimising the hyper-parameters, we obtained promising results with our transfer-learned model achieving a word error rate of 15.42% on Vaksancayah dataset. An online demo of our model is made available for the use of public and to evaluate its performance firsthand thereby paving the way for improved accessibility and technological support for Sanskrit learning in the modern era.", 'abstract_zh': '梵语，人类最古老的语言之一，拥有跨越千年的多样主题的书籍和手稿的庞大文献集合。然而，其数字内容（音频和文本），对于训练人工智能系统至关重要，却极为有限。此外，其复杂的语言结构使得开发适用于更广泛人群的自然语言处理（NLP）工具变得困难。鉴于这些限制，我们通过在OpenAI的Whisper模型上应用迁移学习机制，开发了一种自动语音识别模型。经过仔细优化超参数后，我们的迁移学习模型在Vaksancayah数据集上取得了令人鼓舞的结果，单词错误率为15.42%。我们已提供在线演示版本，供公众使用，以便直接评估其性能，从而为现代时代梵语学习的改进访问性和技术支援铺平道路。', 'title_zh': '基于迁移学习的梵语自动语音识别'}
{'arxiv_id': 'arXiv:2501.10011', 'title': 'Mitigating Hallucinations on Object Attributes using Multiview Images and Negative Instructions', 'authors': 'Zhijie Tan, Yuzhi Li, Shengwei Meng, Xiang Yuan, Weiping Li, Tong Mo, Bingce Wang, Xu Chu', 'link': 'https://arxiv.org/abs/2501.10011', 'abstract': 'Current popular Large Vision-Language Models (LVLMs) are suffering from Hallucinations on Object Attributes (HoOA), leading to incorrect determination of fine-grained attributes in the input images. Leveraging significant advancements in 3D generation from a single image, this paper proposes a novel method to mitigate HoOA in LVLMs. This method utilizes multiview images sampled from generated 3D representations as visual prompts for LVLMs, thereby providing more visual information from other viewpoints. Furthermore, we observe the input order of multiple multiview images significantly affects the performance of LVLMs. Consequently, we have devised Multiview Image Augmented VLM (MIAVLM), incorporating a Multiview Attributes Perceiver (MAP) submodule capable of simultaneously eliminating the influence of input image order and aligning visual information from multiview images with Large Language Models (LLMs). Besides, we designed and employed negative instructions to mitigate LVLMs\' bias towards ``Yes" responses. Comprehensive experiments demonstrate the effectiveness of our method.', 'abstract_zh': '当前流行的大型视觉-语言模型（LVLMs）在对象属性上存在幻觉问题（HoOA），导致输入图像中的细粒度属性判断不正确。基于单张图像生成3D图像的重要进展，本文提出了一种新颖的方法来减轻LVLMs中的HoOA问题。该方法利用从生成的3D表示中采样的多视角图像作为LVLMs的视觉提示，从而提供来自其他视角的更多视觉信息。此外，我们观察到多视角图像的输入顺序对LVLMs的性能有显著影响。因此，我们设计了多视角图像增强视觉语言模型（MIAVLM），该模型包含一个多视角属性感知器（MAP）模块，可以同时消除输入图像顺序的影响，并将多视角图像中的视觉信息与大规模语言模型（LLMs）对齐。此外，我们设计并使用了负指令以减轻LVLMs对“是”回答的偏见。全面的实验表明了我们方法的有效性。', 'title_zh': '使用多视角图像和负向指令减轻对象属性幻觉现象'}
{'arxiv_id': 'arXiv:2501.10010', 'title': 'Adaptive Spatiotemporal Augmentation for Improving Dynamic Graph Learning', 'authors': 'Xu Chu, Hanlin Xue, Bingce Wang, Xiaoyang Liu, Weiping Li, Tong Mo, Tuoyu Feng, Zhijie Tan', 'link': 'https://arxiv.org/abs/2501.10010', 'abstract': 'Dynamic graph augmentation is used to improve the performance of dynamic GNNs. Most methods assume temporal locality, meaning that recent edges are more influential than earlier edges. However, for temporal changes in edges caused by random noise, overemphasizing recent edges while neglecting earlier ones may lead to the model capturing noise. To address this issue, we propose STAA (SpatioTemporal Activity-Aware Random Walk Diffusion). STAA identifies nodes likely to have noisy edges in spatiotemporal dimensions. Spatially, it analyzes critical topological positions through graph wavelet coefficients. Temporally, it analyzes edge evolution through graph wavelet coefficient change rates. Then, random walks are used to reduce the weights of noisy edges, deriving a diffusion matrix containing spatiotemporal information as an augmented adjacency matrix for dynamic GNN learning. Experiments on multiple datasets show that STAA outperforms other dynamic graph augmentation methods in node classification and link prediction tasks.', 'abstract_zh': '动态图增强技术被用于提高动态GNNs的性能。大多数方法假设时序局部性，即认为近期的边比早期的边更具影响力。然而，对于由随机噪声引起的边的时序变化，过分强调近期的边而忽视早期的边可能导致模型捕获噪声。为了解决这一问题，我们提出了一种时空活动感知随机游走扩散方法（SpatioTemporal Activity-Aware Random Walk Diffusion，简称STAA）。STAA能够在时空维度上识别可能具有噪声边的节点。在空间上，通过分析图波系数来识别关键的拓扑位置。在时间上，通过分析边演化情况及其波系数变化率来捕捉边的动态变化。然后，使用随机游走来降低噪声边的权重，从而推导出包含时空信息的扩散矩阵，作为动态GNN学习的增强邻接矩阵。在多个数据集上的实验表明，STAA在节点分类和链接预测任务中优于其他动态图增强方法。', 'title_zh': '适应性时空增强以提高动态图学习效果'}
{'arxiv_id': 'arXiv:2501.09999', 'title': 'Deep Learning for Early Alzheimer Disease Detection with MRI Scans', 'authors': 'Mohammad Rafsan, Tamer Oraby, Upal Roy, Sanjeev Kumar, Hansapani Rodrigo', 'link': 'https://arxiv.org/abs/2501.09999', 'abstract': "Alzheimer's Disease is a neurodegenerative condition characterized by dementia and impairment in neurological function. The study primarily focuses on the individuals above age 40, affecting their memory, behavior, and cognitive processes of the brain. Alzheimer's disease requires diagnosis by a detailed assessment of MRI scans and neuropsychological tests of the patients. This project compares existing deep learning models in the pursuit of enhancing the accuracy and efficiency of AD diagnosis, specifically focusing on the Convolutional Neural Network, Bayesian Convolutional Neural Network, and the U-net model with the Open Access Series of Imaging Studies brain MRI dataset. Besides, to ensure robustness and reliability in the model evaluations, we address the challenge of imbalance in data. We then perform rigorous evaluation to determine strengths and weaknesses for each model by considering sensitivity, specificity, and computational efficiency. This comparative analysis would shed light on the future role of AI in revolutionizing AD diagnostics but also paved ways for future innovation in medical imaging and the management of neurodegenerative diseases.", 'abstract_zh': '阿尔茨海默病是一种神经退行性疾病，主要特征为痴呆和神经功能障碍。本研究主要关注40岁以上个体，这些个体的memory、行为和认知过程受到影响。阿尔茨海默病通常需要通过详细的磁共振成像（MRI）扫描和神经心理学测试来进行诊断。本项目旨在比较现有的深度学习模型，以提高阿尔茨海默病诊断的准确性和效率，重点关注卷积神经网络（CNN）、贝叶斯卷积神经网络（BCNN）以及U-net模型在开放访问影像系列（OASIS）脑部MRI数据集上的应用。此外，为了确保模型评估的稳健性和可靠性，我们还解决数据不平衡的问题。通过严格的评估，考虑敏感性、特异性及计算效率，我们对每个模型的优势和不足进行了分析。这项比较分析不仅会揭示人工智能在未来阿尔茨海默病诊断中的革命性作用，还为未来医疗影像技术的创新以及神经退行性疾病的管理开辟了新的途径。', 'title_zh': '使用MRI扫描进行早期阿尔茨海默病检测的深度学习方法'}
{'arxiv_id': 'arXiv:2501.09997', 'title': 'Attention-guided Self-reflection for Zero-shot Hallucination Detection in Large Language Models', 'authors': 'Qiang Liu, Xinlong Chen, Yue Ding, Shizhen Xu, Shu Wu, Liang Wang', 'link': 'https://arxiv.org/abs/2501.09997', 'abstract': 'Hallucination has emerged as a significant barrier to the effective application of Large Language Models (LLMs). In this work, we introduce a novel Attention-Guided SElf-Reflection (AGSER) approach for zero-shot hallucination detection in LLMs. The AGSER method utilizes attention contributions to categorize the input query into attentive and non-attentive queries. Each query is then processed separately through the LLMs, allowing us to compute consistency scores between the generated responses and the original answer. The difference between the two consistency scores serves as a hallucination estimator. In addition to its efficacy in detecting hallucinations, AGSER notably reduces computational complexity, requiring only three passes through the LLM and utilizing two sets of tokens. We have conducted extensive experiments with four widely-used LLMs across three different hallucination benchmarks, demonstrating that our approach significantly outperforms existing methods in zero-shot hallucination detection.', 'abstract_zh': '幻觉已成为大语言模型（LLMs）有效应用的重要障碍。本文介绍了一种新颖的注意力导向自我反思（AGSER）方法，用于零样本幻觉检测。AGSER 方法利用注意力贡献将输入查询分为关注和不关注查询。随后，每个查询分别通过 LLM 处理，我们可以通过计算生成响应与原始答案之间的一致性分数来进行比较。两者的差异作为幻觉估计器。除了在幻觉检测方面的有效性，AGSER 还显著降低了计算复杂度，只需 LLM 的三次通道通过，并且仅使用两组标记。我们使用四种广泛使用的 LLM 在三个不同的幻觉基准上进行了大量实验，结果表明，本方法在零样本幻觉检测方面显著优于现有方法。', 'title_zh': '基于注意力导向的自我反思方法在大规模语言模型中的零样本幻觉检测'}
{'arxiv_id': 'arXiv:2501.09996', 'title': 'Fast energy-aware OLSR routing in VANETs by means of a parallel evolutionary algorithm', 'authors': 'Jamal Toutouh, Sergio Nesmachnow, Enrique Alba', 'link': 'https://arxiv.org/abs/2501.09996', 'abstract': 'This work tackles the problem of reducing the power consumption of the OLSR routing protocol in vehicular networks. Nowadays, energy-aware and green communication protocols are important research topics, specially when deploying wireless mobile networks. This article introduces a fast automatic methodology to search for energy-efficient OLSR configurations by using a parallel evolutionary algorithm. The experimental analysis demonstrates that significant improvements over the standard configuration can be attained in terms of power consumption, with no noteworthy loss in the QoS.', 'abstract_zh': '本文针对车载网络中OLSR路由协议的功率消耗问题进行了研究。随着无线移动网络的部署，能源意识和绿色通信协议已经成为重要的研究课题。本文介绍了一种快速自动的方法，通过使用并行进化算法搜索节能的OLSR配置。实验分析表明，相对于标准配置，可以在功率消耗方面取得显著改进，同时不会对服务质量（QoS）产生显著损失。', 'title_zh': '通过并行进化算法实现的快速能量感知VANET中OLSRA路由'}
{'arxiv_id': 'arXiv:2501.09994', 'title': 'Multi-Modal Attention Networks for Enhanced Segmentation and Depth Estimation of Subsurface Defects in Pulse Thermography', 'authors': 'Mohammed Salah, Naoufel Werghi, Davor Svetinovic, Yusra Abdulrahman', 'link': 'https://arxiv.org/abs/2501.09994', 'abstract': 'AI-driven pulse thermography (PT) has become a crucial tool in non-destructive testing (NDT), enabling automatic detection of hidden anomalies in various industrial components. Current state-of-the-art techniques feed segmentation and depth estimation networks compressed PT sequences using either Principal Component Analysis (PCA) or Thermographic Signal Reconstruction (TSR). However, treating these two modalities independently constrains the performance of PT inspection models as these representations possess complementary semantic features. To address this limitation, this work proposes PT-Fusion, a multi-modal attention-based fusion network that fuses both PCA and TSR modalities for defect segmentation and depth estimation of subsurface defects in PT setups. PT-Fusion introduces novel feature fusion modules, Encoder Attention Fusion Gate (EAFG) and Attention Enhanced Decoding Block (AEDB), to fuse PCA and TSR features for enhanced segmentation and depth estimation of subsurface defects. In addition, a novel data augmentation technique is proposed based on random data sampling from thermographic sequences to alleviate the scarcity of PT datasets. The proposed method is benchmarked against state-of-the-art PT inspection models, including U-Net, attention U-Net, and 3D-CNN on the Université Laval IRT-PVC dataset. The results demonstrate that PT-Fusion outperforms the aforementioned models in defect segmentation and depth estimation accuracies with a margin of 10%.', 'abstract_zh': '基于AI的脉冲热成像（PT）已成为无损检测（NDT）中的关键工具，能够自动检测工业组件中隐藏的异常。当前最先进的技术使用主成分分析（PCA）或热成像信号重建（TSR）压缩PT序列，输入分割和深度估计网络。然而，独立处理这两种表示方式限制了PT检测模型的性能，因为这两种表示方式具有互补的语义特征。为了解决这一局限性，本研究提出了一种多模态注意融合网络PT-Fusion，该网络将PCA和TSR模态融合，用于PT设置中次表面缺陷的缺陷分割和深度估计。PT-Fusion引入了新颖的特征融合模块——编码器注意力融合门（EAFG）和注意力增强解码块（AEDB），以增强次表面缺陷的分割和深度估计。此外，还提出了一种基于热成像序列中随机数据采样的新颖数据增强技术，以缓解PT数据集稀缺的问题。该方法在Université Laval IRT-PVC数据集上与包括Unet、注意力Unet和3D-CNN在内的最新PT检测模型进行了基准测试。结果表明，PT-Fusion在缺陷分割和深度估计准确性方面分别比上述模型高出10%。', 'title_zh': '用于增强脉冲热成像下层缺陷分割和深度估计的多模态注意力网络'}
{'arxiv_id': 'arXiv:2501.09982', 'title': 'RichSpace: Enriching Text-to-Video Prompt Space via Text Embedding Interpolation', 'authors': 'Yuefan Cao, Chengyue Gong, Xiaoyu Li, Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song', 'link': 'https://arxiv.org/abs/2501.09982', 'abstract': 'Text-to-video generation models have made impressive progress, but they still struggle with generating videos with complex features. This limitation often arises from the inability of the text encoder to produce accurate embeddings, which hinders the video generation model. In this work, we propose a novel approach to overcome this challenge by selecting the optimal text embedding through interpolation in the embedding space. We demonstrate that this method enables the video generation model to produce the desired videos. Additionally, we introduce a simple algorithm using perpendicular foot embeddings and cosine similarity to identify the optimal interpolation embedding. Our findings highlight the importance of accurate text embeddings and offer a pathway for improving text-to-video generation performance.', 'abstract_zh': '文本到视频生成模型在生成方面取得了显著进展，但在生成具有复杂特征的视频方面依然存在局限。这种局限往往源于文本编码器无法生成准确的嵌入表示，从而阻碍了视频生成模型的表现。本文提出了一种新的方法，通过在嵌入空间中进行插值来选择最佳的文本嵌入，以克服这一挑战。我们证明，这种方法使视频生成模型能够生成所需的视频。此外，我们引入了一个简单算法，利用正交投影嵌入和余弦相似性来识别最佳插值嵌入。我们的研究结果突出了准确文本嵌入的重要性，并为提高文本到视频生成性能提供了路径。', 'title_zh': 'RichSpace：通过文本嵌入插值丰富文本到视频提示空间'}
{'arxiv_id': 'arXiv:2501.09980', 'title': 'Aneumo: A Large-Scale Comprehensive Synthetic Dataset of Aneurysm Hemodynamics', 'authors': 'Xigui Li, Yuanye Zhou, Feiyang Xiao, Xin Guo, Yichi Zhang, Chen Jiang, Jianchao Ge, Xiansheng Wang, Qimeng Wang, Taiwei Zhang, Chensen Lin, Yuan Cheng, Yuan Qi', 'link': 'https://arxiv.org/abs/2501.09980', 'abstract': 'Intracranial aneurysm (IA) is a common cerebrovascular disease that is usually asymptomatic but may cause severe subarachnoid hemorrhage (SAH) if ruptured. Although clinical practice is usually based on individual factors and morphological features of the aneurysm, its pathophysiology and hemodynamic mechanisms remain controversial. To address the limitations of current research, this study constructed a comprehensive hemodynamic dataset of intracranial aneurysms. The dataset is based on 466 real aneurysm models, and 10,000 synthetic models were generated by resection and deformation operations, including 466 aneurysm-free models and 9,534 deformed aneurysm models. The dataset also provides medical image-like segmentation mask files to support insightful analysis. In addition, the dataset contains hemodynamic data measured at eight steady-state flow rates (0.001 to 0.004 kg/s), including critical parameters such as flow velocity, pressure, and wall shear stress, providing a valuable resource for investigating aneurysm pathogenesis and clinical prediction. This dataset will help advance the understanding of the pathologic features and hemodynamic mechanisms of intracranial aneurysms and support in-depth research in related fields. Dataset hosted at this https URL.', 'abstract_zh': '颅内动脉瘤（IA）是一种常见的脑血管疾病，通常无症状，但一旦破裂可能导致严重的蛛网膜下腔出血（SAH）。尽管临床实践通常基于动脉瘤的个体因素和形态特征，其病理生理机制和血流动力学机制仍存在争议。为解决当前研究的局限性，本研究构建了一个全面的颅内动脉瘤血流动力学数据集。该数据集基于466例真实的动脉瘤模型，并通过切除和变形操作生成了1万个人工合成模型，其中包括466例无动脉瘤模型和9534例变形动脉瘤模型。数据集还提供了医学影像级别的分割掩模文件，以支持深入分析。此外，数据集包含了在八种稳态流速（0.001至0.004 kg/s）下测量的血流动力学数据，包括关键参数如流速、压力和壁剪切应力等，为研究动脉瘤的发生机制和临床预测提供了宝贵的资源。该数据集将有助于深化对颅内动脉瘤病理特征和血流动力学机制的理解，并支持相关领域的深入研究。数据集网址详见此处 <https://this.is.url>。', 'title_zh': 'Aneumo：大规模综合合成动脉瘤血流动力学数据集'}
{'arxiv_id': 'arXiv:2501.09972', 'title': 'GVMGen: A General Video-to-Music Generation Model with Hierarchical Attentions', 'authors': 'Heda Zuo, Weitao You, Junxian Wu, Shihong Ren, Pei Chen, Mingxu Zhou, Yujia Lu, Lingyun Sun', 'link': 'https://arxiv.org/abs/2501.09972', 'abstract': 'Composing music for video is essential yet challenging, leading to a growing interest in automating music generation for video applications. Existing approaches often struggle to achieve robust music-video correspondence and generative diversity, primarily due to inadequate feature alignment methods and insufficient datasets. In this study, we present General Video-to-Music Generation model (GVMGen), designed for generating high-related music to the video input. Our model employs hierarchical attentions to extract and align video features with music in both spatial and temporal dimensions, ensuring the preservation of pertinent features while minimizing redundancy. Remarkably, our method is versatile, capable of generating multi-style music from different video inputs, even in zero-shot scenarios. We also propose an evaluation model along with two novel objective metrics for assessing video-music alignment. Additionally, we have compiled a large-scale dataset comprising diverse types of video-music pairs. Experimental results demonstrate that GVMGen surpasses previous models in terms of music-video correspondence, generative diversity, and application universality.', 'abstract_zh': '为视频作曲是必不可少但极具挑战性的任务，这导致了在视频应用中自动化音乐生成的兴趣日益增长。现有的方法往往难以实现稳健的音乐-视频对应和生成多样性，主要原因是特征对齐方法不足以及数据集不充足。在此研究中，我们提出了通用视频到音乐生成模型（GVMGen），旨在生成与视频输入高度相关的音乐。我们的模型采用了层次注意力机制，在空间和时间维度上提取并对齐视频特征和音乐，确保保留关键特征的同时减少冗余。值得一提的是，我们的方法具有极大的通用性，能够在零样本的情况下从不同类型的视频输入生成多种风格的音乐。我们还提出了一种评估模型，并引入了两个新的客观评估指标，用于评估视频-音乐对齐情况。此外，我们还编译了一个包含多种类型的视频-音乐配对的大规模数据集。实验结果表明，GVMGen在音乐-视频对应、生成多样性和应用通用性方面超越了之前的模型。', 'title_zh': 'GVMGen：一种基于层次注意力机制的通用视频到音乐生成模型'}
{'arxiv_id': 'arXiv:2501.09967', 'title': 'Explainable artificial intelligence (XAI): from inherent explainability to large language models', 'authors': 'Fuseini Mumuni, Alhassan Mumuni', 'link': 'https://arxiv.org/abs/2501.09967', 'abstract': 'Artificial Intelligence (AI) has continued to achieve tremendous success in recent times. However, the decision logic of these frameworks is often not transparent, making it difficult for stakeholders to understand, interpret or explain their behavior. This limitation hinders trust in machine learning systems and causes a general reluctance towards their adoption in practical applications, particularly in mission-critical domains like healthcare and autonomous driving. Explainable AI (XAI) techniques facilitate the explainability or interpretability of machine learning models, enabling users to discern the basis of the decision and possibly avert undesirable behavior. This comprehensive survey details the advancements of explainable AI methods, from inherently interpretable models to modern approaches for achieving interpretability of various black box models, including large language models (LLMs). Additionally, we review explainable AI techniques that leverage LLM and vision-language model (VLM) frameworks to automate or improve the explainability of other machine learning models. The use of LLM and VLM as interpretability methods particularly enables high-level, semantically meaningful explanations of model decisions and behavior. Throughout the paper, we highlight the scientific principles, strengths and weaknesses of state-of-the-art methods and outline different areas of improvement. Where appropriate, we also present qualitative and quantitative comparison results of various methods to show how they compare. Finally, we discuss the key challenges of XAI and directions for future research.', 'abstract_zh': '近年来，人工智能（AI）取得了 tremendous 的成功。然而，这些框架的决策逻辑往往不够透明，这使得利益相关者难以理解、解释或解释其行为。这一局限性阻碍了对机器学习系统的信任，并导致在关键任务领域，如医疗保健和自动驾驶等广泛应用中，存在普遍的采用犹豫情绪。可解释的人工智能（XAI）技术能够增强机器学习模型的可解释性或可理解性，允许用户了解决策的基础，并可能防止不良行为。本文综述了可解释人工智能方法的最新进展，从固有的可解释性模型到现代实现各种黑盒模型可解释性的方法，包括大型语言模型（LLMs）。此外，本文还回顾了利用LLM和视觉-语言模型（VLM）框架提高其他机器学习模型可解释性的技术。使用LLM和VLM作为可解释性方法特别能够提供关于模型决策和行为的高层次、语义上具有意义的解释。在论文中，我们强调了最先进的方法的科学原理、优势和局限性，并概述了不同的改进领域。在适当时，我们还提供了各种方法的定性和定量比较结果，展示了它们之间的差异。最后，本文讨论了可解释人工智能的关键挑战和未来研究的方向。', 'title_zh': '可解释的人工智能（XAI）：从固有可解释性到大型语言模型'}
{'arxiv_id': 'arXiv:2501.09954', 'title': 'AIRCHITECT v2: Learning the Hardware Accelerator Design Space through Unified Representations', 'authors': 'Jamin Seo, Akshat Ramachandran, Yu-Chuan Chuang, Anirudh Itagi, Tushar Krishna', 'link': 'https://arxiv.org/abs/2501.09954', 'abstract': 'Design space exploration (DSE) plays a crucial role in enabling custom hardware architectures, particularly for emerging applications like AI, where optimized and specialized designs are essential. With the growing complexity of deep neural networks (DNNs) and the introduction of advanced foundational models (FMs), the design space for DNN accelerators is expanding at an exponential rate. Additionally, this space is highly non-uniform and non-convex, making it increasingly difficult to navigate and optimize. Traditional DSE techniques rely on search-based methods, which involve iterative sampling of the design space to find the optimal solution. However, this process is both time-consuming and often fails to converge to the global optima for such design spaces. Recently, AIrchitect v1, the first attempt to address the limitations of search-based techniques, transformed DSE into a constant-time classification problem using recommendation networks. In this work, we propose AIrchitect v2, a more accurate and generalizable learning-based DSE technique applicable to large-scale design spaces that overcomes the shortcomings of earlier approaches. Specifically, we devise an encoder-decoder transformer model that (a) encodes the complex design space into a uniform intermediate representation using contrastive learning and (b) leverages a novel unified representation blending the advantages of classification and regression to effectively explore the large DSE space without sacrificing accuracy. Experimental results evaluated on 10^5 real DNN workloads demonstrate that, on average, AIrchitect v2 outperforms existing techniques by 15% in identifying optimal design points. Furthermore, to demonstrate the generalizability of our method, we evaluate performance on unseen model workloads (LLMs) and attain a 1.7x improvement in inference latency on the identified hardware architecture.', 'abstract_zh': '设计空间探索（DSE）在推动定制硬件架构的发展中扮演着关键角色，尤其是在AI等新兴应用领域，优化和专业化的设计至关重要。随着深度神经网络（DNNs）复杂性的不断增加以及先进基础模型（FMs）的引入，DNN加速器的设计空间以指数级速度扩展。此外，这个空间高度非均匀且非凸，使得导航和优化变得越来越困难。传统的DSE技术依赖于基于搜索的方法，这些方法通过迭代采样设计空间以找到最优解。然而，这一过程既耗时又往往无法收敛到全局最优解。最近，AIrchitect v1作为一个克服基于搜索技术限制的尝试，使用推荐网络将DSE转变为常量时间分类问题。在此基础上，我们提出了AIrchitect v2，这是一种更准确且更具普适性的基于学习的DSE技术，适用于大型设计空间，能克服早期方法的不足。具体来说，我们设计了一个编码器-解码器变换模型，该模型通过对比学习将复杂的DSE空间编码为均匀的中间表示，并通过结合分类和回归的优势的新型统一表示来有效地探索大数据量的设计空间而不牺牲精度。在对10^5个实际DNN工作负载的实验结果中，AIrchitect v2在识别最优设计点方面平均优于现有技术15%。此外，为了证明我们方法的一般性，我们在未见过的工作负载（LLMs）上评估了性能，并在所识别的硬件架构上实现了1.7倍的推理延迟改进。', 'title_zh': 'AIRCHITECT v2: 通过统一表示学习硬件加速器设计空间'}
{'arxiv_id': 'arXiv:2501.09949', 'title': 'MultiPruner: Balanced Structure Removal in Foundation Models', 'authors': 'J. Pablo Muñoz, Jinjie Yuan, Nilesh Jain', 'link': 'https://arxiv.org/abs/2501.09949', 'abstract': 'Recently, state-of-the-art approaches for pruning large pre-trained models (LPMs) have demonstrated that the training-free removal of non-critical residual blocks in Transformers is viable for reducing model size, achieving results that outperform previous training-free pruning approaches. Motivated by these findings, we extend BlockPruner (Zhong et al., 2024) and propose MultiPruner, a pruning approach that surpasses recent training-free pruning methods by adopting a multidimensional, iterative, fine-grained pruning strategy. In MultiPruner, multidimensional pruning reinstates the structural balance in block-pruned models by sequentially compressing along three dimensions: i) residual blocks, ii) channels of multilayer perceptrons (MLP), and iii) attention heads. This solution enhances zero-shot accuracy on downstream tasks compared to other techniques while improving model compression ratios, producing compressed models with fewer computing and memory requirements. Extensive experiments demonstrate the advantages of the proposed method across various large pre-trained models. The code and pruning configurations are available at this https URL.', 'abstract_zh': '近年来，剪枝大型预训练模型（LPMs）的最新方法表明，在不训练的情况下移除变压器中的非关键残差块是可行的，可以减小模型大小并获得优于以往无训练剪枝方法的结果。受这一发现的启发，我们扩展了BlockPruner（Zhong et al., 2024），并提出了一种新的剪枝方法——MultiPruner。MultiPruner 采用多维度、迭代且精细的剪枝策略，超越了现有的无训练剪枝方法。在MultiPruner 中，多维度剪枝通过依次在三个维度上进行压缩来恢复剪枝模型的结构平衡：i) 残差块，ii) 多层感知器（MLP）的通道，iii) 注意力头。这种方法在下游任务中的零样本准确性上优于其他技术，同时改善了模型压缩比，产生了对计算和内存需求更低的压缩模型。广泛的实验表明，所提出的方法在各种大型预训练模型中具有优势。相关代码和剪枝配置可在以下网址获取：this https URL', 'title_zh': 'MultiPruner: 基础模型中的均衡结构修剪'}
{'arxiv_id': 'arXiv:2501.09948', 'title': 'AI Explainability for Power Electronics: From a Lipschitz Continuity Perspective', 'authors': 'Xinze Li, Fanfan Lin, Homer Alan Mantooth, Juan José Rodríguez-Andina', 'link': 'https://arxiv.org/abs/2501.09948', 'abstract': 'Lifecycle management of power converters continues to thrive with emerging artificial intelligence (AI) solutions, yet AI mathematical explainability remains unexplored in power electronics (PE) community. The lack of theoretical rigor challenges adoption in mission-critical applications. Therefore, this letter proposes a generic framework to evaluate mathematical explainability, highlighting inference stability and training convergence from a Lipschitz continuity perspective. Inference stability governs consistent outputs under input perturbations, essential for robust real-time control and fault diagnosis. Training convergence guarantees stable learning dynamics, facilitating accurate modeling in PE contexts. Additionally, a Lipschitz-aware learning rate selection strategy is introduced to accelerate convergence while mitigating overshoots and oscillations. The feasibility of the proposed Lipschitz-oriented framework is demonstrated by validating the mathematical explainability of a state-of-the-art physics-in-architecture neural network, and substantiated through empirical case studies on dual-active-bridge converters. This letter serves as a clarion call for the PE community to embrace mathematical explainability, heralding a transformative era of trustworthy and explainable AI solutions that potentially redefine the future of power electronics.', 'abstract_zh': '功率转换器的生命周期管理在新兴的人工智能（AI）解决方案推动下不断发展，但在功率电子学（PE）领域，AI的数学可解释性尚未得到探讨。缺乏理论严谨性，这在关键任务应用中构成了挑战。因此，本文提出了一种通用框架来评估数学可解释性，并从Lipschitz连续性的角度突出推理稳定性和训练收敛性。推理稳定性决定了在输入扰动下输出的一致性，对于稳健的实时控制和故障诊断至关重要。训练收敛性保证了稳定的动态学习过程，有助于在PE上下文中实现准确建模。此外，还引入了一种基于Lipschitz感知的学习率选择策略，以加速收敛并减少过度振荡。通过验证最先进的基于物理架构的神经网络的数学可解释性，以及在双活性桥变换器的实证案例研究中证实了所提出的Lipschitz导向框架的可行性。本文呼吁PE社区接受数学可解释性，预示着一个变革时代，即具有可信赖性和可解释性的AI解决方案可能重新定义功率电子学的未来。', 'title_zh': '从Lipschitz连续性的视角探讨电力电子中的AI可解释性'}
{'arxiv_id': 'arXiv:2501.09946', 'title': 'Client-Centric Federated Adaptive Optimization', 'authors': 'Jianhui Sun, Xidong Wu, Heng Huang, Aidong Zhang', 'link': 'https://arxiv.org/abs/2501.09946', 'abstract': 'Federated Learning (FL) is a distributed learning paradigm where clients collaboratively train a model while keeping their own data private. With an increasing scale of clients and models, FL encounters two key challenges, client drift due to a high degree of statistical/system heterogeneity, and lack of adaptivity. However, most existing FL research is based on unrealistic assumptions that virtually ignore system heterogeneity. In this paper, we propose Client-Centric Federated Adaptive Optimization, which is a class of novel federated adaptive optimization approaches. We enable several features in this framework such as arbitrary client participation, asynchronous server aggregation, and heterogeneous local computing, which are ubiquitous in real-world FL systems but are missed in most existing works. We provide a rigorous convergence analysis of our proposed framework for general nonconvex objectives, which is shown to converge with the best-known rate. Extensive experiments show that our approaches consistently outperform the baseline by a large margin across benchmarks.', 'abstract_zh': '联邦学习（FL）是一种分布式机器学习范式，在这种范式中，客户端协作训练模型的同时保持其数据的隐私性。随着客户端和模型规模的不断扩大，FL 遇到了两个关键挑战：由于高度的统计异质性和系统异质性导致的客户端漂移，以及缺乏适应性。然而，目前大多数现有的FL研究基于一些不切实际的假设，几乎忽视了系统异质性。本文中，我们提出了客户端中心的联邦自适应优化框架，这是一种新型的联邦自适应优化方法。该框架支持多种功能，如任意客户端参与、异步服务器聚合以及异质本地计算，这些都是真实世界FL系统中的常见功能，但在大多数现有研究中未被提及。我们对一般非凸目标函数的本框架进行了严格的收敛性分析，并证明其收敛速度与已知的最佳速度相同。广泛的实验表明，在各种基准测试中，我们的方法相对于基准方法具有显著的优越性。', 'title_zh': '以客户端为中心的联邦自适应优化'}
{'arxiv_id': 'arXiv:2501.09934', 'title': 'HEART: Achieving Timely Multi-Model Training for Vehicle-Edge-Cloud-Integrated Hierarchical Federated Learning', 'authors': 'Xiaohong Yang, Minghui Liwang, Xianbin Wang, Zhipeng Cheng, Seyyedali Hosseinalipour, Huaiyu Dai, Zhenzhen Jiao', 'link': 'https://arxiv.org/abs/2501.09934', 'abstract': 'The rapid growth of AI-enabled Internet of Vehicles (IoV) calls for efficient machine learning (ML) solutions that can handle high vehicular mobility and decentralized data. This has motivated the emergence of Hierarchical Federated Learning over vehicle-edge-cloud architectures (VEC-HFL). Nevertheless, one aspect which is underexplored in the literature on VEC-HFL is that vehicles often need to execute multiple ML tasks simultaneously, where this multi-model training environment introduces crucial challenges. First, improper aggregation rules can lead to model obsolescence and prolonged training times. Second, vehicular mobility may result in inefficient data utilization by preventing the vehicles from returning their models to the network edge. Third, achieving a balanced resource allocation across diverse tasks becomes of paramount importance as it majorly affects the effectiveness of collaborative training. We take one of the first steps towards addressing these challenges via proposing a framework for multi-model training in dynamic VEC-HFL with the goal of minimizing global training latency while ensuring balanced training across various tasks-a problem that turns out to be NP-hard. To facilitate timely model training, we introduce a hybrid synchronous-asynchronous aggregation rule. Building on this, we present a novel method called Hybrid Evolutionary And gReedy allocaTion (HEART). The framework operates in two stages: first, it achieves balanced task scheduling through a hybrid heuristic approach that combines improved Particle Swarm Optimization (PSO) and Genetic Algorithms (GA); second, it employs a low-complexity greedy algorithm to determine the training priority of assigned tasks on vehicles. Experiments on real-world datasets demonstrate the superiority of HEART over existing methods.', 'abstract_zh': 'AI驱动的车联网（IoV）的快速增长要求能够处理高车速移动性和分散式数据的高效机器学习（ML）解决方案。这促进了车辆-边缘-云架构（VEC-HFL）分层级联邦学习的出现。然而，文献中的VEC-HFL方面的一个未被充分探索的问题是，车辆经常需要同时执行多个ML任务，这种多模型训练环境引入了关键挑战。首先，不恰当的聚合规则可能导致模型过时和延长训练时间；其次，车辆的移动性可能会导致数据利用效率低下，因为车辆无法将模型返回到网络边缘；第三，资源在不同任务间的平衡分配变得至关重要，因为这主要影响协同训练的效果。我们通过提出一种框架，旨在解决这些挑战中的部分问题，以最小化全局训练延迟并确保任务训练的均衡进行——这是一个确定NP-hard的问题。为了实现及时的模型训练，我们引入了一种混合同步-异步聚合规则。在此基础上，我们提出了一种名为Hybrid Evolutionary And Greedy Allocation（HEART）的新方法。该框架分为两个阶段：首先，通过结合改进的粒子群优化（PSO）和遗传算法（GA）的混合启发式方法来实现任务调度的平衡；其次，采用低复杂度的贪婪算法来确定分配给各个车辆的任务的优先级。实验证明，HEART方法在实际数据集上优于现有方法。', 'title_zh': 'HEART：实现车辆-边缘-云集成分层联邦学习的及时多模型训练'}
{'arxiv_id': 'arXiv:2501.09929', 'title': 'Steering Large Language Models with Feature Guided Activation Additions', 'authors': 'Samuel Soo, Wesley Teng, Chandrasekaran Balaganesh', 'link': 'https://arxiv.org/abs/2501.09929', 'abstract': "Effective and reliable control over large language model (LLM) behavior is a significant challenge. While activation steering methods, which add steering vectors to a model's hidden states, are a promising approach, existing techniques often lack precision and interpretability in how they influence model outputs. We introduce Feature Guided Activation Additions (FGAA), a novel activation steering method that leverages insights from Contrastive Activation Addition (CAA) and Sparse Autoencoder-Targeted Steering (SAE-TS). By operating in the latent space of a Sparse Autoencoder (SAE) and employing optimization techniques to select desired SAE features, FGAA constructs precise steering vectors that provide better steering effects while maintaining coherence of steered model outputs. In this regard, evaluations on Gemma-2-2B and Gemma-2-9B models across various steering tasks demonstrate that FGAA outperforms existing steering methods of CAA, SAE decoder steering, and SAE-TS. Our results also highlight important trade-offs between steering scale and general model capabilities that are consistent across all tested steering methods.", 'abstract_zh': '对大型语言模型（LLM）行为的有效且可靠的控制是一项重大挑战。虽然添加引导向量到模型隐状态的激活引导方法是一种有前途的方法，但现有技术在影响模型输出方面往往缺乏精确性和可解释性。我们引入了一种名为特征引导激活添加（FGAA）的新激活引导方法，它结合了对比激活添加（CAA）和稀疏自编码器目标引导（SAE-TS）的见解。FGAA在稀疏自编码器（SAE）的潜在空间中操作，并通过优化技术选择所需的SAE特征，构建了精确的引导向量，这些向量提供了更好的引导效果，同时保持了引导后模型输出的一致性。在这种情况下，对Gemma-2-2B和Gemma-2-9B模型在各种引导任务上的评估表明，FGAA在引导效果方面优于现有的CAA、SAE解码器引导和SAE-TS引导方法。我们的结果还强调了在所有测试的引导方法中贯时间的一致性权衡，即引导规模与通用模型能力之间的权衡。', 'title_zh': '使用特征导向激活增益引导大型语言模型'}
{'arxiv_id': 'arXiv:2501.09928', 'title': 'Dialogue Benchmark Generation from Knowledge Graphs with Cost-Effective Retrieval-Augmented LLMs', 'authors': 'Reham Omar, Omij Mangukiya, Essam Mansour', 'link': 'https://arxiv.org/abs/2501.09928', 'abstract': 'Dialogue benchmarks are crucial in training and evaluating chatbots engaging in domain-specific conversations. Knowledge graphs (KGs) represent semantically rich and well-organized data spanning various domains, such as DBLP, DBpedia, and YAGO. Traditionally, dialogue benchmarks have been manually created from documents, neglecting the potential of KGs in automating this process. Some question-answering benchmarks are automatically generated using extensive preprocessing from KGs, but they do not support dialogue generation. This paper introduces Chatty-Gen, a novel multi-stage retrieval-augmented generation platform for automatically generating high-quality dialogue benchmarks tailored to a specific domain using a KG. Chatty-Gen decomposes the generation process into manageable stages and uses assertion rules for automatic validation between stages. Our approach enables control over intermediate results to prevent time-consuming restarts due to hallucinations. It also reduces reliance on costly and more powerful commercial LLMs. Chatty-Gen eliminates upfront processing of the entire KG using efficient query-based retrieval to find representative subgraphs based on the dialogue context. Our experiments with several real and large KGs demonstrate that Chatty-Gen significantly outperforms state-of-the-art systems and ensures consistent model and system performance across multiple LLMs of diverse capabilities, such as GPT-4o, Gemini 1.5, Llama 3, and Mistral.', 'abstract_zh': '对话基准在训练和评估从事特定领域对话的聊天机器人时至关重要。知识图谱（KGs）表示涵盖各种领域、具有丰富语义和良好组织的数据，如DBLP、DBpedia和YAGO。传统上，对话基准是通过手动从文档中创建的，忽略了利用KGs自动执行此过程的潜力。虽然有些问答基准是通过从KGs进行大量预处理自动生成的，但它们并不支持对话生成。本文介绍了Chatty-Gen，这是一种新颖的多阶段检索增强生成平台，能够利用KG自动生成高质量的对话基准，这些基准针对特定领域进行定制。Chatty-Gen将生成过程分解为可管理的阶段，并使用断言规则进行自动校验。我们的方法使得能够控制中间结果，以防止由于幻觉而导致的时间消耗的重新启动，从而减少了对昂贵且更强大的商业LLM的依赖。Chatty-Gen利用高效的基于查询的检索，直接从整个KG中检索代表性的子图，而不是进行前期处理整个KG。我们的实验表明，Chatty-Gen在多个大型实际KG上的表现显著优于现有系统，并确保了跨不同能力的多种LLM的一致模型和系统性能，包括GPT-4o、Gemini 1.5、Llama 3和Mistral。', 'title_zh': '使用经济高效检索增强的大语言模型从知识图谱生成对话基准'}
{'arxiv_id': 'arXiv:2501.09927', 'title': 'IE-Bench: Advancing the Measurement of Text-Driven Image Editing for Human Perception Alignment', 'authors': 'Shangkun Sun, Bowen Qu, Xiaoyu Liang, Songlin Fan, Wei Gao', 'link': 'https://arxiv.org/abs/2501.09927', 'abstract': "Recent advances in text-driven image editing have been significant, yet the task of accurately evaluating these edited images continues to pose a considerable challenge. Different from the assessment of text-driven image generation, text-driven image editing is characterized by simultaneously conditioning on both text and a source image. The edited images often retain an intrinsic connection to the original image, which dynamically change with the semantics of the text. However, previous methods tend to solely focus on text-image alignment or have not aligned with human perception. In this work, we introduce the Text-driven Image Editing Benchmark suite (IE-Bench) to enhance the assessment of text-driven edited images. IE-Bench includes a database contains diverse source images, various editing prompts and the corresponding results different editing methods, and total 3,010 Mean Opinion Scores (MOS) provided by 25 human subjects. Furthermore, we introduce IE-QA, a multi-modality source-aware quality assessment method for text-driven image editing. To the best of our knowledge, IE-Bench offers the first IQA dataset and model tailored for text-driven image editing. Extensive experiments demonstrate IE-QA's superior subjective-alignments on the text-driven image editing task compared with previous metrics. We will make all related data and code available to the public.", 'abstract_zh': '近年来，基于文本的图像编辑取得了显著进步，然而评估这些编辑后的图像仍面临 considerable 挑战。与基于文本的图像生成评估不同，基于文本的图像编辑同时需根据文本和源图像进行条件控制。编辑后的图像通常保留与原始图像的内在联系，这种联系会随着文本语义的变化而变化。然而，先前的方法往往仅集中在文本与图像的对齐上，或者未能与人类感知相符。在本文中，我们引入了基于文本的图像编辑基准套件（IE-Bench）以改进对基于文本的编辑图像的评估。IE-Bench 包含一个包含多种类型源图像、多种编辑提示及其相应结果的数据库，以及总计由 25 位人类受试者提供的 3,010 个期望质量评分（MOS）。此外，我们还引入了 IE-QA，这是一种多模态感知意识质量评估方法，用于基于文本的图像编辑。据我们所知，IE-Bench 提供了首个针对基于文本的图像编辑定制的 IQA 数据集和模型。广泛实验表明，IE-QA 在基于文本的图像编辑任务上的主观对齐方面优于以往的度量标准。我们将所有相关数据和代码向公众公开。', 'title_zh': 'IE-Bench: 推动基于文本驱动的图像编辑测量以实现人类感知对齐'}
{'arxiv_id': 'arXiv:2501.09923', 'title': 'Study on a Fast Solver for Combined Field Integral Equations of 3D Conducting Bodies Based on Graph Neural Networks', 'authors': 'Tao Shan, Xin Zhang, Di Wu', 'link': 'https://arxiv.org/abs/2501.09923', 'abstract': 'In this paper, we present a graph neural networks (GNNs)-based fast solver (GraphSolver) for solving combined field integral equations (CFIEs) of 3D conducting bodies. Rao-Wilton-Glisson (RWG) basis functions are employed to discretely and accurately represent the geometry of 3D conducting bodies. A concise and informative graph representation is then constructed by treating each RWG function as a node in the graph, enabling the flow of current between nodes. With the transformed graphs, GraphSolver is developed to directly predict real and imaginary parts of the x, y and z components of the surface current densities at each node (RWG function). Numerical results demonstrate the efficacy of GraphSolver in solving CFIEs for 3D conducting bodies with varying levels of geometric complexity, including basic 3D targets, missile-shaped targets, and airplane-shaped targets.', 'abstract_zh': '在本文中，我们提出了一种基于图神经网络（GNNs）的快速求解器（GraphSolver），用于解决三维导体的组合场积分方程（CFIEs）。采用了Rao-Wilton-Glisson (RWG) 基函数来离散和准确地表示三维导体的几何形状。通过将每个RWG函数视为图中的一个节点，构建了一个简洁且信息丰富的图表示，从而能够在节点间流动电流。借助转换后的图结构，GraphSolver能够直接预测每个节点（RWG函数）处x、y和z方向的表面电流密度的实部和虚部。数值结果表明，GraphSolver在解决具有不同几何复杂程度的三维导体的CFIEs方面具有有效性，包括基本的3D目标、导弹形目标和飞机形目标。', 'title_zh': '基于图神经网络的三维导体结合场积分方程快速求解方法研究'}
{'arxiv_id': 'arXiv:2501.09905', 'title': 'SLIM: Sim-to-Real Legged Instructive Manipulation via Long-Horizon Visuomotor Learning', 'authors': 'Haichao Zhang, Haonan Yu, Le Zhao, Andrew Choi, Qinxun Bai, Yiqing Yang, Wei Xu', 'link': 'https://arxiv.org/abs/2501.09905', 'abstract': 'We present a low-cost quadruped manipulation system that solves long-horizon real-world tasks, trained by reinforcement learning purely in simulation. The system comprises 1) a hierarchical design of a high-level policy for visual-mobile manipulation following instructions, and a low-level policy for quadruped movement and limb-control, 2) a progressive policy expansion approach for solving the long-horizon task together with a teacher-student framework for efficient high-level training of the high-level visuomotor policy, and 3) a suite of techniques for minimizing sim-to-real gaps.\nWith budget-friendly but limited reliability and performance hardware, and just one wrist-mounted RGB camera, the entire system fully trained in simulation achieves high success rates for long horizon tasks involving search, move, grasp, and drop-into, with fluid sim-to-real transfer in a wide variety of indoor and outdoor scenes and lighting this http URL real-world evaluations show that on the long horizon mobile manipulation tasks, our system achieves good performance when transferred to real both in terms of task success rate and execution efficiency. Finally, we discuss the necessity of our sim-to-real techniques for legged mobile manipulation, and show their ablation performance.', 'abstract_zh': '我们提出了一种低成本的四足操作系统，该系统能够解决长期前景的现实世界任务，并且完全是通过模拟中的强化学习进行训练。该系统包含以下组成部分：\n1）一个层次化的设计，包括用于根据指令进行视觉-移动操作的高层策略，以及用于四足运动和四肢控制的低层策略；\n2）用于解决长期任务的逐步策略扩展方法，以及一种教师-学生框架，用于高效训练高层的视觉-运动策略；\n3）一系列减少模拟到现实差距的技术。\n即使使用预算有限但可靠性较低且性能有限的硬件，并且仅配备一个腕部安装的RGB相机，整个系统在模拟中完全训练后，在涉及搜索、移动、抓取和释放等多种长期任务中取得了较高的成功率，并在各种室内外场景中实现了流畅的模拟到现实的转移。实际世界评估显示，我们的系统在转移至现实世界的长期移动操作任务中，在任务成功率和执行效率方面均表现良好。最后，我们讨论了模拟到现实技术对腿足式移动操作的重要性，并展示了它们的消融性能。', 'title_zh': 'SLIM：长时 horizon 视觉运动学习指导的腿部仿真实践操作'}
{'arxiv_id': 'arXiv:2501.09878', 'title': 'ASTRA: A Scene-aware TRAnsformer-based model for trajectory prediction', 'authors': 'Izzeddin Teeti, Aniket Thomas, Munish Monga, Sachin Kumar, Uddeshya Singh, Andrew Bradley, Biplab Banerjee, Fabio Cuzzolin', 'link': 'https://arxiv.org/abs/2501.09878', 'abstract': "We present ASTRA (A} Scene-aware TRAnsformer-based model for trajectory prediction), a light-weight pedestrian trajectory forecasting model that integrates the scene context, spatial dynamics, social inter-agent interactions and temporal progressions for precise forecasting. We utilised a U-Net-based feature extractor, via its latent vector representation, to capture scene representations and a graph-aware transformer encoder for capturing social interactions. These components are integrated to learn an agent-scene aware embedding, enabling the model to learn spatial dynamics and forecast the future trajectory of pedestrians. The model is designed to produce both deterministic and stochastic outcomes, with the stochastic predictions being generated by incorporating a Conditional Variational Auto-Encoder (CVAE). ASTRA also proposes a simple yet effective weighted penalty loss function, which helps to yield predictions that outperform a wide array of state-of-the-art deterministic and generative models. ASTRA demonstrates an average improvement of 27%/10% in deterministic/stochastic settings on the ETH-UCY dataset, and 26% improvement on the PIE dataset, respectively, along with seven times fewer parameters than the existing state-of-the-art model (see Figure 1). Additionally, the model's versatility allows it to generalize across different perspectives, such as Bird's Eye View (BEV) and Ego-Vehicle View (EVV).", 'abstract_zh': '我们提出了ASTRA（一种场景感知的基于Transformer的轨迹预测模型），该模型是一个轻量级的人行轨迹预测模型，能够整合场景上下文、空间动力学、社交交互以及时间进程，以实现精确的预测。我们使用了基于U-Net的特征提取器，并通过其潜在向量表示来捕获场景感知特征，并使用图感知的Transformer编码器来捕获社交交互。这些组件被集成以学习代理-场景感知嵌入，使得模型能够学习空间动力学并预测行人的未来轨迹。该模型旨在生成确定性和随机性两种结果，随机性预测通过引入条件变分自编码器（CVAE）进行生成。ASTRA还提出了一种简单而有效的加权惩罚损失函数，该函数有助于生成优于多种最先进的确定性生成模型的预测结果。在ETH-UCY数据集的确定性设置中，ASTRA的性能提高了27%，在随机设置中提高了10%；在PIE数据集上，性能提高了26%。此外，该模型的通用性使其能够在不同的视角（如鸟瞰图（BEV）和以车为参照的视角（EVV））之间进行扩展和泛化，且参数量仅为现有最先进的模型的七分之一（参见图1）。', 'title_zh': 'ASTRA：一种场景意识的 Transformer 基础轨迹预测模型'}
{'arxiv_id': 'arXiv:2501.09858', 'title': 'From Explainability to Interpretability: Interpretable Policies in Reinforcement Learning Via Model Explanation', 'authors': 'Peilang Li, Umer Siddique, Yongcan Cao', 'link': 'https://arxiv.org/abs/2501.09858', 'abstract': "Deep reinforcement learning (RL) has shown remarkable success in complex domains, however, the inherent black box nature of deep neural network policies raises significant challenges in understanding and trusting the decision-making processes. While existing explainable RL methods provide local insights, they fail to deliver a global understanding of the model, particularly in high-stakes applications. To overcome this limitation, we propose a novel model-agnostic approach that bridges the gap between explainability and interpretability by leveraging Shapley values to transform complex deep RL policies into transparent representations. The proposed approach offers two key contributions: a novel approach employing Shapley values to policy interpretation beyond local explanations and a general framework applicable to off-policy and on-policy algorithms. We evaluate our approach with three existing deep RL algorithms and validate its performance in two classic control environments. The results demonstrate that our approach not only preserves the original models' performance but also generates more stable interpretable policies.", 'abstract_zh': '深度强化学习（RL）在复杂领域中已经显示出显著的成功，然而，深层神经网络策略固有的黑箱特性在理解与信任决策过程方面提出了重大挑战。尽管现有可解释的RL方法提供了局部洞察，但在高风险应用中，它们未能提供模型的全局理解。为了克服这一局限性，我们提出了一种新的模型无关方法，通过利用Shapley值将复杂的深度RL策略转换为透明表示，从而在可解释性和可理解性之间架起桥梁。所提出的方法提供了两大贡献：一种新颖的方法，利用Shapley值进行超出局部解释的策略解释，以及一种适用于离策和在线策算法的一个通用框架。我们使用三种现有的深度RL算法评估了该方法，并在两个经典的控制环境中验证了其性能。结果表明，该方法不仅保留了原始模型的性能，还生成了更加稳定的可解释策略。', 'title_zh': '从可解释性到可解析性：通过模型解释实现强化学习中的可解析策略'}
{'arxiv_id': 'arXiv:2501.09838', 'title': 'CrossModalityDiffusion: Multi-Modal Novel View Synthesis with Unified Intermediate Representation', 'authors': 'Alex Berian, Daniel Brignac, JhihYang Wu, Natnael Daba, Abhijit Mahalanobis', 'link': 'https://arxiv.org/abs/2501.09838', 'abstract': "Geospatial imaging leverages data from diverse sensing modalities-such as EO, SAR, and LiDAR, ranging from ground-level drones to satellite views. These heterogeneous inputs offer significant opportunities for scene understanding but present challenges in interpreting geometry accurately, particularly in the absence of precise ground truth data. To address this, we propose CrossModalityDiffusion, a modular framework designed to generate images across different modalities and viewpoints without prior knowledge of scene geometry. CrossModalityDiffusion employs modality-specific encoders that take multiple input images and produce geometry-aware feature volumes that encode scene structure relative to their input camera positions. The space where the feature volumes are placed acts as a common ground for unifying input modalities. These feature volumes are overlapped and rendered into feature images from novel perspectives using volumetric rendering techniques. The rendered feature images are used as conditioning inputs for a modality-specific diffusion model, enabling the synthesis of novel images for the desired output modality. In this paper, we show that jointly training different modules ensures consistent geometric understanding across all modalities within the framework. We validate CrossModalityDiffusion's capabilities on the synthetic ShapeNet cars dataset, demonstrating its effectiveness in generating accurate and consistent novel views across multiple imaging modalities and perspectives.", 'abstract_zh': '地理空间成像利用了多种传感器数据，如光学遥感（EO）、合成孔径雷达（SAR）和激光雷达（LiDAR），这些数据来源从低空无人机到卫星视图不等。这些异构输入为场景理解提供了重大机遇，但缺乏精确的地面真实数据时，它们在准确解释几何形状方面带来了挑战。为解决这一问题，我们提出了一种名为CrossModalityDiffusion的模块化框架，该框架能够在无需先验场景几何知识的情况下，生成不同模态和视角的图像。CrossModalityDiffusion采用了特定模态的编码器，这些编码器接受多个输入图像，并生成编码场景结构相对于输入相机位置的几何感知特征体。这些特征体所在的空间充当了一个统一输入模态的共同基础。特征体通过体绘制技术从新颖视角重叠并渲染成特征图像。渲染出的特征图像作为特定模态的扩散模型的条件输入，从而能够合成所需输出模态的新图像。在本文中，我们展示了联合训练不同模块确保框架内各模态之间几何理解的一致性。我们在合成ShapeNet汽车数据集上验证了CrossModalityDiffusion的能力，展示了其在多种成像模态和视角下生成准确且一致的新视角图像的有效性。', 'title_zh': 'CrossModalityDiffusion: 使用统一中间表示的多模态新型视角合成'}
{'arxiv_id': 'arXiv:2501.09825', 'title': 'Bridging Language Barriers in Healthcare: A Study on Arabic LLMs', 'authors': 'Nada Saadi, Tathagata Raha, Clément Christophe, Marco AF Pimentel, Ronnie Rajan, Praveen K Kanithi', 'link': 'https://arxiv.org/abs/2501.09825', 'abstract': 'This paper investigates the challenges of developing large language models (LLMs) proficient in both multilingual understanding and medical knowledge. We demonstrate that simply translating medical data does not guarantee strong performance on clinical tasks in the target language. Our experiments reveal that the optimal language mix in training data varies significantly across different medical tasks. We find that larger models with carefully calibrated language ratios achieve superior performance on native-language clinical tasks. Furthermore, our results suggest that relying solely on fine-tuning may not be the most effective approach for incorporating new language knowledge into LLMs. Instead, data and computationally intensive pretraining methods may still be necessary to achieve optimal performance in multilingual medical settings. These findings provide valuable guidance for building effective and inclusive medical AI systems for diverse linguistic communities.', 'abstract_zh': '本文探讨了开发既擅长多语言理解又具备医学知识的大规模语言模型（LLMs）所面临的挑战。我们证明，简单地翻译医学数据并不能保证在目标语言的临床任务中表现出色。我们的实验表明，用于训练的数据中最佳的语言组合在不同医学任务中差异显著。我们发现，经过仔细校准语言比例的大规模模型在母语临床任务中能够获得更好的性能。此外，我们的研究结果表明，仅仅依赖微调可能不是将新语言知识有效整合到LLMs中的最有效方法。相反，在多语言医学环境中实现最佳性能可能仍需要数据和计算量密集的预训练方法。这些发现为构建适用于多样语言社区的有效和包容性医疗AI系统提供了宝贵的指导。', 'title_zh': '跨越医疗语言障碍：阿拉伯语大语言模型的研究'}
{'arxiv_id': 'arXiv:2501.09817', 'title': 'Generalized Single-Image-Based Morphing Attack Detection Using Deep Representations from Vision Transformer', 'authors': 'Haoyu Zhang, Raghavendra Ramachandra, Kiran Raja, Christoph Busch', 'link': 'https://arxiv.org/abs/2501.09817', 'abstract': 'Face morphing attacks have posed severe threats to Face Recognition Systems (FRS), which are operated in border control and passport issuance use cases. Correspondingly, morphing attack detection algorithms (MAD) are needed to defend against such attacks. MAD approaches must be robust enough to handle unknown attacks in an open-set scenario where attacks can originate from various morphing generation algorithms, post-processing and the diversity of printers/scanners. The problem of generalization is further pronounced when the detection has to be made on a single suspected image. In this paper, we propose a generalized single-image-based MAD (S-MAD) algorithm by learning the encoding from Vision Transformer (ViT) architecture. Compared to CNN-based architectures, ViT model has the advantage on integrating local and global information and hence can be suitable to detect the morphing traces widely distributed among the face region. Extensive experiments are carried out on face morphing datasets generated using publicly available FRGC face datasets. Several state-of-the-art (SOTA) MAD algorithms, including representative ones that have been publicly evaluated, have been selected and benchmarked with our ViT-based approach. Obtained results demonstrate the improved detection performance of the proposed S-MAD method on inter-dataset testing (when different data is used for training and testing) and comparable performance on intra-dataset testing (when the same data is used for training and testing) experimental protocol.', 'abstract_zh': '面部融合攻击对边控和护照发放等场景下运行的面部识别系统（FRS）构成了严重威胁，相应的，需要提出融合攻击检测算法（MAD）来防御此类攻击。MAD方法必须具备足够的鲁棒性，以应对未知类型的攻击，在开放集场景中，这些攻击可能源自各种面部融合生成算法、后处理和打印机/扫描仪的多样性。当检测仅基于单张疑似受损图像时，泛化问题进一步加剧。本文提出了一种基于视网膜变换器（Vision Transformer，ViT）架构的通用单图像MAD（S-MAD）算法，通过学习ViT的编码来提高检测性能。与基于卷积神经网络（CNN）的架构相比，ViT模型在整合局部和全局信息方面具有优势，因此更适合检测面部区域中广泛分布的融合痕迹。我们在使用公开可用的FRGC面部数据集生成的面部融合数据集上进行了大量实验。我们选择了几种最先进的MAD算法（SOTA），包括已经公开评估的一些代表方法，并将其与基于ViT的方法进行了基准测试。实验结果表明，所提出的S-MAD方法在跨数据集测试（使用不同数据进行训练和测试）中表现出更优的检测性能，并且在同数据集测试（使用相同数据进行训练和测试）的实验协议中具有可比的性能。', 'title_zh': '基于视觉变换器的深度表示的广义单图像形态攻击检测'}
{'arxiv_id': 'arXiv:2501.09804', 'title': 'Enhancing Generalization in Chain of Thought Reasoning for Smaller Models', 'authors': 'Maxwell J. Yin, Dingyi Jiang, Yongbing Chen, Boyu Wang, Charles Ling', 'link': 'https://arxiv.org/abs/2501.09804', 'abstract': 'Chain-of-Thought (CoT) reasoning in smaller language models is a challenging natural language process problem yet highly desirable in many real-life applications. Existing CoT knowledge distillation methods often suffer from overly conservative memorization in smaller LLMs, leading to low generalization confidence. As fully preserving the CoT ability of teacher model is impossible, we hypothesize that adversarial CoT fine-tuning is crucial for developing smaller LLM with robust CoT generalization. To this end, we propose \\textit{PRompt-Assisted Domain-Adversarial fine-tuning} (PRADA), a principled fine-tuning framework that integrates diverse CoT domains. Specifically, PRADA pioneers two CoT improvements in smaller LLM: (1) Recovering the domain-invariant feature insight which typically lost during distillation with domain adversarial fine-tuning; (2) Enhancing the domain adaptability of CoT prompt engineering by employing domain-adversarial approaches. We theoretically demonstrate the effectiveness of our approach and empirically show that it significantly outperforms the state of the arts in a wide range of tasks. Moreover, our empirical findings reveal that the smaller LLM, when leveraging PRADA, aligns closely with domain knowledge, thereby improving the explainability of our approach.', 'abstract_zh': '较小语言模型中的链式思考（CoT）推理是一种具有挑战性的自然语言处理问题，但在许多实际应用中极具吸引力。现有的CoT知识精炼方法往往在较小的语言模型中表现出过度保守的记忆，导致较低的泛化置信度。由于完全保留教师模型的CoT能力是不可能的，我们假设对抗性CoT微调对于开发具有稳健CoT泛化能力的小型语言模型至关重要。为实现这一目标，我们提出了\\textit{PRompt-Assisted Domain-Adversarial fine-tuning}（PRADA），这是一种原理性的微调框架，结合了多元化的CoT领域知识。具体来说，PRADA在较小语言模型中实现了两项CoT改进：（1）通过领域对抗性微调恢复领域不变特征的洞察，这是在精炼过程中通常会丢失的；（2）通过运用领域对抗性方法提高CoT提示工程的领域适应性。我们从理论上证明了该方法的有效性，并通过实验证明，在多种任务中，它在性能上显著优于现有的最佳方法。此外，我们的实验结果表明，在利用PRADA时，较小语言模型能够更好地与领域知识对齐，从而提高我们方法的可解释性。', 'title_zh': '提升较小模型在链式思维推理中的泛化能力'}
{'arxiv_id': 'arXiv:2501.09775', 'title': 'Multiple Choice Questions: Reasoning Makes Large Language Models (LLMs) More Self-Confident Even When They Are Wrong', 'authors': 'Tairan Fu, Javier Conde, Gonzalo Martínez, María Grandury, Pedro Reviriego', 'link': 'https://arxiv.org/abs/2501.09775', 'abstract': 'One of the most widely used methods to evaluate LLMs are Multiple Choice Question (MCQ) tests. MCQ benchmarks enable the testing of LLM knowledge on almost any topic at scale as the results can be processed automatically. To help the LLM answer, a few examples called few shots can be included in the prompt. Moreover, the LLM can be asked to answer the question directly with the selected option or to first provide the reasoning and then the selected answer, which is known as chain of thought. In addition to checking whether the selected answer is correct, the evaluation can look at the LLM-estimated probability of its response as an indication of the confidence of the LLM in the response. In this paper, we study how the LLM confidence in its answer depends on whether the model has been asked to answer directly or to provide the reasoning before answering. The results of the evaluation of questions on a wide range of topics in seven different models show that LLMs are more confident in their answers when they provide reasoning before the answer. This occurs regardless of whether the selected answer is correct. Our hypothesis is that this behavior is due to the reasoning that modifies the probability of the selected answer, as the LLM predicts the answer based on the input question and the reasoning that supports the selection made. Therefore, LLM estimated probabilities seem to have intrinsic limitations that should be understood in order to use them in evaluation procedures. Interestingly, the same behavior has been observed in humans, for whom explaining an answer increases confidence in its correctness.', 'abstract_zh': '评价大型语言模型（LLM）最广泛使用的方法之一是多项选择题（MCQ）测试。MCQ基准测试能够大规模地测试LLM在几乎任何主题上的知识，因为测试结果可以自动处理。为了帮助LLM作答，可以在提示中包含一两个示例，称为“少量示例”（few shots）。此外，LLM可以被要求直接选择一个选项作答，或者首先提供推理过程，然后再选择答案，这种做法被称为“推理链”。除了检查所选答案是否正确外，评估还可以考察LLM对其回答的概率估计，以体现LLM对其回答的信心程度。在本文中，我们研究了LLM在被要求直接作答与先提供推理再作答这两种情况下，其对自身答案的信心度是否会有所不同。在七个不同模型上针对广泛主题的多个问题的评估结果显示，当LLM在作答前提供推理时，其对答案的信心度更高。无论所选答案是否正确，这种现象都普遍存在。我们认为这种行为可能是由于推理过程改变了所选答案的概率估计，因为LLM是基于输入问题和支撑其选择的推理来进行预测的。因此，LLM的概率估计似乎存在固有的局限性，需要理解这些局限性以便在评估过程中加以应用。有趣的是，同样的行为也观察到了人类身上，对于人类而言，在解释答案时信心会增加其正确性的感知。', 'title_zh': '多项选择题：推理使大型语言模型（LLMs）即使在错误的情况下也更加自信'}
{'arxiv_id': 'arXiv:2501.09770', 'title': 'EVAL: EigenVector-based Average-reward Learning', 'authors': 'Jacob Adamczyk, Volodymyr Makarenko, Stas Tiomkin, Rahul V. Kulkarni', 'link': 'https://arxiv.org/abs/2501.09770', 'abstract': 'In reinforcement learning, two objective functions have been developed extensively in the literature: discounted and averaged rewards. The generalization to an entropy-regularized setting has led to improved robustness and exploration for both of these objectives. Recently, the entropy-regularized average-reward problem was addressed using tools from large deviation theory in the tabular setting. This method has the advantage of linearity, providing access to both the optimal policy and average reward-rate through properties of a single matrix. In this paper, we extend that framework to more general settings by developing approaches based on function approximation by neural networks. This formulation reveals new theoretical insights into the relationship between different objectives used in RL. Additionally, we combine our algorithm with a posterior policy iteration scheme, showing how our approach can also solve the average-reward RL problem without entropy-regularization. Using classic control benchmarks, we experimentally find that our method compares favorably with other algorithms in terms of stability and rate of convergence.', 'abstract_zh': '在强化学习中，文献中广泛发展了两种目标函数：折扣奖励和平均奖励。将这两种目标函数推广到带熵正则化的设置中，可以增强其稳健性和探索性。最近，使用大型 deviation 理论中的工具，针对表征设置下平均奖励问题中的熵正则化方法进行了研究。该方法的优势在于线性性，通过单个矩阵的性质可以同时获得最优策略和平均奖励率。在本文中，我们通过基于神经网络的功能近似方法，将该框架扩展到更一般的设置中。这种表述揭示了不同在强化学习中使用的各种目标函数之间的新的理论洞察。此外，我们将我们的算法与后验策略迭代方案相结合，展示了我们的方法也可以在不使用熵正则化的情况下解决平均奖励的强化学习问题。通过使用经典的控制基准实验，我们发现我们的方法在稳定性和收敛速度方面与其他算法相比具有竞争力。', 'title_zh': 'EVAL：基于特征向量的平均奖励学习'}
{'arxiv_id': 'arXiv:2501.09768', 'title': 'Can Large Language Models Predict the Outcome of Judicial Decisions?', 'authors': 'Mohamed Bayan Kmainasi, Ali Ezzat Shahroor, Amani Al-Ghraibah', 'link': 'https://arxiv.org/abs/2501.09768', 'abstract': 'Large Language Models (LLMs) have shown exceptional capabilities in Natural Language Processing (NLP) across diverse domains. However, their application in specialized tasks such as Legal Judgment Prediction (LJP) for low-resource languages like Arabic remains underexplored. In this work, we address this gap by developing an Arabic LJP dataset, collected and preprocessed from Saudi commercial court judgments. We benchmark state-of-the-art open-source LLMs, including LLaMA-3.2-3B and LLaMA-3.1-8B, under varying configurations such as zero-shot, one-shot, and fine-tuning using QLoRA. Additionally, we used a comprehensive evaluation framework combining quantitative metrics (BLEU and ROUGE) and qualitative assessments (Coherence, legal language, clarity). Our results demonstrate that fine-tuned smaller models achieve comparable performance to larger models in task-specific contexts while offering significant resource efficiency. Furthermore, we investigate the effects of prompt engineering and fine-tuning on model outputs, providing insights into performance variability and instruction sensitivity. By making the dataset, implementation code, and models publicly available, we establish a robust foundation for future research in Arabic legal NLP.', 'abstract_zh': '大型语言模型（LLMs）在跨多个领域进行自然语言处理（NLP）方面展现出了非凡的能力。然而，它们在阿拉伯语等低资源语言的法律判决预测（LJP）等专业化任务中的应用仍未得到充分探索。本文通过建立并预处理了来自沙特商业法院判决的阿拉伯语LJP数据集，来弥补这一空白。我们使用了包括LLaMA-3.2-3B和LLaMA-3.1-8B在内的最新开源LLMs，并在零样本、单样本和使用QLoRA微调等不同配置下进行了基准测试。此外，我们采用了一套综合的评估框架，结合定量指标（BLEU和ROUGE）和定性评估（连贯性、法律语言、清晰度）来进行评估。我们的结果显示，在特定任务中，微调后的较小模型可以达到与大型模型相当的性能，同时在资源效率上具有明显优势。此外，我们还研究了提示工程和微调对模型输出的影响，提供了关于性能变异性及指令敏感性的见解。通过公开数据集、实现代码和模型，我们为未来阿拉伯语法律NLP的研究奠定了坚实的基础。', 'title_zh': '大型语言模型能否预测司法判决的结果？'}
{'arxiv_id': 'arXiv:2501.09767', 'title': 'LeMo: Enabling LEss Token Involvement for MOre Context Fine-tuning', 'authors': 'Tuowei Wang, Xingyu Chen, Kun Li, Ting Cao, Ju Ren, Yaoxue Zhang', 'link': 'https://arxiv.org/abs/2501.09767', 'abstract': 'The escalating demand for long-context applications has intensified the necessity of extending the LLM context windows. Despite recent fine-tuning approaches successfully expanding context lengths, their high memory footprints, especially for activations, present a critical practical limitation. Current parameter-efficient fine-tuning methods prioritize reducing parameter update overhead over addressing activation memory constraints. Similarly, existing sparsity mechanisms improve computational efficiency but overlook activation memory optimization due to the phenomenon of Shadowy Activation.\nIn this paper, we propose LeMo, the first LLM fine-tuning system that explores and exploits a new token-level sparsity mechanism inherent in long-context scenarios, termed Contextual Token Sparsity. LeMo minimizes redundant token involvement by assessing the informativeness of token embeddings while preserving model accuracy. Specifically, LeMo introduces three key techniques: (1) Token Elimination, dynamically identifying and excluding redundant tokens across varying inputs and layers. (2) Pattern Prediction, utilizing well-trained predictors to approximate token sparsity patterns with minimal overhead. (3) Kernel Optimization, employing permutation-free and segment-based strategies to boost system performance. We implement LeMo as an end-to-end fine-tuning system compatible with various LLM architectures and other optimization techniques. Comprehensive evaluations demonstrate that LeMo reduces memory consumption by up to 1.93x and achieves up to 1.36x speedups, outperforming state-of-the-art fine-tuning systems.', 'abstract_zh': '随着对长上下文应用需求的不断增长，延长LLM的上下文窗口变得愈发必要。尽管近年来的微调方法成功地扩展了上下文长度，但它们高内存占用，特别是激活值的内存占用，成为关键的应用限制。目前的参数高效微调方法侧重于减少参数更新开销，而忽视了解决激活内存限制的问题。同样，现有的稀疏机制虽然提高了计算效率，但由于“幽暗激活”现象的影响，忽略了激活内存优化。\n\n本文提出了一种新的LLM微调系统——LeMo，这是首个探索和利用长上下文场景中固有的新token级稀疏机制的系统，称之为上下文相关token稀疏性（Contextual Token Sparsity）。LeMo通过评估token嵌入的有用性并保留模型准确性来最小化冗余token的参与。具体而言，LeMo引入了三种关键技术：（1）Token Elimination，动态地识别和排除不同输入和层间的冗余token。（2）Pattern Prediction，利用训练良好的预测器以最小的开销近似token稀疏模式。（3）Kernel Optimization，采用无排列和基于段的策略来提升系统性能。我们实现了LeMo作为兼容各种LLM架构和其他优化技术的端到端微调系统。全面的评估结果表明，LeMo可以将内存消耗减少高达1.93倍，并实现高达1.36倍的速度提升，超越了最先进的微调系统。', 'title_zh': 'LeMo：使Token参与 fewer，以便实现更多的上下文微调'}
{'arxiv_id': 'arXiv:2501.09766', 'title': 'Boosting Tool Use of Large Language Models via Iterative Reinforced Fine-Tuning', 'authors': 'Yirong Zeng, Xiao Ding, Yuxian Wang, Weiwen Liu, Wu Ning, Yutai Hou, Xu Huang, Bing Qin, Ting Liu', 'link': 'https://arxiv.org/abs/2501.09766', 'abstract': "Augmenting large language models (LLMs) with external tools is a promising approach to enhance their capabilities. Effectively leveraging this potential for complex tasks hinges crucially on improving their ability to use tools. Synthesizing tool use data by simulating the real world is an effective approach. Nevertheless, our investigation reveals that training gains significantly decay as the scale of these data increases. The primary factor is the model's poor performance (a.k.a deficiency) in complex scenarios, which hinders learning from data using SFT. Driven by this objective, we propose an iterative reinforced fine-tuning strategy to continually guide the model to alleviate it. Specifically, we first identify deficiency-related data based on feedback from the policy model, then perform a Monte Carlo Tree Search to collect fine-grained preference pairs to pinpoint deficiencies. Subsequently, we update the policy model using preference optimization to align with ground truth and misalign with deficiencies. This process can be iterated. Moreover, before the iteration, we propose an easy-to-hard warm-up SFT strategy to facilitate learning from challenging data. The experiments demonstrate our models go beyond the same parametric models, outperforming many larger open-source and closed-source models. Additionally, it has achieved notable training gains in complex tool use scenarios.", 'abstract_zh': '增强大型语言模型（LLMs）的功能可以通过与外部工具结合来实现，这是一种有前途的方法。要有效地利用这一潜力以应对复杂任务，关键在于提高模型使用工具的能力。通过模拟现实世界来综合工具使用数据是一种有效的方法。然而，我们的研究发现，随着这些数据规模的增加，训练增益显著衰减。主要因素是模型在复杂场景中的表现较差（即缺陷），这阻碍了通过强化 fine-tuning（SFT）从数据中学习。受到这一目标的驱动，我们提出了一种迭代强化 fine-tuning 策略，不断引导模型以减轻这些问题。具体而言，首先根据策略模型提供的反馈识别与缺陷相关的数据，然后进行蒙特卡洛树搜索以收集细粒度的偏好对，以确定缺陷。随后，我们使用偏好优化更新策略模型，使其与真实情况对齐，并与缺陷不一致。该过程可以迭代进行。此外，在迭代之前，我们提出了一种易于开始到困难的 warm-up SFT 策略，以促进从挑战性数据中学习。实验表明，我们的模型超越了相同参数量的模型，优于许多更大规模的开源和闭源模型。此外，该策略还在复杂工具使用场景下实现了显著的训练增益。', 'title_zh': '通过迭代强化微调增强大型语言模型的工具使用能力'}
{'arxiv_id': 'arXiv:2501.09765', 'title': 'Enhancing the De-identification of Personally Identifiable Information in Educational Data', 'authors': 'Y. Shen, Z. Ji, J. Lin, K. R. Koedginer', 'link': 'https://arxiv.org/abs/2501.09765', 'abstract': "Protecting Personally Identifiable Information (PII), such as names, is a critical requirement in learning technologies to safeguard student and teacher privacy and maintain trust. Accurate PII detection is an essential step toward anonymizing sensitive information while preserving the utility of educational data. Motivated by recent advancements in artificial intelligence, our study investigates the GPT-4o-mini model as a cost-effective and efficient solution for PII detection tasks. We explore both prompting and fine-tuning approaches and compare GPT-4o-mini's performance against established frameworks, including Microsoft Presidio and Azure AI Language. Our evaluation on two public datasets, CRAPII and TSCC, demonstrates that the fine-tuned GPT-4o-mini model achieves superior performance, with a recall of 0.9589 on CRAPII. Additionally, fine-tuned GPT-4o-mini significantly improves precision scores (a threefold increase) while reducing computational costs to nearly one-tenth of those associated with Azure AI Language. Furthermore, our bias analysis reveals that the fine-tuned GPT-4o-mini model consistently delivers accurate results across diverse cultural backgrounds and genders. The generalizability analysis using the TSCC dataset further highlights its robustness, achieving a recall of 0.9895 with minimal additional training data from TSCC. These results emphasize the potential of fine-tuned GPT-4o-mini as an accurate and cost-effective tool for PII detection in educational data. It offers robust privacy protection while preserving the data's utility for research and pedagogical analysis. Our code is available on GitHub: this https URL", 'abstract_zh': '保护个人可识别信息（PII），如姓名，在学习技术中是一个关键要求，以确保学生和教师的隐私并维护信任。准确的PII检测是实现敏感信息匿名化同时保留教育数据实用性的重要步骤。受最近人工智能进展的启发，本研究探讨了GPT-4o-mini模型作为PII检测任务的经济高效且高效的解决方案。我们研究了提示和微调两种方法，并将GPT-4o-mini的性能与Microsoft Presidio和Azure AI Language等现有框架进行了比较。我们在两个公开数据集CRAPII和TSCC上的评估表明，微调后的GPT-4o-mini模型表现更加出色，CRAPII数据集的召回率为0.9589。此外，微调后的GPT-4o-mini在精确度方面显著提高（提高三倍），同时将计算成本降低到Azure AI Language相关成本的十分之一左右。另外，我们的偏差分析表明，微调后的GPT-4o-mini模型能够在不同的文化背景和性别中持续提供准确的结果。使用TSCC数据集进行的通用性分析进一步突出了其稳健性，即使使用少量额外的TSCC训练数据也实现了0.9895的召回率。这些结果强调了微调后的GPT-4o-mini作为教育数据中PII检测准确且经济有效的工具的潜力。它在提供强大隐私保护的同时，还保留了数据的研究和教学分析价值。我们的代码已发布在GitHub上：this https URL', 'title_zh': '提升教育数据中个人可识别信息去标识化的效果'}
{'arxiv_id': 'arXiv:2501.09761', 'title': 'VERITAS: Verifying the Performance of AI-native Transceiver Actions in Base-Stations', 'authors': 'Nasim Soltani, Michael Loehning, Kaushik Chowdhury', 'link': 'https://arxiv.org/abs/2501.09761', 'abstract': 'Artificial Intelligence (AI)-native receivers prove significant performance improvement in high noise regimes and can potentially reduce communication overhead compared to the traditional receiver. However, their performance highly depends on the representativeness of the training dataset. A major issue is the uncertainty of whether the training dataset covers all test environments and waveform configurations, and thus, whether the trained model is robust in practical deployment conditions. To this end, we propose a joint measurement-recovery framework for AI-native transceivers post deployment, called VERITAS, that continuously looks for distribution shifts in the received signals and triggers finite re-training spurts. VERITAS monitors the wireless channel using 5G pilots fed to an auxiliary neural network that detects out-of-distribution channel profile, transmitter speed, and delay spread. As soon as such a change is detected, a traditional (reference) receiver is activated, which runs for a period of time in parallel to the AI-native receiver. Finally, VERTIAS compares the bit probabilities of the AI-native and the reference receivers for the same received data inputs, and decides whether or not a retraining process needs to be initiated. Our evaluations reveal that VERITAS can detect changes in the channel profile, transmitter speed, and delay spread with 99%, 97%, and 69% accuracies, respectively, followed by timely initiation of retraining for 86%, 93.3%, and 94.8% of inputs in channel profile, transmitter speed, and delay spread test sets, respectively.', 'abstract_zh': 'AI原生接收机在高噪声环境下表现出显著的性能提升，并且与传统接收机相比，有可能减少通信开销。然而，其性能高度依赖于训练数据集的代表性。主要问题是训练数据集是否涵盖了所有测试环境和波形配置，从而决定了训练模型在实际部署条件下的鲁棒性。为了解决这一问题，我们提出了一种名为VERITAS的联合测量-恢复框架，该框架在部署后用于AI原生传输接收机，持续检测接收信号中的分布偏移并触发有限的重新训练周期。VERITAS使用5G导频信号喂入辅助神经网络，以检测超出分布范围的信道特征、发射机速度和时延扩展。一旦检测到这些变化，传统的（参考）接收机会被激活，并且会与AI原生接收机并行运行一段时间。最后，VERITAS将AI原生接收机和参考接收机在同一输入数据下的位概率进行比较，并决定是否需要启动重新训练过程。我们的评估结果显示，VERITAS可以在信道特征、发射机速度和时延扩展的变化检测中分别达到99%、97%和69%的准确性，并且在信道特征、发射机速度和时延扩展测试集中的输入中，能及时启动重新训练的比例分别为86%、93.3%和94.8%。', 'title_zh': 'VERITAS：验证AI原生传输收发器动作在基站中的性能'}
{'arxiv_id': 'arXiv:2501.09751', 'title': 'OmniThink: Expanding Knowledge Boundaries in Machine Writing through Thinking', 'authors': 'Zekun Xi, Wenbiao Yin, Jizhan Fang, Jialong Wu, Runnan Fang, Ningyu Zhang, Jiang Yong, Pengjun Xie, Fei Huang, Huajun Chen', 'link': 'https://arxiv.org/abs/2501.09751', 'abstract': "Machine writing with large language models often relies on retrieval-augmented generation. However, these approaches remain confined within the boundaries of the model's predefined scope, limiting the generation of content with rich information. Specifically, vanilla-retrieved information tends to lack depth, utility, and suffers from redundancy, which negatively impacts the quality of generated articles, leading to shallow, repetitive, and unoriginal outputs. To address these issues, we propose OmniThink, a machine writing framework that emulates the human-like process of iterative expansion and reflection. The core idea behind OmniThink is to simulate the cognitive behavior of learners as they progressively deepen their knowledge of the topics. Experimental results demonstrate that OmniThink improves the knowledge density of generated articles without compromising metrics such as coherence and depth. Human evaluations and expert feedback further highlight the potential of OmniThink to address real-world challenges in the generation of long-form articles.", 'abstract_zh': '大规模语言模型进行机器写作时，往往依赖于检索增强生成。然而，这些方法仍然局限于模型预设的范围边界，限制了内容丰富性的生成。具体来说，传统的检索信息往往缺乏深度、实用性和冗余，这会负面影响生成文章的质量，导致浅薄、重复且缺乏原创性的输出。为了解决这些问题，我们提出了一种名为OmniThink的机器写作框架，该框架模拟了人类逐步深化知识理解的迭代扩展和反思过程。OmniThink的核心思想是模拟学习者在逐步深化主题理解过程中的认知行为。实验结果表明，OmniThink能够提高生成文章的知识密度，同时不牺牲连贯性和深度等指标。人类评估和专家反馈进一步强调了OmniThink在解决长文生成中的实际挑战方面的潜力。', 'title_zh': 'OmniThink：通过思考拓展机器写作的知识边界'}
