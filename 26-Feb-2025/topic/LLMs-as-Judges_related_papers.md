# Debt Collection Negotiations with Large Language Models: An Evaluation System and Optimizing Decision Making with Multi-Agent 

**Title (ZH)**: 使用大型语言模型进行债务追收谈判：评估系统与多代理优化决策研究 

**Authors**: Xiaofeng Wang, Zhixin Zhang, Jinguang Zheng, Yiming Ai, Rui Wang  

**Link**: [PDF](https://arxiv.org/pdf/2502.18228)  

**Abstract**: Debt collection negotiations (DCN) are vital for managing non-performing loans (NPLs) and reducing creditor losses. Traditional methods are labor-intensive, while large language models (LLMs) offer promising automation potential. However, prior systems lacked dynamic negotiation and real-time decision-making capabilities. This paper explores LLMs in automating DCN and proposes a novel evaluation framework with 13 metrics across 4 aspects. Our experiments reveal that LLMs tend to over-concede compared to human negotiators. To address this, we propose the Multi-Agent Debt Negotiation (MADeN) framework, incorporating planning and judging modules to improve decision rationality. We also apply post-training techniques, including DPO with rejection sampling, to optimize performance. Our studies provide valuable insights for practitioners and researchers seeking to enhance efficiency and outcomes in this domain. 

**Abstract (ZH)**: 债务催收谈判（DCN）对于管理不良贷款（NPLs）和减少债权人的损失至关重要。传统方法耗时且劳动密集，而大型语言模型（LLMs）则提供了自动化的潜力。然而，之前的系统缺乏动态谈判和实时决策的能力。本文探讨了利用LLMs自动进行DCN的方法，并提出了一种全新的评估框架，涵盖4个方面的13个指标。我们的实验表明，与人类谈判者相比，LLMs往往会过度让步。为解决这一问题，我们提出了一个多智能体债务谈判（MADeN）框架，该框架通过引入计划和判断模块以提高决策的合理性。此外，我们还应用了后训练技术，包括带 rejection sampling 的 DPO，以优化性能。我们的研究为希望在此领域提高效率和成果的实践者和研究人员提供了宝贵的见解。 

---
# Verdict: A Library for Scaling Judge-Time Compute 

**Title (ZH)**: 判决：一个扩展判决时计算的库 

**Authors**: Nimit Kalra, Leonard Tang  

**Link**: [PDF](https://arxiv.org/pdf/2502.18018)  

**Abstract**: The use of LLMs as automated judges ("LLM-as-a-judge") is now widespread, yet standard judges suffer from a multitude of reliability issues. To address these challenges, we introduce Verdict, an open-source library for scaling judge-time compute to enhance the accuracy, reliability, and interpretability of automated evaluators. Verdict leverages the composition of modular reasoning units -- such as verification, debate, and aggregation -- and increased inference-time compute to improve LLM judge quality. Across a variety of challenging tasks such as content moderation, fact-checking, and hallucination detection, Verdict judges achieve state-of-the-art (SOTA) or near-SOTA performance, surpassing orders-of-magnitude larger fine-tuned judges, prompted judges, and reasoning models. Ultimately, we hope Verdict serves as a useful framework for researchers and practitioners building scalable, interpretable, and reliable LLM-based evaluators. 

**Abstract (ZH)**: 作为自动化法官（“LLM-as-a-judge”）的大型语言模型（LLM）如今已被广泛应用，然而标准法官面临着众多可靠性问题。为应对这些挑战，我们提出了Verdict——一个开源库，用于扩展法官时间计算量，以提升自动化评估器的准确度、可靠性和可解释性。Verdict 利用模块化推理单元（如验证、辩论和聚合）的组合以及增加推理时间计算量来提高 LLM 法官的质量。在内容审核、事实核查和幻觉检测等各种具有挑战性的任务中，Verdict 法官实现了目前最先进（SOTA）或接近最先进（near-SOTA）的性能，超越了大量微调法官、触发法官和推理模型。最终，我们希望Verdict能够作为研究人员和实践者构建可扩展、可解释且可靠的基于LLM的评估器的一个有用框架。 

---
# FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking Evaluation of Large Language Models 

**Title (ZH)**: FACT-AUDIT：一种适应性多代理框架，用于大型语言模型动态事实核查评估 

**Authors**: Hongzhan Lin, Yang Deng, Yuxuan Gu, Wenxuan Zhang, Jing Ma, See-Kiong Ng, Tat-Seng Chua  

**Link**: [PDF](https://arxiv.org/pdf/2502.17924)  

**Abstract**: Large Language Models (LLMs) have significantly advanced the fact-checking studies. However, existing automated fact-checking evaluation methods rely on static datasets and classification metrics, which fail to automatically evaluate the justification production and uncover the nuanced limitations of LLMs in fact-checking. In this work, we introduce FACT-AUDIT, an agent-driven framework that adaptively and dynamically assesses LLMs' fact-checking capabilities. Leveraging importance sampling principles and multi-agent collaboration, FACT-AUDIT generates adaptive and scalable datasets, performs iterative model-centric evaluations, and updates assessments based on model-specific responses. By incorporating justification production alongside verdict prediction, this framework provides a comprehensive and evolving audit of LLMs' factual reasoning capabilities, to investigate their trustworthiness. Extensive experiments demonstrate that FACT-AUDIT effectively differentiates among state-of-the-art LLMs, providing valuable insights into model strengths and limitations in model-centric fact-checking analysis. 

**Abstract (ZH)**: 大型语言模型（LLMs）在事实核查研究中取得了显著进展。然而，现有的自动化事实核查评估方法依赖于静态数据集和分类指标，无法自动评估推理过程中的论证生成，并揭示LLMs在事实核查中的细微限制。在此项工作中，我们引入了FACT-AUDIT，这是一种基于代理的框架，能够适应性和动态地评估LLMs的事实核查能力。通过利用重要性采样原理和多代理协作，FACT-AUDIT生成适应性和可扩展的数据集，进行迭代的模型导向评估，并根据模型特定的响应更新评估结果。通过结合论证生成与判决预测，这一框架提供了对LLMs事实推理能力的全面且不断演化的审计，以研究其可信度。大量实验证明，FACT-AUDIT能够有效地区分最先进的LLMs，并提供了有关模型在模型导向的事实核查分析中优势和局限性的宝贵见解。 

---
